{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPC48th8IWLon1wKjVIF6Yy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyTHVHaDaXOP","executionInfo":{"status":"ok","timestamp":1711565313489,"user_tz":-60,"elapsed":19307,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"3b50ab1c-c79d-4688-db86-4e8822e66b3b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.4.0)\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.5.2\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch_geometric.nn as graphnn\n","import pandas as pd\n","from sklearn.metrics import f1_score\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.utils import scatter\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.model_selection import KFold\n","from itertools import product\n"],"metadata":{"id":"bOJ3iArDfiUG","executionInfo":{"status":"ok","timestamp":1711565344522,"user_tz":-60,"elapsed":8699,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nDevice: \", device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTQnYw9QHvE4","executionInfo":{"status":"ok","timestamp":1711565348808,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"02c5f893-32ca-4c62-807d-5428e5a9eeeb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Device:  cuda\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"OB2lZuGuaD0h","executionInfo":{"status":"ok","timestamp":1711565367643,"user_tz":-60,"elapsed":18424,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2a529e71-141b-4fb3-e591-61dd3809e663"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n","Processing...\n","Done!\n","Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-BINARY.zip\n","Processing...\n","Done!\n","Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n","Processing...\n","Done!\n"]}],"source":["from torch_geometric.datasets import TUDataset\n","\n","dataset_en = TUDataset(root='', name='ENZYMES',use_node_attr = True)\n","dataset_rd = TUDataset(root='', name='REDDIT-BINARY')\n","dataset_pr = TUDataset(root='', name='PROTEINS')\n"]},{"cell_type":"code","source":["print(len(dataset_en))\n","print(len(dataset_rd))\n","print(len(dataset_pr))\n","\n","print(dataset_en.num_classes)\n","print(dataset_rd.num_classes)\n","print(dataset_pr.num_classes)\n","\n","print(dataset_en.num_node_features)\n","print(dataset_rd.num_node_features)\n","print(dataset_pr.num_node_features)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmBdQSPvaPp8","executionInfo":{"status":"ok","timestamp":1711565367643,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"78b5ca53-3ab9-4925-bcb3-d7178675ab5b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["600\n","2000\n","1113\n","6\n","2\n","2\n","21\n","0\n","3\n"]}]},{"cell_type":"markdown","source":["# try with a basic GNN model"],"metadata":{"id":"Q1f8mdVvfa7w"}},{"cell_type":"code","source":["class BasicGraphModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size,dropout_rate=0.5):\n","        super().__init__()\n","\n","        self.graphconv1 = graphnn.GCNConv(input_size, hidden_size)\n","        self.graphconv2 = graphnn.GCNConv(hidden_size, hidden_size)\n","        self.graphconv3 = graphnn.GCNConv(hidden_size, output_size)\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        self.elu = nn.ELU()\n","\n","    def forward(self, data):\n","        x = self.graphconv1(data.x, data.edge_index)\n","        x = self.elu(x)\n","        x = self.dropout(x)\n","        x = self.graphconv2(x, data.edge_index)\n","        x = self.elu(x)\n","        x = self.dropout(x)\n","        x = self.graphconv3(x, data.edge_index)\n","        x = graphnn.global_mean_pool(x, data.batch)\n","\n","        return x"],"metadata":{"id":"iKIAFW3YfCFf","executionInfo":{"status":"ok","timestamp":1711565371571,"user_tz":-60,"elapsed":3,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["#Define evaluate and train function"],"metadata":{"id":"20sSTS0EhZz0"}},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","train_en = dataset_en[:int(len(dataset_en)*0.8)]\n","val_en = dataset_en[int(len(dataset_en)*0.8):int(len(dataset_en)*0.9)]\n","test_en = dataset_en[int(len(dataset_en)*0.9):]\n","\n","train_en_loader = DataLoader(train_en, batch_size=32, shuffle=True)\n","val_en_loader = DataLoader(val_en, batch_size=32, shuffle=False)\n","test_en_loader = DataLoader(test_en, batch_size=32, shuffle=False)"],"metadata":{"id":"TeNQ3Pd4UZYb","executionInfo":{"status":"ok","timestamp":1711565380656,"user_tz":-60,"elapsed":562,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train(model, loss_fcn, device, optimizer, max_epochs, train_dataloader, val_dataloader, patience=30):\n","    best_val_score = 0\n","    patience_counter = 0\n","    metrics_history = {'train_loss': [], 'val_loss': [], 'f1_micro': [], 'f1_macro': [], 'accuracy': [], 'best_score':[]}\n","\n","    for epoch in range(max_epochs):\n","        model.train()\n","        train_losses = []\n","        for batch in train_dataloader:\n","            if batch.x is None:\n","                raise ValueError(\"Node features are missing. Ensure data.x is correctly set.\")\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            logits = model(batch)\n","            loss = loss_fcn(logits, batch.y)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","\n","        val_loss = evaluate_loss(model, loss_fcn, device, val_dataloader)\n","        f1_micro, f1_macro, accuracy = evaluate_metrics(model, device, val_dataloader)\n","\n","        # Save metrics\n","        metrics_history['train_loss'].append(np.mean(train_losses))\n","        metrics_history['val_loss'].append(val_loss)\n","        metrics_history['f1_micro'].append(f1_micro)\n","        metrics_history['f1_macro'].append(f1_macro)\n","        metrics_history['accuracy'].append(accuracy)\n","\n","        print(f\"Epoch {epoch+1}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {val_loss:.4f}, F1 Micro: {f1_micro:.4f}, F1 Macro: {f1_macro:.4f}, Accuracy: {accuracy:.4f}\")\n","\n","        # Early stopping logic using f1_micro score\n","        if f1_micro > best_val_score:\n","            best_val_score = f1_micro\n","            metrics_history['best_score'] = best_val_score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(\"Early stopping triggered\")\n","                break\n","\n","    return metrics_history"],"metadata":{"id":"jlJ8V6gVwq7C","executionInfo":{"status":"ok","timestamp":1711565383396,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def evaluate_loss(model, loss_fcn, device, dataloader):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            batch = batch.to(device)\n","            outputs = model(batch)\n","            loss = loss_fcn(outputs, batch.y)\n","            total_loss += loss.item()\n","    return total_loss / len(dataloader)"],"metadata":{"id":"6lMiFDy9zrmH","executionInfo":{"status":"ok","timestamp":1711565384405,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def evaluate_metrics(model, device, dataloader):\n","    model.eval()\n","    total_preds = []\n","    total_targets = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            batch = batch.to(device)\n","            outputs = model(batch)\n","            _, predicted = torch.max(outputs, 1)\n","            total_preds.extend(predicted.view(-1).cpu().numpy())\n","            total_targets.extend(batch.y.view(-1).cpu().numpy())\n","\n","    f1_micro = f1_score(total_targets, total_preds, average='micro')\n","    f1_macro = f1_score(total_targets, total_preds, average='macro')\n","    accuracy = accuracy_score(total_targets, total_preds)\n","    return f1_micro, f1_macro, accuracy"],"metadata":{"id":"K6PSJ-sTwvT2","executionInfo":{"status":"ok","timestamp":1711565385569,"user_tz":-60,"elapsed":1,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["\n","### Max number of epochs\n","max_epochs = 300\n","n_features = dataset_en.num_node_features\n","n_classes = dataset_en.num_classes\n","### DEFINE THE MODEL\n","basic_model = BasicGraphModel(\n","    input_size=n_features, hidden_size=256, output_size=n_classes\n",").to(device)\n","\n","### DEFINE LOSS FUNCTION\n","loss_fcn = nn.CrossEntropyLoss()\n","### DEFINE OPTIMIZER\n","optimizer = torch.optim.Adam(basic_model.parameters(), lr=0.001)\n","\n","### TRAIN THE MODEL\n","metrics_history=train(\n","    basic_model,\n","    loss_fcn,\n","    device,\n","    optimizer,\n","    max_epochs,\n","    train_en_loader,\n","    val_en_loader,\n","    patience=100\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3JDPSLZissT","executionInfo":{"status":"ok","timestamp":1711565587114,"user_tz":-60,"elapsed":16452,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"52b7295c-e05a-45da-cfeb-056135f9c3eb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 3.0010, Val Loss: 24.1678, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 2, Train Loss: 2.2168, Val Loss: 23.8126, F1 Micro: 0.3000, F1 Macro: 0.2000, Accuracy: 0.3000\n","Epoch 3, Train Loss: 2.1167, Val Loss: 21.7633, F1 Micro: 0.3000, F1 Macro: 0.1043, Accuracy: 0.3000\n","Epoch 4, Train Loss: 1.9451, Val Loss: 19.5818, F1 Micro: 0.3000, F1 Macro: 0.1304, Accuracy: 0.3000\n","Epoch 5, Train Loss: 1.9856, Val Loss: 17.9018, F1 Micro: 0.0833, F1 Macro: 0.0833, Accuracy: 0.0833\n","Epoch 6, Train Loss: 1.8673, Val Loss: 16.2364, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 7, Train Loss: 1.7605, Val Loss: 15.1460, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 8, Train Loss: 1.7038, Val Loss: 14.0629, F1 Micro: 0.0167, F1 Macro: 0.0160, Accuracy: 0.0167\n","Epoch 9, Train Loss: 1.6442, Val Loss: 12.9626, F1 Micro: 0.2833, F1 Macro: 0.0958, Accuracy: 0.2833\n","Epoch 10, Train Loss: 1.6621, Val Loss: 11.9540, F1 Micro: 0.1167, F1 Macro: 0.0778, Accuracy: 0.1167\n","Epoch 11, Train Loss: 1.6437, Val Loss: 10.8491, F1 Micro: 0.2833, F1 Macro: 0.1090, Accuracy: 0.2833\n","Epoch 12, Train Loss: 1.6067, Val Loss: 10.3607, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 13, Train Loss: 1.6386, Val Loss: 10.0742, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 14, Train Loss: 1.6023, Val Loss: 8.3943, F1 Micro: 0.0667, F1 Macro: 0.0460, Accuracy: 0.0667\n","Epoch 15, Train Loss: 1.5554, Val Loss: 7.8827, F1 Micro: 0.0500, F1 Macro: 0.0435, Accuracy: 0.0500\n","Epoch 16, Train Loss: 1.5483, Val Loss: 7.3782, F1 Micro: 0.0167, F1 Macro: 0.0159, Accuracy: 0.0167\n","Epoch 17, Train Loss: 1.5628, Val Loss: 6.5633, F1 Micro: 0.0333, F1 Macro: 0.0303, Accuracy: 0.0333\n","Epoch 18, Train Loss: 1.4834, Val Loss: 6.3617, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 19, Train Loss: 1.5998, Val Loss: 5.8809, F1 Micro: 0.2333, F1 Macro: 0.1197, Accuracy: 0.2333\n","Epoch 20, Train Loss: 1.4972, Val Loss: 5.5460, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 21, Train Loss: 1.4747, Val Loss: 5.2802, F1 Micro: 0.2667, F1 Macro: 0.1088, Accuracy: 0.2667\n","Epoch 22, Train Loss: 1.5634, Val Loss: 5.0859, F1 Micro: 0.2500, F1 Macro: 0.1190, Accuracy: 0.2500\n","Epoch 23, Train Loss: 1.4885, Val Loss: 5.1904, F1 Micro: 0.1833, F1 Macro: 0.1111, Accuracy: 0.1833\n","Epoch 24, Train Loss: 1.4850, Val Loss: 5.0748, F1 Micro: 0.2167, F1 Macro: 0.1111, Accuracy: 0.2167\n","Epoch 25, Train Loss: 1.4397, Val Loss: 5.1598, F1 Micro: 0.0833, F1 Macro: 0.0667, Accuracy: 0.0833\n","Epoch 26, Train Loss: 1.4404, Val Loss: 5.0880, F1 Micro: 0.0500, F1 Macro: 0.0400, Accuracy: 0.0500\n","Epoch 27, Train Loss: 1.4616, Val Loss: 4.9522, F1 Micro: 0.2500, F1 Macro: 0.1282, Accuracy: 0.2500\n","Epoch 28, Train Loss: 1.4754, Val Loss: 5.0671, F1 Micro: 0.2000, F1 Macro: 0.1297, Accuracy: 0.2000\n","Epoch 29, Train Loss: 1.4517, Val Loss: 5.0220, F1 Micro: 0.2833, F1 Macro: 0.1288, Accuracy: 0.2833\n","Epoch 30, Train Loss: 1.4433, Val Loss: 5.2679, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 31, Train Loss: 1.4368, Val Loss: 5.2057, F1 Micro: 0.2000, F1 Macro: 0.1250, Accuracy: 0.2000\n","Epoch 32, Train Loss: 1.4188, Val Loss: 5.4242, F1 Micro: 0.2333, F1 Macro: 0.1333, Accuracy: 0.2333\n","Epoch 33, Train Loss: 1.4414, Val Loss: 5.3130, F1 Micro: 0.2833, F1 Macro: 0.1349, Accuracy: 0.2833\n","Epoch 34, Train Loss: 1.4048, Val Loss: 5.7583, F1 Micro: 0.0500, F1 Macro: 0.0435, Accuracy: 0.0500\n","Epoch 35, Train Loss: 1.3817, Val Loss: 5.4598, F1 Micro: 0.2333, F1 Macro: 0.1600, Accuracy: 0.2333\n","Epoch 36, Train Loss: 1.4244, Val Loss: 5.8162, F1 Micro: 0.1667, F1 Macro: 0.1333, Accuracy: 0.1667\n","Epoch 37, Train Loss: 1.4044, Val Loss: 5.8939, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 38, Train Loss: 1.4056, Val Loss: 6.0925, F1 Micro: 0.0333, F1 Macro: 0.0364, Accuracy: 0.0333\n","Epoch 39, Train Loss: 1.4081, Val Loss: 6.1310, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 40, Train Loss: 1.3989, Val Loss: 5.8876, F1 Micro: 0.1333, F1 Macro: 0.1143, Accuracy: 0.1333\n","Epoch 41, Train Loss: 1.4120, Val Loss: 5.4862, F1 Micro: 0.0833, F1 Macro: 0.0667, Accuracy: 0.0833\n","Epoch 42, Train Loss: 1.3662, Val Loss: 5.5208, F1 Micro: 0.1833, F1 Macro: 0.1183, Accuracy: 0.1833\n","Epoch 43, Train Loss: 1.3593, Val Loss: 6.1488, F1 Micro: 0.1000, F1 Macro: 0.0769, Accuracy: 0.1000\n","Epoch 44, Train Loss: 1.3867, Val Loss: 6.0926, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 45, Train Loss: 1.3762, Val Loss: 6.3605, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 46, Train Loss: 1.3763, Val Loss: 6.0914, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 47, Train Loss: 1.3621, Val Loss: 5.5942, F1 Micro: 0.2333, F1 Macro: 0.1373, Accuracy: 0.2333\n","Epoch 48, Train Loss: 1.3603, Val Loss: 5.6248, F1 Micro: 0.0833, F1 Macro: 0.0667, Accuracy: 0.0833\n","Epoch 49, Train Loss: 1.3372, Val Loss: 5.6384, F1 Micro: 0.1500, F1 Macro: 0.1034, Accuracy: 0.1500\n","Epoch 50, Train Loss: 1.3614, Val Loss: 5.5834, F1 Micro: 0.2500, F1 Macro: 0.1282, Accuracy: 0.2500\n","Epoch 51, Train Loss: 1.3272, Val Loss: 5.7377, F1 Micro: 0.2000, F1 Macro: 0.1500, Accuracy: 0.2000\n","Epoch 52, Train Loss: 1.3609, Val Loss: 6.1838, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 53, Train Loss: 1.3168, Val Loss: 5.8876, F1 Micro: 0.1500, F1 Macro: 0.1034, Accuracy: 0.1500\n","Epoch 54, Train Loss: 1.3355, Val Loss: 5.8205, F1 Micro: 0.1167, F1 Macro: 0.0864, Accuracy: 0.1167\n","Epoch 55, Train Loss: 1.3104, Val Loss: 6.0311, F1 Micro: 0.1167, F1 Macro: 0.0864, Accuracy: 0.1167\n","Epoch 56, Train Loss: 1.3604, Val Loss: 5.8520, F1 Micro: 0.1000, F1 Macro: 0.0769, Accuracy: 0.1000\n","Epoch 57, Train Loss: 1.3380, Val Loss: 5.9796, F1 Micro: 0.1333, F1 Macro: 0.0952, Accuracy: 0.1333\n","Epoch 58, Train Loss: 1.3526, Val Loss: 6.1283, F1 Micro: 0.1833, F1 Macro: 0.1183, Accuracy: 0.1833\n","Epoch 59, Train Loss: 1.3747, Val Loss: 6.2019, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 60, Train Loss: 1.3536, Val Loss: 5.9715, F1 Micro: 0.0833, F1 Macro: 0.0667, Accuracy: 0.0833\n","Epoch 61, Train Loss: 1.3220, Val Loss: 6.1991, F1 Micro: 0.1000, F1 Macro: 0.0769, Accuracy: 0.1000\n","Epoch 62, Train Loss: 1.3283, Val Loss: 6.3281, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 63, Train Loss: 1.2743, Val Loss: 6.8874, F1 Micro: 0.0333, F1 Macro: 0.0303, Accuracy: 0.0333\n","Epoch 64, Train Loss: 1.2827, Val Loss: 6.4989, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 65, Train Loss: 1.2874, Val Loss: 6.5116, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 66, Train Loss: 1.2617, Val Loss: 6.2331, F1 Micro: 0.1500, F1 Macro: 0.1034, Accuracy: 0.1500\n","Epoch 67, Train Loss: 1.2739, Val Loss: 6.7472, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 68, Train Loss: 1.2435, Val Loss: 6.7794, F1 Micro: 0.0833, F1 Macro: 0.0667, Accuracy: 0.0833\n","Epoch 69, Train Loss: 1.2607, Val Loss: 6.9906, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 70, Train Loss: 1.2587, Val Loss: 6.4150, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 71, Train Loss: 1.2257, Val Loss: 6.6431, F1 Micro: 0.0500, F1 Macro: 0.0435, Accuracy: 0.0500\n","Epoch 72, Train Loss: 1.2567, Val Loss: 6.5833, F1 Micro: 0.1167, F1 Macro: 0.0864, Accuracy: 0.1167\n","Epoch 73, Train Loss: 1.2829, Val Loss: 6.5309, F1 Micro: 0.1833, F1 Macro: 0.1183, Accuracy: 0.1833\n","Epoch 74, Train Loss: 1.2249, Val Loss: 6.4636, F1 Micro: 0.1667, F1 Macro: 0.1075, Accuracy: 0.1667\n","Epoch 75, Train Loss: 1.2470, Val Loss: 6.5147, F1 Micro: 0.1000, F1 Macro: 0.0769, Accuracy: 0.1000\n","Epoch 76, Train Loss: 1.2504, Val Loss: 6.4102, F1 Micro: 0.2167, F1 Macro: 0.1238, Accuracy: 0.2167\n","Epoch 77, Train Loss: 1.2227, Val Loss: 6.4155, F1 Micro: 0.2500, F1 Macro: 0.1282, Accuracy: 0.2500\n","Epoch 78, Train Loss: 1.2770, Val Loss: 6.7338, F1 Micro: 0.1167, F1 Macro: 0.0833, Accuracy: 0.1167\n","Epoch 79, Train Loss: 1.3238, Val Loss: 7.1047, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 80, Train Loss: 1.2203, Val Loss: 6.7579, F1 Micro: 0.1667, F1 Macro: 0.1075, Accuracy: 0.1667\n","Epoch 81, Train Loss: 1.2162, Val Loss: 6.5130, F1 Micro: 0.2333, F1 Macro: 0.1333, Accuracy: 0.2333\n","Epoch 82, Train Loss: 1.2316, Val Loss: 6.7186, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 83, Train Loss: 1.1931, Val Loss: 6.5852, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 84, Train Loss: 1.2067, Val Loss: 6.8172, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 85, Train Loss: 1.2391, Val Loss: 6.9954, F1 Micro: 0.1000, F1 Macro: 0.0769, Accuracy: 0.1000\n","Epoch 86, Train Loss: 1.1903, Val Loss: 7.1843, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 87, Train Loss: 1.1881, Val Loss: 7.3610, F1 Micro: 0.0833, F1 Macro: 0.0667, Accuracy: 0.0833\n","Epoch 88, Train Loss: 1.1866, Val Loss: 7.2030, F1 Micro: 0.0667, F1 Macro: 0.0556, Accuracy: 0.0667\n","Epoch 89, Train Loss: 1.2121, Val Loss: 7.5017, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 90, Train Loss: 1.1845, Val Loss: 7.0427, F1 Micro: 0.1667, F1 Macro: 0.1111, Accuracy: 0.1667\n","Epoch 91, Train Loss: 1.1846, Val Loss: 7.1678, F1 Micro: 0.1500, F1 Macro: 0.1000, Accuracy: 0.1500\n","Epoch 92, Train Loss: 1.1548, Val Loss: 7.3950, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 93, Train Loss: 1.1863, Val Loss: 7.3496, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 94, Train Loss: 1.1501, Val Loss: 7.4418, F1 Micro: 0.0167, F1 Macro: 0.0159, Accuracy: 0.0167\n","Epoch 95, Train Loss: 1.1627, Val Loss: 7.4420, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 96, Train Loss: 1.1668, Val Loss: 6.7918, F1 Micro: 0.1833, F1 Macro: 0.1146, Accuracy: 0.1833\n","Epoch 97, Train Loss: 1.1389, Val Loss: 6.9866, F1 Micro: 0.1167, F1 Macro: 0.0864, Accuracy: 0.1167\n","Epoch 98, Train Loss: 1.1521, Val Loss: 7.2207, F1 Micro: 0.1000, F1 Macro: 0.0741, Accuracy: 0.1000\n","Epoch 99, Train Loss: 1.1430, Val Loss: 6.9833, F1 Micro: 0.1833, F1 Macro: 0.1146, Accuracy: 0.1833\n","Epoch 100, Train Loss: 1.1215, Val Loss: 7.2308, F1 Micro: 0.1000, F1 Macro: 0.0769, Accuracy: 0.1000\n","Epoch 101, Train Loss: 1.1777, Val Loss: 7.4020, F1 Micro: 0.1167, F1 Macro: 0.0864, Accuracy: 0.1167\n","Epoch 102, Train Loss: 1.1687, Val Loss: 6.9780, F1 Micro: 0.1500, F1 Macro: 0.1000, Accuracy: 0.1500\n","Early stopping triggered\n"]}]},{"cell_type":"markdown","source":["# Try the k-folder"],"metadata":{"id":"dZK7BnLw4dtK"}},{"cell_type":"code","source":["def plot_metrics(metrics_history):\n","    epochs = range(1, len(metrics_history['train_loss']) + 1)\n","\n","    plt.figure(figsize=(14, 10))\n","\n","    plt.subplot(2, 2, 1)\n","    plt.plot(epochs, metrics_history['train_loss'], label='Train Loss')\n","    plt.plot(epochs, metrics_history['val_loss'], label='Validation Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(2, 2, 2)\n","    plt.plot(epochs, metrics_history['f1_micro'], label='F1 Score (Micro)')\n","    plt.plot(epochs, metrics_history['f1_macro'], label='F1 Score (Macro)')\n","    plt.title('F1 Scores')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('F1 Score')\n","    plt.legend()\n","\n","    plt.subplot(2, 2, 3)\n","    plt.plot(epochs, metrics_history['accuracy'], label='Accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"rIS6MVub9N8v","executionInfo":{"status":"ok","timestamp":1711369454777,"user_tz":-60,"elapsed":3,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_en)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_en[train_val_idx]\n","    test_dataset = dataset_en[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = BasicGraphModel(\n","                input_size=dataset_en.num_node_features,\n","                hidden_size=256,\n","                output_size=dataset_en.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = BasicGraphModel(\n","        input_size=dataset_en.num_node_features,\n","        hidden_size=256,\n","        output_size=dataset_en.num_classes,\n","        dropout_rate=0.5  # You could also tune the dropout rate if you wanted\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'Basic_model_fold_{fold}.pth')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynhJ39ya4c3n","executionInfo":{"status":"ok","timestamp":1711213014241,"user_tz":-60,"elapsed":5063120,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"74dec665-a848-469b-bbcf-2f5562b2c16f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 183, Train Loss: 0.7700, Val Loss: 1.6199, F1 Micro: 0.5000, F1 Macro: 0.4958, Accuracy: 0.5000\n","Epoch 184, Train Loss: 0.7443, Val Loss: 1.3067, F1 Micro: 0.5938, F1 Macro: 0.5931, Accuracy: 0.5938\n","Epoch 185, Train Loss: 0.6439, Val Loss: 1.3061, F1 Micro: 0.6250, F1 Macro: 0.6276, Accuracy: 0.6250\n","Epoch 186, Train Loss: 0.6463, Val Loss: 1.3514, F1 Micro: 0.6042, F1 Macro: 0.6010, Accuracy: 0.6042\n","Epoch 187, Train Loss: 0.6730, Val Loss: 1.4169, F1 Micro: 0.6354, F1 Macro: 0.6385, Accuracy: 0.6354\n","Epoch 188, Train Loss: 0.6975, Val Loss: 1.3984, F1 Micro: 0.6250, F1 Macro: 0.6355, Accuracy: 0.6250\n","Epoch 189, Train Loss: 0.6944, Val Loss: 1.4154, F1 Micro: 0.6250, F1 Macro: 0.6263, Accuracy: 0.6250\n","Epoch 190, Train Loss: 0.6498, Val Loss: 1.3965, F1 Micro: 0.6042, F1 Macro: 0.6001, Accuracy: 0.6042\n","Epoch 191, Train Loss: 0.6610, Val Loss: 1.3900, F1 Micro: 0.5833, F1 Macro: 0.5760, Accuracy: 0.5833\n","Epoch 192, Train Loss: 0.6710, Val Loss: 1.7289, F1 Micro: 0.5625, F1 Macro: 0.5616, Accuracy: 0.5625\n","Epoch 193, Train Loss: 0.7285, Val Loss: 1.4562, F1 Micro: 0.5833, F1 Macro: 0.5575, Accuracy: 0.5833\n","Epoch 194, Train Loss: 0.6687, Val Loss: 1.3901, F1 Micro: 0.5625, F1 Macro: 0.5410, Accuracy: 0.5625\n","Epoch 195, Train Loss: 0.6693, Val Loss: 1.4670, F1 Micro: 0.6042, F1 Macro: 0.6061, Accuracy: 0.6042\n","Epoch 196, Train Loss: 0.8147, Val Loss: 1.4224, F1 Micro: 0.5104, F1 Macro: 0.5185, Accuracy: 0.5104\n","Epoch 197, Train Loss: 0.6542, Val Loss: 1.5070, F1 Micro: 0.5833, F1 Macro: 0.5657, Accuracy: 0.5833\n","Epoch 198, Train Loss: 0.6135, Val Loss: 1.5959, F1 Micro: 0.5000, F1 Macro: 0.5046, Accuracy: 0.5000\n","Epoch 199, Train Loss: 0.6659, Val Loss: 1.5318, F1 Micro: 0.5521, F1 Macro: 0.5455, Accuracy: 0.5521\n","Epoch 200, Train Loss: 0.5838, Val Loss: 1.4849, F1 Micro: 0.5833, F1 Macro: 0.5883, Accuracy: 0.5833\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.3145, Val Loss: 2.1840, F1 Micro: 0.1458, F1 Macro: 0.1116, Accuracy: 0.1458\n","Epoch 2, Train Loss: 2.2668, Val Loss: 2.1383, F1 Micro: 0.1875, F1 Macro: 0.1353, Accuracy: 0.1875\n","Epoch 3, Train Loss: 2.1701, Val Loss: 1.8278, F1 Micro: 0.1667, F1 Macro: 0.1413, Accuracy: 0.1667\n","Epoch 4, Train Loss: 2.0309, Val Loss: 1.7773, F1 Micro: 0.2083, F1 Macro: 0.1696, Accuracy: 0.2083\n","Epoch 5, Train Loss: 1.9630, Val Loss: 1.7641, F1 Micro: 0.1979, F1 Macro: 0.1365, Accuracy: 0.1979\n","Epoch 6, Train Loss: 1.8216, Val Loss: 1.7906, F1 Micro: 0.2083, F1 Macro: 0.1721, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.7683, Val Loss: 1.9435, F1 Micro: 0.1354, F1 Macro: 0.0906, Accuracy: 0.1354\n","Epoch 8, Train Loss: 1.7459, Val Loss: 1.7366, F1 Micro: 0.3125, F1 Macro: 0.2473, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.7345, Val Loss: 2.0541, F1 Micro: 0.1979, F1 Macro: 0.1509, Accuracy: 0.1979\n","Epoch 10, Train Loss: 1.8195, Val Loss: 1.8096, F1 Micro: 0.2083, F1 Macro: 0.1036, Accuracy: 0.2083\n","Epoch 11, Train Loss: 1.7135, Val Loss: 1.8018, F1 Micro: 0.1979, F1 Macro: 0.1686, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.6985, Val Loss: 1.8136, F1 Micro: 0.2917, F1 Macro: 0.1941, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.7035, Val Loss: 1.7488, F1 Micro: 0.2604, F1 Macro: 0.2216, Accuracy: 0.2604\n","Epoch 14, Train Loss: 1.6870, Val Loss: 1.7234, F1 Micro: 0.2604, F1 Macro: 0.2311, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.7157, Val Loss: 1.7596, F1 Micro: 0.2292, F1 Macro: 0.1728, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.7071, Val Loss: 1.7917, F1 Micro: 0.1562, F1 Macro: 0.1323, Accuracy: 0.1562\n","Epoch 17, Train Loss: 1.6627, Val Loss: 1.8513, F1 Micro: 0.2500, F1 Macro: 0.1752, Accuracy: 0.2500\n","Epoch 18, Train Loss: 1.6835, Val Loss: 1.7811, F1 Micro: 0.2292, F1 Macro: 0.1678, Accuracy: 0.2292\n","Epoch 19, Train Loss: 1.7063, Val Loss: 1.7114, F1 Micro: 0.2396, F1 Macro: 0.2503, Accuracy: 0.2396\n","Epoch 20, Train Loss: 1.6897, Val Loss: 1.8797, F1 Micro: 0.2500, F1 Macro: 0.1885, Accuracy: 0.2500\n","Epoch 21, Train Loss: 1.6528, Val Loss: 1.7857, F1 Micro: 0.2812, F1 Macro: 0.2646, Accuracy: 0.2812\n","Epoch 22, Train Loss: 1.7025, Val Loss: 2.0368, F1 Micro: 0.1458, F1 Macro: 0.1131, Accuracy: 0.1458\n","Epoch 23, Train Loss: 1.6276, Val Loss: 1.7151, F1 Micro: 0.3021, F1 Macro: 0.2422, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.6593, Val Loss: 1.8118, F1 Micro: 0.2812, F1 Macro: 0.2353, Accuracy: 0.2812\n","Epoch 25, Train Loss: 1.6758, Val Loss: 1.7746, F1 Micro: 0.3229, F1 Macro: 0.2862, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.6162, Val Loss: 1.8955, F1 Micro: 0.2188, F1 Macro: 0.2161, Accuracy: 0.2188\n","Epoch 27, Train Loss: 1.6257, Val Loss: 1.7774, F1 Micro: 0.2708, F1 Macro: 0.2354, Accuracy: 0.2708\n","Epoch 28, Train Loss: 1.6158, Val Loss: 1.8234, F1 Micro: 0.2396, F1 Macro: 0.1897, Accuracy: 0.2396\n","Epoch 29, Train Loss: 1.5818, Val Loss: 1.7907, F1 Micro: 0.3333, F1 Macro: 0.2668, Accuracy: 0.3333\n","Epoch 30, Train Loss: 1.6202, Val Loss: 1.7523, F1 Micro: 0.3333, F1 Macro: 0.3033, Accuracy: 0.3333\n","Epoch 31, Train Loss: 1.6252, Val Loss: 1.8687, F1 Micro: 0.2917, F1 Macro: 0.2383, Accuracy: 0.2917\n","Epoch 32, Train Loss: 1.5760, Val Loss: 1.7388, F1 Micro: 0.3125, F1 Macro: 0.3146, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.5896, Val Loss: 1.9024, F1 Micro: 0.1667, F1 Macro: 0.1498, Accuracy: 0.1667\n","Epoch 34, Train Loss: 1.5493, Val Loss: 1.7461, F1 Micro: 0.3125, F1 Macro: 0.2720, Accuracy: 0.3125\n","Epoch 35, Train Loss: 1.5311, Val Loss: 1.7970, F1 Micro: 0.2292, F1 Macro: 0.2197, Accuracy: 0.2292\n","Epoch 36, Train Loss: 1.5126, Val Loss: 1.7925, F1 Micro: 0.2917, F1 Macro: 0.2600, Accuracy: 0.2917\n","Epoch 37, Train Loss: 1.5407, Val Loss: 1.7958, F1 Micro: 0.3438, F1 Macro: 0.3148, Accuracy: 0.3438\n","Epoch 38, Train Loss: 1.5068, Val Loss: 1.8792, F1 Micro: 0.3229, F1 Macro: 0.2834, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.4876, Val Loss: 1.8653, F1 Micro: 0.3438, F1 Macro: 0.2607, Accuracy: 0.3438\n","Epoch 40, Train Loss: 1.4904, Val Loss: 1.8635, F1 Micro: 0.3542, F1 Macro: 0.3275, Accuracy: 0.3542\n","Epoch 41, Train Loss: 1.4538, Val Loss: 1.7637, F1 Micro: 0.3125, F1 Macro: 0.2411, Accuracy: 0.3125\n","Epoch 42, Train Loss: 1.4467, Val Loss: 1.8265, F1 Micro: 0.3438, F1 Macro: 0.3280, Accuracy: 0.3438\n","Epoch 43, Train Loss: 1.4418, Val Loss: 1.9570, F1 Micro: 0.2812, F1 Macro: 0.2618, Accuracy: 0.2812\n","Epoch 44, Train Loss: 1.5018, Val Loss: 1.7971, F1 Micro: 0.3125, F1 Macro: 0.2919, Accuracy: 0.3125\n","Epoch 45, Train Loss: 1.4564, Val Loss: 1.9912, F1 Micro: 0.3125, F1 Macro: 0.2600, Accuracy: 0.3125\n","Epoch 46, Train Loss: 1.4288, Val Loss: 1.9222, F1 Micro: 0.3021, F1 Macro: 0.2955, Accuracy: 0.3021\n","Epoch 47, Train Loss: 1.4883, Val Loss: 1.9747, F1 Micro: 0.3229, F1 Macro: 0.2475, Accuracy: 0.3229\n","Epoch 48, Train Loss: 1.4741, Val Loss: 1.8124, F1 Micro: 0.3125, F1 Macro: 0.3008, Accuracy: 0.3125\n","Epoch 49, Train Loss: 1.4562, Val Loss: 1.8804, F1 Micro: 0.3333, F1 Macro: 0.2790, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.4240, Val Loss: 1.8533, F1 Micro: 0.3438, F1 Macro: 0.3224, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.4113, Val Loss: 1.8103, F1 Micro: 0.3229, F1 Macro: 0.2922, Accuracy: 0.3229\n","Epoch 52, Train Loss: 1.4072, Val Loss: 1.9539, F1 Micro: 0.3021, F1 Macro: 0.2815, Accuracy: 0.3021\n","Epoch 53, Train Loss: 1.4561, Val Loss: 1.8866, F1 Micro: 0.3021, F1 Macro: 0.2838, Accuracy: 0.3021\n","Epoch 54, Train Loss: 1.4690, Val Loss: 2.0472, F1 Micro: 0.2604, F1 Macro: 0.2127, Accuracy: 0.2604\n","Epoch 55, Train Loss: 1.4283, Val Loss: 1.7214, F1 Micro: 0.3750, F1 Macro: 0.3595, Accuracy: 0.3750\n","Epoch 56, Train Loss: 1.3917, Val Loss: 1.8391, F1 Micro: 0.3125, F1 Macro: 0.3030, Accuracy: 0.3125\n","Epoch 57, Train Loss: 1.3564, Val Loss: 1.9658, F1 Micro: 0.3229, F1 Macro: 0.2942, Accuracy: 0.3229\n","Epoch 58, Train Loss: 1.3945, Val Loss: 1.8500, F1 Micro: 0.3229, F1 Macro: 0.2955, Accuracy: 0.3229\n","Epoch 59, Train Loss: 1.3783, Val Loss: 1.9337, F1 Micro: 0.3542, F1 Macro: 0.2969, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.4279, Val Loss: 1.8240, F1 Micro: 0.3333, F1 Macro: 0.3235, Accuracy: 0.3333\n","Epoch 61, Train Loss: 1.3366, Val Loss: 1.8964, F1 Micro: 0.3125, F1 Macro: 0.2568, Accuracy: 0.3125\n","Epoch 62, Train Loss: 1.3592, Val Loss: 1.9014, F1 Micro: 0.3333, F1 Macro: 0.3056, Accuracy: 0.3333\n","Epoch 63, Train Loss: 1.3567, Val Loss: 1.8110, F1 Micro: 0.3438, F1 Macro: 0.3280, Accuracy: 0.3438\n","Epoch 64, Train Loss: 1.3333, Val Loss: 1.9902, F1 Micro: 0.3333, F1 Macro: 0.3024, Accuracy: 0.3333\n","Epoch 65, Train Loss: 1.3039, Val Loss: 1.8581, F1 Micro: 0.2812, F1 Macro: 0.2704, Accuracy: 0.2812\n","Epoch 66, Train Loss: 1.3149, Val Loss: 1.9292, F1 Micro: 0.3542, F1 Macro: 0.3527, Accuracy: 0.3542\n","Epoch 67, Train Loss: 1.3315, Val Loss: 1.9296, F1 Micro: 0.3229, F1 Macro: 0.3064, Accuracy: 0.3229\n","Epoch 68, Train Loss: 1.3121, Val Loss: 1.9564, F1 Micro: 0.2604, F1 Macro: 0.2471, Accuracy: 0.2604\n","Epoch 69, Train Loss: 1.2807, Val Loss: 1.9352, F1 Micro: 0.3750, F1 Macro: 0.3493, Accuracy: 0.3750\n","Epoch 70, Train Loss: 1.3269, Val Loss: 1.9088, F1 Micro: 0.3438, F1 Macro: 0.3196, Accuracy: 0.3438\n","Epoch 71, Train Loss: 1.3241, Val Loss: 1.9678, F1 Micro: 0.3229, F1 Macro: 0.2766, Accuracy: 0.3229\n","Epoch 72, Train Loss: 1.2742, Val Loss: 1.8508, F1 Micro: 0.3542, F1 Macro: 0.3229, Accuracy: 0.3542\n","Epoch 73, Train Loss: 1.3385, Val Loss: 1.9388, F1 Micro: 0.2812, F1 Macro: 0.2353, Accuracy: 0.2812\n","Epoch 74, Train Loss: 1.3156, Val Loss: 1.8580, F1 Micro: 0.3438, F1 Macro: 0.3036, Accuracy: 0.3438\n","Epoch 75, Train Loss: 1.2631, Val Loss: 2.0564, F1 Micro: 0.3125, F1 Macro: 0.3054, Accuracy: 0.3125\n","Epoch 76, Train Loss: 1.2674, Val Loss: 1.8312, F1 Micro: 0.3438, F1 Macro: 0.3088, Accuracy: 0.3438\n","Epoch 77, Train Loss: 1.2136, Val Loss: 1.9692, F1 Micro: 0.3021, F1 Macro: 0.2913, Accuracy: 0.3021\n","Epoch 78, Train Loss: 1.2284, Val Loss: 2.0441, F1 Micro: 0.3333, F1 Macro: 0.3030, Accuracy: 0.3333\n","Epoch 79, Train Loss: 1.2527, Val Loss: 1.9301, F1 Micro: 0.3438, F1 Macro: 0.3148, Accuracy: 0.3438\n","Epoch 80, Train Loss: 1.2535, Val Loss: 1.9136, F1 Micro: 0.3438, F1 Macro: 0.3168, Accuracy: 0.3438\n","Epoch 81, Train Loss: 1.2254, Val Loss: 1.7989, F1 Micro: 0.3333, F1 Macro: 0.3031, Accuracy: 0.3333\n","Epoch 82, Train Loss: 1.2085, Val Loss: 1.9663, F1 Micro: 0.3750, F1 Macro: 0.3072, Accuracy: 0.3750\n","Epoch 83, Train Loss: 1.2546, Val Loss: 1.8966, F1 Micro: 0.3542, F1 Macro: 0.3290, Accuracy: 0.3542\n","Epoch 84, Train Loss: 1.2154, Val Loss: 1.9097, F1 Micro: 0.3333, F1 Macro: 0.3323, Accuracy: 0.3333\n","Epoch 85, Train Loss: 1.1652, Val Loss: 1.9473, F1 Micro: 0.3646, F1 Macro: 0.3298, Accuracy: 0.3646\n","Epoch 86, Train Loss: 1.2012, Val Loss: 1.9800, F1 Micro: 0.3958, F1 Macro: 0.3922, Accuracy: 0.3958\n","Epoch 87, Train Loss: 1.2424, Val Loss: 1.8118, F1 Micro: 0.3958, F1 Macro: 0.3541, Accuracy: 0.3958\n","Epoch 88, Train Loss: 1.1596, Val Loss: 1.9412, F1 Micro: 0.3333, F1 Macro: 0.2957, Accuracy: 0.3333\n","Epoch 89, Train Loss: 1.1305, Val Loss: 1.8994, F1 Micro: 0.3854, F1 Macro: 0.3532, Accuracy: 0.3854\n","Epoch 90, Train Loss: 1.1682, Val Loss: 2.2374, F1 Micro: 0.3646, F1 Macro: 0.3535, Accuracy: 0.3646\n","Epoch 91, Train Loss: 1.2076, Val Loss: 1.9188, F1 Micro: 0.3333, F1 Macro: 0.3148, Accuracy: 0.3333\n","Epoch 92, Train Loss: 1.1364, Val Loss: 1.8814, F1 Micro: 0.3750, F1 Macro: 0.3435, Accuracy: 0.3750\n","Epoch 93, Train Loss: 1.1867, Val Loss: 2.0391, F1 Micro: 0.3438, F1 Macro: 0.3204, Accuracy: 0.3438\n","Epoch 94, Train Loss: 1.2014, Val Loss: 1.9404, F1 Micro: 0.3646, F1 Macro: 0.3433, Accuracy: 0.3646\n","Epoch 95, Train Loss: 1.1724, Val Loss: 1.7973, F1 Micro: 0.3750, F1 Macro: 0.3453, Accuracy: 0.3750\n","Epoch 96, Train Loss: 1.1623, Val Loss: 2.0165, F1 Micro: 0.3125, F1 Macro: 0.2713, Accuracy: 0.3125\n","Epoch 97, Train Loss: 1.1419, Val Loss: 1.9094, F1 Micro: 0.3438, F1 Macro: 0.3365, Accuracy: 0.3438\n","Epoch 98, Train Loss: 1.1478, Val Loss: 1.7937, F1 Micro: 0.4271, F1 Macro: 0.3913, Accuracy: 0.4271\n","Epoch 99, Train Loss: 1.1167, Val Loss: 1.8820, F1 Micro: 0.3750, F1 Macro: 0.3467, Accuracy: 0.3750\n","Epoch 100, Train Loss: 1.0918, Val Loss: 1.8998, F1 Micro: 0.4271, F1 Macro: 0.4213, Accuracy: 0.4271\n","Epoch 101, Train Loss: 1.1108, Val Loss: 1.8514, F1 Micro: 0.3958, F1 Macro: 0.3739, Accuracy: 0.3958\n","Epoch 102, Train Loss: 1.1253, Val Loss: 1.9133, F1 Micro: 0.3646, F1 Macro: 0.3648, Accuracy: 0.3646\n","Epoch 103, Train Loss: 1.0979, Val Loss: 2.1553, F1 Micro: 0.3854, F1 Macro: 0.3616, Accuracy: 0.3854\n","Epoch 104, Train Loss: 1.1330, Val Loss: 1.8674, F1 Micro: 0.3854, F1 Macro: 0.3690, Accuracy: 0.3854\n","Epoch 105, Train Loss: 1.0828, Val Loss: 1.9242, F1 Micro: 0.4062, F1 Macro: 0.3920, Accuracy: 0.4062\n","Epoch 106, Train Loss: 1.0951, Val Loss: 2.3020, F1 Micro: 0.3438, F1 Macro: 0.3123, Accuracy: 0.3438\n","Epoch 107, Train Loss: 1.1521, Val Loss: 1.7845, F1 Micro: 0.4479, F1 Macro: 0.3834, Accuracy: 0.4479\n","Epoch 108, Train Loss: 1.1441, Val Loss: 1.9802, F1 Micro: 0.4271, F1 Macro: 0.4141, Accuracy: 0.4271\n","Epoch 109, Train Loss: 1.1028, Val Loss: 1.8662, F1 Micro: 0.3542, F1 Macro: 0.3176, Accuracy: 0.3542\n","Epoch 110, Train Loss: 1.0758, Val Loss: 2.1389, F1 Micro: 0.3646, F1 Macro: 0.3259, Accuracy: 0.3646\n","Epoch 111, Train Loss: 1.0798, Val Loss: 1.9725, F1 Micro: 0.3646, F1 Macro: 0.3370, Accuracy: 0.3646\n","Epoch 112, Train Loss: 1.0884, Val Loss: 1.8604, F1 Micro: 0.3854, F1 Macro: 0.3651, Accuracy: 0.3854\n","Epoch 113, Train Loss: 1.0495, Val Loss: 2.2009, F1 Micro: 0.3229, F1 Macro: 0.2847, Accuracy: 0.3229\n","Epoch 114, Train Loss: 1.0650, Val Loss: 2.0028, F1 Micro: 0.3854, F1 Macro: 0.3822, Accuracy: 0.3854\n","Epoch 115, Train Loss: 1.0506, Val Loss: 1.8463, F1 Micro: 0.4062, F1 Macro: 0.3969, Accuracy: 0.4062\n","Epoch 116, Train Loss: 1.0717, Val Loss: 2.0081, F1 Micro: 0.3542, F1 Macro: 0.3171, Accuracy: 0.3542\n","Epoch 117, Train Loss: 1.0540, Val Loss: 1.8575, F1 Micro: 0.4167, F1 Macro: 0.3841, Accuracy: 0.4167\n","Epoch 118, Train Loss: 1.1074, Val Loss: 2.0900, F1 Micro: 0.3229, F1 Macro: 0.3122, Accuracy: 0.3229\n","Epoch 119, Train Loss: 1.0652, Val Loss: 1.9226, F1 Micro: 0.3750, F1 Macro: 0.3517, Accuracy: 0.3750\n","Epoch 120, Train Loss: 1.0589, Val Loss: 1.8734, F1 Micro: 0.4271, F1 Macro: 0.4016, Accuracy: 0.4271\n","Epoch 121, Train Loss: 0.9875, Val Loss: 1.9812, F1 Micro: 0.4271, F1 Macro: 0.4042, Accuracy: 0.4271\n","Epoch 122, Train Loss: 1.0001, Val Loss: 1.9884, F1 Micro: 0.4167, F1 Macro: 0.4033, Accuracy: 0.4167\n","Epoch 123, Train Loss: 1.0346, Val Loss: 1.8273, F1 Micro: 0.4896, F1 Macro: 0.4660, Accuracy: 0.4896\n","Epoch 124, Train Loss: 0.9790, Val Loss: 1.8395, F1 Micro: 0.4479, F1 Macro: 0.4169, Accuracy: 0.4479\n","Epoch 125, Train Loss: 0.9390, Val Loss: 1.9882, F1 Micro: 0.4062, F1 Macro: 0.3790, Accuracy: 0.4062\n","Epoch 126, Train Loss: 0.9745, Val Loss: 1.8973, F1 Micro: 0.4583, F1 Macro: 0.4206, Accuracy: 0.4583\n","Epoch 127, Train Loss: 0.9932, Val Loss: 1.9824, F1 Micro: 0.4167, F1 Macro: 0.3879, Accuracy: 0.4167\n","Epoch 128, Train Loss: 1.0166, Val Loss: 1.7898, F1 Micro: 0.4375, F1 Macro: 0.3983, Accuracy: 0.4375\n","Epoch 129, Train Loss: 1.0015, Val Loss: 1.8787, F1 Micro: 0.4688, F1 Macro: 0.4413, Accuracy: 0.4688\n","Epoch 130, Train Loss: 1.0024, Val Loss: 1.9161, F1 Micro: 0.4271, F1 Macro: 0.4039, Accuracy: 0.4271\n","Epoch 131, Train Loss: 0.9444, Val Loss: 1.8585, F1 Micro: 0.4896, F1 Macro: 0.4587, Accuracy: 0.4896\n","Epoch 132, Train Loss: 0.9484, Val Loss: 1.9373, F1 Micro: 0.4271, F1 Macro: 0.4180, Accuracy: 0.4271\n","Epoch 133, Train Loss: 0.9933, Val Loss: 1.9019, F1 Micro: 0.4062, F1 Macro: 0.3647, Accuracy: 0.4062\n","Epoch 134, Train Loss: 0.9603, Val Loss: 1.8160, F1 Micro: 0.4688, F1 Macro: 0.4460, Accuracy: 0.4688\n","Epoch 135, Train Loss: 0.9659, Val Loss: 1.9130, F1 Micro: 0.4271, F1 Macro: 0.4021, Accuracy: 0.4271\n","Epoch 136, Train Loss: 0.9198, Val Loss: 1.8732, F1 Micro: 0.4062, F1 Macro: 0.3598, Accuracy: 0.4062\n","Epoch 137, Train Loss: 0.9772, Val Loss: 1.9629, F1 Micro: 0.3958, F1 Macro: 0.3748, Accuracy: 0.3958\n","Epoch 138, Train Loss: 0.9590, Val Loss: 1.9511, F1 Micro: 0.4271, F1 Macro: 0.4096, Accuracy: 0.4271\n","Epoch 139, Train Loss: 0.9860, Val Loss: 1.9257, F1 Micro: 0.4583, F1 Macro: 0.4236, Accuracy: 0.4583\n","Epoch 140, Train Loss: 0.8986, Val Loss: 1.8664, F1 Micro: 0.4479, F1 Macro: 0.4371, Accuracy: 0.4479\n","Epoch 141, Train Loss: 0.9045, Val Loss: 2.0370, F1 Micro: 0.4375, F1 Macro: 0.4124, Accuracy: 0.4375\n","Epoch 142, Train Loss: 0.9144, Val Loss: 1.9888, F1 Micro: 0.3646, F1 Macro: 0.3535, Accuracy: 0.3646\n","Epoch 143, Train Loss: 0.8880, Val Loss: 1.9393, F1 Micro: 0.4167, F1 Macro: 0.3858, Accuracy: 0.4167\n","Epoch 144, Train Loss: 0.9309, Val Loss: 2.0345, F1 Micro: 0.4375, F1 Macro: 0.4278, Accuracy: 0.4375\n","Epoch 145, Train Loss: 0.8843, Val Loss: 1.9001, F1 Micro: 0.4688, F1 Macro: 0.4506, Accuracy: 0.4688\n","Epoch 146, Train Loss: 0.8868, Val Loss: 1.8918, F1 Micro: 0.4479, F1 Macro: 0.4189, Accuracy: 0.4479\n","Epoch 147, Train Loss: 0.9024, Val Loss: 1.9641, F1 Micro: 0.5000, F1 Macro: 0.4963, Accuracy: 0.5000\n","Epoch 148, Train Loss: 0.8922, Val Loss: 2.2050, F1 Micro: 0.4479, F1 Macro: 0.3943, Accuracy: 0.4479\n","Epoch 149, Train Loss: 0.9215, Val Loss: 1.9776, F1 Micro: 0.3958, F1 Macro: 0.3926, Accuracy: 0.3958\n","Epoch 150, Train Loss: 0.9645, Val Loss: 1.9153, F1 Micro: 0.4688, F1 Macro: 0.4466, Accuracy: 0.4688\n","Epoch 151, Train Loss: 0.8658, Val Loss: 1.9842, F1 Micro: 0.3958, F1 Macro: 0.3822, Accuracy: 0.3958\n","Epoch 152, Train Loss: 0.8761, Val Loss: 1.9118, F1 Micro: 0.4792, F1 Macro: 0.4448, Accuracy: 0.4792\n","Epoch 153, Train Loss: 0.9378, Val Loss: 1.8467, F1 Micro: 0.4688, F1 Macro: 0.4301, Accuracy: 0.4688\n","Epoch 154, Train Loss: 0.8664, Val Loss: 1.8846, F1 Micro: 0.4479, F1 Macro: 0.4289, Accuracy: 0.4479\n","Epoch 155, Train Loss: 0.8488, Val Loss: 1.8714, F1 Micro: 0.4792, F1 Macro: 0.4532, Accuracy: 0.4792\n","Epoch 156, Train Loss: 0.8687, Val Loss: 2.0776, F1 Micro: 0.4271, F1 Macro: 0.3740, Accuracy: 0.4271\n","Epoch 157, Train Loss: 0.8290, Val Loss: 1.8747, F1 Micro: 0.4792, F1 Macro: 0.4597, Accuracy: 0.4792\n","Epoch 158, Train Loss: 0.8413, Val Loss: 1.8556, F1 Micro: 0.4167, F1 Macro: 0.4063, Accuracy: 0.4167\n","Epoch 159, Train Loss: 0.8355, Val Loss: 1.9528, F1 Micro: 0.4062, F1 Macro: 0.4017, Accuracy: 0.4062\n","Epoch 160, Train Loss: 0.8315, Val Loss: 1.8046, F1 Micro: 0.4896, F1 Macro: 0.4726, Accuracy: 0.4896\n","Epoch 161, Train Loss: 0.7901, Val Loss: 1.9124, F1 Micro: 0.4479, F1 Macro: 0.4274, Accuracy: 0.4479\n","Epoch 162, Train Loss: 0.8073, Val Loss: 1.8623, F1 Micro: 0.5000, F1 Macro: 0.4833, Accuracy: 0.5000\n","Epoch 163, Train Loss: 0.8362, Val Loss: 1.9053, F1 Micro: 0.4479, F1 Macro: 0.4239, Accuracy: 0.4479\n","Epoch 164, Train Loss: 0.7972, Val Loss: 1.7692, F1 Micro: 0.5000, F1 Macro: 0.4986, Accuracy: 0.5000\n","Epoch 165, Train Loss: 0.8747, Val Loss: 1.8863, F1 Micro: 0.5312, F1 Macro: 0.4969, Accuracy: 0.5312\n","Epoch 166, Train Loss: 0.7863, Val Loss: 1.9562, F1 Micro: 0.4583, F1 Macro: 0.4315, Accuracy: 0.4583\n","Epoch 167, Train Loss: 0.8207, Val Loss: 2.0662, F1 Micro: 0.4688, F1 Macro: 0.4431, Accuracy: 0.4688\n","Epoch 168, Train Loss: 0.8640, Val Loss: 2.0336, F1 Micro: 0.4479, F1 Macro: 0.4586, Accuracy: 0.4479\n","Epoch 169, Train Loss: 0.7714, Val Loss: 1.8116, F1 Micro: 0.5000, F1 Macro: 0.4630, Accuracy: 0.5000\n","Epoch 170, Train Loss: 0.7842, Val Loss: 1.8277, F1 Micro: 0.5208, F1 Macro: 0.4935, Accuracy: 0.5208\n","Epoch 171, Train Loss: 0.7972, Val Loss: 1.8933, F1 Micro: 0.4896, F1 Macro: 0.4674, Accuracy: 0.4896\n","Epoch 172, Train Loss: 0.7734, Val Loss: 1.8433, F1 Micro: 0.4792, F1 Macro: 0.4520, Accuracy: 0.4792\n","Epoch 173, Train Loss: 0.8250, Val Loss: 1.9962, F1 Micro: 0.4896, F1 Macro: 0.4684, Accuracy: 0.4896\n","Epoch 174, Train Loss: 0.7643, Val Loss: 2.0415, F1 Micro: 0.4479, F1 Macro: 0.4111, Accuracy: 0.4479\n","Epoch 175, Train Loss: 0.7850, Val Loss: 2.1070, F1 Micro: 0.5104, F1 Macro: 0.4973, Accuracy: 0.5104\n","Epoch 176, Train Loss: 0.7423, Val Loss: 2.0642, F1 Micro: 0.4271, F1 Macro: 0.4157, Accuracy: 0.4271\n","Epoch 177, Train Loss: 0.7164, Val Loss: 1.8620, F1 Micro: 0.5000, F1 Macro: 0.4756, Accuracy: 0.5000\n","Epoch 178, Train Loss: 0.7772, Val Loss: 1.9101, F1 Micro: 0.4688, F1 Macro: 0.4442, Accuracy: 0.4688\n","Epoch 179, Train Loss: 0.7123, Val Loss: 1.9031, F1 Micro: 0.5104, F1 Macro: 0.4966, Accuracy: 0.5104\n","Epoch 180, Train Loss: 0.7490, Val Loss: 2.0933, F1 Micro: 0.4479, F1 Macro: 0.4467, Accuracy: 0.4479\n","Epoch 181, Train Loss: 0.6847, Val Loss: 1.8454, F1 Micro: 0.5208, F1 Macro: 0.5003, Accuracy: 0.5208\n","Epoch 182, Train Loss: 0.6495, Val Loss: 2.0353, F1 Micro: 0.5417, F1 Macro: 0.5102, Accuracy: 0.5417\n","Epoch 183, Train Loss: 0.7261, Val Loss: 1.8457, F1 Micro: 0.5312, F1 Macro: 0.5224, Accuracy: 0.5312\n","Epoch 184, Train Loss: 0.7231, Val Loss: 1.8823, F1 Micro: 0.5104, F1 Macro: 0.4942, Accuracy: 0.5104\n","Epoch 185, Train Loss: 0.7429, Val Loss: 1.9790, F1 Micro: 0.5208, F1 Macro: 0.4992, Accuracy: 0.5208\n","Epoch 186, Train Loss: 0.7064, Val Loss: 2.1739, F1 Micro: 0.4583, F1 Macro: 0.4244, Accuracy: 0.4583\n","Epoch 187, Train Loss: 0.7553, Val Loss: 2.0466, F1 Micro: 0.5417, F1 Macro: 0.5236, Accuracy: 0.5417\n","Epoch 188, Train Loss: 0.7092, Val Loss: 2.0322, F1 Micro: 0.5104, F1 Macro: 0.4800, Accuracy: 0.5104\n","Epoch 189, Train Loss: 0.7013, Val Loss: 2.0306, F1 Micro: 0.4688, F1 Macro: 0.4406, Accuracy: 0.4688\n","Epoch 190, Train Loss: 0.6524, Val Loss: 2.0911, F1 Micro: 0.5104, F1 Macro: 0.4888, Accuracy: 0.5104\n","Epoch 191, Train Loss: 0.6749, Val Loss: 1.8902, F1 Micro: 0.5833, F1 Macro: 0.5640, Accuracy: 0.5833\n","Epoch 192, Train Loss: 0.6756, Val Loss: 1.9858, F1 Micro: 0.5208, F1 Macro: 0.4800, Accuracy: 0.5208\n","Epoch 193, Train Loss: 0.6799, Val Loss: 2.0238, F1 Micro: 0.5312, F1 Macro: 0.5122, Accuracy: 0.5312\n","Epoch 194, Train Loss: 0.6397, Val Loss: 1.7002, F1 Micro: 0.5729, F1 Macro: 0.5495, Accuracy: 0.5729\n","Epoch 195, Train Loss: 0.6577, Val Loss: 1.9581, F1 Micro: 0.5312, F1 Macro: 0.5004, Accuracy: 0.5312\n","Epoch 196, Train Loss: 0.6371, Val Loss: 1.9663, F1 Micro: 0.5521, F1 Macro: 0.5386, Accuracy: 0.5521\n","Epoch 197, Train Loss: 0.6890, Val Loss: 1.8790, F1 Micro: 0.5729, F1 Macro: 0.5527, Accuracy: 0.5729\n","Epoch 198, Train Loss: 0.7446, Val Loss: 2.2341, F1 Micro: 0.5104, F1 Macro: 0.4756, Accuracy: 0.5104\n","Epoch 199, Train Loss: 0.6658, Val Loss: 1.8953, F1 Micro: 0.5625, F1 Macro: 0.5385, Accuracy: 0.5625\n","Epoch 200, Train Loss: 0.6131, Val Loss: 1.8734, F1 Micro: 0.5312, F1 Macro: 0.5070, Accuracy: 0.5312\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.2612, Val Loss: 1.9768, F1 Micro: 0.2083, F1 Macro: 0.1299, Accuracy: 0.2083\n","Epoch 2, Train Loss: 2.0932, Val Loss: 2.6688, F1 Micro: 0.1771, F1 Macro: 0.1022, Accuracy: 0.1771\n","Epoch 3, Train Loss: 2.2340, Val Loss: 1.9212, F1 Micro: 0.2188, F1 Macro: 0.1324, Accuracy: 0.2188\n","Epoch 4, Train Loss: 2.0713, Val Loss: 1.8737, F1 Micro: 0.2292, F1 Macro: 0.1373, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.8504, Val Loss: 2.0017, F1 Micro: 0.1979, F1 Macro: 0.1027, Accuracy: 0.1979\n","Epoch 6, Train Loss: 1.8105, Val Loss: 1.8661, F1 Micro: 0.2188, F1 Macro: 0.1880, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.7742, Val Loss: 1.8183, F1 Micro: 0.2188, F1 Macro: 0.1383, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.8379, Val Loss: 1.8551, F1 Micro: 0.2083, F1 Macro: 0.1216, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.7256, Val Loss: 1.8327, F1 Micro: 0.1875, F1 Macro: 0.1303, Accuracy: 0.1875\n","Epoch 10, Train Loss: 1.7566, Val Loss: 1.8058, F1 Micro: 0.1667, F1 Macro: 0.1162, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.7586, Val Loss: 1.8407, F1 Micro: 0.2188, F1 Macro: 0.1486, Accuracy: 0.2188\n","Epoch 12, Train Loss: 1.7445, Val Loss: 1.8237, F1 Micro: 0.2500, F1 Macro: 0.2238, Accuracy: 0.2500\n","Epoch 13, Train Loss: 1.7362, Val Loss: 1.8237, F1 Micro: 0.1979, F1 Macro: 0.1623, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.7323, Val Loss: 1.8263, F1 Micro: 0.1875, F1 Macro: 0.1218, Accuracy: 0.1875\n","Epoch 15, Train Loss: 1.6984, Val Loss: 1.8257, F1 Micro: 0.1667, F1 Macro: 0.0998, Accuracy: 0.1667\n","Epoch 16, Train Loss: 1.7094, Val Loss: 1.7728, F1 Micro: 0.2292, F1 Macro: 0.1513, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.7326, Val Loss: 1.7844, F1 Micro: 0.2500, F1 Macro: 0.2038, Accuracy: 0.2500\n","Epoch 18, Train Loss: 1.6642, Val Loss: 1.8638, F1 Micro: 0.2708, F1 Macro: 0.2171, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.6942, Val Loss: 1.8825, F1 Micro: 0.2083, F1 Macro: 0.1326, Accuracy: 0.2083\n","Epoch 20, Train Loss: 1.7372, Val Loss: 1.8196, F1 Micro: 0.2188, F1 Macro: 0.1699, Accuracy: 0.2188\n","Epoch 21, Train Loss: 1.7032, Val Loss: 1.7779, F1 Micro: 0.2083, F1 Macro: 0.1804, Accuracy: 0.2083\n","Epoch 22, Train Loss: 1.7149, Val Loss: 1.8946, F1 Micro: 0.2083, F1 Macro: 0.1267, Accuracy: 0.2083\n","Epoch 23, Train Loss: 1.6771, Val Loss: 1.8168, F1 Micro: 0.2396, F1 Macro: 0.1973, Accuracy: 0.2396\n","Epoch 24, Train Loss: 1.7227, Val Loss: 1.8408, F1 Micro: 0.2188, F1 Macro: 0.1825, Accuracy: 0.2188\n","Epoch 25, Train Loss: 1.6321, Val Loss: 1.8694, F1 Micro: 0.2083, F1 Macro: 0.1321, Accuracy: 0.2083\n","Epoch 26, Train Loss: 1.6184, Val Loss: 1.9334, F1 Micro: 0.2188, F1 Macro: 0.1708, Accuracy: 0.2188\n","Epoch 27, Train Loss: 1.6395, Val Loss: 1.8422, F1 Micro: 0.2188, F1 Macro: 0.1361, Accuracy: 0.2188\n","Epoch 28, Train Loss: 1.6380, Val Loss: 1.7600, F1 Micro: 0.2708, F1 Macro: 0.2399, Accuracy: 0.2708\n","Epoch 29, Train Loss: 1.6331, Val Loss: 1.9453, F1 Micro: 0.2188, F1 Macro: 0.1676, Accuracy: 0.2188\n","Epoch 30, Train Loss: 1.6538, Val Loss: 1.8003, F1 Micro: 0.2500, F1 Macro: 0.1907, Accuracy: 0.2500\n","Epoch 31, Train Loss: 1.6086, Val Loss: 1.7782, F1 Micro: 0.2396, F1 Macro: 0.1903, Accuracy: 0.2396\n","Epoch 32, Train Loss: 1.6054, Val Loss: 1.7415, F1 Micro: 0.2083, F1 Macro: 0.1935, Accuracy: 0.2083\n","Epoch 33, Train Loss: 1.5781, Val Loss: 1.7435, F1 Micro: 0.2500, F1 Macro: 0.2095, Accuracy: 0.2500\n","Epoch 34, Train Loss: 1.5809, Val Loss: 1.8147, F1 Micro: 0.2292, F1 Macro: 0.1947, Accuracy: 0.2292\n","Epoch 35, Train Loss: 1.6041, Val Loss: 1.7150, F1 Micro: 0.3542, F1 Macro: 0.3043, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.5584, Val Loss: 1.7299, F1 Micro: 0.3125, F1 Macro: 0.2602, Accuracy: 0.3125\n","Epoch 37, Train Loss: 1.5820, Val Loss: 1.8023, F1 Micro: 0.2500, F1 Macro: 0.1996, Accuracy: 0.2500\n","Epoch 38, Train Loss: 1.5791, Val Loss: 1.8358, F1 Micro: 0.2812, F1 Macro: 0.2176, Accuracy: 0.2812\n","Epoch 39, Train Loss: 1.5793, Val Loss: 1.9000, F1 Micro: 0.1979, F1 Macro: 0.1609, Accuracy: 0.1979\n","Epoch 40, Train Loss: 1.5861, Val Loss: 1.8210, F1 Micro: 0.2396, F1 Macro: 0.1708, Accuracy: 0.2396\n","Epoch 41, Train Loss: 1.5773, Val Loss: 1.8829, F1 Micro: 0.2500, F1 Macro: 0.2081, Accuracy: 0.2500\n","Epoch 42, Train Loss: 1.5817, Val Loss: 1.7747, F1 Micro: 0.3542, F1 Macro: 0.2731, Accuracy: 0.3542\n","Epoch 43, Train Loss: 1.5991, Val Loss: 1.7847, F1 Micro: 0.2292, F1 Macro: 0.1854, Accuracy: 0.2292\n","Epoch 44, Train Loss: 1.5144, Val Loss: 1.7734, F1 Micro: 0.3229, F1 Macro: 0.3204, Accuracy: 0.3229\n","Epoch 45, Train Loss: 1.5299, Val Loss: 1.7994, F1 Micro: 0.3542, F1 Macro: 0.2801, Accuracy: 0.3542\n","Epoch 46, Train Loss: 1.5130, Val Loss: 1.7547, F1 Micro: 0.3229, F1 Macro: 0.3137, Accuracy: 0.3229\n","Epoch 47, Train Loss: 1.4796, Val Loss: 1.8325, F1 Micro: 0.3229, F1 Macro: 0.2498, Accuracy: 0.3229\n","Epoch 48, Train Loss: 1.5949, Val Loss: 1.7490, F1 Micro: 0.2500, F1 Macro: 0.2204, Accuracy: 0.2500\n","Epoch 49, Train Loss: 1.4726, Val Loss: 1.7291, F1 Micro: 0.2812, F1 Macro: 0.2710, Accuracy: 0.2812\n","Epoch 50, Train Loss: 1.5062, Val Loss: 1.7221, F1 Micro: 0.2604, F1 Macro: 0.2137, Accuracy: 0.2604\n","Epoch 51, Train Loss: 1.4789, Val Loss: 1.7847, F1 Micro: 0.2500, F1 Macro: 0.2112, Accuracy: 0.2500\n","Epoch 52, Train Loss: 1.5213, Val Loss: 1.7402, F1 Micro: 0.3229, F1 Macro: 0.2925, Accuracy: 0.3229\n","Epoch 53, Train Loss: 1.4951, Val Loss: 1.7724, F1 Micro: 0.3125, F1 Macro: 0.2564, Accuracy: 0.3125\n","Epoch 54, Train Loss: 1.4692, Val Loss: 1.7768, F1 Micro: 0.3229, F1 Macro: 0.3012, Accuracy: 0.3229\n","Epoch 55, Train Loss: 1.4647, Val Loss: 1.8182, F1 Micro: 0.3021, F1 Macro: 0.2929, Accuracy: 0.3021\n","Epoch 56, Train Loss: 1.4297, Val Loss: 1.7762, F1 Micro: 0.3333, F1 Macro: 0.2864, Accuracy: 0.3333\n","Epoch 57, Train Loss: 1.5025, Val Loss: 1.9880, F1 Micro: 0.2604, F1 Macro: 0.2023, Accuracy: 0.2604\n","Epoch 58, Train Loss: 1.4400, Val Loss: 1.8125, F1 Micro: 0.3333, F1 Macro: 0.2967, Accuracy: 0.3333\n","Epoch 59, Train Loss: 1.4099, Val Loss: 1.8794, F1 Micro: 0.3021, F1 Macro: 0.2884, Accuracy: 0.3021\n","Epoch 60, Train Loss: 1.4723, Val Loss: 1.7719, F1 Micro: 0.3125, F1 Macro: 0.2505, Accuracy: 0.3125\n","Epoch 61, Train Loss: 1.4785, Val Loss: 1.8427, F1 Micro: 0.3021, F1 Macro: 0.2740, Accuracy: 0.3021\n","Epoch 62, Train Loss: 1.4231, Val Loss: 1.8543, F1 Micro: 0.3542, F1 Macro: 0.3302, Accuracy: 0.3542\n","Epoch 63, Train Loss: 1.3989, Val Loss: 1.8507, F1 Micro: 0.3229, F1 Macro: 0.3037, Accuracy: 0.3229\n","Epoch 64, Train Loss: 1.4120, Val Loss: 1.7862, F1 Micro: 0.3125, F1 Macro: 0.2991, Accuracy: 0.3125\n","Epoch 65, Train Loss: 1.4269, Val Loss: 1.8431, F1 Micro: 0.3021, F1 Macro: 0.2945, Accuracy: 0.3021\n","Epoch 66, Train Loss: 1.3465, Val Loss: 1.9481, F1 Micro: 0.3333, F1 Macro: 0.3038, Accuracy: 0.3333\n","Epoch 67, Train Loss: 1.3861, Val Loss: 1.8408, F1 Micro: 0.2812, F1 Macro: 0.2716, Accuracy: 0.2812\n","Epoch 68, Train Loss: 1.3838, Val Loss: 1.8297, F1 Micro: 0.3854, F1 Macro: 0.3864, Accuracy: 0.3854\n","Epoch 69, Train Loss: 1.3476, Val Loss: 1.8017, F1 Micro: 0.3438, F1 Macro: 0.3263, Accuracy: 0.3438\n","Epoch 70, Train Loss: 1.3323, Val Loss: 1.9343, F1 Micro: 0.3021, F1 Macro: 0.2769, Accuracy: 0.3021\n","Epoch 71, Train Loss: 1.3742, Val Loss: 1.8698, F1 Micro: 0.2917, F1 Macro: 0.2583, Accuracy: 0.2917\n","Epoch 72, Train Loss: 1.3892, Val Loss: 1.9236, F1 Micro: 0.3542, F1 Macro: 0.3024, Accuracy: 0.3542\n","Epoch 73, Train Loss: 1.4093, Val Loss: 2.0230, F1 Micro: 0.3229, F1 Macro: 0.2990, Accuracy: 0.3229\n","Epoch 74, Train Loss: 1.3557, Val Loss: 1.8312, F1 Micro: 0.4062, F1 Macro: 0.3710, Accuracy: 0.4062\n","Epoch 75, Train Loss: 1.3044, Val Loss: 1.9894, F1 Micro: 0.3438, F1 Macro: 0.2926, Accuracy: 0.3438\n","Epoch 76, Train Loss: 1.3510, Val Loss: 1.8612, F1 Micro: 0.3438, F1 Macro: 0.3174, Accuracy: 0.3438\n","Epoch 77, Train Loss: 1.2821, Val Loss: 1.9210, F1 Micro: 0.3438, F1 Macro: 0.3296, Accuracy: 0.3438\n","Epoch 78, Train Loss: 1.3113, Val Loss: 2.1206, F1 Micro: 0.2604, F1 Macro: 0.2349, Accuracy: 0.2604\n","Epoch 79, Train Loss: 1.3598, Val Loss: 1.9706, F1 Micro: 0.3438, F1 Macro: 0.3181, Accuracy: 0.3438\n","Epoch 80, Train Loss: 1.3189, Val Loss: 1.8441, F1 Micro: 0.3750, F1 Macro: 0.3667, Accuracy: 0.3750\n","Epoch 81, Train Loss: 1.2463, Val Loss: 2.0440, F1 Micro: 0.3333, F1 Macro: 0.3265, Accuracy: 0.3333\n","Epoch 82, Train Loss: 1.2749, Val Loss: 1.9025, F1 Micro: 0.3438, F1 Macro: 0.3323, Accuracy: 0.3438\n","Epoch 83, Train Loss: 1.2701, Val Loss: 1.8779, F1 Micro: 0.3958, F1 Macro: 0.3837, Accuracy: 0.3958\n","Epoch 84, Train Loss: 1.2999, Val Loss: 1.9449, F1 Micro: 0.3854, F1 Macro: 0.3485, Accuracy: 0.3854\n","Epoch 85, Train Loss: 1.2584, Val Loss: 1.9492, F1 Micro: 0.3333, F1 Macro: 0.2826, Accuracy: 0.3333\n","Epoch 86, Train Loss: 1.1881, Val Loss: 1.8794, F1 Micro: 0.4479, F1 Macro: 0.4384, Accuracy: 0.4479\n","Epoch 87, Train Loss: 1.2563, Val Loss: 1.8785, F1 Micro: 0.3854, F1 Macro: 0.3738, Accuracy: 0.3854\n","Epoch 88, Train Loss: 1.2213, Val Loss: 1.9910, F1 Micro: 0.3750, F1 Macro: 0.3540, Accuracy: 0.3750\n","Epoch 89, Train Loss: 1.2491, Val Loss: 2.0299, F1 Micro: 0.3438, F1 Macro: 0.3126, Accuracy: 0.3438\n","Epoch 90, Train Loss: 1.2123, Val Loss: 2.0058, F1 Micro: 0.3125, F1 Macro: 0.3017, Accuracy: 0.3125\n","Epoch 91, Train Loss: 1.1842, Val Loss: 1.9533, F1 Micro: 0.3958, F1 Macro: 0.3762, Accuracy: 0.3958\n","Epoch 92, Train Loss: 1.2437, Val Loss: 1.9552, F1 Micro: 0.3750, F1 Macro: 0.3741, Accuracy: 0.3750\n","Epoch 93, Train Loss: 1.1793, Val Loss: 1.8723, F1 Micro: 0.4375, F1 Macro: 0.4325, Accuracy: 0.4375\n","Epoch 94, Train Loss: 1.1650, Val Loss: 1.9429, F1 Micro: 0.4167, F1 Macro: 0.3851, Accuracy: 0.4167\n","Epoch 95, Train Loss: 1.1533, Val Loss: 1.8627, F1 Micro: 0.4271, F1 Macro: 0.4361, Accuracy: 0.4271\n","Epoch 96, Train Loss: 1.1542, Val Loss: 1.9779, F1 Micro: 0.3854, F1 Macro: 0.3902, Accuracy: 0.3854\n","Epoch 97, Train Loss: 1.1543, Val Loss: 1.8394, F1 Micro: 0.3750, F1 Macro: 0.3564, Accuracy: 0.3750\n","Epoch 98, Train Loss: 1.1469, Val Loss: 1.9552, F1 Micro: 0.4896, F1 Macro: 0.4712, Accuracy: 0.4896\n","Epoch 99, Train Loss: 1.1055, Val Loss: 1.9554, F1 Micro: 0.4479, F1 Macro: 0.4242, Accuracy: 0.4479\n","Epoch 100, Train Loss: 1.1224, Val Loss: 1.8934, F1 Micro: 0.4167, F1 Macro: 0.4141, Accuracy: 0.4167\n","Epoch 101, Train Loss: 1.1824, Val Loss: 1.8832, F1 Micro: 0.3646, F1 Macro: 0.3721, Accuracy: 0.3646\n","Epoch 102, Train Loss: 1.1396, Val Loss: 1.9740, F1 Micro: 0.4271, F1 Macro: 0.4208, Accuracy: 0.4271\n","Epoch 103, Train Loss: 1.1636, Val Loss: 1.9354, F1 Micro: 0.3958, F1 Macro: 0.3855, Accuracy: 0.3958\n","Epoch 104, Train Loss: 1.0976, Val Loss: 1.9902, F1 Micro: 0.4167, F1 Macro: 0.3948, Accuracy: 0.4167\n","Epoch 105, Train Loss: 1.1675, Val Loss: 1.9250, F1 Micro: 0.3958, F1 Macro: 0.3771, Accuracy: 0.3958\n","Epoch 106, Train Loss: 1.0947, Val Loss: 1.9672, F1 Micro: 0.4479, F1 Macro: 0.4333, Accuracy: 0.4479\n","Epoch 107, Train Loss: 1.1160, Val Loss: 1.8264, F1 Micro: 0.4062, F1 Macro: 0.3937, Accuracy: 0.4062\n","Epoch 108, Train Loss: 1.0794, Val Loss: 2.0104, F1 Micro: 0.3958, F1 Macro: 0.3774, Accuracy: 0.3958\n","Epoch 109, Train Loss: 1.0707, Val Loss: 2.0305, F1 Micro: 0.3542, F1 Macro: 0.3438, Accuracy: 0.3542\n","Epoch 110, Train Loss: 1.0436, Val Loss: 1.9818, F1 Micro: 0.3958, F1 Macro: 0.3785, Accuracy: 0.3958\n","Epoch 111, Train Loss: 1.0776, Val Loss: 1.8582, F1 Micro: 0.4062, F1 Macro: 0.3909, Accuracy: 0.4062\n","Epoch 112, Train Loss: 1.0360, Val Loss: 1.9418, F1 Micro: 0.4167, F1 Macro: 0.4197, Accuracy: 0.4167\n","Epoch 113, Train Loss: 1.0364, Val Loss: 1.9227, F1 Micro: 0.4167, F1 Macro: 0.4033, Accuracy: 0.4167\n","Epoch 114, Train Loss: 1.0216, Val Loss: 2.1132, F1 Micro: 0.3958, F1 Macro: 0.3886, Accuracy: 0.3958\n","Epoch 115, Train Loss: 1.0350, Val Loss: 1.8935, F1 Micro: 0.3958, F1 Macro: 0.3991, Accuracy: 0.3958\n","Epoch 116, Train Loss: 0.9968, Val Loss: 2.0387, F1 Micro: 0.4167, F1 Macro: 0.3970, Accuracy: 0.4167\n","Epoch 117, Train Loss: 1.0513, Val Loss: 1.9556, F1 Micro: 0.3854, F1 Macro: 0.3774, Accuracy: 0.3854\n","Epoch 118, Train Loss: 1.1587, Val Loss: 2.0104, F1 Micro: 0.3542, F1 Macro: 0.3344, Accuracy: 0.3542\n","Epoch 119, Train Loss: 1.0784, Val Loss: 1.9492, F1 Micro: 0.3854, F1 Macro: 0.3715, Accuracy: 0.3854\n","Epoch 120, Train Loss: 0.9762, Val Loss: 1.9908, F1 Micro: 0.3958, F1 Macro: 0.3965, Accuracy: 0.3958\n","Epoch 121, Train Loss: 0.9513, Val Loss: 1.8794, F1 Micro: 0.4479, F1 Macro: 0.4338, Accuracy: 0.4479\n","Epoch 122, Train Loss: 0.9989, Val Loss: 2.0807, F1 Micro: 0.4271, F1 Macro: 0.4191, Accuracy: 0.4271\n","Epoch 123, Train Loss: 0.9441, Val Loss: 1.9530, F1 Micro: 0.4479, F1 Macro: 0.4398, Accuracy: 0.4479\n","Epoch 124, Train Loss: 0.9511, Val Loss: 2.0027, F1 Micro: 0.4688, F1 Macro: 0.4675, Accuracy: 0.4688\n","Epoch 125, Train Loss: 0.9731, Val Loss: 1.9222, F1 Micro: 0.3958, F1 Macro: 0.3660, Accuracy: 0.3958\n","Epoch 126, Train Loss: 0.9636, Val Loss: 2.3570, F1 Micro: 0.4062, F1 Macro: 0.4046, Accuracy: 0.4062\n","Epoch 127, Train Loss: 1.0252, Val Loss: 1.9654, F1 Micro: 0.3958, F1 Macro: 0.3722, Accuracy: 0.3958\n","Epoch 128, Train Loss: 0.9192, Val Loss: 2.1274, F1 Micro: 0.3542, F1 Macro: 0.3522, Accuracy: 0.3542\n","Epoch 129, Train Loss: 0.9913, Val Loss: 2.0087, F1 Micro: 0.4896, F1 Macro: 0.4755, Accuracy: 0.4896\n","Epoch 130, Train Loss: 0.9549, Val Loss: 1.9954, F1 Micro: 0.4896, F1 Macro: 0.4804, Accuracy: 0.4896\n","Epoch 131, Train Loss: 0.9351, Val Loss: 2.1153, F1 Micro: 0.4062, F1 Macro: 0.4004, Accuracy: 0.4062\n","Epoch 132, Train Loss: 0.9238, Val Loss: 2.0950, F1 Micro: 0.3854, F1 Macro: 0.3879, Accuracy: 0.3854\n","Epoch 133, Train Loss: 0.9453, Val Loss: 2.0688, F1 Micro: 0.3333, F1 Macro: 0.3284, Accuracy: 0.3333\n","Epoch 134, Train Loss: 0.9604, Val Loss: 2.1053, F1 Micro: 0.4271, F1 Macro: 0.4077, Accuracy: 0.4271\n","Epoch 135, Train Loss: 0.9489, Val Loss: 2.0244, F1 Micro: 0.4271, F1 Macro: 0.4145, Accuracy: 0.4271\n","Epoch 136, Train Loss: 0.8422, Val Loss: 2.0709, F1 Micro: 0.3958, F1 Macro: 0.3717, Accuracy: 0.3958\n","Epoch 137, Train Loss: 0.8924, Val Loss: 2.2112, F1 Micro: 0.4688, F1 Macro: 0.4648, Accuracy: 0.4688\n","Epoch 138, Train Loss: 0.8570, Val Loss: 2.2725, F1 Micro: 0.3750, F1 Macro: 0.3804, Accuracy: 0.3750\n","Epoch 139, Train Loss: 0.8617, Val Loss: 2.1164, F1 Micro: 0.4375, F1 Macro: 0.4420, Accuracy: 0.4375\n","Epoch 140, Train Loss: 0.8896, Val Loss: 2.1934, F1 Micro: 0.4479, F1 Macro: 0.4352, Accuracy: 0.4479\n","Epoch 141, Train Loss: 0.8379, Val Loss: 2.0584, F1 Micro: 0.4271, F1 Macro: 0.4260, Accuracy: 0.4271\n","Epoch 142, Train Loss: 0.8639, Val Loss: 2.0046, F1 Micro: 0.4271, F1 Macro: 0.4297, Accuracy: 0.4271\n","Epoch 143, Train Loss: 0.7887, Val Loss: 2.1089, F1 Micro: 0.4062, F1 Macro: 0.3938, Accuracy: 0.4062\n","Epoch 144, Train Loss: 0.8491, Val Loss: 2.2060, F1 Micro: 0.3958, F1 Macro: 0.4019, Accuracy: 0.3958\n","Epoch 145, Train Loss: 0.8000, Val Loss: 2.1825, F1 Micro: 0.4271, F1 Macro: 0.4206, Accuracy: 0.4271\n","Epoch 146, Train Loss: 0.8840, Val Loss: 2.2413, F1 Micro: 0.4375, F1 Macro: 0.4139, Accuracy: 0.4375\n","Epoch 147, Train Loss: 0.8262, Val Loss: 2.1937, F1 Micro: 0.4167, F1 Macro: 0.4184, Accuracy: 0.4167\n","Epoch 148, Train Loss: 0.8496, Val Loss: 2.2810, F1 Micro: 0.3958, F1 Macro: 0.3909, Accuracy: 0.3958\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.5588, Val Loss: 1.6835, F1 Micro: 0.2917, F1 Macro: 0.2398, Accuracy: 0.2917\n","Epoch 2, Train Loss: 2.4620, Val Loss: 2.0371, F1 Micro: 0.2188, F1 Macro: 0.1125, Accuracy: 0.2188\n","Epoch 3, Train Loss: 2.1172, Val Loss: 1.9145, F1 Micro: 0.2188, F1 Macro: 0.1365, Accuracy: 0.2188\n","Epoch 4, Train Loss: 2.1627, Val Loss: 1.8663, F1 Micro: 0.1979, F1 Macro: 0.1211, Accuracy: 0.1979\n","Epoch 5, Train Loss: 2.0058, Val Loss: 2.0014, F1 Micro: 0.2292, F1 Macro: 0.1694, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.9323, Val Loss: 1.7363, F1 Micro: 0.2604, F1 Macro: 0.1775, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.8398, Val Loss: 1.8244, F1 Micro: 0.3542, F1 Macro: 0.3181, Accuracy: 0.3542\n","Epoch 8, Train Loss: 1.8245, Val Loss: 1.7357, F1 Micro: 0.2708, F1 Macro: 0.2010, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.8749, Val Loss: 1.6525, F1 Micro: 0.3750, F1 Macro: 0.3491, Accuracy: 0.3750\n","Epoch 10, Train Loss: 1.7567, Val Loss: 1.6455, F1 Micro: 0.3438, F1 Macro: 0.2739, Accuracy: 0.3438\n","Epoch 11, Train Loss: 1.7656, Val Loss: 1.6746, F1 Micro: 0.3021, F1 Macro: 0.2061, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.7293, Val Loss: 1.6665, F1 Micro: 0.3229, F1 Macro: 0.2636, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.7796, Val Loss: 1.6819, F1 Micro: 0.3021, F1 Macro: 0.2642, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.6817, Val Loss: 1.6519, F1 Micro: 0.2917, F1 Macro: 0.2609, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.7195, Val Loss: 1.5970, F1 Micro: 0.3646, F1 Macro: 0.3630, Accuracy: 0.3646\n","Epoch 16, Train Loss: 1.7069, Val Loss: 1.6269, F1 Micro: 0.3750, F1 Macro: 0.3179, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.6992, Val Loss: 1.6910, F1 Micro: 0.3750, F1 Macro: 0.3260, Accuracy: 0.3750\n","Epoch 18, Train Loss: 1.7093, Val Loss: 1.6248, F1 Micro: 0.3958, F1 Macro: 0.3974, Accuracy: 0.3958\n","Epoch 19, Train Loss: 1.7095, Val Loss: 1.7064, F1 Micro: 0.2812, F1 Macro: 0.2444, Accuracy: 0.2812\n","Epoch 20, Train Loss: 1.7067, Val Loss: 1.7425, F1 Micro: 0.2500, F1 Macro: 0.2004, Accuracy: 0.2500\n","Epoch 21, Train Loss: 1.7006, Val Loss: 1.6466, F1 Micro: 0.3438, F1 Macro: 0.2749, Accuracy: 0.3438\n","Epoch 22, Train Loss: 1.6322, Val Loss: 1.6011, F1 Micro: 0.3333, F1 Macro: 0.2820, Accuracy: 0.3333\n","Epoch 23, Train Loss: 1.6830, Val Loss: 1.6785, F1 Micro: 0.3021, F1 Macro: 0.2653, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.6689, Val Loss: 1.6898, F1 Micro: 0.3854, F1 Macro: 0.3355, Accuracy: 0.3854\n","Epoch 25, Train Loss: 1.6633, Val Loss: 1.6587, F1 Micro: 0.3333, F1 Macro: 0.2981, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.6408, Val Loss: 1.6235, F1 Micro: 0.3438, F1 Macro: 0.3196, Accuracy: 0.3438\n","Epoch 27, Train Loss: 1.6223, Val Loss: 1.5911, F1 Micro: 0.3333, F1 Macro: 0.3186, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.6594, Val Loss: 1.6017, F1 Micro: 0.3750, F1 Macro: 0.3282, Accuracy: 0.3750\n","Epoch 29, Train Loss: 1.6331, Val Loss: 1.6077, F1 Micro: 0.3646, F1 Macro: 0.3606, Accuracy: 0.3646\n","Epoch 30, Train Loss: 1.6297, Val Loss: 1.5874, F1 Micro: 0.3750, F1 Macro: 0.3840, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.6017, Val Loss: 1.5921, F1 Micro: 0.3542, F1 Macro: 0.3140, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.5846, Val Loss: 1.5986, F1 Micro: 0.3333, F1 Macro: 0.2481, Accuracy: 0.3333\n","Epoch 33, Train Loss: 1.6304, Val Loss: 1.5918, F1 Micro: 0.3229, F1 Macro: 0.2836, Accuracy: 0.3229\n","Epoch 34, Train Loss: 1.6080, Val Loss: 1.8335, F1 Micro: 0.3333, F1 Macro: 0.2795, Accuracy: 0.3333\n","Epoch 35, Train Loss: 1.5966, Val Loss: 1.5919, F1 Micro: 0.3438, F1 Macro: 0.2888, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.6270, Val Loss: 1.6988, F1 Micro: 0.2812, F1 Macro: 0.2207, Accuracy: 0.2812\n","Epoch 37, Train Loss: 1.6684, Val Loss: 1.5797, F1 Micro: 0.3854, F1 Macro: 0.3858, Accuracy: 0.3854\n","Epoch 38, Train Loss: 1.6167, Val Loss: 1.7210, F1 Micro: 0.3125, F1 Macro: 0.2603, Accuracy: 0.3125\n","Epoch 39, Train Loss: 1.5808, Val Loss: 1.6033, F1 Micro: 0.3125, F1 Macro: 0.2666, Accuracy: 0.3125\n","Epoch 40, Train Loss: 1.6291, Val Loss: 1.5865, F1 Micro: 0.4375, F1 Macro: 0.3788, Accuracy: 0.4375\n","Epoch 41, Train Loss: 1.5555, Val Loss: 1.5228, F1 Micro: 0.3854, F1 Macro: 0.3822, Accuracy: 0.3854\n","Epoch 42, Train Loss: 1.5514, Val Loss: 1.5299, F1 Micro: 0.4583, F1 Macro: 0.4415, Accuracy: 0.4583\n","Epoch 43, Train Loss: 1.5579, Val Loss: 1.6035, F1 Micro: 0.3438, F1 Macro: 0.3175, Accuracy: 0.3438\n","Epoch 44, Train Loss: 1.5413, Val Loss: 1.6296, F1 Micro: 0.3542, F1 Macro: 0.3413, Accuracy: 0.3542\n","Epoch 45, Train Loss: 1.5673, Val Loss: 1.6258, F1 Micro: 0.3750, F1 Macro: 0.3656, Accuracy: 0.3750\n","Epoch 46, Train Loss: 1.5513, Val Loss: 1.6567, F1 Micro: 0.3646, F1 Macro: 0.3059, Accuracy: 0.3646\n","Epoch 47, Train Loss: 1.5374, Val Loss: 1.5940, F1 Micro: 0.3438, F1 Macro: 0.2590, Accuracy: 0.3438\n","Epoch 48, Train Loss: 1.5227, Val Loss: 1.5848, F1 Micro: 0.3750, F1 Macro: 0.2971, Accuracy: 0.3750\n","Epoch 49, Train Loss: 1.5145, Val Loss: 1.5454, F1 Micro: 0.4271, F1 Macro: 0.3948, Accuracy: 0.4271\n","Epoch 50, Train Loss: 1.5032, Val Loss: 1.6896, F1 Micro: 0.3646, F1 Macro: 0.3470, Accuracy: 0.3646\n","Epoch 51, Train Loss: 1.4859, Val Loss: 1.7121, F1 Micro: 0.3125, F1 Macro: 0.2539, Accuracy: 0.3125\n","Epoch 52, Train Loss: 1.5270, Val Loss: 1.5287, F1 Micro: 0.4583, F1 Macro: 0.4321, Accuracy: 0.4583\n","Epoch 53, Train Loss: 1.5361, Val Loss: 1.5696, F1 Micro: 0.3854, F1 Macro: 0.3505, Accuracy: 0.3854\n","Epoch 54, Train Loss: 1.4964, Val Loss: 1.4936, F1 Micro: 0.4167, F1 Macro: 0.3989, Accuracy: 0.4167\n","Epoch 55, Train Loss: 1.4274, Val Loss: 1.5084, F1 Micro: 0.4688, F1 Macro: 0.4451, Accuracy: 0.4688\n","Epoch 56, Train Loss: 1.4846, Val Loss: 1.6028, F1 Micro: 0.3021, F1 Macro: 0.2665, Accuracy: 0.3021\n","Epoch 57, Train Loss: 1.5099, Val Loss: 1.5405, F1 Micro: 0.3542, F1 Macro: 0.3300, Accuracy: 0.3542\n","Epoch 58, Train Loss: 1.4315, Val Loss: 1.5627, F1 Micro: 0.3750, F1 Macro: 0.3409, Accuracy: 0.3750\n","Epoch 59, Train Loss: 1.4546, Val Loss: 1.6752, F1 Micro: 0.3646, F1 Macro: 0.3308, Accuracy: 0.3646\n","Epoch 60, Train Loss: 1.4952, Val Loss: 1.6826, F1 Micro: 0.3333, F1 Macro: 0.2824, Accuracy: 0.3333\n","Epoch 61, Train Loss: 1.4453, Val Loss: 1.5801, F1 Micro: 0.3125, F1 Macro: 0.3108, Accuracy: 0.3125\n","Epoch 62, Train Loss: 1.4413, Val Loss: 1.4718, F1 Micro: 0.4688, F1 Macro: 0.4556, Accuracy: 0.4688\n","Epoch 63, Train Loss: 1.4293, Val Loss: 1.4658, F1 Micro: 0.4792, F1 Macro: 0.4434, Accuracy: 0.4792\n","Epoch 64, Train Loss: 1.4240, Val Loss: 1.5860, F1 Micro: 0.3438, F1 Macro: 0.3263, Accuracy: 0.3438\n","Epoch 65, Train Loss: 1.4306, Val Loss: 1.5150, F1 Micro: 0.4271, F1 Macro: 0.3811, Accuracy: 0.4271\n","Epoch 66, Train Loss: 1.4203, Val Loss: 1.5481, F1 Micro: 0.4271, F1 Macro: 0.4144, Accuracy: 0.4271\n","Epoch 67, Train Loss: 1.3782, Val Loss: 1.5244, F1 Micro: 0.4167, F1 Macro: 0.4055, Accuracy: 0.4167\n","Epoch 68, Train Loss: 1.3933, Val Loss: 1.4790, F1 Micro: 0.4062, F1 Macro: 0.3817, Accuracy: 0.4062\n","Epoch 69, Train Loss: 1.3468, Val Loss: 1.4885, F1 Micro: 0.4479, F1 Macro: 0.4136, Accuracy: 0.4479\n","Epoch 70, Train Loss: 1.3584, Val Loss: 1.5661, F1 Micro: 0.4479, F1 Macro: 0.4320, Accuracy: 0.4479\n","Epoch 71, Train Loss: 1.3584, Val Loss: 1.5183, F1 Micro: 0.4375, F1 Macro: 0.4021, Accuracy: 0.4375\n","Epoch 72, Train Loss: 1.3122, Val Loss: 1.4527, F1 Micro: 0.4896, F1 Macro: 0.4819, Accuracy: 0.4896\n","Epoch 73, Train Loss: 1.3275, Val Loss: 1.5901, F1 Micro: 0.3333, F1 Macro: 0.3232, Accuracy: 0.3333\n","Epoch 74, Train Loss: 1.3015, Val Loss: 1.5147, F1 Micro: 0.4583, F1 Macro: 0.4552, Accuracy: 0.4583\n","Epoch 75, Train Loss: 1.3171, Val Loss: 1.5303, F1 Micro: 0.4792, F1 Macro: 0.4710, Accuracy: 0.4792\n","Epoch 76, Train Loss: 1.3781, Val Loss: 1.5801, F1 Micro: 0.4062, F1 Macro: 0.3937, Accuracy: 0.4062\n","Epoch 77, Train Loss: 1.3210, Val Loss: 1.5741, F1 Micro: 0.4167, F1 Macro: 0.3954, Accuracy: 0.4167\n","Epoch 78, Train Loss: 1.3185, Val Loss: 1.6436, F1 Micro: 0.4375, F1 Macro: 0.3968, Accuracy: 0.4375\n","Epoch 79, Train Loss: 1.2867, Val Loss: 1.5497, F1 Micro: 0.4479, F1 Macro: 0.4364, Accuracy: 0.4479\n","Epoch 80, Train Loss: 1.2989, Val Loss: 1.5779, F1 Micro: 0.4688, F1 Macro: 0.4498, Accuracy: 0.4688\n","Epoch 81, Train Loss: 1.3575, Val Loss: 1.5177, F1 Micro: 0.4167, F1 Macro: 0.4145, Accuracy: 0.4167\n","Epoch 82, Train Loss: 1.3265, Val Loss: 1.5564, F1 Micro: 0.4167, F1 Macro: 0.4152, Accuracy: 0.4167\n","Epoch 83, Train Loss: 1.2473, Val Loss: 1.6184, F1 Micro: 0.3854, F1 Macro: 0.3571, Accuracy: 0.3854\n","Epoch 84, Train Loss: 1.2386, Val Loss: 1.6231, F1 Micro: 0.4479, F1 Macro: 0.4292, Accuracy: 0.4479\n","Epoch 85, Train Loss: 1.3120, Val Loss: 1.5571, F1 Micro: 0.4479, F1 Macro: 0.4158, Accuracy: 0.4479\n","Epoch 86, Train Loss: 1.3048, Val Loss: 1.6741, F1 Micro: 0.3542, F1 Macro: 0.3526, Accuracy: 0.3542\n","Epoch 87, Train Loss: 1.2646, Val Loss: 1.6647, F1 Micro: 0.4375, F1 Macro: 0.4291, Accuracy: 0.4375\n","Epoch 88, Train Loss: 1.2911, Val Loss: 1.6054, F1 Micro: 0.4375, F1 Macro: 0.4271, Accuracy: 0.4375\n","Epoch 89, Train Loss: 1.2098, Val Loss: 1.5867, F1 Micro: 0.4896, F1 Macro: 0.4752, Accuracy: 0.4896\n","Epoch 90, Train Loss: 1.2228, Val Loss: 1.5200, F1 Micro: 0.5000, F1 Macro: 0.4955, Accuracy: 0.5000\n","Epoch 91, Train Loss: 1.2420, Val Loss: 1.6038, F1 Micro: 0.4583, F1 Macro: 0.4519, Accuracy: 0.4583\n","Epoch 92, Train Loss: 1.1893, Val Loss: 1.6094, F1 Micro: 0.4271, F1 Macro: 0.4013, Accuracy: 0.4271\n","Epoch 93, Train Loss: 1.1660, Val Loss: 1.5755, F1 Micro: 0.4688, F1 Macro: 0.4649, Accuracy: 0.4688\n","Epoch 94, Train Loss: 1.2283, Val Loss: 1.5507, F1 Micro: 0.4167, F1 Macro: 0.4141, Accuracy: 0.4167\n","Epoch 95, Train Loss: 1.1838, Val Loss: 1.6845, F1 Micro: 0.4375, F1 Macro: 0.4242, Accuracy: 0.4375\n","Epoch 96, Train Loss: 1.2062, Val Loss: 1.6270, F1 Micro: 0.4896, F1 Macro: 0.4843, Accuracy: 0.4896\n","Epoch 97, Train Loss: 1.2265, Val Loss: 1.7849, F1 Micro: 0.3438, F1 Macro: 0.3190, Accuracy: 0.3438\n","Epoch 98, Train Loss: 1.1718, Val Loss: 1.6121, F1 Micro: 0.5104, F1 Macro: 0.5006, Accuracy: 0.5104\n","Epoch 99, Train Loss: 1.1733, Val Loss: 1.6140, F1 Micro: 0.4583, F1 Macro: 0.4551, Accuracy: 0.4583\n","Epoch 100, Train Loss: 1.1778, Val Loss: 1.8059, F1 Micro: 0.3958, F1 Macro: 0.3890, Accuracy: 0.3958\n","Epoch 101, Train Loss: 1.1315, Val Loss: 1.7523, F1 Micro: 0.4896, F1 Macro: 0.4565, Accuracy: 0.4896\n","Epoch 102, Train Loss: 1.1370, Val Loss: 1.5901, F1 Micro: 0.5104, F1 Macro: 0.4989, Accuracy: 0.5104\n","Epoch 103, Train Loss: 1.1282, Val Loss: 1.7394, F1 Micro: 0.3958, F1 Macro: 0.3833, Accuracy: 0.3958\n","Epoch 104, Train Loss: 1.1147, Val Loss: 1.6994, F1 Micro: 0.4271, F1 Macro: 0.4168, Accuracy: 0.4271\n","Epoch 105, Train Loss: 1.1807, Val Loss: 1.6298, F1 Micro: 0.4375, F1 Macro: 0.4347, Accuracy: 0.4375\n","Epoch 106, Train Loss: 1.1071, Val Loss: 1.6191, F1 Micro: 0.4792, F1 Macro: 0.4764, Accuracy: 0.4792\n","Epoch 107, Train Loss: 1.1354, Val Loss: 1.6042, F1 Micro: 0.4479, F1 Macro: 0.4384, Accuracy: 0.4479\n","Epoch 108, Train Loss: 1.1059, Val Loss: 1.6949, F1 Micro: 0.4896, F1 Macro: 0.4827, Accuracy: 0.4896\n","Epoch 109, Train Loss: 1.0963, Val Loss: 1.7475, F1 Micro: 0.4583, F1 Macro: 0.4598, Accuracy: 0.4583\n","Epoch 110, Train Loss: 1.0515, Val Loss: 1.8407, F1 Micro: 0.4375, F1 Macro: 0.3989, Accuracy: 0.4375\n","Epoch 111, Train Loss: 1.0744, Val Loss: 1.6653, F1 Micro: 0.4896, F1 Macro: 0.4832, Accuracy: 0.4896\n","Epoch 112, Train Loss: 1.0916, Val Loss: 1.6685, F1 Micro: 0.4167, F1 Macro: 0.3893, Accuracy: 0.4167\n","Epoch 113, Train Loss: 1.1199, Val Loss: 1.6687, F1 Micro: 0.4375, F1 Macro: 0.4055, Accuracy: 0.4375\n","Epoch 114, Train Loss: 1.0709, Val Loss: 1.6380, F1 Micro: 0.5104, F1 Macro: 0.5144, Accuracy: 0.5104\n","Epoch 115, Train Loss: 1.0988, Val Loss: 1.7120, F1 Micro: 0.4688, F1 Macro: 0.4467, Accuracy: 0.4688\n","Epoch 116, Train Loss: 1.0630, Val Loss: 1.6420, F1 Micro: 0.4792, F1 Macro: 0.4674, Accuracy: 0.4792\n","Epoch 117, Train Loss: 1.0441, Val Loss: 1.7529, F1 Micro: 0.4583, F1 Macro: 0.4492, Accuracy: 0.4583\n","Epoch 118, Train Loss: 1.0388, Val Loss: 1.7472, F1 Micro: 0.4167, F1 Macro: 0.4113, Accuracy: 0.4167\n","Epoch 119, Train Loss: 1.0643, Val Loss: 1.6350, F1 Micro: 0.5312, F1 Macro: 0.5128, Accuracy: 0.5312\n","Epoch 120, Train Loss: 1.0927, Val Loss: 1.5472, F1 Micro: 0.5104, F1 Macro: 0.5123, Accuracy: 0.5104\n","Epoch 121, Train Loss: 1.0956, Val Loss: 1.6322, F1 Micro: 0.4583, F1 Macro: 0.4526, Accuracy: 0.4583\n","Epoch 122, Train Loss: 1.0873, Val Loss: 1.5892, F1 Micro: 0.4583, F1 Macro: 0.4399, Accuracy: 0.4583\n","Epoch 123, Train Loss: 1.0049, Val Loss: 1.7294, F1 Micro: 0.4271, F1 Macro: 0.4089, Accuracy: 0.4271\n","Epoch 124, Train Loss: 1.0543, Val Loss: 1.6023, F1 Micro: 0.4896, F1 Macro: 0.4737, Accuracy: 0.4896\n","Epoch 125, Train Loss: 1.0135, Val Loss: 1.6438, F1 Micro: 0.4896, F1 Macro: 0.4848, Accuracy: 0.4896\n","Epoch 126, Train Loss: 1.0432, Val Loss: 1.6408, F1 Micro: 0.4583, F1 Macro: 0.4522, Accuracy: 0.4583\n","Epoch 127, Train Loss: 1.0367, Val Loss: 1.7446, F1 Micro: 0.4896, F1 Macro: 0.4725, Accuracy: 0.4896\n","Epoch 128, Train Loss: 1.0290, Val Loss: 1.6849, F1 Micro: 0.4896, F1 Macro: 0.4766, Accuracy: 0.4896\n","Epoch 129, Train Loss: 0.9982, Val Loss: 1.5736, F1 Micro: 0.5208, F1 Macro: 0.5117, Accuracy: 0.5208\n","Epoch 130, Train Loss: 0.9990, Val Loss: 1.6787, F1 Micro: 0.4167, F1 Macro: 0.4087, Accuracy: 0.4167\n","Epoch 131, Train Loss: 0.9858, Val Loss: 1.7643, F1 Micro: 0.5104, F1 Macro: 0.5065, Accuracy: 0.5104\n","Epoch 132, Train Loss: 0.9978, Val Loss: 1.6694, F1 Micro: 0.5104, F1 Macro: 0.5058, Accuracy: 0.5104\n","Epoch 133, Train Loss: 0.9245, Val Loss: 1.7098, F1 Micro: 0.5417, F1 Macro: 0.5341, Accuracy: 0.5417\n","Epoch 134, Train Loss: 0.9488, Val Loss: 1.7674, F1 Micro: 0.5312, F1 Macro: 0.5347, Accuracy: 0.5312\n","Epoch 135, Train Loss: 0.8973, Val Loss: 1.6841, F1 Micro: 0.5000, F1 Macro: 0.4998, Accuracy: 0.5000\n","Epoch 136, Train Loss: 0.8911, Val Loss: 1.7376, F1 Micro: 0.5104, F1 Macro: 0.5053, Accuracy: 0.5104\n","Epoch 137, Train Loss: 0.8999, Val Loss: 1.7780, F1 Micro: 0.4896, F1 Macro: 0.4716, Accuracy: 0.4896\n","Epoch 138, Train Loss: 0.9904, Val Loss: 1.7530, F1 Micro: 0.5104, F1 Macro: 0.5002, Accuracy: 0.5104\n","Epoch 139, Train Loss: 1.0005, Val Loss: 1.7377, F1 Micro: 0.5000, F1 Macro: 0.4964, Accuracy: 0.5000\n","Epoch 140, Train Loss: 0.9632, Val Loss: 1.7057, F1 Micro: 0.4896, F1 Macro: 0.4890, Accuracy: 0.4896\n","Epoch 141, Train Loss: 0.9317, Val Loss: 1.8246, F1 Micro: 0.5104, F1 Macro: 0.4991, Accuracy: 0.5104\n","Epoch 142, Train Loss: 0.8874, Val Loss: 1.7010, F1 Micro: 0.4792, F1 Macro: 0.4445, Accuracy: 0.4792\n","Epoch 143, Train Loss: 0.9030, Val Loss: 1.7523, F1 Micro: 0.4792, F1 Macro: 0.4669, Accuracy: 0.4792\n","Epoch 144, Train Loss: 0.9100, Val Loss: 1.7000, F1 Micro: 0.5521, F1 Macro: 0.5512, Accuracy: 0.5521\n","Epoch 145, Train Loss: 0.9087, Val Loss: 1.7720, F1 Micro: 0.5000, F1 Macro: 0.5036, Accuracy: 0.5000\n","Epoch 146, Train Loss: 0.8799, Val Loss: 1.6781, F1 Micro: 0.5208, F1 Macro: 0.5259, Accuracy: 0.5208\n","Epoch 147, Train Loss: 0.9439, Val Loss: 1.6900, F1 Micro: 0.5104, F1 Macro: 0.5116, Accuracy: 0.5104\n","Epoch 148, Train Loss: 0.8299, Val Loss: 1.6532, F1 Micro: 0.5208, F1 Macro: 0.5129, Accuracy: 0.5208\n","Epoch 149, Train Loss: 0.8793, Val Loss: 1.6855, F1 Micro: 0.5417, F1 Macro: 0.5402, Accuracy: 0.5417\n","Epoch 150, Train Loss: 0.8824, Val Loss: 1.8419, F1 Micro: 0.4896, F1 Macro: 0.4825, Accuracy: 0.4896\n","Epoch 151, Train Loss: 0.8816, Val Loss: 1.7309, F1 Micro: 0.5000, F1 Macro: 0.4909, Accuracy: 0.5000\n","Epoch 152, Train Loss: 0.8441, Val Loss: 1.6895, F1 Micro: 0.5521, F1 Macro: 0.5450, Accuracy: 0.5521\n","Epoch 153, Train Loss: 0.8598, Val Loss: 1.7740, F1 Micro: 0.5208, F1 Macro: 0.5239, Accuracy: 0.5208\n","Epoch 154, Train Loss: 0.9021, Val Loss: 1.9334, F1 Micro: 0.5000, F1 Macro: 0.4863, Accuracy: 0.5000\n","Epoch 155, Train Loss: 0.8922, Val Loss: 1.7971, F1 Micro: 0.5000, F1 Macro: 0.4930, Accuracy: 0.5000\n","Epoch 156, Train Loss: 0.8757, Val Loss: 1.7465, F1 Micro: 0.5104, F1 Macro: 0.5044, Accuracy: 0.5104\n","Epoch 157, Train Loss: 0.7914, Val Loss: 1.7532, F1 Micro: 0.4688, F1 Macro: 0.4644, Accuracy: 0.4688\n","Epoch 158, Train Loss: 0.8207, Val Loss: 1.9273, F1 Micro: 0.4792, F1 Macro: 0.4631, Accuracy: 0.4792\n","Epoch 159, Train Loss: 0.8668, Val Loss: 1.8309, F1 Micro: 0.4896, F1 Macro: 0.4850, Accuracy: 0.4896\n","Epoch 160, Train Loss: 0.8273, Val Loss: 1.9891, F1 Micro: 0.4792, F1 Macro: 0.4682, Accuracy: 0.4792\n","Epoch 161, Train Loss: 0.8340, Val Loss: 1.7195, F1 Micro: 0.5521, F1 Macro: 0.5519, Accuracy: 0.5521\n","Epoch 162, Train Loss: 0.7473, Val Loss: 1.8931, F1 Micro: 0.5312, F1 Macro: 0.5274, Accuracy: 0.5312\n","Epoch 163, Train Loss: 0.8030, Val Loss: 1.9124, F1 Micro: 0.4688, F1 Macro: 0.4655, Accuracy: 0.4688\n","Epoch 164, Train Loss: 0.8327, Val Loss: 1.9897, F1 Micro: 0.4375, F1 Macro: 0.4326, Accuracy: 0.4375\n","Epoch 165, Train Loss: 0.8646, Val Loss: 1.7464, F1 Micro: 0.5312, F1 Macro: 0.5306, Accuracy: 0.5312\n","Epoch 166, Train Loss: 0.7942, Val Loss: 2.0431, F1 Micro: 0.5208, F1 Macro: 0.5255, Accuracy: 0.5208\n","Epoch 167, Train Loss: 0.8135, Val Loss: 1.9206, F1 Micro: 0.4896, F1 Macro: 0.4816, Accuracy: 0.4896\n","Epoch 168, Train Loss: 0.7477, Val Loss: 2.1196, F1 Micro: 0.4792, F1 Macro: 0.4608, Accuracy: 0.4792\n","Epoch 169, Train Loss: 0.8355, Val Loss: 1.8026, F1 Micro: 0.5521, F1 Macro: 0.5480, Accuracy: 0.5521\n","Epoch 170, Train Loss: 0.7593, Val Loss: 1.8417, F1 Micro: 0.4792, F1 Macro: 0.4703, Accuracy: 0.4792\n","Epoch 171, Train Loss: 0.7555, Val Loss: 1.7158, F1 Micro: 0.5312, F1 Macro: 0.5266, Accuracy: 0.5312\n","Epoch 172, Train Loss: 0.7748, Val Loss: 1.9032, F1 Micro: 0.4792, F1 Macro: 0.4760, Accuracy: 0.4792\n","Epoch 173, Train Loss: 0.7858, Val Loss: 1.8992, F1 Micro: 0.4688, F1 Macro: 0.4574, Accuracy: 0.4688\n","Epoch 174, Train Loss: 0.7436, Val Loss: 1.8162, F1 Micro: 0.5000, F1 Macro: 0.4977, Accuracy: 0.5000\n","Epoch 175, Train Loss: 0.7164, Val Loss: 1.8623, F1 Micro: 0.5104, F1 Macro: 0.5108, Accuracy: 0.5104\n","Epoch 176, Train Loss: 0.7475, Val Loss: 1.9094, F1 Micro: 0.5000, F1 Macro: 0.4933, Accuracy: 0.5000\n","Epoch 177, Train Loss: 0.7431, Val Loss: 1.7931, F1 Micro: 0.5625, F1 Macro: 0.5642, Accuracy: 0.5625\n","Epoch 178, Train Loss: 0.7341, Val Loss: 1.8544, F1 Micro: 0.5208, F1 Macro: 0.5075, Accuracy: 0.5208\n","Epoch 179, Train Loss: 0.7767, Val Loss: 1.8497, F1 Micro: 0.5000, F1 Macro: 0.4985, Accuracy: 0.5000\n","Epoch 180, Train Loss: 0.7505, Val Loss: 1.8108, F1 Micro: 0.5521, F1 Macro: 0.5513, Accuracy: 0.5521\n","Epoch 181, Train Loss: 0.6718, Val Loss: 2.0814, F1 Micro: 0.5208, F1 Macro: 0.5197, Accuracy: 0.5208\n","Epoch 182, Train Loss: 0.8182, Val Loss: 1.7737, F1 Micro: 0.5521, F1 Macro: 0.5454, Accuracy: 0.5521\n","Epoch 183, Train Loss: 0.7497, Val Loss: 1.9716, F1 Micro: 0.4688, F1 Macro: 0.4441, Accuracy: 0.4688\n","Epoch 184, Train Loss: 0.6530, Val Loss: 1.8394, F1 Micro: 0.5625, F1 Macro: 0.5630, Accuracy: 0.5625\n","Epoch 185, Train Loss: 0.7527, Val Loss: 1.8946, F1 Micro: 0.5521, F1 Macro: 0.5502, Accuracy: 0.5521\n","Epoch 186, Train Loss: 0.7387, Val Loss: 2.0610, F1 Micro: 0.4896, F1 Macro: 0.4760, Accuracy: 0.4896\n","Epoch 187, Train Loss: 0.7059, Val Loss: 1.8338, F1 Micro: 0.5729, F1 Macro: 0.5664, Accuracy: 0.5729\n","Epoch 188, Train Loss: 0.6681, Val Loss: 1.9040, F1 Micro: 0.5312, F1 Macro: 0.5220, Accuracy: 0.5312\n","Epoch 189, Train Loss: 0.6886, Val Loss: 1.9984, F1 Micro: 0.4896, F1 Macro: 0.4771, Accuracy: 0.4896\n","Epoch 190, Train Loss: 0.7636, Val Loss: 1.8016, F1 Micro: 0.5104, F1 Macro: 0.5143, Accuracy: 0.5104\n","Epoch 191, Train Loss: 0.6639, Val Loss: 1.9307, F1 Micro: 0.4896, F1 Macro: 0.4762, Accuracy: 0.4896\n","Epoch 192, Train Loss: 0.7503, Val Loss: 1.9632, F1 Micro: 0.5208, F1 Macro: 0.5112, Accuracy: 0.5208\n","Epoch 193, Train Loss: 0.7036, Val Loss: 1.9032, F1 Micro: 0.5625, F1 Macro: 0.5633, Accuracy: 0.5625\n","Epoch 194, Train Loss: 0.7206, Val Loss: 1.8407, F1 Micro: 0.5521, F1 Macro: 0.5476, Accuracy: 0.5521\n","Epoch 195, Train Loss: 0.6580, Val Loss: 2.0363, F1 Micro: 0.5000, F1 Macro: 0.4921, Accuracy: 0.5000\n","Epoch 196, Train Loss: 0.6698, Val Loss: 1.8731, F1 Micro: 0.5625, F1 Macro: 0.5684, Accuracy: 0.5625\n","Epoch 197, Train Loss: 0.6628, Val Loss: 1.9418, F1 Micro: 0.5729, F1 Macro: 0.5571, Accuracy: 0.5729\n","Epoch 198, Train Loss: 0.6376, Val Loss: 2.0117, F1 Micro: 0.5312, F1 Macro: 0.5327, Accuracy: 0.5312\n","Epoch 199, Train Loss: 0.6476, Val Loss: 1.8584, F1 Micro: 0.5625, F1 Macro: 0.5648, Accuracy: 0.5625\n","Epoch 200, Train Loss: 0.6631, Val Loss: 1.8922, F1 Micro: 0.5208, F1 Macro: 0.5259, Accuracy: 0.5208\n","Average Score for hyperparameters (0.001, 8, 50): 0.5625\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.4711, Val Loss: 1.9599, F1 Micro: 0.2292, F1 Macro: 0.1145, Accuracy: 0.2292\n","Epoch 2, Train Loss: 2.1750, Val Loss: 1.7583, F1 Micro: 0.2500, F1 Macro: 0.1819, Accuracy: 0.2500\n","Epoch 3, Train Loss: 2.1059, Val Loss: 1.8372, F1 Micro: 0.3125, F1 Macro: 0.2559, Accuracy: 0.3125\n","Epoch 4, Train Loss: 2.0331, Val Loss: 1.8332, F1 Micro: 0.2396, F1 Macro: 0.1605, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.9409, Val Loss: 1.9180, F1 Micro: 0.2708, F1 Macro: 0.1723, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.9439, Val Loss: 1.8472, F1 Micro: 0.3229, F1 Macro: 0.2487, Accuracy: 0.3229\n","Epoch 7, Train Loss: 1.9480, Val Loss: 1.8216, F1 Micro: 0.2708, F1 Macro: 0.2291, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.8472, Val Loss: 1.6559, F1 Micro: 0.3333, F1 Macro: 0.2672, Accuracy: 0.3333\n","Epoch 9, Train Loss: 1.8101, Val Loss: 1.6681, F1 Micro: 0.3229, F1 Macro: 0.2580, Accuracy: 0.3229\n","Epoch 10, Train Loss: 1.7268, Val Loss: 1.7639, F1 Micro: 0.2500, F1 Macro: 0.1967, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.7866, Val Loss: 1.7766, F1 Micro: 0.2396, F1 Macro: 0.1880, Accuracy: 0.2396\n","Epoch 12, Train Loss: 1.7564, Val Loss: 1.6502, F1 Micro: 0.3229, F1 Macro: 0.2510, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.7454, Val Loss: 1.7430, F1 Micro: 0.2812, F1 Macro: 0.2242, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.7267, Val Loss: 1.6742, F1 Micro: 0.3125, F1 Macro: 0.2576, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.7273, Val Loss: 1.7320, F1 Micro: 0.3021, F1 Macro: 0.2442, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.6865, Val Loss: 1.6844, F1 Micro: 0.3333, F1 Macro: 0.2466, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.7596, Val Loss: 1.6673, F1 Micro: 0.3125, F1 Macro: 0.2046, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.7010, Val Loss: 1.6923, F1 Micro: 0.2396, F1 Macro: 0.1853, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.2521, Val Loss: 2.4202, F1 Micro: 0.2396, F1 Macro: 0.1542, Accuracy: 0.2396\n","Epoch 2, Train Loss: 2.2117, Val Loss: 2.1364, F1 Micro: 0.1667, F1 Macro: 0.1041, Accuracy: 0.1667\n","Epoch 3, Train Loss: 2.2194, Val Loss: 2.0346, F1 Micro: 0.1458, F1 Macro: 0.0755, Accuracy: 0.1458\n","Epoch 4, Train Loss: 2.1912, Val Loss: 1.9279, F1 Micro: 0.2188, F1 Macro: 0.1443, Accuracy: 0.2188\n","Epoch 5, Train Loss: 2.0309, Val Loss: 1.9305, F1 Micro: 0.1458, F1 Macro: 0.0755, Accuracy: 0.1458\n","Epoch 6, Train Loss: 1.9879, Val Loss: 1.8343, F1 Micro: 0.2812, F1 Macro: 0.1885, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.9090, Val Loss: 1.8911, F1 Micro: 0.2292, F1 Macro: 0.1584, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.8259, Val Loss: 1.8178, F1 Micro: 0.1771, F1 Macro: 0.1455, Accuracy: 0.1771\n","Epoch 9, Train Loss: 1.7999, Val Loss: 1.6929, F1 Micro: 0.3021, F1 Macro: 0.2208, Accuracy: 0.3021\n","Epoch 10, Train Loss: 1.7990, Val Loss: 1.8137, F1 Micro: 0.1875, F1 Macro: 0.1632, Accuracy: 0.1875\n","Epoch 11, Train Loss: 1.7962, Val Loss: 1.7905, F1 Micro: 0.2708, F1 Macro: 0.2293, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.7626, Val Loss: 1.7139, F1 Micro: 0.3125, F1 Macro: 0.2218, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.7677, Val Loss: 1.6938, F1 Micro: 0.3021, F1 Macro: 0.2582, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.7334, Val Loss: 1.7629, F1 Micro: 0.2396, F1 Macro: 0.1734, Accuracy: 0.2396\n","Epoch 15, Train Loss: 1.7622, Val Loss: 1.8471, F1 Micro: 0.2708, F1 Macro: 0.2516, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.6929, Val Loss: 1.8659, F1 Micro: 0.1979, F1 Macro: 0.1699, Accuracy: 0.1979\n","Epoch 17, Train Loss: 1.7035, Val Loss: 1.7290, F1 Micro: 0.2917, F1 Macro: 0.2298, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.6998, Val Loss: 1.8374, F1 Micro: 0.1562, F1 Macro: 0.0933, Accuracy: 0.1562\n","Epoch 19, Train Loss: 1.7362, Val Loss: 1.8521, F1 Micro: 0.2812, F1 Macro: 0.2175, Accuracy: 0.2812\n","Epoch 20, Train Loss: 1.7274, Val Loss: 1.7155, F1 Micro: 0.2188, F1 Macro: 0.2017, Accuracy: 0.2188\n","Epoch 21, Train Loss: 1.6975, Val Loss: 1.7345, F1 Micro: 0.2500, F1 Macro: 0.2339, Accuracy: 0.2500\n","Epoch 22, Train Loss: 1.6691, Val Loss: 1.7337, F1 Micro: 0.2604, F1 Macro: 0.2120, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.5457, Val Loss: 2.5435, F1 Micro: 0.2812, F1 Macro: 0.1663, Accuracy: 0.2812\n","Epoch 2, Train Loss: 2.3136, Val Loss: 1.9989, F1 Micro: 0.2812, F1 Macro: 0.1928, Accuracy: 0.2812\n","Epoch 3, Train Loss: 2.0331, Val Loss: 1.9885, F1 Micro: 0.2083, F1 Macro: 0.1401, Accuracy: 0.2083\n","Epoch 4, Train Loss: 2.1613, Val Loss: 2.3010, F1 Micro: 0.1354, F1 Macro: 0.1006, Accuracy: 0.1354\n","Epoch 5, Train Loss: 2.1513, Val Loss: 1.7896, F1 Micro: 0.2812, F1 Macro: 0.1792, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.8975, Val Loss: 1.9377, F1 Micro: 0.2083, F1 Macro: 0.1721, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.8909, Val Loss: 1.8294, F1 Micro: 0.2188, F1 Macro: 0.1734, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.7750, Val Loss: 1.7623, F1 Micro: 0.2292, F1 Macro: 0.1720, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.7934, Val Loss: 1.9464, F1 Micro: 0.2396, F1 Macro: 0.2027, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.7455, Val Loss: 1.8298, F1 Micro: 0.2188, F1 Macro: 0.1779, Accuracy: 0.2188\n","Epoch 11, Train Loss: 1.7321, Val Loss: 1.8018, F1 Micro: 0.2396, F1 Macro: 0.2068, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.0937, Val Loss: 2.9784, F1 Micro: 0.1979, F1 Macro: 0.0847, Accuracy: 0.1979\n","Epoch 2, Train Loss: 2.4084, Val Loss: 2.4782, F1 Micro: 0.2083, F1 Macro: 0.1430, Accuracy: 0.2083\n","Epoch 3, Train Loss: 2.1366, Val Loss: 2.1003, F1 Micro: 0.1979, F1 Macro: 0.0843, Accuracy: 0.1979\n","Epoch 4, Train Loss: 1.9903, Val Loss: 2.2374, F1 Micro: 0.2083, F1 Macro: 0.1368, Accuracy: 0.2083\n","Epoch 5, Train Loss: 2.0073, Val Loss: 1.8797, F1 Micro: 0.2188, F1 Macro: 0.1530, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.8296, Val Loss: 2.0141, F1 Micro: 0.2500, F1 Macro: 0.1560, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.9502, Val Loss: 2.0618, F1 Micro: 0.2292, F1 Macro: 0.1482, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.8936, Val Loss: 1.9853, F1 Micro: 0.2083, F1 Macro: 0.1179, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.7810, Val Loss: 1.9541, F1 Micro: 0.2396, F1 Macro: 0.1501, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.8092, Val Loss: 1.9276, F1 Micro: 0.1979, F1 Macro: 0.1306, Accuracy: 0.1979\n","Epoch 11, Train Loss: 1.7896, Val Loss: 1.8040, F1 Micro: 0.2188, F1 Macro: 0.1643, Accuracy: 0.2188\n","Epoch 12, Train Loss: 1.7407, Val Loss: 1.8227, F1 Micro: 0.2708, F1 Macro: 0.1713, Accuracy: 0.2708\n","Epoch 13, Train Loss: 1.7480, Val Loss: 1.8576, F1 Micro: 0.2292, F1 Macro: 0.1414, Accuracy: 0.2292\n","Epoch 14, Train Loss: 1.7114, Val Loss: 1.7801, F1 Micro: 0.2188, F1 Macro: 0.1928, Accuracy: 0.2188\n","Epoch 15, Train Loss: 1.6826, Val Loss: 1.7711, F1 Micro: 0.2708, F1 Macro: 0.2507, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.6715, Val Loss: 1.8659, F1 Micro: 0.2604, F1 Macro: 0.1715, Accuracy: 0.2604\n","Epoch 17, Train Loss: 1.6805, Val Loss: 1.7792, F1 Micro: 0.1979, F1 Macro: 0.1725, Accuracy: 0.1979\n","Epoch 18, Train Loss: 1.6748, Val Loss: 1.8336, F1 Micro: 0.2500, F1 Macro: 0.1532, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.6855, Val Loss: 1.7616, F1 Micro: 0.2917, F1 Macro: 0.2292, Accuracy: 0.2917\n","Epoch 20, Train Loss: 1.6823, Val Loss: 1.7906, F1 Micro: 0.2708, F1 Macro: 0.2052, Accuracy: 0.2708\n","Epoch 21, Train Loss: 1.6816, Val Loss: 1.8016, F1 Micro: 0.2500, F1 Macro: 0.1673, Accuracy: 0.2500\n","Epoch 22, Train Loss: 1.6431, Val Loss: 1.7767, F1 Micro: 0.1979, F1 Macro: 0.1619, Accuracy: 0.1979\n","Epoch 23, Train Loss: 1.6642, Val Loss: 1.8063, F1 Micro: 0.2083, F1 Macro: 0.1686, Accuracy: 0.2083\n","Epoch 24, Train Loss: 1.6416, Val Loss: 1.8348, F1 Micro: 0.1979, F1 Macro: 0.1405, Accuracy: 0.1979\n","Epoch 25, Train Loss: 1.6723, Val Loss: 1.7473, F1 Micro: 0.3021, F1 Macro: 0.2207, Accuracy: 0.3021\n","Epoch 26, Train Loss: 1.6642, Val Loss: 1.7677, F1 Micro: 0.2604, F1 Macro: 0.1873, Accuracy: 0.2604\n","Epoch 27, Train Loss: 1.6840, Val Loss: 1.8811, F1 Micro: 0.2812, F1 Macro: 0.1682, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.6568, Val Loss: 1.8506, F1 Micro: 0.2292, F1 Macro: 0.1636, Accuracy: 0.2292\n","Epoch 29, Train Loss: 1.6402, Val Loss: 1.8319, F1 Micro: 0.2083, F1 Macro: 0.1297, Accuracy: 0.2083\n","Epoch 30, Train Loss: 1.5972, Val Loss: 1.7814, F1 Micro: 0.3021, F1 Macro: 0.2472, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.6248, Val Loss: 1.7946, F1 Micro: 0.2812, F1 Macro: 0.1796, Accuracy: 0.2812\n","Epoch 32, Train Loss: 1.6095, Val Loss: 1.7767, F1 Micro: 0.2708, F1 Macro: 0.2001, Accuracy: 0.2708\n","Epoch 33, Train Loss: 1.6382, Val Loss: 1.7796, F1 Micro: 0.3229, F1 Macro: 0.2470, Accuracy: 0.3229\n","Epoch 34, Train Loss: 1.5796, Val Loss: 1.8759, F1 Micro: 0.2188, F1 Macro: 0.1800, Accuracy: 0.2188\n","Epoch 35, Train Loss: 1.6111, Val Loss: 1.7843, F1 Micro: 0.2708, F1 Macro: 0.2041, Accuracy: 0.2708\n","Epoch 36, Train Loss: 1.5814, Val Loss: 1.7536, F1 Micro: 0.2292, F1 Macro: 0.1913, Accuracy: 0.2292\n","Epoch 37, Train Loss: 1.5791, Val Loss: 1.7696, F1 Micro: 0.2500, F1 Macro: 0.2074, Accuracy: 0.2500\n","Epoch 38, Train Loss: 1.6093, Val Loss: 1.7597, F1 Micro: 0.3021, F1 Macro: 0.2297, Accuracy: 0.3021\n","Epoch 39, Train Loss: 1.5633, Val Loss: 1.7499, F1 Micro: 0.2396, F1 Macro: 0.1897, Accuracy: 0.2396\n","Epoch 40, Train Loss: 1.5757, Val Loss: 1.7584, F1 Micro: 0.3333, F1 Macro: 0.2705, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.5679, Val Loss: 1.7158, F1 Micro: 0.2708, F1 Macro: 0.2329, Accuracy: 0.2708\n","Epoch 42, Train Loss: 1.5425, Val Loss: 1.7829, F1 Micro: 0.2917, F1 Macro: 0.2500, Accuracy: 0.2917\n","Epoch 43, Train Loss: 1.5584, Val Loss: 1.7551, F1 Micro: 0.2604, F1 Macro: 0.2609, Accuracy: 0.2604\n","Epoch 44, Train Loss: 1.5194, Val Loss: 1.7365, F1 Micro: 0.3333, F1 Macro: 0.2955, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.5856, Val Loss: 1.8672, F1 Micro: 0.2396, F1 Macro: 0.1721, Accuracy: 0.2396\n","Epoch 46, Train Loss: 1.5564, Val Loss: 1.7301, F1 Micro: 0.3021, F1 Macro: 0.2764, Accuracy: 0.3021\n","Epoch 47, Train Loss: 1.5293, Val Loss: 1.7800, F1 Micro: 0.3021, F1 Macro: 0.2850, Accuracy: 0.3021\n","Epoch 48, Train Loss: 1.5042, Val Loss: 1.7916, F1 Micro: 0.2708, F1 Macro: 0.2590, Accuracy: 0.2708\n","Epoch 49, Train Loss: 1.5272, Val Loss: 1.7022, F1 Micro: 0.3646, F1 Macro: 0.3155, Accuracy: 0.3646\n","Epoch 50, Train Loss: 1.5121, Val Loss: 1.7222, F1 Micro: 0.2500, F1 Macro: 0.2199, Accuracy: 0.2500\n","Epoch 51, Train Loss: 1.5417, Val Loss: 1.6920, F1 Micro: 0.2917, F1 Macro: 0.2614, Accuracy: 0.2917\n","Epoch 52, Train Loss: 1.4491, Val Loss: 1.7302, F1 Micro: 0.3333, F1 Macro: 0.3090, Accuracy: 0.3333\n","Epoch 53, Train Loss: 1.5097, Val Loss: 1.7911, F1 Micro: 0.2708, F1 Macro: 0.2455, Accuracy: 0.2708\n","Epoch 54, Train Loss: 1.5001, Val Loss: 1.6639, F1 Micro: 0.3542, F1 Macro: 0.3451, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.4726, Val Loss: 1.8386, F1 Micro: 0.2188, F1 Macro: 0.1845, Accuracy: 0.2188\n","Epoch 56, Train Loss: 1.4985, Val Loss: 1.7118, F1 Micro: 0.3021, F1 Macro: 0.2853, Accuracy: 0.3021\n","Epoch 57, Train Loss: 1.5026, Val Loss: 1.7128, F1 Micro: 0.3125, F1 Macro: 0.3009, Accuracy: 0.3125\n","Epoch 58, Train Loss: 1.4884, Val Loss: 1.7740, F1 Micro: 0.2500, F1 Macro: 0.2241, Accuracy: 0.2500\n","Epoch 59, Train Loss: 1.4445, Val Loss: 1.7234, F1 Micro: 0.2812, F1 Macro: 0.2641, Accuracy: 0.2812\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.4613, Val Loss: 2.0693, F1 Micro: 0.2812, F1 Macro: 0.2083, Accuracy: 0.2812\n","Epoch 2, Train Loss: 2.6143, Val Loss: 2.1290, F1 Micro: 0.2292, F1 Macro: 0.1353, Accuracy: 0.2292\n","Epoch 3, Train Loss: 2.2330, Val Loss: 2.4964, F1 Micro: 0.1979, F1 Macro: 0.1062, Accuracy: 0.1979\n","Epoch 4, Train Loss: 2.1702, Val Loss: 1.7654, F1 Micro: 0.2812, F1 Macro: 0.2189, Accuracy: 0.2812\n","Epoch 5, Train Loss: 2.0867, Val Loss: 1.8897, F1 Micro: 0.2708, F1 Macro: 0.2313, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.9244, Val Loss: 1.7128, F1 Micro: 0.2292, F1 Macro: 0.1763, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.9171, Val Loss: 1.7641, F1 Micro: 0.2708, F1 Macro: 0.2040, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.8098, Val Loss: 1.6991, F1 Micro: 0.3125, F1 Macro: 0.2496, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.8159, Val Loss: 1.7115, F1 Micro: 0.2708, F1 Macro: 0.1987, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.7279, Val Loss: 1.6452, F1 Micro: 0.3125, F1 Macro: 0.2353, Accuracy: 0.3125\n","Epoch 11, Train Loss: 1.7964, Val Loss: 1.6422, F1 Micro: 0.3125, F1 Macro: 0.2387, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.7788, Val Loss: 1.6794, F1 Micro: 0.3542, F1 Macro: 0.3191, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.7480, Val Loss: 1.6537, F1 Micro: 0.3438, F1 Macro: 0.2736, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.7546, Val Loss: 1.8275, F1 Micro: 0.3229, F1 Macro: 0.2581, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.7426, Val Loss: 1.6261, F1 Micro: 0.3750, F1 Macro: 0.3423, Accuracy: 0.3750\n","Epoch 16, Train Loss: 1.7163, Val Loss: 1.6841, F1 Micro: 0.2500, F1 Macro: 0.1841, Accuracy: 0.2500\n","Epoch 17, Train Loss: 1.6991, Val Loss: 1.6791, F1 Micro: 0.3438, F1 Macro: 0.2756, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.6859, Val Loss: 1.6269, F1 Micro: 0.3229, F1 Macro: 0.2989, Accuracy: 0.3229\n","Epoch 19, Train Loss: 1.7464, Val Loss: 1.6383, F1 Micro: 0.3021, F1 Macro: 0.2482, Accuracy: 0.3021\n","Epoch 20, Train Loss: 1.7518, Val Loss: 1.7399, F1 Micro: 0.3646, F1 Macro: 0.3430, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.6790, Val Loss: 1.7787, F1 Micro: 0.2396, F1 Macro: 0.1591, Accuracy: 0.2396\n","Epoch 22, Train Loss: 1.6859, Val Loss: 1.6464, F1 Micro: 0.3646, F1 Macro: 0.3219, Accuracy: 0.3646\n","Epoch 23, Train Loss: 1.6526, Val Loss: 1.6667, F1 Micro: 0.3542, F1 Macro: 0.2866, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.6857, Val Loss: 1.6326, F1 Micro: 0.3542, F1 Macro: 0.3135, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.6654, Val Loss: 1.6598, F1 Micro: 0.3438, F1 Macro: 0.3354, Accuracy: 0.3438\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.3333333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.8668, Val Loss: 1.9949, F1 Micro: 0.3125, F1 Macro: 0.2288, Accuracy: 0.3125\n","Epoch 2, Train Loss: 2.4296, Val Loss: 2.2382, F1 Micro: 0.2604, F1 Macro: 0.1888, Accuracy: 0.2604\n","Epoch 3, Train Loss: 2.3662, Val Loss: 1.8593, F1 Micro: 0.2708, F1 Macro: 0.2039, Accuracy: 0.2708\n","Epoch 4, Train Loss: 2.0569, Val Loss: 1.8023, F1 Micro: 0.3021, F1 Macro: 0.2149, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.8703, Val Loss: 1.9153, F1 Micro: 0.2708, F1 Macro: 0.1720, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.9138, Val Loss: 1.8047, F1 Micro: 0.2708, F1 Macro: 0.1939, Accuracy: 0.2708\n","Epoch 7, Train Loss: 1.8807, Val Loss: 1.8814, F1 Micro: 0.2292, F1 Macro: 0.1722, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.9423, Val Loss: 1.7170, F1 Micro: 0.2812, F1 Macro: 0.2329, Accuracy: 0.2812\n","Epoch 9, Train Loss: 1.8263, Val Loss: 1.6547, F1 Micro: 0.2917, F1 Macro: 0.2010, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.7855, Val Loss: 1.7491, F1 Micro: 0.3125, F1 Macro: 0.2141, Accuracy: 0.3125\n","Epoch 11, Train Loss: 1.7703, Val Loss: 1.7779, F1 Micro: 0.2083, F1 Macro: 0.1619, Accuracy: 0.2083\n","Epoch 12, Train Loss: 1.7820, Val Loss: 1.7857, F1 Micro: 0.2917, F1 Macro: 0.2331, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.7597, Val Loss: 1.6822, F1 Micro: 0.3333, F1 Macro: 0.2562, Accuracy: 0.3333\n","Epoch 14, Train Loss: 1.7125, Val Loss: 1.6689, F1 Micro: 0.3125, F1 Macro: 0.2571, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.7329, Val Loss: 1.8055, F1 Micro: 0.2292, F1 Macro: 0.1174, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.6973, Val Loss: 1.7625, F1 Micro: 0.2604, F1 Macro: 0.2316, Accuracy: 0.2604\n","Epoch 17, Train Loss: 1.7516, Val Loss: 1.7559, F1 Micro: 0.2292, F1 Macro: 0.1937, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.7496, Val Loss: 1.7680, F1 Micro: 0.2188, F1 Macro: 0.1850, Accuracy: 0.2188\n","Epoch 19, Train Loss: 1.7094, Val Loss: 1.7031, F1 Micro: 0.2708, F1 Macro: 0.2302, Accuracy: 0.2708\n","Epoch 20, Train Loss: 1.6728, Val Loss: 1.6918, F1 Micro: 0.3333, F1 Macro: 0.2721, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.7113, Val Loss: 1.6904, F1 Micro: 0.3229, F1 Macro: 0.2462, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.6703, Val Loss: 1.7277, F1 Micro: 0.2708, F1 Macro: 0.2471, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.6595, Val Loss: 1.7332, F1 Micro: 0.2396, F1 Macro: 0.1992, Accuracy: 0.2396\n","Epoch 24, Train Loss: 1.6982, Val Loss: 1.7775, F1 Micro: 0.2500, F1 Macro: 0.2066, Accuracy: 0.2500\n","Epoch 25, Train Loss: 1.6745, Val Loss: 1.6753, F1 Micro: 0.3125, F1 Macro: 0.2116, Accuracy: 0.3125\n","Epoch 26, Train Loss: 1.7405, Val Loss: 1.6844, F1 Micro: 0.3125, F1 Macro: 0.2943, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.6953, Val Loss: 1.7724, F1 Micro: 0.3021, F1 Macro: 0.2524, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.6532, Val Loss: 1.7289, F1 Micro: 0.2917, F1 Macro: 0.2162, Accuracy: 0.2917\n","Epoch 29, Train Loss: 1.6779, Val Loss: 1.7659, F1 Micro: 0.2708, F1 Macro: 0.1941, Accuracy: 0.2708\n","Epoch 30, Train Loss: 1.6919, Val Loss: 1.6427, F1 Micro: 0.2708, F1 Macro: 0.2109, Accuracy: 0.2708\n","Epoch 31, Train Loss: 1.6535, Val Loss: 1.7480, F1 Micro: 0.2604, F1 Macro: 0.2288, Accuracy: 0.2604\n","Epoch 32, Train Loss: 1.6270, Val Loss: 1.6754, F1 Micro: 0.3229, F1 Macro: 0.2878, Accuracy: 0.3229\n","Epoch 33, Train Loss: 1.6245, Val Loss: 1.6636, F1 Micro: 0.3542, F1 Macro: 0.3237, Accuracy: 0.3542\n","Epoch 34, Train Loss: 1.6089, Val Loss: 1.7499, F1 Micro: 0.2708, F1 Macro: 0.2301, Accuracy: 0.2708\n","Epoch 35, Train Loss: 1.6685, Val Loss: 1.7749, F1 Micro: 0.2812, F1 Macro: 0.2148, Accuracy: 0.2812\n","Epoch 36, Train Loss: 1.6260, Val Loss: 1.6509, F1 Micro: 0.3438, F1 Macro: 0.3333, Accuracy: 0.3438\n","Epoch 37, Train Loss: 1.6575, Val Loss: 1.6864, F1 Micro: 0.3750, F1 Macro: 0.3716, Accuracy: 0.3750\n","Epoch 38, Train Loss: 1.5793, Val Loss: 1.7114, F1 Micro: 0.3333, F1 Macro: 0.2771, Accuracy: 0.3333\n","Epoch 39, Train Loss: 1.6029, Val Loss: 1.7602, F1 Micro: 0.2917, F1 Macro: 0.2707, Accuracy: 0.2917\n","Epoch 40, Train Loss: 1.6308, Val Loss: 1.6468, F1 Micro: 0.3333, F1 Macro: 0.2731, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.6485, Val Loss: 1.7025, F1 Micro: 0.2812, F1 Macro: 0.2538, Accuracy: 0.2812\n","Epoch 42, Train Loss: 1.5647, Val Loss: 1.6901, F1 Micro: 0.3021, F1 Macro: 0.2936, Accuracy: 0.3021\n","Epoch 43, Train Loss: 1.5690, Val Loss: 1.6203, F1 Micro: 0.3542, F1 Macro: 0.3353, Accuracy: 0.3542\n","Epoch 44, Train Loss: 1.6022, Val Loss: 1.7011, F1 Micro: 0.2708, F1 Macro: 0.2208, Accuracy: 0.2708\n","Epoch 45, Train Loss: 1.5752, Val Loss: 1.7137, F1 Micro: 0.3125, F1 Macro: 0.3190, Accuracy: 0.3125\n","Epoch 46, Train Loss: 1.5824, Val Loss: 1.6217, F1 Micro: 0.3854, F1 Macro: 0.3834, Accuracy: 0.3854\n","Epoch 47, Train Loss: 1.5439, Val Loss: 1.7029, F1 Micro: 0.3229, F1 Macro: 0.2932, Accuracy: 0.3229\n","Epoch 48, Train Loss: 1.5879, Val Loss: 1.6111, F1 Micro: 0.3646, F1 Macro: 0.3343, Accuracy: 0.3646\n","Epoch 49, Train Loss: 1.5825, Val Loss: 1.7306, F1 Micro: 0.3646, F1 Macro: 0.3073, Accuracy: 0.3646\n","Epoch 50, Train Loss: 1.5746, Val Loss: 1.6120, F1 Micro: 0.3229, F1 Macro: 0.3199, Accuracy: 0.3229\n","Epoch 51, Train Loss: 1.5549, Val Loss: 1.6350, F1 Micro: 0.4062, F1 Macro: 0.4025, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.5489, Val Loss: 1.6294, F1 Micro: 0.3542, F1 Macro: 0.3320, Accuracy: 0.3542\n","Epoch 53, Train Loss: 1.5113, Val Loss: 1.7443, F1 Micro: 0.2917, F1 Macro: 0.2423, Accuracy: 0.2917\n","Epoch 54, Train Loss: 1.5672, Val Loss: 1.7065, F1 Micro: 0.3125, F1 Macro: 0.2559, Accuracy: 0.3125\n","Epoch 55, Train Loss: 1.5403, Val Loss: 1.6570, F1 Micro: 0.3542, F1 Macro: 0.3289, Accuracy: 0.3542\n","Epoch 56, Train Loss: 1.4937, Val Loss: 1.6849, F1 Micro: 0.3125, F1 Macro: 0.3023, Accuracy: 0.3125\n","Epoch 57, Train Loss: 1.5615, Val Loss: 1.7002, F1 Micro: 0.3125, F1 Macro: 0.2850, Accuracy: 0.3125\n","Epoch 58, Train Loss: 1.5102, Val Loss: 1.6531, F1 Micro: 0.3125, F1 Macro: 0.2975, Accuracy: 0.3125\n","Epoch 59, Train Loss: 1.4794, Val Loss: 1.6594, F1 Micro: 0.3854, F1 Macro: 0.3550, Accuracy: 0.3854\n","Epoch 60, Train Loss: 1.5405, Val Loss: 1.7076, F1 Micro: 0.3229, F1 Macro: 0.3246, Accuracy: 0.3229\n","Epoch 61, Train Loss: 1.5313, Val Loss: 1.7076, F1 Micro: 0.2604, F1 Macro: 0.2180, Accuracy: 0.2604\n","Epoch 62, Train Loss: 1.4981, Val Loss: 1.6345, F1 Micro: 0.3750, F1 Macro: 0.3148, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.4882, Val Loss: 1.5952, F1 Micro: 0.3750, F1 Macro: 0.3688, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.4424, Val Loss: 1.6687, F1 Micro: 0.2917, F1 Macro: 0.2592, Accuracy: 0.2917\n","Epoch 65, Train Loss: 1.4768, Val Loss: 1.6063, F1 Micro: 0.4167, F1 Macro: 0.3736, Accuracy: 0.4167\n","Epoch 66, Train Loss: 1.4696, Val Loss: 1.6246, F1 Micro: 0.3646, F1 Macro: 0.3545, Accuracy: 0.3646\n","Epoch 67, Train Loss: 1.4555, Val Loss: 1.6622, F1 Micro: 0.3438, F1 Macro: 0.3237, Accuracy: 0.3438\n","Epoch 68, Train Loss: 1.3973, Val Loss: 1.5967, F1 Micro: 0.4375, F1 Macro: 0.4200, Accuracy: 0.4375\n","Epoch 69, Train Loss: 1.4420, Val Loss: 1.6581, F1 Micro: 0.3438, F1 Macro: 0.3283, Accuracy: 0.3438\n","Epoch 70, Train Loss: 1.4330, Val Loss: 1.5524, F1 Micro: 0.4062, F1 Macro: 0.3828, Accuracy: 0.4062\n","Epoch 71, Train Loss: 1.4466, Val Loss: 1.8475, F1 Micro: 0.3125, F1 Macro: 0.2861, Accuracy: 0.3125\n","Epoch 72, Train Loss: 1.4745, Val Loss: 1.5780, F1 Micro: 0.4375, F1 Macro: 0.4077, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.4304, Val Loss: 1.6659, F1 Micro: 0.3021, F1 Macro: 0.2660, Accuracy: 0.3021\n","Epoch 74, Train Loss: 1.3993, Val Loss: 1.6686, F1 Micro: 0.3854, F1 Macro: 0.3817, Accuracy: 0.3854\n","Epoch 75, Train Loss: 1.3868, Val Loss: 1.6658, F1 Micro: 0.3646, F1 Macro: 0.3705, Accuracy: 0.3646\n","Epoch 76, Train Loss: 1.4041, Val Loss: 1.6729, F1 Micro: 0.3542, F1 Macro: 0.3264, Accuracy: 0.3542\n","Epoch 77, Train Loss: 1.3767, Val Loss: 1.6364, F1 Micro: 0.4167, F1 Macro: 0.4153, Accuracy: 0.4167\n","Epoch 78, Train Loss: 1.4119, Val Loss: 1.6322, F1 Micro: 0.3958, F1 Macro: 0.3774, Accuracy: 0.3958\n","Epoch 79, Train Loss: 1.3805, Val Loss: 1.6155, F1 Micro: 0.4062, F1 Macro: 0.3967, Accuracy: 0.4062\n","Epoch 80, Train Loss: 1.4138, Val Loss: 1.6748, F1 Micro: 0.2708, F1 Macro: 0.2471, Accuracy: 0.2708\n","Epoch 81, Train Loss: 1.3974, Val Loss: 1.5750, F1 Micro: 0.4062, F1 Macro: 0.3686, Accuracy: 0.4062\n","Epoch 82, Train Loss: 1.4052, Val Loss: 1.6466, F1 Micro: 0.3542, F1 Macro: 0.3250, Accuracy: 0.3542\n","Epoch 83, Train Loss: 1.4238, Val Loss: 1.6596, F1 Micro: 0.3750, F1 Macro: 0.3692, Accuracy: 0.3750\n","Epoch 84, Train Loss: 1.3853, Val Loss: 1.6131, F1 Micro: 0.4062, F1 Macro: 0.3437, Accuracy: 0.4062\n","Epoch 85, Train Loss: 1.3895, Val Loss: 1.5996, F1 Micro: 0.3438, F1 Macro: 0.3290, Accuracy: 0.3438\n","Epoch 86, Train Loss: 1.3305, Val Loss: 1.6415, F1 Micro: 0.3333, F1 Macro: 0.3232, Accuracy: 0.3333\n","Epoch 87, Train Loss: 1.3365, Val Loss: 1.5719, F1 Micro: 0.4375, F1 Macro: 0.3962, Accuracy: 0.4375\n","Epoch 88, Train Loss: 1.3639, Val Loss: 1.5809, F1 Micro: 0.4062, F1 Macro: 0.3714, Accuracy: 0.4062\n","Epoch 89, Train Loss: 1.3219, Val Loss: 1.7165, F1 Micro: 0.4167, F1 Macro: 0.4440, Accuracy: 0.4167\n","Epoch 90, Train Loss: 1.3647, Val Loss: 1.6336, F1 Micro: 0.3333, F1 Macro: 0.2942, Accuracy: 0.3333\n","Epoch 91, Train Loss: 1.2978, Val Loss: 1.6849, F1 Micro: 0.3854, F1 Macro: 0.3648, Accuracy: 0.3854\n","Epoch 92, Train Loss: 1.3513, Val Loss: 1.7129, F1 Micro: 0.3854, F1 Macro: 0.3350, Accuracy: 0.3854\n","Epoch 93, Train Loss: 1.2948, Val Loss: 1.5491, F1 Micro: 0.4479, F1 Macro: 0.4397, Accuracy: 0.4479\n","Epoch 94, Train Loss: 1.2942, Val Loss: 1.5745, F1 Micro: 0.4167, F1 Macro: 0.3981, Accuracy: 0.4167\n","Epoch 95, Train Loss: 1.3231, Val Loss: 1.6360, F1 Micro: 0.4479, F1 Macro: 0.4495, Accuracy: 0.4479\n","Epoch 96, Train Loss: 1.2834, Val Loss: 1.5468, F1 Micro: 0.3854, F1 Macro: 0.3745, Accuracy: 0.3854\n","Epoch 97, Train Loss: 1.2414, Val Loss: 1.5956, F1 Micro: 0.4271, F1 Macro: 0.4018, Accuracy: 0.4271\n","Epoch 98, Train Loss: 1.2791, Val Loss: 1.6391, F1 Micro: 0.4062, F1 Macro: 0.3811, Accuracy: 0.4062\n","Epoch 99, Train Loss: 1.3136, Val Loss: 1.5520, F1 Micro: 0.4479, F1 Macro: 0.4426, Accuracy: 0.4479\n","Epoch 100, Train Loss: 1.2883, Val Loss: 1.5555, F1 Micro: 0.5000, F1 Macro: 0.5027, Accuracy: 0.5000\n","Epoch 101, Train Loss: 1.2252, Val Loss: 1.6336, F1 Micro: 0.3750, F1 Macro: 0.3810, Accuracy: 0.3750\n","Epoch 102, Train Loss: 1.2877, Val Loss: 1.6222, F1 Micro: 0.3958, F1 Macro: 0.3754, Accuracy: 0.3958\n","Epoch 103, Train Loss: 1.2625, Val Loss: 1.7096, F1 Micro: 0.3854, F1 Macro: 0.3433, Accuracy: 0.3854\n","Epoch 104, Train Loss: 1.2760, Val Loss: 1.6048, F1 Micro: 0.4375, F1 Macro: 0.4048, Accuracy: 0.4375\n","Epoch 105, Train Loss: 1.2583, Val Loss: 1.5344, F1 Micro: 0.4792, F1 Macro: 0.4366, Accuracy: 0.4792\n","Epoch 106, Train Loss: 1.2352, Val Loss: 1.5884, F1 Micro: 0.4375, F1 Macro: 0.4296, Accuracy: 0.4375\n","Epoch 107, Train Loss: 1.2181, Val Loss: 1.5871, F1 Micro: 0.4375, F1 Macro: 0.3981, Accuracy: 0.4375\n","Epoch 108, Train Loss: 1.2513, Val Loss: 1.6163, F1 Micro: 0.4583, F1 Macro: 0.4597, Accuracy: 0.4583\n","Epoch 109, Train Loss: 1.2666, Val Loss: 1.5815, F1 Micro: 0.4375, F1 Macro: 0.4356, Accuracy: 0.4375\n","Epoch 110, Train Loss: 1.1930, Val Loss: 1.6957, F1 Micro: 0.3125, F1 Macro: 0.2955, Accuracy: 0.3125\n","Epoch 111, Train Loss: 1.1933, Val Loss: 1.7224, F1 Micro: 0.3854, F1 Macro: 0.3527, Accuracy: 0.3854\n","Epoch 112, Train Loss: 1.2000, Val Loss: 1.6015, F1 Micro: 0.4792, F1 Macro: 0.4782, Accuracy: 0.4792\n","Epoch 113, Train Loss: 1.1971, Val Loss: 1.6752, F1 Micro: 0.4167, F1 Macro: 0.3709, Accuracy: 0.4167\n","Epoch 114, Train Loss: 1.2084, Val Loss: 1.7225, F1 Micro: 0.3958, F1 Macro: 0.4038, Accuracy: 0.3958\n","Epoch 115, Train Loss: 1.2078, Val Loss: 1.5497, F1 Micro: 0.3958, F1 Macro: 0.3714, Accuracy: 0.3958\n","Epoch 116, Train Loss: 1.1745, Val Loss: 1.5671, F1 Micro: 0.4271, F1 Macro: 0.4294, Accuracy: 0.4271\n","Epoch 117, Train Loss: 1.2007, Val Loss: 1.7693, F1 Micro: 0.4062, F1 Macro: 0.3566, Accuracy: 0.4062\n","Epoch 118, Train Loss: 1.2055, Val Loss: 1.6246, F1 Micro: 0.4167, F1 Macro: 0.4141, Accuracy: 0.4167\n","Epoch 119, Train Loss: 1.1113, Val Loss: 1.5714, F1 Micro: 0.4375, F1 Macro: 0.4234, Accuracy: 0.4375\n","Epoch 120, Train Loss: 1.1890, Val Loss: 1.6851, F1 Micro: 0.4167, F1 Macro: 0.4147, Accuracy: 0.4167\n","Epoch 121, Train Loss: 1.1823, Val Loss: 1.7454, F1 Micro: 0.3125, F1 Macro: 0.2789, Accuracy: 0.3125\n","Epoch 122, Train Loss: 1.1460, Val Loss: 1.6947, F1 Micro: 0.4062, F1 Macro: 0.3655, Accuracy: 0.4062\n","Epoch 123, Train Loss: 1.1410, Val Loss: 1.8171, F1 Micro: 0.3542, F1 Macro: 0.3298, Accuracy: 0.3542\n","Epoch 124, Train Loss: 1.1658, Val Loss: 1.6971, F1 Micro: 0.4271, F1 Macro: 0.4308, Accuracy: 0.4271\n","Epoch 125, Train Loss: 1.1103, Val Loss: 1.6206, F1 Micro: 0.4375, F1 Macro: 0.4148, Accuracy: 0.4375\n","Epoch 126, Train Loss: 1.1068, Val Loss: 1.6036, F1 Micro: 0.4792, F1 Macro: 0.4857, Accuracy: 0.4792\n","Epoch 127, Train Loss: 1.1783, Val Loss: 1.7600, F1 Micro: 0.4375, F1 Macro: 0.3986, Accuracy: 0.4375\n","Epoch 128, Train Loss: 1.1241, Val Loss: 1.6988, F1 Micro: 0.3646, F1 Macro: 0.3619, Accuracy: 0.3646\n","Epoch 129, Train Loss: 1.1119, Val Loss: 1.8819, F1 Micro: 0.3542, F1 Macro: 0.3166, Accuracy: 0.3542\n","Epoch 130, Train Loss: 1.1315, Val Loss: 1.8133, F1 Micro: 0.3854, F1 Macro: 0.3268, Accuracy: 0.3854\n","Epoch 131, Train Loss: 1.1098, Val Loss: 1.6090, F1 Micro: 0.4271, F1 Macro: 0.4416, Accuracy: 0.4271\n","Epoch 132, Train Loss: 1.0666, Val Loss: 1.7274, F1 Micro: 0.4271, F1 Macro: 0.4352, Accuracy: 0.4271\n","Epoch 133, Train Loss: 1.0294, Val Loss: 1.7280, F1 Micro: 0.4479, F1 Macro: 0.4537, Accuracy: 0.4479\n","Epoch 134, Train Loss: 1.0539, Val Loss: 1.6930, F1 Micro: 0.4583, F1 Macro: 0.4604, Accuracy: 0.4583\n","Epoch 135, Train Loss: 1.0305, Val Loss: 1.7691, F1 Micro: 0.4375, F1 Macro: 0.4322, Accuracy: 0.4375\n","Epoch 136, Train Loss: 1.0542, Val Loss: 1.8205, F1 Micro: 0.3750, F1 Macro: 0.3388, Accuracy: 0.3750\n","Epoch 137, Train Loss: 1.1033, Val Loss: 1.7240, F1 Micro: 0.4375, F1 Macro: 0.4414, Accuracy: 0.4375\n","Epoch 138, Train Loss: 1.0218, Val Loss: 1.7532, F1 Micro: 0.4271, F1 Macro: 0.4258, Accuracy: 0.4271\n","Epoch 139, Train Loss: 1.0672, Val Loss: 1.7505, F1 Micro: 0.4375, F1 Macro: 0.4467, Accuracy: 0.4375\n","Epoch 140, Train Loss: 1.0149, Val Loss: 1.6571, F1 Micro: 0.4167, F1 Macro: 0.4037, Accuracy: 0.4167\n","Epoch 141, Train Loss: 1.0332, Val Loss: 1.5913, F1 Micro: 0.4896, F1 Macro: 0.4808, Accuracy: 0.4896\n","Epoch 142, Train Loss: 1.0247, Val Loss: 1.7117, F1 Micro: 0.5208, F1 Macro: 0.5148, Accuracy: 0.5208\n","Epoch 143, Train Loss: 1.0589, Val Loss: 1.8327, F1 Micro: 0.3854, F1 Macro: 0.3933, Accuracy: 0.3854\n","Epoch 144, Train Loss: 1.0645, Val Loss: 1.7115, F1 Micro: 0.4167, F1 Macro: 0.4227, Accuracy: 0.4167\n","Epoch 145, Train Loss: 1.0127, Val Loss: 1.7246, F1 Micro: 0.4375, F1 Macro: 0.4042, Accuracy: 0.4375\n","Epoch 146, Train Loss: 1.0175, Val Loss: 1.7224, F1 Micro: 0.4167, F1 Macro: 0.4169, Accuracy: 0.4167\n","Epoch 147, Train Loss: 1.0474, Val Loss: 1.8453, F1 Micro: 0.4792, F1 Macro: 0.4482, Accuracy: 0.4792\n","Epoch 148, Train Loss: 0.9960, Val Loss: 1.6601, F1 Micro: 0.5417, F1 Macro: 0.5394, Accuracy: 0.5417\n","Epoch 149, Train Loss: 0.9935, Val Loss: 1.7433, F1 Micro: 0.4375, F1 Macro: 0.4185, Accuracy: 0.4375\n","Epoch 150, Train Loss: 0.9683, Val Loss: 1.6232, F1 Micro: 0.4583, F1 Macro: 0.4432, Accuracy: 0.4583\n","Epoch 151, Train Loss: 0.9759, Val Loss: 1.8215, F1 Micro: 0.4583, F1 Macro: 0.4354, Accuracy: 0.4583\n","Epoch 152, Train Loss: 1.0381, Val Loss: 1.8132, F1 Micro: 0.4896, F1 Macro: 0.4929, Accuracy: 0.4896\n","Epoch 153, Train Loss: 1.0137, Val Loss: 1.7743, F1 Micro: 0.4479, F1 Macro: 0.4145, Accuracy: 0.4479\n","Epoch 154, Train Loss: 1.0346, Val Loss: 1.6642, F1 Micro: 0.4688, F1 Macro: 0.4637, Accuracy: 0.4688\n","Epoch 155, Train Loss: 1.0210, Val Loss: 1.7445, F1 Micro: 0.4896, F1 Macro: 0.4729, Accuracy: 0.4896\n","Epoch 156, Train Loss: 1.0121, Val Loss: 1.7576, F1 Micro: 0.4583, F1 Macro: 0.4413, Accuracy: 0.4583\n","Epoch 157, Train Loss: 0.9814, Val Loss: 1.8968, F1 Micro: 0.4167, F1 Macro: 0.4043, Accuracy: 0.4167\n","Epoch 158, Train Loss: 0.9111, Val Loss: 1.8651, F1 Micro: 0.4062, F1 Macro: 0.4074, Accuracy: 0.4062\n","Epoch 159, Train Loss: 0.9706, Val Loss: 1.6919, F1 Micro: 0.4896, F1 Macro: 0.4869, Accuracy: 0.4896\n","Epoch 160, Train Loss: 0.9986, Val Loss: 1.7200, F1 Micro: 0.5312, F1 Macro: 0.5230, Accuracy: 0.5312\n","Epoch 161, Train Loss: 1.0140, Val Loss: 1.7003, F1 Micro: 0.4375, F1 Macro: 0.4363, Accuracy: 0.4375\n","Epoch 162, Train Loss: 0.9126, Val Loss: 1.7619, F1 Micro: 0.4583, F1 Macro: 0.4583, Accuracy: 0.4583\n","Epoch 163, Train Loss: 0.8936, Val Loss: 1.8703, F1 Micro: 0.4792, F1 Macro: 0.4828, Accuracy: 0.4792\n","Epoch 164, Train Loss: 0.9026, Val Loss: 1.8288, F1 Micro: 0.4479, F1 Macro: 0.4428, Accuracy: 0.4479\n","Epoch 165, Train Loss: 0.9195, Val Loss: 1.6950, F1 Micro: 0.5104, F1 Macro: 0.4898, Accuracy: 0.5104\n","Epoch 166, Train Loss: 0.9266, Val Loss: 1.8926, F1 Micro: 0.4375, F1 Macro: 0.4381, Accuracy: 0.4375\n","Epoch 167, Train Loss: 0.9537, Val Loss: 1.7362, F1 Micro: 0.4479, F1 Macro: 0.4208, Accuracy: 0.4479\n","Epoch 168, Train Loss: 0.8859, Val Loss: 1.9526, F1 Micro: 0.3854, F1 Macro: 0.3773, Accuracy: 0.3854\n","Epoch 169, Train Loss: 0.9452, Val Loss: 1.7853, F1 Micro: 0.4792, F1 Macro: 0.4875, Accuracy: 0.4792\n","Epoch 170, Train Loss: 0.9826, Val Loss: 1.7615, F1 Micro: 0.5208, F1 Macro: 0.5109, Accuracy: 0.5208\n","Epoch 171, Train Loss: 0.8830, Val Loss: 1.7539, F1 Micro: 0.5417, F1 Macro: 0.5389, Accuracy: 0.5417\n","Epoch 172, Train Loss: 0.8448, Val Loss: 1.7929, F1 Micro: 0.4792, F1 Macro: 0.4735, Accuracy: 0.4792\n","Epoch 173, Train Loss: 0.8737, Val Loss: 1.9474, F1 Micro: 0.3542, F1 Macro: 0.3656, Accuracy: 0.3542\n","Epoch 174, Train Loss: 0.9425, Val Loss: 1.8086, F1 Micro: 0.4688, F1 Macro: 0.4583, Accuracy: 0.4688\n","Epoch 175, Train Loss: 0.8939, Val Loss: 1.7447, F1 Micro: 0.5417, F1 Macro: 0.5285, Accuracy: 0.5417\n","Epoch 176, Train Loss: 0.8939, Val Loss: 1.7594, F1 Micro: 0.4792, F1 Macro: 0.4570, Accuracy: 0.4792\n","Epoch 177, Train Loss: 0.8886, Val Loss: 1.7367, F1 Micro: 0.5208, F1 Macro: 0.4973, Accuracy: 0.5208\n","Epoch 178, Train Loss: 0.8790, Val Loss: 2.0503, F1 Micro: 0.3958, F1 Macro: 0.3893, Accuracy: 0.3958\n","Epoch 179, Train Loss: 0.9359, Val Loss: 1.8179, F1 Micro: 0.4583, F1 Macro: 0.4295, Accuracy: 0.4583\n","Epoch 180, Train Loss: 0.8944, Val Loss: 1.7801, F1 Micro: 0.4792, F1 Macro: 0.4852, Accuracy: 0.4792\n","Epoch 181, Train Loss: 0.8082, Val Loss: 1.7978, F1 Micro: 0.4583, F1 Macro: 0.4446, Accuracy: 0.4583\n","Epoch 182, Train Loss: 0.8296, Val Loss: 1.7279, F1 Micro: 0.5417, F1 Macro: 0.5344, Accuracy: 0.5417\n","Epoch 183, Train Loss: 0.8114, Val Loss: 1.7878, F1 Micro: 0.5000, F1 Macro: 0.4875, Accuracy: 0.5000\n","Epoch 184, Train Loss: 0.8349, Val Loss: 1.9711, F1 Micro: 0.3854, F1 Macro: 0.3629, Accuracy: 0.3854\n","Epoch 185, Train Loss: 0.9041, Val Loss: 1.7955, F1 Micro: 0.5000, F1 Macro: 0.4711, Accuracy: 0.5000\n","Epoch 186, Train Loss: 0.8266, Val Loss: 1.6919, F1 Micro: 0.5417, F1 Macro: 0.5110, Accuracy: 0.5417\n","Epoch 187, Train Loss: 0.8056, Val Loss: 1.7227, F1 Micro: 0.5312, F1 Macro: 0.5159, Accuracy: 0.5312\n","Epoch 188, Train Loss: 0.7657, Val Loss: 2.0316, F1 Micro: 0.4167, F1 Macro: 0.4126, Accuracy: 0.4167\n","Epoch 189, Train Loss: 0.9222, Val Loss: 1.7098, F1 Micro: 0.5312, F1 Macro: 0.5016, Accuracy: 0.5312\n","Epoch 190, Train Loss: 0.7991, Val Loss: 1.7841, F1 Micro: 0.5208, F1 Macro: 0.5216, Accuracy: 0.5208\n","Epoch 191, Train Loss: 0.7953, Val Loss: 1.8508, F1 Micro: 0.4896, F1 Macro: 0.4752, Accuracy: 0.4896\n","Epoch 192, Train Loss: 0.7931, Val Loss: 1.8120, F1 Micro: 0.5104, F1 Macro: 0.5030, Accuracy: 0.5104\n","Epoch 193, Train Loss: 0.7827, Val Loss: 1.8353, F1 Micro: 0.5938, F1 Macro: 0.5905, Accuracy: 0.5938\n","Epoch 194, Train Loss: 0.7938, Val Loss: 1.8004, F1 Micro: 0.5625, F1 Macro: 0.5455, Accuracy: 0.5625\n","Epoch 195, Train Loss: 0.7638, Val Loss: 1.8773, F1 Micro: 0.5312, F1 Macro: 0.5405, Accuracy: 0.5312\n","Epoch 196, Train Loss: 0.7322, Val Loss: 2.0364, F1 Micro: 0.4167, F1 Macro: 0.4189, Accuracy: 0.4167\n","Epoch 197, Train Loss: 0.7582, Val Loss: 1.7593, F1 Micro: 0.5521, F1 Macro: 0.5216, Accuracy: 0.5521\n","Epoch 198, Train Loss: 0.8465, Val Loss: 1.9126, F1 Micro: 0.4583, F1 Macro: 0.4535, Accuracy: 0.4583\n","Epoch 199, Train Loss: 0.7879, Val Loss: 1.7428, F1 Micro: 0.5208, F1 Macro: 0.4897, Accuracy: 0.5208\n","Epoch 200, Train Loss: 0.7515, Val Loss: 1.8836, F1 Micro: 0.4688, F1 Macro: 0.4509, Accuracy: 0.4688\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.4150, Val Loss: 1.8180, F1 Micro: 0.2500, F1 Macro: 0.1882, Accuracy: 0.2500\n","Epoch 2, Train Loss: 2.2690, Val Loss: 2.3668, F1 Micro: 0.2188, F1 Macro: 0.1582, Accuracy: 0.2188\n","Epoch 3, Train Loss: 2.2067, Val Loss: 1.9922, F1 Micro: 0.1458, F1 Macro: 0.0762, Accuracy: 0.1458\n","Epoch 4, Train Loss: 2.0438, Val Loss: 2.0551, F1 Micro: 0.2396, F1 Macro: 0.1883, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.9492, Val Loss: 1.7542, F1 Micro: 0.2604, F1 Macro: 0.2034, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.8966, Val Loss: 1.7708, F1 Micro: 0.2500, F1 Macro: 0.1878, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.9077, Val Loss: 1.9910, F1 Micro: 0.1667, F1 Macro: 0.1005, Accuracy: 0.1667\n","Epoch 8, Train Loss: 1.8881, Val Loss: 1.8676, F1 Micro: 0.1771, F1 Macro: 0.1314, Accuracy: 0.1771\n","Epoch 9, Train Loss: 1.7053, Val Loss: 1.6986, F1 Micro: 0.2708, F1 Macro: 0.2234, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.8480, Val Loss: 1.6421, F1 Micro: 0.2917, F1 Macro: 0.1912, Accuracy: 0.2917\n","Epoch 11, Train Loss: 1.8530, Val Loss: 1.7486, F1 Micro: 0.2292, F1 Macro: 0.1589, Accuracy: 0.2292\n","Epoch 12, Train Loss: 1.8141, Val Loss: 1.7769, F1 Micro: 0.3125, F1 Macro: 0.2834, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.7356, Val Loss: 1.7149, F1 Micro: 0.2396, F1 Macro: 0.2101, Accuracy: 0.2396\n","Epoch 14, Train Loss: 1.6920, Val Loss: 1.6938, F1 Micro: 0.2500, F1 Macro: 0.2139, Accuracy: 0.2500\n","Epoch 15, Train Loss: 1.6998, Val Loss: 1.8639, F1 Micro: 0.1771, F1 Macro: 0.1442, Accuracy: 0.1771\n","Epoch 16, Train Loss: 1.6723, Val Loss: 1.6576, F1 Micro: 0.3646, F1 Macro: 0.2702, Accuracy: 0.3646\n","Epoch 17, Train Loss: 1.6835, Val Loss: 1.6530, F1 Micro: 0.2812, F1 Macro: 0.2004, Accuracy: 0.2812\n","Epoch 18, Train Loss: 1.7080, Val Loss: 1.6899, F1 Micro: 0.2396, F1 Macro: 0.1770, Accuracy: 0.2396\n","Epoch 19, Train Loss: 1.7029, Val Loss: 1.6965, F1 Micro: 0.3229, F1 Macro: 0.2781, Accuracy: 0.3229\n","Epoch 20, Train Loss: 1.6821, Val Loss: 1.6937, F1 Micro: 0.3333, F1 Macro: 0.2225, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.6591, Val Loss: 1.7301, F1 Micro: 0.2604, F1 Macro: 0.1687, Accuracy: 0.2604\n","Epoch 22, Train Loss: 1.6784, Val Loss: 1.7578, F1 Micro: 0.3646, F1 Macro: 0.2872, Accuracy: 0.3646\n","Epoch 23, Train Loss: 1.6709, Val Loss: 1.7088, F1 Micro: 0.3229, F1 Macro: 0.2113, Accuracy: 0.3229\n","Epoch 24, Train Loss: 1.7266, Val Loss: 1.7225, F1 Micro: 0.3750, F1 Macro: 0.3240, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.7132, Val Loss: 1.8088, F1 Micro: 0.2292, F1 Macro: 0.1599, Accuracy: 0.2292\n","Epoch 26, Train Loss: 1.6996, Val Loss: 1.7702, F1 Micro: 0.1771, F1 Macro: 0.1484, Accuracy: 0.1771\n","Epoch 27, Train Loss: 1.6897, Val Loss: 1.6498, F1 Micro: 0.3854, F1 Macro: 0.3428, Accuracy: 0.3854\n","Epoch 28, Train Loss: 1.6858, Val Loss: 1.6150, F1 Micro: 0.3646, F1 Macro: 0.3073, Accuracy: 0.3646\n","Epoch 29, Train Loss: 1.6153, Val Loss: 1.6946, F1 Micro: 0.2708, F1 Macro: 0.1957, Accuracy: 0.2708\n","Epoch 30, Train Loss: 1.6760, Val Loss: 1.6084, F1 Micro: 0.3229, F1 Macro: 0.2546, Accuracy: 0.3229\n","Epoch 31, Train Loss: 1.6206, Val Loss: 1.6640, F1 Micro: 0.2292, F1 Macro: 0.2163, Accuracy: 0.2292\n","Epoch 32, Train Loss: 1.6349, Val Loss: 1.8369, F1 Micro: 0.1979, F1 Macro: 0.1277, Accuracy: 0.1979\n","Epoch 33, Train Loss: 1.6404, Val Loss: 1.6380, F1 Micro: 0.3438, F1 Macro: 0.3004, Accuracy: 0.3438\n","Epoch 34, Train Loss: 1.6547, Val Loss: 1.6217, F1 Micro: 0.3333, F1 Macro: 0.2669, Accuracy: 0.3333\n","Epoch 35, Train Loss: 1.6158, Val Loss: 1.7217, F1 Micro: 0.3438, F1 Macro: 0.2828, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.6130, Val Loss: 1.6846, F1 Micro: 0.2917, F1 Macro: 0.2116, Accuracy: 0.2917\n","Epoch 37, Train Loss: 1.6526, Val Loss: 1.7625, F1 Micro: 0.3229, F1 Macro: 0.2736, Accuracy: 0.3229\n","Epoch 38, Train Loss: 1.6465, Val Loss: 1.6124, F1 Micro: 0.3958, F1 Macro: 0.3395, Accuracy: 0.3958\n","Epoch 39, Train Loss: 1.5868, Val Loss: 1.6206, F1 Micro: 0.3333, F1 Macro: 0.3381, Accuracy: 0.3333\n","Epoch 40, Train Loss: 1.6037, Val Loss: 1.6255, F1 Micro: 0.3750, F1 Macro: 0.3913, Accuracy: 0.3750\n","Epoch 41, Train Loss: 1.6256, Val Loss: 1.6927, F1 Micro: 0.3438, F1 Macro: 0.3448, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.6029, Val Loss: 1.5365, F1 Micro: 0.3958, F1 Macro: 0.3458, Accuracy: 0.3958\n","Epoch 43, Train Loss: 1.5545, Val Loss: 1.5807, F1 Micro: 0.3438, F1 Macro: 0.3614, Accuracy: 0.3438\n","Epoch 44, Train Loss: 1.5712, Val Loss: 1.6527, F1 Micro: 0.3333, F1 Macro: 0.3317, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.5923, Val Loss: 1.6681, F1 Micro: 0.3229, F1 Macro: 0.2923, Accuracy: 0.3229\n","Epoch 46, Train Loss: 1.6089, Val Loss: 1.7161, F1 Micro: 0.3125, F1 Macro: 0.2827, Accuracy: 0.3125\n","Epoch 47, Train Loss: 1.5989, Val Loss: 1.5334, F1 Micro: 0.3958, F1 Macro: 0.3444, Accuracy: 0.3958\n","Epoch 48, Train Loss: 1.5871, Val Loss: 1.5884, F1 Micro: 0.3750, F1 Macro: 0.3146, Accuracy: 0.3750\n","Epoch 49, Train Loss: 1.5662, Val Loss: 1.6058, F1 Micro: 0.4062, F1 Macro: 0.3822, Accuracy: 0.4062\n","Epoch 50, Train Loss: 1.5476, Val Loss: 1.5438, F1 Micro: 0.3646, F1 Macro: 0.3578, Accuracy: 0.3646\n","Epoch 51, Train Loss: 1.5121, Val Loss: 1.5474, F1 Micro: 0.4167, F1 Macro: 0.3676, Accuracy: 0.4167\n","Epoch 52, Train Loss: 1.5099, Val Loss: 1.5519, F1 Micro: 0.3958, F1 Macro: 0.4156, Accuracy: 0.3958\n","Epoch 53, Train Loss: 1.5113, Val Loss: 1.5924, F1 Micro: 0.3750, F1 Macro: 0.3582, Accuracy: 0.3750\n","Epoch 54, Train Loss: 1.4853, Val Loss: 1.4796, F1 Micro: 0.3750, F1 Macro: 0.3470, Accuracy: 0.3750\n","Epoch 55, Train Loss: 1.5083, Val Loss: 1.5474, F1 Micro: 0.4375, F1 Macro: 0.4065, Accuracy: 0.4375\n","Epoch 56, Train Loss: 1.5236, Val Loss: 1.5360, F1 Micro: 0.4479, F1 Macro: 0.4399, Accuracy: 0.4479\n","Epoch 57, Train Loss: 1.4775, Val Loss: 1.5308, F1 Micro: 0.3542, F1 Macro: 0.3442, Accuracy: 0.3542\n","Epoch 58, Train Loss: 1.5073, Val Loss: 1.5742, F1 Micro: 0.4583, F1 Macro: 0.4213, Accuracy: 0.4583\n","Epoch 59, Train Loss: 1.5047, Val Loss: 1.5353, F1 Micro: 0.4062, F1 Macro: 0.3597, Accuracy: 0.4062\n","Epoch 60, Train Loss: 1.4735, Val Loss: 1.6873, F1 Micro: 0.3958, F1 Macro: 0.3488, Accuracy: 0.3958\n","Epoch 61, Train Loss: 1.5072, Val Loss: 1.6143, F1 Micro: 0.3854, F1 Macro: 0.3735, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.4896, Val Loss: 1.5241, F1 Micro: 0.3750, F1 Macro: 0.3482, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.4813, Val Loss: 1.5492, F1 Micro: 0.3438, F1 Macro: 0.2668, Accuracy: 0.3438\n","Epoch 64, Train Loss: 1.4696, Val Loss: 1.4570, F1 Micro: 0.4375, F1 Macro: 0.3654, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.4425, Val Loss: 1.5633, F1 Micro: 0.4271, F1 Macro: 0.4230, Accuracy: 0.4271\n","Epoch 66, Train Loss: 1.4389, Val Loss: 1.4957, F1 Micro: 0.3958, F1 Macro: 0.3604, Accuracy: 0.3958\n","Epoch 67, Train Loss: 1.4331, Val Loss: 1.5676, F1 Micro: 0.4896, F1 Macro: 0.4689, Accuracy: 0.4896\n","Epoch 68, Train Loss: 1.4273, Val Loss: 1.5652, F1 Micro: 0.4479, F1 Macro: 0.4516, Accuracy: 0.4479\n","Epoch 69, Train Loss: 1.4267, Val Loss: 1.6254, F1 Micro: 0.4167, F1 Macro: 0.4030, Accuracy: 0.4167\n","Epoch 70, Train Loss: 1.4406, Val Loss: 1.5162, F1 Micro: 0.4896, F1 Macro: 0.4906, Accuracy: 0.4896\n","Epoch 71, Train Loss: 1.4072, Val Loss: 1.5502, F1 Micro: 0.4062, F1 Macro: 0.4117, Accuracy: 0.4062\n","Epoch 72, Train Loss: 1.4142, Val Loss: 1.4901, F1 Micro: 0.4271, F1 Macro: 0.4075, Accuracy: 0.4271\n","Epoch 73, Train Loss: 1.3926, Val Loss: 1.4734, F1 Micro: 0.4583, F1 Macro: 0.4481, Accuracy: 0.4583\n","Epoch 74, Train Loss: 1.4335, Val Loss: 1.5678, F1 Micro: 0.4583, F1 Macro: 0.4452, Accuracy: 0.4583\n","Epoch 75, Train Loss: 1.5020, Val Loss: 1.5340, F1 Micro: 0.4375, F1 Macro: 0.3979, Accuracy: 0.4375\n","Epoch 76, Train Loss: 1.4009, Val Loss: 1.8082, F1 Micro: 0.2708, F1 Macro: 0.2097, Accuracy: 0.2708\n","Epoch 77, Train Loss: 1.4050, Val Loss: 1.4766, F1 Micro: 0.4896, F1 Macro: 0.4650, Accuracy: 0.4896\n","Epoch 78, Train Loss: 1.3586, Val Loss: 1.5516, F1 Micro: 0.4688, F1 Macro: 0.4629, Accuracy: 0.4688\n","Epoch 79, Train Loss: 1.3526, Val Loss: 1.4687, F1 Micro: 0.4271, F1 Macro: 0.3884, Accuracy: 0.4271\n","Epoch 80, Train Loss: 1.3735, Val Loss: 1.5098, F1 Micro: 0.4375, F1 Macro: 0.4177, Accuracy: 0.4375\n","Epoch 81, Train Loss: 1.3471, Val Loss: 1.6694, F1 Micro: 0.4167, F1 Macro: 0.4227, Accuracy: 0.4167\n","Epoch 82, Train Loss: 1.3338, Val Loss: 1.5214, F1 Micro: 0.4896, F1 Macro: 0.4647, Accuracy: 0.4896\n","Epoch 83, Train Loss: 1.3578, Val Loss: 1.5681, F1 Micro: 0.4792, F1 Macro: 0.4692, Accuracy: 0.4792\n","Epoch 84, Train Loss: 1.3522, Val Loss: 1.6086, F1 Micro: 0.4479, F1 Macro: 0.4465, Accuracy: 0.4479\n","Epoch 85, Train Loss: 1.3787, Val Loss: 1.4674, F1 Micro: 0.4896, F1 Macro: 0.4850, Accuracy: 0.4896\n","Epoch 86, Train Loss: 1.3373, Val Loss: 1.4288, F1 Micro: 0.4792, F1 Macro: 0.4652, Accuracy: 0.4792\n","Epoch 87, Train Loss: 1.3530, Val Loss: 1.6572, F1 Micro: 0.4271, F1 Macro: 0.4051, Accuracy: 0.4271\n","Epoch 88, Train Loss: 1.3876, Val Loss: 1.5893, F1 Micro: 0.4167, F1 Macro: 0.4069, Accuracy: 0.4167\n","Epoch 89, Train Loss: 1.3449, Val Loss: 1.6270, F1 Micro: 0.4167, F1 Macro: 0.3736, Accuracy: 0.4167\n","Epoch 90, Train Loss: 1.3700, Val Loss: 1.5166, F1 Micro: 0.4792, F1 Macro: 0.4465, Accuracy: 0.4792\n","Epoch 91, Train Loss: 1.2924, Val Loss: 1.4564, F1 Micro: 0.4688, F1 Macro: 0.4486, Accuracy: 0.4688\n","Epoch 92, Train Loss: 1.3102, Val Loss: 1.4509, F1 Micro: 0.4375, F1 Macro: 0.4237, Accuracy: 0.4375\n","Epoch 93, Train Loss: 1.2711, Val Loss: 1.4805, F1 Micro: 0.4479, F1 Macro: 0.4154, Accuracy: 0.4479\n","Epoch 94, Train Loss: 1.3335, Val Loss: 1.4070, F1 Micro: 0.4688, F1 Macro: 0.4418, Accuracy: 0.4688\n","Epoch 95, Train Loss: 1.2837, Val Loss: 1.5639, F1 Micro: 0.3958, F1 Macro: 0.3377, Accuracy: 0.3958\n","Epoch 96, Train Loss: 1.2824, Val Loss: 1.4678, F1 Micro: 0.5417, F1 Macro: 0.5484, Accuracy: 0.5417\n","Epoch 97, Train Loss: 1.2842, Val Loss: 1.4741, F1 Micro: 0.4792, F1 Macro: 0.4924, Accuracy: 0.4792\n","Epoch 98, Train Loss: 1.2430, Val Loss: 1.5559, F1 Micro: 0.4583, F1 Macro: 0.4585, Accuracy: 0.4583\n","Epoch 99, Train Loss: 1.2702, Val Loss: 1.4201, F1 Micro: 0.4896, F1 Macro: 0.4829, Accuracy: 0.4896\n","Epoch 100, Train Loss: 1.2890, Val Loss: 1.3840, F1 Micro: 0.4688, F1 Macro: 0.4510, Accuracy: 0.4688\n","Epoch 101, Train Loss: 1.2998, Val Loss: 1.4334, F1 Micro: 0.5000, F1 Macro: 0.5039, Accuracy: 0.5000\n","Epoch 102, Train Loss: 1.2228, Val Loss: 1.4532, F1 Micro: 0.5729, F1 Macro: 0.5725, Accuracy: 0.5729\n","Epoch 103, Train Loss: 1.2548, Val Loss: 1.4194, F1 Micro: 0.5104, F1 Macro: 0.5185, Accuracy: 0.5104\n","Epoch 104, Train Loss: 1.3273, Val Loss: 1.5784, F1 Micro: 0.4792, F1 Macro: 0.4577, Accuracy: 0.4792\n","Epoch 105, Train Loss: 1.2619, Val Loss: 1.4674, F1 Micro: 0.5208, F1 Macro: 0.5268, Accuracy: 0.5208\n","Epoch 106, Train Loss: 1.2181, Val Loss: 1.5154, F1 Micro: 0.5104, F1 Macro: 0.5102, Accuracy: 0.5104\n","Epoch 107, Train Loss: 1.2248, Val Loss: 1.4013, F1 Micro: 0.5104, F1 Macro: 0.5081, Accuracy: 0.5104\n","Epoch 108, Train Loss: 1.2210, Val Loss: 1.4493, F1 Micro: 0.5000, F1 Macro: 0.4943, Accuracy: 0.5000\n","Epoch 109, Train Loss: 1.2186, Val Loss: 1.5180, F1 Micro: 0.4896, F1 Macro: 0.4933, Accuracy: 0.4896\n","Epoch 110, Train Loss: 1.2524, Val Loss: 1.4435, F1 Micro: 0.4688, F1 Macro: 0.4488, Accuracy: 0.4688\n","Epoch 111, Train Loss: 1.1882, Val Loss: 1.4060, F1 Micro: 0.5104, F1 Macro: 0.5067, Accuracy: 0.5104\n","Epoch 112, Train Loss: 1.1723, Val Loss: 1.3502, F1 Micro: 0.5312, F1 Macro: 0.5215, Accuracy: 0.5312\n","Epoch 113, Train Loss: 1.1882, Val Loss: 1.5090, F1 Micro: 0.4375, F1 Macro: 0.4368, Accuracy: 0.4375\n","Epoch 114, Train Loss: 1.1796, Val Loss: 1.5048, F1 Micro: 0.4583, F1 Macro: 0.4645, Accuracy: 0.4583\n","Epoch 115, Train Loss: 1.1854, Val Loss: 1.5230, F1 Micro: 0.4896, F1 Macro: 0.4950, Accuracy: 0.4896\n","Epoch 116, Train Loss: 1.1741, Val Loss: 1.4345, F1 Micro: 0.4896, F1 Macro: 0.4888, Accuracy: 0.4896\n","Epoch 117, Train Loss: 1.1761, Val Loss: 1.4055, F1 Micro: 0.5208, F1 Macro: 0.5207, Accuracy: 0.5208\n","Epoch 118, Train Loss: 1.1458, Val Loss: 1.4441, F1 Micro: 0.4688, F1 Macro: 0.4481, Accuracy: 0.4688\n","Epoch 119, Train Loss: 1.1729, Val Loss: 1.4924, F1 Micro: 0.4688, F1 Macro: 0.4609, Accuracy: 0.4688\n","Epoch 120, Train Loss: 1.2127, Val Loss: 1.6253, F1 Micro: 0.4792, F1 Macro: 0.4868, Accuracy: 0.4792\n","Epoch 121, Train Loss: 1.2026, Val Loss: 1.3100, F1 Micro: 0.5208, F1 Macro: 0.5177, Accuracy: 0.5208\n","Epoch 122, Train Loss: 1.1350, Val Loss: 1.3174, F1 Micro: 0.5104, F1 Macro: 0.5066, Accuracy: 0.5104\n","Epoch 123, Train Loss: 1.1224, Val Loss: 1.2971, F1 Micro: 0.5104, F1 Macro: 0.4796, Accuracy: 0.5104\n","Epoch 124, Train Loss: 1.1547, Val Loss: 1.3479, F1 Micro: 0.5208, F1 Macro: 0.5149, Accuracy: 0.5208\n","Epoch 125, Train Loss: 1.1140, Val Loss: 1.4373, F1 Micro: 0.5208, F1 Macro: 0.5154, Accuracy: 0.5208\n","Epoch 126, Train Loss: 1.1029, Val Loss: 1.4488, F1 Micro: 0.4479, F1 Macro: 0.4382, Accuracy: 0.4479\n","Epoch 127, Train Loss: 1.2062, Val Loss: 1.2823, F1 Micro: 0.5312, F1 Macro: 0.5240, Accuracy: 0.5312\n","Epoch 128, Train Loss: 1.1494, Val Loss: 1.4536, F1 Micro: 0.5104, F1 Macro: 0.5072, Accuracy: 0.5104\n","Epoch 129, Train Loss: 1.1205, Val Loss: 1.4079, F1 Micro: 0.5417, F1 Macro: 0.5318, Accuracy: 0.5417\n","Epoch 130, Train Loss: 1.1789, Val Loss: 1.4198, F1 Micro: 0.5000, F1 Macro: 0.4881, Accuracy: 0.5000\n","Epoch 131, Train Loss: 1.0955, Val Loss: 1.3987, F1 Micro: 0.5208, F1 Macro: 0.5264, Accuracy: 0.5208\n","Epoch 132, Train Loss: 1.1067, Val Loss: 1.5740, F1 Micro: 0.5000, F1 Macro: 0.4884, Accuracy: 0.5000\n","Epoch 133, Train Loss: 1.1047, Val Loss: 1.3345, F1 Micro: 0.5417, F1 Macro: 0.5273, Accuracy: 0.5417\n","Epoch 134, Train Loss: 1.1200, Val Loss: 1.4595, F1 Micro: 0.5000, F1 Macro: 0.4694, Accuracy: 0.5000\n","Epoch 135, Train Loss: 1.1678, Val Loss: 1.3184, F1 Micro: 0.5312, F1 Macro: 0.5134, Accuracy: 0.5312\n","Epoch 136, Train Loss: 1.0832, Val Loss: 1.3990, F1 Micro: 0.5625, F1 Macro: 0.5617, Accuracy: 0.5625\n","Epoch 137, Train Loss: 1.0193, Val Loss: 1.5170, F1 Micro: 0.4792, F1 Macro: 0.4710, Accuracy: 0.4792\n","Epoch 138, Train Loss: 1.1023, Val Loss: 1.4579, F1 Micro: 0.4688, F1 Macro: 0.4570, Accuracy: 0.4688\n","Epoch 139, Train Loss: 1.1345, Val Loss: 1.3802, F1 Micro: 0.5417, F1 Macro: 0.5332, Accuracy: 0.5417\n","Epoch 140, Train Loss: 1.0597, Val Loss: 1.4983, F1 Micro: 0.4479, F1 Macro: 0.4369, Accuracy: 0.4479\n","Epoch 141, Train Loss: 1.0726, Val Loss: 1.4763, F1 Micro: 0.5417, F1 Macro: 0.5407, Accuracy: 0.5417\n","Epoch 142, Train Loss: 1.0684, Val Loss: 1.4051, F1 Micro: 0.5104, F1 Macro: 0.5155, Accuracy: 0.5104\n","Epoch 143, Train Loss: 1.0738, Val Loss: 1.3522, F1 Micro: 0.5521, F1 Macro: 0.5307, Accuracy: 0.5521\n","Epoch 144, Train Loss: 1.0547, Val Loss: 1.3192, F1 Micro: 0.5729, F1 Macro: 0.5592, Accuracy: 0.5729\n","Epoch 145, Train Loss: 1.0409, Val Loss: 1.4775, F1 Micro: 0.4688, F1 Macro: 0.4430, Accuracy: 0.4688\n","Epoch 146, Train Loss: 1.0591, Val Loss: 1.4972, F1 Micro: 0.5312, F1 Macro: 0.5148, Accuracy: 0.5312\n","Epoch 147, Train Loss: 1.0452, Val Loss: 1.4691, F1 Micro: 0.5104, F1 Macro: 0.4902, Accuracy: 0.5104\n","Epoch 148, Train Loss: 1.1103, Val Loss: 1.5151, F1 Micro: 0.5208, F1 Macro: 0.4986, Accuracy: 0.5208\n","Epoch 149, Train Loss: 1.0929, Val Loss: 1.4999, F1 Micro: 0.5000, F1 Macro: 0.5016, Accuracy: 0.5000\n","Epoch 150, Train Loss: 1.0754, Val Loss: 1.4055, F1 Micro: 0.5312, F1 Macro: 0.5391, Accuracy: 0.5312\n","Epoch 151, Train Loss: 1.0264, Val Loss: 1.3393, F1 Micro: 0.5521, F1 Macro: 0.5442, Accuracy: 0.5521\n","Epoch 152, Train Loss: 0.9929, Val Loss: 1.3767, F1 Micro: 0.5312, F1 Macro: 0.5279, Accuracy: 0.5312\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.5055, Val Loss: 1.9411, F1 Micro: 0.2708, F1 Macro: 0.1675, Accuracy: 0.2708\n","Epoch 2, Train Loss: 2.3473, Val Loss: 2.2579, F1 Micro: 0.2500, F1 Macro: 0.1679, Accuracy: 0.2500\n","Epoch 3, Train Loss: 2.2855, Val Loss: 2.4152, F1 Micro: 0.2396, F1 Macro: 0.1613, Accuracy: 0.2396\n","Epoch 4, Train Loss: 2.3246, Val Loss: 2.1812, F1 Micro: 0.2708, F1 Macro: 0.1645, Accuracy: 0.2708\n","Epoch 5, Train Loss: 2.2608, Val Loss: 1.8860, F1 Micro: 0.1979, F1 Macro: 0.1428, Accuracy: 0.1979\n","Epoch 6, Train Loss: 2.1029, Val Loss: 1.8698, F1 Micro: 0.2188, F1 Macro: 0.1654, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.8703, Val Loss: 1.7116, F1 Micro: 0.2396, F1 Macro: 0.2018, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.8736, Val Loss: 1.7633, F1 Micro: 0.1875, F1 Macro: 0.1682, Accuracy: 0.1875\n","Epoch 9, Train Loss: 1.9223, Val Loss: 1.7316, F1 Micro: 0.2188, F1 Macro: 0.1318, Accuracy: 0.2188\n","Epoch 10, Train Loss: 1.8092, Val Loss: 1.7629, F1 Micro: 0.2812, F1 Macro: 0.2179, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.7420, Val Loss: 1.7083, F1 Micro: 0.1979, F1 Macro: 0.1977, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.7647, Val Loss: 1.7151, F1 Micro: 0.2188, F1 Macro: 0.2008, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.7224, Val Loss: 1.7469, F1 Micro: 0.1979, F1 Macro: 0.1625, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.6778, Val Loss: 1.7490, F1 Micro: 0.2083, F1 Macro: 0.1446, Accuracy: 0.2083\n","Epoch 15, Train Loss: 1.7344, Val Loss: 1.7469, F1 Micro: 0.2500, F1 Macro: 0.2123, Accuracy: 0.2500\n","Epoch 16, Train Loss: 1.7855, Val Loss: 1.7338, F1 Micro: 0.2917, F1 Macro: 0.2679, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.6931, Val Loss: 1.7218, F1 Micro: 0.2292, F1 Macro: 0.1792, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.6630, Val Loss: 1.7754, F1 Micro: 0.2083, F1 Macro: 0.1518, Accuracy: 0.2083\n","Epoch 19, Train Loss: 1.6996, Val Loss: 1.7151, F1 Micro: 0.2083, F1 Macro: 0.1995, Accuracy: 0.2083\n","Epoch 20, Train Loss: 1.6716, Val Loss: 1.7652, F1 Micro: 0.3229, F1 Macro: 0.2550, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.6715, Val Loss: 1.8614, F1 Micro: 0.1771, F1 Macro: 0.1487, Accuracy: 0.1771\n","Epoch 22, Train Loss: 1.6556, Val Loss: 1.9413, F1 Micro: 0.2188, F1 Macro: 0.1365, Accuracy: 0.2188\n","Epoch 23, Train Loss: 1.6380, Val Loss: 1.7946, F1 Micro: 0.2500, F1 Macro: 0.2132, Accuracy: 0.2500\n","Epoch 24, Train Loss: 1.6861, Val Loss: 1.8026, F1 Micro: 0.2396, F1 Macro: 0.1862, Accuracy: 0.2396\n","Epoch 25, Train Loss: 1.6297, Val Loss: 1.7644, F1 Micro: 0.2396, F1 Macro: 0.2297, Accuracy: 0.2396\n","Epoch 26, Train Loss: 1.6332, Val Loss: 1.7504, F1 Micro: 0.2812, F1 Macro: 0.2244, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.6781, Val Loss: 1.7109, F1 Micro: 0.2917, F1 Macro: 0.2121, Accuracy: 0.2917\n","Epoch 28, Train Loss: 1.6218, Val Loss: 1.7366, F1 Micro: 0.2604, F1 Macro: 0.1955, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.6096, Val Loss: 1.8261, F1 Micro: 0.2292, F1 Macro: 0.2165, Accuracy: 0.2292\n","Epoch 30, Train Loss: 1.6481, Val Loss: 1.7196, F1 Micro: 0.2396, F1 Macro: 0.1937, Accuracy: 0.2396\n","Epoch 31, Train Loss: 1.6585, Val Loss: 1.8233, F1 Micro: 0.2083, F1 Macro: 0.1798, Accuracy: 0.2083\n","Epoch 32, Train Loss: 1.6479, Val Loss: 1.9241, F1 Micro: 0.1562, F1 Macro: 0.1194, Accuracy: 0.1562\n","Epoch 33, Train Loss: 1.6666, Val Loss: 1.8085, F1 Micro: 0.2500, F1 Macro: 0.1943, Accuracy: 0.2500\n","Epoch 34, Train Loss: 1.5725, Val Loss: 1.8576, F1 Micro: 0.2812, F1 Macro: 0.2180, Accuracy: 0.2812\n","Epoch 35, Train Loss: 1.6113, Val Loss: 1.8041, F1 Micro: 0.2708, F1 Macro: 0.2469, Accuracy: 0.2708\n","Epoch 36, Train Loss: 1.5936, Val Loss: 1.8680, F1 Micro: 0.1667, F1 Macro: 0.1547, Accuracy: 0.1667\n","Epoch 37, Train Loss: 1.5823, Val Loss: 1.8059, F1 Micro: 0.2500, F1 Macro: 0.1871, Accuracy: 0.2500\n","Epoch 38, Train Loss: 1.5862, Val Loss: 1.8007, F1 Micro: 0.3229, F1 Macro: 0.3007, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.5554, Val Loss: 1.8414, F1 Micro: 0.2812, F1 Macro: 0.2482, Accuracy: 0.2812\n","Epoch 40, Train Loss: 1.5812, Val Loss: 1.8105, F1 Micro: 0.3229, F1 Macro: 0.2716, Accuracy: 0.3229\n","Epoch 41, Train Loss: 1.5238, Val Loss: 1.8431, F1 Micro: 0.2396, F1 Macro: 0.2187, Accuracy: 0.2396\n","Epoch 42, Train Loss: 1.6052, Val Loss: 1.8688, F1 Micro: 0.2188, F1 Macro: 0.1745, Accuracy: 0.2188\n","Epoch 43, Train Loss: 1.5400, Val Loss: 1.8510, F1 Micro: 0.2292, F1 Macro: 0.2396, Accuracy: 0.2292\n","Epoch 44, Train Loss: 1.5769, Val Loss: 1.7324, F1 Micro: 0.2812, F1 Macro: 0.2733, Accuracy: 0.2812\n","Epoch 45, Train Loss: 1.5487, Val Loss: 1.9008, F1 Micro: 0.2917, F1 Macro: 0.2654, Accuracy: 0.2917\n","Epoch 46, Train Loss: 1.5164, Val Loss: 1.8614, F1 Micro: 0.2500, F1 Macro: 0.2114, Accuracy: 0.2500\n","Epoch 47, Train Loss: 1.4906, Val Loss: 1.7877, F1 Micro: 0.2917, F1 Macro: 0.2588, Accuracy: 0.2917\n","Epoch 48, Train Loss: 1.5438, Val Loss: 1.7203, F1 Micro: 0.3333, F1 Macro: 0.2866, Accuracy: 0.3333\n","Epoch 49, Train Loss: 1.5087, Val Loss: 1.8632, F1 Micro: 0.3229, F1 Macro: 0.2984, Accuracy: 0.3229\n","Epoch 50, Train Loss: 1.5077, Val Loss: 1.8739, F1 Micro: 0.3021, F1 Macro: 0.2669, Accuracy: 0.3021\n","Epoch 51, Train Loss: 1.4568, Val Loss: 1.7702, F1 Micro: 0.3333, F1 Macro: 0.2673, Accuracy: 0.3333\n","Epoch 52, Train Loss: 1.5249, Val Loss: 1.8919, F1 Micro: 0.2708, F1 Macro: 0.2510, Accuracy: 0.2708\n","Epoch 53, Train Loss: 1.4388, Val Loss: 1.8269, F1 Micro: 0.3438, F1 Macro: 0.2858, Accuracy: 0.3438\n","Epoch 54, Train Loss: 1.5093, Val Loss: 1.8210, F1 Micro: 0.3333, F1 Macro: 0.2953, Accuracy: 0.3333\n","Epoch 55, Train Loss: 1.4245, Val Loss: 1.8704, F1 Micro: 0.3333, F1 Macro: 0.3051, Accuracy: 0.3333\n","Epoch 56, Train Loss: 1.4506, Val Loss: 1.9024, F1 Micro: 0.2917, F1 Macro: 0.2723, Accuracy: 0.2917\n","Epoch 57, Train Loss: 1.4589, Val Loss: 1.8163, F1 Micro: 0.3750, F1 Macro: 0.3504, Accuracy: 0.3750\n","Epoch 58, Train Loss: 1.4317, Val Loss: 1.8446, F1 Micro: 0.3021, F1 Macro: 0.2933, Accuracy: 0.3021\n","Epoch 59, Train Loss: 1.4569, Val Loss: 1.8620, F1 Micro: 0.2917, F1 Macro: 0.2432, Accuracy: 0.2917\n","Epoch 60, Train Loss: 1.4641, Val Loss: 1.8392, F1 Micro: 0.3125, F1 Macro: 0.3131, Accuracy: 0.3125\n","Epoch 61, Train Loss: 1.4578, Val Loss: 1.9104, F1 Micro: 0.3438, F1 Macro: 0.3261, Accuracy: 0.3438\n","Epoch 62, Train Loss: 1.4837, Val Loss: 1.8532, F1 Micro: 0.3021, F1 Macro: 0.2482, Accuracy: 0.3021\n","Epoch 63, Train Loss: 1.4742, Val Loss: 1.8452, F1 Micro: 0.3125, F1 Macro: 0.2991, Accuracy: 0.3125\n","Epoch 64, Train Loss: 1.4101, Val Loss: 1.8527, F1 Micro: 0.3229, F1 Macro: 0.2823, Accuracy: 0.3229\n","Epoch 65, Train Loss: 1.3994, Val Loss: 1.8031, F1 Micro: 0.3438, F1 Macro: 0.3308, Accuracy: 0.3438\n","Epoch 66, Train Loss: 1.3434, Val Loss: 1.8393, F1 Micro: 0.3750, F1 Macro: 0.3626, Accuracy: 0.3750\n","Epoch 67, Train Loss: 1.3761, Val Loss: 1.8814, F1 Micro: 0.4062, F1 Macro: 0.3736, Accuracy: 0.4062\n","Epoch 68, Train Loss: 1.3951, Val Loss: 1.8458, F1 Micro: 0.3333, F1 Macro: 0.3012, Accuracy: 0.3333\n","Epoch 69, Train Loss: 1.3691, Val Loss: 1.8610, F1 Micro: 0.3125, F1 Macro: 0.2725, Accuracy: 0.3125\n","Epoch 70, Train Loss: 1.3687, Val Loss: 1.8182, F1 Micro: 0.3542, F1 Macro: 0.2970, Accuracy: 0.3542\n","Epoch 71, Train Loss: 1.3780, Val Loss: 1.9705, F1 Micro: 0.3438, F1 Macro: 0.3207, Accuracy: 0.3438\n","Epoch 72, Train Loss: 1.3710, Val Loss: 1.9190, F1 Micro: 0.3438, F1 Macro: 0.2754, Accuracy: 0.3438\n","Epoch 73, Train Loss: 1.3408, Val Loss: 1.8788, F1 Micro: 0.3333, F1 Macro: 0.3359, Accuracy: 0.3333\n","Epoch 74, Train Loss: 1.3578, Val Loss: 1.8399, F1 Micro: 0.3438, F1 Macro: 0.2897, Accuracy: 0.3438\n","Epoch 75, Train Loss: 1.3218, Val Loss: 1.9716, F1 Micro: 0.2917, F1 Macro: 0.2536, Accuracy: 0.2917\n","Epoch 76, Train Loss: 1.3710, Val Loss: 1.9113, F1 Micro: 0.3021, F1 Macro: 0.2791, Accuracy: 0.3021\n","Epoch 77, Train Loss: 1.3342, Val Loss: 1.9131, F1 Micro: 0.3438, F1 Macro: 0.2826, Accuracy: 0.3438\n","Epoch 78, Train Loss: 1.3567, Val Loss: 1.9240, F1 Micro: 0.3542, F1 Macro: 0.3245, Accuracy: 0.3542\n","Epoch 79, Train Loss: 1.2977, Val Loss: 1.8355, F1 Micro: 0.3229, F1 Macro: 0.2917, Accuracy: 0.3229\n","Epoch 80, Train Loss: 1.2807, Val Loss: 1.9173, F1 Micro: 0.3646, F1 Macro: 0.3412, Accuracy: 0.3646\n","Epoch 81, Train Loss: 1.2928, Val Loss: 1.8791, F1 Micro: 0.3438, F1 Macro: 0.2910, Accuracy: 0.3438\n","Epoch 82, Train Loss: 1.3094, Val Loss: 1.8742, F1 Micro: 0.3333, F1 Macro: 0.2903, Accuracy: 0.3333\n","Epoch 83, Train Loss: 1.3372, Val Loss: 2.0041, F1 Micro: 0.3333, F1 Macro: 0.2727, Accuracy: 0.3333\n","Epoch 84, Train Loss: 1.3036, Val Loss: 1.9147, F1 Micro: 0.3333, F1 Macro: 0.3063, Accuracy: 0.3333\n","Epoch 85, Train Loss: 1.2717, Val Loss: 1.8309, F1 Micro: 0.3438, F1 Macro: 0.3376, Accuracy: 0.3438\n","Epoch 86, Train Loss: 1.3005, Val Loss: 1.9067, F1 Micro: 0.3333, F1 Macro: 0.3071, Accuracy: 0.3333\n","Epoch 87, Train Loss: 1.3147, Val Loss: 1.9160, F1 Micro: 0.3438, F1 Macro: 0.3406, Accuracy: 0.3438\n","Epoch 88, Train Loss: 1.2715, Val Loss: 1.9377, F1 Micro: 0.3958, F1 Macro: 0.3702, Accuracy: 0.3958\n","Epoch 89, Train Loss: 1.2785, Val Loss: 1.9368, F1 Micro: 0.3021, F1 Macro: 0.2771, Accuracy: 0.3021\n","Epoch 90, Train Loss: 1.3072, Val Loss: 1.8849, F1 Micro: 0.3333, F1 Macro: 0.2743, Accuracy: 0.3333\n","Epoch 91, Train Loss: 1.2527, Val Loss: 1.8241, F1 Micro: 0.3438, F1 Macro: 0.3408, Accuracy: 0.3438\n","Epoch 92, Train Loss: 1.2560, Val Loss: 1.8666, F1 Micro: 0.3646, F1 Macro: 0.3511, Accuracy: 0.3646\n","Epoch 93, Train Loss: 1.2578, Val Loss: 1.8359, F1 Micro: 0.3542, F1 Macro: 0.3322, Accuracy: 0.3542\n","Epoch 94, Train Loss: 1.2515, Val Loss: 1.9625, F1 Micro: 0.3854, F1 Macro: 0.3617, Accuracy: 0.3854\n","Epoch 95, Train Loss: 1.2726, Val Loss: 1.9487, F1 Micro: 0.3333, F1 Macro: 0.3205, Accuracy: 0.3333\n","Epoch 96, Train Loss: 1.2199, Val Loss: 1.9178, F1 Micro: 0.3646, F1 Macro: 0.3621, Accuracy: 0.3646\n","Epoch 97, Train Loss: 1.2306, Val Loss: 1.8239, F1 Micro: 0.3438, F1 Macro: 0.3246, Accuracy: 0.3438\n","Epoch 98, Train Loss: 1.2524, Val Loss: 1.8726, F1 Micro: 0.3229, F1 Macro: 0.2845, Accuracy: 0.3229\n","Epoch 99, Train Loss: 1.2305, Val Loss: 1.8681, F1 Micro: 0.3542, F1 Macro: 0.3142, Accuracy: 0.3542\n","Epoch 100, Train Loss: 1.2071, Val Loss: 1.8309, F1 Micro: 0.3542, F1 Macro: 0.3428, Accuracy: 0.3542\n","Epoch 101, Train Loss: 1.2404, Val Loss: 1.9322, F1 Micro: 0.3750, F1 Macro: 0.3587, Accuracy: 0.3750\n","Epoch 102, Train Loss: 1.1931, Val Loss: 1.9126, F1 Micro: 0.3958, F1 Macro: 0.3974, Accuracy: 0.3958\n","Epoch 103, Train Loss: 1.2302, Val Loss: 1.9746, F1 Micro: 0.3229, F1 Macro: 0.2959, Accuracy: 0.3229\n","Epoch 104, Train Loss: 1.2206, Val Loss: 1.9244, F1 Micro: 0.3125, F1 Macro: 0.2873, Accuracy: 0.3125\n","Epoch 105, Train Loss: 1.2519, Val Loss: 1.8761, F1 Micro: 0.3229, F1 Macro: 0.3304, Accuracy: 0.3229\n","Epoch 106, Train Loss: 1.1376, Val Loss: 1.9172, F1 Micro: 0.3333, F1 Macro: 0.3083, Accuracy: 0.3333\n","Epoch 107, Train Loss: 1.1418, Val Loss: 1.9177, F1 Micro: 0.3542, F1 Macro: 0.3131, Accuracy: 0.3542\n","Epoch 108, Train Loss: 1.1946, Val Loss: 2.0338, F1 Micro: 0.3542, F1 Macro: 0.3044, Accuracy: 0.3542\n","Epoch 109, Train Loss: 1.1709, Val Loss: 1.9159, F1 Micro: 0.3542, F1 Macro: 0.3402, Accuracy: 0.3542\n","Epoch 110, Train Loss: 1.1921, Val Loss: 1.9161, F1 Micro: 0.3542, F1 Macro: 0.3391, Accuracy: 0.3542\n","Epoch 111, Train Loss: 1.1858, Val Loss: 1.8973, F1 Micro: 0.3750, F1 Macro: 0.3602, Accuracy: 0.3750\n","Epoch 112, Train Loss: 1.1893, Val Loss: 1.8902, F1 Micro: 0.3958, F1 Macro: 0.3670, Accuracy: 0.3958\n","Epoch 113, Train Loss: 1.1215, Val Loss: 1.9714, F1 Micro: 0.3958, F1 Macro: 0.3751, Accuracy: 0.3958\n","Epoch 114, Train Loss: 1.1288, Val Loss: 1.8431, F1 Micro: 0.3854, F1 Macro: 0.3718, Accuracy: 0.3854\n","Epoch 115, Train Loss: 1.2099, Val Loss: 1.9721, F1 Micro: 0.3229, F1 Macro: 0.2913, Accuracy: 0.3229\n","Epoch 116, Train Loss: 1.2362, Val Loss: 2.0184, F1 Micro: 0.3438, F1 Macro: 0.3260, Accuracy: 0.3438\n","Epoch 117, Train Loss: 1.1559, Val Loss: 1.8871, F1 Micro: 0.3646, F1 Macro: 0.3330, Accuracy: 0.3646\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.3336, Val Loss: 2.2078, F1 Micro: 0.1667, F1 Macro: 0.0932, Accuracy: 0.1667\n","Epoch 2, Train Loss: 2.1209, Val Loss: 1.9589, F1 Micro: 0.2188, F1 Macro: 0.1293, Accuracy: 0.2188\n","Epoch 3, Train Loss: 2.1364, Val Loss: 2.0123, F1 Micro: 0.2083, F1 Macro: 0.1365, Accuracy: 0.2083\n","Epoch 4, Train Loss: 1.9622, Val Loss: 1.9044, F1 Micro: 0.1875, F1 Macro: 0.0968, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.9474, Val Loss: 1.8764, F1 Micro: 0.2083, F1 Macro: 0.1641, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.8164, Val Loss: 2.0532, F1 Micro: 0.1875, F1 Macro: 0.1148, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.8558, Val Loss: 1.9088, F1 Micro: 0.1667, F1 Macro: 0.1200, Accuracy: 0.1667\n","Epoch 8, Train Loss: 1.7591, Val Loss: 1.8116, F1 Micro: 0.2188, F1 Macro: 0.1386, Accuracy: 0.2188\n","Epoch 9, Train Loss: 1.7734, Val Loss: 1.8204, F1 Micro: 0.2083, F1 Macro: 0.1521, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.8040, Val Loss: 1.8824, F1 Micro: 0.1667, F1 Macro: 0.0913, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.8132, Val Loss: 1.8362, F1 Micro: 0.1979, F1 Macro: 0.1250, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.7452, Val Loss: 1.7798, F1 Micro: 0.2292, F1 Macro: 0.1908, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.7315, Val Loss: 1.8131, F1 Micro: 0.2604, F1 Macro: 0.2105, Accuracy: 0.2604\n","Epoch 14, Train Loss: 1.7129, Val Loss: 1.8496, F1 Micro: 0.2083, F1 Macro: 0.1298, Accuracy: 0.2083\n","Epoch 15, Train Loss: 1.7147, Val Loss: 1.8497, F1 Micro: 0.1562, F1 Macro: 0.0894, Accuracy: 0.1562\n","Epoch 16, Train Loss: 1.6841, Val Loss: 1.7734, F1 Micro: 0.2917, F1 Macro: 0.2179, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.7006, Val Loss: 1.9481, F1 Micro: 0.2188, F1 Macro: 0.1390, Accuracy: 0.2188\n","Epoch 18, Train Loss: 1.7076, Val Loss: 1.8229, F1 Micro: 0.2812, F1 Macro: 0.2302, Accuracy: 0.2812\n","Epoch 19, Train Loss: 1.6750, Val Loss: 1.8301, F1 Micro: 0.2292, F1 Macro: 0.1812, Accuracy: 0.2292\n","Epoch 20, Train Loss: 1.6773, Val Loss: 1.7894, F1 Micro: 0.2604, F1 Macro: 0.1792, Accuracy: 0.2604\n","Epoch 21, Train Loss: 1.6896, Val Loss: 1.8447, F1 Micro: 0.2292, F1 Macro: 0.1625, Accuracy: 0.2292\n","Epoch 22, Train Loss: 1.6835, Val Loss: 1.7732, F1 Micro: 0.2917, F1 Macro: 0.2180, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.6559, Val Loss: 1.7530, F1 Micro: 0.3125, F1 Macro: 0.2734, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.6568, Val Loss: 1.7634, F1 Micro: 0.2812, F1 Macro: 0.2595, Accuracy: 0.2812\n","Epoch 25, Train Loss: 1.6865, Val Loss: 1.7733, F1 Micro: 0.2604, F1 Macro: 0.1926, Accuracy: 0.2604\n","Epoch 26, Train Loss: 1.6534, Val Loss: 1.7796, F1 Micro: 0.2812, F1 Macro: 0.2123, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.6043, Val Loss: 1.8070, F1 Micro: 0.1771, F1 Macro: 0.1173, Accuracy: 0.1771\n","Epoch 28, Train Loss: 1.6733, Val Loss: 1.8355, F1 Micro: 0.1667, F1 Macro: 0.1085, Accuracy: 0.1667\n","Epoch 29, Train Loss: 1.6507, Val Loss: 1.7899, F1 Micro: 0.1979, F1 Macro: 0.1209, Accuracy: 0.1979\n","Epoch 30, Train Loss: 1.6618, Val Loss: 1.7812, F1 Micro: 0.2083, F1 Macro: 0.1974, Accuracy: 0.2083\n","Epoch 31, Train Loss: 1.6360, Val Loss: 1.7512, F1 Micro: 0.2812, F1 Macro: 0.2102, Accuracy: 0.2812\n","Epoch 32, Train Loss: 1.6221, Val Loss: 1.8184, F1 Micro: 0.2500, F1 Macro: 0.2437, Accuracy: 0.2500\n","Epoch 33, Train Loss: 1.6411, Val Loss: 1.8408, F1 Micro: 0.2708, F1 Macro: 0.2221, Accuracy: 0.2708\n","Epoch 34, Train Loss: 1.6138, Val Loss: 1.8007, F1 Micro: 0.2083, F1 Macro: 0.1702, Accuracy: 0.2083\n","Epoch 35, Train Loss: 1.6437, Val Loss: 1.7732, F1 Micro: 0.2604, F1 Macro: 0.2046, Accuracy: 0.2604\n","Epoch 36, Train Loss: 1.5705, Val Loss: 1.7443, F1 Micro: 0.2917, F1 Macro: 0.2333, Accuracy: 0.2917\n","Epoch 37, Train Loss: 1.5933, Val Loss: 1.8476, F1 Micro: 0.2396, F1 Macro: 0.1936, Accuracy: 0.2396\n","Epoch 38, Train Loss: 1.6060, Val Loss: 1.7499, F1 Micro: 0.3125, F1 Macro: 0.2741, Accuracy: 0.3125\n","Epoch 39, Train Loss: 1.5614, Val Loss: 1.7923, F1 Micro: 0.2604, F1 Macro: 0.2175, Accuracy: 0.2604\n","Epoch 40, Train Loss: 1.6449, Val Loss: 1.8018, F1 Micro: 0.2708, F1 Macro: 0.2312, Accuracy: 0.2708\n","Epoch 41, Train Loss: 1.5572, Val Loss: 1.8810, F1 Micro: 0.2604, F1 Macro: 0.2062, Accuracy: 0.2604\n","Epoch 42, Train Loss: 1.5744, Val Loss: 1.7070, F1 Micro: 0.3021, F1 Macro: 0.2676, Accuracy: 0.3021\n","Epoch 43, Train Loss: 1.5692, Val Loss: 1.9128, F1 Micro: 0.2604, F1 Macro: 0.2348, Accuracy: 0.2604\n","Epoch 44, Train Loss: 1.6302, Val Loss: 1.7604, F1 Micro: 0.2812, F1 Macro: 0.2414, Accuracy: 0.2812\n","Epoch 45, Train Loss: 1.5473, Val Loss: 1.7587, F1 Micro: 0.2396, F1 Macro: 0.2258, Accuracy: 0.2396\n","Epoch 46, Train Loss: 1.5701, Val Loss: 1.7369, F1 Micro: 0.3125, F1 Macro: 0.3105, Accuracy: 0.3125\n","Epoch 47, Train Loss: 1.5562, Val Loss: 1.8081, F1 Micro: 0.2708, F1 Macro: 0.2256, Accuracy: 0.2708\n","Epoch 48, Train Loss: 1.5215, Val Loss: 1.7650, F1 Micro: 0.2917, F1 Macro: 0.2854, Accuracy: 0.2917\n","Epoch 49, Train Loss: 1.6035, Val Loss: 1.7507, F1 Micro: 0.2500, F1 Macro: 0.2076, Accuracy: 0.2500\n","Epoch 50, Train Loss: 1.5795, Val Loss: 1.8329, F1 Micro: 0.2917, F1 Macro: 0.2501, Accuracy: 0.2917\n","Epoch 51, Train Loss: 1.5853, Val Loss: 1.9812, F1 Micro: 0.1979, F1 Macro: 0.1516, Accuracy: 0.1979\n","Epoch 52, Train Loss: 1.5653, Val Loss: 1.7605, F1 Micro: 0.2812, F1 Macro: 0.2669, Accuracy: 0.2812\n","Epoch 53, Train Loss: 1.5224, Val Loss: 1.8428, F1 Micro: 0.3021, F1 Macro: 0.2269, Accuracy: 0.3021\n","Epoch 54, Train Loss: 1.5352, Val Loss: 1.8721, F1 Micro: 0.2812, F1 Macro: 0.2228, Accuracy: 0.2812\n","Epoch 55, Train Loss: 1.5148, Val Loss: 1.7119, F1 Micro: 0.2812, F1 Macro: 0.2866, Accuracy: 0.2812\n","Epoch 56, Train Loss: 1.5025, Val Loss: 1.7096, F1 Micro: 0.3229, F1 Macro: 0.2800, Accuracy: 0.3229\n","Epoch 57, Train Loss: 1.5251, Val Loss: 1.6841, F1 Micro: 0.3125, F1 Macro: 0.2839, Accuracy: 0.3125\n","Epoch 58, Train Loss: 1.4630, Val Loss: 1.7382, F1 Micro: 0.3333, F1 Macro: 0.3032, Accuracy: 0.3333\n","Epoch 59, Train Loss: 1.5224, Val Loss: 1.7291, F1 Micro: 0.2812, F1 Macro: 0.2652, Accuracy: 0.2812\n","Epoch 60, Train Loss: 1.4698, Val Loss: 1.7588, F1 Micro: 0.3125, F1 Macro: 0.2761, Accuracy: 0.3125\n","Epoch 61, Train Loss: 1.5064, Val Loss: 1.7534, F1 Micro: 0.3229, F1 Macro: 0.2633, Accuracy: 0.3229\n","Epoch 62, Train Loss: 1.5170, Val Loss: 1.6931, F1 Micro: 0.3333, F1 Macro: 0.3034, Accuracy: 0.3333\n","Epoch 63, Train Loss: 1.4840, Val Loss: 1.7079, F1 Micro: 0.3542, F1 Macro: 0.3335, Accuracy: 0.3542\n","Epoch 64, Train Loss: 1.4589, Val Loss: 1.7888, F1 Micro: 0.2812, F1 Macro: 0.2410, Accuracy: 0.2812\n","Epoch 65, Train Loss: 1.5171, Val Loss: 1.8199, F1 Micro: 0.2917, F1 Macro: 0.2282, Accuracy: 0.2917\n","Epoch 66, Train Loss: 1.5041, Val Loss: 1.8297, F1 Micro: 0.2917, F1 Macro: 0.2486, Accuracy: 0.2917\n","Epoch 67, Train Loss: 1.4415, Val Loss: 1.7541, F1 Micro: 0.3229, F1 Macro: 0.2884, Accuracy: 0.3229\n","Epoch 68, Train Loss: 1.3926, Val Loss: 1.7998, F1 Micro: 0.2917, F1 Macro: 0.2822, Accuracy: 0.2917\n","Epoch 69, Train Loss: 1.4440, Val Loss: 1.8300, F1 Micro: 0.3229, F1 Macro: 0.2913, Accuracy: 0.3229\n","Epoch 70, Train Loss: 1.4243, Val Loss: 1.7915, F1 Micro: 0.3646, F1 Macro: 0.3435, Accuracy: 0.3646\n","Epoch 71, Train Loss: 1.4006, Val Loss: 1.7886, F1 Micro: 0.3438, F1 Macro: 0.3194, Accuracy: 0.3438\n","Epoch 72, Train Loss: 1.4365, Val Loss: 1.8389, F1 Micro: 0.3333, F1 Macro: 0.3092, Accuracy: 0.3333\n","Epoch 73, Train Loss: 1.4290, Val Loss: 1.7480, F1 Micro: 0.3646, F1 Macro: 0.3527, Accuracy: 0.3646\n","Epoch 74, Train Loss: 1.3918, Val Loss: 1.8211, F1 Micro: 0.3646, F1 Macro: 0.3330, Accuracy: 0.3646\n","Epoch 75, Train Loss: 1.4184, Val Loss: 1.8166, F1 Micro: 0.3646, F1 Macro: 0.3410, Accuracy: 0.3646\n","Epoch 76, Train Loss: 1.4226, Val Loss: 1.7595, F1 Micro: 0.3333, F1 Macro: 0.3017, Accuracy: 0.3333\n","Epoch 77, Train Loss: 1.3639, Val Loss: 1.9017, F1 Micro: 0.2708, F1 Macro: 0.2499, Accuracy: 0.2708\n","Epoch 78, Train Loss: 1.3879, Val Loss: 1.8917, F1 Micro: 0.2604, F1 Macro: 0.2299, Accuracy: 0.2604\n","Epoch 79, Train Loss: 1.3817, Val Loss: 1.7877, F1 Micro: 0.3854, F1 Macro: 0.3754, Accuracy: 0.3854\n","Epoch 80, Train Loss: 1.3410, Val Loss: 1.8763, F1 Micro: 0.3438, F1 Macro: 0.2923, Accuracy: 0.3438\n","Epoch 81, Train Loss: 1.3286, Val Loss: 1.8655, F1 Micro: 0.3438, F1 Macro: 0.3163, Accuracy: 0.3438\n","Epoch 82, Train Loss: 1.3719, Val Loss: 1.8221, F1 Micro: 0.3542, F1 Macro: 0.2990, Accuracy: 0.3542\n","Epoch 83, Train Loss: 1.3209, Val Loss: 1.8168, F1 Micro: 0.3438, F1 Macro: 0.3040, Accuracy: 0.3438\n","Epoch 84, Train Loss: 1.3606, Val Loss: 1.7942, F1 Micro: 0.3646, F1 Macro: 0.3511, Accuracy: 0.3646\n","Epoch 85, Train Loss: 1.3418, Val Loss: 1.8246, F1 Micro: 0.3229, F1 Macro: 0.3147, Accuracy: 0.3229\n","Epoch 86, Train Loss: 1.3108, Val Loss: 1.7230, F1 Micro: 0.4167, F1 Macro: 0.3923, Accuracy: 0.4167\n","Epoch 87, Train Loss: 1.2524, Val Loss: 1.8941, F1 Micro: 0.3646, F1 Macro: 0.3098, Accuracy: 0.3646\n","Epoch 88, Train Loss: 1.3632, Val Loss: 1.8272, F1 Micro: 0.3333, F1 Macro: 0.2930, Accuracy: 0.3333\n","Epoch 89, Train Loss: 1.4271, Val Loss: 1.7689, F1 Micro: 0.3021, F1 Macro: 0.2694, Accuracy: 0.3021\n","Epoch 90, Train Loss: 1.3193, Val Loss: 1.7601, F1 Micro: 0.3958, F1 Macro: 0.3898, Accuracy: 0.3958\n","Epoch 91, Train Loss: 1.3157, Val Loss: 1.9961, F1 Micro: 0.2917, F1 Macro: 0.2584, Accuracy: 0.2917\n","Epoch 92, Train Loss: 1.3038, Val Loss: 1.8558, F1 Micro: 0.3646, F1 Macro: 0.3440, Accuracy: 0.3646\n","Epoch 93, Train Loss: 1.2837, Val Loss: 1.8095, F1 Micro: 0.3750, F1 Macro: 0.3617, Accuracy: 0.3750\n","Epoch 94, Train Loss: 1.2566, Val Loss: 1.8246, F1 Micro: 0.3438, F1 Macro: 0.3034, Accuracy: 0.3438\n","Epoch 95, Train Loss: 1.2825, Val Loss: 1.7907, F1 Micro: 0.3333, F1 Macro: 0.3344, Accuracy: 0.3333\n","Epoch 96, Train Loss: 1.2469, Val Loss: 1.8762, F1 Micro: 0.3125, F1 Macro: 0.3006, Accuracy: 0.3125\n","Epoch 97, Train Loss: 1.2355, Val Loss: 1.8433, F1 Micro: 0.3333, F1 Macro: 0.3300, Accuracy: 0.3333\n","Epoch 98, Train Loss: 1.2313, Val Loss: 1.7599, F1 Micro: 0.4271, F1 Macro: 0.3872, Accuracy: 0.4271\n","Epoch 99, Train Loss: 1.2267, Val Loss: 1.7880, F1 Micro: 0.3542, F1 Macro: 0.3374, Accuracy: 0.3542\n","Epoch 100, Train Loss: 1.2396, Val Loss: 1.9242, F1 Micro: 0.4062, F1 Macro: 0.3613, Accuracy: 0.4062\n","Epoch 101, Train Loss: 1.2747, Val Loss: 1.8531, F1 Micro: 0.3958, F1 Macro: 0.3665, Accuracy: 0.3958\n","Epoch 102, Train Loss: 1.2316, Val Loss: 1.8814, F1 Micro: 0.3750, F1 Macro: 0.3742, Accuracy: 0.3750\n","Epoch 103, Train Loss: 1.2526, Val Loss: 1.8324, F1 Micro: 0.3542, F1 Macro: 0.3340, Accuracy: 0.3542\n","Epoch 104, Train Loss: 1.2172, Val Loss: 1.8365, F1 Micro: 0.3854, F1 Macro: 0.3669, Accuracy: 0.3854\n","Epoch 105, Train Loss: 1.2514, Val Loss: 1.8674, F1 Micro: 0.3438, F1 Macro: 0.3437, Accuracy: 0.3438\n","Epoch 106, Train Loss: 1.2414, Val Loss: 1.9989, F1 Micro: 0.3646, F1 Macro: 0.3457, Accuracy: 0.3646\n","Epoch 107, Train Loss: 1.2071, Val Loss: 1.8179, F1 Micro: 0.3646, F1 Macro: 0.3481, Accuracy: 0.3646\n","Epoch 108, Train Loss: 1.1888, Val Loss: 1.9176, F1 Micro: 0.3229, F1 Macro: 0.3249, Accuracy: 0.3229\n","Epoch 109, Train Loss: 1.2087, Val Loss: 1.8974, F1 Micro: 0.3750, F1 Macro: 0.3270, Accuracy: 0.3750\n","Epoch 110, Train Loss: 1.2195, Val Loss: 1.8166, F1 Micro: 0.3958, F1 Macro: 0.3657, Accuracy: 0.3958\n","Epoch 111, Train Loss: 1.2425, Val Loss: 1.9540, F1 Micro: 0.3646, F1 Macro: 0.3506, Accuracy: 0.3646\n","Epoch 112, Train Loss: 1.1721, Val Loss: 1.8675, F1 Micro: 0.3438, F1 Macro: 0.3441, Accuracy: 0.3438\n","Epoch 113, Train Loss: 1.1913, Val Loss: 1.9523, F1 Micro: 0.3958, F1 Macro: 0.3466, Accuracy: 0.3958\n","Epoch 114, Train Loss: 1.1696, Val Loss: 1.9825, F1 Micro: 0.3438, F1 Macro: 0.3337, Accuracy: 0.3438\n","Epoch 115, Train Loss: 1.1980, Val Loss: 1.9320, F1 Micro: 0.4062, F1 Macro: 0.3856, Accuracy: 0.4062\n","Epoch 116, Train Loss: 1.1500, Val Loss: 1.9849, F1 Micro: 0.3333, F1 Macro: 0.2973, Accuracy: 0.3333\n","Epoch 117, Train Loss: 1.1711, Val Loss: 1.9119, F1 Micro: 0.4271, F1 Macro: 0.4030, Accuracy: 0.4271\n","Epoch 118, Train Loss: 1.1739, Val Loss: 1.8707, F1 Micro: 0.4479, F1 Macro: 0.4253, Accuracy: 0.4479\n","Epoch 119, Train Loss: 1.2021, Val Loss: 1.8883, F1 Micro: 0.3958, F1 Macro: 0.4019, Accuracy: 0.3958\n","Epoch 120, Train Loss: 1.1906, Val Loss: 1.8833, F1 Micro: 0.3646, F1 Macro: 0.3752, Accuracy: 0.3646\n","Epoch 121, Train Loss: 1.1655, Val Loss: 1.8566, F1 Micro: 0.3958, F1 Macro: 0.3904, Accuracy: 0.3958\n","Epoch 122, Train Loss: 1.1704, Val Loss: 1.9497, F1 Micro: 0.3854, F1 Macro: 0.3553, Accuracy: 0.3854\n","Epoch 123, Train Loss: 1.1100, Val Loss: 1.8609, F1 Micro: 0.3750, F1 Macro: 0.3806, Accuracy: 0.3750\n","Epoch 124, Train Loss: 1.0825, Val Loss: 1.9205, F1 Micro: 0.4062, F1 Macro: 0.3952, Accuracy: 0.4062\n","Epoch 125, Train Loss: 1.1409, Val Loss: 1.9582, F1 Micro: 0.3854, F1 Macro: 0.3653, Accuracy: 0.3854\n","Epoch 126, Train Loss: 1.0951, Val Loss: 1.8724, F1 Micro: 0.3958, F1 Macro: 0.3644, Accuracy: 0.3958\n","Epoch 127, Train Loss: 1.1332, Val Loss: 1.9802, F1 Micro: 0.3646, F1 Macro: 0.3286, Accuracy: 0.3646\n","Epoch 128, Train Loss: 1.0517, Val Loss: 1.9023, F1 Micro: 0.4271, F1 Macro: 0.4203, Accuracy: 0.4271\n","Epoch 129, Train Loss: 1.1395, Val Loss: 2.0106, F1 Micro: 0.3854, F1 Macro: 0.3824, Accuracy: 0.3854\n","Epoch 130, Train Loss: 1.0998, Val Loss: 1.8386, F1 Micro: 0.3958, F1 Macro: 0.3621, Accuracy: 0.3958\n","Epoch 131, Train Loss: 1.1075, Val Loss: 1.9754, F1 Micro: 0.4062, F1 Macro: 0.3747, Accuracy: 0.4062\n","Epoch 132, Train Loss: 1.1007, Val Loss: 2.0037, F1 Micro: 0.3646, F1 Macro: 0.3122, Accuracy: 0.3646\n","Epoch 133, Train Loss: 1.1045, Val Loss: 1.9470, F1 Micro: 0.3542, F1 Macro: 0.3486, Accuracy: 0.3542\n","Epoch 134, Train Loss: 1.0451, Val Loss: 1.8793, F1 Micro: 0.4062, F1 Macro: 0.3850, Accuracy: 0.4062\n","Epoch 135, Train Loss: 1.1098, Val Loss: 1.8715, F1 Micro: 0.3854, F1 Macro: 0.4011, Accuracy: 0.3854\n","Epoch 136, Train Loss: 1.0340, Val Loss: 1.9067, F1 Micro: 0.4271, F1 Macro: 0.4009, Accuracy: 0.4271\n","Epoch 137, Train Loss: 1.0597, Val Loss: 1.9092, F1 Micro: 0.4062, F1 Macro: 0.4036, Accuracy: 0.4062\n","Epoch 138, Train Loss: 1.0291, Val Loss: 1.8982, F1 Micro: 0.3646, F1 Macro: 0.3656, Accuracy: 0.3646\n","Epoch 139, Train Loss: 1.0303, Val Loss: 1.8680, F1 Micro: 0.3958, F1 Macro: 0.3999, Accuracy: 0.3958\n","Epoch 140, Train Loss: 1.0519, Val Loss: 1.8080, F1 Micro: 0.3958, F1 Macro: 0.3822, Accuracy: 0.3958\n","Epoch 141, Train Loss: 1.0221, Val Loss: 1.9245, F1 Micro: 0.3646, F1 Macro: 0.3737, Accuracy: 0.3646\n","Epoch 142, Train Loss: 1.0524, Val Loss: 1.9855, F1 Micro: 0.3958, F1 Macro: 0.3683, Accuracy: 0.3958\n","Epoch 143, Train Loss: 1.0560, Val Loss: 2.0689, F1 Micro: 0.3646, F1 Macro: 0.3372, Accuracy: 0.3646\n","Epoch 144, Train Loss: 1.0541, Val Loss: 2.1363, F1 Micro: 0.3646, F1 Macro: 0.3589, Accuracy: 0.3646\n","Epoch 145, Train Loss: 1.0020, Val Loss: 1.9933, F1 Micro: 0.3854, F1 Macro: 0.3878, Accuracy: 0.3854\n","Epoch 146, Train Loss: 1.0020, Val Loss: 2.0571, F1 Micro: 0.4062, F1 Macro: 0.3734, Accuracy: 0.4062\n","Epoch 147, Train Loss: 1.0096, Val Loss: 1.9338, F1 Micro: 0.4271, F1 Macro: 0.4105, Accuracy: 0.4271\n","Epoch 148, Train Loss: 0.9989, Val Loss: 1.8663, F1 Micro: 0.4583, F1 Macro: 0.4670, Accuracy: 0.4583\n","Epoch 149, Train Loss: 0.9518, Val Loss: 2.0679, F1 Micro: 0.4375, F1 Macro: 0.4313, Accuracy: 0.4375\n","Epoch 150, Train Loss: 0.9394, Val Loss: 2.0186, F1 Micro: 0.4271, F1 Macro: 0.4249, Accuracy: 0.4271\n","Epoch 151, Train Loss: 0.9566, Val Loss: 1.9934, F1 Micro: 0.4479, F1 Macro: 0.4335, Accuracy: 0.4479\n","Epoch 152, Train Loss: 0.9876, Val Loss: 1.9945, F1 Micro: 0.4062, F1 Macro: 0.3866, Accuracy: 0.4062\n","Epoch 153, Train Loss: 0.9934, Val Loss: 1.9346, F1 Micro: 0.4375, F1 Macro: 0.4357, Accuracy: 0.4375\n","Epoch 154, Train Loss: 0.9625, Val Loss: 1.9328, F1 Micro: 0.4583, F1 Macro: 0.4540, Accuracy: 0.4583\n","Epoch 155, Train Loss: 1.0155, Val Loss: 1.9463, F1 Micro: 0.4479, F1 Macro: 0.4463, Accuracy: 0.4479\n","Epoch 156, Train Loss: 0.9290, Val Loss: 2.0742, F1 Micro: 0.4583, F1 Macro: 0.4353, Accuracy: 0.4583\n","Epoch 157, Train Loss: 0.9565, Val Loss: 2.1037, F1 Micro: 0.3750, F1 Macro: 0.3700, Accuracy: 0.3750\n","Epoch 158, Train Loss: 0.9624, Val Loss: 1.9637, F1 Micro: 0.4062, F1 Macro: 0.4079, Accuracy: 0.4062\n","Epoch 159, Train Loss: 0.9468, Val Loss: 2.0871, F1 Micro: 0.4167, F1 Macro: 0.4044, Accuracy: 0.4167\n","Epoch 160, Train Loss: 0.9595, Val Loss: 2.0579, F1 Micro: 0.4167, F1 Macro: 0.3905, Accuracy: 0.4167\n","Epoch 161, Train Loss: 0.9389, Val Loss: 1.9509, F1 Micro: 0.4583, F1 Macro: 0.4522, Accuracy: 0.4583\n","Epoch 162, Train Loss: 1.0086, Val Loss: 2.1577, F1 Micro: 0.3958, F1 Macro: 0.3777, Accuracy: 0.3958\n","Epoch 163, Train Loss: 0.9780, Val Loss: 2.1731, F1 Micro: 0.3854, F1 Macro: 0.3866, Accuracy: 0.3854\n","Epoch 164, Train Loss: 0.9463, Val Loss: 2.1712, F1 Micro: 0.3646, F1 Macro: 0.3470, Accuracy: 0.3646\n","Epoch 165, Train Loss: 0.9395, Val Loss: 2.0489, F1 Micro: 0.4062, F1 Macro: 0.3881, Accuracy: 0.4062\n","Epoch 166, Train Loss: 0.9109, Val Loss: 2.0285, F1 Micro: 0.3854, F1 Macro: 0.3710, Accuracy: 0.3854\n","Epoch 167, Train Loss: 0.8815, Val Loss: 2.0845, F1 Micro: 0.4375, F1 Macro: 0.4196, Accuracy: 0.4375\n","Epoch 168, Train Loss: 0.8642, Val Loss: 2.0805, F1 Micro: 0.3854, F1 Macro: 0.3791, Accuracy: 0.3854\n","Epoch 169, Train Loss: 0.8771, Val Loss: 2.1080, F1 Micro: 0.4375, F1 Macro: 0.4297, Accuracy: 0.4375\n","Epoch 170, Train Loss: 0.8383, Val Loss: 2.0421, F1 Micro: 0.4167, F1 Macro: 0.4171, Accuracy: 0.4167\n","Epoch 171, Train Loss: 0.8598, Val Loss: 2.1184, F1 Micro: 0.4688, F1 Macro: 0.4640, Accuracy: 0.4688\n","Epoch 172, Train Loss: 0.9265, Val Loss: 2.2204, F1 Micro: 0.4479, F1 Macro: 0.4351, Accuracy: 0.4479\n","Epoch 173, Train Loss: 0.8828, Val Loss: 2.3138, F1 Micro: 0.4167, F1 Macro: 0.4070, Accuracy: 0.4167\n","Epoch 174, Train Loss: 0.8627, Val Loss: 2.1918, F1 Micro: 0.4583, F1 Macro: 0.4300, Accuracy: 0.4583\n","Epoch 175, Train Loss: 0.8963, Val Loss: 2.0327, F1 Micro: 0.4583, F1 Macro: 0.4477, Accuracy: 0.4583\n","Epoch 176, Train Loss: 0.8191, Val Loss: 2.0115, F1 Micro: 0.4792, F1 Macro: 0.4812, Accuracy: 0.4792\n","Epoch 177, Train Loss: 0.8603, Val Loss: 2.1506, F1 Micro: 0.4688, F1 Macro: 0.4544, Accuracy: 0.4688\n","Epoch 178, Train Loss: 0.8000, Val Loss: 2.0534, F1 Micro: 0.4167, F1 Macro: 0.4134, Accuracy: 0.4167\n","Epoch 179, Train Loss: 0.8540, Val Loss: 2.1949, F1 Micro: 0.3958, F1 Macro: 0.3825, Accuracy: 0.3958\n","Epoch 180, Train Loss: 0.8393, Val Loss: 2.0826, F1 Micro: 0.4792, F1 Macro: 0.4825, Accuracy: 0.4792\n","Epoch 181, Train Loss: 0.8268, Val Loss: 2.1394, F1 Micro: 0.4271, F1 Macro: 0.4294, Accuracy: 0.4271\n","Epoch 182, Train Loss: 0.8017, Val Loss: 2.1154, F1 Micro: 0.4375, F1 Macro: 0.4376, Accuracy: 0.4375\n","Epoch 183, Train Loss: 0.7637, Val Loss: 2.1005, F1 Micro: 0.4583, F1 Macro: 0.4489, Accuracy: 0.4583\n","Epoch 184, Train Loss: 0.7989, Val Loss: 2.3674, F1 Micro: 0.3854, F1 Macro: 0.3768, Accuracy: 0.3854\n","Epoch 185, Train Loss: 0.9283, Val Loss: 2.1626, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 186, Train Loss: 0.8600, Val Loss: 2.1185, F1 Micro: 0.4271, F1 Macro: 0.4321, Accuracy: 0.4271\n","Epoch 187, Train Loss: 0.7858, Val Loss: 2.2762, F1 Micro: 0.3542, F1 Macro: 0.3443, Accuracy: 0.3542\n","Epoch 188, Train Loss: 0.8287, Val Loss: 2.1733, F1 Micro: 0.4479, F1 Macro: 0.4438, Accuracy: 0.4479\n","Epoch 189, Train Loss: 0.7499, Val Loss: 2.0570, F1 Micro: 0.4792, F1 Macro: 0.4806, Accuracy: 0.4792\n","Epoch 190, Train Loss: 0.7627, Val Loss: 2.1845, F1 Micro: 0.4271, F1 Macro: 0.4332, Accuracy: 0.4271\n","Epoch 191, Train Loss: 0.8245, Val Loss: 2.1235, F1 Micro: 0.4583, F1 Macro: 0.4587, Accuracy: 0.4583\n","Epoch 192, Train Loss: 0.7873, Val Loss: 2.1084, F1 Micro: 0.4167, F1 Macro: 0.4112, Accuracy: 0.4167\n","Epoch 193, Train Loss: 0.7542, Val Loss: 2.2451, F1 Micro: 0.4479, F1 Macro: 0.4277, Accuracy: 0.4479\n","Epoch 194, Train Loss: 0.7294, Val Loss: 2.1720, F1 Micro: 0.4271, F1 Macro: 0.4292, Accuracy: 0.4271\n","Epoch 195, Train Loss: 0.7688, Val Loss: 2.2051, F1 Micro: 0.4479, F1 Macro: 0.4254, Accuracy: 0.4479\n","Epoch 196, Train Loss: 0.7759, Val Loss: 2.3673, F1 Micro: 0.4479, F1 Macro: 0.4198, Accuracy: 0.4479\n","Epoch 197, Train Loss: 0.8070, Val Loss: 2.3060, F1 Micro: 0.4062, F1 Macro: 0.3881, Accuracy: 0.4062\n","Epoch 198, Train Loss: 0.7826, Val Loss: 2.2885, F1 Micro: 0.3854, F1 Macro: 0.3943, Accuracy: 0.3854\n","Epoch 199, Train Loss: 0.7802, Val Loss: 2.2515, F1 Micro: 0.4271, F1 Macro: 0.4221, Accuracy: 0.4271\n","Epoch 200, Train Loss: 0.8197, Val Loss: 2.1971, F1 Micro: 0.4896, F1 Macro: 0.4933, Accuracy: 0.4896\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.4759, Val Loss: 2.0787, F1 Micro: 0.2708, F1 Macro: 0.2159, Accuracy: 0.2708\n","Epoch 2, Train Loss: 2.3641, Val Loss: 1.7778, F1 Micro: 0.2500, F1 Macro: 0.2107, Accuracy: 0.2500\n","Epoch 3, Train Loss: 2.0845, Val Loss: 1.8071, F1 Micro: 0.2396, F1 Macro: 0.2214, Accuracy: 0.2396\n","Epoch 4, Train Loss: 2.1306, Val Loss: 1.7068, F1 Micro: 0.3021, F1 Macro: 0.2579, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.9796, Val Loss: 1.8079, F1 Micro: 0.2500, F1 Macro: 0.1739, Accuracy: 0.2500\n","Epoch 6, Train Loss: 1.8706, Val Loss: 1.8341, F1 Micro: 0.2604, F1 Macro: 0.1995, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.8488, Val Loss: 1.7858, F1 Micro: 0.3125, F1 Macro: 0.2518, Accuracy: 0.3125\n","Epoch 8, Train Loss: 1.8571, Val Loss: 1.6863, F1 Micro: 0.3229, F1 Macro: 0.2545, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.8051, Val Loss: 1.7246, F1 Micro: 0.3125, F1 Macro: 0.2629, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.7133, Val Loss: 1.6850, F1 Micro: 0.2708, F1 Macro: 0.1864, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.8673, Val Loss: 1.6748, F1 Micro: 0.3229, F1 Macro: 0.3071, Accuracy: 0.3229\n","Epoch 12, Train Loss: 1.8086, Val Loss: 1.6548, F1 Micro: 0.3542, F1 Macro: 0.2811, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.7434, Val Loss: 1.6924, F1 Micro: 0.2812, F1 Macro: 0.2456, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.7348, Val Loss: 1.6881, F1 Micro: 0.3125, F1 Macro: 0.2495, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.6906, Val Loss: 1.6711, F1 Micro: 0.3646, F1 Macro: 0.3088, Accuracy: 0.3646\n","Epoch 16, Train Loss: 1.7158, Val Loss: 1.6369, F1 Micro: 0.3229, F1 Macro: 0.2705, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.7267, Val Loss: 1.6622, F1 Micro: 0.3542, F1 Macro: 0.2870, Accuracy: 0.3542\n","Epoch 18, Train Loss: 1.7277, Val Loss: 1.6306, F1 Micro: 0.3125, F1 Macro: 0.2607, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.6848, Val Loss: 1.6884, F1 Micro: 0.2708, F1 Macro: 0.2373, Accuracy: 0.2708\n","Epoch 20, Train Loss: 1.7018, Val Loss: 1.6596, F1 Micro: 0.3125, F1 Macro: 0.2511, Accuracy: 0.3125\n","Epoch 21, Train Loss: 1.6863, Val Loss: 1.6456, F1 Micro: 0.2917, F1 Macro: 0.2536, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.7131, Val Loss: 1.6484, F1 Micro: 0.3333, F1 Macro: 0.2718, Accuracy: 0.3333\n","Epoch 23, Train Loss: 1.6990, Val Loss: 1.7153, F1 Micro: 0.3021, F1 Macro: 0.2223, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.7020, Val Loss: 1.6560, F1 Micro: 0.3542, F1 Macro: 0.2764, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.6580, Val Loss: 1.6363, F1 Micro: 0.3229, F1 Macro: 0.2512, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.6683, Val Loss: 1.6586, F1 Micro: 0.3542, F1 Macro: 0.2962, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.6383, Val Loss: 1.6391, F1 Micro: 0.3333, F1 Macro: 0.2748, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.6694, Val Loss: 1.7048, F1 Micro: 0.3229, F1 Macro: 0.2658, Accuracy: 0.3229\n","Epoch 29, Train Loss: 1.6609, Val Loss: 1.6476, F1 Micro: 0.3646, F1 Macro: 0.3180, Accuracy: 0.3646\n","Epoch 30, Train Loss: 1.6750, Val Loss: 1.6415, F1 Micro: 0.3542, F1 Macro: 0.3318, Accuracy: 0.3542\n","Epoch 31, Train Loss: 1.6138, Val Loss: 1.6648, F1 Micro: 0.3021, F1 Macro: 0.2821, Accuracy: 0.3021\n","Epoch 32, Train Loss: 1.6078, Val Loss: 1.6172, F1 Micro: 0.3750, F1 Macro: 0.3419, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.6979, Val Loss: 1.6477, F1 Micro: 0.3333, F1 Macro: 0.2655, Accuracy: 0.3333\n","Epoch 34, Train Loss: 1.6065, Val Loss: 1.6062, F1 Micro: 0.3854, F1 Macro: 0.3490, Accuracy: 0.3854\n","Epoch 35, Train Loss: 1.6353, Val Loss: 1.6645, F1 Micro: 0.3333, F1 Macro: 0.2892, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.6356, Val Loss: 1.5891, F1 Micro: 0.3542, F1 Macro: 0.3108, Accuracy: 0.3542\n","Epoch 37, Train Loss: 1.5953, Val Loss: 1.6451, F1 Micro: 0.3750, F1 Macro: 0.3212, Accuracy: 0.3750\n","Epoch 38, Train Loss: 1.6529, Val Loss: 1.6087, F1 Micro: 0.3229, F1 Macro: 0.2816, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.6052, Val Loss: 1.6035, F1 Micro: 0.3854, F1 Macro: 0.3617, Accuracy: 0.3854\n","Epoch 40, Train Loss: 1.6429, Val Loss: 1.6683, F1 Micro: 0.3333, F1 Macro: 0.3074, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.5986, Val Loss: 1.5810, F1 Micro: 0.3750, F1 Macro: 0.3296, Accuracy: 0.3750\n","Epoch 42, Train Loss: 1.5658, Val Loss: 1.6123, F1 Micro: 0.4062, F1 Macro: 0.3457, Accuracy: 0.4062\n","Epoch 43, Train Loss: 1.6075, Val Loss: 1.6525, F1 Micro: 0.3438, F1 Macro: 0.3255, Accuracy: 0.3438\n","Epoch 44, Train Loss: 1.5931, Val Loss: 1.6553, F1 Micro: 0.3750, F1 Macro: 0.3145, Accuracy: 0.3750\n","Epoch 45, Train Loss: 1.5921, Val Loss: 1.5559, F1 Micro: 0.3438, F1 Macro: 0.3369, Accuracy: 0.3438\n","Epoch 46, Train Loss: 1.5593, Val Loss: 1.6858, F1 Micro: 0.3333, F1 Macro: 0.2906, Accuracy: 0.3333\n","Epoch 47, Train Loss: 1.6099, Val Loss: 1.5945, F1 Micro: 0.3333, F1 Macro: 0.2804, Accuracy: 0.3333\n","Epoch 48, Train Loss: 1.5614, Val Loss: 1.5762, F1 Micro: 0.3646, F1 Macro: 0.3163, Accuracy: 0.3646\n","Epoch 49, Train Loss: 1.5621, Val Loss: 1.6028, F1 Micro: 0.3021, F1 Macro: 0.2791, Accuracy: 0.3021\n","Epoch 50, Train Loss: 1.5800, Val Loss: 1.5793, F1 Micro: 0.4167, F1 Macro: 0.3719, Accuracy: 0.4167\n","Epoch 51, Train Loss: 1.5811, Val Loss: 1.6826, F1 Micro: 0.3125, F1 Macro: 0.3037, Accuracy: 0.3125\n","Epoch 52, Train Loss: 1.5888, Val Loss: 1.6148, F1 Micro: 0.3958, F1 Macro: 0.3548, Accuracy: 0.3958\n","Epoch 53, Train Loss: 1.5474, Val Loss: 1.5982, F1 Micro: 0.3438, F1 Macro: 0.3275, Accuracy: 0.3438\n","Epoch 54, Train Loss: 1.5062, Val Loss: 1.5372, F1 Micro: 0.4375, F1 Macro: 0.4205, Accuracy: 0.4375\n","Epoch 55, Train Loss: 1.5275, Val Loss: 1.6474, F1 Micro: 0.3125, F1 Macro: 0.2908, Accuracy: 0.3125\n","Epoch 56, Train Loss: 1.5330, Val Loss: 1.5903, F1 Micro: 0.3854, F1 Macro: 0.3546, Accuracy: 0.3854\n","Epoch 57, Train Loss: 1.5260, Val Loss: 1.5579, F1 Micro: 0.4062, F1 Macro: 0.3541, Accuracy: 0.4062\n","Epoch 58, Train Loss: 1.4682, Val Loss: 1.6000, F1 Micro: 0.4167, F1 Macro: 0.4132, Accuracy: 0.4167\n","Epoch 59, Train Loss: 1.5334, Val Loss: 1.5760, F1 Micro: 0.3958, F1 Macro: 0.3489, Accuracy: 0.3958\n","Epoch 60, Train Loss: 1.5249, Val Loss: 1.5937, F1 Micro: 0.3542, F1 Macro: 0.3182, Accuracy: 0.3542\n","Epoch 61, Train Loss: 1.4668, Val Loss: 1.5278, F1 Micro: 0.4062, F1 Macro: 0.4026, Accuracy: 0.4062\n","Epoch 62, Train Loss: 1.5183, Val Loss: 1.5334, F1 Micro: 0.3958, F1 Macro: 0.3750, Accuracy: 0.3958\n","Epoch 63, Train Loss: 1.5692, Val Loss: 1.5301, F1 Micro: 0.3750, F1 Macro: 0.3534, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.4669, Val Loss: 1.5359, F1 Micro: 0.4375, F1 Macro: 0.4406, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.4694, Val Loss: 1.5366, F1 Micro: 0.4062, F1 Macro: 0.3705, Accuracy: 0.4062\n","Epoch 66, Train Loss: 1.4727, Val Loss: 1.5261, F1 Micro: 0.3958, F1 Macro: 0.3785, Accuracy: 0.3958\n","Epoch 67, Train Loss: 1.4717, Val Loss: 1.5829, F1 Micro: 0.3438, F1 Macro: 0.3569, Accuracy: 0.3438\n","Epoch 68, Train Loss: 1.4430, Val Loss: 1.5381, F1 Micro: 0.3542, F1 Macro: 0.3549, Accuracy: 0.3542\n","Epoch 69, Train Loss: 1.4367, Val Loss: 1.4917, F1 Micro: 0.4062, F1 Macro: 0.4023, Accuracy: 0.4062\n","Epoch 70, Train Loss: 1.4524, Val Loss: 1.6369, F1 Micro: 0.3958, F1 Macro: 0.3671, Accuracy: 0.3958\n","Epoch 71, Train Loss: 1.4673, Val Loss: 1.6277, F1 Micro: 0.4375, F1 Macro: 0.4218, Accuracy: 0.4375\n","Epoch 72, Train Loss: 1.5063, Val Loss: 1.5645, F1 Micro: 0.3958, F1 Macro: 0.3628, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.4583, Val Loss: 1.5957, F1 Micro: 0.4062, F1 Macro: 0.3782, Accuracy: 0.4062\n","Epoch 74, Train Loss: 1.4410, Val Loss: 1.5660, F1 Micro: 0.3750, F1 Macro: 0.3346, Accuracy: 0.3750\n","Epoch 75, Train Loss: 1.4177, Val Loss: 1.5446, F1 Micro: 0.3958, F1 Macro: 0.3500, Accuracy: 0.3958\n","Epoch 76, Train Loss: 1.4329, Val Loss: 1.5752, F1 Micro: 0.4271, F1 Macro: 0.4098, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.4362, Val Loss: 1.5132, F1 Micro: 0.4271, F1 Macro: 0.4171, Accuracy: 0.4271\n","Epoch 78, Train Loss: 1.4578, Val Loss: 1.4942, F1 Micro: 0.4479, F1 Macro: 0.4354, Accuracy: 0.4479\n","Epoch 79, Train Loss: 1.4755, Val Loss: 1.5134, F1 Micro: 0.4271, F1 Macro: 0.3904, Accuracy: 0.4271\n","Epoch 80, Train Loss: 1.3913, Val Loss: 1.5604, F1 Micro: 0.4479, F1 Macro: 0.4437, Accuracy: 0.4479\n","Epoch 81, Train Loss: 1.4021, Val Loss: 1.5537, F1 Micro: 0.3646, F1 Macro: 0.3650, Accuracy: 0.3646\n","Epoch 82, Train Loss: 1.3778, Val Loss: 1.5342, F1 Micro: 0.4583, F1 Macro: 0.4098, Accuracy: 0.4583\n","Epoch 83, Train Loss: 1.3911, Val Loss: 1.6790, F1 Micro: 0.3646, F1 Macro: 0.3493, Accuracy: 0.3646\n","Epoch 84, Train Loss: 1.4173, Val Loss: 1.5211, F1 Micro: 0.4271, F1 Macro: 0.3948, Accuracy: 0.4271\n","Epoch 85, Train Loss: 1.3900, Val Loss: 1.5776, F1 Micro: 0.3750, F1 Macro: 0.3527, Accuracy: 0.3750\n","Epoch 86, Train Loss: 1.3732, Val Loss: 1.5278, F1 Micro: 0.3750, F1 Macro: 0.3662, Accuracy: 0.3750\n","Epoch 87, Train Loss: 1.3423, Val Loss: 1.4804, F1 Micro: 0.5104, F1 Macro: 0.5070, Accuracy: 0.5104\n","Epoch 88, Train Loss: 1.3653, Val Loss: 1.6268, F1 Micro: 0.3021, F1 Macro: 0.2779, Accuracy: 0.3021\n","Epoch 89, Train Loss: 1.3498, Val Loss: 1.5071, F1 Micro: 0.4375, F1 Macro: 0.4065, Accuracy: 0.4375\n","Epoch 90, Train Loss: 1.3715, Val Loss: 1.5601, F1 Micro: 0.4062, F1 Macro: 0.3904, Accuracy: 0.4062\n","Epoch 91, Train Loss: 1.3513, Val Loss: 1.5122, F1 Micro: 0.4792, F1 Macro: 0.4792, Accuracy: 0.4792\n","Epoch 92, Train Loss: 1.3833, Val Loss: 1.5408, F1 Micro: 0.3854, F1 Macro: 0.3826, Accuracy: 0.3854\n","Epoch 93, Train Loss: 1.3254, Val Loss: 1.5211, F1 Micro: 0.5104, F1 Macro: 0.4996, Accuracy: 0.5104\n","Epoch 94, Train Loss: 1.3764, Val Loss: 1.5664, F1 Micro: 0.4167, F1 Macro: 0.3857, Accuracy: 0.4167\n","Epoch 95, Train Loss: 1.3715, Val Loss: 1.5171, F1 Micro: 0.4167, F1 Macro: 0.4086, Accuracy: 0.4167\n","Epoch 96, Train Loss: 1.3896, Val Loss: 1.5271, F1 Micro: 0.4479, F1 Macro: 0.4312, Accuracy: 0.4479\n","Epoch 97, Train Loss: 1.3148, Val Loss: 1.5115, F1 Micro: 0.5000, F1 Macro: 0.4855, Accuracy: 0.5000\n","Epoch 98, Train Loss: 1.3812, Val Loss: 1.4867, F1 Micro: 0.4062, F1 Macro: 0.4084, Accuracy: 0.4062\n","Epoch 99, Train Loss: 1.2987, Val Loss: 1.5604, F1 Micro: 0.4271, F1 Macro: 0.4155, Accuracy: 0.4271\n","Epoch 100, Train Loss: 1.3236, Val Loss: 1.6182, F1 Micro: 0.3854, F1 Macro: 0.3533, Accuracy: 0.3854\n","Epoch 101, Train Loss: 1.3480, Val Loss: 1.5637, F1 Micro: 0.4062, F1 Macro: 0.3765, Accuracy: 0.4062\n","Epoch 102, Train Loss: 1.2775, Val Loss: 1.5066, F1 Micro: 0.4583, F1 Macro: 0.4399, Accuracy: 0.4583\n","Epoch 103, Train Loss: 1.2903, Val Loss: 1.6101, F1 Micro: 0.3854, F1 Macro: 0.3439, Accuracy: 0.3854\n","Epoch 104, Train Loss: 1.2801, Val Loss: 1.5074, F1 Micro: 0.4271, F1 Macro: 0.4280, Accuracy: 0.4271\n","Epoch 105, Train Loss: 1.2516, Val Loss: 1.5250, F1 Micro: 0.4167, F1 Macro: 0.3938, Accuracy: 0.4167\n","Epoch 106, Train Loss: 1.2890, Val Loss: 1.6112, F1 Micro: 0.3750, F1 Macro: 0.3594, Accuracy: 0.3750\n","Epoch 107, Train Loss: 1.3167, Val Loss: 1.5548, F1 Micro: 0.4688, F1 Macro: 0.4519, Accuracy: 0.4688\n","Epoch 108, Train Loss: 1.2922, Val Loss: 1.5220, F1 Micro: 0.5000, F1 Macro: 0.4752, Accuracy: 0.5000\n","Epoch 109, Train Loss: 1.2527, Val Loss: 1.5150, F1 Micro: 0.4896, F1 Macro: 0.4843, Accuracy: 0.4896\n","Epoch 110, Train Loss: 1.2858, Val Loss: 1.5024, F1 Micro: 0.4792, F1 Macro: 0.4706, Accuracy: 0.4792\n","Epoch 111, Train Loss: 1.2536, Val Loss: 1.4960, F1 Micro: 0.4792, F1 Macro: 0.4681, Accuracy: 0.4792\n","Epoch 112, Train Loss: 1.2474, Val Loss: 1.6209, F1 Micro: 0.4167, F1 Macro: 0.3719, Accuracy: 0.4167\n","Epoch 113, Train Loss: 1.3014, Val Loss: 1.5091, F1 Micro: 0.4792, F1 Macro: 0.4691, Accuracy: 0.4792\n","Epoch 114, Train Loss: 1.2359, Val Loss: 1.6776, F1 Micro: 0.3958, F1 Macro: 0.3932, Accuracy: 0.3958\n","Epoch 115, Train Loss: 1.2047, Val Loss: 1.5854, F1 Micro: 0.3958, F1 Macro: 0.3920, Accuracy: 0.3958\n","Epoch 116, Train Loss: 1.3047, Val Loss: 1.5681, F1 Micro: 0.4062, F1 Macro: 0.3681, Accuracy: 0.4062\n","Epoch 117, Train Loss: 1.2875, Val Loss: 1.5529, F1 Micro: 0.4375, F1 Macro: 0.4246, Accuracy: 0.4375\n","Epoch 118, Train Loss: 1.2269, Val Loss: 1.5261, F1 Micro: 0.5417, F1 Macro: 0.5339, Accuracy: 0.5417\n","Epoch 119, Train Loss: 1.2037, Val Loss: 1.7137, F1 Micro: 0.3958, F1 Macro: 0.3789, Accuracy: 0.3958\n","Epoch 120, Train Loss: 1.2377, Val Loss: 1.5760, F1 Micro: 0.4375, F1 Macro: 0.4030, Accuracy: 0.4375\n","Epoch 121, Train Loss: 1.1805, Val Loss: 1.6565, F1 Micro: 0.3854, F1 Macro: 0.3578, Accuracy: 0.3854\n","Epoch 122, Train Loss: 1.2575, Val Loss: 1.6467, F1 Micro: 0.3438, F1 Macro: 0.3136, Accuracy: 0.3438\n","Epoch 123, Train Loss: 1.2254, Val Loss: 1.5025, F1 Micro: 0.4479, F1 Macro: 0.4334, Accuracy: 0.4479\n","Epoch 124, Train Loss: 1.2288, Val Loss: 1.6500, F1 Micro: 0.4479, F1 Macro: 0.4430, Accuracy: 0.4479\n","Epoch 125, Train Loss: 1.1977, Val Loss: 1.4910, F1 Micro: 0.5208, F1 Macro: 0.5101, Accuracy: 0.5208\n","Epoch 126, Train Loss: 1.1650, Val Loss: 1.6812, F1 Micro: 0.4271, F1 Macro: 0.4244, Accuracy: 0.4271\n","Epoch 127, Train Loss: 1.1978, Val Loss: 1.5680, F1 Micro: 0.4167, F1 Macro: 0.3917, Accuracy: 0.4167\n","Epoch 128, Train Loss: 1.1672, Val Loss: 1.6504, F1 Micro: 0.4271, F1 Macro: 0.4076, Accuracy: 0.4271\n","Epoch 129, Train Loss: 1.2099, Val Loss: 1.5893, F1 Micro: 0.4896, F1 Macro: 0.4660, Accuracy: 0.4896\n","Epoch 130, Train Loss: 1.1598, Val Loss: 1.6487, F1 Micro: 0.4479, F1 Macro: 0.4332, Accuracy: 0.4479\n","Epoch 131, Train Loss: 1.2181, Val Loss: 1.5983, F1 Micro: 0.4896, F1 Macro: 0.4953, Accuracy: 0.4896\n","Epoch 132, Train Loss: 1.1141, Val Loss: 1.5307, F1 Micro: 0.4375, F1 Macro: 0.4086, Accuracy: 0.4375\n","Epoch 133, Train Loss: 1.1194, Val Loss: 1.6352, F1 Micro: 0.4375, F1 Macro: 0.4273, Accuracy: 0.4375\n","Epoch 134, Train Loss: 1.1106, Val Loss: 1.5460, F1 Micro: 0.4896, F1 Macro: 0.4897, Accuracy: 0.4896\n","Epoch 135, Train Loss: 1.1643, Val Loss: 1.5457, F1 Micro: 0.5104, F1 Macro: 0.5097, Accuracy: 0.5104\n","Epoch 136, Train Loss: 1.1381, Val Loss: 1.5916, F1 Micro: 0.5000, F1 Macro: 0.4937, Accuracy: 0.5000\n","Epoch 137, Train Loss: 1.1887, Val Loss: 1.6146, F1 Micro: 0.5000, F1 Macro: 0.4933, Accuracy: 0.5000\n","Epoch 138, Train Loss: 1.1103, Val Loss: 1.6309, F1 Micro: 0.4583, F1 Macro: 0.4481, Accuracy: 0.4583\n","Epoch 139, Train Loss: 1.0974, Val Loss: 1.6121, F1 Micro: 0.4583, F1 Macro: 0.4546, Accuracy: 0.4583\n","Epoch 140, Train Loss: 1.0944, Val Loss: 1.5652, F1 Micro: 0.5104, F1 Macro: 0.5004, Accuracy: 0.5104\n","Epoch 141, Train Loss: 1.1500, Val Loss: 1.5466, F1 Micro: 0.5104, F1 Macro: 0.5100, Accuracy: 0.5104\n","Epoch 142, Train Loss: 1.0596, Val Loss: 1.5607, F1 Micro: 0.5000, F1 Macro: 0.4994, Accuracy: 0.5000\n","Epoch 143, Train Loss: 1.0765, Val Loss: 1.5587, F1 Micro: 0.5312, F1 Macro: 0.5212, Accuracy: 0.5312\n","Epoch 144, Train Loss: 1.0937, Val Loss: 1.5395, F1 Micro: 0.5000, F1 Macro: 0.5029, Accuracy: 0.5000\n","Epoch 145, Train Loss: 1.0265, Val Loss: 1.7414, F1 Micro: 0.4062, F1 Macro: 0.3882, Accuracy: 0.4062\n","Epoch 146, Train Loss: 1.0917, Val Loss: 1.6241, F1 Micro: 0.4688, F1 Macro: 0.4575, Accuracy: 0.4688\n","Epoch 147, Train Loss: 1.0356, Val Loss: 1.6821, F1 Micro: 0.4479, F1 Macro: 0.4376, Accuracy: 0.4479\n","Epoch 148, Train Loss: 1.1175, Val Loss: 1.6544, F1 Micro: 0.5104, F1 Macro: 0.4991, Accuracy: 0.5104\n","Epoch 149, Train Loss: 1.1900, Val Loss: 1.7205, F1 Micro: 0.3854, F1 Macro: 0.3694, Accuracy: 0.3854\n","Epoch 150, Train Loss: 1.0972, Val Loss: 1.6159, F1 Micro: 0.4688, F1 Macro: 0.4638, Accuracy: 0.4688\n","Epoch 151, Train Loss: 1.0582, Val Loss: 1.6241, F1 Micro: 0.4688, F1 Macro: 0.4669, Accuracy: 0.4688\n","Epoch 152, Train Loss: 1.0200, Val Loss: 1.7142, F1 Micro: 0.4896, F1 Macro: 0.4881, Accuracy: 0.4896\n","Epoch 153, Train Loss: 1.0511, Val Loss: 1.7995, F1 Micro: 0.3438, F1 Macro: 0.3290, Accuracy: 0.3438\n","Epoch 154, Train Loss: 1.0688, Val Loss: 1.5929, F1 Micro: 0.4375, F1 Macro: 0.4251, Accuracy: 0.4375\n","Epoch 155, Train Loss: 0.9941, Val Loss: 1.6063, F1 Micro: 0.4688, F1 Macro: 0.4599, Accuracy: 0.4688\n","Epoch 156, Train Loss: 1.0558, Val Loss: 1.6525, F1 Micro: 0.5000, F1 Macro: 0.4979, Accuracy: 0.5000\n","Epoch 157, Train Loss: 1.0448, Val Loss: 1.6396, F1 Micro: 0.4792, F1 Macro: 0.4652, Accuracy: 0.4792\n","Epoch 158, Train Loss: 0.9833, Val Loss: 1.6465, F1 Micro: 0.4896, F1 Macro: 0.4791, Accuracy: 0.4896\n","Epoch 159, Train Loss: 1.0203, Val Loss: 1.6215, F1 Micro: 0.5208, F1 Macro: 0.5162, Accuracy: 0.5208\n","Epoch 160, Train Loss: 1.0098, Val Loss: 1.5659, F1 Micro: 0.5000, F1 Macro: 0.4834, Accuracy: 0.5000\n","Epoch 161, Train Loss: 1.0545, Val Loss: 1.9627, F1 Micro: 0.3438, F1 Macro: 0.3329, Accuracy: 0.3438\n","Epoch 162, Train Loss: 1.0461, Val Loss: 1.5972, F1 Micro: 0.5312, F1 Macro: 0.5300, Accuracy: 0.5312\n","Epoch 163, Train Loss: 0.9826, Val Loss: 1.6733, F1 Micro: 0.4896, F1 Macro: 0.4857, Accuracy: 0.4896\n","Epoch 164, Train Loss: 1.0551, Val Loss: 1.7439, F1 Micro: 0.5104, F1 Macro: 0.5033, Accuracy: 0.5104\n","Epoch 165, Train Loss: 0.9418, Val Loss: 1.5933, F1 Micro: 0.4896, F1 Macro: 0.4826, Accuracy: 0.4896\n","Epoch 166, Train Loss: 0.9519, Val Loss: 1.7166, F1 Micro: 0.4792, F1 Macro: 0.4748, Accuracy: 0.4792\n","Epoch 167, Train Loss: 0.9743, Val Loss: 1.6649, F1 Micro: 0.4583, F1 Macro: 0.4395, Accuracy: 0.4583\n","Epoch 168, Train Loss: 0.9542, Val Loss: 1.6194, F1 Micro: 0.4792, F1 Macro: 0.4713, Accuracy: 0.4792\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.5208333333333333\n","Best hyperparameters for Outer FOLD 3: (0.001, 8, 50) with score 0.5625\n","Epoch 1, Train Loss: 3.2979, Val Loss: 2.6698, F1 Micro: 0.1667, F1 Macro: 0.1217, Accuracy: 0.1667\n","Epoch 2, Train Loss: 2.3329, Val Loss: 2.1434, F1 Micro: 0.2000, F1 Macro: 0.1250, Accuracy: 0.2000\n","Epoch 3, Train Loss: 1.9435, Val Loss: 2.0216, F1 Micro: 0.1667, F1 Macro: 0.0628, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.8804, Val Loss: 1.7792, F1 Micro: 0.2750, F1 Macro: 0.2074, Accuracy: 0.2750\n","Epoch 5, Train Loss: 1.8462, Val Loss: 2.0758, F1 Micro: 0.1667, F1 Macro: 0.0632, Accuracy: 0.1667\n","Epoch 6, Train Loss: 1.7802, Val Loss: 1.7468, F1 Micro: 0.2583, F1 Macro: 0.1602, Accuracy: 0.2583\n","Epoch 7, Train Loss: 1.7874, Val Loss: 1.7720, F1 Micro: 0.2250, F1 Macro: 0.1416, Accuracy: 0.2250\n","Epoch 8, Train Loss: 1.7440, Val Loss: 1.7262, F1 Micro: 0.2833, F1 Macro: 0.2297, Accuracy: 0.2833\n","Epoch 9, Train Loss: 1.7592, Val Loss: 1.7264, F1 Micro: 0.2583, F1 Macro: 0.2071, Accuracy: 0.2583\n","Epoch 10, Train Loss: 1.7308, Val Loss: 1.7203, F1 Micro: 0.2750, F1 Macro: 0.2378, Accuracy: 0.2750\n","Epoch 11, Train Loss: 1.7424, Val Loss: 1.7166, F1 Micro: 0.2917, F1 Macro: 0.2513, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.7559, Val Loss: 1.7956, F1 Micro: 0.2583, F1 Macro: 0.1657, Accuracy: 0.2583\n","Epoch 13, Train Loss: 1.7289, Val Loss: 1.7556, F1 Micro: 0.3583, F1 Macro: 0.2880, Accuracy: 0.3583\n","Epoch 14, Train Loss: 1.7177, Val Loss: 1.7567, F1 Micro: 0.2250, F1 Macro: 0.1698, Accuracy: 0.2250\n","Epoch 15, Train Loss: 1.7088, Val Loss: 1.6814, F1 Micro: 0.2417, F1 Macro: 0.1900, Accuracy: 0.2417\n","Epoch 16, Train Loss: 1.6763, Val Loss: 1.7305, F1 Micro: 0.2500, F1 Macro: 0.2025, Accuracy: 0.2500\n","Epoch 17, Train Loss: 1.7015, Val Loss: 1.6900, F1 Micro: 0.2917, F1 Macro: 0.2369, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.7076, Val Loss: 1.6837, F1 Micro: 0.3083, F1 Macro: 0.2583, Accuracy: 0.3083\n","Epoch 19, Train Loss: 1.7105, Val Loss: 1.7248, F1 Micro: 0.2583, F1 Macro: 0.1992, Accuracy: 0.2583\n","Epoch 20, Train Loss: 1.7181, Val Loss: 1.7226, F1 Micro: 0.3500, F1 Macro: 0.3279, Accuracy: 0.3500\n","Epoch 21, Train Loss: 1.6990, Val Loss: 1.8957, F1 Micro: 0.2750, F1 Macro: 0.1850, Accuracy: 0.2750\n","Epoch 22, Train Loss: 1.6918, Val Loss: 1.7423, F1 Micro: 0.2917, F1 Macro: 0.2572, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.6511, Val Loss: 1.6264, F1 Micro: 0.3583, F1 Macro: 0.3180, Accuracy: 0.3583\n","Epoch 24, Train Loss: 1.6915, Val Loss: 1.6497, F1 Micro: 0.3500, F1 Macro: 0.3195, Accuracy: 0.3500\n","Epoch 25, Train Loss: 1.6572, Val Loss: 1.6155, F1 Micro: 0.3250, F1 Macro: 0.2876, Accuracy: 0.3250\n","Epoch 26, Train Loss: 1.6617, Val Loss: 1.6332, F1 Micro: 0.3583, F1 Macro: 0.3054, Accuracy: 0.3583\n","Epoch 27, Train Loss: 1.6271, Val Loss: 1.6656, F1 Micro: 0.3583, F1 Macro: 0.3438, Accuracy: 0.3583\n","Epoch 28, Train Loss: 1.6345, Val Loss: 1.8115, F1 Micro: 0.2750, F1 Macro: 0.2491, Accuracy: 0.2750\n","Epoch 29, Train Loss: 1.5942, Val Loss: 1.7023, F1 Micro: 0.3000, F1 Macro: 0.2865, Accuracy: 0.3000\n","Epoch 30, Train Loss: 1.5852, Val Loss: 1.6148, F1 Micro: 0.3417, F1 Macro: 0.3141, Accuracy: 0.3417\n","Epoch 31, Train Loss: 1.6042, Val Loss: 1.5868, F1 Micro: 0.3750, F1 Macro: 0.3271, Accuracy: 0.3750\n","Epoch 32, Train Loss: 1.6243, Val Loss: 1.8755, F1 Micro: 0.3000, F1 Macro: 0.2415, Accuracy: 0.3000\n","Epoch 33, Train Loss: 1.6195, Val Loss: 1.6842, F1 Micro: 0.3167, F1 Macro: 0.3078, Accuracy: 0.3167\n","Epoch 34, Train Loss: 1.6074, Val Loss: 1.5838, F1 Micro: 0.4167, F1 Macro: 0.4139, Accuracy: 0.4167\n","Epoch 35, Train Loss: 1.5881, Val Loss: 1.5564, F1 Micro: 0.4000, F1 Macro: 0.3707, Accuracy: 0.4000\n","Epoch 36, Train Loss: 1.5806, Val Loss: 1.5938, F1 Micro: 0.3917, F1 Macro: 0.3758, Accuracy: 0.3917\n","Epoch 37, Train Loss: 1.5873, Val Loss: 1.6610, F1 Micro: 0.3333, F1 Macro: 0.3061, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.6155, Val Loss: 1.6236, F1 Micro: 0.3667, F1 Macro: 0.3287, Accuracy: 0.3667\n","Epoch 39, Train Loss: 1.5907, Val Loss: 1.5991, F1 Micro: 0.3833, F1 Macro: 0.3692, Accuracy: 0.3833\n","Epoch 40, Train Loss: 1.5562, Val Loss: 1.5727, F1 Micro: 0.4250, F1 Macro: 0.3817, Accuracy: 0.4250\n","Epoch 41, Train Loss: 1.5576, Val Loss: 1.5814, F1 Micro: 0.3500, F1 Macro: 0.3347, Accuracy: 0.3500\n","Epoch 42, Train Loss: 1.5459, Val Loss: 1.6273, F1 Micro: 0.4000, F1 Macro: 0.3575, Accuracy: 0.4000\n","Epoch 43, Train Loss: 1.5470, Val Loss: 1.6252, F1 Micro: 0.3583, F1 Macro: 0.3534, Accuracy: 0.3583\n","Epoch 44, Train Loss: 1.5631, Val Loss: 1.5192, F1 Micro: 0.3583, F1 Macro: 0.3589, Accuracy: 0.3583\n","Epoch 45, Train Loss: 1.4936, Val Loss: 1.7101, F1 Micro: 0.3417, F1 Macro: 0.2934, Accuracy: 0.3417\n","Epoch 46, Train Loss: 1.5355, Val Loss: 1.6161, F1 Micro: 0.3750, F1 Macro: 0.3752, Accuracy: 0.3750\n","Epoch 47, Train Loss: 1.5054, Val Loss: 1.5596, F1 Micro: 0.4083, F1 Macro: 0.3680, Accuracy: 0.4083\n","Epoch 48, Train Loss: 1.5046, Val Loss: 1.5547, F1 Micro: 0.4000, F1 Macro: 0.3981, Accuracy: 0.4000\n","Epoch 49, Train Loss: 1.4757, Val Loss: 1.5988, F1 Micro: 0.4000, F1 Macro: 0.3444, Accuracy: 0.4000\n","Epoch 50, Train Loss: 1.4893, Val Loss: 1.6927, F1 Micro: 0.2583, F1 Macro: 0.2375, Accuracy: 0.2583\n","Epoch 51, Train Loss: 1.5229, Val Loss: 1.4905, F1 Micro: 0.4000, F1 Macro: 0.3754, Accuracy: 0.4000\n","Epoch 52, Train Loss: 1.4451, Val Loss: 1.5173, F1 Micro: 0.4167, F1 Macro: 0.3894, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.4579, Val Loss: 1.6172, F1 Micro: 0.3750, F1 Macro: 0.3437, Accuracy: 0.3750\n","Epoch 54, Train Loss: 1.4440, Val Loss: 1.5102, F1 Micro: 0.4417, F1 Macro: 0.4476, Accuracy: 0.4417\n","Epoch 55, Train Loss: 1.4453, Val Loss: 1.5517, F1 Micro: 0.3917, F1 Macro: 0.3596, Accuracy: 0.3917\n","Epoch 56, Train Loss: 1.4366, Val Loss: 1.5529, F1 Micro: 0.4083, F1 Macro: 0.3778, Accuracy: 0.4083\n","Epoch 57, Train Loss: 1.4015, Val Loss: 1.5127, F1 Micro: 0.4000, F1 Macro: 0.3929, Accuracy: 0.4000\n","Epoch 58, Train Loss: 1.4367, Val Loss: 1.4918, F1 Micro: 0.4250, F1 Macro: 0.3999, Accuracy: 0.4250\n","Epoch 59, Train Loss: 1.4020, Val Loss: 1.4706, F1 Micro: 0.4333, F1 Macro: 0.4200, Accuracy: 0.4333\n","Epoch 60, Train Loss: 1.3980, Val Loss: 1.4557, F1 Micro: 0.4500, F1 Macro: 0.4334, Accuracy: 0.4500\n","Epoch 61, Train Loss: 1.4081, Val Loss: 1.5428, F1 Micro: 0.4333, F1 Macro: 0.4186, Accuracy: 0.4333\n","Epoch 62, Train Loss: 1.3835, Val Loss: 1.5398, F1 Micro: 0.4000, F1 Macro: 0.3910, Accuracy: 0.4000\n","Epoch 63, Train Loss: 1.3909, Val Loss: 1.5502, F1 Micro: 0.4167, F1 Macro: 0.3901, Accuracy: 0.4167\n","Epoch 64, Train Loss: 1.3598, Val Loss: 1.5579, F1 Micro: 0.4083, F1 Macro: 0.4103, Accuracy: 0.4083\n","Epoch 65, Train Loss: 1.3331, Val Loss: 1.5149, F1 Micro: 0.4500, F1 Macro: 0.4324, Accuracy: 0.4500\n","Epoch 66, Train Loss: 1.3289, Val Loss: 1.5266, F1 Micro: 0.4250, F1 Macro: 0.4005, Accuracy: 0.4250\n","Epoch 67, Train Loss: 1.4057, Val Loss: 1.4755, F1 Micro: 0.3917, F1 Macro: 0.3966, Accuracy: 0.3917\n","Epoch 68, Train Loss: 1.3567, Val Loss: 1.5416, F1 Micro: 0.3750, F1 Macro: 0.3475, Accuracy: 0.3750\n","Epoch 69, Train Loss: 1.3284, Val Loss: 1.4202, F1 Micro: 0.4833, F1 Macro: 0.4666, Accuracy: 0.4833\n","Epoch 70, Train Loss: 1.3364, Val Loss: 1.5034, F1 Micro: 0.4417, F1 Macro: 0.4163, Accuracy: 0.4417\n","Epoch 71, Train Loss: 1.3091, Val Loss: 1.4586, F1 Micro: 0.4917, F1 Macro: 0.4766, Accuracy: 0.4917\n","Epoch 72, Train Loss: 1.2929, Val Loss: 1.5491, F1 Micro: 0.4250, F1 Macro: 0.3879, Accuracy: 0.4250\n","Epoch 73, Train Loss: 1.2946, Val Loss: 1.4033, F1 Micro: 0.4500, F1 Macro: 0.4382, Accuracy: 0.4500\n","Epoch 74, Train Loss: 1.3125, Val Loss: 1.4304, F1 Micro: 0.4833, F1 Macro: 0.4761, Accuracy: 0.4833\n","Epoch 75, Train Loss: 1.3209, Val Loss: 1.4520, F1 Micro: 0.4500, F1 Macro: 0.4376, Accuracy: 0.4500\n","Epoch 76, Train Loss: 1.2594, Val Loss: 1.5173, F1 Micro: 0.4333, F1 Macro: 0.4432, Accuracy: 0.4333\n","Epoch 77, Train Loss: 1.2369, Val Loss: 1.4375, F1 Micro: 0.4917, F1 Macro: 0.4759, Accuracy: 0.4917\n","Epoch 78, Train Loss: 1.2550, Val Loss: 1.4999, F1 Micro: 0.4583, F1 Macro: 0.4338, Accuracy: 0.4583\n","Epoch 79, Train Loss: 1.2796, Val Loss: 1.4335, F1 Micro: 0.4750, F1 Macro: 0.4835, Accuracy: 0.4750\n","Epoch 80, Train Loss: 1.2254, Val Loss: 1.4148, F1 Micro: 0.4667, F1 Macro: 0.4556, Accuracy: 0.4667\n","Epoch 81, Train Loss: 1.2693, Val Loss: 1.3724, F1 Micro: 0.5000, F1 Macro: 0.5030, Accuracy: 0.5000\n","Epoch 82, Train Loss: 1.2289, Val Loss: 1.3675, F1 Micro: 0.4750, F1 Macro: 0.4691, Accuracy: 0.4750\n","Epoch 83, Train Loss: 1.1972, Val Loss: 1.4136, F1 Micro: 0.5333, F1 Macro: 0.5252, Accuracy: 0.5333\n","Epoch 84, Train Loss: 1.2198, Val Loss: 1.3825, F1 Micro: 0.5250, F1 Macro: 0.5221, Accuracy: 0.5250\n","Epoch 85, Train Loss: 1.2409, Val Loss: 1.3968, F1 Micro: 0.5000, F1 Macro: 0.4817, Accuracy: 0.5000\n","Epoch 86, Train Loss: 1.2120, Val Loss: 1.4319, F1 Micro: 0.4833, F1 Macro: 0.4844, Accuracy: 0.4833\n","Epoch 87, Train Loss: 1.2527, Val Loss: 1.4187, F1 Micro: 0.4750, F1 Macro: 0.4555, Accuracy: 0.4750\n","Epoch 88, Train Loss: 1.1755, Val Loss: 1.4169, F1 Micro: 0.4667, F1 Macro: 0.4513, Accuracy: 0.4667\n","Epoch 89, Train Loss: 1.1819, Val Loss: 1.6330, F1 Micro: 0.4167, F1 Macro: 0.3903, Accuracy: 0.4167\n","Epoch 90, Train Loss: 1.2365, Val Loss: 1.3548, F1 Micro: 0.5667, F1 Macro: 0.5634, Accuracy: 0.5667\n","Epoch 91, Train Loss: 1.1510, Val Loss: 1.4241, F1 Micro: 0.4667, F1 Macro: 0.4730, Accuracy: 0.4667\n","Epoch 92, Train Loss: 1.1475, Val Loss: 1.3983, F1 Micro: 0.5167, F1 Macro: 0.5027, Accuracy: 0.5167\n","Epoch 93, Train Loss: 1.1579, Val Loss: 1.3870, F1 Micro: 0.4833, F1 Macro: 0.4778, Accuracy: 0.4833\n","Epoch 94, Train Loss: 1.1449, Val Loss: 1.4298, F1 Micro: 0.4833, F1 Macro: 0.4635, Accuracy: 0.4833\n","Epoch 95, Train Loss: 1.1628, Val Loss: 1.2927, F1 Micro: 0.5083, F1 Macro: 0.5057, Accuracy: 0.5083\n","Epoch 96, Train Loss: 1.1439, Val Loss: 1.5019, F1 Micro: 0.4917, F1 Macro: 0.4630, Accuracy: 0.4917\n","Epoch 97, Train Loss: 1.1140, Val Loss: 1.4752, F1 Micro: 0.4750, F1 Macro: 0.4738, Accuracy: 0.4750\n","Epoch 98, Train Loss: 1.1357, Val Loss: 1.3038, F1 Micro: 0.5333, F1 Macro: 0.5199, Accuracy: 0.5333\n","Epoch 99, Train Loss: 1.1066, Val Loss: 1.3093, F1 Micro: 0.5833, F1 Macro: 0.5744, Accuracy: 0.5833\n","Epoch 100, Train Loss: 1.1307, Val Loss: 1.3327, F1 Micro: 0.5250, F1 Macro: 0.5213, Accuracy: 0.5250\n","Epoch 101, Train Loss: 1.0853, Val Loss: 1.3311, F1 Micro: 0.5417, F1 Macro: 0.5427, Accuracy: 0.5417\n","Epoch 102, Train Loss: 1.0766, Val Loss: 1.3958, F1 Micro: 0.5417, F1 Macro: 0.4935, Accuracy: 0.5417\n","Epoch 103, Train Loss: 1.0929, Val Loss: 1.3943, F1 Micro: 0.5083, F1 Macro: 0.5036, Accuracy: 0.5083\n","Epoch 104, Train Loss: 1.1317, Val Loss: 1.4543, F1 Micro: 0.5083, F1 Macro: 0.5031, Accuracy: 0.5083\n","Epoch 105, Train Loss: 1.0573, Val Loss: 1.3930, F1 Micro: 0.5250, F1 Macro: 0.5094, Accuracy: 0.5250\n","Epoch 106, Train Loss: 1.0904, Val Loss: 1.3197, F1 Micro: 0.5417, F1 Macro: 0.5187, Accuracy: 0.5417\n","Epoch 107, Train Loss: 1.0904, Val Loss: 1.5660, F1 Micro: 0.5167, F1 Macro: 0.5052, Accuracy: 0.5167\n","Epoch 108, Train Loss: 1.0959, Val Loss: 1.3713, F1 Micro: 0.5250, F1 Macro: 0.5262, Accuracy: 0.5250\n","Epoch 109, Train Loss: 1.0590, Val Loss: 1.2935, F1 Micro: 0.5500, F1 Macro: 0.5562, Accuracy: 0.5500\n","Epoch 110, Train Loss: 1.0900, Val Loss: 1.3660, F1 Micro: 0.5083, F1 Macro: 0.5068, Accuracy: 0.5083\n","Epoch 111, Train Loss: 1.0842, Val Loss: 1.3861, F1 Micro: 0.4667, F1 Macro: 0.4530, Accuracy: 0.4667\n","Epoch 112, Train Loss: 1.0323, Val Loss: 1.2773, F1 Micro: 0.5917, F1 Macro: 0.5852, Accuracy: 0.5917\n","Epoch 113, Train Loss: 0.9814, Val Loss: 1.2987, F1 Micro: 0.4917, F1 Macro: 0.4834, Accuracy: 0.4917\n","Epoch 114, Train Loss: 0.9336, Val Loss: 1.3301, F1 Micro: 0.5667, F1 Macro: 0.5554, Accuracy: 0.5667\n","Epoch 115, Train Loss: 1.0398, Val Loss: 1.4391, F1 Micro: 0.5250, F1 Macro: 0.5103, Accuracy: 0.5250\n","Epoch 116, Train Loss: 1.0635, Val Loss: 1.3046, F1 Micro: 0.5667, F1 Macro: 0.5625, Accuracy: 0.5667\n","Epoch 117, Train Loss: 1.0611, Val Loss: 1.4653, F1 Micro: 0.4833, F1 Macro: 0.4841, Accuracy: 0.4833\n","Epoch 118, Train Loss: 1.0234, Val Loss: 1.3042, F1 Micro: 0.5917, F1 Macro: 0.5880, Accuracy: 0.5917\n","Epoch 119, Train Loss: 0.9841, Val Loss: 1.2737, F1 Micro: 0.5417, F1 Macro: 0.5383, Accuracy: 0.5417\n","Epoch 120, Train Loss: 0.9956, Val Loss: 1.3674, F1 Micro: 0.4917, F1 Macro: 0.4836, Accuracy: 0.4917\n","Epoch 121, Train Loss: 0.9831, Val Loss: 1.3047, F1 Micro: 0.5417, F1 Macro: 0.5351, Accuracy: 0.5417\n","Epoch 122, Train Loss: 0.9968, Val Loss: 1.3207, F1 Micro: 0.5833, F1 Macro: 0.5767, Accuracy: 0.5833\n","Epoch 123, Train Loss: 0.9651, Val Loss: 1.2850, F1 Micro: 0.5417, F1 Macro: 0.5316, Accuracy: 0.5417\n","Epoch 124, Train Loss: 0.9671, Val Loss: 1.3434, F1 Micro: 0.5417, F1 Macro: 0.5383, Accuracy: 0.5417\n","Epoch 125, Train Loss: 0.9293, Val Loss: 1.3950, F1 Micro: 0.5583, F1 Macro: 0.5569, Accuracy: 0.5583\n","Epoch 126, Train Loss: 0.9695, Val Loss: 1.3882, F1 Micro: 0.5500, F1 Macro: 0.5485, Accuracy: 0.5500\n","Epoch 127, Train Loss: 0.9877, Val Loss: 1.3536, F1 Micro: 0.5667, F1 Macro: 0.5658, Accuracy: 0.5667\n","Epoch 128, Train Loss: 0.9327, Val Loss: 1.3699, F1 Micro: 0.5417, F1 Macro: 0.5311, Accuracy: 0.5417\n","Epoch 129, Train Loss: 0.9187, Val Loss: 1.4484, F1 Micro: 0.5333, F1 Macro: 0.5221, Accuracy: 0.5333\n","Epoch 130, Train Loss: 0.9036, Val Loss: 1.4586, F1 Micro: 0.5750, F1 Macro: 0.5709, Accuracy: 0.5750\n","Epoch 131, Train Loss: 0.9663, Val Loss: 1.3093, F1 Micro: 0.5250, F1 Macro: 0.5359, Accuracy: 0.5250\n","Epoch 132, Train Loss: 0.9509, Val Loss: 1.4474, F1 Micro: 0.5667, F1 Macro: 0.5561, Accuracy: 0.5667\n","Epoch 133, Train Loss: 0.9954, Val Loss: 1.7828, F1 Micro: 0.4583, F1 Macro: 0.4525, Accuracy: 0.4583\n","Epoch 134, Train Loss: 0.9284, Val Loss: 1.4171, F1 Micro: 0.5167, F1 Macro: 0.5144, Accuracy: 0.5167\n","Epoch 135, Train Loss: 0.8733, Val Loss: 1.3663, F1 Micro: 0.5500, F1 Macro: 0.5529, Accuracy: 0.5500\n","Epoch 136, Train Loss: 0.8890, Val Loss: 1.3341, F1 Micro: 0.5167, F1 Macro: 0.5146, Accuracy: 0.5167\n","Epoch 137, Train Loss: 0.8727, Val Loss: 1.2540, F1 Micro: 0.6167, F1 Macro: 0.6099, Accuracy: 0.6167\n","Epoch 138, Train Loss: 0.8129, Val Loss: 1.4224, F1 Micro: 0.5250, F1 Macro: 0.4980, Accuracy: 0.5250\n","Epoch 139, Train Loss: 0.8483, Val Loss: 1.2809, F1 Micro: 0.5500, F1 Macro: 0.5424, Accuracy: 0.5500\n","Epoch 140, Train Loss: 0.8603, Val Loss: 1.3395, F1 Micro: 0.5750, F1 Macro: 0.5618, Accuracy: 0.5750\n","Epoch 141, Train Loss: 0.8592, Val Loss: 1.4078, F1 Micro: 0.5583, F1 Macro: 0.5569, Accuracy: 0.5583\n","Epoch 142, Train Loss: 0.8451, Val Loss: 1.4471, F1 Micro: 0.5333, F1 Macro: 0.5164, Accuracy: 0.5333\n","Epoch 143, Train Loss: 0.8920, Val Loss: 1.3643, F1 Micro: 0.5417, F1 Macro: 0.5398, Accuracy: 0.5417\n","Epoch 144, Train Loss: 0.8564, Val Loss: 1.4353, F1 Micro: 0.4833, F1 Macro: 0.4676, Accuracy: 0.4833\n","Epoch 145, Train Loss: 0.9027, Val Loss: 1.3597, F1 Micro: 0.6000, F1 Macro: 0.5941, Accuracy: 0.6000\n","Epoch 146, Train Loss: 0.8652, Val Loss: 1.2707, F1 Micro: 0.5833, F1 Macro: 0.5834, Accuracy: 0.5833\n","Epoch 147, Train Loss: 0.8383, Val Loss: 1.3394, F1 Micro: 0.5833, F1 Macro: 0.5819, Accuracy: 0.5833\n","Epoch 148, Train Loss: 0.7886, Val Loss: 1.4526, F1 Micro: 0.5750, F1 Macro: 0.5604, Accuracy: 0.5750\n","Epoch 149, Train Loss: 0.8843, Val Loss: 1.3760, F1 Micro: 0.5917, F1 Macro: 0.5868, Accuracy: 0.5917\n","Epoch 150, Train Loss: 0.8674, Val Loss: 1.4398, F1 Micro: 0.5917, F1 Macro: 0.5742, Accuracy: 0.5917\n","Epoch 151, Train Loss: 0.8070, Val Loss: 1.3770, F1 Micro: 0.5667, F1 Macro: 0.5546, Accuracy: 0.5667\n","Epoch 152, Train Loss: 0.7673, Val Loss: 1.3002, F1 Micro: 0.5833, F1 Macro: 0.5794, Accuracy: 0.5833\n","Epoch 153, Train Loss: 0.8085, Val Loss: 1.6933, F1 Micro: 0.5333, F1 Macro: 0.5260, Accuracy: 0.5333\n","Epoch 154, Train Loss: 0.8259, Val Loss: 1.4264, F1 Micro: 0.5583, F1 Macro: 0.5513, Accuracy: 0.5583\n","Epoch 155, Train Loss: 0.7805, Val Loss: 1.3281, F1 Micro: 0.6000, F1 Macro: 0.5894, Accuracy: 0.6000\n","Epoch 156, Train Loss: 0.7671, Val Loss: 1.4893, F1 Micro: 0.5917, F1 Macro: 0.5977, Accuracy: 0.5917\n","Epoch 157, Train Loss: 0.7566, Val Loss: 1.3627, F1 Micro: 0.5917, F1 Macro: 0.5899, Accuracy: 0.5917\n","Epoch 158, Train Loss: 0.7486, Val Loss: 1.5575, F1 Micro: 0.5250, F1 Macro: 0.5209, Accuracy: 0.5250\n","Epoch 159, Train Loss: 0.7428, Val Loss: 1.4105, F1 Micro: 0.5750, F1 Macro: 0.5725, Accuracy: 0.5750\n","Epoch 160, Train Loss: 0.7673, Val Loss: 1.4138, F1 Micro: 0.5333, F1 Macro: 0.5310, Accuracy: 0.5333\n","Epoch 161, Train Loss: 0.7725, Val Loss: 1.3982, F1 Micro: 0.5833, F1 Macro: 0.5840, Accuracy: 0.5833\n","Epoch 162, Train Loss: 0.7759, Val Loss: 1.2704, F1 Micro: 0.6000, F1 Macro: 0.5931, Accuracy: 0.6000\n","Epoch 163, Train Loss: 0.8048, Val Loss: 1.4388, F1 Micro: 0.5917, F1 Macro: 0.5762, Accuracy: 0.5917\n","Epoch 164, Train Loss: 0.7425, Val Loss: 1.4570, F1 Micro: 0.5917, F1 Macro: 0.5922, Accuracy: 0.5917\n","Epoch 165, Train Loss: 0.8103, Val Loss: 1.4361, F1 Micro: 0.5250, F1 Macro: 0.5304, Accuracy: 0.5250\n","Epoch 166, Train Loss: 0.7080, Val Loss: 1.4065, F1 Micro: 0.5833, F1 Macro: 0.5804, Accuracy: 0.5833\n","Epoch 167, Train Loss: 0.7628, Val Loss: 1.3366, F1 Micro: 0.5417, F1 Macro: 0.5147, Accuracy: 0.5417\n","Epoch 168, Train Loss: 0.8568, Val Loss: 1.4050, F1 Micro: 0.5917, F1 Macro: 0.5828, Accuracy: 0.5917\n","Epoch 169, Train Loss: 0.7924, Val Loss: 1.3608, F1 Micro: 0.6000, F1 Macro: 0.5934, Accuracy: 0.6000\n","Epoch 170, Train Loss: 0.7732, Val Loss: 1.5254, F1 Micro: 0.5750, F1 Macro: 0.5642, Accuracy: 0.5750\n","Epoch 171, Train Loss: 0.7350, Val Loss: 1.4319, F1 Micro: 0.5667, F1 Macro: 0.5676, Accuracy: 0.5667\n","Epoch 172, Train Loss: 0.7111, Val Loss: 1.5564, F1 Micro: 0.5000, F1 Macro: 0.4978, Accuracy: 0.5000\n","Epoch 173, Train Loss: 0.7118, Val Loss: 1.4629, F1 Micro: 0.5667, F1 Macro: 0.5401, Accuracy: 0.5667\n","Epoch 174, Train Loss: 0.6858, Val Loss: 1.4512, F1 Micro: 0.5583, F1 Macro: 0.5521, Accuracy: 0.5583\n","Epoch 175, Train Loss: 0.6579, Val Loss: 1.3587, F1 Micro: 0.6000, F1 Macro: 0.6036, Accuracy: 0.6000\n","Epoch 176, Train Loss: 0.7066, Val Loss: 1.2754, F1 Micro: 0.6333, F1 Macro: 0.6274, Accuracy: 0.6333\n","Epoch 177, Train Loss: 0.6556, Val Loss: 1.6089, F1 Micro: 0.5917, F1 Macro: 0.5895, Accuracy: 0.5917\n","Epoch 178, Train Loss: 0.6544, Val Loss: 1.3335, F1 Micro: 0.6417, F1 Macro: 0.6322, Accuracy: 0.6417\n","Epoch 179, Train Loss: 0.6756, Val Loss: 1.3736, F1 Micro: 0.5667, F1 Macro: 0.5511, Accuracy: 0.5667\n","Epoch 180, Train Loss: 0.7293, Val Loss: 1.5095, F1 Micro: 0.5917, F1 Macro: 0.5939, Accuracy: 0.5917\n","Epoch 181, Train Loss: 0.7418, Val Loss: 1.5538, F1 Micro: 0.6083, F1 Macro: 0.5988, Accuracy: 0.6083\n","Epoch 182, Train Loss: 0.7118, Val Loss: 1.3835, F1 Micro: 0.6167, F1 Macro: 0.6146, Accuracy: 0.6167\n","Epoch 183, Train Loss: 0.6621, Val Loss: 1.4605, F1 Micro: 0.6417, F1 Macro: 0.6327, Accuracy: 0.6417\n","Epoch 184, Train Loss: 0.6462, Val Loss: 1.5722, F1 Micro: 0.5583, F1 Macro: 0.5641, Accuracy: 0.5583\n","Epoch 185, Train Loss: 0.6015, Val Loss: 1.4953, F1 Micro: 0.6083, F1 Macro: 0.6080, Accuracy: 0.6083\n","Epoch 186, Train Loss: 0.6966, Val Loss: 1.5654, F1 Micro: 0.6250, F1 Macro: 0.6136, Accuracy: 0.6250\n","Epoch 187, Train Loss: 0.6530, Val Loss: 1.4985, F1 Micro: 0.5333, F1 Macro: 0.5187, Accuracy: 0.5333\n","Epoch 188, Train Loss: 0.7584, Val Loss: 1.6623, F1 Micro: 0.5667, F1 Macro: 0.5654, Accuracy: 0.5667\n","Epoch 189, Train Loss: 0.7351, Val Loss: 1.4792, F1 Micro: 0.5917, F1 Macro: 0.5838, Accuracy: 0.5917\n","Epoch 190, Train Loss: 0.6464, Val Loss: 1.4781, F1 Micro: 0.5917, F1 Macro: 0.5876, Accuracy: 0.5917\n","Epoch 191, Train Loss: 0.6481, Val Loss: 1.4074, F1 Micro: 0.6500, F1 Macro: 0.6553, Accuracy: 0.6500\n","Epoch 192, Train Loss: 0.6008, Val Loss: 1.5599, F1 Micro: 0.5917, F1 Macro: 0.6026, Accuracy: 0.5917\n","Epoch 193, Train Loss: 0.6048, Val Loss: 1.6271, F1 Micro: 0.6250, F1 Macro: 0.6192, Accuracy: 0.6250\n","Epoch 194, Train Loss: 0.6628, Val Loss: 1.5664, F1 Micro: 0.5750, F1 Macro: 0.5728, Accuracy: 0.5750\n","Epoch 195, Train Loss: 0.5935, Val Loss: 1.3863, F1 Micro: 0.6250, F1 Macro: 0.6192, Accuracy: 0.6250\n","Epoch 196, Train Loss: 0.6239, Val Loss: 1.4348, F1 Micro: 0.6083, F1 Macro: 0.6060, Accuracy: 0.6083\n","Epoch 197, Train Loss: 0.5734, Val Loss: 1.3424, F1 Micro: 0.6833, F1 Macro: 0.6861, Accuracy: 0.6833\n","Epoch 198, Train Loss: 0.5961, Val Loss: 1.5216, F1 Micro: 0.6167, F1 Macro: 0.6134, Accuracy: 0.6167\n","Epoch 199, Train Loss: 0.6058, Val Loss: 1.4211, F1 Micro: 0.6500, F1 Macro: 0.6409, Accuracy: 0.6500\n","Epoch 200, Train Loss: 0.6436, Val Loss: 1.5227, F1 Micro: 0.6083, F1 Macro: 0.6102, Accuracy: 0.6083\n","Test set evaluation - F1 Micro: 0.6083, F1 Macro: 0.6102, Accuracy: 0.6083\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 5.5941, Val Loss: 1.8333, F1 Micro: 0.2292, F1 Macro: 0.1201, Accuracy: 0.2292\n","Epoch 2, Train Loss: 1.9535, Val Loss: 1.8683, F1 Micro: 0.2708, F1 Macro: 0.1583, Accuracy: 0.2708\n","Epoch 3, Train Loss: 2.0096, Val Loss: 1.8442, F1 Micro: 0.1979, F1 Macro: 0.1238, Accuracy: 0.1979\n","Epoch 4, Train Loss: 2.0995, Val Loss: 1.7998, F1 Micro: 0.2604, F1 Macro: 0.1369, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.9536, Val Loss: 1.8792, F1 Micro: 0.2708, F1 Macro: 0.1423, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.9584, Val Loss: 2.0173, F1 Micro: 0.1979, F1 Macro: 0.1238, Accuracy: 0.1979\n","Epoch 7, Train Loss: 2.0042, Val Loss: 2.1120, F1 Micro: 0.1875, F1 Macro: 0.1182, Accuracy: 0.1875\n","Epoch 8, Train Loss: 2.1467, Val Loss: 2.1899, F1 Micro: 0.1875, F1 Macro: 0.1218, Accuracy: 0.1875\n","Epoch 9, Train Loss: 2.1537, Val Loss: 2.5014, F1 Micro: 0.1875, F1 Macro: 0.1214, Accuracy: 0.1875\n","Epoch 10, Train Loss: 2.1792, Val Loss: 1.7855, F1 Micro: 0.2604, F1 Macro: 0.1397, Accuracy: 0.2604\n","Epoch 11, Train Loss: 2.0139, Val Loss: 2.0846, F1 Micro: 0.1875, F1 Macro: 0.1214, Accuracy: 0.1875\n","Epoch 12, Train Loss: 2.1051, Val Loss: 1.9699, F1 Micro: 0.2604, F1 Macro: 0.1336, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 5.3574, Val Loss: 2.6485, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 2, Train Loss: 2.0028, Val Loss: 2.2498, F1 Micro: 0.2396, F1 Macro: 0.1161, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.9354, Val Loss: 2.1353, F1 Micro: 0.1667, F1 Macro: 0.1023, Accuracy: 0.1667\n","Epoch 4, Train Loss: 2.1340, Val Loss: 2.2258, F1 Micro: 0.2396, F1 Macro: 0.1221, Accuracy: 0.2396\n","Epoch 5, Train Loss: 2.0728, Val Loss: 2.1028, F1 Micro: 0.1771, F1 Macro: 0.0986, Accuracy: 0.1771\n","Epoch 6, Train Loss: 2.0539, Val Loss: 2.2322, F1 Micro: 0.2708, F1 Macro: 0.1845, Accuracy: 0.2708\n","Epoch 7, Train Loss: 2.0702, Val Loss: 2.3423, F1 Micro: 0.1667, F1 Macro: 0.1007, Accuracy: 0.1667\n","Epoch 8, Train Loss: 2.0350, Val Loss: 2.3718, F1 Micro: 0.2188, F1 Macro: 0.1098, Accuracy: 0.2188\n","Epoch 9, Train Loss: 2.0261, Val Loss: 2.1730, F1 Micro: 0.1771, F1 Macro: 0.1365, Accuracy: 0.1771\n","Epoch 10, Train Loss: 1.9333, Val Loss: 2.4888, F1 Micro: 0.2396, F1 Macro: 0.1601, Accuracy: 0.2396\n","Epoch 11, Train Loss: 2.1140, Val Loss: 3.0701, F1 Micro: 0.1042, F1 Macro: 0.0317, Accuracy: 0.1042\n","Epoch 12, Train Loss: 2.0142, Val Loss: 2.8732, F1 Micro: 0.1042, F1 Macro: 0.0317, Accuracy: 0.1042\n","Epoch 13, Train Loss: 2.0817, Val Loss: 2.3036, F1 Micro: 0.2500, F1 Macro: 0.1450, Accuracy: 0.2500\n","Epoch 14, Train Loss: 2.1225, Val Loss: 2.3775, F1 Micro: 0.2396, F1 Macro: 0.1155, Accuracy: 0.2396\n","Epoch 15, Train Loss: 2.0653, Val Loss: 2.3213, F1 Micro: 0.2396, F1 Macro: 0.1391, Accuracy: 0.2396\n","Epoch 16, Train Loss: 2.1186, Val Loss: 2.2438, F1 Micro: 0.1146, F1 Macro: 0.0476, Accuracy: 0.1146\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 5.4346, Val Loss: 2.1087, F1 Micro: 0.2396, F1 Macro: 0.1122, Accuracy: 0.2396\n","Epoch 2, Train Loss: 2.1046, Val Loss: 2.5150, F1 Micro: 0.1146, F1 Macro: 0.0742, Accuracy: 0.1146\n","Epoch 3, Train Loss: 1.9395, Val Loss: 1.9115, F1 Micro: 0.1979, F1 Macro: 0.1292, Accuracy: 0.1979\n","Epoch 4, Train Loss: 2.0225, Val Loss: 2.0306, F1 Micro: 0.0938, F1 Macro: 0.0647, Accuracy: 0.0938\n","Epoch 5, Train Loss: 2.1465, Val Loss: 2.1472, F1 Micro: 0.2188, F1 Macro: 0.1443, Accuracy: 0.2188\n","Epoch 6, Train Loss: 2.0887, Val Loss: 1.9480, F1 Micro: 0.2083, F1 Macro: 0.1033, Accuracy: 0.2083\n","Epoch 7, Train Loss: 2.0019, Val Loss: 2.1062, F1 Micro: 0.2188, F1 Macro: 0.0984, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.9715, Val Loss: 2.1949, F1 Micro: 0.0938, F1 Macro: 0.0538, Accuracy: 0.0938\n","Epoch 9, Train Loss: 2.0859, Val Loss: 2.0273, F1 Micro: 0.1354, F1 Macro: 0.1061, Accuracy: 0.1354\n","Epoch 10, Train Loss: 2.0535, Val Loss: 2.3041, F1 Micro: 0.1354, F1 Macro: 0.1115, Accuracy: 0.1354\n","Epoch 11, Train Loss: 2.0773, Val Loss: 1.9746, F1 Micro: 0.1250, F1 Macro: 0.0806, Accuracy: 0.1250\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 7.1337, Val Loss: 2.5080, F1 Micro: 0.1979, F1 Macro: 0.1005, Accuracy: 0.1979\n","Epoch 2, Train Loss: 2.0103, Val Loss: 1.8846, F1 Micro: 0.1562, F1 Macro: 0.0476, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.8958, Val Loss: 2.0401, F1 Micro: 0.1771, F1 Macro: 0.0707, Accuracy: 0.1771\n","Epoch 4, Train Loss: 1.9505, Val Loss: 2.2729, F1 Micro: 0.1771, F1 Macro: 0.0908, Accuracy: 0.1771\n","Epoch 5, Train Loss: 2.0625, Val Loss: 2.1936, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 6, Train Loss: 2.0706, Val Loss: 2.3228, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 7, Train Loss: 2.1489, Val Loss: 2.4187, F1 Micro: 0.1771, F1 Macro: 0.0702, Accuracy: 0.1771\n","Epoch 8, Train Loss: 2.2598, Val Loss: 2.1184, F1 Micro: 0.1771, F1 Macro: 0.0921, Accuracy: 0.1771\n","Epoch 9, Train Loss: 2.0956, Val Loss: 2.0465, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 10, Train Loss: 2.1069, Val Loss: 2.1987, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 11, Train Loss: 1.9409, Val Loss: 1.9296, F1 Micro: 0.1771, F1 Macro: 0.0814, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 7.7587, Val Loss: 1.9208, F1 Micro: 0.2188, F1 Macro: 0.1271, Accuracy: 0.2188\n","Epoch 2, Train Loss: 2.0027, Val Loss: 1.7554, F1 Micro: 0.2396, F1 Macro: 0.1296, Accuracy: 0.2396\n","Epoch 3, Train Loss: 2.0136, Val Loss: 1.8657, F1 Micro: 0.2292, F1 Macro: 0.1305, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.8758, Val Loss: 1.7802, F1 Micro: 0.2292, F1 Macro: 0.1279, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.9573, Val Loss: 1.7734, F1 Micro: 0.2500, F1 Macro: 0.1361, Accuracy: 0.2500\n","Epoch 6, Train Loss: 2.0488, Val Loss: 1.9221, F1 Micro: 0.2188, F1 Macro: 0.1258, Accuracy: 0.2188\n","Epoch 7, Train Loss: 2.1604, Val Loss: 1.8813, F1 Micro: 0.2188, F1 Macro: 0.1246, Accuracy: 0.2188\n","Epoch 8, Train Loss: 2.1234, Val Loss: 2.0646, F1 Micro: 0.1562, F1 Macro: 0.0490, Accuracy: 0.1562\n","Epoch 9, Train Loss: 2.0656, Val Loss: 1.8000, F1 Micro: 0.2500, F1 Macro: 0.1354, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.8977, Val Loss: 1.8653, F1 Micro: 0.2292, F1 Macro: 0.1154, Accuracy: 0.2292\n","Epoch 11, Train Loss: 2.1103, Val Loss: 1.7987, F1 Micro: 0.1875, F1 Macro: 0.1029, Accuracy: 0.1875\n","Epoch 12, Train Loss: 2.0177, Val Loss: 1.8780, F1 Micro: 0.2292, F1 Macro: 0.1272, Accuracy: 0.2292\n","Epoch 13, Train Loss: 2.1258, Val Loss: 1.7766, F1 Micro: 0.2396, F1 Macro: 0.1308, Accuracy: 0.2396\n","Epoch 14, Train Loss: 2.2263, Val Loss: 1.8344, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 15, Train Loss: 2.0946, Val Loss: 2.2299, F1 Micro: 0.1562, F1 Macro: 0.0467, Accuracy: 0.1562\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.2458333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 7.2579, Val Loss: 1.7686, F1 Micro: 0.2708, F1 Macro: 0.1456, Accuracy: 0.2708\n","Epoch 2, Train Loss: 2.0878, Val Loss: 2.2015, F1 Micro: 0.2292, F1 Macro: 0.0989, Accuracy: 0.2292\n","Epoch 3, Train Loss: 2.0233, Val Loss: 2.0267, F1 Micro: 0.2604, F1 Macro: 0.1369, Accuracy: 0.2604\n","Epoch 4, Train Loss: 2.0598, Val Loss: 2.2767, F1 Micro: 0.1875, F1 Macro: 0.1227, Accuracy: 0.1875\n","Epoch 5, Train Loss: 2.1689, Val Loss: 1.8874, F1 Micro: 0.2500, F1 Macro: 0.1409, Accuracy: 0.2500\n","Epoch 6, Train Loss: 2.0176, Val Loss: 2.2386, F1 Micro: 0.1354, F1 Macro: 0.0417, Accuracy: 0.1354\n","Epoch 7, Train Loss: 2.1308, Val Loss: 1.7698, F1 Micro: 0.2604, F1 Macro: 0.1397, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.9447, Val Loss: 1.9271, F1 Micro: 0.2604, F1 Macro: 0.1400, Accuracy: 0.2604\n","Epoch 9, Train Loss: 2.1044, Val Loss: 2.0401, F1 Micro: 0.2708, F1 Macro: 0.1423, Accuracy: 0.2708\n","Epoch 10, Train Loss: 2.1459, Val Loss: 1.8513, F1 Micro: 0.2812, F1 Macro: 0.1526, Accuracy: 0.2812\n","Epoch 11, Train Loss: 2.1536, Val Loss: 2.0057, F1 Micro: 0.1875, F1 Macro: 0.1227, Accuracy: 0.1875\n","Epoch 12, Train Loss: 2.0659, Val Loss: 2.1035, F1 Micro: 0.1979, F1 Macro: 0.1242, Accuracy: 0.1979\n","Epoch 13, Train Loss: 2.1945, Val Loss: 2.0880, F1 Micro: 0.1771, F1 Macro: 0.1150, Accuracy: 0.1771\n","Epoch 14, Train Loss: 2.1491, Val Loss: 1.8213, F1 Micro: 0.2604, F1 Macro: 0.1400, Accuracy: 0.2604\n","Epoch 15, Train Loss: 2.0422, Val Loss: 2.2083, F1 Micro: 0.2083, F1 Macro: 0.1335, Accuracy: 0.2083\n","Epoch 16, Train Loss: 2.1456, Val Loss: 2.4711, F1 Micro: 0.1979, F1 Macro: 0.1242, Accuracy: 0.1979\n","Epoch 17, Train Loss: 2.0631, Val Loss: 1.8295, F1 Micro: 0.2708, F1 Macro: 0.1602, Accuracy: 0.2708\n","Epoch 18, Train Loss: 2.0001, Val Loss: 1.8248, F1 Micro: 0.2708, F1 Macro: 0.1501, Accuracy: 0.2708\n","Epoch 19, Train Loss: 2.1431, Val Loss: 2.2320, F1 Micro: 0.1771, F1 Macro: 0.1150, Accuracy: 0.1771\n","Epoch 20, Train Loss: 2.1182, Val Loss: 2.0431, F1 Micro: 0.1667, F1 Macro: 0.0807, Accuracy: 0.1667\n","Epoch 21, Train Loss: 2.1341, Val Loss: 2.4121, F1 Micro: 0.1979, F1 Macro: 0.1306, Accuracy: 0.1979\n","Epoch 22, Train Loss: 2.0844, Val Loss: 2.2117, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 23, Train Loss: 2.0551, Val Loss: 2.2011, F1 Micro: 0.1771, F1 Macro: 0.1150, Accuracy: 0.1771\n","Epoch 24, Train Loss: 2.2977, Val Loss: 2.2820, F1 Micro: 0.2083, F1 Macro: 0.1335, Accuracy: 0.2083\n","Epoch 25, Train Loss: 2.0531, Val Loss: 2.0391, F1 Micro: 0.2188, F1 Macro: 0.1321, Accuracy: 0.2188\n","Epoch 26, Train Loss: 2.2827, Val Loss: 2.2646, F1 Micro: 0.1771, F1 Macro: 0.1182, Accuracy: 0.1771\n","Epoch 27, Train Loss: 2.1398, Val Loss: 2.5651, F1 Micro: 0.1979, F1 Macro: 0.1482, Accuracy: 0.1979\n","Epoch 28, Train Loss: 2.1544, Val Loss: 2.0479, F1 Micro: 0.2396, F1 Macro: 0.1264, Accuracy: 0.2396\n","Epoch 29, Train Loss: 2.2076, Val Loss: 2.3429, F1 Micro: 0.1667, F1 Macro: 0.1017, Accuracy: 0.1667\n","Epoch 30, Train Loss: 2.1426, Val Loss: 1.9528, F1 Micro: 0.2708, F1 Macro: 0.1487, Accuracy: 0.2708\n","Epoch 31, Train Loss: 2.0796, Val Loss: 2.1150, F1 Micro: 0.1771, F1 Macro: 0.1092, Accuracy: 0.1771\n","Epoch 32, Train Loss: 2.0908, Val Loss: 1.8720, F1 Micro: 0.1979, F1 Macro: 0.1211, Accuracy: 0.1979\n","Epoch 33, Train Loss: 2.3440, Val Loss: 2.4777, F1 Micro: 0.1354, F1 Macro: 0.0409, Accuracy: 0.1354\n","Epoch 34, Train Loss: 2.2442, Val Loss: 1.8234, F1 Micro: 0.1979, F1 Macro: 0.1385, Accuracy: 0.1979\n","Epoch 35, Train Loss: 2.2251, Val Loss: 2.0098, F1 Micro: 0.2604, F1 Macro: 0.1423, Accuracy: 0.2604\n","Epoch 36, Train Loss: 2.1277, Val Loss: 2.1451, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 37, Train Loss: 2.0471, Val Loss: 2.6444, F1 Micro: 0.1979, F1 Macro: 0.1242, Accuracy: 0.1979\n","Epoch 38, Train Loss: 2.1491, Val Loss: 2.0916, F1 Micro: 0.2708, F1 Macro: 0.1487, Accuracy: 0.2708\n","Epoch 39, Train Loss: 2.4187, Val Loss: 1.7548, F1 Micro: 0.2604, F1 Macro: 0.1387, Accuracy: 0.2604\n","Epoch 40, Train Loss: 2.1080, Val Loss: 2.1794, F1 Micro: 0.2292, F1 Macro: 0.0982, Accuracy: 0.2292\n","Epoch 41, Train Loss: 2.1901, Val Loss: 2.2562, F1 Micro: 0.2188, F1 Macro: 0.1600, Accuracy: 0.2188\n","Epoch 42, Train Loss: 2.1437, Val Loss: 1.7466, F1 Micro: 0.2604, F1 Macro: 0.1423, Accuracy: 0.2604\n","Epoch 43, Train Loss: 2.2219, Val Loss: 2.2637, F1 Micro: 0.2604, F1 Macro: 0.1400, Accuracy: 0.2604\n","Epoch 44, Train Loss: 2.0955, Val Loss: 1.7356, F1 Micro: 0.2604, F1 Macro: 0.1431, Accuracy: 0.2604\n","Epoch 45, Train Loss: 2.0339, Val Loss: 2.0817, F1 Micro: 0.1979, F1 Macro: 0.1267, Accuracy: 0.1979\n","Epoch 46, Train Loss: 1.9958, Val Loss: 2.4295, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 47, Train Loss: 2.0505, Val Loss: 1.9548, F1 Micro: 0.2500, F1 Macro: 0.1247, Accuracy: 0.2500\n","Epoch 48, Train Loss: 2.1346, Val Loss: 2.0496, F1 Micro: 0.1771, F1 Macro: 0.1083, Accuracy: 0.1771\n","Epoch 49, Train Loss: 2.1130, Val Loss: 2.3684, F1 Micro: 0.1354, F1 Macro: 0.0417, Accuracy: 0.1354\n","Epoch 50, Train Loss: 2.1446, Val Loss: 2.1253, F1 Micro: 0.2604, F1 Macro: 0.1405, Accuracy: 0.2604\n","Epoch 51, Train Loss: 2.2916, Val Loss: 1.9223, F1 Micro: 0.1771, F1 Macro: 0.1202, Accuracy: 0.1771\n","Epoch 52, Train Loss: 3.0481, Val Loss: 3.6665, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 53, Train Loss: 2.2589, Val Loss: 2.0000, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 54, Train Loss: 2.2513, Val Loss: 1.9058, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 55, Train Loss: 2.2832, Val Loss: 2.2419, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 56, Train Loss: 2.1236, Val Loss: 2.5375, F1 Micro: 0.1771, F1 Macro: 0.1083, Accuracy: 0.1771\n","Epoch 57, Train Loss: 2.2071, Val Loss: 1.9370, F1 Micro: 0.1771, F1 Macro: 0.1182, Accuracy: 0.1771\n","Epoch 58, Train Loss: 2.0507, Val Loss: 2.0279, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 59, Train Loss: 2.3654, Val Loss: 1.8739, F1 Micro: 0.1458, F1 Macro: 0.0428, Accuracy: 0.1458\n","Epoch 60, Train Loss: 2.0637, Val Loss: 2.7857, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 6.3442, Val Loss: 2.2877, F1 Micro: 0.1562, F1 Macro: 0.0904, Accuracy: 0.1562\n","Epoch 2, Train Loss: 1.9378, Val Loss: 2.2148, F1 Micro: 0.2396, F1 Macro: 0.1244, Accuracy: 0.2396\n","Epoch 3, Train Loss: 2.0505, Val Loss: 2.2230, F1 Micro: 0.2396, F1 Macro: 0.1270, Accuracy: 0.2396\n","Epoch 4, Train Loss: 2.0700, Val Loss: 2.0273, F1 Micro: 0.2396, F1 Macro: 0.1238, Accuracy: 0.2396\n","Epoch 5, Train Loss: 2.0574, Val Loss: 2.3177, F1 Micro: 0.1354, F1 Macro: 0.0856, Accuracy: 0.1354\n","Epoch 6, Train Loss: 2.1430, Val Loss: 2.1640, F1 Micro: 0.2396, F1 Macro: 0.1668, Accuracy: 0.2396\n","Epoch 7, Train Loss: 2.1065, Val Loss: 2.1060, F1 Micro: 0.2396, F1 Macro: 0.1231, Accuracy: 0.2396\n","Epoch 8, Train Loss: 2.0599, Val Loss: 2.0213, F1 Micro: 0.2500, F1 Macro: 0.1440, Accuracy: 0.2500\n","Epoch 9, Train Loss: 2.0719, Val Loss: 2.1399, F1 Micro: 0.2500, F1 Macro: 0.1583, Accuracy: 0.2500\n","Epoch 10, Train Loss: 2.1436, Val Loss: 1.9153, F1 Micro: 0.1667, F1 Macro: 0.1087, Accuracy: 0.1667\n","Epoch 11, Train Loss: 2.0985, Val Loss: 2.3187, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 12, Train Loss: 2.3091, Val Loss: 2.1254, F1 Micro: 0.2292, F1 Macro: 0.1298, Accuracy: 0.2292\n","Epoch 13, Train Loss: 2.1481, Val Loss: 2.2630, F1 Micro: 0.2500, F1 Macro: 0.1314, Accuracy: 0.2500\n","Epoch 14, Train Loss: 2.0954, Val Loss: 2.4883, F1 Micro: 0.1354, F1 Macro: 0.0856, Accuracy: 0.1354\n","Epoch 15, Train Loss: 2.0953, Val Loss: 2.1515, F1 Micro: 0.2292, F1 Macro: 0.1212, Accuracy: 0.2292\n","Epoch 16, Train Loss: 2.1571, Val Loss: 2.0158, F1 Micro: 0.1562, F1 Macro: 0.1177, Accuracy: 0.1562\n","Epoch 17, Train Loss: 1.9960, Val Loss: 2.0139, F1 Micro: 0.2292, F1 Macro: 0.1223, Accuracy: 0.2292\n","Epoch 18, Train Loss: 2.1601, Val Loss: 2.3038, F1 Micro: 0.1354, F1 Macro: 0.0856, Accuracy: 0.1354\n","Epoch 19, Train Loss: 2.0957, Val Loss: 2.2807, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 20, Train Loss: 2.0960, Val Loss: 2.3894, F1 Micro: 0.2396, F1 Macro: 0.1201, Accuracy: 0.2396\n","Epoch 21, Train Loss: 2.1470, Val Loss: 2.5310, F1 Micro: 0.1771, F1 Macro: 0.1246, Accuracy: 0.1771\n","Epoch 22, Train Loss: 2.2130, Val Loss: 2.1848, F1 Micro: 0.2292, F1 Macro: 0.1262, Accuracy: 0.2292\n","Epoch 23, Train Loss: 2.1330, Val Loss: 2.0265, F1 Micro: 0.2188, F1 Macro: 0.1167, Accuracy: 0.2188\n","Epoch 24, Train Loss: 2.1962, Val Loss: 1.9461, F1 Micro: 0.2292, F1 Macro: 0.1223, Accuracy: 0.2292\n","Epoch 25, Train Loss: 2.2133, Val Loss: 2.6319, F1 Micro: 0.1771, F1 Macro: 0.1252, Accuracy: 0.1771\n","Epoch 26, Train Loss: 2.2111, Val Loss: 1.9317, F1 Micro: 0.2188, F1 Macro: 0.1167, Accuracy: 0.2188\n","Epoch 27, Train Loss: 2.2930, Val Loss: 2.2562, F1 Micro: 0.2188, F1 Macro: 0.1103, Accuracy: 0.2188\n","Epoch 28, Train Loss: 2.2448, Val Loss: 3.0432, F1 Micro: 0.1667, F1 Macro: 0.1023, Accuracy: 0.1667\n","Epoch 29, Train Loss: 2.2113, Val Loss: 2.4604, F1 Micro: 0.2292, F1 Macro: 0.1124, Accuracy: 0.2292\n","Epoch 30, Train Loss: 2.1259, Val Loss: 1.9925, F1 Micro: 0.2500, F1 Macro: 0.1314, Accuracy: 0.2500\n","Epoch 31, Train Loss: 2.2523, Val Loss: 2.4966, F1 Micro: 0.2188, F1 Macro: 0.1127, Accuracy: 0.2188\n","Epoch 32, Train Loss: 2.0330, Val Loss: 2.1565, F1 Micro: 0.2396, F1 Macro: 0.1155, Accuracy: 0.2396\n","Epoch 33, Train Loss: 2.0186, Val Loss: 1.9629, F1 Micro: 0.2188, F1 Macro: 0.1083, Accuracy: 0.2188\n","Epoch 34, Train Loss: 1.9919, Val Loss: 2.2191, F1 Micro: 0.2500, F1 Macro: 0.1314, Accuracy: 0.2500\n","Epoch 35, Train Loss: 2.1068, Val Loss: 2.1312, F1 Micro: 0.1146, F1 Macro: 0.0476, Accuracy: 0.1146\n","Epoch 36, Train Loss: 2.3107, Val Loss: 2.3512, F1 Micro: 0.1042, F1 Macro: 0.0317, Accuracy: 0.1042\n","Epoch 37, Train Loss: 2.2169, Val Loss: 2.5493, F1 Micro: 0.2396, F1 Macro: 0.1221, Accuracy: 0.2396\n","Epoch 38, Train Loss: 2.2609, Val Loss: 3.8828, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 39, Train Loss: 2.0662, Val Loss: 2.1465, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 40, Train Loss: 2.0309, Val Loss: 1.9711, F1 Micro: 0.1458, F1 Macro: 0.0972, Accuracy: 0.1458\n","Epoch 41, Train Loss: 2.1144, Val Loss: 2.2687, F1 Micro: 0.2188, F1 Macro: 0.1103, Accuracy: 0.2188\n","Epoch 42, Train Loss: 2.1244, Val Loss: 2.6586, F1 Micro: 0.1458, F1 Macro: 0.0972, Accuracy: 0.1458\n","Epoch 43, Train Loss: 2.0071, Val Loss: 1.9957, F1 Micro: 0.1667, F1 Macro: 0.1023, Accuracy: 0.1667\n","Epoch 44, Train Loss: 2.2109, Val Loss: 2.2338, F1 Micro: 0.2500, F1 Macro: 0.1314, Accuracy: 0.2500\n","Epoch 45, Train Loss: 2.2157, Val Loss: 2.6390, F1 Micro: 0.1042, F1 Macro: 0.0317, Accuracy: 0.1042\n","Epoch 46, Train Loss: 2.5097, Val Loss: 2.1784, F1 Micro: 0.2292, F1 Macro: 0.1124, Accuracy: 0.2292\n","Epoch 47, Train Loss: 2.2927, Val Loss: 2.9244, F1 Micro: 0.1042, F1 Macro: 0.0317, Accuracy: 0.1042\n","Epoch 48, Train Loss: 2.2053, Val Loss: 2.2543, F1 Micro: 0.2500, F1 Macro: 0.1302, Accuracy: 0.2500\n","Epoch 49, Train Loss: 2.1836, Val Loss: 2.0739, F1 Micro: 0.1667, F1 Macro: 0.1089, Accuracy: 0.1667\n","Epoch 50, Train Loss: 2.1252, Val Loss: 2.0125, F1 Micro: 0.2188, F1 Macro: 0.1475, Accuracy: 0.2188\n","Epoch 51, Train Loss: 2.1573, Val Loss: 2.1642, F1 Micro: 0.1146, F1 Macro: 0.0476, Accuracy: 0.1146\n","Epoch 52, Train Loss: 2.1563, Val Loss: 2.3951, F1 Micro: 0.1354, F1 Macro: 0.0889, Accuracy: 0.1354\n","Epoch 53, Train Loss: 2.2987, Val Loss: 2.1038, F1 Micro: 0.1354, F1 Macro: 0.0813, Accuracy: 0.1354\n","Epoch 54, Train Loss: 2.0688, Val Loss: 2.4932, F1 Micro: 0.2292, F1 Macro: 0.1223, Accuracy: 0.2292\n","Epoch 55, Train Loss: 2.4088, Val Loss: 2.4111, F1 Micro: 0.2396, F1 Macro: 0.1161, Accuracy: 0.2396\n","Epoch 56, Train Loss: 2.1284, Val Loss: 3.7335, F1 Micro: 0.1354, F1 Macro: 0.0882, Accuracy: 0.1354\n","Epoch 57, Train Loss: 2.2545, Val Loss: 3.2614, F1 Micro: 0.2292, F1 Macro: 0.1175, Accuracy: 0.2292\n","Epoch 58, Train Loss: 2.1575, Val Loss: 2.5194, F1 Micro: 0.2188, F1 Macro: 0.1167, Accuracy: 0.2188\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 5.5331, Val Loss: 2.0374, F1 Micro: 0.2083, F1 Macro: 0.1322, Accuracy: 0.2083\n","Epoch 2, Train Loss: 2.0775, Val Loss: 2.3127, F1 Micro: 0.1146, F1 Macro: 0.0719, Accuracy: 0.1146\n","Epoch 3, Train Loss: 2.0682, Val Loss: 2.1165, F1 Micro: 0.1458, F1 Macro: 0.0432, Accuracy: 0.1458\n","Epoch 4, Train Loss: 2.0574, Val Loss: 2.0788, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.9625, Val Loss: 2.1692, F1 Micro: 0.2396, F1 Macro: 0.1063, Accuracy: 0.2396\n","Epoch 6, Train Loss: 2.1256, Val Loss: 2.1666, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 7, Train Loss: 2.0282, Val Loss: 2.2907, F1 Micro: 0.2292, F1 Macro: 0.1072, Accuracy: 0.2292\n","Epoch 8, Train Loss: 2.0957, Val Loss: 1.9662, F1 Micro: 0.2396, F1 Macro: 0.1122, Accuracy: 0.2396\n","Epoch 9, Train Loss: 2.1074, Val Loss: 2.2255, F1 Micro: 0.1250, F1 Macro: 0.0789, Accuracy: 0.1250\n","Epoch 10, Train Loss: 1.9718, Val Loss: 2.1780, F1 Micro: 0.1771, F1 Macro: 0.0819, Accuracy: 0.1771\n","Epoch 11, Train Loss: 2.1244, Val Loss: 2.5831, F1 Micro: 0.2292, F1 Macro: 0.1037, Accuracy: 0.2292\n","Epoch 12, Train Loss: 2.1102, Val Loss: 2.2300, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 13, Train Loss: 1.9929, Val Loss: 1.9348, F1 Micro: 0.2396, F1 Macro: 0.1063, Accuracy: 0.2396\n","Epoch 14, Train Loss: 2.0791, Val Loss: 1.9056, F1 Micro: 0.1042, F1 Macro: 0.0687, Accuracy: 0.1042\n","Epoch 15, Train Loss: 2.0248, Val Loss: 2.1641, F1 Micro: 0.2292, F1 Macro: 0.1026, Accuracy: 0.2292\n","Epoch 16, Train Loss: 2.0923, Val Loss: 2.4283, F1 Micro: 0.1250, F1 Macro: 0.0789, Accuracy: 0.1250\n","Epoch 17, Train Loss: 2.2040, Val Loss: 2.0868, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 18, Train Loss: 2.3429, Val Loss: 2.1070, F1 Micro: 0.1771, F1 Macro: 0.0887, Accuracy: 0.1771\n","Epoch 19, Train Loss: 2.1938, Val Loss: 2.5499, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 20, Train Loss: 2.1576, Val Loss: 1.8856, F1 Micro: 0.1979, F1 Macro: 0.0556, Accuracy: 0.1979\n","Epoch 21, Train Loss: 2.1088, Val Loss: 2.1679, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 22, Train Loss: 2.1443, Val Loss: 2.4770, F1 Micro: 0.1250, F1 Macro: 0.0804, Accuracy: 0.1250\n","Epoch 23, Train Loss: 2.2854, Val Loss: 2.4154, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 24, Train Loss: 2.5072, Val Loss: 2.6437, F1 Micro: 0.0938, F1 Macro: 0.0538, Accuracy: 0.0938\n","Epoch 25, Train Loss: 2.0039, Val Loss: 2.2489, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 26, Train Loss: 2.1131, Val Loss: 2.1808, F1 Micro: 0.2188, F1 Macro: 0.0843, Accuracy: 0.2188\n","Epoch 27, Train Loss: 2.0852, Val Loss: 2.1579, F1 Micro: 0.0938, F1 Macro: 0.0512, Accuracy: 0.0938\n","Epoch 28, Train Loss: 2.0685, Val Loss: 2.3081, F1 Micro: 0.2188, F1 Macro: 0.0882, Accuracy: 0.2188\n","Epoch 29, Train Loss: 2.1837, Val Loss: 2.4737, F1 Micro: 0.1667, F1 Macro: 0.0714, Accuracy: 0.1667\n","Epoch 30, Train Loss: 2.2178, Val Loss: 2.1294, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 31, Train Loss: 2.1365, Val Loss: 1.9938, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 32, Train Loss: 2.2024, Val Loss: 2.0641, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 33, Train Loss: 2.2517, Val Loss: 2.0923, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 34, Train Loss: 2.2063, Val Loss: 1.8953, F1 Micro: 0.1458, F1 Macro: 0.0449, Accuracy: 0.1458\n","Epoch 35, Train Loss: 2.1693, Val Loss: 1.9541, F1 Micro: 0.2292, F1 Macro: 0.1072, Accuracy: 0.2292\n","Epoch 36, Train Loss: 2.0754, Val Loss: 1.8326, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 37, Train Loss: 2.1819, Val Loss: 2.0612, F1 Micro: 0.2396, F1 Macro: 0.1122, Accuracy: 0.2396\n","Epoch 38, Train Loss: 2.1142, Val Loss: 2.0844, F1 Micro: 0.1979, F1 Macro: 0.0985, Accuracy: 0.1979\n","Epoch 39, Train Loss: 2.1420, Val Loss: 2.2479, F1 Micro: 0.2396, F1 Macro: 0.1063, Accuracy: 0.2396\n","Epoch 40, Train Loss: 2.4378, Val Loss: 2.1879, F1 Micro: 0.2292, F1 Macro: 0.1095, Accuracy: 0.2292\n","Epoch 41, Train Loss: 2.3253, Val Loss: 2.1689, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 42, Train Loss: 2.2857, Val Loss: 1.9227, F1 Micro: 0.2188, F1 Macro: 0.0843, Accuracy: 0.2188\n","Epoch 43, Train Loss: 2.2164, Val Loss: 2.3324, F1 Micro: 0.1250, F1 Macro: 0.0804, Accuracy: 0.1250\n","Epoch 44, Train Loss: 2.1197, Val Loss: 2.2949, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 45, Train Loss: 2.2727, Val Loss: 1.9545, F1 Micro: 0.2083, F1 Macro: 0.1046, Accuracy: 0.2083\n","Epoch 46, Train Loss: 1.9821, Val Loss: 1.8762, F1 Micro: 0.2292, F1 Macro: 0.1161, Accuracy: 0.2292\n","Epoch 47, Train Loss: 2.1153, Val Loss: 2.3118, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 48, Train Loss: 2.3172, Val Loss: 2.0188, F1 Micro: 0.2188, F1 Macro: 0.1011, Accuracy: 0.2188\n","Epoch 49, Train Loss: 2.0074, Val Loss: 2.4698, F1 Micro: 0.1250, F1 Macro: 0.0804, Accuracy: 0.1250\n","Epoch 50, Train Loss: 2.1197, Val Loss: 2.0495, F1 Micro: 0.1979, F1 Macro: 0.0970, Accuracy: 0.1979\n","Epoch 51, Train Loss: 2.2689, Val Loss: 2.0235, F1 Micro: 0.1979, F1 Macro: 0.0970, Accuracy: 0.1979\n","Epoch 52, Train Loss: 2.3529, Val Loss: 3.1241, F1 Micro: 0.1979, F1 Macro: 0.1018, Accuracy: 0.1979\n","Epoch 53, Train Loss: 2.4572, Val Loss: 2.6155, F1 Micro: 0.0833, F1 Macro: 0.0380, Accuracy: 0.0833\n","Epoch 54, Train Loss: 2.4770, Val Loss: 3.0106, F1 Micro: 0.2292, F1 Macro: 0.0951, Accuracy: 0.2292\n","Epoch 55, Train Loss: 2.1171, Val Loss: 2.3106, F1 Micro: 0.1771, F1 Macro: 0.0819, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 5.6904, Val Loss: 2.4013, F1 Micro: 0.2083, F1 Macro: 0.1221, Accuracy: 0.2083\n","Epoch 2, Train Loss: 2.0058, Val Loss: 1.9189, F1 Micro: 0.1875, F1 Macro: 0.1047, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.8910, Val Loss: 1.8511, F1 Micro: 0.1562, F1 Macro: 0.1072, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.9156, Val Loss: 2.2874, F1 Micro: 0.1771, F1 Macro: 0.0702, Accuracy: 0.1771\n","Epoch 5, Train Loss: 2.1102, Val Loss: 2.4031, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 6, Train Loss: 2.0459, Val Loss: 2.1118, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.9472, Val Loss: 2.1271, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 2.0403, Val Loss: 1.8558, F1 Micro: 0.2188, F1 Macro: 0.1032, Accuracy: 0.2188\n","Epoch 9, Train Loss: 2.0843, Val Loss: 1.9045, F1 Micro: 0.1667, F1 Macro: 0.0791, Accuracy: 0.1667\n","Epoch 10, Train Loss: 2.2019, Val Loss: 2.2719, F1 Micro: 0.1771, F1 Macro: 0.0925, Accuracy: 0.1771\n","Epoch 11, Train Loss: 2.1410, Val Loss: 2.3142, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 12, Train Loss: 2.0563, Val Loss: 2.0674, F1 Micro: 0.1979, F1 Macro: 0.0958, Accuracy: 0.1979\n","Epoch 13, Train Loss: 2.0139, Val Loss: 2.1958, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 14, Train Loss: 2.2441, Val Loss: 1.9575, F1 Micro: 0.1667, F1 Macro: 0.0503, Accuracy: 0.1667\n","Epoch 15, Train Loss: 2.1157, Val Loss: 2.2387, F1 Micro: 0.1979, F1 Macro: 0.0975, Accuracy: 0.1979\n","Epoch 16, Train Loss: 2.1312, Val Loss: 2.4465, F1 Micro: 0.1667, F1 Macro: 0.0680, Accuracy: 0.1667\n","Epoch 17, Train Loss: 2.1454, Val Loss: 2.1491, F1 Micro: 0.1667, F1 Macro: 0.0494, Accuracy: 0.1667\n","Epoch 18, Train Loss: 2.1038, Val Loss: 2.0157, F1 Micro: 0.1979, F1 Macro: 0.0732, Accuracy: 0.1979\n","Epoch 19, Train Loss: 2.1516, Val Loss: 2.3960, F1 Micro: 0.1875, F1 Macro: 0.0946, Accuracy: 0.1875\n","Epoch 20, Train Loss: 2.0727, Val Loss: 2.1196, F1 Micro: 0.1979, F1 Macro: 0.1114, Accuracy: 0.1979\n","Epoch 21, Train Loss: 2.2014, Val Loss: 1.8840, F1 Micro: 0.1875, F1 Macro: 0.0849, Accuracy: 0.1875\n","Epoch 22, Train Loss: 2.0209, Val Loss: 2.4922, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 23, Train Loss: 2.4041, Val Loss: 2.2646, F1 Micro: 0.1667, F1 Macro: 0.0503, Accuracy: 0.1667\n","Epoch 24, Train Loss: 2.1750, Val Loss: 2.0080, F1 Micro: 0.2188, F1 Macro: 0.1207, Accuracy: 0.2188\n","Epoch 25, Train Loss: 2.1089, Val Loss: 2.1653, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 26, Train Loss: 2.0799, Val Loss: 1.8787, F1 Micro: 0.1562, F1 Macro: 0.0459, Accuracy: 0.1562\n","Epoch 27, Train Loss: 2.1168, Val Loss: 2.4435, F1 Micro: 0.1562, F1 Macro: 0.0472, Accuracy: 0.1562\n","Epoch 28, Train Loss: 1.9718, Val Loss: 2.3687, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 29, Train Loss: 2.0411, Val Loss: 1.9524, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 30, Train Loss: 2.0098, Val Loss: 1.9834, F1 Micro: 0.1667, F1 Macro: 0.0680, Accuracy: 0.1667\n","Epoch 31, Train Loss: 1.9629, Val Loss: 2.0010, F1 Micro: 0.1771, F1 Macro: 0.0925, Accuracy: 0.1771\n","Epoch 32, Train Loss: 2.2174, Val Loss: 2.3257, F1 Micro: 0.1667, F1 Macro: 0.0680, Accuracy: 0.1667\n","Epoch 33, Train Loss: 2.1563, Val Loss: 2.0051, F1 Micro: 0.1979, F1 Macro: 0.0746, Accuracy: 0.1979\n","Epoch 34, Train Loss: 2.0691, Val Loss: 2.5261, F1 Micro: 0.1771, F1 Macro: 0.0801, Accuracy: 0.1771\n","Epoch 35, Train Loss: 2.2047, Val Loss: 1.9292, F1 Micro: 0.1562, F1 Macro: 0.0641, Accuracy: 0.1562\n","Epoch 36, Train Loss: 1.9863, Val Loss: 1.9440, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 37, Train Loss: 2.0351, Val Loss: 2.1596, F1 Micro: 0.1979, F1 Macro: 0.0732, Accuracy: 0.1979\n","Epoch 38, Train Loss: 2.0920, Val Loss: 2.1776, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 39, Train Loss: 2.4350, Val Loss: 2.6993, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 40, Train Loss: 2.1524, Val Loss: 2.3741, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 41, Train Loss: 2.1488, Val Loss: 2.2088, F1 Micro: 0.1458, F1 Macro: 0.0449, Accuracy: 0.1458\n","Epoch 42, Train Loss: 2.1347, Val Loss: 2.1357, F1 Micro: 0.1667, F1 Macro: 0.0638, Accuracy: 0.1667\n","Epoch 43, Train Loss: 2.2098, Val Loss: 2.4109, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 44, Train Loss: 2.5039, Val Loss: 2.0936, F1 Micro: 0.1667, F1 Macro: 0.0778, Accuracy: 0.1667\n","Epoch 45, Train Loss: 2.1543, Val Loss: 2.4053, F1 Micro: 0.1875, F1 Macro: 0.0821, Accuracy: 0.1875\n","Epoch 46, Train Loss: 2.3008, Val Loss: 1.8502, F1 Micro: 0.2188, F1 Macro: 0.1050, Accuracy: 0.2188\n","Epoch 47, Train Loss: 2.1269, Val Loss: 1.9768, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 48, Train Loss: 2.0212, Val Loss: 1.8719, F1 Micro: 0.1667, F1 Macro: 0.0648, Accuracy: 0.1667\n","Epoch 49, Train Loss: 1.9278, Val Loss: 1.9552, F1 Micro: 0.1771, F1 Macro: 0.0681, Accuracy: 0.1771\n","Epoch 50, Train Loss: 2.0739, Val Loss: 1.8811, F1 Micro: 0.2188, F1 Macro: 0.1032, Accuracy: 0.2188\n","Epoch 51, Train Loss: 2.0677, Val Loss: 2.2013, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 52, Train Loss: 2.1124, Val Loss: 2.0526, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 53, Train Loss: 2.1278, Val Loss: 2.2104, F1 Micro: 0.1667, F1 Macro: 0.0652, Accuracy: 0.1667\n","Epoch 54, Train Loss: 2.1782, Val Loss: 2.0380, F1 Micro: 0.1771, F1 Macro: 0.0726, Accuracy: 0.1771\n","Epoch 55, Train Loss: 2.0543, Val Loss: 1.8221, F1 Micro: 0.2188, F1 Macro: 0.1207, Accuracy: 0.2188\n","Epoch 56, Train Loss: 2.1369, Val Loss: 2.5608, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 57, Train Loss: 2.2716, Val Loss: 2.2242, F1 Micro: 0.1771, F1 Macro: 0.0801, Accuracy: 0.1771\n","Epoch 58, Train Loss: 2.1671, Val Loss: 2.4703, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 6.7369, Val Loss: 1.7170, F1 Micro: 0.2500, F1 Macro: 0.1466, Accuracy: 0.2500\n","Epoch 2, Train Loss: 2.1005, Val Loss: 2.1753, F1 Micro: 0.1562, F1 Macro: 0.0490, Accuracy: 0.1562\n","Epoch 3, Train Loss: 2.0236, Val Loss: 2.3448, F1 Micro: 0.1562, F1 Macro: 0.0481, Accuracy: 0.1562\n","Epoch 4, Train Loss: 2.2255, Val Loss: 1.9615, F1 Micro: 0.2292, F1 Macro: 0.1346, Accuracy: 0.2292\n","Epoch 5, Train Loss: 2.0211, Val Loss: 1.9521, F1 Micro: 0.2812, F1 Macro: 0.1772, Accuracy: 0.2812\n","Epoch 6, Train Loss: 2.0674, Val Loss: 2.0887, F1 Micro: 0.2083, F1 Macro: 0.1172, Accuracy: 0.2083\n","Epoch 7, Train Loss: 2.0197, Val Loss: 1.9998, F1 Micro: 0.1562, F1 Macro: 0.0490, Accuracy: 0.1562\n","Epoch 8, Train Loss: 1.9819, Val Loss: 2.5634, F1 Micro: 0.2292, F1 Macro: 0.1290, Accuracy: 0.2292\n","Epoch 9, Train Loss: 2.0475, Val Loss: 1.8458, F1 Micro: 0.1875, F1 Macro: 0.0880, Accuracy: 0.1875\n","Epoch 10, Train Loss: 2.0542, Val Loss: 2.0016, F1 Micro: 0.2292, F1 Macro: 0.1327, Accuracy: 0.2292\n","Epoch 11, Train Loss: 2.1406, Val Loss: 2.0991, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 12, Train Loss: 2.1966, Val Loss: 1.9060, F1 Micro: 0.2396, F1 Macro: 0.1497, Accuracy: 0.2396\n","Epoch 13, Train Loss: 2.0772, Val Loss: 2.1593, F1 Micro: 0.2292, F1 Macro: 0.1290, Accuracy: 0.2292\n","Epoch 14, Train Loss: 2.0532, Val Loss: 1.9797, F1 Micro: 0.2396, F1 Macro: 0.1644, Accuracy: 0.2396\n","Epoch 15, Train Loss: 2.1422, Val Loss: 2.0512, F1 Micro: 0.1771, F1 Macro: 0.0910, Accuracy: 0.1771\n","Epoch 16, Train Loss: 2.0295, Val Loss: 2.0182, F1 Micro: 0.1979, F1 Macro: 0.0894, Accuracy: 0.1979\n","Epoch 17, Train Loss: 2.0923, Val Loss: 1.9053, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 18, Train Loss: 2.1242, Val Loss: 2.1012, F1 Micro: 0.2396, F1 Macro: 0.1341, Accuracy: 0.2396\n","Epoch 19, Train Loss: 2.2735, Val Loss: 1.8045, F1 Micro: 0.2604, F1 Macro: 0.1137, Accuracy: 0.2604\n","Epoch 20, Train Loss: 2.0526, Val Loss: 1.9244, F1 Micro: 0.2292, F1 Macro: 0.1327, Accuracy: 0.2292\n","Epoch 21, Train Loss: 2.1957, Val Loss: 2.5187, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 22, Train Loss: 2.4635, Val Loss: 2.6174, F1 Micro: 0.1667, F1 Macro: 0.0629, Accuracy: 0.1667\n","Epoch 23, Train Loss: 2.2972, Val Loss: 2.4004, F1 Micro: 0.2083, F1 Macro: 0.1113, Accuracy: 0.2083\n","Epoch 24, Train Loss: 2.1608, Val Loss: 2.3479, F1 Micro: 0.1979, F1 Macro: 0.1094, Accuracy: 0.1979\n","Epoch 25, Train Loss: 2.0393, Val Loss: 2.2555, F1 Micro: 0.2292, F1 Macro: 0.1290, Accuracy: 0.2292\n","Epoch 26, Train Loss: 2.1985, Val Loss: 1.9693, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 27, Train Loss: 1.9632, Val Loss: 1.7797, F1 Micro: 0.2292, F1 Macro: 0.1290, Accuracy: 0.2292\n","Epoch 28, Train Loss: 1.9992, Val Loss: 1.7926, F1 Micro: 0.2500, F1 Macro: 0.1361, Accuracy: 0.2500\n","Epoch 29, Train Loss: 2.1659, Val Loss: 2.4923, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 30, Train Loss: 2.2556, Val Loss: 1.7952, F1 Micro: 0.2396, F1 Macro: 0.1308, Accuracy: 0.2396\n","Epoch 31, Train Loss: 2.1197, Val Loss: 1.8431, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 32, Train Loss: 2.2247, Val Loss: 2.4502, F1 Micro: 0.2188, F1 Macro: 0.1235, Accuracy: 0.2188\n","Epoch 33, Train Loss: 2.0814, Val Loss: 2.6856, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 34, Train Loss: 2.1027, Val Loss: 1.9950, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 35, Train Loss: 2.0553, Val Loss: 1.8493, F1 Micro: 0.2188, F1 Macro: 0.1139, Accuracy: 0.2188\n","Epoch 36, Train Loss: 2.0438, Val Loss: 1.8517, F1 Micro: 0.2500, F1 Macro: 0.1664, Accuracy: 0.2500\n","Epoch 37, Train Loss: 2.2069, Val Loss: 2.0426, F1 Micro: 0.1979, F1 Macro: 0.1178, Accuracy: 0.1979\n","Epoch 38, Train Loss: 2.1961, Val Loss: 1.8228, F1 Micro: 0.2292, F1 Macro: 0.1279, Accuracy: 0.2292\n","Epoch 39, Train Loss: 2.2740, Val Loss: 2.2271, F1 Micro: 0.2188, F1 Macro: 0.1240, Accuracy: 0.2188\n","Epoch 40, Train Loss: 2.0658, Val Loss: 2.0797, F1 Micro: 0.2188, F1 Macro: 0.1262, Accuracy: 0.2188\n","Epoch 41, Train Loss: 2.0731, Val Loss: 1.8906, F1 Micro: 0.2396, F1 Macro: 0.1735, Accuracy: 0.2396\n","Epoch 42, Train Loss: 2.1049, Val Loss: 2.3322, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 43, Train Loss: 2.4544, Val Loss: 2.2738, F1 Micro: 0.1771, F1 Macro: 0.0874, Accuracy: 0.1771\n","Epoch 44, Train Loss: 2.2921, Val Loss: 2.5445, F1 Micro: 0.2188, F1 Macro: 0.1246, Accuracy: 0.2188\n","Epoch 45, Train Loss: 2.4110, Val Loss: 2.5954, F1 Micro: 0.1771, F1 Macro: 0.0853, Accuracy: 0.1771\n","Epoch 46, Train Loss: 2.1573, Val Loss: 1.9173, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 47, Train Loss: 1.9505, Val Loss: 1.8490, F1 Micro: 0.2292, F1 Macro: 0.1279, Accuracy: 0.2292\n","Epoch 48, Train Loss: 2.0802, Val Loss: 2.1673, F1 Micro: 0.1771, F1 Macro: 0.1058, Accuracy: 0.1771\n","Epoch 49, Train Loss: 2.1296, Val Loss: 2.3610, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 50, Train Loss: 2.2983, Val Loss: 2.3809, F1 Micro: 0.2292, F1 Macro: 0.1454, Accuracy: 0.2292\n","Epoch 51, Train Loss: 2.2579, Val Loss: 2.0225, F1 Micro: 0.1875, F1 Macro: 0.0893, Accuracy: 0.1875\n","Epoch 52, Train Loss: 2.0703, Val Loss: 2.1439, F1 Micro: 0.2188, F1 Macro: 0.1291, Accuracy: 0.2188\n","Epoch 53, Train Loss: 2.1780, Val Loss: 2.2609, F1 Micro: 0.2188, F1 Macro: 0.1267, Accuracy: 0.2188\n","Epoch 54, Train Loss: 2.0704, Val Loss: 1.8423, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 55, Train Loss: 2.2210, Val Loss: 1.9356, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.2541666666666667\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 7.6594, Val Loss: 2.0295, F1 Micro: 0.1458, F1 Macro: 0.0737, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.9288, Val Loss: 2.0629, F1 Micro: 0.1875, F1 Macro: 0.1214, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.8983, Val Loss: 1.8368, F1 Micro: 0.1562, F1 Macro: 0.0912, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.9193, Val Loss: 1.8912, F1 Micro: 0.2604, F1 Macro: 0.1807, Accuracy: 0.2604\n","Epoch 5, Train Loss: 2.0901, Val Loss: 2.5838, F1 Micro: 0.1458, F1 Macro: 0.0610, Accuracy: 0.1458\n","Epoch 6, Train Loss: 1.9840, Val Loss: 1.7495, F1 Micro: 0.2500, F1 Macro: 0.1608, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.8346, Val Loss: 1.7707, F1 Micro: 0.2396, F1 Macro: 0.1563, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.9028, Val Loss: 2.0380, F1 Micro: 0.1771, F1 Macro: 0.1182, Accuracy: 0.1771\n","Epoch 9, Train Loss: 1.9565, Val Loss: 1.7526, F1 Micro: 0.2083, F1 Macro: 0.1590, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.9229, Val Loss: 1.9080, F1 Micro: 0.2083, F1 Macro: 0.1100, Accuracy: 0.2083\n","Epoch 11, Train Loss: 1.9177, Val Loss: 1.7526, F1 Micro: 0.1875, F1 Macro: 0.0953, Accuracy: 0.1875\n","Epoch 12, Train Loss: 2.0710, Val Loss: 2.1153, F1 Micro: 0.1875, F1 Macro: 0.1204, Accuracy: 0.1875\n","Epoch 13, Train Loss: 1.9751, Val Loss: 1.8785, F1 Micro: 0.2812, F1 Macro: 0.1731, Accuracy: 0.2812\n","Epoch 14, Train Loss: 2.0007, Val Loss: 1.8403, F1 Micro: 0.2604, F1 Macro: 0.1403, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.9249, Val Loss: 1.8005, F1 Micro: 0.2188, F1 Macro: 0.1631, Accuracy: 0.2188\n","Epoch 16, Train Loss: 1.8523, Val Loss: 2.4101, F1 Micro: 0.1875, F1 Macro: 0.1214, Accuracy: 0.1875\n","Epoch 17, Train Loss: 2.0664, Val Loss: 2.1297, F1 Micro: 0.2708, F1 Macro: 0.1588, Accuracy: 0.2708\n","Epoch 18, Train Loss: 1.8573, Val Loss: 1.7009, F1 Micro: 0.2708, F1 Macro: 0.1356, Accuracy: 0.2708\n","Epoch 19, Train Loss: 2.0187, Val Loss: 2.1538, F1 Micro: 0.2500, F1 Macro: 0.1758, Accuracy: 0.2500\n","Epoch 20, Train Loss: 1.9881, Val Loss: 1.9317, F1 Micro: 0.2708, F1 Macro: 0.1429, Accuracy: 0.2708\n","Epoch 21, Train Loss: 2.0941, Val Loss: 1.8610, F1 Micro: 0.1979, F1 Macro: 0.1211, Accuracy: 0.1979\n","Epoch 22, Train Loss: 1.9700, Val Loss: 2.0014, F1 Micro: 0.2083, F1 Macro: 0.1505, Accuracy: 0.2083\n","Epoch 23, Train Loss: 1.9555, Val Loss: 2.1186, F1 Micro: 0.2188, F1 Macro: 0.1483, Accuracy: 0.2188\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 11.1286, Val Loss: 1.9905, F1 Micro: 0.1771, F1 Macro: 0.1266, Accuracy: 0.1771\n","Epoch 2, Train Loss: 1.9644, Val Loss: 1.7928, F1 Micro: 0.2083, F1 Macro: 0.1574, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.8661, Val Loss: 1.9942, F1 Micro: 0.1667, F1 Macro: 0.0965, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.9115, Val Loss: 1.8313, F1 Micro: 0.1667, F1 Macro: 0.1097, Accuracy: 0.1667\n","Epoch 5, Train Loss: 1.8566, Val Loss: 2.0232, F1 Micro: 0.1771, F1 Macro: 0.1403, Accuracy: 0.1771\n","Epoch 6, Train Loss: 1.8697, Val Loss: 1.7745, F1 Micro: 0.3021, F1 Macro: 0.1992, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.8031, Val Loss: 1.8395, F1 Micro: 0.2396, F1 Macro: 0.1606, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.8632, Val Loss: 2.1596, F1 Micro: 0.1146, F1 Macro: 0.0476, Accuracy: 0.1146\n","Epoch 9, Train Loss: 2.0279, Val Loss: 2.1388, F1 Micro: 0.1979, F1 Macro: 0.1472, Accuracy: 0.1979\n","Epoch 10, Train Loss: 1.9656, Val Loss: 1.8367, F1 Micro: 0.2604, F1 Macro: 0.1327, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.9548, Val Loss: 1.9885, F1 Micro: 0.1979, F1 Macro: 0.1481, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.9090, Val Loss: 1.8578, F1 Micro: 0.1771, F1 Macro: 0.1407, Accuracy: 0.1771\n","Epoch 13, Train Loss: 1.8012, Val Loss: 1.7356, F1 Micro: 0.2917, F1 Macro: 0.1927, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.7961, Val Loss: 1.6941, F1 Micro: 0.2812, F1 Macro: 0.1943, Accuracy: 0.2812\n","Epoch 15, Train Loss: 1.9380, Val Loss: 1.8814, F1 Micro: 0.2292, F1 Macro: 0.1421, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.9116, Val Loss: 1.7547, F1 Micro: 0.3125, F1 Macro: 0.2007, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.8035, Val Loss: 1.9927, F1 Micro: 0.2500, F1 Macro: 0.1572, Accuracy: 0.2500\n","Epoch 18, Train Loss: 1.9425, Val Loss: 1.9233, F1 Micro: 0.1562, F1 Macro: 0.1140, Accuracy: 0.1562\n","Epoch 19, Train Loss: 1.9391, Val Loss: 1.9451, F1 Micro: 0.1979, F1 Macro: 0.1481, Accuracy: 0.1979\n","Epoch 20, Train Loss: 1.8871, Val Loss: 1.9593, F1 Micro: 0.2083, F1 Macro: 0.1638, Accuracy: 0.2083\n","Epoch 21, Train Loss: 1.8512, Val Loss: 2.1983, F1 Micro: 0.2604, F1 Macro: 0.1418, Accuracy: 0.2604\n","Epoch 22, Train Loss: 1.8330, Val Loss: 1.9524, F1 Micro: 0.1771, F1 Macro: 0.1360, Accuracy: 0.1771\n","Epoch 23, Train Loss: 1.9288, Val Loss: 1.8675, F1 Micro: 0.1875, F1 Macro: 0.1494, Accuracy: 0.1875\n","Epoch 24, Train Loss: 1.9285, Val Loss: 1.7129, F1 Micro: 0.2812, F1 Macro: 0.1812, Accuracy: 0.2812\n","Epoch 25, Train Loss: 1.9449, Val Loss: 1.8520, F1 Micro: 0.2500, F1 Macro: 0.1247, Accuracy: 0.2500\n","Epoch 26, Train Loss: 2.0133, Val Loss: 2.3580, F1 Micro: 0.1146, F1 Macro: 0.0476, Accuracy: 0.1146\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 11.1185, Val Loss: 2.6779, F1 Micro: 0.2188, F1 Macro: 0.1372, Accuracy: 0.2188\n","Epoch 2, Train Loss: 2.2190, Val Loss: 1.9102, F1 Micro: 0.1146, F1 Macro: 0.0725, Accuracy: 0.1146\n","Epoch 3, Train Loss: 1.8132, Val Loss: 2.0165, F1 Micro: 0.1979, F1 Macro: 0.0960, Accuracy: 0.1979\n","Epoch 4, Train Loss: 1.9521, Val Loss: 2.0181, F1 Micro: 0.2292, F1 Macro: 0.1021, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.8313, Val Loss: 1.8344, F1 Micro: 0.1875, F1 Macro: 0.1070, Accuracy: 0.1875\n","Epoch 6, Train Loss: 1.7982, Val Loss: 1.8786, F1 Micro: 0.2188, F1 Macro: 0.1260, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.7787, Val Loss: 1.7951, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.8721, Val Loss: 2.0921, F1 Micro: 0.1979, F1 Macro: 0.1198, Accuracy: 0.1979\n","Epoch 9, Train Loss: 1.9325, Val Loss: 2.2298, F1 Micro: 0.1979, F1 Macro: 0.1272, Accuracy: 0.1979\n","Epoch 10, Train Loss: 1.8264, Val Loss: 1.8138, F1 Micro: 0.2292, F1 Macro: 0.1174, Accuracy: 0.2292\n","Epoch 11, Train Loss: 1.8286, Val Loss: 1.9118, F1 Micro: 0.2083, F1 Macro: 0.1195, Accuracy: 0.2083\n","Epoch 12, Train Loss: 1.8638, Val Loss: 1.8243, F1 Micro: 0.2292, F1 Macro: 0.1026, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.9005, Val Loss: 1.9369, F1 Micro: 0.2188, F1 Macro: 0.0984, Accuracy: 0.2188\n","Epoch 14, Train Loss: 1.8504, Val Loss: 2.0230, F1 Micro: 0.2083, F1 Macro: 0.1621, Accuracy: 0.2083\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 6.8038, Val Loss: 1.8366, F1 Micro: 0.1458, F1 Macro: 0.0784, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.9495, Val Loss: 1.8881, F1 Micro: 0.2292, F1 Macro: 0.1561, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.8847, Val Loss: 1.7544, F1 Micro: 0.2292, F1 Macro: 0.2015, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.8958, Val Loss: 1.8439, F1 Micro: 0.1875, F1 Macro: 0.0705, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.8526, Val Loss: 1.9149, F1 Micro: 0.2292, F1 Macro: 0.1582, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.8759, Val Loss: 1.9574, F1 Micro: 0.1979, F1 Macro: 0.1334, Accuracy: 0.1979\n","Epoch 7, Train Loss: 1.8160, Val Loss: 1.8538, F1 Micro: 0.2396, F1 Macro: 0.1633, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.9218, Val Loss: 1.9842, F1 Micro: 0.1562, F1 Macro: 0.0700, Accuracy: 0.1562\n","Epoch 9, Train Loss: 1.9704, Val Loss: 2.0553, F1 Micro: 0.1875, F1 Macro: 0.1230, Accuracy: 0.1875\n","Epoch 10, Train Loss: 1.8785, Val Loss: 1.9240, F1 Micro: 0.1979, F1 Macro: 0.0871, Accuracy: 0.1979\n","Epoch 11, Train Loss: 2.1131, Val Loss: 2.2811, F1 Micro: 0.2188, F1 Macro: 0.1095, Accuracy: 0.2188\n","Epoch 12, Train Loss: 1.9976, Val Loss: 1.9010, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 13, Train Loss: 1.9121, Val Loss: 1.9598, F1 Micro: 0.1562, F1 Macro: 0.0630, Accuracy: 0.1562\n","Epoch 14, Train Loss: 2.0175, Val Loss: 2.3281, F1 Micro: 0.1667, F1 Macro: 0.0680, Accuracy: 0.1667\n","Epoch 15, Train Loss: 1.9458, Val Loss: 2.0134, F1 Micro: 0.1562, F1 Macro: 0.0640, Accuracy: 0.1562\n","Epoch 16, Train Loss: 2.2020, Val Loss: 1.8811, F1 Micro: 0.2083, F1 Macro: 0.1117, Accuracy: 0.2083\n","Epoch 17, Train Loss: 2.0576, Val Loss: 2.1373, F1 Micro: 0.2292, F1 Macro: 0.1228, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 7.2296, Val Loss: 1.9133, F1 Micro: 0.2292, F1 Macro: 0.1325, Accuracy: 0.2292\n","Epoch 2, Train Loss: 1.9910, Val Loss: 1.9200, F1 Micro: 0.2292, F1 Macro: 0.1305, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.9408, Val Loss: 1.7970, F1 Micro: 0.2396, F1 Macro: 0.1333, Accuracy: 0.2396\n","Epoch 4, Train Loss: 1.9284, Val Loss: 1.7390, F1 Micro: 0.2604, F1 Macro: 0.1633, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.9889, Val Loss: 1.9159, F1 Micro: 0.2292, F1 Macro: 0.1461, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.9573, Val Loss: 1.7725, F1 Micro: 0.3125, F1 Macro: 0.2390, Accuracy: 0.3125\n","Epoch 7, Train Loss: 1.8448, Val Loss: 2.0126, F1 Micro: 0.2292, F1 Macro: 0.1268, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.9377, Val Loss: 1.7268, F1 Micro: 0.2188, F1 Macro: 0.1391, Accuracy: 0.2188\n","Epoch 9, Train Loss: 1.8923, Val Loss: 2.0340, F1 Micro: 0.2083, F1 Macro: 0.1176, Accuracy: 0.2083\n","Epoch 10, Train Loss: 2.0208, Val Loss: 2.3711, F1 Micro: 0.2292, F1 Macro: 0.1272, Accuracy: 0.2292\n","Epoch 11, Train Loss: 2.0925, Val Loss: 1.8420, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 12, Train Loss: 2.0205, Val Loss: 2.2357, F1 Micro: 0.1771, F1 Macro: 0.0896, Accuracy: 0.1771\n","Epoch 13, Train Loss: 1.9414, Val Loss: 1.9308, F1 Micro: 0.2292, F1 Macro: 0.1222, Accuracy: 0.2292\n","Epoch 14, Train Loss: 1.9408, Val Loss: 2.0002, F1 Micro: 0.1771, F1 Macro: 0.0988, Accuracy: 0.1771\n","Epoch 15, Train Loss: 1.9532, Val Loss: 1.8989, F1 Micro: 0.2292, F1 Macro: 0.1238, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.9367, Val Loss: 1.8100, F1 Micro: 0.2292, F1 Macro: 0.1463, Accuracy: 0.2292\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.275\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 8.7117, Val Loss: 2.2013, F1 Micro: 0.2604, F1 Macro: 0.1400, Accuracy: 0.2604\n","Epoch 2, Train Loss: 2.0917, Val Loss: 2.0754, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 3, Train Loss: 1.9753, Val Loss: 1.7917, F1 Micro: 0.2812, F1 Macro: 0.1526, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.9557, Val Loss: 1.7519, F1 Micro: 0.1875, F1 Macro: 0.1224, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.8278, Val Loss: 1.7290, F1 Micro: 0.2188, F1 Macro: 0.1509, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.7968, Val Loss: 2.1974, F1 Micro: 0.1979, F1 Macro: 0.1336, Accuracy: 0.1979\n","Epoch 7, Train Loss: 1.8692, Val Loss: 1.8519, F1 Micro: 0.2396, F1 Macro: 0.1874, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.8593, Val Loss: 1.7198, F1 Micro: 0.1979, F1 Macro: 0.1792, Accuracy: 0.1979\n","Epoch 9, Train Loss: 1.9447, Val Loss: 2.1381, F1 Micro: 0.2917, F1 Macro: 0.1981, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.9745, Val Loss: 1.8014, F1 Micro: 0.1875, F1 Macro: 0.1559, Accuracy: 0.1875\n","Epoch 11, Train Loss: 1.9507, Val Loss: 1.8150, F1 Micro: 0.2083, F1 Macro: 0.1423, Accuracy: 0.2083\n","Epoch 12, Train Loss: 1.8944, Val Loss: 1.6841, F1 Micro: 0.2292, F1 Macro: 0.1766, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.7985, Val Loss: 1.7122, F1 Micro: 0.2812, F1 Macro: 0.2085, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.8783, Val Loss: 1.9395, F1 Micro: 0.1979, F1 Macro: 0.1211, Accuracy: 0.1979\n","Epoch 15, Train Loss: 1.8416, Val Loss: 1.8372, F1 Micro: 0.3125, F1 Macro: 0.2435, Accuracy: 0.3125\n","Epoch 16, Train Loss: 1.8786, Val Loss: 1.7602, F1 Micro: 0.2812, F1 Macro: 0.1670, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.8715, Val Loss: 2.0541, F1 Micro: 0.2083, F1 Macro: 0.1398, Accuracy: 0.2083\n","Epoch 18, Train Loss: 1.9581, Val Loss: 1.8805, F1 Micro: 0.2188, F1 Macro: 0.1644, Accuracy: 0.2188\n","Epoch 19, Train Loss: 2.0315, Val Loss: 1.8852, F1 Micro: 0.1979, F1 Macro: 0.1347, Accuracy: 0.1979\n","Epoch 20, Train Loss: 2.0039, Val Loss: 1.8846, F1 Micro: 0.2604, F1 Macro: 0.1896, Accuracy: 0.2604\n","Epoch 21, Train Loss: 2.1987, Val Loss: 2.1024, F1 Micro: 0.2708, F1 Macro: 0.1557, Accuracy: 0.2708\n","Epoch 22, Train Loss: 1.8966, Val Loss: 1.7651, F1 Micro: 0.2708, F1 Macro: 0.1806, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.8492, Val Loss: 1.8854, F1 Micro: 0.1875, F1 Macro: 0.1214, Accuracy: 0.1875\n","Epoch 24, Train Loss: 1.9386, Val Loss: 1.8673, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 25, Train Loss: 1.9481, Val Loss: 1.7583, F1 Micro: 0.2292, F1 Macro: 0.1629, Accuracy: 0.2292\n","Epoch 26, Train Loss: 1.9323, Val Loss: 2.1110, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 27, Train Loss: 1.9098, Val Loss: 1.7439, F1 Micro: 0.2396, F1 Macro: 0.1698, Accuracy: 0.2396\n","Epoch 28, Train Loss: 1.9478, Val Loss: 1.7702, F1 Micro: 0.2812, F1 Macro: 0.1889, Accuracy: 0.2812\n","Epoch 29, Train Loss: 2.0775, Val Loss: 2.1616, F1 Micro: 0.2292, F1 Macro: 0.1650, Accuracy: 0.2292\n","Epoch 30, Train Loss: 2.0527, Val Loss: 1.9470, F1 Micro: 0.2812, F1 Macro: 0.1526, Accuracy: 0.2812\n","Epoch 31, Train Loss: 2.0035, Val Loss: 1.8654, F1 Micro: 0.2812, F1 Macro: 0.1532, Accuracy: 0.2812\n","Epoch 32, Train Loss: 1.9126, Val Loss: 1.8269, F1 Micro: 0.1979, F1 Macro: 0.1552, Accuracy: 0.1979\n","Epoch 33, Train Loss: 1.9118, Val Loss: 2.4017, F1 Micro: 0.1771, F1 Macro: 0.1150, Accuracy: 0.1771\n","Epoch 34, Train Loss: 1.9915, Val Loss: 2.1627, F1 Micro: 0.2083, F1 Macro: 0.1423, Accuracy: 0.2083\n","Epoch 35, Train Loss: 2.0003, Val Loss: 2.0716, F1 Micro: 0.1771, F1 Macro: 0.1189, Accuracy: 0.1771\n","Epoch 36, Train Loss: 1.9148, Val Loss: 2.1014, F1 Micro: 0.1771, F1 Macro: 0.1025, Accuracy: 0.1771\n","Epoch 37, Train Loss: 2.0016, Val Loss: 1.9425, F1 Micro: 0.2292, F1 Macro: 0.1406, Accuracy: 0.2292\n","Epoch 38, Train Loss: 2.0101, Val Loss: 1.9666, F1 Micro: 0.1875, F1 Macro: 0.1204, Accuracy: 0.1875\n","Epoch 39, Train Loss: 1.9817, Val Loss: 1.8953, F1 Micro: 0.2083, F1 Macro: 0.1635, Accuracy: 0.2083\n","Epoch 40, Train Loss: 1.9003, Val Loss: 1.7157, F1 Micro: 0.2604, F1 Macro: 0.1700, Accuracy: 0.2604\n","Epoch 41, Train Loss: 1.9242, Val Loss: 2.0380, F1 Micro: 0.1562, F1 Macro: 0.0801, Accuracy: 0.1562\n","Epoch 42, Train Loss: 1.8754, Val Loss: 1.7354, F1 Micro: 0.1979, F1 Macro: 0.1520, Accuracy: 0.1979\n","Epoch 43, Train Loss: 1.7961, Val Loss: 1.9864, F1 Micro: 0.2604, F1 Macro: 0.1405, Accuracy: 0.2604\n","Epoch 44, Train Loss: 1.8783, Val Loss: 2.0272, F1 Micro: 0.2083, F1 Macro: 0.1521, Accuracy: 0.2083\n","Epoch 45, Train Loss: 2.0443, Val Loss: 1.8127, F1 Micro: 0.2708, F1 Macro: 0.1725, Accuracy: 0.2708\n","Epoch 46, Train Loss: 1.9736, Val Loss: 1.8245, F1 Micro: 0.1875, F1 Macro: 0.1526, Accuracy: 0.1875\n","Epoch 47, Train Loss: 1.9260, Val Loss: 1.9070, F1 Micro: 0.2604, F1 Macro: 0.1397, Accuracy: 0.2604\n","Epoch 48, Train Loss: 1.9067, Val Loss: 1.8418, F1 Micro: 0.2604, F1 Macro: 0.1837, Accuracy: 0.2604\n","Epoch 49, Train Loss: 1.9785, Val Loss: 1.9368, F1 Micro: 0.2396, F1 Macro: 0.1811, Accuracy: 0.2396\n","Epoch 50, Train Loss: 2.0189, Val Loss: 1.9963, F1 Micro: 0.2708, F1 Macro: 0.1649, Accuracy: 0.2708\n","Epoch 51, Train Loss: 2.0586, Val Loss: 1.9952, F1 Micro: 0.2500, F1 Macro: 0.1339, Accuracy: 0.2500\n","Epoch 52, Train Loss: 1.9772, Val Loss: 1.9396, F1 Micro: 0.1875, F1 Macro: 0.0917, Accuracy: 0.1875\n","Epoch 53, Train Loss: 2.1699, Val Loss: 1.8148, F1 Micro: 0.2083, F1 Macro: 0.1513, Accuracy: 0.2083\n","Epoch 54, Train Loss: 1.9073, Val Loss: 2.1492, F1 Micro: 0.1562, F1 Macro: 0.1169, Accuracy: 0.1562\n","Epoch 55, Train Loss: 1.8750, Val Loss: 1.9363, F1 Micro: 0.2292, F1 Macro: 0.1447, Accuracy: 0.2292\n","Epoch 56, Train Loss: 2.0199, Val Loss: 1.8936, F1 Micro: 0.2917, F1 Macro: 0.1903, Accuracy: 0.2917\n","Epoch 57, Train Loss: 1.9223, Val Loss: 1.8300, F1 Micro: 0.2917, F1 Macro: 0.1856, Accuracy: 0.2917\n","Epoch 58, Train Loss: 1.8664, Val Loss: 1.9664, F1 Micro: 0.2396, F1 Macro: 0.1250, Accuracy: 0.2396\n","Epoch 59, Train Loss: 1.8794, Val Loss: 2.4441, F1 Micro: 0.1458, F1 Macro: 0.0613, Accuracy: 0.1458\n","Epoch 60, Train Loss: 2.1324, Val Loss: 1.8751, F1 Micro: 0.3125, F1 Macro: 0.2205, Accuracy: 0.3125\n","Epoch 61, Train Loss: 1.8902, Val Loss: 1.9696, F1 Micro: 0.3021, F1 Macro: 0.1961, Accuracy: 0.3021\n","Epoch 62, Train Loss: 1.8288, Val Loss: 2.1051, F1 Micro: 0.2083, F1 Macro: 0.1390, Accuracy: 0.2083\n","Epoch 63, Train Loss: 1.8871, Val Loss: 1.7985, F1 Micro: 0.2188, F1 Macro: 0.1743, Accuracy: 0.2188\n","Epoch 64, Train Loss: 1.8507, Val Loss: 2.0739, F1 Micro: 0.2083, F1 Macro: 0.1536, Accuracy: 0.2083\n","Epoch 65, Train Loss: 1.9826, Val Loss: 2.1175, F1 Micro: 0.1667, F1 Macro: 0.1194, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 10.0831, Val Loss: 2.1778, F1 Micro: 0.1042, F1 Macro: 0.0627, Accuracy: 0.1042\n","Epoch 2, Train Loss: 1.9647, Val Loss: 2.1501, F1 Micro: 0.2396, F1 Macro: 0.1221, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.9797, Val Loss: 1.9950, F1 Micro: 0.2188, F1 Macro: 0.1103, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.9103, Val Loss: 1.9775, F1 Micro: 0.1771, F1 Macro: 0.1382, Accuracy: 0.1771\n","Epoch 5, Train Loss: 1.9497, Val Loss: 2.1167, F1 Micro: 0.1458, F1 Macro: 0.0743, Accuracy: 0.1458\n","Epoch 6, Train Loss: 1.8614, Val Loss: 1.9338, F1 Micro: 0.1250, F1 Macro: 0.0979, Accuracy: 0.1250\n","Epoch 7, Train Loss: 1.9175, Val Loss: 1.9193, F1 Micro: 0.2396, F1 Macro: 0.1155, Accuracy: 0.2396\n","Epoch 8, Train Loss: 2.0202, Val Loss: 1.9183, F1 Micro: 0.1250, F1 Macro: 0.1176, Accuracy: 0.1250\n","Epoch 9, Train Loss: 1.8870, Val Loss: 1.9122, F1 Micro: 0.2188, F1 Macro: 0.1103, Accuracy: 0.2188\n","Epoch 10, Train Loss: 2.0079, Val Loss: 2.0176, F1 Micro: 0.1771, F1 Macro: 0.1398, Accuracy: 0.1771\n","Epoch 11, Train Loss: 1.8537, Val Loss: 2.3366, F1 Micro: 0.1875, F1 Macro: 0.1336, Accuracy: 0.1875\n","Epoch 12, Train Loss: 2.0195, Val Loss: 1.8972, F1 Micro: 0.2292, F1 Macro: 0.1124, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.9682, Val Loss: 1.8732, F1 Micro: 0.2500, F1 Macro: 0.1873, Accuracy: 0.2500\n","Epoch 14, Train Loss: 1.9765, Val Loss: 2.0026, F1 Micro: 0.2708, F1 Macro: 0.1731, Accuracy: 0.2708\n","Epoch 15, Train Loss: 1.9254, Val Loss: 2.0018, F1 Micro: 0.1979, F1 Macro: 0.1008, Accuracy: 0.1979\n","Epoch 16, Train Loss: 1.9956, Val Loss: 2.2577, F1 Micro: 0.1458, F1 Macro: 0.1030, Accuracy: 0.1458\n","Epoch 17, Train Loss: 2.1347, Val Loss: 1.9522, F1 Micro: 0.2292, F1 Macro: 0.1260, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.8760, Val Loss: 2.1661, F1 Micro: 0.1667, F1 Macro: 0.1105, Accuracy: 0.1667\n","Epoch 19, Train Loss: 1.9496, Val Loss: 2.1997, F1 Micro: 0.1667, F1 Macro: 0.0948, Accuracy: 0.1667\n","Epoch 20, Train Loss: 1.9625, Val Loss: 1.9192, F1 Micro: 0.1458, F1 Macro: 0.1018, Accuracy: 0.1458\n","Epoch 21, Train Loss: 1.9220, Val Loss: 2.0724, F1 Micro: 0.2083, F1 Macro: 0.1305, Accuracy: 0.2083\n","Epoch 22, Train Loss: 1.8699, Val Loss: 1.8797, F1 Micro: 0.2708, F1 Macro: 0.1630, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.9572, Val Loss: 2.0451, F1 Micro: 0.2292, F1 Macro: 0.1091, Accuracy: 0.2292\n","Epoch 24, Train Loss: 1.8616, Val Loss: 1.9677, F1 Micro: 0.2604, F1 Macro: 0.1709, Accuracy: 0.2604\n","Epoch 25, Train Loss: 1.9255, Val Loss: 2.0675, F1 Micro: 0.2292, F1 Macro: 0.1153, Accuracy: 0.2292\n","Epoch 26, Train Loss: 1.8515, Val Loss: 1.8896, F1 Micro: 0.2604, F1 Macro: 0.1650, Accuracy: 0.2604\n","Epoch 27, Train Loss: 1.8342, Val Loss: 2.0159, F1 Micro: 0.1979, F1 Macro: 0.1400, Accuracy: 0.1979\n","Epoch 28, Train Loss: 1.8674, Val Loss: 2.0131, F1 Micro: 0.2292, F1 Macro: 0.1268, Accuracy: 0.2292\n","Epoch 29, Train Loss: 1.8747, Val Loss: 1.9326, F1 Micro: 0.2396, F1 Macro: 0.1507, Accuracy: 0.2396\n","Epoch 30, Train Loss: 1.9314, Val Loss: 2.1949, F1 Micro: 0.2396, F1 Macro: 0.1221, Accuracy: 0.2396\n","Epoch 31, Train Loss: 1.9111, Val Loss: 2.2113, F1 Micro: 0.2396, F1 Macro: 0.1221, Accuracy: 0.2396\n","Epoch 32, Train Loss: 1.9558, Val Loss: 2.1909, F1 Micro: 0.3021, F1 Macro: 0.1877, Accuracy: 0.3021\n","Epoch 33, Train Loss: 1.8876, Val Loss: 2.0912, F1 Micro: 0.2812, F1 Macro: 0.1715, Accuracy: 0.2812\n","Epoch 34, Train Loss: 1.9479, Val Loss: 2.1566, F1 Micro: 0.1354, F1 Macro: 0.0863, Accuracy: 0.1354\n","Epoch 35, Train Loss: 2.0441, Val Loss: 2.2732, F1 Micro: 0.2396, F1 Macro: 0.1184, Accuracy: 0.2396\n","Epoch 36, Train Loss: 1.9573, Val Loss: 2.3783, F1 Micro: 0.1354, F1 Macro: 0.0882, Accuracy: 0.1354\n","Epoch 37, Train Loss: 1.8498, Val Loss: 2.0680, F1 Micro: 0.2500, F1 Macro: 0.1647, Accuracy: 0.2500\n","Epoch 38, Train Loss: 1.8472, Val Loss: 2.0611, F1 Micro: 0.2500, F1 Macro: 0.1492, Accuracy: 0.2500\n","Epoch 39, Train Loss: 2.0226, Val Loss: 2.2519, F1 Micro: 0.2188, F1 Macro: 0.1103, Accuracy: 0.2188\n","Epoch 40, Train Loss: 1.9097, Val Loss: 2.2162, F1 Micro: 0.2708, F1 Macro: 0.1834, Accuracy: 0.2708\n","Epoch 41, Train Loss: 1.9316, Val Loss: 2.2937, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 42, Train Loss: 1.9298, Val Loss: 2.6405, F1 Micro: 0.1458, F1 Macro: 0.0946, Accuracy: 0.1458\n","Epoch 43, Train Loss: 2.1078, Val Loss: 2.5937, F1 Micro: 0.2500, F1 Macro: 0.1326, Accuracy: 0.2500\n","Epoch 44, Train Loss: 2.1286, Val Loss: 2.3994, F1 Micro: 0.2396, F1 Macro: 0.1609, Accuracy: 0.2396\n","Epoch 45, Train Loss: 1.9743, Val Loss: 2.2465, F1 Micro: 0.2396, F1 Macro: 0.1546, Accuracy: 0.2396\n","Epoch 46, Train Loss: 1.9269, Val Loss: 2.7789, F1 Micro: 0.1875, F1 Macro: 0.1364, Accuracy: 0.1875\n","Epoch 47, Train Loss: 2.0544, Val Loss: 2.1707, F1 Micro: 0.2083, F1 Macro: 0.1491, Accuracy: 0.2083\n","Epoch 48, Train Loss: 1.8850, Val Loss: 2.2707, F1 Micro: 0.2812, F1 Macro: 0.1872, Accuracy: 0.2812\n","Epoch 49, Train Loss: 1.9256, Val Loss: 2.3151, F1 Micro: 0.2292, F1 Macro: 0.1103, Accuracy: 0.2292\n","Epoch 50, Train Loss: 1.9688, Val Loss: 2.4899, F1 Micro: 0.1667, F1 Macro: 0.1269, Accuracy: 0.1667\n","Epoch 51, Train Loss: 2.0649, Val Loss: 2.1648, F1 Micro: 0.2188, F1 Macro: 0.1098, Accuracy: 0.2188\n","Epoch 52, Train Loss: 1.9917, Val Loss: 2.3389, F1 Micro: 0.1771, F1 Macro: 0.0839, Accuracy: 0.1771\n","Epoch 53, Train Loss: 1.9448, Val Loss: 2.2702, F1 Micro: 0.2396, F1 Macro: 0.1531, Accuracy: 0.2396\n","Epoch 54, Train Loss: 1.8923, Val Loss: 2.1258, F1 Micro: 0.1458, F1 Macro: 0.1048, Accuracy: 0.1458\n","Epoch 55, Train Loss: 2.0161, Val Loss: 2.7900, F1 Micro: 0.1979, F1 Macro: 0.1469, Accuracy: 0.1979\n","Epoch 56, Train Loss: 2.2299, Val Loss: 2.8284, F1 Micro: 0.2708, F1 Macro: 0.1731, Accuracy: 0.2708\n","Epoch 57, Train Loss: 2.0094, Val Loss: 2.3148, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 58, Train Loss: 1.9782, Val Loss: 2.3709, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 59, Train Loss: 1.9679, Val Loss: 1.9896, F1 Micro: 0.2604, F1 Macro: 0.1803, Accuracy: 0.2604\n","Epoch 60, Train Loss: 1.8362, Val Loss: 2.0951, F1 Micro: 0.2292, F1 Macro: 0.2010, Accuracy: 0.2292\n","Epoch 61, Train Loss: 2.0020, Val Loss: 2.2395, F1 Micro: 0.1354, F1 Macro: 0.0813, Accuracy: 0.1354\n","Epoch 62, Train Loss: 1.9568, Val Loss: 2.3137, F1 Micro: 0.2500, F1 Macro: 0.1276, Accuracy: 0.2500\n","Epoch 63, Train Loss: 1.9392, Val Loss: 2.4042, F1 Micro: 0.1979, F1 Macro: 0.1435, Accuracy: 0.1979\n","Epoch 64, Train Loss: 1.9152, Val Loss: 2.3296, F1 Micro: 0.2396, F1 Macro: 0.1221, Accuracy: 0.2396\n","Epoch 65, Train Loss: 1.8842, Val Loss: 2.0812, F1 Micro: 0.2292, F1 Macro: 0.1223, Accuracy: 0.2292\n","Epoch 66, Train Loss: 1.9285, Val Loss: 2.1608, F1 Micro: 0.2292, F1 Macro: 0.1279, Accuracy: 0.2292\n","Epoch 67, Train Loss: 2.1236, Val Loss: 2.3289, F1 Micro: 0.1771, F1 Macro: 0.1122, Accuracy: 0.1771\n","Epoch 68, Train Loss: 1.9864, Val Loss: 2.2138, F1 Micro: 0.2500, F1 Macro: 0.1328, Accuracy: 0.2500\n","Epoch 69, Train Loss: 1.9652, Val Loss: 2.3534, F1 Micro: 0.2396, F1 Macro: 0.1268, Accuracy: 0.2396\n","Epoch 70, Train Loss: 1.9512, Val Loss: 2.0706, F1 Micro: 0.1667, F1 Macro: 0.1023, Accuracy: 0.1667\n","Epoch 71, Train Loss: 1.8779, Val Loss: 2.3239, F1 Micro: 0.2188, F1 Macro: 0.1064, Accuracy: 0.2188\n","Epoch 72, Train Loss: 1.8718, Val Loss: 2.0247, F1 Micro: 0.2292, F1 Macro: 0.1318, Accuracy: 0.2292\n","Epoch 73, Train Loss: 1.9469, Val Loss: 2.0289, F1 Micro: 0.2292, F1 Macro: 0.1361, Accuracy: 0.2292\n","Epoch 74, Train Loss: 1.9403, Val Loss: 2.1317, F1 Micro: 0.2292, F1 Macro: 0.1223, Accuracy: 0.2292\n","Epoch 75, Train Loss: 1.9747, Val Loss: 2.0204, F1 Micro: 0.2604, F1 Macro: 0.1466, Accuracy: 0.2604\n","Epoch 76, Train Loss: 2.0535, Val Loss: 2.4677, F1 Micro: 0.2083, F1 Macro: 0.1094, Accuracy: 0.2083\n","Epoch 77, Train Loss: 1.9843, Val Loss: 2.8140, F1 Micro: 0.1667, F1 Macro: 0.0875, Accuracy: 0.1667\n","Epoch 78, Train Loss: 1.9070, Val Loss: 2.5163, F1 Micro: 0.2292, F1 Macro: 0.1460, Accuracy: 0.2292\n","Epoch 79, Train Loss: 1.9204, Val Loss: 2.4273, F1 Micro: 0.2708, F1 Macro: 0.1685, Accuracy: 0.2708\n","Epoch 80, Train Loss: 1.9313, Val Loss: 2.9232, F1 Micro: 0.1979, F1 Macro: 0.1373, Accuracy: 0.1979\n","Epoch 81, Train Loss: 2.0240, Val Loss: 2.7693, F1 Micro: 0.1667, F1 Macro: 0.1047, Accuracy: 0.1667\n","Epoch 82, Train Loss: 2.0341, Val Loss: 2.4570, F1 Micro: 0.1979, F1 Macro: 0.1509, Accuracy: 0.1979\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 11.4100, Val Loss: 1.9600, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 2, Train Loss: 1.9859, Val Loss: 1.9305, F1 Micro: 0.1979, F1 Macro: 0.0957, Accuracy: 0.1979\n","Epoch 3, Train Loss: 1.9470, Val Loss: 1.9816, F1 Micro: 0.2188, F1 Macro: 0.1306, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.8928, Val Loss: 1.8168, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.8679, Val Loss: 1.8972, F1 Micro: 0.1979, F1 Macro: 0.0935, Accuracy: 0.1979\n","Epoch 6, Train Loss: 1.8181, Val Loss: 2.0225, F1 Micro: 0.1667, F1 Macro: 0.0707, Accuracy: 0.1667\n","Epoch 7, Train Loss: 1.8737, Val Loss: 2.1879, F1 Micro: 0.1771, F1 Macro: 0.1036, Accuracy: 0.1771\n","Epoch 8, Train Loss: 1.9163, Val Loss: 2.0373, F1 Micro: 0.2292, F1 Macro: 0.1037, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.8430, Val Loss: 1.9055, F1 Micro: 0.1146, F1 Macro: 0.0850, Accuracy: 0.1146\n","Epoch 10, Train Loss: 1.8962, Val Loss: 2.1638, F1 Micro: 0.1354, F1 Macro: 0.1033, Accuracy: 0.1354\n","Epoch 11, Train Loss: 1.9306, Val Loss: 2.0049, F1 Micro: 0.1979, F1 Macro: 0.0945, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.9718, Val Loss: 1.9595, F1 Micro: 0.2292, F1 Macro: 0.1177, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.8329, Val Loss: 1.8994, F1 Micro: 0.1875, F1 Macro: 0.1384, Accuracy: 0.1875\n","Epoch 14, Train Loss: 1.8866, Val Loss: 1.9794, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 15, Train Loss: 1.9546, Val Loss: 2.1823, F1 Micro: 0.2292, F1 Macro: 0.1518, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.8546, Val Loss: 2.0433, F1 Micro: 0.1979, F1 Macro: 0.1112, Accuracy: 0.1979\n","Epoch 17, Train Loss: 1.8771, Val Loss: 1.9054, F1 Micro: 0.2083, F1 Macro: 0.0580, Accuracy: 0.2083\n","Epoch 18, Train Loss: 1.9385, Val Loss: 2.0023, F1 Micro: 0.2188, F1 Macro: 0.0860, Accuracy: 0.2188\n","Epoch 19, Train Loss: 1.9683, Val Loss: 1.9410, F1 Micro: 0.2188, F1 Macro: 0.1341, Accuracy: 0.2188\n","Epoch 20, Train Loss: 1.7638, Val Loss: 1.8263, F1 Micro: 0.1979, F1 Macro: 0.0970, Accuracy: 0.1979\n","Epoch 21, Train Loss: 1.8916, Val Loss: 1.9294, F1 Micro: 0.2812, F1 Macro: 0.1824, Accuracy: 0.2812\n","Epoch 22, Train Loss: 1.9026, Val Loss: 1.9467, F1 Micro: 0.2083, F1 Macro: 0.1112, Accuracy: 0.2083\n","Epoch 23, Train Loss: 1.8650, Val Loss: 1.9871, F1 Micro: 0.1979, F1 Macro: 0.0962, Accuracy: 0.1979\n","Epoch 24, Train Loss: 1.8632, Val Loss: 2.2473, F1 Micro: 0.2188, F1 Macro: 0.1408, Accuracy: 0.2188\n","Epoch 25, Train Loss: 1.8612, Val Loss: 1.9129, F1 Micro: 0.2604, F1 Macro: 0.1741, Accuracy: 0.2604\n","Epoch 26, Train Loss: 1.7853, Val Loss: 2.1337, F1 Micro: 0.2500, F1 Macro: 0.1270, Accuracy: 0.2500\n","Epoch 27, Train Loss: 1.9122, Val Loss: 2.1863, F1 Micro: 0.1875, F1 Macro: 0.1418, Accuracy: 0.1875\n","Epoch 28, Train Loss: 1.8794, Val Loss: 2.2655, F1 Micro: 0.1146, F1 Macro: 0.0862, Accuracy: 0.1146\n","Epoch 29, Train Loss: 1.8935, Val Loss: 2.2918, F1 Micro: 0.2500, F1 Macro: 0.1167, Accuracy: 0.2500\n","Epoch 30, Train Loss: 1.9614, Val Loss: 2.4724, F1 Micro: 0.2083, F1 Macro: 0.1515, Accuracy: 0.2083\n","Epoch 31, Train Loss: 2.0085, Val Loss: 2.0362, F1 Micro: 0.2500, F1 Macro: 0.1167, Accuracy: 0.2500\n","Epoch 32, Train Loss: 1.9621, Val Loss: 2.4050, F1 Micro: 0.2188, F1 Macro: 0.1481, Accuracy: 0.2188\n","Epoch 33, Train Loss: 2.1901, Val Loss: 2.4184, F1 Micro: 0.1042, F1 Macro: 0.0677, Accuracy: 0.1042\n","Epoch 34, Train Loss: 2.0173, Val Loss: 1.9005, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 35, Train Loss: 2.0442, Val Loss: 2.0524, F1 Micro: 0.1979, F1 Macro: 0.0975, Accuracy: 0.1979\n","Epoch 36, Train Loss: 1.9562, Val Loss: 1.9822, F1 Micro: 0.1979, F1 Macro: 0.0820, Accuracy: 0.1979\n","Epoch 37, Train Loss: 1.9011, Val Loss: 2.0733, F1 Micro: 0.1250, F1 Macro: 0.0804, Accuracy: 0.1250\n","Epoch 38, Train Loss: 1.8663, Val Loss: 2.1386, F1 Micro: 0.1250, F1 Macro: 0.0804, Accuracy: 0.1250\n","Epoch 39, Train Loss: 1.9391, Val Loss: 2.1331, F1 Micro: 0.2083, F1 Macro: 0.0936, Accuracy: 0.2083\n","Epoch 40, Train Loss: 2.0016, Val Loss: 1.8343, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 41, Train Loss: 1.9598, Val Loss: 2.1717, F1 Micro: 0.2396, F1 Macro: 0.1333, Accuracy: 0.2396\n","Epoch 42, Train Loss: 1.9995, Val Loss: 2.0384, F1 Micro: 0.1979, F1 Macro: 0.0945, Accuracy: 0.1979\n","Epoch 43, Train Loss: 1.9216, Val Loss: 2.4361, F1 Micro: 0.1250, F1 Macro: 0.0946, Accuracy: 0.1250\n","Epoch 44, Train Loss: 1.9897, Val Loss: 1.9939, F1 Micro: 0.1979, F1 Macro: 0.1455, Accuracy: 0.1979\n","Epoch 45, Train Loss: 2.0450, Val Loss: 1.9494, F1 Micro: 0.1979, F1 Macro: 0.0945, Accuracy: 0.1979\n","Epoch 46, Train Loss: 1.8491, Val Loss: 2.3556, F1 Micro: 0.1250, F1 Macro: 0.0820, Accuracy: 0.1250\n","Epoch 47, Train Loss: 1.8869, Val Loss: 1.8431, F1 Micro: 0.2396, F1 Macro: 0.1127, Accuracy: 0.2396\n","Epoch 48, Train Loss: 1.7969, Val Loss: 2.0175, F1 Micro: 0.1562, F1 Macro: 0.1333, Accuracy: 0.1562\n","Epoch 49, Train Loss: 1.8037, Val Loss: 1.9779, F1 Micro: 0.2083, F1 Macro: 0.1203, Accuracy: 0.2083\n","Epoch 50, Train Loss: 1.9032, Val Loss: 2.0587, F1 Micro: 0.2292, F1 Macro: 0.1393, Accuracy: 0.2292\n","Epoch 51, Train Loss: 1.8198, Val Loss: 2.0120, F1 Micro: 0.2292, F1 Macro: 0.1325, Accuracy: 0.2292\n","Epoch 52, Train Loss: 1.9410, Val Loss: 2.1126, F1 Micro: 0.1979, F1 Macro: 0.1440, Accuracy: 0.1979\n","Epoch 53, Train Loss: 1.8873, Val Loss: 2.4458, F1 Micro: 0.1771, F1 Macro: 0.0819, Accuracy: 0.1771\n","Epoch 54, Train Loss: 2.0536, Val Loss: 2.3264, F1 Micro: 0.1354, F1 Macro: 0.1083, Accuracy: 0.1354\n","Epoch 55, Train Loss: 2.3137, Val Loss: 2.7300, F1 Micro: 0.1979, F1 Macro: 0.0945, Accuracy: 0.1979\n","Epoch 56, Train Loss: 1.9675, Val Loss: 2.0895, F1 Micro: 0.1771, F1 Macro: 0.0844, Accuracy: 0.1771\n","Epoch 57, Train Loss: 1.8049, Val Loss: 2.0159, F1 Micro: 0.2708, F1 Macro: 0.2042, Accuracy: 0.2708\n","Epoch 58, Train Loss: 1.7747, Val Loss: 2.2586, F1 Micro: 0.1458, F1 Macro: 0.1248, Accuracy: 0.1458\n","Epoch 59, Train Loss: 1.8566, Val Loss: 2.4406, F1 Micro: 0.1458, F1 Macro: 0.1160, Accuracy: 0.1458\n","Epoch 60, Train Loss: 1.9578, Val Loss: 2.0335, F1 Micro: 0.2708, F1 Macro: 0.2163, Accuracy: 0.2708\n","Epoch 61, Train Loss: 1.8693, Val Loss: 1.9931, F1 Micro: 0.2500, F1 Macro: 0.1823, Accuracy: 0.2500\n","Epoch 62, Train Loss: 2.0140, Val Loss: 2.3644, F1 Micro: 0.1979, F1 Macro: 0.1438, Accuracy: 0.1979\n","Epoch 63, Train Loss: 1.8782, Val Loss: 2.4160, F1 Micro: 0.1771, F1 Macro: 0.1005, Accuracy: 0.1771\n","Epoch 64, Train Loss: 1.9806, Val Loss: 2.0378, F1 Micro: 0.2292, F1 Macro: 0.1361, Accuracy: 0.2292\n","Epoch 65, Train Loss: 1.7385, Val Loss: 1.9632, F1 Micro: 0.2396, F1 Macro: 0.1658, Accuracy: 0.2396\n","Epoch 66, Train Loss: 1.8353, Val Loss: 2.1464, F1 Micro: 0.2500, F1 Macro: 0.1360, Accuracy: 0.2500\n","Epoch 67, Train Loss: 1.8002, Val Loss: 2.0435, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 68, Train Loss: 1.7814, Val Loss: 2.1256, F1 Micro: 0.2292, F1 Macro: 0.1680, Accuracy: 0.2292\n","Epoch 69, Train Loss: 1.9218, Val Loss: 2.3711, F1 Micro: 0.2396, F1 Macro: 0.1674, Accuracy: 0.2396\n","Epoch 70, Train Loss: 2.0095, Val Loss: 2.2461, F1 Micro: 0.3021, F1 Macro: 0.1385, Accuracy: 0.3021\n","Epoch 71, Train Loss: 1.9761, Val Loss: 2.3865, F1 Micro: 0.2188, F1 Macro: 0.1919, Accuracy: 0.2188\n","Epoch 72, Train Loss: 1.7724, Val Loss: 2.1181, F1 Micro: 0.2604, F1 Macro: 0.1767, Accuracy: 0.2604\n","Epoch 73, Train Loss: 1.7664, Val Loss: 2.2932, F1 Micro: 0.1562, F1 Macro: 0.0606, Accuracy: 0.1562\n","Epoch 74, Train Loss: 1.9144, Val Loss: 1.9250, F1 Micro: 0.2917, F1 Macro: 0.2108, Accuracy: 0.2917\n","Epoch 75, Train Loss: 1.8292, Val Loss: 2.0725, F1 Micro: 0.2500, F1 Macro: 0.2080, Accuracy: 0.2500\n","Epoch 76, Train Loss: 1.8438, Val Loss: 2.0753, F1 Micro: 0.2500, F1 Macro: 0.1441, Accuracy: 0.2500\n","Epoch 77, Train Loss: 1.7738, Val Loss: 2.1502, F1 Micro: 0.2292, F1 Macro: 0.2102, Accuracy: 0.2292\n","Epoch 78, Train Loss: 2.0343, Val Loss: 2.1488, F1 Micro: 0.2604, F1 Macro: 0.1415, Accuracy: 0.2604\n","Epoch 79, Train Loss: 1.9386, Val Loss: 2.2365, F1 Micro: 0.1979, F1 Macro: 0.1157, Accuracy: 0.1979\n","Epoch 80, Train Loss: 2.0550, Val Loss: 2.1986, F1 Micro: 0.2396, F1 Macro: 0.1617, Accuracy: 0.2396\n","Epoch 81, Train Loss: 1.8805, Val Loss: 2.1466, F1 Micro: 0.2396, F1 Macro: 0.2023, Accuracy: 0.2396\n","Epoch 82, Train Loss: 1.9735, Val Loss: 2.2699, F1 Micro: 0.2917, F1 Macro: 0.1941, Accuracy: 0.2917\n","Epoch 83, Train Loss: 1.8942, Val Loss: 1.9985, F1 Micro: 0.2500, F1 Macro: 0.1888, Accuracy: 0.2500\n","Epoch 84, Train Loss: 1.8164, Val Loss: 2.2127, F1 Micro: 0.2083, F1 Macro: 0.1196, Accuracy: 0.2083\n","Epoch 85, Train Loss: 1.9076, Val Loss: 2.5266, F1 Micro: 0.2188, F1 Macro: 0.1438, Accuracy: 0.2188\n","Epoch 86, Train Loss: 2.1277, Val Loss: 2.5128, F1 Micro: 0.2188, F1 Macro: 0.1809, Accuracy: 0.2188\n","Epoch 87, Train Loss: 1.8388, Val Loss: 2.4100, F1 Micro: 0.2188, F1 Macro: 0.1317, Accuracy: 0.2188\n","Epoch 88, Train Loss: 1.9821, Val Loss: 2.0886, F1 Micro: 0.3125, F1 Macro: 0.1979, Accuracy: 0.3125\n","Epoch 89, Train Loss: 1.8718, Val Loss: 1.8443, F1 Micro: 0.3542, F1 Macro: 0.3430, Accuracy: 0.3542\n","Epoch 90, Train Loss: 1.7232, Val Loss: 1.9851, F1 Micro: 0.2812, F1 Macro: 0.2693, Accuracy: 0.2812\n","Epoch 91, Train Loss: 1.7621, Val Loss: 2.0974, F1 Micro: 0.1979, F1 Macro: 0.1251, Accuracy: 0.1979\n","Epoch 92, Train Loss: 1.8202, Val Loss: 2.2000, F1 Micro: 0.2396, F1 Macro: 0.1440, Accuracy: 0.2396\n","Epoch 93, Train Loss: 1.7667, Val Loss: 2.0009, F1 Micro: 0.3021, F1 Macro: 0.2421, Accuracy: 0.3021\n","Epoch 94, Train Loss: 1.8832, Val Loss: 2.0090, F1 Micro: 0.2500, F1 Macro: 0.1683, Accuracy: 0.2500\n","Epoch 95, Train Loss: 1.8035, Val Loss: 1.9445, F1 Micro: 0.3125, F1 Macro: 0.2329, Accuracy: 0.3125\n","Epoch 96, Train Loss: 1.7774, Val Loss: 2.0033, F1 Micro: 0.3229, F1 Macro: 0.2571, Accuracy: 0.3229\n","Epoch 97, Train Loss: 1.7595, Val Loss: 2.1084, F1 Micro: 0.3125, F1 Macro: 0.2622, Accuracy: 0.3125\n","Epoch 98, Train Loss: 1.7892, Val Loss: 1.9772, F1 Micro: 0.2604, F1 Macro: 0.1500, Accuracy: 0.2604\n","Epoch 99, Train Loss: 1.7607, Val Loss: 2.1582, F1 Micro: 0.3125, F1 Macro: 0.2459, Accuracy: 0.3125\n","Epoch 100, Train Loss: 1.9034, Val Loss: 2.7501, F1 Micro: 0.1875, F1 Macro: 0.1250, Accuracy: 0.1875\n","Epoch 101, Train Loss: 2.0104, Val Loss: 2.0961, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 102, Train Loss: 1.9737, Val Loss: 2.1279, F1 Micro: 0.2500, F1 Macro: 0.1697, Accuracy: 0.2500\n","Epoch 103, Train Loss: 1.7896, Val Loss: 2.0028, F1 Micro: 0.2500, F1 Macro: 0.1822, Accuracy: 0.2500\n","Epoch 104, Train Loss: 1.8073, Val Loss: 2.1852, F1 Micro: 0.1979, F1 Macro: 0.1274, Accuracy: 0.1979\n","Epoch 105, Train Loss: 1.9836, Val Loss: 2.9519, F1 Micro: 0.0729, F1 Macro: 0.0402, Accuracy: 0.0729\n","Epoch 106, Train Loss: 2.0788, Val Loss: 2.4882, F1 Micro: 0.1771, F1 Macro: 0.1166, Accuracy: 0.1771\n","Epoch 107, Train Loss: 1.8760, Val Loss: 1.8862, F1 Micro: 0.2188, F1 Macro: 0.1767, Accuracy: 0.2188\n","Epoch 108, Train Loss: 1.8711, Val Loss: 2.2747, F1 Micro: 0.2188, F1 Macro: 0.1072, Accuracy: 0.2188\n","Epoch 109, Train Loss: 2.0701, Val Loss: 2.7121, F1 Micro: 0.1979, F1 Macro: 0.1265, Accuracy: 0.1979\n","Epoch 110, Train Loss: 1.8193, Val Loss: 1.9513, F1 Micro: 0.1979, F1 Macro: 0.2076, Accuracy: 0.1979\n","Epoch 111, Train Loss: 1.8529, Val Loss: 2.2213, F1 Micro: 0.1354, F1 Macro: 0.1254, Accuracy: 0.1354\n","Epoch 112, Train Loss: 1.9295, Val Loss: 2.0094, F1 Micro: 0.3021, F1 Macro: 0.1431, Accuracy: 0.3021\n","Epoch 113, Train Loss: 1.9293, Val Loss: 2.2514, F1 Micro: 0.2083, F1 Macro: 0.1023, Accuracy: 0.2083\n","Epoch 114, Train Loss: 1.9631, Val Loss: 2.0300, F1 Micro: 0.2708, F1 Macro: 0.1571, Accuracy: 0.2708\n","Epoch 115, Train Loss: 1.8943, Val Loss: 2.2866, F1 Micro: 0.2396, F1 Macro: 0.1217, Accuracy: 0.2396\n","Epoch 116, Train Loss: 1.9149, Val Loss: 2.3262, F1 Micro: 0.1771, F1 Macro: 0.0979, Accuracy: 0.1771\n","Epoch 117, Train Loss: 2.0620, Val Loss: 2.4280, F1 Micro: 0.2500, F1 Macro: 0.1167, Accuracy: 0.2500\n","Epoch 118, Train Loss: 2.0034, Val Loss: 2.0036, F1 Micro: 0.2083, F1 Macro: 0.0580, Accuracy: 0.2083\n","Epoch 119, Train Loss: 1.8222, Val Loss: 2.3971, F1 Micro: 0.1354, F1 Macro: 0.1186, Accuracy: 0.1354\n","Epoch 120, Train Loss: 1.9769, Val Loss: 2.1084, F1 Micro: 0.2604, F1 Macro: 0.1439, Accuracy: 0.2604\n","Epoch 121, Train Loss: 1.9607, Val Loss: 2.4254, F1 Micro: 0.1354, F1 Macro: 0.1075, Accuracy: 0.1354\n","Epoch 122, Train Loss: 2.0531, Val Loss: 2.1089, F1 Micro: 0.2083, F1 Macro: 0.1046, Accuracy: 0.2083\n","Epoch 123, Train Loss: 1.8607, Val Loss: 2.3257, F1 Micro: 0.1979, F1 Macro: 0.1018, Accuracy: 0.1979\n","Epoch 124, Train Loss: 2.0091, Val Loss: 2.1227, F1 Micro: 0.2188, F1 Macro: 0.1228, Accuracy: 0.2188\n","Epoch 125, Train Loss: 1.8575, Val Loss: 2.4094, F1 Micro: 0.2188, F1 Macro: 0.0609, Accuracy: 0.2188\n","Epoch 126, Train Loss: 2.0141, Val Loss: 2.5961, F1 Micro: 0.2292, F1 Macro: 0.0957, Accuracy: 0.2292\n","Epoch 127, Train Loss: 2.0245, Val Loss: 2.3329, F1 Micro: 0.1979, F1 Macro: 0.0823, Accuracy: 0.1979\n","Epoch 128, Train Loss: 2.0154, Val Loss: 2.5809, F1 Micro: 0.2292, F1 Macro: 0.1180, Accuracy: 0.2292\n","Epoch 129, Train Loss: 1.9454, Val Loss: 2.0030, F1 Micro: 0.2083, F1 Macro: 0.1109, Accuracy: 0.2083\n","Epoch 130, Train Loss: 1.8698, Val Loss: 2.0852, F1 Micro: 0.2292, F1 Macro: 0.1916, Accuracy: 0.2292\n","Epoch 131, Train Loss: 1.7357, Val Loss: 2.4641, F1 Micro: 0.1250, F1 Macro: 0.0794, Accuracy: 0.1250\n","Epoch 132, Train Loss: 1.8730, Val Loss: 1.9881, F1 Micro: 0.2500, F1 Macro: 0.1453, Accuracy: 0.2500\n","Epoch 133, Train Loss: 1.8778, Val Loss: 2.0165, F1 Micro: 0.2083, F1 Macro: 0.1046, Accuracy: 0.2083\n","Epoch 134, Train Loss: 1.7925, Val Loss: 2.0107, F1 Micro: 0.2396, F1 Macro: 0.1373, Accuracy: 0.2396\n","Epoch 135, Train Loss: 1.9515, Val Loss: 2.0796, F1 Micro: 0.2083, F1 Macro: 0.1092, Accuracy: 0.2083\n","Epoch 136, Train Loss: 1.8934, Val Loss: 2.1153, F1 Micro: 0.1979, F1 Macro: 0.1155, Accuracy: 0.1979\n","Epoch 137, Train Loss: 1.8586, Val Loss: 2.0381, F1 Micro: 0.1771, F1 Macro: 0.0819, Accuracy: 0.1771\n","Epoch 138, Train Loss: 1.8705, Val Loss: 2.6274, F1 Micro: 0.1458, F1 Macro: 0.1486, Accuracy: 0.1458\n","Epoch 139, Train Loss: 1.9701, Val Loss: 2.2330, F1 Micro: 0.2292, F1 Macro: 0.1615, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 7.0099, Val Loss: 1.8834, F1 Micro: 0.1979, F1 Macro: 0.0975, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.9191, Val Loss: 1.8765, F1 Micro: 0.1979, F1 Macro: 0.1025, Accuracy: 0.1979\n","Epoch 3, Train Loss: 1.8630, Val Loss: 1.8569, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.8336, Val Loss: 2.1971, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 5, Train Loss: 2.1247, Val Loss: 2.2889, F1 Micro: 0.1667, F1 Macro: 0.0799, Accuracy: 0.1667\n","Epoch 6, Train Loss: 2.0235, Val Loss: 1.9685, F1 Micro: 0.1979, F1 Macro: 0.0739, Accuracy: 0.1979\n","Epoch 7, Train Loss: 1.8947, Val Loss: 1.8000, F1 Micro: 0.1979, F1 Macro: 0.0975, Accuracy: 0.1979\n","Epoch 8, Train Loss: 2.0113, Val Loss: 1.8894, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 9, Train Loss: 1.9560, Val Loss: 2.4177, F1 Micro: 0.1875, F1 Macro: 0.1135, Accuracy: 0.1875\n","Epoch 10, Train Loss: 2.1252, Val Loss: 2.1454, F1 Micro: 0.1875, F1 Macro: 0.0531, Accuracy: 0.1875\n","Epoch 11, Train Loss: 1.8720, Val Loss: 1.9681, F1 Micro: 0.1875, F1 Macro: 0.0972, Accuracy: 0.1875\n","Epoch 12, Train Loss: 1.9903, Val Loss: 2.0734, F1 Micro: 0.1979, F1 Macro: 0.0732, Accuracy: 0.1979\n","Epoch 13, Train Loss: 1.9661, Val Loss: 1.9436, F1 Micro: 0.1771, F1 Macro: 0.0695, Accuracy: 0.1771\n","Epoch 14, Train Loss: 1.9169, Val Loss: 1.9645, F1 Micro: 0.1771, F1 Macro: 0.0721, Accuracy: 0.1771\n","Epoch 15, Train Loss: 2.0406, Val Loss: 2.0940, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 16, Train Loss: 1.9765, Val Loss: 2.0500, F1 Micro: 0.1458, F1 Macro: 0.0428, Accuracy: 0.1458\n","Epoch 17, Train Loss: 2.0163, Val Loss: 2.3104, F1 Micro: 0.1667, F1 Macro: 0.0644, Accuracy: 0.1667\n","Epoch 18, Train Loss: 2.0325, Val Loss: 1.9410, F1 Micro: 0.1562, F1 Macro: 0.0467, Accuracy: 0.1562\n","Epoch 19, Train Loss: 2.0346, Val Loss: 2.2009, F1 Micro: 0.1562, F1 Macro: 0.0472, Accuracy: 0.1562\n","Epoch 20, Train Loss: 1.9709, Val Loss: 2.2115, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 21, Train Loss: 2.1321, Val Loss: 1.9810, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 22, Train Loss: 1.9399, Val Loss: 1.8106, F1 Micro: 0.1875, F1 Macro: 0.0884, Accuracy: 0.1875\n","Epoch 23, Train Loss: 1.8994, Val Loss: 2.0803, F1 Micro: 0.1667, F1 Macro: 0.0870, Accuracy: 0.1667\n","Epoch 24, Train Loss: 1.9558, Val Loss: 2.1428, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 25, Train Loss: 2.0281, Val Loss: 1.9473, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 26, Train Loss: 1.9600, Val Loss: 1.9872, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 27, Train Loss: 1.9925, Val Loss: 1.9006, F1 Micro: 0.2083, F1 Macro: 0.0949, Accuracy: 0.2083\n","Epoch 28, Train Loss: 1.9508, Val Loss: 1.9625, F1 Micro: 0.1979, F1 Macro: 0.1216, Accuracy: 0.1979\n","Epoch 29, Train Loss: 1.8812, Val Loss: 1.9095, F1 Micro: 0.2396, F1 Macro: 0.1614, Accuracy: 0.2396\n","Epoch 30, Train Loss: 1.8729, Val Loss: 2.0173, F1 Micro: 0.2083, F1 Macro: 0.1521, Accuracy: 0.2083\n","Epoch 31, Train Loss: 2.0036, Val Loss: 2.1981, F1 Micro: 0.2292, F1 Macro: 0.1485, Accuracy: 0.2292\n","Epoch 32, Train Loss: 1.9769, Val Loss: 1.7991, F1 Micro: 0.1875, F1 Macro: 0.1007, Accuracy: 0.1875\n","Epoch 33, Train Loss: 2.0052, Val Loss: 2.0552, F1 Micro: 0.2188, F1 Macro: 0.1321, Accuracy: 0.2188\n","Epoch 34, Train Loss: 1.9651, Val Loss: 1.8270, F1 Micro: 0.2188, F1 Macro: 0.1379, Accuracy: 0.2188\n","Epoch 35, Train Loss: 1.8601, Val Loss: 1.9790, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 36, Train Loss: 1.8884, Val Loss: 1.9176, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 37, Train Loss: 1.9860, Val Loss: 1.9345, F1 Micro: 0.1875, F1 Macro: 0.0832, Accuracy: 0.1875\n","Epoch 38, Train Loss: 1.8512, Val Loss: 2.0513, F1 Micro: 0.1771, F1 Macro: 0.0865, Accuracy: 0.1771\n","Epoch 39, Train Loss: 1.9205, Val Loss: 2.1275, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 40, Train Loss: 1.8500, Val Loss: 2.3477, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 41, Train Loss: 1.8542, Val Loss: 2.0553, F1 Micro: 0.1771, F1 Macro: 0.0702, Accuracy: 0.1771\n","Epoch 42, Train Loss: 2.0931, Val Loss: 1.9246, F1 Micro: 0.1562, F1 Macro: 0.0455, Accuracy: 0.1562\n","Epoch 43, Train Loss: 2.1196, Val Loss: 2.3012, F1 Micro: 0.1771, F1 Macro: 0.0684, Accuracy: 0.1771\n","Epoch 44, Train Loss: 2.0134, Val Loss: 2.1031, F1 Micro: 0.1667, F1 Macro: 0.0498, Accuracy: 0.1667\n","Epoch 45, Train Loss: 1.9922, Val Loss: 2.2142, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 46, Train Loss: 2.0631, Val Loss: 2.3257, F1 Micro: 0.1667, F1 Macro: 0.0659, Accuracy: 0.1667\n","Epoch 47, Train Loss: 1.9737, Val Loss: 2.0417, F1 Micro: 0.1875, F1 Macro: 0.0832, Accuracy: 0.1875\n","Epoch 48, Train Loss: 1.8640, Val Loss: 1.7960, F1 Micro: 0.1979, F1 Macro: 0.0984, Accuracy: 0.1979\n","Epoch 49, Train Loss: 1.8629, Val Loss: 1.9307, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 50, Train Loss: 1.8922, Val Loss: 2.1414, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 51, Train Loss: 2.0548, Val Loss: 1.8410, F1 Micro: 0.2083, F1 Macro: 0.1148, Accuracy: 0.2083\n","Epoch 52, Train Loss: 1.9045, Val Loss: 1.9692, F1 Micro: 0.1979, F1 Macro: 0.0769, Accuracy: 0.1979\n","Epoch 53, Train Loss: 1.9661, Val Loss: 2.0384, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 54, Train Loss: 2.0564, Val Loss: 2.2201, F1 Micro: 0.1771, F1 Macro: 0.0702, Accuracy: 0.1771\n","Epoch 55, Train Loss: 2.1484, Val Loss: 1.9707, F1 Micro: 0.1250, F1 Macro: 0.0507, Accuracy: 0.1250\n","Epoch 56, Train Loss: 1.8929, Val Loss: 1.8522, F1 Micro: 0.1979, F1 Macro: 0.0958, Accuracy: 0.1979\n","Epoch 57, Train Loss: 1.8981, Val Loss: 2.0505, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 58, Train Loss: 2.0003, Val Loss: 2.1067, F1 Micro: 0.1667, F1 Macro: 0.0657, Accuracy: 0.1667\n","Epoch 59, Train Loss: 2.0151, Val Loss: 1.8859, F1 Micro: 0.1875, F1 Macro: 0.0986, Accuracy: 0.1875\n","Epoch 60, Train Loss: 1.8866, Val Loss: 2.0806, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 61, Train Loss: 1.8971, Val Loss: 2.0705, F1 Micro: 0.1771, F1 Macro: 0.0966, Accuracy: 0.1771\n","Epoch 62, Train Loss: 1.8523, Val Loss: 2.3915, F1 Micro: 0.1875, F1 Macro: 0.1107, Accuracy: 0.1875\n","Epoch 63, Train Loss: 1.9086, Val Loss: 1.9520, F1 Micro: 0.1667, F1 Macro: 0.0630, Accuracy: 0.1667\n","Epoch 64, Train Loss: 1.8781, Val Loss: 1.9575, F1 Micro: 0.1771, F1 Macro: 0.0910, Accuracy: 0.1771\n","Epoch 65, Train Loss: 1.9123, Val Loss: 1.7649, F1 Micro: 0.1979, F1 Macro: 0.1376, Accuracy: 0.1979\n","Epoch 66, Train Loss: 1.9639, Val Loss: 1.9893, F1 Micro: 0.1771, F1 Macro: 0.0948, Accuracy: 0.1771\n","Epoch 67, Train Loss: 1.8604, Val Loss: 2.0362, F1 Micro: 0.1979, F1 Macro: 0.1072, Accuracy: 0.1979\n","Epoch 68, Train Loss: 1.8890, Val Loss: 2.0625, F1 Micro: 0.2292, F1 Macro: 0.1345, Accuracy: 0.2292\n","Epoch 69, Train Loss: 1.8763, Val Loss: 2.3198, F1 Micro: 0.1667, F1 Macro: 0.0709, Accuracy: 0.1667\n","Epoch 70, Train Loss: 2.0226, Val Loss: 2.0575, F1 Micro: 0.1562, F1 Macro: 0.0791, Accuracy: 0.1562\n","Epoch 71, Train Loss: 2.0650, Val Loss: 2.4520, F1 Micro: 0.1771, F1 Macro: 0.0716, Accuracy: 0.1771\n","Epoch 72, Train Loss: 1.9258, Val Loss: 1.9209, F1 Micro: 0.1875, F1 Macro: 0.0916, Accuracy: 0.1875\n","Epoch 73, Train Loss: 1.8642, Val Loss: 1.9374, F1 Micro: 0.2292, F1 Macro: 0.1146, Accuracy: 0.2292\n","Epoch 74, Train Loss: 1.9269, Val Loss: 2.2818, F1 Micro: 0.2083, F1 Macro: 0.0873, Accuracy: 0.2083\n","Epoch 75, Train Loss: 2.0664, Val Loss: 2.3812, F1 Micro: 0.2083, F1 Macro: 0.1179, Accuracy: 0.2083\n","Epoch 76, Train Loss: 1.9255, Val Loss: 2.0597, F1 Micro: 0.2292, F1 Macro: 0.1360, Accuracy: 0.2292\n","Epoch 77, Train Loss: 1.8948, Val Loss: 2.2054, F1 Micro: 0.1771, F1 Macro: 0.0675, Accuracy: 0.1771\n","Epoch 78, Train Loss: 1.9392, Val Loss: 2.0269, F1 Micro: 0.2083, F1 Macro: 0.1176, Accuracy: 0.2083\n","Epoch 79, Train Loss: 2.1020, Val Loss: 1.9330, F1 Micro: 0.1875, F1 Macro: 0.1338, Accuracy: 0.1875\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 11.7608, Val Loss: 2.4207, F1 Micro: 0.1562, F1 Macro: 0.1222, Accuracy: 0.1562\n","Epoch 2, Train Loss: 2.0049, Val Loss: 1.8160, F1 Micro: 0.2188, F1 Macro: 0.1294, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.9072, Val Loss: 1.9698, F1 Micro: 0.2604, F1 Macro: 0.2286, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.8606, Val Loss: 1.8249, F1 Micro: 0.2188, F1 Macro: 0.1254, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.9325, Val Loss: 1.7471, F1 Micro: 0.2292, F1 Macro: 0.1473, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.8979, Val Loss: 1.8693, F1 Micro: 0.2292, F1 Macro: 0.1583, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.8465, Val Loss: 1.9758, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 1.9062, Val Loss: 2.0459, F1 Micro: 0.1979, F1 Macro: 0.1197, Accuracy: 0.1979\n","Epoch 9, Train Loss: 1.8931, Val Loss: 1.8923, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 10, Train Loss: 1.9314, Val Loss: 1.7574, F1 Micro: 0.2396, F1 Macro: 0.1699, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.8500, Val Loss: 2.0949, F1 Micro: 0.1979, F1 Macro: 0.1003, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.9439, Val Loss: 1.8651, F1 Micro: 0.1979, F1 Macro: 0.1463, Accuracy: 0.1979\n","Epoch 13, Train Loss: 1.9263, Val Loss: 1.9143, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 14, Train Loss: 1.8411, Val Loss: 1.7202, F1 Micro: 0.2396, F1 Macro: 0.1674, Accuracy: 0.2396\n","Epoch 15, Train Loss: 1.8816, Val Loss: 1.7464, F1 Micro: 0.2188, F1 Macro: 0.1624, Accuracy: 0.2188\n","Epoch 16, Train Loss: 1.8772, Val Loss: 1.9959, F1 Micro: 0.1771, F1 Macro: 0.1169, Accuracy: 0.1771\n","Epoch 17, Train Loss: 1.9482, Val Loss: 2.0534, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 18, Train Loss: 1.9677, Val Loss: 1.9887, F1 Micro: 0.2083, F1 Macro: 0.1186, Accuracy: 0.2083\n","Epoch 19, Train Loss: 1.9714, Val Loss: 1.9871, F1 Micro: 0.2188, F1 Macro: 0.1400, Accuracy: 0.2188\n","Epoch 20, Train Loss: 1.9626, Val Loss: 1.7389, F1 Micro: 0.2292, F1 Macro: 0.1713, Accuracy: 0.2292\n","Epoch 21, Train Loss: 1.8670, Val Loss: 1.8379, F1 Micro: 0.2083, F1 Macro: 0.1069, Accuracy: 0.2083\n","Epoch 22, Train Loss: 1.8733, Val Loss: 1.8061, F1 Micro: 0.2708, F1 Macro: 0.2159, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.9019, Val Loss: 1.6896, F1 Micro: 0.2604, F1 Macro: 0.1812, Accuracy: 0.2604\n","Epoch 24, Train Loss: 1.8181, Val Loss: 1.8214, F1 Micro: 0.2292, F1 Macro: 0.1273, Accuracy: 0.2292\n","Epoch 25, Train Loss: 1.9626, Val Loss: 1.7233, F1 Micro: 0.2292, F1 Macro: 0.1229, Accuracy: 0.2292\n","Epoch 26, Train Loss: 1.8374, Val Loss: 1.9445, F1 Micro: 0.2292, F1 Macro: 0.1456, Accuracy: 0.2292\n","Epoch 27, Train Loss: 1.9274, Val Loss: 1.9251, F1 Micro: 0.2292, F1 Macro: 0.1351, Accuracy: 0.2292\n","Epoch 28, Train Loss: 1.9443, Val Loss: 1.7847, F1 Micro: 0.2604, F1 Macro: 0.1268, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.8340, Val Loss: 1.7043, F1 Micro: 0.2708, F1 Macro: 0.1844, Accuracy: 0.2708\n","Epoch 30, Train Loss: 1.8528, Val Loss: 1.9055, F1 Micro: 0.2188, F1 Macro: 0.1600, Accuracy: 0.2188\n","Epoch 31, Train Loss: 1.7829, Val Loss: 1.9590, F1 Micro: 0.2188, F1 Macro: 0.1224, Accuracy: 0.2188\n","Epoch 32, Train Loss: 1.9095, Val Loss: 1.9734, F1 Micro: 0.3125, F1 Macro: 0.2238, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.9890, Val Loss: 1.7526, F1 Micro: 0.2396, F1 Macro: 0.1648, Accuracy: 0.2396\n","Epoch 34, Train Loss: 1.8686, Val Loss: 2.1350, F1 Micro: 0.1667, F1 Macro: 0.0706, Accuracy: 0.1667\n","Epoch 35, Train Loss: 1.9275, Val Loss: 1.7494, F1 Micro: 0.2604, F1 Macro: 0.1877, Accuracy: 0.2604\n","Epoch 36, Train Loss: 1.9214, Val Loss: 1.9568, F1 Micro: 0.2292, F1 Macro: 0.1268, Accuracy: 0.2292\n","Epoch 37, Train Loss: 1.7789, Val Loss: 1.7566, F1 Micro: 0.2812, F1 Macro: 0.1906, Accuracy: 0.2812\n","Epoch 38, Train Loss: 1.8684, Val Loss: 1.8704, F1 Micro: 0.2396, F1 Macro: 0.1900, Accuracy: 0.2396\n","Epoch 39, Train Loss: 2.0301, Val Loss: 2.0933, F1 Micro: 0.2708, F1 Macro: 0.1921, Accuracy: 0.2708\n","Epoch 40, Train Loss: 1.8592, Val Loss: 2.1315, F1 Micro: 0.2396, F1 Macro: 0.1392, Accuracy: 0.2396\n","Epoch 41, Train Loss: 1.8699, Val Loss: 1.7905, F1 Micro: 0.3125, F1 Macro: 0.2355, Accuracy: 0.3125\n","Epoch 42, Train Loss: 1.8837, Val Loss: 2.0820, F1 Micro: 0.2708, F1 Macro: 0.2013, Accuracy: 0.2708\n","Epoch 43, Train Loss: 1.8226, Val Loss: 1.8218, F1 Micro: 0.2812, F1 Macro: 0.1904, Accuracy: 0.2812\n","Epoch 44, Train Loss: 1.8388, Val Loss: 1.8853, F1 Micro: 0.2292, F1 Macro: 0.1444, Accuracy: 0.2292\n","Epoch 45, Train Loss: 1.8031, Val Loss: 1.8762, F1 Micro: 0.2188, F1 Macro: 0.1386, Accuracy: 0.2188\n","Epoch 46, Train Loss: 1.8819, Val Loss: 2.0286, F1 Micro: 0.2292, F1 Macro: 0.1384, Accuracy: 0.2292\n","Epoch 47, Train Loss: 2.1014, Val Loss: 1.8474, F1 Micro: 0.1979, F1 Macro: 0.1383, Accuracy: 0.1979\n","Epoch 48, Train Loss: 1.8795, Val Loss: 1.9428, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 49, Train Loss: 1.9893, Val Loss: 2.0565, F1 Micro: 0.1771, F1 Macro: 0.1138, Accuracy: 0.1771\n","Epoch 50, Train Loss: 1.9703, Val Loss: 1.7609, F1 Micro: 0.2500, F1 Macro: 0.1723, Accuracy: 0.2500\n","Epoch 51, Train Loss: 1.8895, Val Loss: 1.7335, F1 Micro: 0.1875, F1 Macro: 0.1536, Accuracy: 0.1875\n","Epoch 52, Train Loss: 1.9876, Val Loss: 1.7588, F1 Micro: 0.2292, F1 Macro: 0.1268, Accuracy: 0.2292\n","Epoch 53, Train Loss: 1.8718, Val Loss: 1.8970, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 54, Train Loss: 2.0764, Val Loss: 2.3025, F1 Micro: 0.2188, F1 Macro: 0.1224, Accuracy: 0.2188\n","Epoch 55, Train Loss: 2.1066, Val Loss: 2.3030, F1 Micro: 0.2396, F1 Macro: 0.1379, Accuracy: 0.2396\n","Epoch 56, Train Loss: 2.1182, Val Loss: 1.8425, F1 Micro: 0.1771, F1 Macro: 0.0917, Accuracy: 0.1771\n","Epoch 57, Train Loss: 1.9087, Val Loss: 1.7384, F1 Micro: 0.2500, F1 Macro: 0.1361, Accuracy: 0.2500\n","Epoch 58, Train Loss: 2.0005, Val Loss: 1.9895, F1 Micro: 0.2188, F1 Macro: 0.1395, Accuracy: 0.2188\n","Epoch 59, Train Loss: 1.9129, Val Loss: 2.1639, F1 Micro: 0.2292, F1 Macro: 0.1300, Accuracy: 0.2292\n","Epoch 60, Train Loss: 2.0577, Val Loss: 1.8441, F1 Micro: 0.2292, F1 Macro: 0.1351, Accuracy: 0.2292\n","Epoch 61, Train Loss: 2.0505, Val Loss: 2.3160, F1 Micro: 0.2083, F1 Macro: 0.1457, Accuracy: 0.2083\n","Epoch 62, Train Loss: 2.1982, Val Loss: 2.5481, F1 Micro: 0.2604, F1 Macro: 0.1831, Accuracy: 0.2604\n","Epoch 63, Train Loss: 1.9810, Val Loss: 1.8936, F1 Micro: 0.2396, F1 Macro: 0.1790, Accuracy: 0.2396\n","Epoch 64, Train Loss: 1.9630, Val Loss: 2.5777, F1 Micro: 0.3021, F1 Macro: 0.2469, Accuracy: 0.3021\n","Epoch 65, Train Loss: 1.9194, Val Loss: 2.1102, F1 Micro: 0.2292, F1 Macro: 0.1310, Accuracy: 0.2292\n","Epoch 66, Train Loss: 1.9055, Val Loss: 2.2620, F1 Micro: 0.2292, F1 Macro: 0.1325, Accuracy: 0.2292\n","Epoch 67, Train Loss: 2.0774, Val Loss: 1.7804, F1 Micro: 0.2292, F1 Macro: 0.1154, Accuracy: 0.2292\n","Epoch 68, Train Loss: 1.8981, Val Loss: 2.1011, F1 Micro: 0.1667, F1 Macro: 0.0637, Accuracy: 0.1667\n","Epoch 69, Train Loss: 1.8523, Val Loss: 1.8080, F1 Micro: 0.2292, F1 Macro: 0.1248, Accuracy: 0.2292\n","Epoch 70, Train Loss: 2.1987, Val Loss: 2.0048, F1 Micro: 0.1875, F1 Macro: 0.0767, Accuracy: 0.1875\n","Epoch 71, Train Loss: 2.0506, Val Loss: 1.8949, F1 Micro: 0.2604, F1 Macro: 0.1722, Accuracy: 0.2604\n","Epoch 72, Train Loss: 2.0381, Val Loss: 2.2554, F1 Micro: 0.2083, F1 Macro: 0.1190, Accuracy: 0.2083\n","Epoch 73, Train Loss: 2.1059, Val Loss: 2.1428, F1 Micro: 0.1562, F1 Macro: 0.0490, Accuracy: 0.1562\n","Epoch 74, Train Loss: 2.0583, Val Loss: 2.1022, F1 Micro: 0.1875, F1 Macro: 0.0970, Accuracy: 0.1875\n","Epoch 75, Train Loss: 2.0022, Val Loss: 2.0654, F1 Micro: 0.2188, F1 Macro: 0.1422, Accuracy: 0.2188\n","Epoch 76, Train Loss: 1.8356, Val Loss: 1.9093, F1 Micro: 0.2396, F1 Macro: 0.1559, Accuracy: 0.2396\n","Epoch 77, Train Loss: 1.8200, Val Loss: 1.8071, F1 Micro: 0.2292, F1 Macro: 0.1453, Accuracy: 0.2292\n","Epoch 78, Train Loss: 1.8447, Val Loss: 2.1010, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 79, Train Loss: 1.9226, Val Loss: 2.2662, F1 Micro: 0.1667, F1 Macro: 0.0850, Accuracy: 0.1667\n","Epoch 80, Train Loss: 1.9168, Val Loss: 1.8885, F1 Micro: 0.2292, F1 Macro: 0.1432, Accuracy: 0.2292\n","Epoch 81, Train Loss: 1.7983, Val Loss: 1.8625, F1 Micro: 0.2812, F1 Macro: 0.1717, Accuracy: 0.2812\n","Epoch 82, Train Loss: 1.7558, Val Loss: 1.8494, F1 Micro: 0.2396, F1 Macro: 0.1744, Accuracy: 0.2396\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.30416666666666664\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.8860, Val Loss: 2.6524, F1 Micro: 0.3021, F1 Macro: 0.1756, Accuracy: 0.3021\n","Epoch 2, Train Loss: 2.3833, Val Loss: 1.9157, F1 Micro: 0.1771, F1 Macro: 0.1480, Accuracy: 0.1771\n","Epoch 3, Train Loss: 2.0320, Val Loss: 1.9039, F1 Micro: 0.2812, F1 Macro: 0.2350, Accuracy: 0.2812\n","Epoch 4, Train Loss: 2.0670, Val Loss: 1.9906, F1 Micro: 0.1979, F1 Macro: 0.1271, Accuracy: 0.1979\n","Epoch 5, Train Loss: 1.9195, Val Loss: 1.8879, F1 Micro: 0.2604, F1 Macro: 0.1405, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.8536, Val Loss: 1.8136, F1 Micro: 0.2604, F1 Macro: 0.1381, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.8130, Val Loss: 1.7284, F1 Micro: 0.2604, F1 Macro: 0.2197, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.8352, Val Loss: 1.7234, F1 Micro: 0.3125, F1 Macro: 0.2148, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.7496, Val Loss: 1.6901, F1 Micro: 0.2500, F1 Macro: 0.1786, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.7890, Val Loss: 1.6763, F1 Micro: 0.2812, F1 Macro: 0.1904, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.7542, Val Loss: 1.7193, F1 Micro: 0.3229, F1 Macro: 0.2879, Accuracy: 0.3229\n","Epoch 12, Train Loss: 1.7049, Val Loss: 1.7004, F1 Micro: 0.3125, F1 Macro: 0.2472, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.7514, Val Loss: 1.6422, F1 Micro: 0.3021, F1 Macro: 0.2912, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.7103, Val Loss: 1.7017, F1 Micro: 0.2917, F1 Macro: 0.2722, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.7443, Val Loss: 1.8048, F1 Micro: 0.2708, F1 Macro: 0.2300, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.7144, Val Loss: 1.6544, F1 Micro: 0.3333, F1 Macro: 0.2858, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.6890, Val Loss: 1.6892, F1 Micro: 0.2708, F1 Macro: 0.2289, Accuracy: 0.2708\n","Epoch 18, Train Loss: 1.6852, Val Loss: 1.6767, F1 Micro: 0.2708, F1 Macro: 0.2443, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.6555, Val Loss: 1.7013, F1 Micro: 0.2604, F1 Macro: 0.2149, Accuracy: 0.2604\n","Epoch 20, Train Loss: 1.6498, Val Loss: 1.7008, F1 Micro: 0.3021, F1 Macro: 0.2703, Accuracy: 0.3021\n","Epoch 21, Train Loss: 1.6706, Val Loss: 1.8328, F1 Micro: 0.2708, F1 Macro: 0.1938, Accuracy: 0.2708\n","Epoch 22, Train Loss: 1.6912, Val Loss: 1.6552, F1 Micro: 0.3750, F1 Macro: 0.3545, Accuracy: 0.3750\n","Epoch 23, Train Loss: 1.6432, Val Loss: 1.7150, F1 Micro: 0.2604, F1 Macro: 0.1803, Accuracy: 0.2604\n","Epoch 24, Train Loss: 1.7041, Val Loss: 1.6452, F1 Micro: 0.3021, F1 Macro: 0.2842, Accuracy: 0.3021\n","Epoch 25, Train Loss: 1.6285, Val Loss: 1.7455, F1 Micro: 0.3125, F1 Macro: 0.2876, Accuracy: 0.3125\n","Epoch 26, Train Loss: 1.6675, Val Loss: 1.6934, F1 Micro: 0.2917, F1 Macro: 0.3007, Accuracy: 0.2917\n","Epoch 27, Train Loss: 1.6131, Val Loss: 1.6948, F1 Micro: 0.3438, F1 Macro: 0.3283, Accuracy: 0.3438\n","Epoch 28, Train Loss: 1.6494, Val Loss: 1.6387, F1 Micro: 0.3646, F1 Macro: 0.3524, Accuracy: 0.3646\n","Epoch 29, Train Loss: 1.6249, Val Loss: 1.6910, F1 Micro: 0.3542, F1 Macro: 0.2992, Accuracy: 0.3542\n","Epoch 30, Train Loss: 1.6105, Val Loss: 1.6570, F1 Micro: 0.3229, F1 Macro: 0.2924, Accuracy: 0.3229\n","Epoch 31, Train Loss: 1.5835, Val Loss: 1.6095, F1 Micro: 0.3438, F1 Macro: 0.2874, Accuracy: 0.3438\n","Epoch 32, Train Loss: 1.6095, Val Loss: 1.7748, F1 Micro: 0.3333, F1 Macro: 0.3044, Accuracy: 0.3333\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 3.0817, Val Loss: 2.1605, F1 Micro: 0.2708, F1 Macro: 0.1745, Accuracy: 0.2708\n","Epoch 2, Train Loss: 2.3355, Val Loss: 2.2660, F1 Micro: 0.1771, F1 Macro: 0.1215, Accuracy: 0.1771\n","Epoch 3, Train Loss: 2.1709, Val Loss: 1.8194, F1 Micro: 0.1458, F1 Macro: 0.0972, Accuracy: 0.1458\n","Epoch 4, Train Loss: 1.9922, Val Loss: 1.7189, F1 Micro: 0.1771, F1 Macro: 0.1557, Accuracy: 0.1771\n","Epoch 5, Train Loss: 2.0033, Val Loss: 1.9463, F1 Micro: 0.2083, F1 Macro: 0.1533, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.8688, Val Loss: 1.7492, F1 Micro: 0.3646, F1 Macro: 0.2950, Accuracy: 0.3646\n","Epoch 7, Train Loss: 1.7966, Val Loss: 1.7568, F1 Micro: 0.2812, F1 Macro: 0.1943, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.8131, Val Loss: 1.7232, F1 Micro: 0.2917, F1 Macro: 0.1835, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.7622, Val Loss: 1.6787, F1 Micro: 0.2812, F1 Macro: 0.1806, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.8425, Val Loss: 1.7171, F1 Micro: 0.2500, F1 Macro: 0.1680, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.7615, Val Loss: 1.7261, F1 Micro: 0.2500, F1 Macro: 0.1694, Accuracy: 0.2500\n","Epoch 12, Train Loss: 1.7353, Val Loss: 1.6931, F1 Micro: 0.2708, F1 Macro: 0.2129, Accuracy: 0.2708\n","Epoch 13, Train Loss: 1.7688, Val Loss: 1.6869, F1 Micro: 0.3125, F1 Macro: 0.2327, Accuracy: 0.3125\n","Epoch 14, Train Loss: 1.7693, Val Loss: 1.7096, F1 Micro: 0.2500, F1 Macro: 0.1593, Accuracy: 0.2500\n","Epoch 15, Train Loss: 1.7516, Val Loss: 1.7362, F1 Micro: 0.2083, F1 Macro: 0.1597, Accuracy: 0.2083\n","Epoch 16, Train Loss: 1.7469, Val Loss: 1.8474, F1 Micro: 0.2604, F1 Macro: 0.2018, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 3.3750, Val Loss: 2.6385, F1 Micro: 0.1354, F1 Macro: 0.0986, Accuracy: 0.1354\n","Epoch 2, Train Loss: 2.2624, Val Loss: 2.0175, F1 Micro: 0.2292, F1 Macro: 0.1434, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.9699, Val Loss: 2.0934, F1 Micro: 0.2292, F1 Macro: 0.1609, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.9237, Val Loss: 1.9053, F1 Micro: 0.1771, F1 Macro: 0.0897, Accuracy: 0.1771\n","Epoch 5, Train Loss: 1.8598, Val Loss: 1.8576, F1 Micro: 0.3438, F1 Macro: 0.2611, Accuracy: 0.3438\n","Epoch 6, Train Loss: 1.8637, Val Loss: 1.8780, F1 Micro: 0.2083, F1 Macro: 0.1545, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.8010, Val Loss: 1.9012, F1 Micro: 0.2188, F1 Macro: 0.1270, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.7908, Val Loss: 1.8459, F1 Micro: 0.2292, F1 Macro: 0.1475, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.7188, Val Loss: 1.8134, F1 Micro: 0.3125, F1 Macro: 0.2552, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.7067, Val Loss: 1.8151, F1 Micro: 0.2083, F1 Macro: 0.1379, Accuracy: 0.2083\n","Epoch 11, Train Loss: 1.7064, Val Loss: 1.8841, F1 Micro: 0.2917, F1 Macro: 0.2160, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.7375, Val Loss: 1.8280, F1 Micro: 0.2604, F1 Macro: 0.2301, Accuracy: 0.2604\n","Epoch 13, Train Loss: 1.6843, Val Loss: 1.8372, F1 Micro: 0.2292, F1 Macro: 0.1294, Accuracy: 0.2292\n","Epoch 14, Train Loss: 1.7400, Val Loss: 1.8614, F1 Micro: 0.1979, F1 Macro: 0.0965, Accuracy: 0.1979\n","Epoch 15, Train Loss: 1.7239, Val Loss: 1.9541, F1 Micro: 0.1875, F1 Macro: 0.1188, Accuracy: 0.1875\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 3.2933, Val Loss: 2.6974, F1 Micro: 0.1875, F1 Macro: 0.1371, Accuracy: 0.1875\n","Epoch 2, Train Loss: 2.2547, Val Loss: 2.0081, F1 Micro: 0.1979, F1 Macro: 0.1189, Accuracy: 0.1979\n","Epoch 3, Train Loss: 2.1082, Val Loss: 1.7978, F1 Micro: 0.1875, F1 Macro: 0.1476, Accuracy: 0.1875\n","Epoch 4, Train Loss: 1.8754, Val Loss: 1.8631, F1 Micro: 0.2188, F1 Macro: 0.1348, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.9305, Val Loss: 1.9749, F1 Micro: 0.2292, F1 Macro: 0.1341, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.8406, Val Loss: 1.7096, F1 Micro: 0.2292, F1 Macro: 0.1513, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.7170, Val Loss: 1.7870, F1 Micro: 0.2188, F1 Macro: 0.1461, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.7902, Val Loss: 1.8438, F1 Micro: 0.2604, F1 Macro: 0.1759, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.7482, Val Loss: 1.9008, F1 Micro: 0.1979, F1 Macro: 0.1228, Accuracy: 0.1979\n","Epoch 10, Train Loss: 1.7061, Val Loss: 1.8267, F1 Micro: 0.2708, F1 Macro: 0.1520, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.7474, Val Loss: 1.7578, F1 Micro: 0.3125, F1 Macro: 0.2271, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.7211, Val Loss: 1.7111, F1 Micro: 0.2500, F1 Macro: 0.1576, Accuracy: 0.2500\n","Epoch 13, Train Loss: 1.6869, Val Loss: 1.7343, F1 Micro: 0.2604, F1 Macro: 0.2012, Accuracy: 0.2604\n","Epoch 14, Train Loss: 1.7451, Val Loss: 1.8727, F1 Micro: 0.2500, F1 Macro: 0.1637, Accuracy: 0.2500\n","Epoch 15, Train Loss: 1.7647, Val Loss: 1.7363, F1 Micro: 0.1979, F1 Macro: 0.1310, Accuracy: 0.1979\n","Epoch 16, Train Loss: 1.7730, Val Loss: 1.7439, F1 Micro: 0.2500, F1 Macro: 0.1902, Accuracy: 0.2500\n","Epoch 17, Train Loss: 1.6960, Val Loss: 1.7190, F1 Micro: 0.2292, F1 Macro: 0.1817, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.7268, Val Loss: 1.8074, F1 Micro: 0.2396, F1 Macro: 0.1435, Accuracy: 0.2396\n","Epoch 19, Train Loss: 1.6920, Val Loss: 1.7717, F1 Micro: 0.2396, F1 Macro: 0.1550, Accuracy: 0.2396\n","Epoch 20, Train Loss: 1.6752, Val Loss: 1.7274, F1 Micro: 0.2188, F1 Macro: 0.1509, Accuracy: 0.2188\n","Epoch 21, Train Loss: 1.6983, Val Loss: 1.7732, F1 Micro: 0.3021, F1 Macro: 0.2822, Accuracy: 0.3021\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 3.4400, Val Loss: 2.0177, F1 Micro: 0.2396, F1 Macro: 0.1479, Accuracy: 0.2396\n","Epoch 2, Train Loss: 2.5013, Val Loss: 1.7589, F1 Micro: 0.3229, F1 Macro: 0.2349, Accuracy: 0.3229\n","Epoch 3, Train Loss: 2.0382, Val Loss: 1.9709, F1 Micro: 0.2292, F1 Macro: 0.1699, Accuracy: 0.2292\n","Epoch 4, Train Loss: 2.0331, Val Loss: 1.9412, F1 Micro: 0.2188, F1 Macro: 0.1302, Accuracy: 0.2188\n","Epoch 5, Train Loss: 2.0065, Val Loss: 2.0529, F1 Micro: 0.2500, F1 Macro: 0.2287, Accuracy: 0.2500\n","Epoch 6, Train Loss: 1.8778, Val Loss: 1.7590, F1 Micro: 0.3021, F1 Macro: 0.2326, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.7965, Val Loss: 1.8575, F1 Micro: 0.2500, F1 Macro: 0.2031, Accuracy: 0.2500\n","Epoch 8, Train Loss: 1.8609, Val Loss: 1.6909, F1 Micro: 0.2708, F1 Macro: 0.2230, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.7238, Val Loss: 1.7586, F1 Micro: 0.2500, F1 Macro: 0.2007, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.7086, Val Loss: 1.6914, F1 Micro: 0.2812, F1 Macro: 0.2446, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.7561, Val Loss: 1.6925, F1 Micro: 0.2396, F1 Macro: 0.2027, Accuracy: 0.2396\n","Epoch 12, Train Loss: 1.7234, Val Loss: 1.6943, F1 Micro: 0.2917, F1 Macro: 0.2875, Accuracy: 0.2917\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.34375\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.1185, Val Loss: 2.8414, F1 Micro: 0.2292, F1 Macro: 0.1297, Accuracy: 0.2292\n","Epoch 2, Train Loss: 2.4532, Val Loss: 1.9847, F1 Micro: 0.2812, F1 Macro: 0.1776, Accuracy: 0.2812\n","Epoch 3, Train Loss: 2.2667, Val Loss: 1.8357, F1 Micro: 0.2812, F1 Macro: 0.1802, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.9320, Val Loss: 1.9296, F1 Micro: 0.2292, F1 Macro: 0.1818, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.7860, Val Loss: 1.7297, F1 Micro: 0.2292, F1 Macro: 0.1725, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.8780, Val Loss: 1.6372, F1 Micro: 0.3021, F1 Macro: 0.2230, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.8148, Val Loss: 1.7064, F1 Micro: 0.3229, F1 Macro: 0.2604, Accuracy: 0.3229\n","Epoch 8, Train Loss: 1.7564, Val Loss: 1.6703, F1 Micro: 0.3021, F1 Macro: 0.2324, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.7689, Val Loss: 1.6709, F1 Micro: 0.2292, F1 Macro: 0.1766, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.7909, Val Loss: 1.6720, F1 Micro: 0.3021, F1 Macro: 0.2759, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.7802, Val Loss: 1.7343, F1 Micro: 0.3021, F1 Macro: 0.2089, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.7580, Val Loss: 1.7038, F1 Micro: 0.3125, F1 Macro: 0.2246, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.7003, Val Loss: 1.6563, F1 Micro: 0.2708, F1 Macro: 0.2559, Accuracy: 0.2708\n","Epoch 14, Train Loss: 1.7121, Val Loss: 1.8203, F1 Micro: 0.2292, F1 Macro: 0.2065, Accuracy: 0.2292\n","Epoch 15, Train Loss: 1.7007, Val Loss: 1.6825, F1 Micro: 0.3021, F1 Macro: 0.2530, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.6894, Val Loss: 1.6712, F1 Micro: 0.2812, F1 Macro: 0.2370, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.7099, Val Loss: 1.6427, F1 Micro: 0.3542, F1 Macro: 0.3334, Accuracy: 0.3542\n","Epoch 18, Train Loss: 1.7036, Val Loss: 1.7764, F1 Micro: 0.2604, F1 Macro: 0.2065, Accuracy: 0.2604\n","Epoch 19, Train Loss: 1.6613, Val Loss: 1.6519, F1 Micro: 0.3750, F1 Macro: 0.3577, Accuracy: 0.3750\n","Epoch 20, Train Loss: 1.6282, Val Loss: 1.7416, F1 Micro: 0.2812, F1 Macro: 0.2474, Accuracy: 0.2812\n","Epoch 21, Train Loss: 1.6360, Val Loss: 1.7794, F1 Micro: 0.3021, F1 Macro: 0.2778, Accuracy: 0.3021\n","Epoch 22, Train Loss: 1.6320, Val Loss: 1.7936, F1 Micro: 0.2812, F1 Macro: 0.2702, Accuracy: 0.2812\n","Epoch 23, Train Loss: 1.6666, Val Loss: 1.6555, F1 Micro: 0.3646, F1 Macro: 0.3283, Accuracy: 0.3646\n","Epoch 24, Train Loss: 1.6734, Val Loss: 1.6902, F1 Micro: 0.3125, F1 Macro: 0.3047, Accuracy: 0.3125\n","Epoch 25, Train Loss: 1.6154, Val Loss: 1.7690, F1 Micro: 0.2812, F1 Macro: 0.2256, Accuracy: 0.2812\n","Epoch 26, Train Loss: 1.6067, Val Loss: 1.6800, F1 Micro: 0.2708, F1 Macro: 0.2245, Accuracy: 0.2708\n","Epoch 27, Train Loss: 1.5974, Val Loss: 1.7189, F1 Micro: 0.3021, F1 Macro: 0.2842, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.5733, Val Loss: 1.6870, F1 Micro: 0.3333, F1 Macro: 0.2924, Accuracy: 0.3333\n","Epoch 29, Train Loss: 1.6570, Val Loss: 1.6275, F1 Micro: 0.3438, F1 Macro: 0.3147, Accuracy: 0.3438\n","Epoch 30, Train Loss: 1.6357, Val Loss: 1.6339, F1 Micro: 0.3646, F1 Macro: 0.3399, Accuracy: 0.3646\n","Epoch 31, Train Loss: 1.6080, Val Loss: 1.8471, F1 Micro: 0.2604, F1 Macro: 0.2283, Accuracy: 0.2604\n","Epoch 32, Train Loss: 1.6208, Val Loss: 1.6366, F1 Micro: 0.3958, F1 Macro: 0.3913, Accuracy: 0.3958\n","Epoch 33, Train Loss: 1.5945, Val Loss: 1.6616, F1 Micro: 0.3333, F1 Macro: 0.3313, Accuracy: 0.3333\n","Epoch 34, Train Loss: 1.5263, Val Loss: 1.7507, F1 Micro: 0.3229, F1 Macro: 0.2141, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.5718, Val Loss: 1.8056, F1 Micro: 0.2188, F1 Macro: 0.2043, Accuracy: 0.2188\n","Epoch 36, Train Loss: 1.5392, Val Loss: 1.6160, F1 Micro: 0.3646, F1 Macro: 0.3640, Accuracy: 0.3646\n","Epoch 37, Train Loss: 1.5968, Val Loss: 1.6466, F1 Micro: 0.3958, F1 Macro: 0.3865, Accuracy: 0.3958\n","Epoch 38, Train Loss: 1.5386, Val Loss: 1.6498, F1 Micro: 0.3333, F1 Macro: 0.2868, Accuracy: 0.3333\n","Epoch 39, Train Loss: 1.5169, Val Loss: 1.8277, F1 Micro: 0.2917, F1 Macro: 0.2832, Accuracy: 0.2917\n","Epoch 40, Train Loss: 1.5149, Val Loss: 1.6512, F1 Micro: 0.3750, F1 Macro: 0.3722, Accuracy: 0.3750\n","Epoch 41, Train Loss: 1.4610, Val Loss: 1.7213, F1 Micro: 0.3854, F1 Macro: 0.3166, Accuracy: 0.3854\n","Epoch 42, Train Loss: 1.5944, Val Loss: 1.6999, F1 Micro: 0.3229, F1 Macro: 0.2830, Accuracy: 0.3229\n","Epoch 43, Train Loss: 1.5228, Val Loss: 1.5775, F1 Micro: 0.3958, F1 Macro: 0.3822, Accuracy: 0.3958\n","Epoch 44, Train Loss: 1.4915, Val Loss: 1.6211, F1 Micro: 0.3750, F1 Macro: 0.3585, Accuracy: 0.3750\n","Epoch 45, Train Loss: 1.4964, Val Loss: 1.7475, F1 Micro: 0.3542, F1 Macro: 0.3100, Accuracy: 0.3542\n","Epoch 46, Train Loss: 1.4938, Val Loss: 1.7429, F1 Micro: 0.3125, F1 Macro: 0.3038, Accuracy: 0.3125\n","Epoch 47, Train Loss: 1.4807, Val Loss: 1.6932, F1 Micro: 0.3750, F1 Macro: 0.3688, Accuracy: 0.3750\n","Epoch 48, Train Loss: 1.4613, Val Loss: 1.8367, F1 Micro: 0.3125, F1 Macro: 0.2979, Accuracy: 0.3125\n","Epoch 49, Train Loss: 1.4594, Val Loss: 1.6617, F1 Micro: 0.3333, F1 Macro: 0.3410, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.4776, Val Loss: 1.7387, F1 Micro: 0.3542, F1 Macro: 0.3424, Accuracy: 0.3542\n","Epoch 51, Train Loss: 1.4618, Val Loss: 1.6004, F1 Micro: 0.3750, F1 Macro: 0.3400, Accuracy: 0.3750\n","Epoch 52, Train Loss: 1.4631, Val Loss: 1.6502, F1 Micro: 0.3854, F1 Macro: 0.3670, Accuracy: 0.3854\n","Epoch 53, Train Loss: 1.4731, Val Loss: 1.6426, F1 Micro: 0.3958, F1 Macro: 0.3884, Accuracy: 0.3958\n","Epoch 54, Train Loss: 1.3981, Val Loss: 1.7268, F1 Micro: 0.3750, F1 Macro: 0.3619, Accuracy: 0.3750\n","Epoch 55, Train Loss: 1.4070, Val Loss: 1.6150, F1 Micro: 0.4271, F1 Macro: 0.4174, Accuracy: 0.4271\n","Epoch 56, Train Loss: 1.3573, Val Loss: 1.6486, F1 Micro: 0.4167, F1 Macro: 0.3904, Accuracy: 0.4167\n","Epoch 57, Train Loss: 1.4013, Val Loss: 1.6523, F1 Micro: 0.4062, F1 Macro: 0.4026, Accuracy: 0.4062\n","Epoch 58, Train Loss: 1.3692, Val Loss: 1.6465, F1 Micro: 0.4271, F1 Macro: 0.4231, Accuracy: 0.4271\n","Epoch 59, Train Loss: 1.4104, Val Loss: 1.5764, F1 Micro: 0.4167, F1 Macro: 0.4137, Accuracy: 0.4167\n","Epoch 60, Train Loss: 1.3807, Val Loss: 2.0123, F1 Micro: 0.2917, F1 Macro: 0.2498, Accuracy: 0.2917\n","Epoch 61, Train Loss: 1.4678, Val Loss: 1.8346, F1 Micro: 0.3438, F1 Macro: 0.3184, Accuracy: 0.3438\n","Epoch 62, Train Loss: 1.3342, Val Loss: 1.6851, F1 Micro: 0.3542, F1 Macro: 0.3573, Accuracy: 0.3542\n","Epoch 63, Train Loss: 1.3300, Val Loss: 1.6612, F1 Micro: 0.3958, F1 Macro: 0.3844, Accuracy: 0.3958\n","Epoch 64, Train Loss: 1.3378, Val Loss: 1.6683, F1 Micro: 0.4167, F1 Macro: 0.4010, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.2974, Val Loss: 1.6445, F1 Micro: 0.4375, F1 Macro: 0.4114, Accuracy: 0.4375\n","Epoch 66, Train Loss: 1.3353, Val Loss: 1.7348, F1 Micro: 0.3542, F1 Macro: 0.3404, Accuracy: 0.3542\n","Epoch 67, Train Loss: 1.3522, Val Loss: 1.8061, F1 Micro: 0.3229, F1 Macro: 0.2913, Accuracy: 0.3229\n","Epoch 68, Train Loss: 1.3809, Val Loss: 1.7291, F1 Micro: 0.3958, F1 Macro: 0.3520, Accuracy: 0.3958\n","Epoch 69, Train Loss: 1.3278, Val Loss: 1.6439, F1 Micro: 0.4583, F1 Macro: 0.4576, Accuracy: 0.4583\n","Epoch 70, Train Loss: 1.2514, Val Loss: 1.7162, F1 Micro: 0.3854, F1 Macro: 0.3845, Accuracy: 0.3854\n","Epoch 71, Train Loss: 1.3019, Val Loss: 1.6575, F1 Micro: 0.4062, F1 Macro: 0.4020, Accuracy: 0.4062\n","Epoch 72, Train Loss: 1.2999, Val Loss: 1.7044, F1 Micro: 0.4375, F1 Macro: 0.3638, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.3167, Val Loss: 1.6858, F1 Micro: 0.4062, F1 Macro: 0.4101, Accuracy: 0.4062\n","Epoch 74, Train Loss: 1.2524, Val Loss: 1.6974, F1 Micro: 0.4167, F1 Macro: 0.3522, Accuracy: 0.4167\n","Epoch 75, Train Loss: 1.2656, Val Loss: 1.7890, F1 Micro: 0.3854, F1 Macro: 0.3799, Accuracy: 0.3854\n","Epoch 76, Train Loss: 1.2988, Val Loss: 1.8553, F1 Micro: 0.4375, F1 Macro: 0.4428, Accuracy: 0.4375\n","Epoch 77, Train Loss: 1.2736, Val Loss: 1.6692, F1 Micro: 0.4271, F1 Macro: 0.3958, Accuracy: 0.4271\n","Epoch 78, Train Loss: 1.2281, Val Loss: 1.6546, F1 Micro: 0.4167, F1 Macro: 0.3979, Accuracy: 0.4167\n","Epoch 79, Train Loss: 1.2112, Val Loss: 1.6087, F1 Micro: 0.5104, F1 Macro: 0.4814, Accuracy: 0.5104\n","Epoch 80, Train Loss: 1.2716, Val Loss: 1.7612, F1 Micro: 0.3750, F1 Macro: 0.3501, Accuracy: 0.3750\n","Epoch 81, Train Loss: 1.2401, Val Loss: 1.8804, F1 Micro: 0.3438, F1 Macro: 0.3477, Accuracy: 0.3438\n","Epoch 82, Train Loss: 1.2494, Val Loss: 1.7770, F1 Micro: 0.4167, F1 Macro: 0.4025, Accuracy: 0.4167\n","Epoch 83, Train Loss: 1.2718, Val Loss: 1.6736, F1 Micro: 0.4688, F1 Macro: 0.4515, Accuracy: 0.4688\n","Epoch 84, Train Loss: 1.1973, Val Loss: 1.8148, F1 Micro: 0.4271, F1 Macro: 0.3613, Accuracy: 0.4271\n","Epoch 85, Train Loss: 1.2554, Val Loss: 1.7486, F1 Micro: 0.4062, F1 Macro: 0.3953, Accuracy: 0.4062\n","Epoch 86, Train Loss: 1.1943, Val Loss: 1.6691, F1 Micro: 0.4167, F1 Macro: 0.3883, Accuracy: 0.4167\n","Epoch 87, Train Loss: 1.2097, Val Loss: 1.6327, F1 Micro: 0.4688, F1 Macro: 0.4376, Accuracy: 0.4688\n","Epoch 88, Train Loss: 1.1979, Val Loss: 1.6625, F1 Micro: 0.4479, F1 Macro: 0.4400, Accuracy: 0.4479\n","Epoch 89, Train Loss: 1.2275, Val Loss: 1.8238, F1 Micro: 0.3958, F1 Macro: 0.3759, Accuracy: 0.3958\n","Epoch 90, Train Loss: 1.1982, Val Loss: 1.6370, F1 Micro: 0.4479, F1 Macro: 0.4376, Accuracy: 0.4479\n","Epoch 91, Train Loss: 1.1272, Val Loss: 1.6236, F1 Micro: 0.4167, F1 Macro: 0.3884, Accuracy: 0.4167\n","Epoch 92, Train Loss: 1.1925, Val Loss: 1.6841, F1 Micro: 0.4583, F1 Macro: 0.4468, Accuracy: 0.4583\n","Epoch 93, Train Loss: 1.1559, Val Loss: 1.7298, F1 Micro: 0.4688, F1 Macro: 0.4166, Accuracy: 0.4688\n","Epoch 94, Train Loss: 1.1644, Val Loss: 1.6351, F1 Micro: 0.4479, F1 Macro: 0.4191, Accuracy: 0.4479\n","Epoch 95, Train Loss: 1.1907, Val Loss: 1.7122, F1 Micro: 0.4271, F1 Macro: 0.3944, Accuracy: 0.4271\n","Epoch 96, Train Loss: 1.1613, Val Loss: 2.1488, F1 Micro: 0.3542, F1 Macro: 0.3659, Accuracy: 0.3542\n","Epoch 97, Train Loss: 1.2151, Val Loss: 1.7595, F1 Micro: 0.3958, F1 Macro: 0.3867, Accuracy: 0.3958\n","Epoch 98, Train Loss: 1.1101, Val Loss: 1.6560, F1 Micro: 0.4375, F1 Macro: 0.4191, Accuracy: 0.4375\n","Epoch 99, Train Loss: 1.1659, Val Loss: 1.8194, F1 Micro: 0.3854, F1 Macro: 0.3776, Accuracy: 0.3854\n","Epoch 100, Train Loss: 1.1718, Val Loss: 1.6307, F1 Micro: 0.4271, F1 Macro: 0.4301, Accuracy: 0.4271\n","Epoch 101, Train Loss: 1.1052, Val Loss: 1.6525, F1 Micro: 0.4479, F1 Macro: 0.4381, Accuracy: 0.4479\n","Epoch 102, Train Loss: 1.1758, Val Loss: 1.7321, F1 Micro: 0.4688, F1 Macro: 0.4611, Accuracy: 0.4688\n","Epoch 103, Train Loss: 1.1750, Val Loss: 1.7853, F1 Micro: 0.4271, F1 Macro: 0.4514, Accuracy: 0.4271\n","Epoch 104, Train Loss: 1.1479, Val Loss: 1.6773, F1 Micro: 0.4062, F1 Macro: 0.4013, Accuracy: 0.4062\n","Epoch 105, Train Loss: 1.1526, Val Loss: 1.7400, F1 Micro: 0.4271, F1 Macro: 0.4378, Accuracy: 0.4271\n","Epoch 106, Train Loss: 1.0901, Val Loss: 1.5754, F1 Micro: 0.4688, F1 Macro: 0.4528, Accuracy: 0.4688\n","Epoch 107, Train Loss: 1.0479, Val Loss: 1.5893, F1 Micro: 0.4792, F1 Macro: 0.4545, Accuracy: 0.4792\n","Epoch 108, Train Loss: 1.1091, Val Loss: 1.6065, F1 Micro: 0.5104, F1 Macro: 0.4917, Accuracy: 0.5104\n","Epoch 109, Train Loss: 1.0564, Val Loss: 1.6848, F1 Micro: 0.4896, F1 Macro: 0.4340, Accuracy: 0.4896\n","Epoch 110, Train Loss: 1.1398, Val Loss: 1.6339, F1 Micro: 0.4479, F1 Macro: 0.4395, Accuracy: 0.4479\n","Epoch 111, Train Loss: 1.0617, Val Loss: 1.7265, F1 Micro: 0.4479, F1 Macro: 0.4582, Accuracy: 0.4479\n","Epoch 112, Train Loss: 1.0359, Val Loss: 1.7157, F1 Micro: 0.4583, F1 Macro: 0.4441, Accuracy: 0.4583\n","Epoch 113, Train Loss: 1.0323, Val Loss: 1.7622, F1 Micro: 0.4583, F1 Macro: 0.4379, Accuracy: 0.4583\n","Epoch 114, Train Loss: 1.0304, Val Loss: 1.7555, F1 Micro: 0.4479, F1 Macro: 0.4575, Accuracy: 0.4479\n","Epoch 115, Train Loss: 1.0658, Val Loss: 1.7600, F1 Micro: 0.4479, F1 Macro: 0.4399, Accuracy: 0.4479\n","Epoch 116, Train Loss: 1.0596, Val Loss: 1.7148, F1 Micro: 0.4479, F1 Macro: 0.4150, Accuracy: 0.4479\n","Epoch 117, Train Loss: 1.0230, Val Loss: 1.7302, F1 Micro: 0.5000, F1 Macro: 0.4816, Accuracy: 0.5000\n","Epoch 118, Train Loss: 0.9747, Val Loss: 1.7797, F1 Micro: 0.4375, F1 Macro: 0.4392, Accuracy: 0.4375\n","Epoch 119, Train Loss: 1.0433, Val Loss: 1.7540, F1 Micro: 0.4167, F1 Macro: 0.4006, Accuracy: 0.4167\n","Epoch 120, Train Loss: 1.0818, Val Loss: 1.7986, F1 Micro: 0.5000, F1 Macro: 0.4896, Accuracy: 0.5000\n","Epoch 121, Train Loss: 1.0002, Val Loss: 1.8898, F1 Micro: 0.3958, F1 Macro: 0.3795, Accuracy: 0.3958\n","Epoch 122, Train Loss: 1.0510, Val Loss: 1.7998, F1 Micro: 0.5208, F1 Macro: 0.5196, Accuracy: 0.5208\n","Epoch 123, Train Loss: 1.0215, Val Loss: 1.7817, F1 Micro: 0.4583, F1 Macro: 0.4415, Accuracy: 0.4583\n","Epoch 124, Train Loss: 0.9609, Val Loss: 1.6585, F1 Micro: 0.4688, F1 Macro: 0.4565, Accuracy: 0.4688\n","Epoch 125, Train Loss: 0.9757, Val Loss: 1.8470, F1 Micro: 0.4271, F1 Macro: 0.4091, Accuracy: 0.4271\n","Epoch 126, Train Loss: 1.0149, Val Loss: 1.8337, F1 Micro: 0.4479, F1 Macro: 0.4222, Accuracy: 0.4479\n","Epoch 127, Train Loss: 1.0343, Val Loss: 1.7166, F1 Micro: 0.4688, F1 Macro: 0.4466, Accuracy: 0.4688\n","Epoch 128, Train Loss: 0.9394, Val Loss: 1.8170, F1 Micro: 0.4792, F1 Macro: 0.4674, Accuracy: 0.4792\n","Epoch 129, Train Loss: 0.9728, Val Loss: 1.7143, F1 Micro: 0.4271, F1 Macro: 0.4183, Accuracy: 0.4271\n","Epoch 130, Train Loss: 0.8744, Val Loss: 1.8550, F1 Micro: 0.4271, F1 Macro: 0.4035, Accuracy: 0.4271\n","Epoch 131, Train Loss: 1.0036, Val Loss: 1.6528, F1 Micro: 0.4792, F1 Macro: 0.4560, Accuracy: 0.4792\n","Epoch 132, Train Loss: 0.9688, Val Loss: 1.7040, F1 Micro: 0.4479, F1 Macro: 0.4327, Accuracy: 0.4479\n","Epoch 133, Train Loss: 0.9373, Val Loss: 1.9500, F1 Micro: 0.4375, F1 Macro: 0.4248, Accuracy: 0.4375\n","Epoch 134, Train Loss: 0.9379, Val Loss: 1.7393, F1 Micro: 0.4792, F1 Macro: 0.4468, Accuracy: 0.4792\n","Epoch 135, Train Loss: 0.9370, Val Loss: 1.8747, F1 Micro: 0.4583, F1 Macro: 0.4480, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.9184, Val Loss: 1.6805, F1 Micro: 0.5104, F1 Macro: 0.4984, Accuracy: 0.5104\n","Epoch 137, Train Loss: 0.9071, Val Loss: 1.7828, F1 Micro: 0.4479, F1 Macro: 0.4222, Accuracy: 0.4479\n","Epoch 138, Train Loss: 1.0179, Val Loss: 1.8484, F1 Micro: 0.4375, F1 Macro: 0.4145, Accuracy: 0.4375\n","Epoch 139, Train Loss: 0.9399, Val Loss: 1.6856, F1 Micro: 0.4583, F1 Macro: 0.4563, Accuracy: 0.4583\n","Epoch 140, Train Loss: 0.8766, Val Loss: 1.6793, F1 Micro: 0.4688, F1 Macro: 0.4513, Accuracy: 0.4688\n","Epoch 141, Train Loss: 0.9341, Val Loss: 1.8629, F1 Micro: 0.4688, F1 Macro: 0.4379, Accuracy: 0.4688\n","Epoch 142, Train Loss: 0.8636, Val Loss: 1.7245, F1 Micro: 0.4792, F1 Macro: 0.4748, Accuracy: 0.4792\n","Epoch 143, Train Loss: 0.8843, Val Loss: 1.8741, F1 Micro: 0.4583, F1 Macro: 0.4542, Accuracy: 0.4583\n","Epoch 144, Train Loss: 0.8612, Val Loss: 1.8192, F1 Micro: 0.5000, F1 Macro: 0.4822, Accuracy: 0.5000\n","Epoch 145, Train Loss: 0.9057, Val Loss: 1.6498, F1 Micro: 0.5312, F1 Macro: 0.4949, Accuracy: 0.5312\n","Epoch 146, Train Loss: 0.8321, Val Loss: 1.7429, F1 Micro: 0.4479, F1 Macro: 0.4534, Accuracy: 0.4479\n","Epoch 147, Train Loss: 0.8753, Val Loss: 1.7132, F1 Micro: 0.4583, F1 Macro: 0.4430, Accuracy: 0.4583\n","Epoch 148, Train Loss: 0.8743, Val Loss: 1.6991, F1 Micro: 0.4896, F1 Macro: 0.4642, Accuracy: 0.4896\n","Epoch 149, Train Loss: 0.8307, Val Loss: 1.7015, F1 Micro: 0.5000, F1 Macro: 0.4670, Accuracy: 0.5000\n","Epoch 150, Train Loss: 0.8478, Val Loss: 1.7700, F1 Micro: 0.4896, F1 Macro: 0.4811, Accuracy: 0.4896\n","Epoch 151, Train Loss: 0.8604, Val Loss: 1.8337, F1 Micro: 0.4792, F1 Macro: 0.4731, Accuracy: 0.4792\n","Epoch 152, Train Loss: 0.8330, Val Loss: 1.8010, F1 Micro: 0.5000, F1 Macro: 0.4945, Accuracy: 0.5000\n","Epoch 153, Train Loss: 0.8510, Val Loss: 1.9818, F1 Micro: 0.4479, F1 Macro: 0.4487, Accuracy: 0.4479\n","Epoch 154, Train Loss: 0.8466, Val Loss: 2.0137, F1 Micro: 0.4688, F1 Macro: 0.4739, Accuracy: 0.4688\n","Epoch 155, Train Loss: 0.7992, Val Loss: 1.8851, F1 Micro: 0.5104, F1 Macro: 0.4997, Accuracy: 0.5104\n","Epoch 156, Train Loss: 0.8266, Val Loss: 1.9947, F1 Micro: 0.4479, F1 Macro: 0.4414, Accuracy: 0.4479\n","Epoch 157, Train Loss: 0.8476, Val Loss: 1.8615, F1 Micro: 0.5208, F1 Macro: 0.5242, Accuracy: 0.5208\n","Epoch 158, Train Loss: 0.7566, Val Loss: 1.8164, F1 Micro: 0.5208, F1 Macro: 0.5234, Accuracy: 0.5208\n","Epoch 159, Train Loss: 0.7500, Val Loss: 1.7754, F1 Micro: 0.5000, F1 Macro: 0.4685, Accuracy: 0.5000\n","Epoch 160, Train Loss: 0.7496, Val Loss: 1.7899, F1 Micro: 0.4792, F1 Macro: 0.4534, Accuracy: 0.4792\n","Epoch 161, Train Loss: 0.7963, Val Loss: 1.8283, F1 Micro: 0.4688, F1 Macro: 0.4467, Accuracy: 0.4688\n","Epoch 162, Train Loss: 0.7111, Val Loss: 1.7863, F1 Micro: 0.4479, F1 Macro: 0.4308, Accuracy: 0.4479\n","Epoch 163, Train Loss: 0.7778, Val Loss: 1.9321, F1 Micro: 0.4792, F1 Macro: 0.4622, Accuracy: 0.4792\n","Epoch 164, Train Loss: 0.7751, Val Loss: 1.9095, F1 Micro: 0.5104, F1 Macro: 0.4995, Accuracy: 0.5104\n","Epoch 165, Train Loss: 0.7427, Val Loss: 1.9037, F1 Micro: 0.5625, F1 Macro: 0.5348, Accuracy: 0.5625\n","Epoch 166, Train Loss: 0.7385, Val Loss: 2.0706, F1 Micro: 0.5104, F1 Macro: 0.4896, Accuracy: 0.5104\n","Epoch 167, Train Loss: 0.7517, Val Loss: 2.0166, F1 Micro: 0.4896, F1 Macro: 0.4967, Accuracy: 0.4896\n","Epoch 168, Train Loss: 0.7115, Val Loss: 1.9839, F1 Micro: 0.4792, F1 Macro: 0.4820, Accuracy: 0.4792\n","Epoch 169, Train Loss: 0.7320, Val Loss: 1.8632, F1 Micro: 0.5104, F1 Macro: 0.4798, Accuracy: 0.5104\n","Epoch 170, Train Loss: 0.6804, Val Loss: 1.9621, F1 Micro: 0.4792, F1 Macro: 0.4770, Accuracy: 0.4792\n","Epoch 171, Train Loss: 0.7885, Val Loss: 1.8422, F1 Micro: 0.5625, F1 Macro: 0.5341, Accuracy: 0.5625\n","Epoch 172, Train Loss: 0.7395, Val Loss: 2.0075, F1 Micro: 0.5208, F1 Macro: 0.5007, Accuracy: 0.5208\n","Epoch 173, Train Loss: 0.6565, Val Loss: 2.0430, F1 Micro: 0.5208, F1 Macro: 0.5149, Accuracy: 0.5208\n","Epoch 174, Train Loss: 0.7235, Val Loss: 1.8313, F1 Micro: 0.5104, F1 Macro: 0.4901, Accuracy: 0.5104\n","Epoch 175, Train Loss: 0.7545, Val Loss: 1.8336, F1 Micro: 0.5208, F1 Macro: 0.5086, Accuracy: 0.5208\n","Epoch 176, Train Loss: 0.6625, Val Loss: 1.8668, F1 Micro: 0.5521, F1 Macro: 0.5419, Accuracy: 0.5521\n","Epoch 177, Train Loss: 0.7161, Val Loss: 1.8587, F1 Micro: 0.5312, F1 Macro: 0.4891, Accuracy: 0.5312\n","Epoch 178, Train Loss: 0.6934, Val Loss: 2.1359, F1 Micro: 0.5312, F1 Macro: 0.5002, Accuracy: 0.5312\n","Epoch 179, Train Loss: 0.6407, Val Loss: 2.0578, F1 Micro: 0.4792, F1 Macro: 0.4677, Accuracy: 0.4792\n","Epoch 180, Train Loss: 0.6572, Val Loss: 1.9907, F1 Micro: 0.5312, F1 Macro: 0.5072, Accuracy: 0.5312\n","Epoch 181, Train Loss: 0.6669, Val Loss: 2.0742, F1 Micro: 0.4688, F1 Macro: 0.4572, Accuracy: 0.4688\n","Epoch 182, Train Loss: 0.6542, Val Loss: 1.9773, F1 Micro: 0.5625, F1 Macro: 0.5378, Accuracy: 0.5625\n","Epoch 183, Train Loss: 0.7148, Val Loss: 1.8491, F1 Micro: 0.5000, F1 Macro: 0.4690, Accuracy: 0.5000\n","Epoch 184, Train Loss: 0.6953, Val Loss: 2.2098, F1 Micro: 0.4896, F1 Macro: 0.4780, Accuracy: 0.4896\n","Epoch 185, Train Loss: 0.7453, Val Loss: 2.0963, F1 Micro: 0.4271, F1 Macro: 0.4226, Accuracy: 0.4271\n","Epoch 186, Train Loss: 0.6915, Val Loss: 2.1471, F1 Micro: 0.4896, F1 Macro: 0.4689, Accuracy: 0.4896\n","Epoch 187, Train Loss: 0.6393, Val Loss: 2.0561, F1 Micro: 0.5729, F1 Macro: 0.5487, Accuracy: 0.5729\n","Epoch 188, Train Loss: 0.7255, Val Loss: 2.0995, F1 Micro: 0.4688, F1 Macro: 0.4589, Accuracy: 0.4688\n","Epoch 189, Train Loss: 0.5989, Val Loss: 2.0845, F1 Micro: 0.5000, F1 Macro: 0.4612, Accuracy: 0.5000\n","Epoch 190, Train Loss: 0.7114, Val Loss: 2.0830, F1 Micro: 0.4688, F1 Macro: 0.4624, Accuracy: 0.4688\n","Epoch 191, Train Loss: 0.6274, Val Loss: 1.9669, F1 Micro: 0.5000, F1 Macro: 0.4928, Accuracy: 0.5000\n","Epoch 192, Train Loss: 0.6265, Val Loss: 2.0546, F1 Micro: 0.5312, F1 Macro: 0.5018, Accuracy: 0.5312\n","Epoch 193, Train Loss: 0.5646, Val Loss: 2.1580, F1 Micro: 0.5208, F1 Macro: 0.4939, Accuracy: 0.5208\n","Epoch 194, Train Loss: 0.6019, Val Loss: 2.1168, F1 Micro: 0.4479, F1 Macro: 0.4273, Accuracy: 0.4479\n","Epoch 195, Train Loss: 0.6314, Val Loss: 2.1868, F1 Micro: 0.5000, F1 Macro: 0.4790, Accuracy: 0.5000\n","Epoch 196, Train Loss: 0.5882, Val Loss: 2.0079, F1 Micro: 0.5208, F1 Macro: 0.4930, Accuracy: 0.5208\n","Epoch 197, Train Loss: 0.5651, Val Loss: 2.3779, F1 Micro: 0.4896, F1 Macro: 0.4597, Accuracy: 0.4896\n","Epoch 198, Train Loss: 0.5980, Val Loss: 2.1244, F1 Micro: 0.5208, F1 Macro: 0.4953, Accuracy: 0.5208\n","Epoch 199, Train Loss: 0.5923, Val Loss: 2.0381, F1 Micro: 0.5625, F1 Macro: 0.5263, Accuracy: 0.5625\n","Epoch 200, Train Loss: 0.6021, Val Loss: 1.9715, F1 Micro: 0.5417, F1 Macro: 0.5312, Accuracy: 0.5417\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.4680, Val Loss: 2.0487, F1 Micro: 0.1562, F1 Macro: 0.1362, Accuracy: 0.1562\n","Epoch 2, Train Loss: 2.6184, Val Loss: 2.0947, F1 Micro: 0.2917, F1 Macro: 0.2242, Accuracy: 0.2917\n","Epoch 3, Train Loss: 2.3431, Val Loss: 1.9363, F1 Micro: 0.1771, F1 Macro: 0.1403, Accuracy: 0.1771\n","Epoch 4, Train Loss: 2.0009, Val Loss: 1.7961, F1 Micro: 0.1979, F1 Macro: 0.1568, Accuracy: 0.1979\n","Epoch 5, Train Loss: 1.9338, Val Loss: 1.8250, F1 Micro: 0.2917, F1 Macro: 0.1975, Accuracy: 0.2917\n","Epoch 6, Train Loss: 1.8944, Val Loss: 1.8707, F1 Micro: 0.1875, F1 Macro: 0.1339, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.9439, Val Loss: 1.9373, F1 Micro: 0.2604, F1 Macro: 0.2039, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.8676, Val Loss: 1.7210, F1 Micro: 0.2396, F1 Macro: 0.2088, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.8413, Val Loss: 1.7323, F1 Micro: 0.2917, F1 Macro: 0.2353, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.7855, Val Loss: 1.7463, F1 Micro: 0.1979, F1 Macro: 0.1941, Accuracy: 0.1979\n","Epoch 11, Train Loss: 1.7692, Val Loss: 1.8596, F1 Micro: 0.2604, F1 Macro: 0.2127, Accuracy: 0.2604\n","Epoch 12, Train Loss: 1.8436, Val Loss: 1.6854, F1 Micro: 0.3125, F1 Macro: 0.2027, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.7439, Val Loss: 1.7777, F1 Micro: 0.1979, F1 Macro: 0.1445, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.7749, Val Loss: 1.7559, F1 Micro: 0.2812, F1 Macro: 0.2005, Accuracy: 0.2812\n","Epoch 15, Train Loss: 1.7194, Val Loss: 1.6709, F1 Micro: 0.2708, F1 Macro: 0.2008, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.7400, Val Loss: 1.7974, F1 Micro: 0.1667, F1 Macro: 0.1469, Accuracy: 0.1667\n","Epoch 17, Train Loss: 1.7796, Val Loss: 1.7047, F1 Micro: 0.3333, F1 Macro: 0.2924, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.7609, Val Loss: 1.6735, F1 Micro: 0.2812, F1 Macro: 0.1808, Accuracy: 0.2812\n","Epoch 19, Train Loss: 1.7239, Val Loss: 1.6940, F1 Micro: 0.2812, F1 Macro: 0.1853, Accuracy: 0.2812\n","Epoch 20, Train Loss: 1.7182, Val Loss: 1.6949, F1 Micro: 0.3021, F1 Macro: 0.2289, Accuracy: 0.3021\n","Epoch 21, Train Loss: 1.7291, Val Loss: 1.7448, F1 Micro: 0.3125, F1 Macro: 0.2095, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.7197, Val Loss: 1.7150, F1 Micro: 0.3542, F1 Macro: 0.2713, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.7425, Val Loss: 1.7116, F1 Micro: 0.2292, F1 Macro: 0.1881, Accuracy: 0.2292\n","Epoch 24, Train Loss: 1.7402, Val Loss: 1.7628, F1 Micro: 0.1979, F1 Macro: 0.1606, Accuracy: 0.1979\n","Epoch 25, Train Loss: 1.7350, Val Loss: 1.6529, F1 Micro: 0.3854, F1 Macro: 0.2753, Accuracy: 0.3854\n","Epoch 26, Train Loss: 1.7435, Val Loss: 1.6576, F1 Micro: 0.2292, F1 Macro: 0.2386, Accuracy: 0.2292\n","Epoch 27, Train Loss: 1.6841, Val Loss: 1.7702, F1 Micro: 0.2188, F1 Macro: 0.1757, Accuracy: 0.2188\n","Epoch 28, Train Loss: 1.7243, Val Loss: 1.6581, F1 Micro: 0.3229, F1 Macro: 0.2339, Accuracy: 0.3229\n","Epoch 29, Train Loss: 1.7139, Val Loss: 1.6177, F1 Micro: 0.4167, F1 Macro: 0.3751, Accuracy: 0.4167\n","Epoch 30, Train Loss: 1.6944, Val Loss: 1.6906, F1 Micro: 0.3750, F1 Macro: 0.2928, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.7311, Val Loss: 1.6746, F1 Micro: 0.3438, F1 Macro: 0.2926, Accuracy: 0.3438\n","Epoch 32, Train Loss: 1.6465, Val Loss: 1.7144, F1 Micro: 0.2812, F1 Macro: 0.2275, Accuracy: 0.2812\n","Epoch 33, Train Loss: 1.6889, Val Loss: 1.6113, F1 Micro: 0.3333, F1 Macro: 0.2743, Accuracy: 0.3333\n","Epoch 34, Train Loss: 1.6601, Val Loss: 1.5729, F1 Micro: 0.3958, F1 Macro: 0.3349, Accuracy: 0.3958\n","Epoch 35, Train Loss: 1.6069, Val Loss: 1.6445, F1 Micro: 0.3646, F1 Macro: 0.3690, Accuracy: 0.3646\n","Epoch 36, Train Loss: 1.6327, Val Loss: 1.5956, F1 Micro: 0.3125, F1 Macro: 0.2572, Accuracy: 0.3125\n","Epoch 37, Train Loss: 1.6498, Val Loss: 1.5713, F1 Micro: 0.4375, F1 Macro: 0.3513, Accuracy: 0.4375\n","Epoch 38, Train Loss: 1.6506, Val Loss: 1.6237, F1 Micro: 0.3438, F1 Macro: 0.3108, Accuracy: 0.3438\n","Epoch 39, Train Loss: 1.6659, Val Loss: 1.6520, F1 Micro: 0.4167, F1 Macro: 0.3718, Accuracy: 0.4167\n","Epoch 40, Train Loss: 1.6622, Val Loss: 1.6083, F1 Micro: 0.3854, F1 Macro: 0.3162, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.6235, Val Loss: 1.6936, F1 Micro: 0.2396, F1 Macro: 0.1946, Accuracy: 0.2396\n","Epoch 42, Train Loss: 1.6249, Val Loss: 1.6407, F1 Micro: 0.2500, F1 Macro: 0.2042, Accuracy: 0.2500\n","Epoch 43, Train Loss: 1.5638, Val Loss: 1.5040, F1 Micro: 0.4062, F1 Macro: 0.3114, Accuracy: 0.4062\n","Epoch 44, Train Loss: 1.5811, Val Loss: 1.5461, F1 Micro: 0.3958, F1 Macro: 0.3490, Accuracy: 0.3958\n","Epoch 45, Train Loss: 1.5452, Val Loss: 1.5589, F1 Micro: 0.3542, F1 Macro: 0.2909, Accuracy: 0.3542\n","Epoch 46, Train Loss: 1.6089, Val Loss: 1.5059, F1 Micro: 0.4792, F1 Macro: 0.3927, Accuracy: 0.4792\n","Epoch 47, Train Loss: 1.6055, Val Loss: 1.6364, F1 Micro: 0.3438, F1 Macro: 0.2953, Accuracy: 0.3438\n","Epoch 48, Train Loss: 1.5936, Val Loss: 1.5759, F1 Micro: 0.3438, F1 Macro: 0.2831, Accuracy: 0.3438\n","Epoch 49, Train Loss: 1.5816, Val Loss: 1.5478, F1 Micro: 0.4062, F1 Macro: 0.3854, Accuracy: 0.4062\n","Epoch 50, Train Loss: 1.5562, Val Loss: 1.5230, F1 Micro: 0.4062, F1 Macro: 0.3846, Accuracy: 0.4062\n","Epoch 51, Train Loss: 1.5684, Val Loss: 1.5199, F1 Micro: 0.3750, F1 Macro: 0.3376, Accuracy: 0.3750\n","Epoch 52, Train Loss: 1.5951, Val Loss: 1.5093, F1 Micro: 0.4271, F1 Macro: 0.3701, Accuracy: 0.4271\n","Epoch 53, Train Loss: 1.5298, Val Loss: 1.5402, F1 Micro: 0.3229, F1 Macro: 0.2690, Accuracy: 0.3229\n","Epoch 54, Train Loss: 1.5547, Val Loss: 1.4767, F1 Micro: 0.4062, F1 Macro: 0.3521, Accuracy: 0.4062\n","Epoch 55, Train Loss: 1.5238, Val Loss: 1.5966, F1 Micro: 0.3021, F1 Macro: 0.2389, Accuracy: 0.3021\n","Epoch 56, Train Loss: 1.5669, Val Loss: 1.5629, F1 Micro: 0.3854, F1 Macro: 0.3457, Accuracy: 0.3854\n","Epoch 57, Train Loss: 1.5329, Val Loss: 1.4957, F1 Micro: 0.4792, F1 Macro: 0.4202, Accuracy: 0.4792\n","Epoch 58, Train Loss: 1.5080, Val Loss: 1.4609, F1 Micro: 0.4479, F1 Macro: 0.4094, Accuracy: 0.4479\n","Epoch 59, Train Loss: 1.5360, Val Loss: 1.4973, F1 Micro: 0.4583, F1 Macro: 0.4010, Accuracy: 0.4583\n","Epoch 60, Train Loss: 1.5097, Val Loss: 1.5096, F1 Micro: 0.3958, F1 Macro: 0.3726, Accuracy: 0.3958\n","Epoch 61, Train Loss: 1.5139, Val Loss: 1.5877, F1 Micro: 0.3854, F1 Macro: 0.3639, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.4404, Val Loss: 1.4410, F1 Micro: 0.4688, F1 Macro: 0.4264, Accuracy: 0.4688\n","Epoch 63, Train Loss: 1.4532, Val Loss: 1.4351, F1 Micro: 0.4062, F1 Macro: 0.3695, Accuracy: 0.4062\n","Epoch 64, Train Loss: 1.5153, Val Loss: 1.5127, F1 Micro: 0.4167, F1 Macro: 0.3263, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.4647, Val Loss: 1.5527, F1 Micro: 0.3854, F1 Macro: 0.3626, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.4354, Val Loss: 1.5570, F1 Micro: 0.4792, F1 Macro: 0.4085, Accuracy: 0.4792\n","Epoch 67, Train Loss: 1.4358, Val Loss: 1.4965, F1 Micro: 0.4167, F1 Macro: 0.3692, Accuracy: 0.4167\n","Epoch 68, Train Loss: 1.4317, Val Loss: 1.5706, F1 Micro: 0.4479, F1 Macro: 0.3966, Accuracy: 0.4479\n","Epoch 69, Train Loss: 1.4516, Val Loss: 1.5786, F1 Micro: 0.4479, F1 Macro: 0.4217, Accuracy: 0.4479\n","Epoch 70, Train Loss: 1.4189, Val Loss: 1.4579, F1 Micro: 0.4792, F1 Macro: 0.4801, Accuracy: 0.4792\n","Epoch 71, Train Loss: 1.4103, Val Loss: 1.4681, F1 Micro: 0.4688, F1 Macro: 0.4639, Accuracy: 0.4688\n","Epoch 72, Train Loss: 1.4224, Val Loss: 1.4700, F1 Micro: 0.4896, F1 Macro: 0.4658, Accuracy: 0.4896\n","Epoch 73, Train Loss: 1.4175, Val Loss: 1.6380, F1 Micro: 0.3958, F1 Macro: 0.3389, Accuracy: 0.3958\n","Epoch 74, Train Loss: 1.3829, Val Loss: 1.4635, F1 Micro: 0.4479, F1 Macro: 0.4054, Accuracy: 0.4479\n","Epoch 75, Train Loss: 1.3524, Val Loss: 1.4270, F1 Micro: 0.4896, F1 Macro: 0.3936, Accuracy: 0.4896\n","Epoch 76, Train Loss: 1.3780, Val Loss: 1.6039, F1 Micro: 0.3958, F1 Macro: 0.3537, Accuracy: 0.3958\n","Epoch 77, Train Loss: 1.3434, Val Loss: 1.5477, F1 Micro: 0.5000, F1 Macro: 0.3993, Accuracy: 0.5000\n","Epoch 78, Train Loss: 1.3925, Val Loss: 1.5009, F1 Micro: 0.4375, F1 Macro: 0.3769, Accuracy: 0.4375\n","Epoch 79, Train Loss: 1.3043, Val Loss: 1.4246, F1 Micro: 0.5104, F1 Macro: 0.4781, Accuracy: 0.5104\n","Epoch 80, Train Loss: 1.3710, Val Loss: 1.4993, F1 Micro: 0.4688, F1 Macro: 0.3928, Accuracy: 0.4688\n","Epoch 81, Train Loss: 1.3540, Val Loss: 1.4325, F1 Micro: 0.5312, F1 Macro: 0.4996, Accuracy: 0.5312\n","Epoch 82, Train Loss: 1.4090, Val Loss: 1.5768, F1 Micro: 0.4688, F1 Macro: 0.4287, Accuracy: 0.4688\n","Epoch 83, Train Loss: 1.3730, Val Loss: 1.5475, F1 Micro: 0.3958, F1 Macro: 0.3145, Accuracy: 0.3958\n","Epoch 84, Train Loss: 1.3386, Val Loss: 1.5062, F1 Micro: 0.5208, F1 Macro: 0.4676, Accuracy: 0.5208\n","Epoch 85, Train Loss: 1.3128, Val Loss: 1.4925, F1 Micro: 0.4896, F1 Macro: 0.4563, Accuracy: 0.4896\n","Epoch 86, Train Loss: 1.3252, Val Loss: 1.4708, F1 Micro: 0.5104, F1 Macro: 0.4280, Accuracy: 0.5104\n","Epoch 87, Train Loss: 1.2846, Val Loss: 1.5484, F1 Micro: 0.4375, F1 Macro: 0.3611, Accuracy: 0.4375\n","Epoch 88, Train Loss: 1.2866, Val Loss: 1.5535, F1 Micro: 0.4375, F1 Macro: 0.4110, Accuracy: 0.4375\n","Epoch 89, Train Loss: 1.2646, Val Loss: 1.6156, F1 Micro: 0.3958, F1 Macro: 0.3619, Accuracy: 0.3958\n","Epoch 90, Train Loss: 1.2912, Val Loss: 1.6049, F1 Micro: 0.4062, F1 Macro: 0.3526, Accuracy: 0.4062\n","Epoch 91, Train Loss: 1.2726, Val Loss: 1.5321, F1 Micro: 0.4375, F1 Macro: 0.3780, Accuracy: 0.4375\n","Epoch 92, Train Loss: 1.2577, Val Loss: 1.5512, F1 Micro: 0.4583, F1 Macro: 0.4402, Accuracy: 0.4583\n","Epoch 93, Train Loss: 1.1807, Val Loss: 1.4469, F1 Micro: 0.4792, F1 Macro: 0.4921, Accuracy: 0.4792\n","Epoch 94, Train Loss: 1.2828, Val Loss: 1.5437, F1 Micro: 0.3958, F1 Macro: 0.3899, Accuracy: 0.3958\n","Epoch 95, Train Loss: 1.3038, Val Loss: 1.5768, F1 Micro: 0.3646, F1 Macro: 0.3245, Accuracy: 0.3646\n","Epoch 96, Train Loss: 1.2800, Val Loss: 1.5282, F1 Micro: 0.5208, F1 Macro: 0.4903, Accuracy: 0.5208\n","Epoch 97, Train Loss: 1.2532, Val Loss: 1.5366, F1 Micro: 0.4688, F1 Macro: 0.4460, Accuracy: 0.4688\n","Epoch 98, Train Loss: 1.2260, Val Loss: 1.4819, F1 Micro: 0.5312, F1 Macro: 0.5139, Accuracy: 0.5312\n","Epoch 99, Train Loss: 1.1981, Val Loss: 1.4708, F1 Micro: 0.4792, F1 Macro: 0.4097, Accuracy: 0.4792\n","Epoch 100, Train Loss: 1.1862, Val Loss: 1.4668, F1 Micro: 0.5104, F1 Macro: 0.4788, Accuracy: 0.5104\n","Epoch 101, Train Loss: 1.2361, Val Loss: 1.4597, F1 Micro: 0.5208, F1 Macro: 0.4893, Accuracy: 0.5208\n","Epoch 102, Train Loss: 1.1903, Val Loss: 1.4761, F1 Micro: 0.4896, F1 Macro: 0.4707, Accuracy: 0.4896\n","Epoch 103, Train Loss: 1.2045, Val Loss: 1.5297, F1 Micro: 0.4167, F1 Macro: 0.3889, Accuracy: 0.4167\n","Epoch 104, Train Loss: 1.2103, Val Loss: 1.5382, F1 Micro: 0.4062, F1 Macro: 0.3787, Accuracy: 0.4062\n","Epoch 105, Train Loss: 1.1725, Val Loss: 1.4563, F1 Micro: 0.4896, F1 Macro: 0.4773, Accuracy: 0.4896\n","Epoch 106, Train Loss: 1.0944, Val Loss: 1.4807, F1 Micro: 0.5521, F1 Macro: 0.5336, Accuracy: 0.5521\n","Epoch 107, Train Loss: 1.1626, Val Loss: 1.5381, F1 Micro: 0.4688, F1 Macro: 0.4594, Accuracy: 0.4688\n","Epoch 108, Train Loss: 1.1779, Val Loss: 1.5520, F1 Micro: 0.4583, F1 Macro: 0.4313, Accuracy: 0.4583\n","Epoch 109, Train Loss: 1.1467, Val Loss: 1.5816, F1 Micro: 0.4792, F1 Macro: 0.4653, Accuracy: 0.4792\n","Epoch 110, Train Loss: 1.1156, Val Loss: 1.6018, F1 Micro: 0.4583, F1 Macro: 0.4571, Accuracy: 0.4583\n","Epoch 111, Train Loss: 1.1910, Val Loss: 1.4908, F1 Micro: 0.5208, F1 Macro: 0.4814, Accuracy: 0.5208\n","Epoch 112, Train Loss: 1.1006, Val Loss: 1.5924, F1 Micro: 0.5104, F1 Macro: 0.4769, Accuracy: 0.5104\n","Epoch 113, Train Loss: 1.0498, Val Loss: 1.4930, F1 Micro: 0.4896, F1 Macro: 0.4522, Accuracy: 0.4896\n","Epoch 114, Train Loss: 1.0849, Val Loss: 1.6491, F1 Micro: 0.4271, F1 Macro: 0.4278, Accuracy: 0.4271\n","Epoch 115, Train Loss: 1.1069, Val Loss: 1.4784, F1 Micro: 0.5417, F1 Macro: 0.4928, Accuracy: 0.5417\n","Epoch 116, Train Loss: 1.1173, Val Loss: 1.5130, F1 Micro: 0.5104, F1 Macro: 0.5063, Accuracy: 0.5104\n","Epoch 117, Train Loss: 1.0950, Val Loss: 1.5021, F1 Micro: 0.4896, F1 Macro: 0.4450, Accuracy: 0.4896\n","Epoch 118, Train Loss: 1.0487, Val Loss: 1.4858, F1 Micro: 0.5104, F1 Macro: 0.4784, Accuracy: 0.5104\n","Epoch 119, Train Loss: 1.0983, Val Loss: 1.4656, F1 Micro: 0.5417, F1 Macro: 0.5247, Accuracy: 0.5417\n","Epoch 120, Train Loss: 1.0337, Val Loss: 1.5590, F1 Micro: 0.5312, F1 Macro: 0.5086, Accuracy: 0.5312\n","Epoch 121, Train Loss: 1.0278, Val Loss: 1.5009, F1 Micro: 0.5208, F1 Macro: 0.4988, Accuracy: 0.5208\n","Epoch 122, Train Loss: 1.0659, Val Loss: 1.5483, F1 Micro: 0.4688, F1 Macro: 0.4438, Accuracy: 0.4688\n","Epoch 123, Train Loss: 1.0909, Val Loss: 1.4835, F1 Micro: 0.5000, F1 Macro: 0.4652, Accuracy: 0.5000\n","Epoch 124, Train Loss: 1.0915, Val Loss: 1.4861, F1 Micro: 0.5104, F1 Macro: 0.4528, Accuracy: 0.5104\n","Epoch 125, Train Loss: 1.0730, Val Loss: 1.4779, F1 Micro: 0.4896, F1 Macro: 0.4806, Accuracy: 0.4896\n","Epoch 126, Train Loss: 1.0184, Val Loss: 1.4081, F1 Micro: 0.5625, F1 Macro: 0.5143, Accuracy: 0.5625\n","Epoch 127, Train Loss: 1.0864, Val Loss: 1.6675, F1 Micro: 0.5208, F1 Macro: 0.4958, Accuracy: 0.5208\n","Epoch 128, Train Loss: 1.0462, Val Loss: 1.4775, F1 Micro: 0.5417, F1 Macro: 0.5084, Accuracy: 0.5417\n","Epoch 129, Train Loss: 0.9918, Val Loss: 1.5149, F1 Micro: 0.5000, F1 Macro: 0.4633, Accuracy: 0.5000\n","Epoch 130, Train Loss: 1.0576, Val Loss: 1.4859, F1 Micro: 0.5104, F1 Macro: 0.4776, Accuracy: 0.5104\n","Epoch 131, Train Loss: 1.0239, Val Loss: 1.4954, F1 Micro: 0.5417, F1 Macro: 0.5155, Accuracy: 0.5417\n","Epoch 132, Train Loss: 1.0818, Val Loss: 1.5490, F1 Micro: 0.4896, F1 Macro: 0.4648, Accuracy: 0.4896\n","Epoch 133, Train Loss: 0.9589, Val Loss: 1.4145, F1 Micro: 0.5417, F1 Macro: 0.5053, Accuracy: 0.5417\n","Epoch 134, Train Loss: 0.9380, Val Loss: 1.5607, F1 Micro: 0.5521, F1 Macro: 0.5244, Accuracy: 0.5521\n","Epoch 135, Train Loss: 0.9660, Val Loss: 1.5527, F1 Micro: 0.5312, F1 Macro: 0.4918, Accuracy: 0.5312\n","Epoch 136, Train Loss: 0.9568, Val Loss: 1.7424, F1 Micro: 0.4896, F1 Macro: 0.5071, Accuracy: 0.4896\n","Epoch 137, Train Loss: 0.9906, Val Loss: 1.5737, F1 Micro: 0.5521, F1 Macro: 0.5512, Accuracy: 0.5521\n","Epoch 138, Train Loss: 0.9350, Val Loss: 1.5775, F1 Micro: 0.5625, F1 Macro: 0.5342, Accuracy: 0.5625\n","Epoch 139, Train Loss: 0.9988, Val Loss: 1.5603, F1 Micro: 0.5312, F1 Macro: 0.5035, Accuracy: 0.5312\n","Epoch 140, Train Loss: 0.9660, Val Loss: 1.4674, F1 Micro: 0.5417, F1 Macro: 0.5320, Accuracy: 0.5417\n","Epoch 141, Train Loss: 1.0022, Val Loss: 2.0057, F1 Micro: 0.3854, F1 Macro: 0.3267, Accuracy: 0.3854\n","Epoch 142, Train Loss: 0.9664, Val Loss: 1.4328, F1 Micro: 0.5521, F1 Macro: 0.4979, Accuracy: 0.5521\n","Epoch 143, Train Loss: 0.9437, Val Loss: 1.6456, F1 Micro: 0.4583, F1 Macro: 0.4211, Accuracy: 0.4583\n","Epoch 144, Train Loss: 0.8824, Val Loss: 1.4566, F1 Micro: 0.5417, F1 Macro: 0.5379, Accuracy: 0.5417\n","Epoch 145, Train Loss: 0.9222, Val Loss: 1.5560, F1 Micro: 0.5312, F1 Macro: 0.5077, Accuracy: 0.5312\n","Epoch 146, Train Loss: 0.8957, Val Loss: 1.5027, F1 Micro: 0.5521, F1 Macro: 0.5307, Accuracy: 0.5521\n","Epoch 147, Train Loss: 0.9084, Val Loss: 1.6524, F1 Micro: 0.5000, F1 Macro: 0.4852, Accuracy: 0.5000\n","Epoch 148, Train Loss: 0.8687, Val Loss: 1.6290, F1 Micro: 0.5625, F1 Macro: 0.5456, Accuracy: 0.5625\n","Epoch 149, Train Loss: 0.9133, Val Loss: 1.6169, F1 Micro: 0.5104, F1 Macro: 0.5152, Accuracy: 0.5104\n","Epoch 150, Train Loss: 0.8563, Val Loss: 1.5546, F1 Micro: 0.5208, F1 Macro: 0.4794, Accuracy: 0.5208\n","Epoch 151, Train Loss: 0.8627, Val Loss: 1.6115, F1 Micro: 0.5521, F1 Macro: 0.5216, Accuracy: 0.5521\n","Epoch 152, Train Loss: 0.8129, Val Loss: 1.5818, F1 Micro: 0.5833, F1 Macro: 0.5692, Accuracy: 0.5833\n","Epoch 153, Train Loss: 0.8460, Val Loss: 1.5945, F1 Micro: 0.5000, F1 Macro: 0.4935, Accuracy: 0.5000\n","Epoch 154, Train Loss: 0.8245, Val Loss: 1.6316, F1 Micro: 0.5104, F1 Macro: 0.4895, Accuracy: 0.5104\n","Epoch 155, Train Loss: 0.8660, Val Loss: 1.6090, F1 Micro: 0.5104, F1 Macro: 0.4664, Accuracy: 0.5104\n","Epoch 156, Train Loss: 0.8556, Val Loss: 1.7567, F1 Micro: 0.5208, F1 Macro: 0.4995, Accuracy: 0.5208\n","Epoch 157, Train Loss: 0.8656, Val Loss: 1.6980, F1 Micro: 0.5104, F1 Macro: 0.4542, Accuracy: 0.5104\n","Epoch 158, Train Loss: 0.8668, Val Loss: 1.6700, F1 Micro: 0.5729, F1 Macro: 0.5320, Accuracy: 0.5729\n","Epoch 159, Train Loss: 0.8110, Val Loss: 1.6385, F1 Micro: 0.5208, F1 Macro: 0.5067, Accuracy: 0.5208\n","Epoch 160, Train Loss: 0.7803, Val Loss: 1.6305, F1 Micro: 0.5000, F1 Macro: 0.4860, Accuracy: 0.5000\n","Epoch 161, Train Loss: 0.8587, Val Loss: 1.6502, F1 Micro: 0.4688, F1 Macro: 0.4474, Accuracy: 0.4688\n","Epoch 162, Train Loss: 0.8636, Val Loss: 1.6106, F1 Micro: 0.5938, F1 Macro: 0.5814, Accuracy: 0.5938\n","Epoch 163, Train Loss: 0.8781, Val Loss: 1.6491, F1 Micro: 0.5833, F1 Macro: 0.5648, Accuracy: 0.5833\n","Epoch 164, Train Loss: 0.7785, Val Loss: 1.5650, F1 Micro: 0.5208, F1 Macro: 0.4878, Accuracy: 0.5208\n","Epoch 165, Train Loss: 0.7887, Val Loss: 1.6711, F1 Micro: 0.4896, F1 Macro: 0.4631, Accuracy: 0.4896\n","Epoch 166, Train Loss: 0.8402, Val Loss: 1.5545, F1 Micro: 0.5625, F1 Macro: 0.5380, Accuracy: 0.5625\n","Epoch 167, Train Loss: 0.8123, Val Loss: 1.6096, F1 Micro: 0.5625, F1 Macro: 0.5260, Accuracy: 0.5625\n","Epoch 168, Train Loss: 0.8218, Val Loss: 1.7461, F1 Micro: 0.6354, F1 Macro: 0.6301, Accuracy: 0.6354\n","Epoch 169, Train Loss: 0.7204, Val Loss: 1.7402, F1 Micro: 0.5312, F1 Macro: 0.5159, Accuracy: 0.5312\n","Epoch 170, Train Loss: 0.7626, Val Loss: 1.6837, F1 Micro: 0.5625, F1 Macro: 0.5461, Accuracy: 0.5625\n","Epoch 171, Train Loss: 0.7269, Val Loss: 1.8271, F1 Micro: 0.5729, F1 Macro: 0.5541, Accuracy: 0.5729\n","Epoch 172, Train Loss: 0.7125, Val Loss: 1.7799, F1 Micro: 0.5625, F1 Macro: 0.5461, Accuracy: 0.5625\n","Epoch 173, Train Loss: 0.7422, Val Loss: 1.7609, F1 Micro: 0.5729, F1 Macro: 0.5553, Accuracy: 0.5729\n","Epoch 174, Train Loss: 0.7428, Val Loss: 1.7294, F1 Micro: 0.5833, F1 Macro: 0.5671, Accuracy: 0.5833\n","Epoch 175, Train Loss: 0.7966, Val Loss: 1.8433, F1 Micro: 0.5104, F1 Macro: 0.4798, Accuracy: 0.5104\n","Epoch 176, Train Loss: 0.8212, Val Loss: 1.6579, F1 Micro: 0.5833, F1 Macro: 0.5444, Accuracy: 0.5833\n","Epoch 177, Train Loss: 0.7870, Val Loss: 1.7287, F1 Micro: 0.5521, F1 Macro: 0.5271, Accuracy: 0.5521\n","Epoch 178, Train Loss: 0.7259, Val Loss: 1.8493, F1 Micro: 0.4896, F1 Macro: 0.4364, Accuracy: 0.4896\n","Epoch 179, Train Loss: 0.7474, Val Loss: 1.7845, F1 Micro: 0.6042, F1 Macro: 0.5777, Accuracy: 0.6042\n","Epoch 180, Train Loss: 0.7217, Val Loss: 2.0071, F1 Micro: 0.5208, F1 Macro: 0.4742, Accuracy: 0.5208\n","Epoch 181, Train Loss: 0.7726, Val Loss: 1.8203, F1 Micro: 0.6042, F1 Macro: 0.5934, Accuracy: 0.6042\n","Epoch 182, Train Loss: 0.6798, Val Loss: 1.7914, F1 Micro: 0.5521, F1 Macro: 0.5187, Accuracy: 0.5521\n","Epoch 183, Train Loss: 0.7269, Val Loss: 1.8076, F1 Micro: 0.5312, F1 Macro: 0.4964, Accuracy: 0.5312\n","Epoch 184, Train Loss: 0.7547, Val Loss: 1.7561, F1 Micro: 0.6042, F1 Macro: 0.5685, Accuracy: 0.6042\n","Epoch 185, Train Loss: 0.6737, Val Loss: 1.9995, F1 Micro: 0.5729, F1 Macro: 0.5212, Accuracy: 0.5729\n","Epoch 186, Train Loss: 0.7943, Val Loss: 1.7619, F1 Micro: 0.5833, F1 Macro: 0.5731, Accuracy: 0.5833\n","Epoch 187, Train Loss: 0.7223, Val Loss: 1.7338, F1 Micro: 0.5521, F1 Macro: 0.5462, Accuracy: 0.5521\n","Epoch 188, Train Loss: 0.6349, Val Loss: 1.8495, F1 Micro: 0.5938, F1 Macro: 0.5583, Accuracy: 0.5938\n","Epoch 189, Train Loss: 0.6349, Val Loss: 1.8447, F1 Micro: 0.6042, F1 Macro: 0.5815, Accuracy: 0.6042\n","Epoch 190, Train Loss: 0.6288, Val Loss: 1.8770, F1 Micro: 0.5938, F1 Macro: 0.5614, Accuracy: 0.5938\n","Epoch 191, Train Loss: 0.6298, Val Loss: 1.9426, F1 Micro: 0.6042, F1 Macro: 0.5687, Accuracy: 0.6042\n","Epoch 192, Train Loss: 0.7338, Val Loss: 1.8027, F1 Micro: 0.5938, F1 Macro: 0.5793, Accuracy: 0.5938\n","Epoch 193, Train Loss: 0.6756, Val Loss: 1.8199, F1 Micro: 0.6146, F1 Macro: 0.5854, Accuracy: 0.6146\n","Epoch 194, Train Loss: 0.6323, Val Loss: 1.8435, F1 Micro: 0.6042, F1 Macro: 0.5681, Accuracy: 0.6042\n","Epoch 195, Train Loss: 0.6351, Val Loss: 1.7950, F1 Micro: 0.5521, F1 Macro: 0.5290, Accuracy: 0.5521\n","Epoch 196, Train Loss: 0.6433, Val Loss: 1.8184, F1 Micro: 0.6042, F1 Macro: 0.5696, Accuracy: 0.6042\n","Epoch 197, Train Loss: 0.6206, Val Loss: 1.8244, F1 Micro: 0.6146, F1 Macro: 0.5897, Accuracy: 0.6146\n","Epoch 198, Train Loss: 0.6258, Val Loss: 1.7915, F1 Micro: 0.6146, F1 Macro: 0.5811, Accuracy: 0.6146\n","Epoch 199, Train Loss: 0.6451, Val Loss: 1.8363, F1 Micro: 0.6042, F1 Macro: 0.5842, Accuracy: 0.6042\n","Epoch 200, Train Loss: 0.6870, Val Loss: 1.8508, F1 Micro: 0.6042, F1 Macro: 0.5850, Accuracy: 0.6042\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.2221, Val Loss: 1.9003, F1 Micro: 0.2396, F1 Macro: 0.1357, Accuracy: 0.2396\n","Epoch 2, Train Loss: 2.2838, Val Loss: 2.0623, F1 Micro: 0.2188, F1 Macro: 0.1770, Accuracy: 0.2188\n","Epoch 3, Train Loss: 2.3050, Val Loss: 2.2441, F1 Micro: 0.1667, F1 Macro: 0.1427, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.8901, Val Loss: 1.8127, F1 Micro: 0.2917, F1 Macro: 0.1951, Accuracy: 0.2917\n","Epoch 5, Train Loss: 1.8690, Val Loss: 1.8551, F1 Micro: 0.1875, F1 Macro: 0.1266, Accuracy: 0.1875\n","Epoch 6, Train Loss: 1.7787, Val Loss: 1.9372, F1 Micro: 0.1875, F1 Macro: 0.1215, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.8734, Val Loss: 1.9918, F1 Micro: 0.2396, F1 Macro: 0.1381, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.7921, Val Loss: 1.8845, F1 Micro: 0.2500, F1 Macro: 0.1832, Accuracy: 0.2500\n","Epoch 9, Train Loss: 1.7208, Val Loss: 1.8370, F1 Micro: 0.1979, F1 Macro: 0.1272, Accuracy: 0.1979\n","Epoch 10, Train Loss: 1.7492, Val Loss: 1.8631, F1 Micro: 0.2188, F1 Macro: 0.1399, Accuracy: 0.2188\n","Epoch 11, Train Loss: 1.7065, Val Loss: 1.8833, F1 Micro: 0.1875, F1 Macro: 0.1171, Accuracy: 0.1875\n","Epoch 12, Train Loss: 1.7318, Val Loss: 1.8693, F1 Micro: 0.2292, F1 Macro: 0.1625, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.7411, Val Loss: 1.7955, F1 Micro: 0.3021, F1 Macro: 0.1935, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.7331, Val Loss: 1.8251, F1 Micro: 0.2708, F1 Macro: 0.1569, Accuracy: 0.2708\n","Epoch 15, Train Loss: 1.6918, Val Loss: 1.8437, F1 Micro: 0.2708, F1 Macro: 0.2170, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.7111, Val Loss: 2.0231, F1 Micro: 0.2188, F1 Macro: 0.1301, Accuracy: 0.2188\n","Epoch 17, Train Loss: 1.7091, Val Loss: 1.7599, F1 Micro: 0.3229, F1 Macro: 0.2249, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.6996, Val Loss: 1.7684, F1 Micro: 0.3125, F1 Macro: 0.2303, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.6701, Val Loss: 1.8945, F1 Micro: 0.2500, F1 Macro: 0.2097, Accuracy: 0.2500\n","Epoch 20, Train Loss: 1.6874, Val Loss: 1.8642, F1 Micro: 0.1667, F1 Macro: 0.1336, Accuracy: 0.1667\n","Epoch 21, Train Loss: 1.6833, Val Loss: 1.7535, F1 Micro: 0.3125, F1 Macro: 0.2537, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.6726, Val Loss: 1.8562, F1 Micro: 0.2812, F1 Macro: 0.2475, Accuracy: 0.2812\n","Epoch 23, Train Loss: 1.6789, Val Loss: 1.8881, F1 Micro: 0.2292, F1 Macro: 0.1712, Accuracy: 0.2292\n","Epoch 24, Train Loss: 1.6337, Val Loss: 1.8666, F1 Micro: 0.2083, F1 Macro: 0.1832, Accuracy: 0.2083\n","Epoch 25, Train Loss: 1.6547, Val Loss: 1.8737, F1 Micro: 0.1979, F1 Macro: 0.1409, Accuracy: 0.1979\n","Epoch 26, Train Loss: 1.6453, Val Loss: 1.7861, F1 Micro: 0.3021, F1 Macro: 0.2169, Accuracy: 0.3021\n","Epoch 27, Train Loss: 1.5879, Val Loss: 1.8587, F1 Micro: 0.2604, F1 Macro: 0.1791, Accuracy: 0.2604\n","Epoch 28, Train Loss: 1.6079, Val Loss: 1.8580, F1 Micro: 0.3021, F1 Macro: 0.2729, Accuracy: 0.3021\n","Epoch 29, Train Loss: 1.6185, Val Loss: 2.0161, F1 Micro: 0.2396, F1 Macro: 0.1841, Accuracy: 0.2396\n","Epoch 30, Train Loss: 1.6747, Val Loss: 1.7410, F1 Micro: 0.3229, F1 Macro: 0.3192, Accuracy: 0.3229\n","Epoch 31, Train Loss: 1.6227, Val Loss: 1.6800, F1 Micro: 0.3542, F1 Macro: 0.3029, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.6253, Val Loss: 1.8753, F1 Micro: 0.3021, F1 Macro: 0.2357, Accuracy: 0.3021\n","Epoch 33, Train Loss: 1.6840, Val Loss: 1.7556, F1 Micro: 0.3125, F1 Macro: 0.2993, Accuracy: 0.3125\n","Epoch 34, Train Loss: 1.5906, Val Loss: 1.7416, F1 Micro: 0.3229, F1 Macro: 0.2904, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.6169, Val Loss: 1.6896, F1 Micro: 0.3750, F1 Macro: 0.3632, Accuracy: 0.3750\n","Epoch 36, Train Loss: 1.5504, Val Loss: 1.7622, F1 Micro: 0.3438, F1 Macro: 0.3126, Accuracy: 0.3438\n","Epoch 37, Train Loss: 1.5759, Val Loss: 1.6765, F1 Micro: 0.3958, F1 Macro: 0.3322, Accuracy: 0.3958\n","Epoch 38, Train Loss: 1.5559, Val Loss: 1.6315, F1 Micro: 0.3958, F1 Macro: 0.3768, Accuracy: 0.3958\n","Epoch 39, Train Loss: 1.5367, Val Loss: 1.7624, F1 Micro: 0.3125, F1 Macro: 0.2432, Accuracy: 0.3125\n","Epoch 40, Train Loss: 1.5654, Val Loss: 1.8299, F1 Micro: 0.2917, F1 Macro: 0.2793, Accuracy: 0.2917\n","Epoch 41, Train Loss: 1.5597, Val Loss: 1.6745, F1 Micro: 0.4062, F1 Macro: 0.3398, Accuracy: 0.4062\n","Epoch 42, Train Loss: 1.5636, Val Loss: 1.7772, F1 Micro: 0.3021, F1 Macro: 0.2390, Accuracy: 0.3021\n","Epoch 43, Train Loss: 1.4890, Val Loss: 1.6710, F1 Micro: 0.3646, F1 Macro: 0.3056, Accuracy: 0.3646\n","Epoch 44, Train Loss: 1.5562, Val Loss: 1.7164, F1 Micro: 0.3542, F1 Macro: 0.3018, Accuracy: 0.3542\n","Epoch 45, Train Loss: 1.5145, Val Loss: 1.6699, F1 Micro: 0.4167, F1 Macro: 0.3782, Accuracy: 0.4167\n","Epoch 46, Train Loss: 1.4643, Val Loss: 1.7760, F1 Micro: 0.3021, F1 Macro: 0.2675, Accuracy: 0.3021\n","Epoch 47, Train Loss: 1.5607, Val Loss: 1.7264, F1 Micro: 0.2917, F1 Macro: 0.2725, Accuracy: 0.2917\n","Epoch 48, Train Loss: 1.5172, Val Loss: 1.7020, F1 Micro: 0.3750, F1 Macro: 0.3624, Accuracy: 0.3750\n","Epoch 49, Train Loss: 1.5170, Val Loss: 1.6178, F1 Micro: 0.4062, F1 Macro: 0.3558, Accuracy: 0.4062\n","Epoch 50, Train Loss: 1.5078, Val Loss: 1.6578, F1 Micro: 0.4062, F1 Macro: 0.3752, Accuracy: 0.4062\n","Epoch 51, Train Loss: 1.5300, Val Loss: 1.8706, F1 Micro: 0.3750, F1 Macro: 0.3467, Accuracy: 0.3750\n","Epoch 52, Train Loss: 1.4892, Val Loss: 1.6105, F1 Micro: 0.3854, F1 Macro: 0.3612, Accuracy: 0.3854\n","Epoch 53, Train Loss: 1.4778, Val Loss: 1.7525, F1 Micro: 0.3229, F1 Macro: 0.3065, Accuracy: 0.3229\n","Epoch 54, Train Loss: 1.4287, Val Loss: 1.6458, F1 Micro: 0.3542, F1 Macro: 0.3312, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.4079, Val Loss: 1.5969, F1 Micro: 0.3958, F1 Macro: 0.3842, Accuracy: 0.3958\n","Epoch 56, Train Loss: 1.4517, Val Loss: 1.5981, F1 Micro: 0.4688, F1 Macro: 0.4234, Accuracy: 0.4688\n","Epoch 57, Train Loss: 1.4627, Val Loss: 1.6602, F1 Micro: 0.3542, F1 Macro: 0.3069, Accuracy: 0.3542\n","Epoch 58, Train Loss: 1.4066, Val Loss: 1.6824, F1 Micro: 0.3750, F1 Macro: 0.2847, Accuracy: 0.3750\n","Epoch 59, Train Loss: 1.4734, Val Loss: 1.6513, F1 Micro: 0.3542, F1 Macro: 0.3236, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.3952, Val Loss: 1.5943, F1 Micro: 0.3646, F1 Macro: 0.3230, Accuracy: 0.3646\n","Epoch 61, Train Loss: 1.4123, Val Loss: 1.6528, F1 Micro: 0.4167, F1 Macro: 0.3745, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.4115, Val Loss: 1.5844, F1 Micro: 0.4062, F1 Macro: 0.3895, Accuracy: 0.4062\n","Epoch 63, Train Loss: 1.3916, Val Loss: 1.6302, F1 Micro: 0.3958, F1 Macro: 0.3874, Accuracy: 0.3958\n","Epoch 64, Train Loss: 1.3849, Val Loss: 1.6446, F1 Micro: 0.4167, F1 Macro: 0.4031, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.3765, Val Loss: 1.7692, F1 Micro: 0.3646, F1 Macro: 0.2336, Accuracy: 0.3646\n","Epoch 66, Train Loss: 1.4205, Val Loss: 1.6980, F1 Micro: 0.3542, F1 Macro: 0.3213, Accuracy: 0.3542\n","Epoch 67, Train Loss: 1.3956, Val Loss: 1.6585, F1 Micro: 0.3438, F1 Macro: 0.3272, Accuracy: 0.3438\n","Epoch 68, Train Loss: 1.3751, Val Loss: 1.6251, F1 Micro: 0.3854, F1 Macro: 0.3731, Accuracy: 0.3854\n","Epoch 69, Train Loss: 1.3751, Val Loss: 1.6135, F1 Micro: 0.3958, F1 Macro: 0.3667, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.3640, Val Loss: 1.6606, F1 Micro: 0.3438, F1 Macro: 0.3265, Accuracy: 0.3438\n","Epoch 71, Train Loss: 1.4019, Val Loss: 1.5326, F1 Micro: 0.5521, F1 Macro: 0.5282, Accuracy: 0.5521\n","Epoch 72, Train Loss: 1.3661, Val Loss: 1.6369, F1 Micro: 0.4167, F1 Macro: 0.4051, Accuracy: 0.4167\n","Epoch 73, Train Loss: 1.3197, Val Loss: 1.6323, F1 Micro: 0.3958, F1 Macro: 0.3810, Accuracy: 0.3958\n","Epoch 74, Train Loss: 1.2891, Val Loss: 1.6227, F1 Micro: 0.4062, F1 Macro: 0.4077, Accuracy: 0.4062\n","Epoch 75, Train Loss: 1.3264, Val Loss: 1.6455, F1 Micro: 0.3854, F1 Macro: 0.3664, Accuracy: 0.3854\n","Epoch 76, Train Loss: 1.3036, Val Loss: 1.6946, F1 Micro: 0.4167, F1 Macro: 0.4105, Accuracy: 0.4167\n","Epoch 77, Train Loss: 1.3140, Val Loss: 1.7620, F1 Micro: 0.3750, F1 Macro: 0.3485, Accuracy: 0.3750\n","Epoch 78, Train Loss: 1.3521, Val Loss: 1.6606, F1 Micro: 0.3646, F1 Macro: 0.3039, Accuracy: 0.3646\n","Epoch 79, Train Loss: 1.2919, Val Loss: 1.6152, F1 Micro: 0.4583, F1 Macro: 0.4259, Accuracy: 0.4583\n","Epoch 80, Train Loss: 1.2659, Val Loss: 1.6399, F1 Micro: 0.4167, F1 Macro: 0.3922, Accuracy: 0.4167\n","Epoch 81, Train Loss: 1.2679, Val Loss: 1.6366, F1 Micro: 0.4271, F1 Macro: 0.4151, Accuracy: 0.4271\n","Epoch 82, Train Loss: 1.2470, Val Loss: 1.5055, F1 Micro: 0.4583, F1 Macro: 0.4397, Accuracy: 0.4583\n","Epoch 83, Train Loss: 1.2670, Val Loss: 1.5873, F1 Micro: 0.4688, F1 Macro: 0.4196, Accuracy: 0.4688\n","Epoch 84, Train Loss: 1.3004, Val Loss: 1.6162, F1 Micro: 0.4375, F1 Macro: 0.4077, Accuracy: 0.4375\n","Epoch 85, Train Loss: 1.2245, Val Loss: 1.6412, F1 Micro: 0.4271, F1 Macro: 0.3648, Accuracy: 0.4271\n","Epoch 86, Train Loss: 1.2741, Val Loss: 1.5850, F1 Micro: 0.4688, F1 Macro: 0.4310, Accuracy: 0.4688\n","Epoch 87, Train Loss: 1.2016, Val Loss: 1.6730, F1 Micro: 0.4479, F1 Macro: 0.4372, Accuracy: 0.4479\n","Epoch 88, Train Loss: 1.1756, Val Loss: 1.5314, F1 Micro: 0.4688, F1 Macro: 0.4395, Accuracy: 0.4688\n","Epoch 89, Train Loss: 1.1790, Val Loss: 1.5810, F1 Micro: 0.4792, F1 Macro: 0.4304, Accuracy: 0.4792\n","Epoch 90, Train Loss: 1.2186, Val Loss: 1.6344, F1 Micro: 0.3958, F1 Macro: 0.3389, Accuracy: 0.3958\n","Epoch 91, Train Loss: 1.2148, Val Loss: 1.6331, F1 Micro: 0.4479, F1 Macro: 0.4416, Accuracy: 0.4479\n","Epoch 92, Train Loss: 1.1691, Val Loss: 1.5270, F1 Micro: 0.4375, F1 Macro: 0.3864, Accuracy: 0.4375\n","Epoch 93, Train Loss: 1.1857, Val Loss: 1.5974, F1 Micro: 0.5000, F1 Macro: 0.4378, Accuracy: 0.5000\n","Epoch 94, Train Loss: 1.2059, Val Loss: 1.6015, F1 Micro: 0.4583, F1 Macro: 0.4347, Accuracy: 0.4583\n","Epoch 95, Train Loss: 1.1509, Val Loss: 1.5618, F1 Micro: 0.4792, F1 Macro: 0.4282, Accuracy: 0.4792\n","Epoch 96, Train Loss: 1.2713, Val Loss: 1.7071, F1 Micro: 0.4271, F1 Macro: 0.4019, Accuracy: 0.4271\n","Epoch 97, Train Loss: 1.1513, Val Loss: 1.5548, F1 Micro: 0.4792, F1 Macro: 0.4482, Accuracy: 0.4792\n","Epoch 98, Train Loss: 1.1671, Val Loss: 1.5735, F1 Micro: 0.4896, F1 Macro: 0.4560, Accuracy: 0.4896\n","Epoch 99, Train Loss: 1.1328, Val Loss: 1.5965, F1 Micro: 0.4167, F1 Macro: 0.3989, Accuracy: 0.4167\n","Epoch 100, Train Loss: 1.1234, Val Loss: 1.6537, F1 Micro: 0.4167, F1 Macro: 0.3853, Accuracy: 0.4167\n","Epoch 101, Train Loss: 1.1671, Val Loss: 1.6349, F1 Micro: 0.4792, F1 Macro: 0.4610, Accuracy: 0.4792\n","Epoch 102, Train Loss: 1.1603, Val Loss: 1.7195, F1 Micro: 0.4167, F1 Macro: 0.3799, Accuracy: 0.4167\n","Epoch 103, Train Loss: 1.1383, Val Loss: 1.6475, F1 Micro: 0.4792, F1 Macro: 0.4506, Accuracy: 0.4792\n","Epoch 104, Train Loss: 1.1023, Val Loss: 1.5685, F1 Micro: 0.5000, F1 Macro: 0.4625, Accuracy: 0.5000\n","Epoch 105, Train Loss: 1.0506, Val Loss: 1.5946, F1 Micro: 0.4583, F1 Macro: 0.4427, Accuracy: 0.4583\n","Epoch 106, Train Loss: 1.1255, Val Loss: 1.6288, F1 Micro: 0.4271, F1 Macro: 0.4068, Accuracy: 0.4271\n","Epoch 107, Train Loss: 1.1437, Val Loss: 1.6305, F1 Micro: 0.4792, F1 Macro: 0.4550, Accuracy: 0.4792\n","Epoch 108, Train Loss: 1.0484, Val Loss: 1.5266, F1 Micro: 0.5208, F1 Macro: 0.4714, Accuracy: 0.5208\n","Epoch 109, Train Loss: 1.0323, Val Loss: 1.6503, F1 Micro: 0.4792, F1 Macro: 0.4499, Accuracy: 0.4792\n","Epoch 110, Train Loss: 1.0566, Val Loss: 1.5932, F1 Micro: 0.4896, F1 Macro: 0.4541, Accuracy: 0.4896\n","Epoch 111, Train Loss: 1.0154, Val Loss: 1.7557, F1 Micro: 0.3958, F1 Macro: 0.3574, Accuracy: 0.3958\n","Epoch 112, Train Loss: 1.0584, Val Loss: 1.7013, F1 Micro: 0.3958, F1 Macro: 0.3777, Accuracy: 0.3958\n","Epoch 113, Train Loss: 1.1337, Val Loss: 1.6285, F1 Micro: 0.4896, F1 Macro: 0.4701, Accuracy: 0.4896\n","Epoch 114, Train Loss: 1.0046, Val Loss: 1.8222, F1 Micro: 0.4167, F1 Macro: 0.3461, Accuracy: 0.4167\n","Epoch 115, Train Loss: 1.0019, Val Loss: 1.7199, F1 Micro: 0.3958, F1 Macro: 0.3513, Accuracy: 0.3958\n","Epoch 116, Train Loss: 1.0315, Val Loss: 1.7091, F1 Micro: 0.4792, F1 Macro: 0.4648, Accuracy: 0.4792\n","Epoch 117, Train Loss: 1.0093, Val Loss: 1.6564, F1 Micro: 0.4792, F1 Macro: 0.4353, Accuracy: 0.4792\n","Epoch 118, Train Loss: 1.0128, Val Loss: 1.6086, F1 Micro: 0.4792, F1 Macro: 0.4286, Accuracy: 0.4792\n","Epoch 119, Train Loss: 0.9661, Val Loss: 1.5678, F1 Micro: 0.4167, F1 Macro: 0.3891, Accuracy: 0.4167\n","Epoch 120, Train Loss: 0.9876, Val Loss: 1.7168, F1 Micro: 0.4583, F1 Macro: 0.4457, Accuracy: 0.4583\n","Epoch 121, Train Loss: 1.0831, Val Loss: 1.7112, F1 Micro: 0.4375, F1 Macro: 0.4088, Accuracy: 0.4375\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.3443, Val Loss: 2.1154, F1 Micro: 0.2188, F1 Macro: 0.1266, Accuracy: 0.2188\n","Epoch 2, Train Loss: 2.4099, Val Loss: 2.7620, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 3, Train Loss: 2.2848, Val Loss: 2.0822, F1 Micro: 0.2500, F1 Macro: 0.1647, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.9347, Val Loss: 2.1153, F1 Micro: 0.2812, F1 Macro: 0.2064, Accuracy: 0.2812\n","Epoch 5, Train Loss: 2.1084, Val Loss: 1.7783, F1 Micro: 0.2812, F1 Macro: 0.2072, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.8508, Val Loss: 1.7520, F1 Micro: 0.3646, F1 Macro: 0.3474, Accuracy: 0.3646\n","Epoch 7, Train Loss: 1.8144, Val Loss: 1.8793, F1 Micro: 0.2083, F1 Macro: 0.1240, Accuracy: 0.2083\n","Epoch 8, Train Loss: 1.8448, Val Loss: 1.7367, F1 Micro: 0.3333, F1 Macro: 0.2489, Accuracy: 0.3333\n","Epoch 9, Train Loss: 1.8257, Val Loss: 1.7589, F1 Micro: 0.2292, F1 Macro: 0.1342, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.7734, Val Loss: 1.8040, F1 Micro: 0.2500, F1 Macro: 0.1777, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.6970, Val Loss: 1.7679, F1 Micro: 0.1875, F1 Macro: 0.1218, Accuracy: 0.1875\n","Epoch 12, Train Loss: 1.7092, Val Loss: 1.7854, F1 Micro: 0.2500, F1 Macro: 0.1798, Accuracy: 0.2500\n","Epoch 13, Train Loss: 1.7112, Val Loss: 1.7345, F1 Micro: 0.2396, F1 Macro: 0.1617, Accuracy: 0.2396\n","Epoch 14, Train Loss: 1.6901, Val Loss: 1.8421, F1 Micro: 0.2292, F1 Macro: 0.1310, Accuracy: 0.2292\n","Epoch 15, Train Loss: 1.7053, Val Loss: 1.7235, F1 Micro: 0.2188, F1 Macro: 0.1442, Accuracy: 0.2188\n","Epoch 16, Train Loss: 1.7094, Val Loss: 1.8810, F1 Micro: 0.2292, F1 Macro: 0.1298, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.7381, Val Loss: 1.7753, F1 Micro: 0.2396, F1 Macro: 0.1490, Accuracy: 0.2396\n","Epoch 18, Train Loss: 1.6717, Val Loss: 1.8619, F1 Micro: 0.1979, F1 Macro: 0.1116, Accuracy: 0.1979\n","Epoch 19, Train Loss: 1.6760, Val Loss: 1.7809, F1 Micro: 0.2188, F1 Macro: 0.1607, Accuracy: 0.2188\n","Epoch 20, Train Loss: 1.6962, Val Loss: 1.7322, F1 Micro: 0.2188, F1 Macro: 0.1633, Accuracy: 0.2188\n","Epoch 21, Train Loss: 1.6509, Val Loss: 1.7063, F1 Micro: 0.2500, F1 Macro: 0.2341, Accuracy: 0.2500\n","Epoch 22, Train Loss: 1.6690, Val Loss: 1.9189, F1 Micro: 0.3021, F1 Macro: 0.2190, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.7110, Val Loss: 1.7358, F1 Micro: 0.3021, F1 Macro: 0.2178, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.6892, Val Loss: 1.7120, F1 Micro: 0.2500, F1 Macro: 0.2341, Accuracy: 0.2500\n","Epoch 25, Train Loss: 1.6758, Val Loss: 1.7608, F1 Micro: 0.2604, F1 Macro: 0.2110, Accuracy: 0.2604\n","Epoch 26, Train Loss: 1.6203, Val Loss: 1.6707, F1 Micro: 0.3438, F1 Macro: 0.3148, Accuracy: 0.3438\n","Epoch 27, Train Loss: 1.6154, Val Loss: 1.6912, F1 Micro: 0.2500, F1 Macro: 0.1919, Accuracy: 0.2500\n","Epoch 28, Train Loss: 1.6578, Val Loss: 1.6516, F1 Micro: 0.2604, F1 Macro: 0.2165, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.6005, Val Loss: 1.7434, F1 Micro: 0.3542, F1 Macro: 0.3005, Accuracy: 0.3542\n","Epoch 30, Train Loss: 1.6298, Val Loss: 1.6675, F1 Micro: 0.3021, F1 Macro: 0.2859, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.6286, Val Loss: 1.6323, F1 Micro: 0.3229, F1 Macro: 0.2994, Accuracy: 0.3229\n","Epoch 32, Train Loss: 1.6080, Val Loss: 1.6941, F1 Micro: 0.3229, F1 Macro: 0.2860, Accuracy: 0.3229\n","Epoch 33, Train Loss: 1.6153, Val Loss: 1.6443, F1 Micro: 0.3438, F1 Macro: 0.3370, Accuracy: 0.3438\n","Epoch 34, Train Loss: 1.5869, Val Loss: 1.7828, F1 Micro: 0.2812, F1 Macro: 0.2184, Accuracy: 0.2812\n","Epoch 35, Train Loss: 1.6265, Val Loss: 1.7145, F1 Micro: 0.3542, F1 Macro: 0.2805, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.5601, Val Loss: 1.6772, F1 Micro: 0.3438, F1 Macro: 0.2879, Accuracy: 0.3438\n","Epoch 37, Train Loss: 1.5777, Val Loss: 1.6168, F1 Micro: 0.3438, F1 Macro: 0.3093, Accuracy: 0.3438\n","Epoch 38, Train Loss: 1.5416, Val Loss: 1.7304, F1 Micro: 0.3542, F1 Macro: 0.3202, Accuracy: 0.3542\n","Epoch 39, Train Loss: 1.5580, Val Loss: 1.6366, F1 Micro: 0.3333, F1 Macro: 0.2888, Accuracy: 0.3333\n","Epoch 40, Train Loss: 1.5696, Val Loss: 1.5803, F1 Micro: 0.3438, F1 Macro: 0.3267, Accuracy: 0.3438\n","Epoch 41, Train Loss: 1.5613, Val Loss: 1.7383, F1 Micro: 0.3125, F1 Macro: 0.2416, Accuracy: 0.3125\n","Epoch 42, Train Loss: 1.5901, Val Loss: 1.7622, F1 Micro: 0.3542, F1 Macro: 0.3125, Accuracy: 0.3542\n","Epoch 43, Train Loss: 1.5801, Val Loss: 1.6042, F1 Micro: 0.3438, F1 Macro: 0.2946, Accuracy: 0.3438\n","Epoch 44, Train Loss: 1.4916, Val Loss: 1.6445, F1 Micro: 0.3542, F1 Macro: 0.3544, Accuracy: 0.3542\n","Epoch 45, Train Loss: 1.5664, Val Loss: 1.5973, F1 Micro: 0.3438, F1 Macro: 0.3186, Accuracy: 0.3438\n","Epoch 46, Train Loss: 1.5026, Val Loss: 1.7102, F1 Micro: 0.3542, F1 Macro: 0.3058, Accuracy: 0.3542\n","Epoch 47, Train Loss: 1.5132, Val Loss: 1.6983, F1 Micro: 0.2708, F1 Macro: 0.2214, Accuracy: 0.2708\n","Epoch 48, Train Loss: 1.5106, Val Loss: 1.6330, F1 Micro: 0.3646, F1 Macro: 0.3403, Accuracy: 0.3646\n","Epoch 49, Train Loss: 1.4995, Val Loss: 1.5875, F1 Micro: 0.3333, F1 Macro: 0.2980, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.4754, Val Loss: 1.6056, F1 Micro: 0.3750, F1 Macro: 0.3475, Accuracy: 0.3750\n","Epoch 51, Train Loss: 1.5133, Val Loss: 1.5651, F1 Micro: 0.3021, F1 Macro: 0.2651, Accuracy: 0.3021\n","Epoch 52, Train Loss: 1.4868, Val Loss: 1.6807, F1 Micro: 0.3333, F1 Macro: 0.3181, Accuracy: 0.3333\n","Epoch 53, Train Loss: 1.5117, Val Loss: 1.5095, F1 Micro: 0.3646, F1 Macro: 0.3312, Accuracy: 0.3646\n","Epoch 54, Train Loss: 1.4562, Val Loss: 1.5273, F1 Micro: 0.4271, F1 Macro: 0.4168, Accuracy: 0.4271\n","Epoch 55, Train Loss: 1.4235, Val Loss: 1.6135, F1 Micro: 0.3333, F1 Macro: 0.3228, Accuracy: 0.3333\n","Epoch 56, Train Loss: 1.5137, Val Loss: 1.6205, F1 Micro: 0.3750, F1 Macro: 0.3538, Accuracy: 0.3750\n","Epoch 57, Train Loss: 1.4565, Val Loss: 1.5283, F1 Micro: 0.3854, F1 Macro: 0.3630, Accuracy: 0.3854\n","Epoch 58, Train Loss: 1.4602, Val Loss: 1.6472, F1 Micro: 0.3854, F1 Macro: 0.3574, Accuracy: 0.3854\n","Epoch 59, Train Loss: 1.4216, Val Loss: 1.5822, F1 Micro: 0.3958, F1 Macro: 0.3753, Accuracy: 0.3958\n","Epoch 60, Train Loss: 1.4396, Val Loss: 1.5389, F1 Micro: 0.3646, F1 Macro: 0.3708, Accuracy: 0.3646\n","Epoch 61, Train Loss: 1.4618, Val Loss: 1.6147, F1 Micro: 0.3438, F1 Macro: 0.3041, Accuracy: 0.3438\n","Epoch 62, Train Loss: 1.4602, Val Loss: 1.5863, F1 Micro: 0.3646, F1 Macro: 0.3372, Accuracy: 0.3646\n","Epoch 63, Train Loss: 1.4017, Val Loss: 1.7079, F1 Micro: 0.3750, F1 Macro: 0.3246, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.4567, Val Loss: 1.5275, F1 Micro: 0.4271, F1 Macro: 0.3873, Accuracy: 0.4271\n","Epoch 65, Train Loss: 1.4066, Val Loss: 1.5599, F1 Micro: 0.3958, F1 Macro: 0.3648, Accuracy: 0.3958\n","Epoch 66, Train Loss: 1.3575, Val Loss: 1.5050, F1 Micro: 0.4271, F1 Macro: 0.4372, Accuracy: 0.4271\n","Epoch 67, Train Loss: 1.4257, Val Loss: 1.5604, F1 Micro: 0.3750, F1 Macro: 0.3687, Accuracy: 0.3750\n","Epoch 68, Train Loss: 1.4000, Val Loss: 1.4987, F1 Micro: 0.4167, F1 Macro: 0.3973, Accuracy: 0.4167\n","Epoch 69, Train Loss: 1.3466, Val Loss: 1.5461, F1 Micro: 0.3646, F1 Macro: 0.3695, Accuracy: 0.3646\n","Epoch 70, Train Loss: 1.4011, Val Loss: 1.5972, F1 Micro: 0.3958, F1 Macro: 0.3934, Accuracy: 0.3958\n","Epoch 71, Train Loss: 1.4221, Val Loss: 1.5955, F1 Micro: 0.3229, F1 Macro: 0.3177, Accuracy: 0.3229\n","Epoch 72, Train Loss: 1.3646, Val Loss: 1.5791, F1 Micro: 0.3750, F1 Macro: 0.3562, Accuracy: 0.3750\n","Epoch 73, Train Loss: 1.3902, Val Loss: 1.5422, F1 Micro: 0.3750, F1 Macro: 0.3415, Accuracy: 0.3750\n","Epoch 74, Train Loss: 1.3305, Val Loss: 1.6022, F1 Micro: 0.4062, F1 Macro: 0.3717, Accuracy: 0.4062\n","Epoch 75, Train Loss: 1.3505, Val Loss: 1.5996, F1 Micro: 0.3542, F1 Macro: 0.3462, Accuracy: 0.3542\n","Epoch 76, Train Loss: 1.3253, Val Loss: 1.5108, F1 Micro: 0.4062, F1 Macro: 0.4216, Accuracy: 0.4062\n","Epoch 77, Train Loss: 1.3133, Val Loss: 1.4495, F1 Micro: 0.4479, F1 Macro: 0.4431, Accuracy: 0.4479\n","Epoch 78, Train Loss: 1.3061, Val Loss: 1.5470, F1 Micro: 0.3333, F1 Macro: 0.3102, Accuracy: 0.3333\n","Epoch 79, Train Loss: 1.2835, Val Loss: 1.6277, F1 Micro: 0.3646, F1 Macro: 0.2969, Accuracy: 0.3646\n","Epoch 80, Train Loss: 1.2958, Val Loss: 1.5515, F1 Micro: 0.3333, F1 Macro: 0.3288, Accuracy: 0.3333\n","Epoch 81, Train Loss: 1.3317, Val Loss: 1.5342, F1 Micro: 0.4062, F1 Macro: 0.4036, Accuracy: 0.4062\n","Epoch 82, Train Loss: 1.3265, Val Loss: 1.6026, F1 Micro: 0.3958, F1 Macro: 0.3737, Accuracy: 0.3958\n","Epoch 83, Train Loss: 1.2804, Val Loss: 1.6001, F1 Micro: 0.3854, F1 Macro: 0.3548, Accuracy: 0.3854\n","Epoch 84, Train Loss: 1.2861, Val Loss: 1.4962, F1 Micro: 0.4271, F1 Macro: 0.4104, Accuracy: 0.4271\n","Epoch 85, Train Loss: 1.2889, Val Loss: 1.5671, F1 Micro: 0.3854, F1 Macro: 0.3411, Accuracy: 0.3854\n","Epoch 86, Train Loss: 1.2237, Val Loss: 1.5010, F1 Micro: 0.3854, F1 Macro: 0.3730, Accuracy: 0.3854\n","Epoch 87, Train Loss: 1.2686, Val Loss: 1.7077, F1 Micro: 0.3542, F1 Macro: 0.3423, Accuracy: 0.3542\n","Epoch 88, Train Loss: 1.2761, Val Loss: 1.6420, F1 Micro: 0.3542, F1 Macro: 0.3100, Accuracy: 0.3542\n","Epoch 89, Train Loss: 1.2556, Val Loss: 1.6112, F1 Micro: 0.3750, F1 Macro: 0.3631, Accuracy: 0.3750\n","Epoch 90, Train Loss: 1.2009, Val Loss: 1.5443, F1 Micro: 0.4062, F1 Macro: 0.4122, Accuracy: 0.4062\n","Epoch 91, Train Loss: 1.3389, Val Loss: 1.5257, F1 Micro: 0.3750, F1 Macro: 0.3857, Accuracy: 0.3750\n","Epoch 92, Train Loss: 1.2845, Val Loss: 1.4280, F1 Micro: 0.3542, F1 Macro: 0.3639, Accuracy: 0.3542\n","Epoch 93, Train Loss: 1.2287, Val Loss: 1.5123, F1 Micro: 0.4062, F1 Macro: 0.3915, Accuracy: 0.4062\n","Epoch 94, Train Loss: 1.2181, Val Loss: 1.5176, F1 Micro: 0.4271, F1 Macro: 0.4104, Accuracy: 0.4271\n","Epoch 95, Train Loss: 1.2423, Val Loss: 1.5032, F1 Micro: 0.4167, F1 Macro: 0.4021, Accuracy: 0.4167\n","Epoch 96, Train Loss: 1.1848, Val Loss: 1.4409, F1 Micro: 0.4375, F1 Macro: 0.4507, Accuracy: 0.4375\n","Epoch 97, Train Loss: 1.2213, Val Loss: 1.5428, F1 Micro: 0.4062, F1 Macro: 0.4063, Accuracy: 0.4062\n","Epoch 98, Train Loss: 1.1762, Val Loss: 1.6339, F1 Micro: 0.3542, F1 Macro: 0.3547, Accuracy: 0.3542\n","Epoch 99, Train Loss: 1.2716, Val Loss: 1.5743, F1 Micro: 0.4271, F1 Macro: 0.4070, Accuracy: 0.4271\n","Epoch 100, Train Loss: 1.1846, Val Loss: 1.6560, F1 Micro: 0.3333, F1 Macro: 0.3304, Accuracy: 0.3333\n","Epoch 101, Train Loss: 1.1869, Val Loss: 1.5523, F1 Micro: 0.3854, F1 Macro: 0.3871, Accuracy: 0.3854\n","Epoch 102, Train Loss: 1.1419, Val Loss: 1.4825, F1 Micro: 0.4167, F1 Macro: 0.4194, Accuracy: 0.4167\n","Epoch 103, Train Loss: 1.1854, Val Loss: 1.7239, F1 Micro: 0.3542, F1 Macro: 0.3361, Accuracy: 0.3542\n","Epoch 104, Train Loss: 1.2139, Val Loss: 1.4979, F1 Micro: 0.3958, F1 Macro: 0.3918, Accuracy: 0.3958\n","Epoch 105, Train Loss: 1.1598, Val Loss: 1.6275, F1 Micro: 0.3854, F1 Macro: 0.3778, Accuracy: 0.3854\n","Epoch 106, Train Loss: 1.2079, Val Loss: 1.5819, F1 Micro: 0.4062, F1 Macro: 0.3903, Accuracy: 0.4062\n","Epoch 107, Train Loss: 1.1619, Val Loss: 1.5912, F1 Micro: 0.3646, F1 Macro: 0.3564, Accuracy: 0.3646\n","Epoch 108, Train Loss: 1.1758, Val Loss: 1.5702, F1 Micro: 0.4167, F1 Macro: 0.3930, Accuracy: 0.4167\n","Epoch 109, Train Loss: 1.1061, Val Loss: 1.5732, F1 Micro: 0.3750, F1 Macro: 0.3884, Accuracy: 0.3750\n","Epoch 110, Train Loss: 1.1498, Val Loss: 1.5252, F1 Micro: 0.4375, F1 Macro: 0.4376, Accuracy: 0.4375\n","Epoch 111, Train Loss: 1.0760, Val Loss: 1.4683, F1 Micro: 0.3854, F1 Macro: 0.3873, Accuracy: 0.3854\n","Epoch 112, Train Loss: 1.1031, Val Loss: 1.4717, F1 Micro: 0.4375, F1 Macro: 0.4454, Accuracy: 0.4375\n","Epoch 113, Train Loss: 1.1125, Val Loss: 1.4718, F1 Micro: 0.4375, F1 Macro: 0.4451, Accuracy: 0.4375\n","Epoch 114, Train Loss: 1.1204, Val Loss: 1.5762, F1 Micro: 0.4375, F1 Macro: 0.4505, Accuracy: 0.4375\n","Epoch 115, Train Loss: 1.0737, Val Loss: 1.6498, F1 Micro: 0.3958, F1 Macro: 0.3979, Accuracy: 0.3958\n","Epoch 116, Train Loss: 1.0372, Val Loss: 1.4074, F1 Micro: 0.4896, F1 Macro: 0.4936, Accuracy: 0.4896\n","Epoch 117, Train Loss: 1.0388, Val Loss: 1.4922, F1 Micro: 0.4896, F1 Macro: 0.4727, Accuracy: 0.4896\n","Epoch 118, Train Loss: 1.0621, Val Loss: 1.5649, F1 Micro: 0.4375, F1 Macro: 0.4225, Accuracy: 0.4375\n","Epoch 119, Train Loss: 1.1104, Val Loss: 1.4372, F1 Micro: 0.4271, F1 Macro: 0.4246, Accuracy: 0.4271\n","Epoch 120, Train Loss: 1.0843, Val Loss: 1.6426, F1 Micro: 0.3542, F1 Macro: 0.3538, Accuracy: 0.3542\n","Epoch 121, Train Loss: 1.0556, Val Loss: 1.6834, F1 Micro: 0.3333, F1 Macro: 0.3112, Accuracy: 0.3333\n","Epoch 122, Train Loss: 1.0665, Val Loss: 1.4547, F1 Micro: 0.4896, F1 Macro: 0.4878, Accuracy: 0.4896\n","Epoch 123, Train Loss: 1.0500, Val Loss: 1.4649, F1 Micro: 0.4688, F1 Macro: 0.4733, Accuracy: 0.4688\n","Epoch 124, Train Loss: 1.0418, Val Loss: 1.4820, F1 Micro: 0.4479, F1 Macro: 0.4286, Accuracy: 0.4479\n","Epoch 125, Train Loss: 0.9787, Val Loss: 1.5422, F1 Micro: 0.4479, F1 Macro: 0.4460, Accuracy: 0.4479\n","Epoch 126, Train Loss: 1.0169, Val Loss: 1.5122, F1 Micro: 0.4479, F1 Macro: 0.4521, Accuracy: 0.4479\n","Epoch 127, Train Loss: 1.0271, Val Loss: 1.3960, F1 Micro: 0.4792, F1 Macro: 0.4867, Accuracy: 0.4792\n","Epoch 128, Train Loss: 0.9866, Val Loss: 1.6220, F1 Micro: 0.4479, F1 Macro: 0.4356, Accuracy: 0.4479\n","Epoch 129, Train Loss: 0.9678, Val Loss: 1.4450, F1 Micro: 0.4896, F1 Macro: 0.4883, Accuracy: 0.4896\n","Epoch 130, Train Loss: 0.9629, Val Loss: 1.5707, F1 Micro: 0.4479, F1 Macro: 0.4448, Accuracy: 0.4479\n","Epoch 131, Train Loss: 1.0363, Val Loss: 1.5009, F1 Micro: 0.5000, F1 Macro: 0.5003, Accuracy: 0.5000\n","Epoch 132, Train Loss: 0.9951, Val Loss: 1.5753, F1 Micro: 0.4271, F1 Macro: 0.4147, Accuracy: 0.4271\n","Epoch 133, Train Loss: 1.0018, Val Loss: 1.4909, F1 Micro: 0.4583, F1 Macro: 0.4391, Accuracy: 0.4583\n","Epoch 134, Train Loss: 1.0168, Val Loss: 1.5004, F1 Micro: 0.4792, F1 Macro: 0.4710, Accuracy: 0.4792\n","Epoch 135, Train Loss: 0.9965, Val Loss: 1.5285, F1 Micro: 0.4062, F1 Macro: 0.4077, Accuracy: 0.4062\n","Epoch 136, Train Loss: 1.0471, Val Loss: 1.5332, F1 Micro: 0.4375, F1 Macro: 0.4338, Accuracy: 0.4375\n","Epoch 137, Train Loss: 0.9561, Val Loss: 1.4524, F1 Micro: 0.5000, F1 Macro: 0.5070, Accuracy: 0.5000\n","Epoch 138, Train Loss: 0.9170, Val Loss: 1.5897, F1 Micro: 0.4583, F1 Macro: 0.4515, Accuracy: 0.4583\n","Epoch 139, Train Loss: 1.0363, Val Loss: 1.5493, F1 Micro: 0.4688, F1 Macro: 0.4549, Accuracy: 0.4688\n","Epoch 140, Train Loss: 0.9083, Val Loss: 1.4773, F1 Micro: 0.4688, F1 Macro: 0.4569, Accuracy: 0.4688\n","Epoch 141, Train Loss: 0.8820, Val Loss: 1.4381, F1 Micro: 0.4896, F1 Macro: 0.4920, Accuracy: 0.4896\n","Epoch 142, Train Loss: 0.9293, Val Loss: 1.5003, F1 Micro: 0.5000, F1 Macro: 0.4888, Accuracy: 0.5000\n","Epoch 143, Train Loss: 0.8692, Val Loss: 1.5190, F1 Micro: 0.4792, F1 Macro: 0.4736, Accuracy: 0.4792\n","Epoch 144, Train Loss: 0.8593, Val Loss: 1.4539, F1 Micro: 0.4896, F1 Macro: 0.4950, Accuracy: 0.4896\n","Epoch 145, Train Loss: 0.8463, Val Loss: 1.4765, F1 Micro: 0.4792, F1 Macro: 0.4852, Accuracy: 0.4792\n","Epoch 146, Train Loss: 0.9126, Val Loss: 1.5285, F1 Micro: 0.4688, F1 Macro: 0.4607, Accuracy: 0.4688\n","Epoch 147, Train Loss: 0.8419, Val Loss: 1.5115, F1 Micro: 0.4583, F1 Macro: 0.4605, Accuracy: 0.4583\n","Epoch 148, Train Loss: 0.8932, Val Loss: 1.5559, F1 Micro: 0.4792, F1 Macro: 0.4750, Accuracy: 0.4792\n","Epoch 149, Train Loss: 0.9337, Val Loss: 1.5540, F1 Micro: 0.5312, F1 Macro: 0.5260, Accuracy: 0.5312\n","Epoch 150, Train Loss: 0.8464, Val Loss: 1.5909, F1 Micro: 0.4583, F1 Macro: 0.4579, Accuracy: 0.4583\n","Epoch 151, Train Loss: 0.9155, Val Loss: 1.6804, F1 Micro: 0.4375, F1 Macro: 0.4527, Accuracy: 0.4375\n","Epoch 152, Train Loss: 0.9012, Val Loss: 1.6454, F1 Micro: 0.4896, F1 Macro: 0.4879, Accuracy: 0.4896\n","Epoch 153, Train Loss: 0.8568, Val Loss: 1.5837, F1 Micro: 0.4792, F1 Macro: 0.4754, Accuracy: 0.4792\n","Epoch 154, Train Loss: 0.7966, Val Loss: 1.5217, F1 Micro: 0.5312, F1 Macro: 0.5280, Accuracy: 0.5312\n","Epoch 155, Train Loss: 0.8192, Val Loss: 1.6081, F1 Micro: 0.5000, F1 Macro: 0.4993, Accuracy: 0.5000\n","Epoch 156, Train Loss: 0.8056, Val Loss: 1.6460, F1 Micro: 0.4583, F1 Macro: 0.4592, Accuracy: 0.4583\n","Epoch 157, Train Loss: 0.7669, Val Loss: 1.4431, F1 Micro: 0.5208, F1 Macro: 0.5211, Accuracy: 0.5208\n","Epoch 158, Train Loss: 0.8511, Val Loss: 1.7371, F1 Micro: 0.4375, F1 Macro: 0.4262, Accuracy: 0.4375\n","Epoch 159, Train Loss: 0.8615, Val Loss: 1.4346, F1 Micro: 0.5000, F1 Macro: 0.5064, Accuracy: 0.5000\n","Epoch 160, Train Loss: 0.8063, Val Loss: 1.5689, F1 Micro: 0.4479, F1 Macro: 0.4384, Accuracy: 0.4479\n","Epoch 161, Train Loss: 0.8150, Val Loss: 1.5066, F1 Micro: 0.5521, F1 Macro: 0.5550, Accuracy: 0.5521\n","Epoch 162, Train Loss: 0.7702, Val Loss: 1.5388, F1 Micro: 0.4792, F1 Macro: 0.4903, Accuracy: 0.4792\n","Epoch 163, Train Loss: 0.8070, Val Loss: 1.4971, F1 Micro: 0.4688, F1 Macro: 0.4777, Accuracy: 0.4688\n","Epoch 164, Train Loss: 0.7941, Val Loss: 1.7631, F1 Micro: 0.5104, F1 Macro: 0.5135, Accuracy: 0.5104\n","Epoch 165, Train Loss: 0.7995, Val Loss: 1.5313, F1 Micro: 0.4271, F1 Macro: 0.4267, Accuracy: 0.4271\n","Epoch 166, Train Loss: 0.7796, Val Loss: 1.7568, F1 Micro: 0.4688, F1 Macro: 0.4678, Accuracy: 0.4688\n","Epoch 167, Train Loss: 0.7606, Val Loss: 1.5422, F1 Micro: 0.5312, F1 Macro: 0.5376, Accuracy: 0.5312\n","Epoch 168, Train Loss: 0.7360, Val Loss: 1.5368, F1 Micro: 0.5104, F1 Macro: 0.5139, Accuracy: 0.5104\n","Epoch 169, Train Loss: 0.7781, Val Loss: 1.6628, F1 Micro: 0.4271, F1 Macro: 0.4282, Accuracy: 0.4271\n","Epoch 170, Train Loss: 0.6974, Val Loss: 1.5867, F1 Micro: 0.5104, F1 Macro: 0.5117, Accuracy: 0.5104\n","Epoch 171, Train Loss: 0.7092, Val Loss: 1.6653, F1 Micro: 0.5000, F1 Macro: 0.4961, Accuracy: 0.5000\n","Epoch 172, Train Loss: 0.7420, Val Loss: 1.6110, F1 Micro: 0.5729, F1 Macro: 0.5742, Accuracy: 0.5729\n","Epoch 173, Train Loss: 0.7587, Val Loss: 1.5445, F1 Micro: 0.4792, F1 Macro: 0.4885, Accuracy: 0.4792\n","Epoch 174, Train Loss: 0.7111, Val Loss: 1.6601, F1 Micro: 0.4792, F1 Macro: 0.4767, Accuracy: 0.4792\n","Epoch 175, Train Loss: 0.7180, Val Loss: 1.6292, F1 Micro: 0.5208, F1 Macro: 0.5160, Accuracy: 0.5208\n","Epoch 176, Train Loss: 0.7602, Val Loss: 1.8069, F1 Micro: 0.4479, F1 Macro: 0.4535, Accuracy: 0.4479\n","Epoch 177, Train Loss: 0.8139, Val Loss: 1.6195, F1 Micro: 0.4583, F1 Macro: 0.4651, Accuracy: 0.4583\n","Epoch 178, Train Loss: 0.7427, Val Loss: 1.5386, F1 Micro: 0.5208, F1 Macro: 0.5177, Accuracy: 0.5208\n","Epoch 179, Train Loss: 0.7049, Val Loss: 1.5453, F1 Micro: 0.5521, F1 Macro: 0.5612, Accuracy: 0.5521\n","Epoch 180, Train Loss: 0.7385, Val Loss: 1.8063, F1 Micro: 0.5000, F1 Macro: 0.4823, Accuracy: 0.5000\n","Epoch 181, Train Loss: 0.7024, Val Loss: 1.5622, F1 Micro: 0.4792, F1 Macro: 0.4866, Accuracy: 0.4792\n","Epoch 182, Train Loss: 0.6457, Val Loss: 1.7150, F1 Micro: 0.5417, F1 Macro: 0.5305, Accuracy: 0.5417\n","Epoch 183, Train Loss: 0.6504, Val Loss: 1.6032, F1 Micro: 0.5208, F1 Macro: 0.5208, Accuracy: 0.5208\n","Epoch 184, Train Loss: 0.6410, Val Loss: 1.6953, F1 Micro: 0.5000, F1 Macro: 0.5027, Accuracy: 0.5000\n","Epoch 185, Train Loss: 0.6768, Val Loss: 1.6887, F1 Micro: 0.5000, F1 Macro: 0.4848, Accuracy: 0.5000\n","Epoch 186, Train Loss: 0.7751, Val Loss: 1.6800, F1 Micro: 0.4896, F1 Macro: 0.4892, Accuracy: 0.4896\n","Epoch 187, Train Loss: 0.6757, Val Loss: 1.7265, F1 Micro: 0.4896, F1 Macro: 0.5016, Accuracy: 0.4896\n","Epoch 188, Train Loss: 0.6515, Val Loss: 1.6838, F1 Micro: 0.4479, F1 Macro: 0.4446, Accuracy: 0.4479\n","Epoch 189, Train Loss: 0.6897, Val Loss: 1.8718, F1 Micro: 0.5104, F1 Macro: 0.5042, Accuracy: 0.5104\n","Epoch 190, Train Loss: 0.6767, Val Loss: 1.6429, F1 Micro: 0.5208, F1 Macro: 0.5022, Accuracy: 0.5208\n","Epoch 191, Train Loss: 0.6116, Val Loss: 1.6010, F1 Micro: 0.5000, F1 Macro: 0.5112, Accuracy: 0.5000\n","Epoch 192, Train Loss: 0.6032, Val Loss: 1.6353, F1 Micro: 0.4792, F1 Macro: 0.4805, Accuracy: 0.4792\n","Epoch 193, Train Loss: 0.6615, Val Loss: 1.6094, F1 Micro: 0.5104, F1 Macro: 0.5184, Accuracy: 0.5104\n","Epoch 194, Train Loss: 0.6379, Val Loss: 1.7923, F1 Micro: 0.4583, F1 Macro: 0.4426, Accuracy: 0.4583\n","Epoch 195, Train Loss: 0.6729, Val Loss: 1.7434, F1 Micro: 0.5208, F1 Macro: 0.5256, Accuracy: 0.5208\n","Epoch 196, Train Loss: 0.7211, Val Loss: 1.9306, F1 Micro: 0.4479, F1 Macro: 0.4350, Accuracy: 0.4479\n","Epoch 197, Train Loss: 0.7548, Val Loss: 1.7299, F1 Micro: 0.4688, F1 Macro: 0.4624, Accuracy: 0.4688\n","Epoch 198, Train Loss: 0.5727, Val Loss: 1.5796, F1 Micro: 0.5312, F1 Macro: 0.5361, Accuracy: 0.5312\n","Epoch 199, Train Loss: 0.6571, Val Loss: 1.6285, F1 Micro: 0.5625, F1 Macro: 0.5585, Accuracy: 0.5625\n","Epoch 200, Train Loss: 0.6452, Val Loss: 1.8100, F1 Micro: 0.5000, F1 Macro: 0.5099, Accuracy: 0.5000\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 3.3094, Val Loss: 2.1158, F1 Micro: 0.2812, F1 Macro: 0.2130, Accuracy: 0.2812\n","Epoch 2, Train Loss: 2.3850, Val Loss: 2.4333, F1 Micro: 0.1875, F1 Macro: 0.1201, Accuracy: 0.1875\n","Epoch 3, Train Loss: 2.1536, Val Loss: 1.8255, F1 Micro: 0.2188, F1 Macro: 0.1776, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.9497, Val Loss: 1.7533, F1 Micro: 0.2292, F1 Macro: 0.1570, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.9045, Val Loss: 1.7661, F1 Micro: 0.1979, F1 Macro: 0.1536, Accuracy: 0.1979\n","Epoch 6, Train Loss: 1.8887, Val Loss: 1.8528, F1 Micro: 0.2292, F1 Macro: 0.1905, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.9189, Val Loss: 1.8406, F1 Micro: 0.2396, F1 Macro: 0.1843, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.7950, Val Loss: 1.8135, F1 Micro: 0.2917, F1 Macro: 0.2123, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.7550, Val Loss: 1.7850, F1 Micro: 0.2083, F1 Macro: 0.1869, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.8243, Val Loss: 1.7539, F1 Micro: 0.3021, F1 Macro: 0.2751, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.7421, Val Loss: 1.7427, F1 Micro: 0.2604, F1 Macro: 0.1917, Accuracy: 0.2604\n","Epoch 12, Train Loss: 1.7131, Val Loss: 1.7431, F1 Micro: 0.3021, F1 Macro: 0.2266, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.7054, Val Loss: 1.8051, F1 Micro: 0.2812, F1 Macro: 0.1915, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.7048, Val Loss: 1.7592, F1 Micro: 0.3125, F1 Macro: 0.2684, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.6910, Val Loss: 1.6844, F1 Micro: 0.3021, F1 Macro: 0.2670, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.6514, Val Loss: 1.7282, F1 Micro: 0.3021, F1 Macro: 0.2484, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.6442, Val Loss: 1.8261, F1 Micro: 0.2396, F1 Macro: 0.1628, Accuracy: 0.2396\n","Epoch 18, Train Loss: 1.6690, Val Loss: 2.0001, F1 Micro: 0.2500, F1 Macro: 0.1943, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.6330, Val Loss: 1.7272, F1 Micro: 0.3021, F1 Macro: 0.2441, Accuracy: 0.3021\n","Epoch 20, Train Loss: 1.6956, Val Loss: 1.7530, F1 Micro: 0.2604, F1 Macro: 0.2351, Accuracy: 0.2604\n","Epoch 21, Train Loss: 1.6708, Val Loss: 1.7752, F1 Micro: 0.3021, F1 Macro: 0.2834, Accuracy: 0.3021\n","Epoch 22, Train Loss: 1.6215, Val Loss: 1.7782, F1 Micro: 0.3229, F1 Macro: 0.2828, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.6486, Val Loss: 1.7477, F1 Micro: 0.3125, F1 Macro: 0.2866, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.5846, Val Loss: 1.8426, F1 Micro: 0.2188, F1 Macro: 0.1552, Accuracy: 0.2188\n","Epoch 25, Train Loss: 1.6025, Val Loss: 1.7578, F1 Micro: 0.3333, F1 Macro: 0.2878, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.5985, Val Loss: 1.7646, F1 Micro: 0.2812, F1 Macro: 0.2807, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.6075, Val Loss: 1.7350, F1 Micro: 0.3438, F1 Macro: 0.3093, Accuracy: 0.3438\n","Epoch 28, Train Loss: 1.5026, Val Loss: 1.8164, F1 Micro: 0.3333, F1 Macro: 0.3336, Accuracy: 0.3333\n","Epoch 29, Train Loss: 1.5080, Val Loss: 1.8474, F1 Micro: 0.3229, F1 Macro: 0.2673, Accuracy: 0.3229\n","Epoch 30, Train Loss: 1.5473, Val Loss: 1.9385, F1 Micro: 0.2396, F1 Macro: 0.1676, Accuracy: 0.2396\n","Epoch 31, Train Loss: 1.5314, Val Loss: 1.8886, F1 Micro: 0.2917, F1 Macro: 0.2631, Accuracy: 0.2917\n","Epoch 32, Train Loss: 1.5227, Val Loss: 1.7856, F1 Micro: 0.2917, F1 Macro: 0.2532, Accuracy: 0.2917\n","Epoch 33, Train Loss: 1.5183, Val Loss: 1.8137, F1 Micro: 0.2917, F1 Macro: 0.2751, Accuracy: 0.2917\n","Epoch 34, Train Loss: 1.5486, Val Loss: 1.7568, F1 Micro: 0.3646, F1 Macro: 0.3081, Accuracy: 0.3646\n","Epoch 35, Train Loss: 1.5339, Val Loss: 1.7300, F1 Micro: 0.3854, F1 Macro: 0.3773, Accuracy: 0.3854\n","Epoch 36, Train Loss: 1.4911, Val Loss: 1.8607, F1 Micro: 0.2917, F1 Macro: 0.2258, Accuracy: 0.2917\n","Epoch 37, Train Loss: 1.5489, Val Loss: 1.8082, F1 Micro: 0.2396, F1 Macro: 0.2398, Accuracy: 0.2396\n","Epoch 38, Train Loss: 1.4977, Val Loss: 1.7259, F1 Micro: 0.2917, F1 Macro: 0.2545, Accuracy: 0.2917\n","Epoch 39, Train Loss: 1.4721, Val Loss: 1.7315, F1 Micro: 0.3750, F1 Macro: 0.3501, Accuracy: 0.3750\n","Epoch 40, Train Loss: 1.4593, Val Loss: 1.8417, F1 Micro: 0.3646, F1 Macro: 0.3321, Accuracy: 0.3646\n","Epoch 41, Train Loss: 1.4360, Val Loss: 1.7856, F1 Micro: 0.3021, F1 Macro: 0.2892, Accuracy: 0.3021\n","Epoch 42, Train Loss: 1.4584, Val Loss: 1.7113, F1 Micro: 0.3958, F1 Macro: 0.3878, Accuracy: 0.3958\n","Epoch 43, Train Loss: 1.4909, Val Loss: 1.8045, F1 Micro: 0.3542, F1 Macro: 0.3234, Accuracy: 0.3542\n","Epoch 44, Train Loss: 1.4887, Val Loss: 1.7779, F1 Micro: 0.3229, F1 Macro: 0.3339, Accuracy: 0.3229\n","Epoch 45, Train Loss: 1.4827, Val Loss: 1.8352, F1 Micro: 0.3646, F1 Macro: 0.3519, Accuracy: 0.3646\n","Epoch 46, Train Loss: 1.4490, Val Loss: 1.7171, F1 Micro: 0.3854, F1 Macro: 0.3343, Accuracy: 0.3854\n","Epoch 47, Train Loss: 1.4847, Val Loss: 1.7284, F1 Micro: 0.3125, F1 Macro: 0.3048, Accuracy: 0.3125\n","Epoch 48, Train Loss: 1.3999, Val Loss: 1.8258, F1 Micro: 0.3229, F1 Macro: 0.2903, Accuracy: 0.3229\n","Epoch 49, Train Loss: 1.4535, Val Loss: 1.8682, F1 Micro: 0.3333, F1 Macro: 0.3003, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.4193, Val Loss: 1.7889, F1 Micro: 0.3646, F1 Macro: 0.3569, Accuracy: 0.3646\n","Epoch 51, Train Loss: 1.3681, Val Loss: 1.8800, F1 Micro: 0.2604, F1 Macro: 0.2365, Accuracy: 0.2604\n","Epoch 52, Train Loss: 1.4083, Val Loss: 1.8982, F1 Micro: 0.3125, F1 Macro: 0.2710, Accuracy: 0.3125\n","Epoch 53, Train Loss: 1.4018, Val Loss: 1.7323, F1 Micro: 0.3958, F1 Macro: 0.3613, Accuracy: 0.3958\n","Epoch 54, Train Loss: 1.4011, Val Loss: 1.8808, F1 Micro: 0.3229, F1 Macro: 0.3155, Accuracy: 0.3229\n","Epoch 55, Train Loss: 1.3736, Val Loss: 1.8499, F1 Micro: 0.3333, F1 Macro: 0.3282, Accuracy: 0.3333\n","Epoch 56, Train Loss: 1.3852, Val Loss: 1.7379, F1 Micro: 0.3750, F1 Macro: 0.3811, Accuracy: 0.3750\n","Epoch 57, Train Loss: 1.3959, Val Loss: 1.7607, F1 Micro: 0.3750, F1 Macro: 0.3838, Accuracy: 0.3750\n","Epoch 58, Train Loss: 1.3568, Val Loss: 1.7072, F1 Micro: 0.4167, F1 Macro: 0.3982, Accuracy: 0.4167\n","Epoch 59, Train Loss: 1.3593, Val Loss: 1.7763, F1 Micro: 0.3646, F1 Macro: 0.3510, Accuracy: 0.3646\n","Epoch 60, Train Loss: 1.3625, Val Loss: 1.8331, F1 Micro: 0.3958, F1 Macro: 0.3909, Accuracy: 0.3958\n","Epoch 61, Train Loss: 1.3405, Val Loss: 1.9916, F1 Micro: 0.3438, F1 Macro: 0.3033, Accuracy: 0.3438\n","Epoch 62, Train Loss: 1.3375, Val Loss: 1.7472, F1 Micro: 0.3646, F1 Macro: 0.3561, Accuracy: 0.3646\n","Epoch 63, Train Loss: 1.3523, Val Loss: 1.7885, F1 Micro: 0.3438, F1 Macro: 0.3261, Accuracy: 0.3438\n","Epoch 64, Train Loss: 1.3149, Val Loss: 1.8157, F1 Micro: 0.3229, F1 Macro: 0.3157, Accuracy: 0.3229\n","Epoch 65, Train Loss: 1.3508, Val Loss: 1.8181, F1 Micro: 0.3646, F1 Macro: 0.3525, Accuracy: 0.3646\n","Epoch 66, Train Loss: 1.3219, Val Loss: 1.8648, F1 Micro: 0.3646, F1 Macro: 0.3255, Accuracy: 0.3646\n","Epoch 67, Train Loss: 1.2787, Val Loss: 1.8946, F1 Micro: 0.3646, F1 Macro: 0.3446, Accuracy: 0.3646\n","Epoch 68, Train Loss: 1.2991, Val Loss: 1.7281, F1 Micro: 0.4479, F1 Macro: 0.4489, Accuracy: 0.4479\n","Epoch 69, Train Loss: 1.3048, Val Loss: 1.8077, F1 Micro: 0.3542, F1 Macro: 0.3540, Accuracy: 0.3542\n","Epoch 70, Train Loss: 1.2736, Val Loss: 1.7875, F1 Micro: 0.3854, F1 Macro: 0.3892, Accuracy: 0.3854\n","Epoch 71, Train Loss: 1.3131, Val Loss: 1.8502, F1 Micro: 0.3646, F1 Macro: 0.3679, Accuracy: 0.3646\n","Epoch 72, Train Loss: 1.2728, Val Loss: 1.8076, F1 Micro: 0.3229, F1 Macro: 0.3110, Accuracy: 0.3229\n","Epoch 73, Train Loss: 1.2888, Val Loss: 1.9224, F1 Micro: 0.3750, F1 Macro: 0.3573, Accuracy: 0.3750\n","Epoch 74, Train Loss: 1.2149, Val Loss: 2.0653, F1 Micro: 0.3646, F1 Macro: 0.3379, Accuracy: 0.3646\n","Epoch 75, Train Loss: 1.2749, Val Loss: 1.9439, F1 Micro: 0.3854, F1 Macro: 0.3758, Accuracy: 0.3854\n","Epoch 76, Train Loss: 1.2694, Val Loss: 1.9223, F1 Micro: 0.3854, F1 Macro: 0.3687, Accuracy: 0.3854\n","Epoch 77, Train Loss: 1.2115, Val Loss: 1.7908, F1 Micro: 0.4479, F1 Macro: 0.4419, Accuracy: 0.4479\n","Epoch 78, Train Loss: 1.2548, Val Loss: 1.7591, F1 Micro: 0.4583, F1 Macro: 0.4222, Accuracy: 0.4583\n","Epoch 79, Train Loss: 1.1939, Val Loss: 1.7695, F1 Micro: 0.4062, F1 Macro: 0.3960, Accuracy: 0.4062\n","Epoch 80, Train Loss: 1.2194, Val Loss: 1.9075, F1 Micro: 0.4271, F1 Macro: 0.3984, Accuracy: 0.4271\n","Epoch 81, Train Loss: 1.2351, Val Loss: 1.8041, F1 Micro: 0.4479, F1 Macro: 0.4340, Accuracy: 0.4479\n","Epoch 82, Train Loss: 1.2825, Val Loss: 1.8325, F1 Micro: 0.4271, F1 Macro: 0.4203, Accuracy: 0.4271\n","Epoch 83, Train Loss: 1.2209, Val Loss: 1.7825, F1 Micro: 0.4375, F1 Macro: 0.4254, Accuracy: 0.4375\n","Epoch 84, Train Loss: 1.1667, Val Loss: 1.7424, F1 Micro: 0.4583, F1 Macro: 0.4475, Accuracy: 0.4583\n","Epoch 85, Train Loss: 1.1881, Val Loss: 1.8579, F1 Micro: 0.3854, F1 Macro: 0.3521, Accuracy: 0.3854\n","Epoch 86, Train Loss: 1.1647, Val Loss: 1.8367, F1 Micro: 0.4271, F1 Macro: 0.4336, Accuracy: 0.4271\n","Epoch 87, Train Loss: 1.2256, Val Loss: 1.9227, F1 Micro: 0.3854, F1 Macro: 0.3783, Accuracy: 0.3854\n","Epoch 88, Train Loss: 1.1427, Val Loss: 1.8319, F1 Micro: 0.3958, F1 Macro: 0.3790, Accuracy: 0.3958\n","Epoch 89, Train Loss: 1.1365, Val Loss: 1.7489, F1 Micro: 0.4271, F1 Macro: 0.4043, Accuracy: 0.4271\n","Epoch 90, Train Loss: 1.1222, Val Loss: 1.7754, F1 Micro: 0.4167, F1 Macro: 0.4165, Accuracy: 0.4167\n","Epoch 91, Train Loss: 1.1474, Val Loss: 1.7428, F1 Micro: 0.4375, F1 Macro: 0.4196, Accuracy: 0.4375\n","Epoch 92, Train Loss: 1.1316, Val Loss: 2.0405, F1 Micro: 0.3854, F1 Macro: 0.3734, Accuracy: 0.3854\n","Epoch 93, Train Loss: 1.1171, Val Loss: 1.7412, F1 Micro: 0.5000, F1 Macro: 0.4841, Accuracy: 0.5000\n","Epoch 94, Train Loss: 1.1173, Val Loss: 1.6902, F1 Micro: 0.4583, F1 Macro: 0.4577, Accuracy: 0.4583\n","Epoch 95, Train Loss: 1.1628, Val Loss: 1.8427, F1 Micro: 0.4062, F1 Macro: 0.3967, Accuracy: 0.4062\n","Epoch 96, Train Loss: 1.1509, Val Loss: 1.9190, F1 Micro: 0.3854, F1 Macro: 0.3212, Accuracy: 0.3854\n","Epoch 97, Train Loss: 1.1171, Val Loss: 1.8859, F1 Micro: 0.4062, F1 Macro: 0.3813, Accuracy: 0.4062\n","Epoch 98, Train Loss: 1.1158, Val Loss: 1.8978, F1 Micro: 0.3958, F1 Macro: 0.3788, Accuracy: 0.3958\n","Epoch 99, Train Loss: 1.0720, Val Loss: 1.7963, F1 Micro: 0.4583, F1 Macro: 0.4280, Accuracy: 0.4583\n","Epoch 100, Train Loss: 1.0827, Val Loss: 1.9016, F1 Micro: 0.5000, F1 Macro: 0.4817, Accuracy: 0.5000\n","Epoch 101, Train Loss: 1.0990, Val Loss: 1.9453, F1 Micro: 0.3854, F1 Macro: 0.3742, Accuracy: 0.3854\n","Epoch 102, Train Loss: 1.1525, Val Loss: 1.8084, F1 Micro: 0.4271, F1 Macro: 0.3916, Accuracy: 0.4271\n","Epoch 103, Train Loss: 1.1485, Val Loss: 1.8585, F1 Micro: 0.4792, F1 Macro: 0.4553, Accuracy: 0.4792\n","Epoch 104, Train Loss: 1.0828, Val Loss: 1.9044, F1 Micro: 0.4375, F1 Macro: 0.4348, Accuracy: 0.4375\n","Epoch 105, Train Loss: 1.0477, Val Loss: 1.7638, F1 Micro: 0.4688, F1 Macro: 0.4598, Accuracy: 0.4688\n","Epoch 106, Train Loss: 1.0565, Val Loss: 1.8251, F1 Micro: 0.3958, F1 Macro: 0.3963, Accuracy: 0.3958\n","Epoch 107, Train Loss: 1.0551, Val Loss: 1.8252, F1 Micro: 0.5000, F1 Macro: 0.5043, Accuracy: 0.5000\n","Epoch 108, Train Loss: 1.0598, Val Loss: 1.7010, F1 Micro: 0.5000, F1 Macro: 0.4984, Accuracy: 0.5000\n","Epoch 109, Train Loss: 1.0215, Val Loss: 1.8211, F1 Micro: 0.4792, F1 Macro: 0.4661, Accuracy: 0.4792\n","Epoch 110, Train Loss: 1.0249, Val Loss: 1.7598, F1 Micro: 0.4583, F1 Macro: 0.4342, Accuracy: 0.4583\n","Epoch 111, Train Loss: 1.0457, Val Loss: 1.7974, F1 Micro: 0.5104, F1 Macro: 0.5050, Accuracy: 0.5104\n","Epoch 112, Train Loss: 1.0018, Val Loss: 1.8530, F1 Micro: 0.4375, F1 Macro: 0.4207, Accuracy: 0.4375\n","Epoch 113, Train Loss: 0.9985, Val Loss: 1.8526, F1 Micro: 0.4375, F1 Macro: 0.4410, Accuracy: 0.4375\n","Epoch 114, Train Loss: 0.9837, Val Loss: 2.0373, F1 Micro: 0.4375, F1 Macro: 0.4299, Accuracy: 0.4375\n","Epoch 115, Train Loss: 0.9886, Val Loss: 1.8740, F1 Micro: 0.4688, F1 Macro: 0.4486, Accuracy: 0.4688\n","Epoch 116, Train Loss: 0.9707, Val Loss: 2.0502, F1 Micro: 0.4271, F1 Macro: 0.4395, Accuracy: 0.4271\n","Epoch 117, Train Loss: 1.0964, Val Loss: 2.1086, F1 Micro: 0.3854, F1 Macro: 0.3590, Accuracy: 0.3854\n","Epoch 118, Train Loss: 1.0140, Val Loss: 1.8598, F1 Micro: 0.4479, F1 Macro: 0.4472, Accuracy: 0.4479\n","Epoch 119, Train Loss: 0.9135, Val Loss: 1.8139, F1 Micro: 0.4792, F1 Macro: 0.4724, Accuracy: 0.4792\n","Epoch 120, Train Loss: 0.9497, Val Loss: 1.9920, F1 Micro: 0.3854, F1 Macro: 0.3659, Accuracy: 0.3854\n","Epoch 121, Train Loss: 0.9543, Val Loss: 1.8671, F1 Micro: 0.4583, F1 Macro: 0.4340, Accuracy: 0.4583\n","Epoch 122, Train Loss: 1.0154, Val Loss: 1.9284, F1 Micro: 0.4583, F1 Macro: 0.4541, Accuracy: 0.4583\n","Epoch 123, Train Loss: 0.9337, Val Loss: 1.8334, F1 Micro: 0.5312, F1 Macro: 0.5212, Accuracy: 0.5312\n","Epoch 124, Train Loss: 0.9428, Val Loss: 1.8890, F1 Micro: 0.4688, F1 Macro: 0.4823, Accuracy: 0.4688\n","Epoch 125, Train Loss: 0.9340, Val Loss: 1.8885, F1 Micro: 0.4688, F1 Macro: 0.4529, Accuracy: 0.4688\n","Epoch 126, Train Loss: 0.9201, Val Loss: 1.9590, F1 Micro: 0.4896, F1 Macro: 0.4896, Accuracy: 0.4896\n","Epoch 127, Train Loss: 0.9296, Val Loss: 1.8482, F1 Micro: 0.5000, F1 Macro: 0.5014, Accuracy: 0.5000\n","Epoch 128, Train Loss: 0.8976, Val Loss: 2.1226, F1 Micro: 0.5104, F1 Macro: 0.5080, Accuracy: 0.5104\n","Epoch 129, Train Loss: 0.9476, Val Loss: 1.8956, F1 Micro: 0.4896, F1 Macro: 0.4800, Accuracy: 0.4896\n","Epoch 130, Train Loss: 0.9800, Val Loss: 1.9728, F1 Micro: 0.4479, F1 Macro: 0.4376, Accuracy: 0.4479\n","Epoch 131, Train Loss: 0.8663, Val Loss: 1.9768, F1 Micro: 0.4583, F1 Macro: 0.4552, Accuracy: 0.4583\n","Epoch 132, Train Loss: 0.9750, Val Loss: 1.9946, F1 Micro: 0.4375, F1 Macro: 0.4339, Accuracy: 0.4375\n","Epoch 133, Train Loss: 0.8917, Val Loss: 1.8274, F1 Micro: 0.5208, F1 Macro: 0.5134, Accuracy: 0.5208\n","Epoch 134, Train Loss: 0.8977, Val Loss: 2.0794, F1 Micro: 0.3750, F1 Macro: 0.3576, Accuracy: 0.3750\n","Epoch 135, Train Loss: 0.9546, Val Loss: 1.8850, F1 Micro: 0.4583, F1 Macro: 0.4363, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.9060, Val Loss: 2.0416, F1 Micro: 0.4479, F1 Macro: 0.4445, Accuracy: 0.4479\n","Epoch 137, Train Loss: 0.9330, Val Loss: 1.9408, F1 Micro: 0.4479, F1 Macro: 0.4541, Accuracy: 0.4479\n","Epoch 138, Train Loss: 0.8159, Val Loss: 1.9017, F1 Micro: 0.4688, F1 Macro: 0.4700, Accuracy: 0.4688\n","Epoch 139, Train Loss: 0.8550, Val Loss: 1.9048, F1 Micro: 0.4688, F1 Macro: 0.4723, Accuracy: 0.4688\n","Epoch 140, Train Loss: 0.8486, Val Loss: 1.8990, F1 Micro: 0.4896, F1 Macro: 0.4821, Accuracy: 0.4896\n","Epoch 141, Train Loss: 0.8436, Val Loss: 2.0992, F1 Micro: 0.4062, F1 Macro: 0.3885, Accuracy: 0.4062\n","Epoch 142, Train Loss: 0.8973, Val Loss: 1.8758, F1 Micro: 0.4792, F1 Macro: 0.4933, Accuracy: 0.4792\n","Epoch 143, Train Loss: 0.9091, Val Loss: 1.9540, F1 Micro: 0.5000, F1 Macro: 0.4956, Accuracy: 0.5000\n","Epoch 144, Train Loss: 0.9748, Val Loss: 1.9560, F1 Micro: 0.4896, F1 Macro: 0.4903, Accuracy: 0.4896\n","Epoch 145, Train Loss: 0.8130, Val Loss: 1.9035, F1 Micro: 0.5312, F1 Macro: 0.5393, Accuracy: 0.5312\n","Epoch 146, Train Loss: 0.8459, Val Loss: 1.9171, F1 Micro: 0.5000, F1 Macro: 0.4839, Accuracy: 0.5000\n","Epoch 147, Train Loss: 0.7896, Val Loss: 1.8557, F1 Micro: 0.5104, F1 Macro: 0.5186, Accuracy: 0.5104\n","Epoch 148, Train Loss: 0.8479, Val Loss: 2.0836, F1 Micro: 0.4062, F1 Macro: 0.3640, Accuracy: 0.4062\n","Epoch 149, Train Loss: 0.8306, Val Loss: 1.9438, F1 Micro: 0.4896, F1 Macro: 0.4748, Accuracy: 0.4896\n","Epoch 150, Train Loss: 0.8877, Val Loss: 1.9044, F1 Micro: 0.4896, F1 Macro: 0.4874, Accuracy: 0.4896\n","Epoch 151, Train Loss: 0.8385, Val Loss: 1.8771, F1 Micro: 0.5104, F1 Macro: 0.5169, Accuracy: 0.5104\n","Epoch 152, Train Loss: 0.8184, Val Loss: 1.9948, F1 Micro: 0.5000, F1 Macro: 0.4876, Accuracy: 0.5000\n","Epoch 153, Train Loss: 0.8965, Val Loss: 2.0578, F1 Micro: 0.5417, F1 Macro: 0.5397, Accuracy: 0.5417\n","Epoch 154, Train Loss: 0.7821, Val Loss: 1.9805, F1 Micro: 0.4688, F1 Macro: 0.4657, Accuracy: 0.4688\n","Epoch 155, Train Loss: 0.8302, Val Loss: 2.2298, F1 Micro: 0.4583, F1 Macro: 0.4503, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.8522, Val Loss: 2.0388, F1 Micro: 0.5312, F1 Macro: 0.5411, Accuracy: 0.5312\n","Epoch 157, Train Loss: 0.7592, Val Loss: 2.0194, F1 Micro: 0.5208, F1 Macro: 0.5275, Accuracy: 0.5208\n","Epoch 158, Train Loss: 0.8330, Val Loss: 1.9041, F1 Micro: 0.4896, F1 Macro: 0.4841, Accuracy: 0.4896\n","Epoch 159, Train Loss: 0.7751, Val Loss: 1.9010, F1 Micro: 0.5729, F1 Macro: 0.5716, Accuracy: 0.5729\n","Epoch 160, Train Loss: 0.8240, Val Loss: 2.1039, F1 Micro: 0.4375, F1 Macro: 0.4425, Accuracy: 0.4375\n","Epoch 161, Train Loss: 0.7833, Val Loss: 2.0791, F1 Micro: 0.5104, F1 Macro: 0.5104, Accuracy: 0.5104\n","Epoch 162, Train Loss: 0.8144, Val Loss: 2.1884, F1 Micro: 0.4896, F1 Macro: 0.4762, Accuracy: 0.4896\n","Epoch 163, Train Loss: 0.8219, Val Loss: 2.0944, F1 Micro: 0.5104, F1 Macro: 0.5219, Accuracy: 0.5104\n","Epoch 164, Train Loss: 0.7664, Val Loss: 2.0890, F1 Micro: 0.4479, F1 Macro: 0.4530, Accuracy: 0.4479\n","Epoch 165, Train Loss: 0.7569, Val Loss: 2.1067, F1 Micro: 0.4792, F1 Macro: 0.4660, Accuracy: 0.4792\n","Epoch 166, Train Loss: 0.7728, Val Loss: 1.9656, F1 Micro: 0.5312, F1 Macro: 0.5416, Accuracy: 0.5312\n","Epoch 167, Train Loss: 0.7357, Val Loss: 1.9708, F1 Micro: 0.5417, F1 Macro: 0.5513, Accuracy: 0.5417\n","Epoch 168, Train Loss: 0.7483, Val Loss: 2.1801, F1 Micro: 0.5208, F1 Macro: 0.5313, Accuracy: 0.5208\n","Epoch 169, Train Loss: 0.7553, Val Loss: 2.0497, F1 Micro: 0.4792, F1 Macro: 0.4702, Accuracy: 0.4792\n","Epoch 170, Train Loss: 0.8308, Val Loss: 2.0741, F1 Micro: 0.4583, F1 Macro: 0.4569, Accuracy: 0.4583\n","Epoch 171, Train Loss: 0.6948, Val Loss: 2.1929, F1 Micro: 0.5104, F1 Macro: 0.5220, Accuracy: 0.5104\n","Epoch 172, Train Loss: 0.8271, Val Loss: 2.0566, F1 Micro: 0.5312, F1 Macro: 0.5254, Accuracy: 0.5312\n","Epoch 173, Train Loss: 0.7325, Val Loss: 1.9823, F1 Micro: 0.4896, F1 Macro: 0.4852, Accuracy: 0.4896\n","Epoch 174, Train Loss: 0.7301, Val Loss: 1.9169, F1 Micro: 0.5625, F1 Macro: 0.5642, Accuracy: 0.5625\n","Epoch 175, Train Loss: 0.7645, Val Loss: 2.3728, F1 Micro: 0.4583, F1 Macro: 0.4544, Accuracy: 0.4583\n","Epoch 176, Train Loss: 0.7475, Val Loss: 2.0512, F1 Micro: 0.5104, F1 Macro: 0.5265, Accuracy: 0.5104\n","Epoch 177, Train Loss: 0.7185, Val Loss: 1.9628, F1 Micro: 0.5208, F1 Macro: 0.5075, Accuracy: 0.5208\n","Epoch 178, Train Loss: 0.6967, Val Loss: 2.2014, F1 Micro: 0.5521, F1 Macro: 0.5544, Accuracy: 0.5521\n","Epoch 179, Train Loss: 0.7308, Val Loss: 2.0900, F1 Micro: 0.5208, F1 Macro: 0.5249, Accuracy: 0.5208\n","Epoch 180, Train Loss: 0.6752, Val Loss: 1.9004, F1 Micro: 0.5417, F1 Macro: 0.5426, Accuracy: 0.5417\n","Epoch 181, Train Loss: 0.6398, Val Loss: 1.9635, F1 Micro: 0.5729, F1 Macro: 0.5750, Accuracy: 0.5729\n","Epoch 182, Train Loss: 0.6592, Val Loss: 2.3014, F1 Micro: 0.4792, F1 Macro: 0.4785, Accuracy: 0.4792\n","Epoch 183, Train Loss: 0.7455, Val Loss: 2.1830, F1 Micro: 0.4583, F1 Macro: 0.4449, Accuracy: 0.4583\n","Epoch 184, Train Loss: 0.7867, Val Loss: 2.2389, F1 Micro: 0.4792, F1 Macro: 0.4722, Accuracy: 0.4792\n","Epoch 185, Train Loss: 0.7259, Val Loss: 2.1045, F1 Micro: 0.5312, F1 Macro: 0.5315, Accuracy: 0.5312\n","Epoch 186, Train Loss: 0.6941, Val Loss: 2.0431, F1 Micro: 0.5521, F1 Macro: 0.5452, Accuracy: 0.5521\n","Epoch 187, Train Loss: 0.6552, Val Loss: 2.1519, F1 Micro: 0.5833, F1 Macro: 0.5881, Accuracy: 0.5833\n","Epoch 188, Train Loss: 0.7481, Val Loss: 2.4899, F1 Micro: 0.4167, F1 Macro: 0.4145, Accuracy: 0.4167\n","Epoch 189, Train Loss: 0.7976, Val Loss: 2.2943, F1 Micro: 0.5000, F1 Macro: 0.4993, Accuracy: 0.5000\n","Epoch 190, Train Loss: 0.6707, Val Loss: 2.2398, F1 Micro: 0.5104, F1 Macro: 0.5230, Accuracy: 0.5104\n","Epoch 191, Train Loss: 0.5936, Val Loss: 2.1555, F1 Micro: 0.5312, F1 Macro: 0.5352, Accuracy: 0.5312\n","Epoch 192, Train Loss: 0.6823, Val Loss: 2.3151, F1 Micro: 0.5417, F1 Macro: 0.5179, Accuracy: 0.5417\n","Epoch 193, Train Loss: 0.6456, Val Loss: 1.9967, F1 Micro: 0.5521, F1 Macro: 0.5554, Accuracy: 0.5521\n","Epoch 194, Train Loss: 0.5857, Val Loss: 2.0495, F1 Micro: 0.5521, F1 Macro: 0.5596, Accuracy: 0.5521\n","Epoch 195, Train Loss: 0.6570, Val Loss: 2.2844, F1 Micro: 0.5104, F1 Macro: 0.5049, Accuracy: 0.5104\n","Epoch 196, Train Loss: 0.6267, Val Loss: 2.1088, F1 Micro: 0.5208, F1 Macro: 0.5303, Accuracy: 0.5208\n","Epoch 197, Train Loss: 0.5705, Val Loss: 2.4068, F1 Micro: 0.4583, F1 Macro: 0.4491, Accuracy: 0.4583\n","Epoch 198, Train Loss: 0.5947, Val Loss: 2.3095, F1 Micro: 0.4688, F1 Macro: 0.4548, Accuracy: 0.4688\n","Epoch 199, Train Loss: 0.5864, Val Loss: 2.3279, F1 Micro: 0.5521, F1 Macro: 0.5528, Accuracy: 0.5521\n","Epoch 200, Train Loss: 0.7075, Val Loss: 2.1573, F1 Micro: 0.5521, F1 Macro: 0.5563, Accuracy: 0.5521\n","Average Score for hyperparameters (0.001, 8, 50): 0.5833333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.1507, Val Loss: 2.7821, F1 Micro: 0.1979, F1 Macro: 0.1596, Accuracy: 0.1979\n","Epoch 2, Train Loss: 2.4938, Val Loss: 1.9994, F1 Micro: 0.2500, F1 Macro: 0.1601, Accuracy: 0.2500\n","Epoch 3, Train Loss: 2.2042, Val Loss: 1.8771, F1 Micro: 0.2604, F1 Macro: 0.1890, Accuracy: 0.2604\n","Epoch 4, Train Loss: 2.0220, Val Loss: 1.7159, F1 Micro: 0.2604, F1 Macro: 0.1992, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.9817, Val Loss: 1.7386, F1 Micro: 0.2708, F1 Macro: 0.1875, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.9150, Val Loss: 1.7538, F1 Micro: 0.2500, F1 Macro: 0.2086, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.8927, Val Loss: 1.7429, F1 Micro: 0.2812, F1 Macro: 0.2170, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.8287, Val Loss: 1.7840, F1 Micro: 0.2917, F1 Macro: 0.2483, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.8104, Val Loss: 1.8063, F1 Micro: 0.2083, F1 Macro: 0.1406, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.8515, Val Loss: 1.8633, F1 Micro: 0.2500, F1 Macro: 0.2005, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.7501, Val Loss: 1.7422, F1 Micro: 0.2812, F1 Macro: 0.2488, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.7026, Val Loss: 1.8462, F1 Micro: 0.2292, F1 Macro: 0.1846, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.7438, Val Loss: 1.8002, F1 Micro: 0.2812, F1 Macro: 0.2407, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.7199, Val Loss: 1.7738, F1 Micro: 0.2917, F1 Macro: 0.2309, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.6810, Val Loss: 1.7437, F1 Micro: 0.2396, F1 Macro: 0.2040, Accuracy: 0.2396\n","Epoch 16, Train Loss: 1.7020, Val Loss: 1.7741, F1 Micro: 0.2917, F1 Macro: 0.2593, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.6877, Val Loss: 1.7530, F1 Micro: 0.2292, F1 Macro: 0.2109, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.7041, Val Loss: 1.6408, F1 Micro: 0.3333, F1 Macro: 0.2782, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.6310, Val Loss: 1.6577, F1 Micro: 0.3542, F1 Macro: 0.3258, Accuracy: 0.3542\n","Epoch 20, Train Loss: 1.6661, Val Loss: 1.6754, F1 Micro: 0.3229, F1 Macro: 0.2526, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.6661, Val Loss: 1.6786, F1 Micro: 0.2917, F1 Macro: 0.2547, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.6506, Val Loss: 1.6939, F1 Micro: 0.3229, F1 Macro: 0.2590, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.6192, Val Loss: 1.7279, F1 Micro: 0.2812, F1 Macro: 0.2295, Accuracy: 0.2812\n","Epoch 24, Train Loss: 1.6439, Val Loss: 1.6484, F1 Micro: 0.3125, F1 Macro: 0.2765, Accuracy: 0.3125\n","Epoch 25, Train Loss: 1.6109, Val Loss: 1.7343, F1 Micro: 0.2500, F1 Macro: 0.1982, Accuracy: 0.2500\n","Epoch 26, Train Loss: 1.6676, Val Loss: 1.6337, F1 Micro: 0.3021, F1 Macro: 0.2698, Accuracy: 0.3021\n","Epoch 27, Train Loss: 1.6375, Val Loss: 1.6744, F1 Micro: 0.3438, F1 Macro: 0.2952, Accuracy: 0.3438\n","Epoch 28, Train Loss: 1.6319, Val Loss: 1.6662, F1 Micro: 0.3229, F1 Macro: 0.2854, Accuracy: 0.3229\n","Epoch 29, Train Loss: 1.6061, Val Loss: 1.7027, F1 Micro: 0.2812, F1 Macro: 0.2885, Accuracy: 0.2812\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.3192, Val Loss: 2.2476, F1 Micro: 0.2708, F1 Macro: 0.1820, Accuracy: 0.2708\n","Epoch 2, Train Loss: 2.4415, Val Loss: 2.1402, F1 Micro: 0.2500, F1 Macro: 0.1337, Accuracy: 0.2500\n","Epoch 3, Train Loss: 2.0693, Val Loss: 1.9566, F1 Micro: 0.2292, F1 Macro: 0.1680, Accuracy: 0.2292\n","Epoch 4, Train Loss: 2.0854, Val Loss: 1.8260, F1 Micro: 0.2500, F1 Macro: 0.2066, Accuracy: 0.2500\n","Epoch 5, Train Loss: 2.0569, Val Loss: 1.7840, F1 Micro: 0.2917, F1 Macro: 0.2029, Accuracy: 0.2917\n","Epoch 6, Train Loss: 1.9738, Val Loss: 2.1111, F1 Micro: 0.2188, F1 Macro: 0.1698, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.8664, Val Loss: 2.0180, F1 Micro: 0.1458, F1 Macro: 0.1015, Accuracy: 0.1458\n","Epoch 8, Train Loss: 1.8884, Val Loss: 1.8247, F1 Micro: 0.2396, F1 Macro: 0.2080, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.8290, Val Loss: 1.5889, F1 Micro: 0.3125, F1 Macro: 0.2444, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.9251, Val Loss: 1.7626, F1 Micro: 0.2500, F1 Macro: 0.1620, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.8617, Val Loss: 1.6957, F1 Micro: 0.2708, F1 Macro: 0.2260, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.7718, Val Loss: 1.7164, F1 Micro: 0.2917, F1 Macro: 0.2291, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.8005, Val Loss: 1.7718, F1 Micro: 0.2083, F1 Macro: 0.1779, Accuracy: 0.2083\n","Epoch 14, Train Loss: 1.8145, Val Loss: 1.5931, F1 Micro: 0.3229, F1 Macro: 0.2044, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.7417, Val Loss: 1.6789, F1 Micro: 0.2917, F1 Macro: 0.2463, Accuracy: 0.2917\n","Epoch 16, Train Loss: 1.7128, Val Loss: 1.6161, F1 Micro: 0.3333, F1 Macro: 0.2830, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.7455, Val Loss: 1.7271, F1 Micro: 0.1979, F1 Macro: 0.1529, Accuracy: 0.1979\n","Epoch 18, Train Loss: 1.7217, Val Loss: 1.5719, F1 Micro: 0.4062, F1 Macro: 0.3532, Accuracy: 0.4062\n","Epoch 19, Train Loss: 1.7106, Val Loss: 1.5949, F1 Micro: 0.4375, F1 Macro: 0.3713, Accuracy: 0.4375\n","Epoch 20, Train Loss: 1.7141, Val Loss: 1.7482, F1 Micro: 0.2188, F1 Macro: 0.1714, Accuracy: 0.2188\n","Epoch 21, Train Loss: 1.7002, Val Loss: 1.7708, F1 Micro: 0.1875, F1 Macro: 0.1734, Accuracy: 0.1875\n","Epoch 22, Train Loss: 1.6772, Val Loss: 1.7184, F1 Micro: 0.2604, F1 Macro: 0.2227, Accuracy: 0.2604\n","Epoch 23, Train Loss: 1.7139, Val Loss: 1.7427, F1 Micro: 0.2083, F1 Macro: 0.1704, Accuracy: 0.2083\n","Epoch 24, Train Loss: 1.6839, Val Loss: 1.7058, F1 Micro: 0.2917, F1 Macro: 0.2322, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.6803, Val Loss: 1.5758, F1 Micro: 0.3854, F1 Macro: 0.3083, Accuracy: 0.3854\n","Epoch 26, Train Loss: 1.6882, Val Loss: 1.6594, F1 Micro: 0.3333, F1 Macro: 0.2433, Accuracy: 0.3333\n","Epoch 27, Train Loss: 1.6972, Val Loss: 1.6431, F1 Micro: 0.3438, F1 Macro: 0.3020, Accuracy: 0.3438\n","Epoch 28, Train Loss: 1.6866, Val Loss: 1.7331, F1 Micro: 0.3229, F1 Macro: 0.2744, Accuracy: 0.3229\n","Epoch 29, Train Loss: 1.7352, Val Loss: 1.6754, F1 Micro: 0.2292, F1 Macro: 0.1984, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.0742, Val Loss: 2.2969, F1 Micro: 0.2083, F1 Macro: 0.1584, Accuracy: 0.2083\n","Epoch 2, Train Loss: 2.4681, Val Loss: 2.4597, F1 Micro: 0.1250, F1 Macro: 0.0869, Accuracy: 0.1250\n","Epoch 3, Train Loss: 2.2028, Val Loss: 2.1396, F1 Micro: 0.2500, F1 Macro: 0.1511, Accuracy: 0.2500\n","Epoch 4, Train Loss: 2.0502, Val Loss: 1.9547, F1 Micro: 0.2917, F1 Macro: 0.1670, Accuracy: 0.2917\n","Epoch 5, Train Loss: 1.9528, Val Loss: 2.0327, F1 Micro: 0.2708, F1 Macro: 0.2150, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.9468, Val Loss: 1.9354, F1 Micro: 0.1875, F1 Macro: 0.1340, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.8783, Val Loss: 1.8620, F1 Micro: 0.3125, F1 Macro: 0.1875, Accuracy: 0.3125\n","Epoch 8, Train Loss: 1.8173, Val Loss: 1.9494, F1 Micro: 0.2083, F1 Macro: 0.1519, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.7938, Val Loss: 1.8662, F1 Micro: 0.2396, F1 Macro: 0.2149, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.7683, Val Loss: 1.7761, F1 Micro: 0.2812, F1 Macro: 0.1946, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.7467, Val Loss: 1.9181, F1 Micro: 0.2292, F1 Macro: 0.1326, Accuracy: 0.2292\n","Epoch 12, Train Loss: 1.7319, Val Loss: 1.7942, F1 Micro: 0.2812, F1 Macro: 0.2443, Accuracy: 0.2812\n","Epoch 13, Train Loss: 1.7358, Val Loss: 1.8699, F1 Micro: 0.1979, F1 Macro: 0.1704, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.7369, Val Loss: 2.0378, F1 Micro: 0.2083, F1 Macro: 0.1860, Accuracy: 0.2083\n","Epoch 15, Train Loss: 1.6846, Val Loss: 1.8839, F1 Micro: 0.2500, F1 Macro: 0.1952, Accuracy: 0.2500\n","Epoch 16, Train Loss: 1.6905, Val Loss: 1.7842, F1 Micro: 0.2604, F1 Macro: 0.2109, Accuracy: 0.2604\n","Epoch 17, Train Loss: 1.6752, Val Loss: 1.8167, F1 Micro: 0.2292, F1 Macro: 0.1423, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.6984, Val Loss: 2.6259, F1 Micro: 0.1979, F1 Macro: 0.1523, Accuracy: 0.1979\n","Epoch 2, Train Loss: 2.2996, Val Loss: 1.9592, F1 Micro: 0.2083, F1 Macro: 0.1584, Accuracy: 0.2083\n","Epoch 3, Train Loss: 2.2321, Val Loss: 2.0489, F1 Micro: 0.1875, F1 Macro: 0.0869, Accuracy: 0.1875\n","Epoch 4, Train Loss: 2.1826, Val Loss: 1.8259, F1 Micro: 0.2708, F1 Macro: 0.2153, Accuracy: 0.2708\n","Epoch 5, Train Loss: 2.0626, Val Loss: 2.2186, F1 Micro: 0.1979, F1 Macro: 0.1287, Accuracy: 0.1979\n","Epoch 6, Train Loss: 1.8956, Val Loss: 1.8815, F1 Micro: 0.1875, F1 Macro: 0.1506, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.8393, Val Loss: 2.0253, F1 Micro: 0.2604, F1 Macro: 0.1719, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.8785, Val Loss: 2.0185, F1 Micro: 0.2604, F1 Macro: 0.1826, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.9021, Val Loss: 1.9326, F1 Micro: 0.2500, F1 Macro: 0.1876, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.7563, Val Loss: 1.7853, F1 Micro: 0.3021, F1 Macro: 0.2499, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.8450, Val Loss: 1.9644, F1 Micro: 0.2917, F1 Macro: 0.1929, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.7823, Val Loss: 1.8006, F1 Micro: 0.2083, F1 Macro: 0.1542, Accuracy: 0.2083\n","Epoch 13, Train Loss: 1.7549, Val Loss: 1.7031, F1 Micro: 0.2917, F1 Macro: 0.2674, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.7451, Val Loss: 1.7109, F1 Micro: 0.3125, F1 Macro: 0.2584, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.7426, Val Loss: 1.7267, F1 Micro: 0.3438, F1 Macro: 0.2820, Accuracy: 0.3438\n","Epoch 16, Train Loss: 1.7610, Val Loss: 1.7332, F1 Micro: 0.2500, F1 Macro: 0.2100, Accuracy: 0.2500\n","Epoch 17, Train Loss: 1.6750, Val Loss: 1.6947, F1 Micro: 0.3333, F1 Macro: 0.2798, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.6768, Val Loss: 1.7408, F1 Micro: 0.3021, F1 Macro: 0.2572, Accuracy: 0.3021\n","Epoch 19, Train Loss: 1.6454, Val Loss: 1.8393, F1 Micro: 0.2188, F1 Macro: 0.1405, Accuracy: 0.2188\n","Epoch 20, Train Loss: 1.6997, Val Loss: 1.7018, F1 Micro: 0.3229, F1 Macro: 0.2650, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.7187, Val Loss: 1.9041, F1 Micro: 0.2500, F1 Macro: 0.1574, Accuracy: 0.2500\n","Epoch 22, Train Loss: 1.7074, Val Loss: 1.7144, F1 Micro: 0.2708, F1 Macro: 0.2061, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.6437, Val Loss: 1.7254, F1 Micro: 0.3125, F1 Macro: 0.2500, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.6335, Val Loss: 1.6908, F1 Micro: 0.2604, F1 Macro: 0.2196, Accuracy: 0.2604\n","Epoch 25, Train Loss: 1.6465, Val Loss: 1.6808, F1 Micro: 0.3438, F1 Macro: 0.2722, Accuracy: 0.3438\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.5262, Val Loss: 2.3703, F1 Micro: 0.1979, F1 Macro: 0.1322, Accuracy: 0.1979\n","Epoch 2, Train Loss: 2.2001, Val Loss: 2.0154, F1 Micro: 0.2083, F1 Macro: 0.1220, Accuracy: 0.2083\n","Epoch 3, Train Loss: 2.2909, Val Loss: 2.1630, F1 Micro: 0.2812, F1 Macro: 0.2401, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.9772, Val Loss: 1.7909, F1 Micro: 0.2396, F1 Macro: 0.2064, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.9064, Val Loss: 1.8931, F1 Micro: 0.2604, F1 Macro: 0.2337, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.9257, Val Loss: 2.0308, F1 Micro: 0.1771, F1 Macro: 0.0883, Accuracy: 0.1771\n","Epoch 7, Train Loss: 1.8077, Val Loss: 2.0937, F1 Micro: 0.2500, F1 Macro: 0.2026, Accuracy: 0.2500\n","Epoch 8, Train Loss: 1.8423, Val Loss: 1.9632, F1 Micro: 0.2083, F1 Macro: 0.1351, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.8538, Val Loss: 1.8872, F1 Micro: 0.2083, F1 Macro: 0.1846, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.7960, Val Loss: 1.8719, F1 Micro: 0.2500, F1 Macro: 0.2135, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.8334, Val Loss: 1.7837, F1 Micro: 0.2708, F1 Macro: 0.2414, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.7607, Val Loss: 2.0055, F1 Micro: 0.2083, F1 Macro: 0.1036, Accuracy: 0.2083\n","Epoch 13, Train Loss: 1.8214, Val Loss: 1.7524, F1 Micro: 0.2500, F1 Macro: 0.1993, Accuracy: 0.2500\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.3458333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.3470, Val Loss: 2.0672, F1 Micro: 0.2604, F1 Macro: 0.1781, Accuracy: 0.2604\n","Epoch 2, Train Loss: 2.2501, Val Loss: 2.3956, F1 Micro: 0.2500, F1 Macro: 0.1403, Accuracy: 0.2500\n","Epoch 3, Train Loss: 2.2647, Val Loss: 1.8866, F1 Micro: 0.2604, F1 Macro: 0.1870, Accuracy: 0.2604\n","Epoch 4, Train Loss: 2.0677, Val Loss: 1.7237, F1 Micro: 0.2292, F1 Macro: 0.2115, Accuracy: 0.2292\n","Epoch 5, Train Loss: 2.0496, Val Loss: 1.9196, F1 Micro: 0.2083, F1 Macro: 0.1252, Accuracy: 0.2083\n","Epoch 6, Train Loss: 2.1711, Val Loss: 1.9192, F1 Micro: 0.2812, F1 Macro: 0.1877, Accuracy: 0.2812\n","Epoch 7, Train Loss: 2.0211, Val Loss: 1.9644, F1 Micro: 0.2917, F1 Macro: 0.2613, Accuracy: 0.2917\n","Epoch 8, Train Loss: 1.8118, Val Loss: 1.7146, F1 Micro: 0.2708, F1 Macro: 0.2548, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.7246, Val Loss: 1.6871, F1 Micro: 0.2708, F1 Macro: 0.2268, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.7099, Val Loss: 1.7454, F1 Micro: 0.2604, F1 Macro: 0.2252, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.6779, Val Loss: 1.7619, F1 Micro: 0.2812, F1 Macro: 0.1920, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.8178, Val Loss: 1.7023, F1 Micro: 0.2812, F1 Macro: 0.2318, Accuracy: 0.2812\n","Epoch 13, Train Loss: 1.7062, Val Loss: 1.6938, F1 Micro: 0.2500, F1 Macro: 0.1946, Accuracy: 0.2500\n","Epoch 14, Train Loss: 1.8311, Val Loss: 1.7180, F1 Micro: 0.2708, F1 Macro: 0.1847, Accuracy: 0.2708\n","Epoch 15, Train Loss: 1.7403, Val Loss: 1.6692, F1 Micro: 0.2708, F1 Macro: 0.1961, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.6491, Val Loss: 1.7888, F1 Micro: 0.3021, F1 Macro: 0.2332, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.6853, Val Loss: 1.7043, F1 Micro: 0.2500, F1 Macro: 0.2117, Accuracy: 0.2500\n","Epoch 18, Train Loss: 1.7083, Val Loss: 1.6639, F1 Micro: 0.3333, F1 Macro: 0.3134, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.7051, Val Loss: 1.6503, F1 Micro: 0.2604, F1 Macro: 0.2432, Accuracy: 0.2604\n","Epoch 20, Train Loss: 1.6928, Val Loss: 1.6586, F1 Micro: 0.3438, F1 Macro: 0.3392, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.6488, Val Loss: 1.6427, F1 Micro: 0.2917, F1 Macro: 0.2822, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.6653, Val Loss: 1.6948, F1 Micro: 0.2812, F1 Macro: 0.2602, Accuracy: 0.2812\n","Epoch 23, Train Loss: 1.6301, Val Loss: 1.6783, F1 Micro: 0.3021, F1 Macro: 0.2737, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.6324, Val Loss: 1.6582, F1 Micro: 0.3021, F1 Macro: 0.2718, Accuracy: 0.3021\n","Epoch 25, Train Loss: 1.6234, Val Loss: 1.7100, F1 Micro: 0.2708, F1 Macro: 0.2389, Accuracy: 0.2708\n","Epoch 26, Train Loss: 1.6212, Val Loss: 1.7706, F1 Micro: 0.2396, F1 Macro: 0.2015, Accuracy: 0.2396\n","Epoch 27, Train Loss: 1.6579, Val Loss: 1.7163, F1 Micro: 0.3125, F1 Macro: 0.3201, Accuracy: 0.3125\n","Epoch 28, Train Loss: 1.6391, Val Loss: 1.6993, F1 Micro: 0.2500, F1 Macro: 0.2338, Accuracy: 0.2500\n","Epoch 29, Train Loss: 1.6039, Val Loss: 1.6941, F1 Micro: 0.2917, F1 Macro: 0.2533, Accuracy: 0.2917\n","Epoch 30, Train Loss: 1.6312, Val Loss: 1.6972, F1 Micro: 0.3125, F1 Macro: 0.2842, Accuracy: 0.3125\n","Epoch 31, Train Loss: 1.5793, Val Loss: 1.7229, F1 Micro: 0.2708, F1 Macro: 0.2773, Accuracy: 0.2708\n","Epoch 32, Train Loss: 1.5711, Val Loss: 1.7340, F1 Micro: 0.3021, F1 Macro: 0.2518, Accuracy: 0.3021\n","Epoch 33, Train Loss: 1.5665, Val Loss: 1.6525, F1 Micro: 0.3646, F1 Macro: 0.3405, Accuracy: 0.3646\n","Epoch 34, Train Loss: 1.5494, Val Loss: 1.6665, F1 Micro: 0.3229, F1 Macro: 0.2895, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.5916, Val Loss: 1.6577, F1 Micro: 0.3021, F1 Macro: 0.3098, Accuracy: 0.3021\n","Epoch 36, Train Loss: 1.5589, Val Loss: 1.6752, F1 Micro: 0.3125, F1 Macro: 0.3110, Accuracy: 0.3125\n","Epoch 37, Train Loss: 1.5896, Val Loss: 1.7317, F1 Micro: 0.3229, F1 Macro: 0.2911, Accuracy: 0.3229\n","Epoch 38, Train Loss: 1.5672, Val Loss: 1.9071, F1 Micro: 0.2500, F1 Macro: 0.2093, Accuracy: 0.2500\n","Epoch 39, Train Loss: 1.5980, Val Loss: 1.6675, F1 Micro: 0.3438, F1 Macro: 0.3114, Accuracy: 0.3438\n","Epoch 40, Train Loss: 1.5600, Val Loss: 1.7094, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 41, Train Loss: 1.5252, Val Loss: 1.6694, F1 Micro: 0.3229, F1 Macro: 0.3246, Accuracy: 0.3229\n","Epoch 42, Train Loss: 1.5668, Val Loss: 1.7123, F1 Micro: 0.3021, F1 Macro: 0.2900, Accuracy: 0.3021\n","Epoch 43, Train Loss: 1.5446, Val Loss: 1.7211, F1 Micro: 0.2604, F1 Macro: 0.2386, Accuracy: 0.2604\n","Epoch 44, Train Loss: 1.5650, Val Loss: 1.6649, F1 Micro: 0.3646, F1 Macro: 0.3287, Accuracy: 0.3646\n","Epoch 45, Train Loss: 1.5072, Val Loss: 1.6276, F1 Micro: 0.3542, F1 Macro: 0.3393, Accuracy: 0.3542\n","Epoch 46, Train Loss: 1.5337, Val Loss: 1.6342, F1 Micro: 0.3958, F1 Macro: 0.3514, Accuracy: 0.3958\n","Epoch 47, Train Loss: 1.4988, Val Loss: 1.6660, F1 Micro: 0.3750, F1 Macro: 0.3276, Accuracy: 0.3750\n","Epoch 48, Train Loss: 1.4889, Val Loss: 1.7224, F1 Micro: 0.3646, F1 Macro: 0.3466, Accuracy: 0.3646\n","Epoch 49, Train Loss: 1.4989, Val Loss: 1.7044, F1 Micro: 0.3438, F1 Macro: 0.3324, Accuracy: 0.3438\n","Epoch 50, Train Loss: 1.4685, Val Loss: 1.6645, F1 Micro: 0.3542, F1 Macro: 0.3387, Accuracy: 0.3542\n","Epoch 51, Train Loss: 1.4810, Val Loss: 1.6853, F1 Micro: 0.3438, F1 Macro: 0.3296, Accuracy: 0.3438\n","Epoch 52, Train Loss: 1.5111, Val Loss: 1.7411, F1 Micro: 0.3646, F1 Macro: 0.3483, Accuracy: 0.3646\n","Epoch 53, Train Loss: 1.4780, Val Loss: 1.6479, F1 Micro: 0.4271, F1 Macro: 0.4216, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.4856, Val Loss: 1.7681, F1 Micro: 0.3021, F1 Macro: 0.3041, Accuracy: 0.3021\n","Epoch 55, Train Loss: 1.4327, Val Loss: 1.6647, F1 Micro: 0.3854, F1 Macro: 0.3714, Accuracy: 0.3854\n","Epoch 56, Train Loss: 1.4311, Val Loss: 1.6589, F1 Micro: 0.3333, F1 Macro: 0.3321, Accuracy: 0.3333\n","Epoch 57, Train Loss: 1.4469, Val Loss: 1.6386, F1 Micro: 0.3854, F1 Macro: 0.3704, Accuracy: 0.3854\n","Epoch 58, Train Loss: 1.4191, Val Loss: 1.6763, F1 Micro: 0.3438, F1 Macro: 0.3224, Accuracy: 0.3438\n","Epoch 59, Train Loss: 1.4482, Val Loss: 1.7560, F1 Micro: 0.3750, F1 Macro: 0.3415, Accuracy: 0.3750\n","Epoch 60, Train Loss: 1.4283, Val Loss: 1.6953, F1 Micro: 0.3646, F1 Macro: 0.3295, Accuracy: 0.3646\n","Epoch 61, Train Loss: 1.4289, Val Loss: 1.6448, F1 Micro: 0.3854, F1 Macro: 0.3305, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.4413, Val Loss: 1.6338, F1 Micro: 0.3750, F1 Macro: 0.3430, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.4521, Val Loss: 1.6431, F1 Micro: 0.3854, F1 Macro: 0.3276, Accuracy: 0.3854\n","Epoch 64, Train Loss: 1.3785, Val Loss: 1.6221, F1 Micro: 0.4167, F1 Macro: 0.3843, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.3997, Val Loss: 1.6118, F1 Micro: 0.3958, F1 Macro: 0.4006, Accuracy: 0.3958\n","Epoch 66, Train Loss: 1.3652, Val Loss: 1.6135, F1 Micro: 0.3958, F1 Macro: 0.3932, Accuracy: 0.3958\n","Epoch 67, Train Loss: 1.3619, Val Loss: 1.6620, F1 Micro: 0.4167, F1 Macro: 0.4018, Accuracy: 0.4167\n","Epoch 68, Train Loss: 1.3586, Val Loss: 1.7391, F1 Micro: 0.3333, F1 Macro: 0.2990, Accuracy: 0.3333\n","Epoch 69, Train Loss: 1.4155, Val Loss: 1.7462, F1 Micro: 0.3646, F1 Macro: 0.3503, Accuracy: 0.3646\n","Epoch 70, Train Loss: 1.3575, Val Loss: 1.7531, F1 Micro: 0.3646, F1 Macro: 0.3663, Accuracy: 0.3646\n","Epoch 71, Train Loss: 1.4182, Val Loss: 1.5972, F1 Micro: 0.4375, F1 Macro: 0.4152, Accuracy: 0.4375\n","Epoch 72, Train Loss: 1.4152, Val Loss: 1.7296, F1 Micro: 0.3125, F1 Macro: 0.3020, Accuracy: 0.3125\n","Epoch 73, Train Loss: 1.3654, Val Loss: 1.6622, F1 Micro: 0.3854, F1 Macro: 0.3873, Accuracy: 0.3854\n","Epoch 74, Train Loss: 1.3460, Val Loss: 1.6261, F1 Micro: 0.4375, F1 Macro: 0.4210, Accuracy: 0.4375\n","Epoch 75, Train Loss: 1.3588, Val Loss: 1.6373, F1 Micro: 0.3854, F1 Macro: 0.3667, Accuracy: 0.3854\n","Epoch 76, Train Loss: 1.3447, Val Loss: 1.8938, F1 Micro: 0.3646, F1 Macro: 0.3747, Accuracy: 0.3646\n","Epoch 77, Train Loss: 1.3939, Val Loss: 1.6911, F1 Micro: 0.3750, F1 Macro: 0.3817, Accuracy: 0.3750\n","Epoch 78, Train Loss: 1.3659, Val Loss: 1.7263, F1 Micro: 0.3646, F1 Macro: 0.3536, Accuracy: 0.3646\n","Epoch 79, Train Loss: 1.3203, Val Loss: 1.7557, F1 Micro: 0.3229, F1 Macro: 0.3304, Accuracy: 0.3229\n","Epoch 80, Train Loss: 1.3176, Val Loss: 1.7662, F1 Micro: 0.3646, F1 Macro: 0.3624, Accuracy: 0.3646\n","Epoch 81, Train Loss: 1.3349, Val Loss: 1.6426, F1 Micro: 0.3958, F1 Macro: 0.3656, Accuracy: 0.3958\n","Epoch 82, Train Loss: 1.3119, Val Loss: 1.7746, F1 Micro: 0.3854, F1 Macro: 0.3108, Accuracy: 0.3854\n","Epoch 83, Train Loss: 1.3426, Val Loss: 1.6374, F1 Micro: 0.4271, F1 Macro: 0.3898, Accuracy: 0.4271\n","Epoch 84, Train Loss: 1.2866, Val Loss: 1.7518, F1 Micro: 0.4062, F1 Macro: 0.3825, Accuracy: 0.4062\n","Epoch 85, Train Loss: 1.3120, Val Loss: 1.6686, F1 Micro: 0.4271, F1 Macro: 0.3983, Accuracy: 0.4271\n","Epoch 86, Train Loss: 1.3468, Val Loss: 1.6754, F1 Micro: 0.4167, F1 Macro: 0.3977, Accuracy: 0.4167\n","Epoch 87, Train Loss: 1.2361, Val Loss: 1.6543, F1 Micro: 0.4062, F1 Macro: 0.3963, Accuracy: 0.4062\n","Epoch 88, Train Loss: 1.2714, Val Loss: 1.7994, F1 Micro: 0.3646, F1 Macro: 0.3604, Accuracy: 0.3646\n","Epoch 89, Train Loss: 1.2721, Val Loss: 1.7191, F1 Micro: 0.4062, F1 Macro: 0.3944, Accuracy: 0.4062\n","Epoch 90, Train Loss: 1.2716, Val Loss: 1.7295, F1 Micro: 0.3542, F1 Macro: 0.3476, Accuracy: 0.3542\n","Epoch 91, Train Loss: 1.2650, Val Loss: 1.6494, F1 Micro: 0.4479, F1 Macro: 0.4125, Accuracy: 0.4479\n","Epoch 92, Train Loss: 1.2531, Val Loss: 1.6311, F1 Micro: 0.4479, F1 Macro: 0.3817, Accuracy: 0.4479\n","Epoch 93, Train Loss: 1.2257, Val Loss: 1.6874, F1 Micro: 0.3958, F1 Macro: 0.3821, Accuracy: 0.3958\n","Epoch 94, Train Loss: 1.2229, Val Loss: 1.7307, F1 Micro: 0.3750, F1 Macro: 0.3673, Accuracy: 0.3750\n","Epoch 95, Train Loss: 1.2250, Val Loss: 1.7087, F1 Micro: 0.3750, F1 Macro: 0.3492, Accuracy: 0.3750\n","Epoch 96, Train Loss: 1.2616, Val Loss: 1.6145, F1 Micro: 0.4167, F1 Macro: 0.3883, Accuracy: 0.4167\n","Epoch 97, Train Loss: 1.2224, Val Loss: 1.6905, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 98, Train Loss: 1.2935, Val Loss: 1.6345, F1 Micro: 0.4688, F1 Macro: 0.4080, Accuracy: 0.4688\n","Epoch 99, Train Loss: 1.2561, Val Loss: 1.8196, F1 Micro: 0.3542, F1 Macro: 0.3466, Accuracy: 0.3542\n","Epoch 100, Train Loss: 1.2381, Val Loss: 1.7146, F1 Micro: 0.3958, F1 Macro: 0.3758, Accuracy: 0.3958\n","Epoch 101, Train Loss: 1.2141, Val Loss: 1.6620, F1 Micro: 0.4583, F1 Macro: 0.4302, Accuracy: 0.4583\n","Epoch 102, Train Loss: 1.2057, Val Loss: 1.6775, F1 Micro: 0.4583, F1 Macro: 0.4465, Accuracy: 0.4583\n","Epoch 103, Train Loss: 1.2630, Val Loss: 1.6330, F1 Micro: 0.4583, F1 Macro: 0.4368, Accuracy: 0.4583\n","Epoch 104, Train Loss: 1.2320, Val Loss: 1.7483, F1 Micro: 0.3854, F1 Macro: 0.3545, Accuracy: 0.3854\n","Epoch 105, Train Loss: 1.2314, Val Loss: 1.7866, F1 Micro: 0.4167, F1 Macro: 0.3777, Accuracy: 0.4167\n","Epoch 106, Train Loss: 1.2112, Val Loss: 1.6851, F1 Micro: 0.4271, F1 Macro: 0.4095, Accuracy: 0.4271\n","Epoch 107, Train Loss: 1.2130, Val Loss: 1.6958, F1 Micro: 0.4688, F1 Macro: 0.4605, Accuracy: 0.4688\n","Epoch 108, Train Loss: 1.2002, Val Loss: 1.7259, F1 Micro: 0.4167, F1 Macro: 0.3759, Accuracy: 0.4167\n","Epoch 109, Train Loss: 1.2019, Val Loss: 1.7252, F1 Micro: 0.4062, F1 Macro: 0.4086, Accuracy: 0.4062\n","Epoch 110, Train Loss: 1.2004, Val Loss: 1.8024, F1 Micro: 0.3333, F1 Macro: 0.3185, Accuracy: 0.3333\n","Epoch 111, Train Loss: 1.1960, Val Loss: 1.8098, F1 Micro: 0.3958, F1 Macro: 0.4100, Accuracy: 0.3958\n","Epoch 112, Train Loss: 1.2183, Val Loss: 1.7172, F1 Micro: 0.4271, F1 Macro: 0.4062, Accuracy: 0.4271\n","Epoch 113, Train Loss: 1.1629, Val Loss: 1.6135, F1 Micro: 0.5000, F1 Macro: 0.4784, Accuracy: 0.5000\n","Epoch 114, Train Loss: 1.1978, Val Loss: 1.6703, F1 Micro: 0.4688, F1 Macro: 0.4479, Accuracy: 0.4688\n","Epoch 115, Train Loss: 1.1888, Val Loss: 1.6081, F1 Micro: 0.4479, F1 Macro: 0.4006, Accuracy: 0.4479\n","Epoch 116, Train Loss: 1.1936, Val Loss: 1.6858, F1 Micro: 0.3958, F1 Macro: 0.3849, Accuracy: 0.3958\n","Epoch 117, Train Loss: 1.1282, Val Loss: 1.7491, F1 Micro: 0.4271, F1 Macro: 0.4091, Accuracy: 0.4271\n","Epoch 118, Train Loss: 1.1888, Val Loss: 1.7816, F1 Micro: 0.4375, F1 Macro: 0.3868, Accuracy: 0.4375\n","Epoch 119, Train Loss: 1.1452, Val Loss: 1.6332, F1 Micro: 0.4479, F1 Macro: 0.4426, Accuracy: 0.4479\n","Epoch 120, Train Loss: 1.1264, Val Loss: 1.9317, F1 Micro: 0.3854, F1 Macro: 0.4038, Accuracy: 0.3854\n","Epoch 121, Train Loss: 1.1902, Val Loss: 1.7275, F1 Micro: 0.3542, F1 Macro: 0.3469, Accuracy: 0.3542\n","Epoch 122, Train Loss: 1.1912, Val Loss: 1.6033, F1 Micro: 0.4167, F1 Macro: 0.3719, Accuracy: 0.4167\n","Epoch 123, Train Loss: 1.1147, Val Loss: 1.8022, F1 Micro: 0.3958, F1 Macro: 0.4039, Accuracy: 0.3958\n","Epoch 124, Train Loss: 1.1569, Val Loss: 1.6942, F1 Micro: 0.4583, F1 Macro: 0.4637, Accuracy: 0.4583\n","Epoch 125, Train Loss: 1.1457, Val Loss: 1.7854, F1 Micro: 0.4375, F1 Macro: 0.4329, Accuracy: 0.4375\n","Epoch 126, Train Loss: 1.1467, Val Loss: 1.8144, F1 Micro: 0.3854, F1 Macro: 0.3850, Accuracy: 0.3854\n","Epoch 127, Train Loss: 1.0795, Val Loss: 1.7266, F1 Micro: 0.4375, F1 Macro: 0.4268, Accuracy: 0.4375\n","Epoch 128, Train Loss: 1.1039, Val Loss: 1.6533, F1 Micro: 0.4167, F1 Macro: 0.4168, Accuracy: 0.4167\n","Epoch 129, Train Loss: 1.0921, Val Loss: 1.8806, F1 Micro: 0.3958, F1 Macro: 0.3766, Accuracy: 0.3958\n","Epoch 130, Train Loss: 1.1230, Val Loss: 1.7240, F1 Micro: 0.4375, F1 Macro: 0.4281, Accuracy: 0.4375\n","Epoch 131, Train Loss: 1.0990, Val Loss: 1.6477, F1 Micro: 0.4896, F1 Macro: 0.4813, Accuracy: 0.4896\n","Epoch 132, Train Loss: 1.1092, Val Loss: 1.7442, F1 Micro: 0.4583, F1 Macro: 0.4318, Accuracy: 0.4583\n","Epoch 133, Train Loss: 1.1101, Val Loss: 1.6032, F1 Micro: 0.4375, F1 Macro: 0.4275, Accuracy: 0.4375\n","Epoch 134, Train Loss: 1.1029, Val Loss: 1.5951, F1 Micro: 0.5000, F1 Macro: 0.4763, Accuracy: 0.5000\n","Epoch 135, Train Loss: 1.0702, Val Loss: 1.6516, F1 Micro: 0.4583, F1 Macro: 0.4233, Accuracy: 0.4583\n","Epoch 136, Train Loss: 1.0877, Val Loss: 1.6634, F1 Micro: 0.4792, F1 Macro: 0.4601, Accuracy: 0.4792\n","Epoch 137, Train Loss: 1.1644, Val Loss: 1.6669, F1 Micro: 0.5104, F1 Macro: 0.4759, Accuracy: 0.5104\n","Epoch 138, Train Loss: 1.0403, Val Loss: 1.6088, F1 Micro: 0.5000, F1 Macro: 0.4747, Accuracy: 0.5000\n","Epoch 139, Train Loss: 1.0834, Val Loss: 1.6416, F1 Micro: 0.4271, F1 Macro: 0.4049, Accuracy: 0.4271\n","Epoch 140, Train Loss: 1.0606, Val Loss: 1.6374, F1 Micro: 0.4896, F1 Macro: 0.4662, Accuracy: 0.4896\n","Epoch 141, Train Loss: 1.0104, Val Loss: 1.7417, F1 Micro: 0.4167, F1 Macro: 0.4073, Accuracy: 0.4167\n","Epoch 142, Train Loss: 1.0423, Val Loss: 1.7855, F1 Micro: 0.4271, F1 Macro: 0.4138, Accuracy: 0.4271\n","Epoch 143, Train Loss: 1.0306, Val Loss: 1.7389, F1 Micro: 0.4375, F1 Macro: 0.4219, Accuracy: 0.4375\n","Epoch 144, Train Loss: 1.0647, Val Loss: 2.1497, F1 Micro: 0.3750, F1 Macro: 0.3626, Accuracy: 0.3750\n","Epoch 145, Train Loss: 1.1476, Val Loss: 1.7294, F1 Micro: 0.4792, F1 Macro: 0.4799, Accuracy: 0.4792\n","Epoch 146, Train Loss: 0.9993, Val Loss: 1.7160, F1 Micro: 0.4688, F1 Macro: 0.4447, Accuracy: 0.4688\n","Epoch 147, Train Loss: 0.9482, Val Loss: 1.7524, F1 Micro: 0.4479, F1 Macro: 0.4330, Accuracy: 0.4479\n","Epoch 148, Train Loss: 1.0137, Val Loss: 1.8386, F1 Micro: 0.4271, F1 Macro: 0.4237, Accuracy: 0.4271\n","Epoch 149, Train Loss: 1.0237, Val Loss: 1.6165, F1 Micro: 0.4792, F1 Macro: 0.4790, Accuracy: 0.4792\n","Epoch 150, Train Loss: 0.9952, Val Loss: 1.7960, F1 Micro: 0.4583, F1 Macro: 0.4562, Accuracy: 0.4583\n","Epoch 151, Train Loss: 1.0130, Val Loss: 1.7447, F1 Micro: 0.4688, F1 Macro: 0.3999, Accuracy: 0.4688\n","Epoch 152, Train Loss: 1.0092, Val Loss: 1.8223, F1 Micro: 0.4375, F1 Macro: 0.4562, Accuracy: 0.4375\n","Epoch 153, Train Loss: 1.0188, Val Loss: 1.8031, F1 Micro: 0.4688, F1 Macro: 0.4624, Accuracy: 0.4688\n","Epoch 154, Train Loss: 0.9345, Val Loss: 1.6719, F1 Micro: 0.4896, F1 Macro: 0.4653, Accuracy: 0.4896\n","Epoch 155, Train Loss: 0.9515, Val Loss: 1.7335, F1 Micro: 0.4583, F1 Macro: 0.4511, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.9302, Val Loss: 1.8083, F1 Micro: 0.4375, F1 Macro: 0.4309, Accuracy: 0.4375\n","Epoch 157, Train Loss: 1.0008, Val Loss: 1.8331, F1 Micro: 0.4792, F1 Macro: 0.4693, Accuracy: 0.4792\n","Epoch 158, Train Loss: 0.9976, Val Loss: 1.8235, F1 Micro: 0.5104, F1 Macro: 0.4943, Accuracy: 0.5104\n","Epoch 159, Train Loss: 1.0313, Val Loss: 1.7359, F1 Micro: 0.4583, F1 Macro: 0.4490, Accuracy: 0.4583\n","Epoch 160, Train Loss: 1.0106, Val Loss: 1.7580, F1 Micro: 0.4479, F1 Macro: 0.4583, Accuracy: 0.4479\n","Epoch 161, Train Loss: 0.9133, Val Loss: 1.7091, F1 Micro: 0.5208, F1 Macro: 0.4863, Accuracy: 0.5208\n","Epoch 162, Train Loss: 0.9698, Val Loss: 1.8032, F1 Micro: 0.4271, F1 Macro: 0.4065, Accuracy: 0.4271\n","Epoch 163, Train Loss: 0.9744, Val Loss: 1.7033, F1 Micro: 0.4583, F1 Macro: 0.4301, Accuracy: 0.4583\n","Epoch 164, Train Loss: 0.9798, Val Loss: 1.7398, F1 Micro: 0.4792, F1 Macro: 0.4669, Accuracy: 0.4792\n","Epoch 165, Train Loss: 0.9629, Val Loss: 1.7378, F1 Micro: 0.4583, F1 Macro: 0.4390, Accuracy: 0.4583\n","Epoch 166, Train Loss: 0.9662, Val Loss: 1.7380, F1 Micro: 0.4688, F1 Macro: 0.4605, Accuracy: 0.4688\n","Epoch 167, Train Loss: 0.9579, Val Loss: 1.7213, F1 Micro: 0.4583, F1 Macro: 0.4408, Accuracy: 0.4583\n","Epoch 168, Train Loss: 1.0313, Val Loss: 1.7754, F1 Micro: 0.5000, F1 Macro: 0.4672, Accuracy: 0.5000\n","Epoch 169, Train Loss: 0.9955, Val Loss: 1.6108, F1 Micro: 0.4688, F1 Macro: 0.4452, Accuracy: 0.4688\n","Epoch 170, Train Loss: 0.9061, Val Loss: 1.8099, F1 Micro: 0.4271, F1 Macro: 0.4270, Accuracy: 0.4271\n","Epoch 171, Train Loss: 0.9591, Val Loss: 1.9261, F1 Micro: 0.3958, F1 Macro: 0.3593, Accuracy: 0.3958\n","Epoch 172, Train Loss: 0.9495, Val Loss: 1.7625, F1 Micro: 0.4792, F1 Macro: 0.4836, Accuracy: 0.4792\n","Epoch 173, Train Loss: 0.9048, Val Loss: 1.7755, F1 Micro: 0.4688, F1 Macro: 0.4620, Accuracy: 0.4688\n","Epoch 174, Train Loss: 0.9307, Val Loss: 1.7601, F1 Micro: 0.4896, F1 Macro: 0.4832, Accuracy: 0.4896\n","Epoch 175, Train Loss: 0.9556, Val Loss: 1.8965, F1 Micro: 0.4896, F1 Macro: 0.4822, Accuracy: 0.4896\n","Epoch 176, Train Loss: 0.8850, Val Loss: 1.7930, F1 Micro: 0.4792, F1 Macro: 0.4671, Accuracy: 0.4792\n","Epoch 177, Train Loss: 0.9290, Val Loss: 1.7472, F1 Micro: 0.5208, F1 Macro: 0.5154, Accuracy: 0.5208\n","Epoch 178, Train Loss: 0.9116, Val Loss: 1.8239, F1 Micro: 0.4583, F1 Macro: 0.4605, Accuracy: 0.4583\n","Epoch 179, Train Loss: 0.8616, Val Loss: 1.7505, F1 Micro: 0.4479, F1 Macro: 0.4249, Accuracy: 0.4479\n","Epoch 180, Train Loss: 0.9394, Val Loss: 1.7475, F1 Micro: 0.4896, F1 Macro: 0.4412, Accuracy: 0.4896\n","Epoch 181, Train Loss: 0.8962, Val Loss: 1.8078, F1 Micro: 0.4583, F1 Macro: 0.4196, Accuracy: 0.4583\n","Epoch 182, Train Loss: 0.9152, Val Loss: 1.8268, F1 Micro: 0.4583, F1 Macro: 0.4445, Accuracy: 0.4583\n","Epoch 183, Train Loss: 0.9010, Val Loss: 1.7035, F1 Micro: 0.4896, F1 Macro: 0.4643, Accuracy: 0.4896\n","Epoch 184, Train Loss: 0.8654, Val Loss: 1.7347, F1 Micro: 0.4792, F1 Macro: 0.4665, Accuracy: 0.4792\n","Epoch 185, Train Loss: 0.8449, Val Loss: 1.8485, F1 Micro: 0.4896, F1 Macro: 0.4507, Accuracy: 0.4896\n","Epoch 186, Train Loss: 0.8537, Val Loss: 1.9214, F1 Micro: 0.4896, F1 Macro: 0.4768, Accuracy: 0.4896\n","Epoch 187, Train Loss: 0.9003, Val Loss: 1.7712, F1 Micro: 0.5208, F1 Macro: 0.5028, Accuracy: 0.5208\n","Epoch 188, Train Loss: 0.8846, Val Loss: 1.8118, F1 Micro: 0.4896, F1 Macro: 0.4812, Accuracy: 0.4896\n","Epoch 189, Train Loss: 0.8589, Val Loss: 1.7468, F1 Micro: 0.4896, F1 Macro: 0.4757, Accuracy: 0.4896\n","Epoch 190, Train Loss: 0.8431, Val Loss: 1.7823, F1 Micro: 0.4896, F1 Macro: 0.4765, Accuracy: 0.4896\n","Epoch 191, Train Loss: 0.8883, Val Loss: 1.8230, F1 Micro: 0.4896, F1 Macro: 0.4667, Accuracy: 0.4896\n","Epoch 192, Train Loss: 0.8261, Val Loss: 1.8296, F1 Micro: 0.5000, F1 Macro: 0.4997, Accuracy: 0.5000\n","Epoch 193, Train Loss: 0.8195, Val Loss: 1.8704, F1 Micro: 0.4479, F1 Macro: 0.4201, Accuracy: 0.4479\n","Epoch 194, Train Loss: 0.8573, Val Loss: 1.8640, F1 Micro: 0.5000, F1 Macro: 0.4922, Accuracy: 0.5000\n","Epoch 195, Train Loss: 0.7881, Val Loss: 1.8377, F1 Micro: 0.4688, F1 Macro: 0.4655, Accuracy: 0.4688\n","Epoch 196, Train Loss: 0.7590, Val Loss: 1.7982, F1 Micro: 0.4479, F1 Macro: 0.4118, Accuracy: 0.4479\n","Epoch 197, Train Loss: 0.8407, Val Loss: 1.8768, F1 Micro: 0.5104, F1 Macro: 0.4936, Accuracy: 0.5104\n","Epoch 198, Train Loss: 0.7940, Val Loss: 1.7542, F1 Micro: 0.4896, F1 Macro: 0.4624, Accuracy: 0.4896\n","Epoch 199, Train Loss: 0.7636, Val Loss: 1.8049, F1 Micro: 0.4896, F1 Macro: 0.4717, Accuracy: 0.4896\n","Epoch 200, Train Loss: 0.8197, Val Loss: 1.7997, F1 Micro: 0.5104, F1 Macro: 0.4988, Accuracy: 0.5104\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.7338, Val Loss: 2.8099, F1 Micro: 0.1667, F1 Macro: 0.0909, Accuracy: 0.1667\n","Epoch 2, Train Loss: 2.4706, Val Loss: 2.0912, F1 Micro: 0.2708, F1 Macro: 0.1666, Accuracy: 0.2708\n","Epoch 3, Train Loss: 2.2463, Val Loss: 1.9908, F1 Micro: 0.2604, F1 Macro: 0.2124, Accuracy: 0.2604\n","Epoch 4, Train Loss: 2.1782, Val Loss: 2.0904, F1 Micro: 0.2188, F1 Macro: 0.1173, Accuracy: 0.2188\n","Epoch 5, Train Loss: 2.1410, Val Loss: 1.7011, F1 Micro: 0.3333, F1 Macro: 0.2068, Accuracy: 0.3333\n","Epoch 6, Train Loss: 1.9634, Val Loss: 1.7587, F1 Micro: 0.3229, F1 Macro: 0.2392, Accuracy: 0.3229\n","Epoch 7, Train Loss: 2.0493, Val Loss: 1.9172, F1 Micro: 0.2396, F1 Macro: 0.1519, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.9880, Val Loss: 1.7037, F1 Micro: 0.3021, F1 Macro: 0.2181, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.8681, Val Loss: 1.9738, F1 Micro: 0.2083, F1 Macro: 0.1010, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.7938, Val Loss: 1.7987, F1 Micro: 0.2083, F1 Macro: 0.1867, Accuracy: 0.2083\n","Epoch 11, Train Loss: 1.8171, Val Loss: 1.6864, F1 Micro: 0.2917, F1 Macro: 0.2062, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.8249, Val Loss: 1.8108, F1 Micro: 0.2396, F1 Macro: 0.1586, Accuracy: 0.2396\n","Epoch 13, Train Loss: 1.8026, Val Loss: 1.7040, F1 Micro: 0.2917, F1 Macro: 0.1855, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.7557, Val Loss: 1.6699, F1 Micro: 0.3021, F1 Macro: 0.2585, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.7472, Val Loss: 1.6327, F1 Micro: 0.2917, F1 Macro: 0.2090, Accuracy: 0.2917\n","Epoch 16, Train Loss: 1.7194, Val Loss: 1.6479, F1 Micro: 0.3021, F1 Macro: 0.2402, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.7582, Val Loss: 1.6620, F1 Micro: 0.3229, F1 Macro: 0.2619, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.7057, Val Loss: 1.6755, F1 Micro: 0.3542, F1 Macro: 0.2684, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.7228, Val Loss: 1.6369, F1 Micro: 0.3125, F1 Macro: 0.2478, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.7672, Val Loss: 1.6600, F1 Micro: 0.3229, F1 Macro: 0.2782, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.7233, Val Loss: 1.7644, F1 Micro: 0.2396, F1 Macro: 0.1740, Accuracy: 0.2396\n","Epoch 22, Train Loss: 1.6937, Val Loss: 1.6278, F1 Micro: 0.2708, F1 Macro: 0.1721, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.7111, Val Loss: 1.6888, F1 Micro: 0.3438, F1 Macro: 0.2958, Accuracy: 0.3438\n","Epoch 24, Train Loss: 1.6919, Val Loss: 1.6165, F1 Micro: 0.3229, F1 Macro: 0.2660, Accuracy: 0.3229\n","Epoch 25, Train Loss: 1.7079, Val Loss: 1.6191, F1 Micro: 0.2917, F1 Macro: 0.2201, Accuracy: 0.2917\n","Epoch 26, Train Loss: 1.6869, Val Loss: 1.6106, F1 Micro: 0.3229, F1 Macro: 0.2688, Accuracy: 0.3229\n","Epoch 27, Train Loss: 1.7355, Val Loss: 1.6189, F1 Micro: 0.3333, F1 Macro: 0.2928, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.6883, Val Loss: 1.8659, F1 Micro: 0.1979, F1 Macro: 0.1509, Accuracy: 0.1979\n","Epoch 29, Train Loss: 1.7088, Val Loss: 1.5893, F1 Micro: 0.3438, F1 Macro: 0.2936, Accuracy: 0.3438\n","Epoch 30, Train Loss: 1.6610, Val Loss: 1.6908, F1 Micro: 0.3021, F1 Macro: 0.3024, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.6377, Val Loss: 1.6705, F1 Micro: 0.3646, F1 Macro: 0.3340, Accuracy: 0.3646\n","Epoch 32, Train Loss: 1.6414, Val Loss: 1.6439, F1 Micro: 0.3333, F1 Macro: 0.2839, Accuracy: 0.3333\n","Epoch 33, Train Loss: 1.6477, Val Loss: 1.6046, F1 Micro: 0.3542, F1 Macro: 0.2931, Accuracy: 0.3542\n","Epoch 34, Train Loss: 1.6536, Val Loss: 1.5377, F1 Micro: 0.4271, F1 Macro: 0.3850, Accuracy: 0.4271\n","Epoch 35, Train Loss: 1.6431, Val Loss: 1.6527, F1 Micro: 0.3125, F1 Macro: 0.2631, Accuracy: 0.3125\n","Epoch 36, Train Loss: 1.6371, Val Loss: 1.5397, F1 Micro: 0.4583, F1 Macro: 0.4238, Accuracy: 0.4583\n","Epoch 37, Train Loss: 1.6123, Val Loss: 1.6251, F1 Micro: 0.3438, F1 Macro: 0.2866, Accuracy: 0.3438\n","Epoch 38, Train Loss: 1.6039, Val Loss: 1.5207, F1 Micro: 0.3958, F1 Macro: 0.3410, Accuracy: 0.3958\n","Epoch 39, Train Loss: 1.6128, Val Loss: 1.5574, F1 Micro: 0.3854, F1 Macro: 0.3554, Accuracy: 0.3854\n","Epoch 40, Train Loss: 1.6286, Val Loss: 1.5545, F1 Micro: 0.4271, F1 Macro: 0.3919, Accuracy: 0.4271\n","Epoch 41, Train Loss: 1.6003, Val Loss: 1.6084, F1 Micro: 0.3229, F1 Macro: 0.2882, Accuracy: 0.3229\n","Epoch 42, Train Loss: 1.6071, Val Loss: 1.5084, F1 Micro: 0.4375, F1 Macro: 0.3759, Accuracy: 0.4375\n","Epoch 43, Train Loss: 1.6052, Val Loss: 1.5279, F1 Micro: 0.4167, F1 Macro: 0.3614, Accuracy: 0.4167\n","Epoch 44, Train Loss: 1.5673, Val Loss: 1.5684, F1 Micro: 0.3125, F1 Macro: 0.2860, Accuracy: 0.3125\n","Epoch 45, Train Loss: 1.6053, Val Loss: 1.4996, F1 Micro: 0.4062, F1 Macro: 0.3943, Accuracy: 0.4062\n","Epoch 46, Train Loss: 1.5896, Val Loss: 1.6524, F1 Micro: 0.3438, F1 Macro: 0.3021, Accuracy: 0.3438\n","Epoch 47, Train Loss: 1.6285, Val Loss: 1.5669, F1 Micro: 0.3333, F1 Macro: 0.2521, Accuracy: 0.3333\n","Epoch 48, Train Loss: 1.7085, Val Loss: 1.5582, F1 Micro: 0.3854, F1 Macro: 0.3865, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.6091, Val Loss: 1.5411, F1 Micro: 0.3854, F1 Macro: 0.3383, Accuracy: 0.3854\n","Epoch 50, Train Loss: 1.5515, Val Loss: 1.5029, F1 Micro: 0.4271, F1 Macro: 0.4276, Accuracy: 0.4271\n","Epoch 51, Train Loss: 1.6032, Val Loss: 1.5929, F1 Micro: 0.4271, F1 Macro: 0.3926, Accuracy: 0.4271\n","Epoch 52, Train Loss: 1.5529, Val Loss: 1.5209, F1 Micro: 0.4167, F1 Macro: 0.3978, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.5446, Val Loss: 1.4717, F1 Micro: 0.4583, F1 Macro: 0.4387, Accuracy: 0.4583\n","Epoch 54, Train Loss: 1.5291, Val Loss: 1.4506, F1 Micro: 0.4375, F1 Macro: 0.3799, Accuracy: 0.4375\n","Epoch 55, Train Loss: 1.5448, Val Loss: 1.5280, F1 Micro: 0.3750, F1 Macro: 0.3027, Accuracy: 0.3750\n","Epoch 56, Train Loss: 1.5715, Val Loss: 1.5146, F1 Micro: 0.3542, F1 Macro: 0.3177, Accuracy: 0.3542\n","Epoch 57, Train Loss: 1.5470, Val Loss: 1.5110, F1 Micro: 0.3646, F1 Macro: 0.3087, Accuracy: 0.3646\n","Epoch 58, Train Loss: 1.5214, Val Loss: 1.4859, F1 Micro: 0.4479, F1 Macro: 0.4010, Accuracy: 0.4479\n","Epoch 59, Train Loss: 1.5393, Val Loss: 1.6127, F1 Micro: 0.3854, F1 Macro: 0.3441, Accuracy: 0.3854\n","Epoch 60, Train Loss: 1.5680, Val Loss: 1.6449, F1 Micro: 0.3229, F1 Macro: 0.2811, Accuracy: 0.3229\n","Epoch 61, Train Loss: 1.5261, Val Loss: 1.5232, F1 Micro: 0.3854, F1 Macro: 0.3280, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.4799, Val Loss: 1.4512, F1 Micro: 0.4479, F1 Macro: 0.4296, Accuracy: 0.4479\n","Epoch 63, Train Loss: 1.4983, Val Loss: 1.4921, F1 Micro: 0.4062, F1 Macro: 0.3921, Accuracy: 0.4062\n","Epoch 64, Train Loss: 1.4963, Val Loss: 1.4479, F1 Micro: 0.4375, F1 Macro: 0.3746, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.5217, Val Loss: 1.5000, F1 Micro: 0.4583, F1 Macro: 0.4489, Accuracy: 0.4583\n","Epoch 66, Train Loss: 1.5453, Val Loss: 1.4770, F1 Micro: 0.4062, F1 Macro: 0.3714, Accuracy: 0.4062\n","Epoch 67, Train Loss: 1.4807, Val Loss: 1.5185, F1 Micro: 0.3750, F1 Macro: 0.3794, Accuracy: 0.3750\n","Epoch 68, Train Loss: 1.5079, Val Loss: 1.5160, F1 Micro: 0.4688, F1 Macro: 0.4328, Accuracy: 0.4688\n","Epoch 69, Train Loss: 1.4373, Val Loss: 1.6418, F1 Micro: 0.3750, F1 Macro: 0.3669, Accuracy: 0.3750\n","Epoch 70, Train Loss: 1.5337, Val Loss: 1.5648, F1 Micro: 0.3750, F1 Macro: 0.3598, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.5126, Val Loss: 1.4901, F1 Micro: 0.4167, F1 Macro: 0.4077, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.4606, Val Loss: 1.3954, F1 Micro: 0.4792, F1 Macro: 0.4119, Accuracy: 0.4792\n","Epoch 73, Train Loss: 1.4814, Val Loss: 1.5348, F1 Micro: 0.4583, F1 Macro: 0.4577, Accuracy: 0.4583\n","Epoch 74, Train Loss: 1.4390, Val Loss: 1.4536, F1 Micro: 0.4375, F1 Macro: 0.4377, Accuracy: 0.4375\n","Epoch 75, Train Loss: 1.4293, Val Loss: 1.4131, F1 Micro: 0.4792, F1 Macro: 0.4669, Accuracy: 0.4792\n","Epoch 76, Train Loss: 1.4790, Val Loss: 1.5141, F1 Micro: 0.4062, F1 Macro: 0.3573, Accuracy: 0.4062\n","Epoch 77, Train Loss: 1.4391, Val Loss: 1.4808, F1 Micro: 0.3958, F1 Macro: 0.3534, Accuracy: 0.3958\n","Epoch 78, Train Loss: 1.3812, Val Loss: 1.4500, F1 Micro: 0.4583, F1 Macro: 0.4133, Accuracy: 0.4583\n","Epoch 79, Train Loss: 1.4200, Val Loss: 1.4368, F1 Micro: 0.4688, F1 Macro: 0.4658, Accuracy: 0.4688\n","Epoch 80, Train Loss: 1.3904, Val Loss: 1.3929, F1 Micro: 0.4688, F1 Macro: 0.4122, Accuracy: 0.4688\n","Epoch 81, Train Loss: 1.3997, Val Loss: 1.4473, F1 Micro: 0.4479, F1 Macro: 0.4125, Accuracy: 0.4479\n","Epoch 82, Train Loss: 1.3954, Val Loss: 1.5539, F1 Micro: 0.3854, F1 Macro: 0.3301, Accuracy: 0.3854\n","Epoch 83, Train Loss: 1.4858, Val Loss: 1.4902, F1 Micro: 0.4583, F1 Macro: 0.3999, Accuracy: 0.4583\n","Epoch 84, Train Loss: 1.4436, Val Loss: 1.4337, F1 Micro: 0.4583, F1 Macro: 0.3571, Accuracy: 0.4583\n","Epoch 85, Train Loss: 1.3964, Val Loss: 1.5333, F1 Micro: 0.3958, F1 Macro: 0.3627, Accuracy: 0.3958\n","Epoch 86, Train Loss: 1.3806, Val Loss: 1.4326, F1 Micro: 0.5000, F1 Macro: 0.4730, Accuracy: 0.5000\n","Epoch 87, Train Loss: 1.3231, Val Loss: 1.3508, F1 Micro: 0.4688, F1 Macro: 0.4178, Accuracy: 0.4688\n","Epoch 88, Train Loss: 1.4211, Val Loss: 1.4518, F1 Micro: 0.4167, F1 Macro: 0.3740, Accuracy: 0.4167\n","Epoch 89, Train Loss: 1.3757, Val Loss: 1.4958, F1 Micro: 0.4167, F1 Macro: 0.3635, Accuracy: 0.4167\n","Epoch 90, Train Loss: 1.4081, Val Loss: 1.3949, F1 Micro: 0.5521, F1 Macro: 0.5268, Accuracy: 0.5521\n","Epoch 91, Train Loss: 1.3495, Val Loss: 1.3712, F1 Micro: 0.5104, F1 Macro: 0.4938, Accuracy: 0.5104\n","Epoch 92, Train Loss: 1.4109, Val Loss: 1.4355, F1 Micro: 0.4583, F1 Macro: 0.3932, Accuracy: 0.4583\n","Epoch 93, Train Loss: 1.3439, Val Loss: 1.4462, F1 Micro: 0.4896, F1 Macro: 0.4434, Accuracy: 0.4896\n","Epoch 94, Train Loss: 1.3435, Val Loss: 1.4224, F1 Micro: 0.5000, F1 Macro: 0.4639, Accuracy: 0.5000\n","Epoch 95, Train Loss: 1.3015, Val Loss: 1.4299, F1 Micro: 0.4375, F1 Macro: 0.4009, Accuracy: 0.4375\n","Epoch 96, Train Loss: 1.3261, Val Loss: 1.4695, F1 Micro: 0.4375, F1 Macro: 0.4146, Accuracy: 0.4375\n","Epoch 97, Train Loss: 1.2964, Val Loss: 1.3671, F1 Micro: 0.5104, F1 Macro: 0.4661, Accuracy: 0.5104\n","Epoch 98, Train Loss: 1.3230, Val Loss: 1.4317, F1 Micro: 0.4375, F1 Macro: 0.4006, Accuracy: 0.4375\n","Epoch 99, Train Loss: 1.2952, Val Loss: 1.3898, F1 Micro: 0.4688, F1 Macro: 0.4378, Accuracy: 0.4688\n","Epoch 100, Train Loss: 1.3045, Val Loss: 1.4311, F1 Micro: 0.4896, F1 Macro: 0.4769, Accuracy: 0.4896\n","Epoch 101, Train Loss: 1.2934, Val Loss: 1.3646, F1 Micro: 0.4479, F1 Macro: 0.4130, Accuracy: 0.4479\n","Epoch 102, Train Loss: 1.2693, Val Loss: 1.4090, F1 Micro: 0.4583, F1 Macro: 0.3827, Accuracy: 0.4583\n","Epoch 103, Train Loss: 1.3321, Val Loss: 1.4483, F1 Micro: 0.4896, F1 Macro: 0.4558, Accuracy: 0.4896\n","Epoch 104, Train Loss: 1.3016, Val Loss: 1.4361, F1 Micro: 0.4271, F1 Macro: 0.4105, Accuracy: 0.4271\n","Epoch 105, Train Loss: 1.2958, Val Loss: 1.4017, F1 Micro: 0.4896, F1 Macro: 0.4547, Accuracy: 0.4896\n","Epoch 106, Train Loss: 1.2959, Val Loss: 1.5420, F1 Micro: 0.4271, F1 Macro: 0.3945, Accuracy: 0.4271\n","Epoch 107, Train Loss: 1.2885, Val Loss: 1.3450, F1 Micro: 0.5625, F1 Macro: 0.5102, Accuracy: 0.5625\n","Epoch 108, Train Loss: 1.2243, Val Loss: 1.4138, F1 Micro: 0.5000, F1 Macro: 0.4347, Accuracy: 0.5000\n","Epoch 109, Train Loss: 1.2322, Val Loss: 1.4150, F1 Micro: 0.4792, F1 Macro: 0.4801, Accuracy: 0.4792\n","Epoch 110, Train Loss: 1.2878, Val Loss: 1.4015, F1 Micro: 0.4688, F1 Macro: 0.4542, Accuracy: 0.4688\n","Epoch 111, Train Loss: 1.3107, Val Loss: 1.4086, F1 Micro: 0.4375, F1 Macro: 0.4175, Accuracy: 0.4375\n","Epoch 112, Train Loss: 1.2034, Val Loss: 1.3908, F1 Micro: 0.5000, F1 Macro: 0.4920, Accuracy: 0.5000\n","Epoch 113, Train Loss: 1.2002, Val Loss: 1.4030, F1 Micro: 0.5104, F1 Macro: 0.4432, Accuracy: 0.5104\n","Epoch 114, Train Loss: 1.2496, Val Loss: 1.4100, F1 Micro: 0.5104, F1 Macro: 0.4428, Accuracy: 0.5104\n","Epoch 115, Train Loss: 1.2305, Val Loss: 1.3577, F1 Micro: 0.5729, F1 Macro: 0.5112, Accuracy: 0.5729\n","Epoch 116, Train Loss: 1.1944, Val Loss: 1.3923, F1 Micro: 0.5000, F1 Macro: 0.4638, Accuracy: 0.5000\n","Epoch 117, Train Loss: 1.2034, Val Loss: 1.3418, F1 Micro: 0.4896, F1 Macro: 0.4573, Accuracy: 0.4896\n","Epoch 118, Train Loss: 1.1504, Val Loss: 1.3038, F1 Micro: 0.5417, F1 Macro: 0.5134, Accuracy: 0.5417\n","Epoch 119, Train Loss: 1.1498, Val Loss: 1.3828, F1 Micro: 0.4792, F1 Macro: 0.4221, Accuracy: 0.4792\n","Epoch 120, Train Loss: 1.1608, Val Loss: 1.3656, F1 Micro: 0.4375, F1 Macro: 0.3925, Accuracy: 0.4375\n","Epoch 121, Train Loss: 1.1831, Val Loss: 1.4748, F1 Micro: 0.4583, F1 Macro: 0.4254, Accuracy: 0.4583\n","Epoch 122, Train Loss: 1.1961, Val Loss: 1.4520, F1 Micro: 0.4479, F1 Macro: 0.4226, Accuracy: 0.4479\n","Epoch 123, Train Loss: 1.1774, Val Loss: 1.3836, F1 Micro: 0.5104, F1 Macro: 0.4879, Accuracy: 0.5104\n","Epoch 124, Train Loss: 1.2247, Val Loss: 1.5062, F1 Micro: 0.4896, F1 Macro: 0.4547, Accuracy: 0.4896\n","Epoch 125, Train Loss: 1.1779, Val Loss: 1.3649, F1 Micro: 0.4792, F1 Macro: 0.4438, Accuracy: 0.4792\n","Epoch 126, Train Loss: 1.1986, Val Loss: 1.3574, F1 Micro: 0.5521, F1 Macro: 0.5363, Accuracy: 0.5521\n","Epoch 127, Train Loss: 1.1145, Val Loss: 1.3342, F1 Micro: 0.5208, F1 Macro: 0.5005, Accuracy: 0.5208\n","Epoch 128, Train Loss: 1.0743, Val Loss: 1.3898, F1 Micro: 0.5000, F1 Macro: 0.4785, Accuracy: 0.5000\n","Epoch 129, Train Loss: 1.2023, Val Loss: 1.3328, F1 Micro: 0.5521, F1 Macro: 0.5365, Accuracy: 0.5521\n","Epoch 130, Train Loss: 1.1554, Val Loss: 1.3145, F1 Micro: 0.5521, F1 Macro: 0.5279, Accuracy: 0.5521\n","Epoch 131, Train Loss: 1.0543, Val Loss: 1.2754, F1 Micro: 0.5729, F1 Macro: 0.5109, Accuracy: 0.5729\n","Epoch 132, Train Loss: 1.1154, Val Loss: 1.3926, F1 Micro: 0.5104, F1 Macro: 0.5053, Accuracy: 0.5104\n","Epoch 133, Train Loss: 1.1368, Val Loss: 1.4269, F1 Micro: 0.4792, F1 Macro: 0.4385, Accuracy: 0.4792\n","Epoch 134, Train Loss: 1.1817, Val Loss: 1.3853, F1 Micro: 0.5208, F1 Macro: 0.5004, Accuracy: 0.5208\n","Epoch 135, Train Loss: 1.0928, Val Loss: 1.3511, F1 Micro: 0.4792, F1 Macro: 0.4410, Accuracy: 0.4792\n","Epoch 136, Train Loss: 1.1496, Val Loss: 1.4247, F1 Micro: 0.4375, F1 Macro: 0.4015, Accuracy: 0.4375\n","Epoch 137, Train Loss: 1.1611, Val Loss: 1.4113, F1 Micro: 0.4792, F1 Macro: 0.4722, Accuracy: 0.4792\n","Epoch 138, Train Loss: 1.0747, Val Loss: 1.2786, F1 Micro: 0.5104, F1 Macro: 0.4719, Accuracy: 0.5104\n","Epoch 139, Train Loss: 1.1015, Val Loss: 1.3347, F1 Micro: 0.5625, F1 Macro: 0.5304, Accuracy: 0.5625\n","Epoch 140, Train Loss: 1.0739, Val Loss: 1.3515, F1 Micro: 0.5208, F1 Macro: 0.4878, Accuracy: 0.5208\n","Epoch 141, Train Loss: 1.0814, Val Loss: 1.4036, F1 Micro: 0.5000, F1 Macro: 0.4544, Accuracy: 0.5000\n","Epoch 142, Train Loss: 1.1433, Val Loss: 1.3163, F1 Micro: 0.5312, F1 Macro: 0.4776, Accuracy: 0.5312\n","Epoch 143, Train Loss: 1.0692, Val Loss: 1.3652, F1 Micro: 0.5208, F1 Macro: 0.4755, Accuracy: 0.5208\n","Epoch 144, Train Loss: 1.0591, Val Loss: 1.3722, F1 Micro: 0.5208, F1 Macro: 0.4953, Accuracy: 0.5208\n","Epoch 145, Train Loss: 1.0290, Val Loss: 1.3466, F1 Micro: 0.4896, F1 Macro: 0.4770, Accuracy: 0.4896\n","Epoch 146, Train Loss: 1.0840, Val Loss: 1.4748, F1 Micro: 0.4896, F1 Macro: 0.4223, Accuracy: 0.4896\n","Epoch 147, Train Loss: 1.1373, Val Loss: 1.3301, F1 Micro: 0.5417, F1 Macro: 0.5221, Accuracy: 0.5417\n","Epoch 148, Train Loss: 1.0334, Val Loss: 1.3265, F1 Micro: 0.5104, F1 Macro: 0.4694, Accuracy: 0.5104\n","Epoch 149, Train Loss: 1.0537, Val Loss: 1.3590, F1 Micro: 0.4792, F1 Macro: 0.4455, Accuracy: 0.4792\n","Epoch 150, Train Loss: 1.0454, Val Loss: 1.3217, F1 Micro: 0.5625, F1 Macro: 0.5248, Accuracy: 0.5625\n","Epoch 151, Train Loss: 1.0234, Val Loss: 1.3764, F1 Micro: 0.5312, F1 Macro: 0.5067, Accuracy: 0.5312\n","Epoch 152, Train Loss: 1.0024, Val Loss: 1.4454, F1 Micro: 0.4896, F1 Macro: 0.4507, Accuracy: 0.4896\n","Epoch 153, Train Loss: 0.9877, Val Loss: 1.3910, F1 Micro: 0.5000, F1 Macro: 0.4755, Accuracy: 0.5000\n","Epoch 154, Train Loss: 1.0184, Val Loss: 1.3303, F1 Micro: 0.5104, F1 Macro: 0.4753, Accuracy: 0.5104\n","Epoch 155, Train Loss: 0.9610, Val Loss: 1.3751, F1 Micro: 0.5208, F1 Macro: 0.4663, Accuracy: 0.5208\n","Epoch 156, Train Loss: 0.9985, Val Loss: 1.3115, F1 Micro: 0.5417, F1 Macro: 0.4956, Accuracy: 0.5417\n","Epoch 157, Train Loss: 1.0029, Val Loss: 1.4084, F1 Micro: 0.5000, F1 Macro: 0.4417, Accuracy: 0.5000\n","Epoch 158, Train Loss: 0.9963, Val Loss: 1.3530, F1 Micro: 0.5521, F1 Macro: 0.5423, Accuracy: 0.5521\n","Epoch 159, Train Loss: 0.9874, Val Loss: 1.3438, F1 Micro: 0.5000, F1 Macro: 0.4597, Accuracy: 0.5000\n","Epoch 160, Train Loss: 1.0045, Val Loss: 1.3813, F1 Micro: 0.5104, F1 Macro: 0.4655, Accuracy: 0.5104\n","Epoch 161, Train Loss: 0.9906, Val Loss: 1.3655, F1 Micro: 0.5312, F1 Macro: 0.4784, Accuracy: 0.5312\n","Epoch 162, Train Loss: 1.0130, Val Loss: 1.3612, F1 Micro: 0.5625, F1 Macro: 0.5236, Accuracy: 0.5625\n","Epoch 163, Train Loss: 0.9981, Val Loss: 1.4094, F1 Micro: 0.4896, F1 Macro: 0.4482, Accuracy: 0.4896\n","Epoch 164, Train Loss: 0.9785, Val Loss: 1.3969, F1 Micro: 0.5521, F1 Macro: 0.5413, Accuracy: 0.5521\n","Epoch 165, Train Loss: 0.9233, Val Loss: 1.2698, F1 Micro: 0.5521, F1 Macro: 0.5084, Accuracy: 0.5521\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.6121, Val Loss: 2.5171, F1 Micro: 0.1042, F1 Macro: 0.0778, Accuracy: 0.1042\n","Epoch 2, Train Loss: 2.6135, Val Loss: 2.3637, F1 Micro: 0.1979, F1 Macro: 0.1253, Accuracy: 0.1979\n","Epoch 3, Train Loss: 2.3995, Val Loss: 2.0372, F1 Micro: 0.2396, F1 Macro: 0.1696, Accuracy: 0.2396\n","Epoch 4, Train Loss: 2.0783, Val Loss: 2.0986, F1 Micro: 0.1042, F1 Macro: 0.0802, Accuracy: 0.1042\n","Epoch 5, Train Loss: 2.0218, Val Loss: 2.1062, F1 Micro: 0.1354, F1 Macro: 0.1124, Accuracy: 0.1354\n","Epoch 6, Train Loss: 1.9092, Val Loss: 2.0841, F1 Micro: 0.1458, F1 Macro: 0.1298, Accuracy: 0.1458\n","Epoch 7, Train Loss: 1.8862, Val Loss: 1.8430, F1 Micro: 0.1771, F1 Macro: 0.1599, Accuracy: 0.1771\n","Epoch 8, Train Loss: 1.9071, Val Loss: 1.9438, F1 Micro: 0.1875, F1 Macro: 0.1552, Accuracy: 0.1875\n","Epoch 9, Train Loss: 1.8561, Val Loss: 1.8387, F1 Micro: 0.1875, F1 Macro: 0.1415, Accuracy: 0.1875\n","Epoch 10, Train Loss: 1.8083, Val Loss: 1.8659, F1 Micro: 0.2708, F1 Macro: 0.2233, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.7199, Val Loss: 1.8643, F1 Micro: 0.1771, F1 Macro: 0.1232, Accuracy: 0.1771\n","Epoch 12, Train Loss: 1.7877, Val Loss: 1.8542, F1 Micro: 0.1667, F1 Macro: 0.1443, Accuracy: 0.1667\n","Epoch 13, Train Loss: 1.7610, Val Loss: 1.8300, F1 Micro: 0.1979, F1 Macro: 0.1192, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.7505, Val Loss: 1.8599, F1 Micro: 0.1875, F1 Macro: 0.1319, Accuracy: 0.1875\n","Epoch 15, Train Loss: 1.7335, Val Loss: 1.7833, F1 Micro: 0.3021, F1 Macro: 0.2608, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.7116, Val Loss: 1.8811, F1 Micro: 0.2292, F1 Macro: 0.1731, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.7028, Val Loss: 1.9475, F1 Micro: 0.2396, F1 Macro: 0.1417, Accuracy: 0.2396\n","Epoch 18, Train Loss: 1.7409, Val Loss: 1.8126, F1 Micro: 0.2604, F1 Macro: 0.2346, Accuracy: 0.2604\n","Epoch 19, Train Loss: 1.6733, Val Loss: 1.7705, F1 Micro: 0.2292, F1 Macro: 0.1646, Accuracy: 0.2292\n","Epoch 20, Train Loss: 1.6835, Val Loss: 1.8021, F1 Micro: 0.2604, F1 Macro: 0.2235, Accuracy: 0.2604\n","Epoch 21, Train Loss: 1.6334, Val Loss: 1.8140, F1 Micro: 0.2708, F1 Macro: 0.2117, Accuracy: 0.2708\n","Epoch 22, Train Loss: 1.6799, Val Loss: 1.8604, F1 Micro: 0.2708, F1 Macro: 0.2642, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.6513, Val Loss: 1.8754, F1 Micro: 0.1979, F1 Macro: 0.1629, Accuracy: 0.1979\n","Epoch 24, Train Loss: 1.6453, Val Loss: 1.8984, F1 Micro: 0.2708, F1 Macro: 0.2363, Accuracy: 0.2708\n","Epoch 25, Train Loss: 1.6531, Val Loss: 1.8327, F1 Micro: 0.2917, F1 Macro: 0.2118, Accuracy: 0.2917\n","Epoch 26, Train Loss: 1.6434, Val Loss: 1.9373, F1 Micro: 0.2083, F1 Macro: 0.1744, Accuracy: 0.2083\n","Epoch 27, Train Loss: 1.6826, Val Loss: 1.7474, F1 Micro: 0.3646, F1 Macro: 0.3085, Accuracy: 0.3646\n","Epoch 28, Train Loss: 1.6353, Val Loss: 1.7868, F1 Micro: 0.2917, F1 Macro: 0.2581, Accuracy: 0.2917\n","Epoch 29, Train Loss: 1.6444, Val Loss: 1.7945, F1 Micro: 0.3021, F1 Macro: 0.2346, Accuracy: 0.3021\n","Epoch 30, Train Loss: 1.6875, Val Loss: 1.8490, F1 Micro: 0.2604, F1 Macro: 0.2228, Accuracy: 0.2604\n","Epoch 31, Train Loss: 1.6654, Val Loss: 1.7691, F1 Micro: 0.3438, F1 Macro: 0.2751, Accuracy: 0.3438\n","Epoch 32, Train Loss: 1.6476, Val Loss: 1.8269, F1 Micro: 0.2396, F1 Macro: 0.1988, Accuracy: 0.2396\n","Epoch 33, Train Loss: 1.6314, Val Loss: 1.7789, F1 Micro: 0.2292, F1 Macro: 0.1892, Accuracy: 0.2292\n","Epoch 34, Train Loss: 1.6071, Val Loss: 1.8163, F1 Micro: 0.2604, F1 Macro: 0.2151, Accuracy: 0.2604\n","Epoch 35, Train Loss: 1.6474, Val Loss: 1.8396, F1 Micro: 0.3333, F1 Macro: 0.2811, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.6147, Val Loss: 1.7778, F1 Micro: 0.3229, F1 Macro: 0.2758, Accuracy: 0.3229\n","Epoch 37, Train Loss: 1.6329, Val Loss: 1.7578, F1 Micro: 0.3125, F1 Macro: 0.2912, Accuracy: 0.3125\n","Epoch 38, Train Loss: 1.6253, Val Loss: 1.8361, F1 Micro: 0.2812, F1 Macro: 0.2958, Accuracy: 0.2812\n","Epoch 39, Train Loss: 1.6036, Val Loss: 1.7184, F1 Micro: 0.3542, F1 Macro: 0.3051, Accuracy: 0.3542\n","Epoch 40, Train Loss: 1.6054, Val Loss: 1.8134, F1 Micro: 0.3229, F1 Macro: 0.2752, Accuracy: 0.3229\n","Epoch 41, Train Loss: 1.5391, Val Loss: 1.7841, F1 Micro: 0.3021, F1 Macro: 0.2715, Accuracy: 0.3021\n","Epoch 42, Train Loss: 1.6085, Val Loss: 1.7141, F1 Micro: 0.3438, F1 Macro: 0.2590, Accuracy: 0.3438\n","Epoch 43, Train Loss: 1.5931, Val Loss: 1.7863, F1 Micro: 0.3333, F1 Macro: 0.2915, Accuracy: 0.3333\n","Epoch 44, Train Loss: 1.6006, Val Loss: 1.7565, F1 Micro: 0.3125, F1 Macro: 0.3114, Accuracy: 0.3125\n","Epoch 45, Train Loss: 1.6316, Val Loss: 1.8092, F1 Micro: 0.2604, F1 Macro: 0.2053, Accuracy: 0.2604\n","Epoch 46, Train Loss: 1.5865, Val Loss: 1.7377, F1 Micro: 0.3125, F1 Macro: 0.2829, Accuracy: 0.3125\n","Epoch 47, Train Loss: 1.5685, Val Loss: 1.8473, F1 Micro: 0.2604, F1 Macro: 0.2087, Accuracy: 0.2604\n","Epoch 48, Train Loss: 1.5655, Val Loss: 1.7292, F1 Micro: 0.3021, F1 Macro: 0.2547, Accuracy: 0.3021\n","Epoch 49, Train Loss: 1.5484, Val Loss: 1.7310, F1 Micro: 0.3125, F1 Macro: 0.3072, Accuracy: 0.3125\n","Epoch 50, Train Loss: 1.5174, Val Loss: 1.7631, F1 Micro: 0.3229, F1 Macro: 0.3002, Accuracy: 0.3229\n","Epoch 51, Train Loss: 1.5292, Val Loss: 1.7729, F1 Micro: 0.3021, F1 Macro: 0.2826, Accuracy: 0.3021\n","Epoch 52, Train Loss: 1.5255, Val Loss: 1.9305, F1 Micro: 0.2396, F1 Macro: 0.2480, Accuracy: 0.2396\n","Epoch 53, Train Loss: 1.5562, Val Loss: 1.6946, F1 Micro: 0.3333, F1 Macro: 0.3161, Accuracy: 0.3333\n","Epoch 54, Train Loss: 1.5114, Val Loss: 1.7319, F1 Micro: 0.3333, F1 Macro: 0.3158, Accuracy: 0.3333\n","Epoch 55, Train Loss: 1.5195, Val Loss: 1.6617, F1 Micro: 0.3542, F1 Macro: 0.3268, Accuracy: 0.3542\n","Epoch 56, Train Loss: 1.5260, Val Loss: 1.6864, F1 Micro: 0.3438, F1 Macro: 0.2949, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.4833, Val Loss: 1.7014, F1 Micro: 0.3542, F1 Macro: 0.3513, Accuracy: 0.3542\n","Epoch 58, Train Loss: 1.5029, Val Loss: 1.7320, F1 Micro: 0.3542, F1 Macro: 0.3053, Accuracy: 0.3542\n","Epoch 59, Train Loss: 1.5206, Val Loss: 1.7970, F1 Micro: 0.3333, F1 Macro: 0.3475, Accuracy: 0.3333\n","Epoch 60, Train Loss: 1.5523, Val Loss: 1.6894, F1 Micro: 0.3438, F1 Macro: 0.2844, Accuracy: 0.3438\n","Epoch 61, Train Loss: 1.5112, Val Loss: 1.7352, F1 Micro: 0.3125, F1 Macro: 0.2711, Accuracy: 0.3125\n","Epoch 62, Train Loss: 1.4901, Val Loss: 1.6414, F1 Micro: 0.3438, F1 Macro: 0.2959, Accuracy: 0.3438\n","Epoch 63, Train Loss: 1.5226, Val Loss: 1.6699, F1 Micro: 0.3542, F1 Macro: 0.3361, Accuracy: 0.3542\n","Epoch 64, Train Loss: 1.4498, Val Loss: 1.6902, F1 Micro: 0.3854, F1 Macro: 0.3702, Accuracy: 0.3854\n","Epoch 65, Train Loss: 1.4617, Val Loss: 1.7033, F1 Micro: 0.3333, F1 Macro: 0.2990, Accuracy: 0.3333\n","Epoch 66, Train Loss: 1.4754, Val Loss: 1.7367, F1 Micro: 0.3333, F1 Macro: 0.3266, Accuracy: 0.3333\n","Epoch 67, Train Loss: 1.4808, Val Loss: 1.7647, F1 Micro: 0.4375, F1 Macro: 0.4130, Accuracy: 0.4375\n","Epoch 68, Train Loss: 1.4827, Val Loss: 1.7037, F1 Micro: 0.3750, F1 Macro: 0.3644, Accuracy: 0.3750\n","Epoch 69, Train Loss: 1.4207, Val Loss: 1.7888, F1 Micro: 0.3125, F1 Macro: 0.2889, Accuracy: 0.3125\n","Epoch 70, Train Loss: 1.4957, Val Loss: 1.6483, F1 Micro: 0.3750, F1 Macro: 0.3644, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.4807, Val Loss: 1.6415, F1 Micro: 0.4062, F1 Macro: 0.3700, Accuracy: 0.4062\n","Epoch 72, Train Loss: 1.4082, Val Loss: 1.5833, F1 Micro: 0.4375, F1 Macro: 0.4020, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.4592, Val Loss: 1.6798, F1 Micro: 0.3542, F1 Macro: 0.3478, Accuracy: 0.3542\n","Epoch 74, Train Loss: 1.4061, Val Loss: 1.6600, F1 Micro: 0.3542, F1 Macro: 0.3023, Accuracy: 0.3542\n","Epoch 75, Train Loss: 1.4438, Val Loss: 1.6228, F1 Micro: 0.4583, F1 Macro: 0.4124, Accuracy: 0.4583\n","Epoch 76, Train Loss: 1.4105, Val Loss: 1.6932, F1 Micro: 0.3229, F1 Macro: 0.3246, Accuracy: 0.3229\n","Epoch 77, Train Loss: 1.4052, Val Loss: 1.5766, F1 Micro: 0.4062, F1 Macro: 0.3801, Accuracy: 0.4062\n","Epoch 78, Train Loss: 1.4262, Val Loss: 1.5820, F1 Micro: 0.4375, F1 Macro: 0.4002, Accuracy: 0.4375\n","Epoch 79, Train Loss: 1.4468, Val Loss: 1.6171, F1 Micro: 0.4271, F1 Macro: 0.3958, Accuracy: 0.4271\n","Epoch 80, Train Loss: 1.4614, Val Loss: 1.6759, F1 Micro: 0.4271, F1 Macro: 0.3809, Accuracy: 0.4271\n","Epoch 81, Train Loss: 1.4218, Val Loss: 1.6292, F1 Micro: 0.4375, F1 Macro: 0.4266, Accuracy: 0.4375\n","Epoch 82, Train Loss: 1.3533, Val Loss: 1.5505, F1 Micro: 0.4583, F1 Macro: 0.4269, Accuracy: 0.4583\n","Epoch 83, Train Loss: 1.3352, Val Loss: 1.6032, F1 Micro: 0.3958, F1 Macro: 0.3743, Accuracy: 0.3958\n","Epoch 84, Train Loss: 1.3898, Val Loss: 1.6300, F1 Micro: 0.3750, F1 Macro: 0.3745, Accuracy: 0.3750\n","Epoch 85, Train Loss: 1.3776, Val Loss: 1.5849, F1 Micro: 0.3646, F1 Macro: 0.3513, Accuracy: 0.3646\n","Epoch 86, Train Loss: 1.4276, Val Loss: 1.6779, F1 Micro: 0.3646, F1 Macro: 0.3488, Accuracy: 0.3646\n","Epoch 87, Train Loss: 1.4210, Val Loss: 1.7370, F1 Micro: 0.3125, F1 Macro: 0.2956, Accuracy: 0.3125\n","Epoch 88, Train Loss: 1.4590, Val Loss: 1.6907, F1 Micro: 0.4062, F1 Macro: 0.3808, Accuracy: 0.4062\n","Epoch 89, Train Loss: 1.3418, Val Loss: 1.6184, F1 Micro: 0.4167, F1 Macro: 0.3928, Accuracy: 0.4167\n","Epoch 90, Train Loss: 1.3413, Val Loss: 1.5716, F1 Micro: 0.4375, F1 Macro: 0.4172, Accuracy: 0.4375\n","Epoch 91, Train Loss: 1.3805, Val Loss: 1.6239, F1 Micro: 0.3854, F1 Macro: 0.3505, Accuracy: 0.3854\n","Epoch 92, Train Loss: 1.3207, Val Loss: 1.6021, F1 Micro: 0.4062, F1 Macro: 0.3909, Accuracy: 0.4062\n","Epoch 93, Train Loss: 1.3308, Val Loss: 1.5244, F1 Micro: 0.5000, F1 Macro: 0.4683, Accuracy: 0.5000\n","Epoch 94, Train Loss: 1.3755, Val Loss: 1.7899, F1 Micro: 0.3542, F1 Macro: 0.2925, Accuracy: 0.3542\n","Epoch 95, Train Loss: 1.4014, Val Loss: 1.6187, F1 Micro: 0.4688, F1 Macro: 0.4479, Accuracy: 0.4688\n","Epoch 96, Train Loss: 1.3452, Val Loss: 1.6156, F1 Micro: 0.3958, F1 Macro: 0.3467, Accuracy: 0.3958\n","Epoch 97, Train Loss: 1.3075, Val Loss: 1.6326, F1 Micro: 0.4479, F1 Macro: 0.4156, Accuracy: 0.4479\n","Epoch 98, Train Loss: 1.3167, Val Loss: 1.5732, F1 Micro: 0.4479, F1 Macro: 0.4375, Accuracy: 0.4479\n","Epoch 99, Train Loss: 1.3114, Val Loss: 1.6161, F1 Micro: 0.4583, F1 Macro: 0.4201, Accuracy: 0.4583\n","Epoch 100, Train Loss: 1.3014, Val Loss: 1.5728, F1 Micro: 0.4688, F1 Macro: 0.4317, Accuracy: 0.4688\n","Epoch 101, Train Loss: 1.2676, Val Loss: 1.6278, F1 Micro: 0.4167, F1 Macro: 0.4259, Accuracy: 0.4167\n","Epoch 102, Train Loss: 1.3069, Val Loss: 1.5511, F1 Micro: 0.4792, F1 Macro: 0.4506, Accuracy: 0.4792\n","Epoch 103, Train Loss: 1.3584, Val Loss: 1.5935, F1 Micro: 0.4062, F1 Macro: 0.3903, Accuracy: 0.4062\n","Epoch 104, Train Loss: 1.3418, Val Loss: 1.6822, F1 Micro: 0.4479, F1 Macro: 0.4257, Accuracy: 0.4479\n","Epoch 105, Train Loss: 1.2745, Val Loss: 1.4905, F1 Micro: 0.4688, F1 Macro: 0.4455, Accuracy: 0.4688\n","Epoch 106, Train Loss: 1.2658, Val Loss: 1.4847, F1 Micro: 0.5312, F1 Macro: 0.5180, Accuracy: 0.5312\n","Epoch 107, Train Loss: 1.2161, Val Loss: 1.5413, F1 Micro: 0.4792, F1 Macro: 0.4482, Accuracy: 0.4792\n","Epoch 108, Train Loss: 1.2714, Val Loss: 1.7331, F1 Micro: 0.3750, F1 Macro: 0.3766, Accuracy: 0.3750\n","Epoch 109, Train Loss: 1.2854, Val Loss: 1.5746, F1 Micro: 0.4688, F1 Macro: 0.4291, Accuracy: 0.4688\n","Epoch 110, Train Loss: 1.3282, Val Loss: 1.5908, F1 Micro: 0.4583, F1 Macro: 0.4033, Accuracy: 0.4583\n","Epoch 111, Train Loss: 1.2473, Val Loss: 1.5897, F1 Micro: 0.5208, F1 Macro: 0.4865, Accuracy: 0.5208\n","Epoch 112, Train Loss: 1.2323, Val Loss: 1.5586, F1 Micro: 0.5000, F1 Macro: 0.4572, Accuracy: 0.5000\n","Epoch 113, Train Loss: 1.2673, Val Loss: 1.6170, F1 Micro: 0.4271, F1 Macro: 0.4134, Accuracy: 0.4271\n","Epoch 114, Train Loss: 1.2222, Val Loss: 1.5974, F1 Micro: 0.3958, F1 Macro: 0.3686, Accuracy: 0.3958\n","Epoch 115, Train Loss: 1.2546, Val Loss: 1.4623, F1 Micro: 0.5417, F1 Macro: 0.5040, Accuracy: 0.5417\n","Epoch 116, Train Loss: 1.2280, Val Loss: 1.4825, F1 Micro: 0.5729, F1 Macro: 0.5365, Accuracy: 0.5729\n","Epoch 117, Train Loss: 1.1725, Val Loss: 1.5661, F1 Micro: 0.4583, F1 Macro: 0.4487, Accuracy: 0.4583\n","Epoch 118, Train Loss: 1.2105, Val Loss: 1.5498, F1 Micro: 0.5000, F1 Macro: 0.4439, Accuracy: 0.5000\n","Epoch 119, Train Loss: 1.2234, Val Loss: 1.6804, F1 Micro: 0.4062, F1 Macro: 0.3905, Accuracy: 0.4062\n","Epoch 120, Train Loss: 1.2163, Val Loss: 1.6229, F1 Micro: 0.4271, F1 Macro: 0.4133, Accuracy: 0.4271\n","Epoch 121, Train Loss: 1.2021, Val Loss: 1.5774, F1 Micro: 0.5312, F1 Macro: 0.4925, Accuracy: 0.5312\n","Epoch 122, Train Loss: 1.1515, Val Loss: 1.5603, F1 Micro: 0.4271, F1 Macro: 0.4172, Accuracy: 0.4271\n","Epoch 123, Train Loss: 1.1549, Val Loss: 1.5540, F1 Micro: 0.4271, F1 Macro: 0.4188, Accuracy: 0.4271\n","Epoch 124, Train Loss: 1.1673, Val Loss: 1.5858, F1 Micro: 0.3958, F1 Macro: 0.3733, Accuracy: 0.3958\n","Epoch 125, Train Loss: 1.1947, Val Loss: 1.4894, F1 Micro: 0.4583, F1 Macro: 0.4219, Accuracy: 0.4583\n","Epoch 126, Train Loss: 1.1770, Val Loss: 1.6449, F1 Micro: 0.4583, F1 Macro: 0.4289, Accuracy: 0.4583\n","Epoch 127, Train Loss: 1.1759, Val Loss: 1.6111, F1 Micro: 0.3958, F1 Macro: 0.3614, Accuracy: 0.3958\n","Epoch 128, Train Loss: 1.2237, Val Loss: 1.6524, F1 Micro: 0.3646, F1 Macro: 0.3163, Accuracy: 0.3646\n","Epoch 129, Train Loss: 1.1754, Val Loss: 1.6231, F1 Micro: 0.4688, F1 Macro: 0.4208, Accuracy: 0.4688\n","Epoch 130, Train Loss: 1.1500, Val Loss: 1.5467, F1 Micro: 0.5208, F1 Macro: 0.4949, Accuracy: 0.5208\n","Epoch 131, Train Loss: 1.1168, Val Loss: 1.5882, F1 Micro: 0.4688, F1 Macro: 0.4433, Accuracy: 0.4688\n","Epoch 132, Train Loss: 1.1810, Val Loss: 1.5973, F1 Micro: 0.4375, F1 Macro: 0.4198, Accuracy: 0.4375\n","Epoch 133, Train Loss: 1.1461, Val Loss: 1.5885, F1 Micro: 0.4375, F1 Macro: 0.4165, Accuracy: 0.4375\n","Epoch 134, Train Loss: 1.1154, Val Loss: 1.5243, F1 Micro: 0.4896, F1 Macro: 0.4590, Accuracy: 0.4896\n","Epoch 135, Train Loss: 1.1239, Val Loss: 1.6619, F1 Micro: 0.4583, F1 Macro: 0.4230, Accuracy: 0.4583\n","Epoch 136, Train Loss: 1.0975, Val Loss: 1.5159, F1 Micro: 0.4896, F1 Macro: 0.4677, Accuracy: 0.4896\n","Epoch 137, Train Loss: 1.0875, Val Loss: 1.4991, F1 Micro: 0.5104, F1 Macro: 0.4869, Accuracy: 0.5104\n","Epoch 138, Train Loss: 1.1018, Val Loss: 1.5158, F1 Micro: 0.5104, F1 Macro: 0.4805, Accuracy: 0.5104\n","Epoch 139, Train Loss: 1.0876, Val Loss: 1.6595, F1 Micro: 0.4583, F1 Macro: 0.4299, Accuracy: 0.4583\n","Epoch 140, Train Loss: 1.1066, Val Loss: 1.5239, F1 Micro: 0.4792, F1 Macro: 0.4596, Accuracy: 0.4792\n","Epoch 141, Train Loss: 1.0512, Val Loss: 1.4817, F1 Micro: 0.5104, F1 Macro: 0.4919, Accuracy: 0.5104\n","Epoch 142, Train Loss: 1.0569, Val Loss: 1.5247, F1 Micro: 0.4479, F1 Macro: 0.4363, Accuracy: 0.4479\n","Epoch 143, Train Loss: 1.0860, Val Loss: 1.6219, F1 Micro: 0.4688, F1 Macro: 0.4591, Accuracy: 0.4688\n","Epoch 144, Train Loss: 1.0718, Val Loss: 1.5189, F1 Micro: 0.5521, F1 Macro: 0.5153, Accuracy: 0.5521\n","Epoch 145, Train Loss: 1.1281, Val Loss: 1.5195, F1 Micro: 0.5208, F1 Macro: 0.4893, Accuracy: 0.5208\n","Epoch 146, Train Loss: 1.0808, Val Loss: 1.5614, F1 Micro: 0.4688, F1 Macro: 0.4427, Accuracy: 0.4688\n","Epoch 147, Train Loss: 1.0810, Val Loss: 1.5297, F1 Micro: 0.5208, F1 Macro: 0.5010, Accuracy: 0.5208\n","Epoch 148, Train Loss: 1.0705, Val Loss: 1.6584, F1 Micro: 0.4375, F1 Macro: 0.4376, Accuracy: 0.4375\n","Epoch 149, Train Loss: 1.0451, Val Loss: 1.6082, F1 Micro: 0.4688, F1 Macro: 0.4533, Accuracy: 0.4688\n","Epoch 150, Train Loss: 1.0464, Val Loss: 1.6328, F1 Micro: 0.4583, F1 Macro: 0.4461, Accuracy: 0.4583\n","Epoch 151, Train Loss: 1.0739, Val Loss: 1.4386, F1 Micro: 0.5312, F1 Macro: 0.5022, Accuracy: 0.5312\n","Epoch 152, Train Loss: 1.0699, Val Loss: 1.6034, F1 Micro: 0.4792, F1 Macro: 0.4516, Accuracy: 0.4792\n","Epoch 153, Train Loss: 1.0904, Val Loss: 1.5869, F1 Micro: 0.4792, F1 Macro: 0.4454, Accuracy: 0.4792\n","Epoch 154, Train Loss: 0.9898, Val Loss: 1.6654, F1 Micro: 0.4375, F1 Macro: 0.4355, Accuracy: 0.4375\n","Epoch 155, Train Loss: 0.9765, Val Loss: 1.5886, F1 Micro: 0.4583, F1 Macro: 0.4436, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.9975, Val Loss: 1.5614, F1 Micro: 0.4896, F1 Macro: 0.4662, Accuracy: 0.4896\n","Epoch 157, Train Loss: 1.0139, Val Loss: 1.6082, F1 Micro: 0.4688, F1 Macro: 0.4450, Accuracy: 0.4688\n","Epoch 158, Train Loss: 1.0126, Val Loss: 1.6263, F1 Micro: 0.4688, F1 Macro: 0.4454, Accuracy: 0.4688\n","Epoch 159, Train Loss: 0.9510, Val Loss: 1.5414, F1 Micro: 0.4583, F1 Macro: 0.4331, Accuracy: 0.4583\n","Epoch 160, Train Loss: 0.9270, Val Loss: 1.6265, F1 Micro: 0.4375, F1 Macro: 0.4204, Accuracy: 0.4375\n","Epoch 161, Train Loss: 0.9708, Val Loss: 1.5206, F1 Micro: 0.4792, F1 Macro: 0.4577, Accuracy: 0.4792\n","Epoch 162, Train Loss: 0.9546, Val Loss: 1.5620, F1 Micro: 0.4896, F1 Macro: 0.4648, Accuracy: 0.4896\n","Epoch 163, Train Loss: 0.9555, Val Loss: 1.6602, F1 Micro: 0.4167, F1 Macro: 0.4046, Accuracy: 0.4167\n","Epoch 164, Train Loss: 1.0274, Val Loss: 1.6962, F1 Micro: 0.4167, F1 Macro: 0.3992, Accuracy: 0.4167\n","Epoch 165, Train Loss: 0.9415, Val Loss: 1.5288, F1 Micro: 0.5104, F1 Macro: 0.4710, Accuracy: 0.5104\n","Epoch 166, Train Loss: 1.0323, Val Loss: 1.5772, F1 Micro: 0.5000, F1 Macro: 0.4585, Accuracy: 0.5000\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.3874, Val Loss: 2.3378, F1 Micro: 0.2083, F1 Macro: 0.1112, Accuracy: 0.2083\n","Epoch 2, Train Loss: 2.3748, Val Loss: 2.0538, F1 Micro: 0.2396, F1 Macro: 0.1645, Accuracy: 0.2396\n","Epoch 3, Train Loss: 2.0855, Val Loss: 1.9477, F1 Micro: 0.1979, F1 Macro: 0.1311, Accuracy: 0.1979\n","Epoch 4, Train Loss: 1.9806, Val Loss: 1.7954, F1 Micro: 0.2083, F1 Macro: 0.1545, Accuracy: 0.2083\n","Epoch 5, Train Loss: 1.9627, Val Loss: 1.7862, F1 Micro: 0.1979, F1 Macro: 0.1292, Accuracy: 0.1979\n","Epoch 6, Train Loss: 2.0273, Val Loss: 1.9612, F1 Micro: 0.2708, F1 Macro: 0.2228, Accuracy: 0.2708\n","Epoch 7, Train Loss: 1.8715, Val Loss: 2.1355, F1 Micro: 0.2292, F1 Macro: 0.1258, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.9412, Val Loss: 1.9252, F1 Micro: 0.2396, F1 Macro: 0.1634, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.7389, Val Loss: 1.7611, F1 Micro: 0.2188, F1 Macro: 0.1956, Accuracy: 0.2188\n","Epoch 10, Train Loss: 1.7572, Val Loss: 1.7968, F1 Micro: 0.2500, F1 Macro: 0.1664, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.7469, Val Loss: 1.9708, F1 Micro: 0.2188, F1 Macro: 0.1767, Accuracy: 0.2188\n","Epoch 12, Train Loss: 1.7829, Val Loss: 1.7527, F1 Micro: 0.3021, F1 Macro: 0.3179, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.6946, Val Loss: 1.8791, F1 Micro: 0.2500, F1 Macro: 0.2075, Accuracy: 0.2500\n","Epoch 14, Train Loss: 1.8052, Val Loss: 1.7683, F1 Micro: 0.2708, F1 Macro: 0.2193, Accuracy: 0.2708\n","Epoch 15, Train Loss: 1.7023, Val Loss: 1.7603, F1 Micro: 0.2083, F1 Macro: 0.1597, Accuracy: 0.2083\n","Epoch 16, Train Loss: 1.6954, Val Loss: 1.7381, F1 Micro: 0.2708, F1 Macro: 0.1812, Accuracy: 0.2708\n","Epoch 17, Train Loss: 1.7062, Val Loss: 1.7653, F1 Micro: 0.3021, F1 Macro: 0.2515, Accuracy: 0.3021\n","Epoch 18, Train Loss: 1.7102, Val Loss: 1.7903, F1 Micro: 0.2812, F1 Macro: 0.2063, Accuracy: 0.2812\n","Epoch 19, Train Loss: 1.7164, Val Loss: 1.7354, F1 Micro: 0.3021, F1 Macro: 0.2646, Accuracy: 0.3021\n","Epoch 20, Train Loss: 1.7173, Val Loss: 1.8774, F1 Micro: 0.2500, F1 Macro: 0.1393, Accuracy: 0.2500\n","Epoch 21, Train Loss: 1.6848, Val Loss: 1.7077, F1 Micro: 0.2708, F1 Macro: 0.2408, Accuracy: 0.2708\n","Epoch 22, Train Loss: 1.6812, Val Loss: 1.7557, F1 Micro: 0.3021, F1 Macro: 0.2520, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.6628, Val Loss: 1.7531, F1 Micro: 0.3229, F1 Macro: 0.2565, Accuracy: 0.3229\n","Epoch 24, Train Loss: 1.7253, Val Loss: 1.7613, F1 Micro: 0.2812, F1 Macro: 0.2021, Accuracy: 0.2812\n","Epoch 25, Train Loss: 1.6359, Val Loss: 1.7025, F1 Micro: 0.2604, F1 Macro: 0.2221, Accuracy: 0.2604\n","Epoch 26, Train Loss: 1.6992, Val Loss: 1.7410, F1 Micro: 0.2396, F1 Macro: 0.1777, Accuracy: 0.2396\n","Epoch 27, Train Loss: 1.6166, Val Loss: 1.6842, F1 Micro: 0.3438, F1 Macro: 0.3271, Accuracy: 0.3438\n","Epoch 28, Train Loss: 1.6298, Val Loss: 1.6954, F1 Micro: 0.3854, F1 Macro: 0.3728, Accuracy: 0.3854\n","Epoch 29, Train Loss: 1.6392, Val Loss: 1.6878, F1 Micro: 0.3125, F1 Macro: 0.2747, Accuracy: 0.3125\n","Epoch 30, Train Loss: 1.6464, Val Loss: 1.7247, F1 Micro: 0.2708, F1 Macro: 0.2181, Accuracy: 0.2708\n","Epoch 31, Train Loss: 1.5728, Val Loss: 1.7357, F1 Micro: 0.3125, F1 Macro: 0.2755, Accuracy: 0.3125\n","Epoch 32, Train Loss: 1.6126, Val Loss: 1.6659, F1 Micro: 0.3750, F1 Macro: 0.3526, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.5482, Val Loss: 1.7036, F1 Micro: 0.2604, F1 Macro: 0.2168, Accuracy: 0.2604\n","Epoch 34, Train Loss: 1.6285, Val Loss: 1.7135, F1 Micro: 0.2292, F1 Macro: 0.1495, Accuracy: 0.2292\n","Epoch 35, Train Loss: 1.5787, Val Loss: 1.7203, F1 Micro: 0.2292, F1 Macro: 0.1426, Accuracy: 0.2292\n","Epoch 36, Train Loss: 1.5418, Val Loss: 1.6564, F1 Micro: 0.3542, F1 Macro: 0.3574, Accuracy: 0.3542\n","Epoch 37, Train Loss: 1.5824, Val Loss: 1.6890, F1 Micro: 0.2812, F1 Macro: 0.2345, Accuracy: 0.2812\n","Epoch 38, Train Loss: 1.6036, Val Loss: 1.6578, F1 Micro: 0.3854, F1 Macro: 0.3690, Accuracy: 0.3854\n","Epoch 39, Train Loss: 1.5586, Val Loss: 1.6683, F1 Micro: 0.2917, F1 Macro: 0.2285, Accuracy: 0.2917\n","Epoch 40, Train Loss: 1.5905, Val Loss: 1.6716, F1 Micro: 0.3333, F1 Macro: 0.2937, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.5535, Val Loss: 1.6563, F1 Micro: 0.3125, F1 Macro: 0.2773, Accuracy: 0.3125\n","Epoch 42, Train Loss: 1.5449, Val Loss: 1.6288, F1 Micro: 0.3542, F1 Macro: 0.3279, Accuracy: 0.3542\n","Epoch 43, Train Loss: 1.5542, Val Loss: 1.6255, F1 Micro: 0.3854, F1 Macro: 0.3504, Accuracy: 0.3854\n","Epoch 44, Train Loss: 1.5325, Val Loss: 1.6599, F1 Micro: 0.3333, F1 Macro: 0.3046, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.5621, Val Loss: 1.6402, F1 Micro: 0.3646, F1 Macro: 0.3330, Accuracy: 0.3646\n","Epoch 46, Train Loss: 1.5119, Val Loss: 1.6867, F1 Micro: 0.3125, F1 Macro: 0.2295, Accuracy: 0.3125\n","Epoch 47, Train Loss: 1.5550, Val Loss: 1.6721, F1 Micro: 0.3333, F1 Macro: 0.2760, Accuracy: 0.3333\n","Epoch 48, Train Loss: 1.5420, Val Loss: 1.6263, F1 Micro: 0.3854, F1 Macro: 0.3452, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.5230, Val Loss: 1.6783, F1 Micro: 0.2812, F1 Macro: 0.2371, Accuracy: 0.2812\n","Epoch 50, Train Loss: 1.5969, Val Loss: 1.6650, F1 Micro: 0.3438, F1 Macro: 0.3012, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.5656, Val Loss: 1.8212, F1 Micro: 0.3333, F1 Macro: 0.2696, Accuracy: 0.3333\n","Epoch 52, Train Loss: 1.5323, Val Loss: 1.6029, F1 Micro: 0.4167, F1 Macro: 0.4094, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.5138, Val Loss: 1.6440, F1 Micro: 0.3854, F1 Macro: 0.3359, Accuracy: 0.3854\n","Epoch 54, Train Loss: 1.4748, Val Loss: 1.6164, F1 Micro: 0.3958, F1 Macro: 0.3800, Accuracy: 0.3958\n","Epoch 55, Train Loss: 1.4692, Val Loss: 1.6021, F1 Micro: 0.4271, F1 Macro: 0.4357, Accuracy: 0.4271\n","Epoch 56, Train Loss: 1.4699, Val Loss: 1.5995, F1 Micro: 0.3958, F1 Macro: 0.3903, Accuracy: 0.3958\n","Epoch 57, Train Loss: 1.4490, Val Loss: 1.6663, F1 Micro: 0.3750, F1 Macro: 0.3747, Accuracy: 0.3750\n","Epoch 58, Train Loss: 1.4694, Val Loss: 1.5842, F1 Micro: 0.4062, F1 Macro: 0.4081, Accuracy: 0.4062\n","Epoch 59, Train Loss: 1.4840, Val Loss: 1.7326, F1 Micro: 0.2812, F1 Macro: 0.2586, Accuracy: 0.2812\n","Epoch 60, Train Loss: 1.5360, Val Loss: 1.6687, F1 Micro: 0.3646, F1 Macro: 0.3239, Accuracy: 0.3646\n","Epoch 61, Train Loss: 1.4516, Val Loss: 1.6464, F1 Micro: 0.3750, F1 Macro: 0.3825, Accuracy: 0.3750\n","Epoch 62, Train Loss: 1.4594, Val Loss: 1.5805, F1 Micro: 0.3750, F1 Macro: 0.3650, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.4284, Val Loss: 1.6262, F1 Micro: 0.3750, F1 Macro: 0.3549, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.4446, Val Loss: 1.6817, F1 Micro: 0.3646, F1 Macro: 0.3232, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.4357, Val Loss: 1.5670, F1 Micro: 0.4271, F1 Macro: 0.4182, Accuracy: 0.4271\n","Epoch 66, Train Loss: 1.3892, Val Loss: 1.5763, F1 Micro: 0.4167, F1 Macro: 0.4047, Accuracy: 0.4167\n","Epoch 67, Train Loss: 1.4467, Val Loss: 1.5706, F1 Micro: 0.3854, F1 Macro: 0.3715, Accuracy: 0.3854\n","Epoch 68, Train Loss: 1.4745, Val Loss: 1.5731, F1 Micro: 0.4062, F1 Macro: 0.3766, Accuracy: 0.4062\n","Epoch 69, Train Loss: 1.4395, Val Loss: 1.5575, F1 Micro: 0.3958, F1 Macro: 0.4132, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.4104, Val Loss: 1.6383, F1 Micro: 0.3750, F1 Macro: 0.3639, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.4389, Val Loss: 1.5911, F1 Micro: 0.3750, F1 Macro: 0.3594, Accuracy: 0.3750\n","Epoch 72, Train Loss: 1.4171, Val Loss: 1.6346, F1 Micro: 0.3958, F1 Macro: 0.3949, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.4235, Val Loss: 1.5161, F1 Micro: 0.4271, F1 Macro: 0.4355, Accuracy: 0.4271\n","Epoch 74, Train Loss: 1.4068, Val Loss: 1.6946, F1 Micro: 0.3646, F1 Macro: 0.3524, Accuracy: 0.3646\n","Epoch 75, Train Loss: 1.3978, Val Loss: 1.5448, F1 Micro: 0.4062, F1 Macro: 0.3982, Accuracy: 0.4062\n","Epoch 76, Train Loss: 1.3523, Val Loss: 1.6596, F1 Micro: 0.3958, F1 Macro: 0.3938, Accuracy: 0.3958\n","Epoch 77, Train Loss: 1.3726, Val Loss: 1.5705, F1 Micro: 0.3958, F1 Macro: 0.3894, Accuracy: 0.3958\n","Epoch 78, Train Loss: 1.3841, Val Loss: 1.5136, F1 Micro: 0.3750, F1 Macro: 0.3539, Accuracy: 0.3750\n","Epoch 79, Train Loss: 1.3552, Val Loss: 1.5702, F1 Micro: 0.4375, F1 Macro: 0.4049, Accuracy: 0.4375\n","Epoch 80, Train Loss: 1.3809, Val Loss: 1.5903, F1 Micro: 0.3958, F1 Macro: 0.3856, Accuracy: 0.3958\n","Epoch 81, Train Loss: 1.3169, Val Loss: 1.5852, F1 Micro: 0.3750, F1 Macro: 0.3846, Accuracy: 0.3750\n","Epoch 82, Train Loss: 1.3097, Val Loss: 1.5634, F1 Micro: 0.3333, F1 Macro: 0.3349, Accuracy: 0.3333\n","Epoch 83, Train Loss: 1.3371, Val Loss: 1.6014, F1 Micro: 0.3854, F1 Macro: 0.3694, Accuracy: 0.3854\n","Epoch 84, Train Loss: 1.3524, Val Loss: 1.5872, F1 Micro: 0.4167, F1 Macro: 0.3874, Accuracy: 0.4167\n","Epoch 85, Train Loss: 1.3606, Val Loss: 1.4975, F1 Micro: 0.4375, F1 Macro: 0.4336, Accuracy: 0.4375\n","Epoch 86, Train Loss: 1.3447, Val Loss: 1.4905, F1 Micro: 0.4062, F1 Macro: 0.4082, Accuracy: 0.4062\n","Epoch 87, Train Loss: 1.3244, Val Loss: 1.5693, F1 Micro: 0.4271, F1 Macro: 0.4089, Accuracy: 0.4271\n","Epoch 88, Train Loss: 1.3219, Val Loss: 1.5384, F1 Micro: 0.4375, F1 Macro: 0.4292, Accuracy: 0.4375\n","Epoch 89, Train Loss: 1.3028, Val Loss: 1.5797, F1 Micro: 0.4062, F1 Macro: 0.3917, Accuracy: 0.4062\n","Epoch 90, Train Loss: 1.3575, Val Loss: 1.5754, F1 Micro: 0.3958, F1 Macro: 0.3825, Accuracy: 0.3958\n","Epoch 91, Train Loss: 1.3418, Val Loss: 1.4957, F1 Micro: 0.4479, F1 Macro: 0.4528, Accuracy: 0.4479\n","Epoch 92, Train Loss: 1.3073, Val Loss: 1.6242, F1 Micro: 0.3958, F1 Macro: 0.3911, Accuracy: 0.3958\n","Epoch 93, Train Loss: 1.3033, Val Loss: 1.6673, F1 Micro: 0.3229, F1 Macro: 0.3037, Accuracy: 0.3229\n","Epoch 94, Train Loss: 1.3093, Val Loss: 1.6241, F1 Micro: 0.4167, F1 Macro: 0.4258, Accuracy: 0.4167\n","Epoch 95, Train Loss: 1.2709, Val Loss: 1.5644, F1 Micro: 0.4167, F1 Macro: 0.4116, Accuracy: 0.4167\n","Epoch 96, Train Loss: 1.2918, Val Loss: 1.5744, F1 Micro: 0.3854, F1 Macro: 0.3576, Accuracy: 0.3854\n","Epoch 97, Train Loss: 1.2919, Val Loss: 1.5077, F1 Micro: 0.4375, F1 Macro: 0.4320, Accuracy: 0.4375\n","Epoch 98, Train Loss: 1.2583, Val Loss: 1.4494, F1 Micro: 0.4271, F1 Macro: 0.4189, Accuracy: 0.4271\n","Epoch 99, Train Loss: 1.2651, Val Loss: 1.5206, F1 Micro: 0.3750, F1 Macro: 0.3941, Accuracy: 0.3750\n","Epoch 100, Train Loss: 1.3152, Val Loss: 1.4742, F1 Micro: 0.3958, F1 Macro: 0.3710, Accuracy: 0.3958\n","Epoch 101, Train Loss: 1.2840, Val Loss: 1.5489, F1 Micro: 0.3646, F1 Macro: 0.3576, Accuracy: 0.3646\n","Epoch 102, Train Loss: 1.2726, Val Loss: 1.4980, F1 Micro: 0.4167, F1 Macro: 0.4281, Accuracy: 0.4167\n","Epoch 103, Train Loss: 1.2727, Val Loss: 1.4619, F1 Micro: 0.4688, F1 Macro: 0.4714, Accuracy: 0.4688\n","Epoch 104, Train Loss: 1.2792, Val Loss: 1.5836, F1 Micro: 0.3646, F1 Macro: 0.3579, Accuracy: 0.3646\n","Epoch 105, Train Loss: 1.2578, Val Loss: 1.5169, F1 Micro: 0.4167, F1 Macro: 0.4274, Accuracy: 0.4167\n","Epoch 106, Train Loss: 1.2194, Val Loss: 1.5128, F1 Micro: 0.4375, F1 Macro: 0.4448, Accuracy: 0.4375\n","Epoch 107, Train Loss: 1.2319, Val Loss: 1.5520, F1 Micro: 0.3958, F1 Macro: 0.3684, Accuracy: 0.3958\n","Epoch 108, Train Loss: 1.1931, Val Loss: 1.4515, F1 Micro: 0.4375, F1 Macro: 0.4235, Accuracy: 0.4375\n","Epoch 109, Train Loss: 1.1816, Val Loss: 1.5366, F1 Micro: 0.4792, F1 Macro: 0.4751, Accuracy: 0.4792\n","Epoch 110, Train Loss: 1.2024, Val Loss: 1.5141, F1 Micro: 0.4479, F1 Macro: 0.4443, Accuracy: 0.4479\n","Epoch 111, Train Loss: 1.1681, Val Loss: 1.6017, F1 Micro: 0.3854, F1 Macro: 0.3752, Accuracy: 0.3854\n","Epoch 112, Train Loss: 1.1932, Val Loss: 1.5360, F1 Micro: 0.4062, F1 Macro: 0.3970, Accuracy: 0.4062\n","Epoch 113, Train Loss: 1.1717, Val Loss: 1.6714, F1 Micro: 0.3958, F1 Macro: 0.3893, Accuracy: 0.3958\n","Epoch 114, Train Loss: 1.1831, Val Loss: 1.5357, F1 Micro: 0.3646, F1 Macro: 0.3583, Accuracy: 0.3646\n","Epoch 115, Train Loss: 1.1834, Val Loss: 1.4574, F1 Micro: 0.4792, F1 Macro: 0.4897, Accuracy: 0.4792\n","Epoch 116, Train Loss: 1.1259, Val Loss: 1.4553, F1 Micro: 0.4375, F1 Macro: 0.4449, Accuracy: 0.4375\n","Epoch 117, Train Loss: 1.1756, Val Loss: 1.5084, F1 Micro: 0.4375, F1 Macro: 0.4355, Accuracy: 0.4375\n","Epoch 118, Train Loss: 1.1731, Val Loss: 1.4566, F1 Micro: 0.4479, F1 Macro: 0.4512, Accuracy: 0.4479\n","Epoch 119, Train Loss: 1.1832, Val Loss: 1.5192, F1 Micro: 0.4375, F1 Macro: 0.4350, Accuracy: 0.4375\n","Epoch 120, Train Loss: 1.1217, Val Loss: 1.4680, F1 Micro: 0.4062, F1 Macro: 0.4174, Accuracy: 0.4062\n","Epoch 121, Train Loss: 1.1026, Val Loss: 1.5444, F1 Micro: 0.4271, F1 Macro: 0.4047, Accuracy: 0.4271\n","Epoch 122, Train Loss: 1.1108, Val Loss: 1.4339, F1 Micro: 0.4688, F1 Macro: 0.4581, Accuracy: 0.4688\n","Epoch 123, Train Loss: 1.1397, Val Loss: 1.6370, F1 Micro: 0.4375, F1 Macro: 0.4078, Accuracy: 0.4375\n","Epoch 124, Train Loss: 1.2458, Val Loss: 1.5877, F1 Micro: 0.4479, F1 Macro: 0.4008, Accuracy: 0.4479\n","Epoch 125, Train Loss: 1.1842, Val Loss: 1.6064, F1 Micro: 0.4062, F1 Macro: 0.3763, Accuracy: 0.4062\n","Epoch 126, Train Loss: 1.1897, Val Loss: 1.5985, F1 Micro: 0.4062, F1 Macro: 0.3865, Accuracy: 0.4062\n","Epoch 127, Train Loss: 1.1500, Val Loss: 1.4527, F1 Micro: 0.4271, F1 Macro: 0.4378, Accuracy: 0.4271\n","Epoch 128, Train Loss: 1.1426, Val Loss: 1.6740, F1 Micro: 0.3958, F1 Macro: 0.3980, Accuracy: 0.3958\n","Epoch 129, Train Loss: 1.1424, Val Loss: 1.4723, F1 Micro: 0.3854, F1 Macro: 0.3864, Accuracy: 0.3854\n","Epoch 130, Train Loss: 1.1145, Val Loss: 1.4903, F1 Micro: 0.4062, F1 Macro: 0.4087, Accuracy: 0.4062\n","Epoch 131, Train Loss: 1.1532, Val Loss: 1.5240, F1 Micro: 0.4375, F1 Macro: 0.4260, Accuracy: 0.4375\n","Epoch 132, Train Loss: 1.0909, Val Loss: 1.4767, F1 Micro: 0.4271, F1 Macro: 0.4304, Accuracy: 0.4271\n","Epoch 133, Train Loss: 1.1051, Val Loss: 1.6109, F1 Micro: 0.4271, F1 Macro: 0.3984, Accuracy: 0.4271\n","Epoch 134, Train Loss: 1.0741, Val Loss: 1.4836, F1 Micro: 0.4479, F1 Macro: 0.4414, Accuracy: 0.4479\n","Epoch 135, Train Loss: 1.0979, Val Loss: 1.4591, F1 Micro: 0.4688, F1 Macro: 0.4815, Accuracy: 0.4688\n","Epoch 136, Train Loss: 1.0682, Val Loss: 1.4476, F1 Micro: 0.4688, F1 Macro: 0.4681, Accuracy: 0.4688\n","Epoch 137, Train Loss: 1.0842, Val Loss: 1.4940, F1 Micro: 0.3958, F1 Macro: 0.3990, Accuracy: 0.3958\n","Epoch 138, Train Loss: 1.0847, Val Loss: 1.5180, F1 Micro: 0.4688, F1 Macro: 0.4418, Accuracy: 0.4688\n","Epoch 139, Train Loss: 1.0638, Val Loss: 1.4185, F1 Micro: 0.4271, F1 Macro: 0.4383, Accuracy: 0.4271\n","Epoch 140, Train Loss: 1.0435, Val Loss: 1.5360, F1 Micro: 0.4271, F1 Macro: 0.4375, Accuracy: 0.4271\n","Epoch 141, Train Loss: 1.0519, Val Loss: 1.4681, F1 Micro: 0.4062, F1 Macro: 0.4058, Accuracy: 0.4062\n","Epoch 142, Train Loss: 1.0712, Val Loss: 1.7039, F1 Micro: 0.3646, F1 Macro: 0.3534, Accuracy: 0.3646\n","Epoch 143, Train Loss: 1.0532, Val Loss: 1.5226, F1 Micro: 0.4271, F1 Macro: 0.3987, Accuracy: 0.4271\n","Epoch 144, Train Loss: 1.0922, Val Loss: 1.7135, F1 Micro: 0.3333, F1 Macro: 0.3358, Accuracy: 0.3333\n","Epoch 145, Train Loss: 1.1171, Val Loss: 1.4643, F1 Micro: 0.4062, F1 Macro: 0.4227, Accuracy: 0.4062\n","Epoch 146, Train Loss: 1.0621, Val Loss: 1.4860, F1 Micro: 0.4062, F1 Macro: 0.4146, Accuracy: 0.4062\n","Epoch 147, Train Loss: 1.0309, Val Loss: 1.5527, F1 Micro: 0.4062, F1 Macro: 0.4037, Accuracy: 0.4062\n","Epoch 148, Train Loss: 1.0538, Val Loss: 1.4703, F1 Micro: 0.4479, F1 Macro: 0.4581, Accuracy: 0.4479\n","Epoch 149, Train Loss: 1.0483, Val Loss: 1.5253, F1 Micro: 0.3958, F1 Macro: 0.4015, Accuracy: 0.3958\n","Epoch 150, Train Loss: 0.9998, Val Loss: 1.5615, F1 Micro: 0.4062, F1 Macro: 0.3871, Accuracy: 0.4062\n","Epoch 151, Train Loss: 1.0109, Val Loss: 1.5887, F1 Micro: 0.4167, F1 Macro: 0.4219, Accuracy: 0.4167\n","Epoch 152, Train Loss: 0.9999, Val Loss: 1.6028, F1 Micro: 0.4167, F1 Macro: 0.4205, Accuracy: 0.4167\n","Epoch 153, Train Loss: 1.0234, Val Loss: 1.4856, F1 Micro: 0.3958, F1 Macro: 0.3906, Accuracy: 0.3958\n","Epoch 154, Train Loss: 0.9778, Val Loss: 1.5203, F1 Micro: 0.4688, F1 Macro: 0.4644, Accuracy: 0.4688\n","Epoch 155, Train Loss: 1.0090, Val Loss: 1.6056, F1 Micro: 0.4271, F1 Macro: 0.4151, Accuracy: 0.4271\n","Epoch 156, Train Loss: 0.9707, Val Loss: 1.4673, F1 Micro: 0.4688, F1 Macro: 0.4572, Accuracy: 0.4688\n","Epoch 157, Train Loss: 1.0041, Val Loss: 1.5870, F1 Micro: 0.4271, F1 Macro: 0.4195, Accuracy: 0.4271\n","Epoch 158, Train Loss: 1.0154, Val Loss: 1.5524, F1 Micro: 0.4583, F1 Macro: 0.4452, Accuracy: 0.4583\n","Epoch 159, Train Loss: 0.9994, Val Loss: 1.8062, F1 Micro: 0.3854, F1 Macro: 0.3795, Accuracy: 0.3854\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.2118, Val Loss: 1.8252, F1 Micro: 0.2708, F1 Macro: 0.1963, Accuracy: 0.2708\n","Epoch 2, Train Loss: 2.4928, Val Loss: 1.8494, F1 Micro: 0.2708, F1 Macro: 0.2048, Accuracy: 0.2708\n","Epoch 3, Train Loss: 2.3811, Val Loss: 1.9463, F1 Micro: 0.2604, F1 Macro: 0.2009, Accuracy: 0.2604\n","Epoch 4, Train Loss: 2.0308, Val Loss: 2.1338, F1 Micro: 0.2396, F1 Macro: 0.1317, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.9501, Val Loss: 1.9388, F1 Micro: 0.2188, F1 Macro: 0.1677, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.8978, Val Loss: 1.7584, F1 Micro: 0.2188, F1 Macro: 0.1537, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.9316, Val Loss: 1.9648, F1 Micro: 0.2396, F1 Macro: 0.1903, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.8731, Val Loss: 1.9580, F1 Micro: 0.2188, F1 Macro: 0.1262, Accuracy: 0.2188\n","Epoch 9, Train Loss: 1.7683, Val Loss: 1.7767, F1 Micro: 0.2500, F1 Macro: 0.2064, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.7537, Val Loss: 1.6874, F1 Micro: 0.3021, F1 Macro: 0.2124, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.7474, Val Loss: 1.7108, F1 Micro: 0.3021, F1 Macro: 0.2278, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.6861, Val Loss: 1.6563, F1 Micro: 0.3125, F1 Macro: 0.3030, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.7277, Val Loss: 1.9308, F1 Micro: 0.1979, F1 Macro: 0.1218, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.8196, Val Loss: 1.9278, F1 Micro: 0.2917, F1 Macro: 0.2585, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.6806, Val Loss: 1.8019, F1 Micro: 0.2500, F1 Macro: 0.1817, Accuracy: 0.2500\n","Epoch 16, Train Loss: 1.6941, Val Loss: 1.7587, F1 Micro: 0.2917, F1 Macro: 0.2413, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.7319, Val Loss: 1.7218, F1 Micro: 0.2917, F1 Macro: 0.2518, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.6371, Val Loss: 1.7763, F1 Micro: 0.2396, F1 Macro: 0.2019, Accuracy: 0.2396\n","Epoch 19, Train Loss: 1.6760, Val Loss: 1.7322, F1 Micro: 0.3125, F1 Macro: 0.3027, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.6042, Val Loss: 1.7612, F1 Micro: 0.2812, F1 Macro: 0.2481, Accuracy: 0.2812\n","Epoch 21, Train Loss: 1.6378, Val Loss: 1.7772, F1 Micro: 0.2604, F1 Macro: 0.2694, Accuracy: 0.2604\n","Epoch 22, Train Loss: 1.6759, Val Loss: 1.7285, F1 Micro: 0.3021, F1 Macro: 0.2680, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.6414, Val Loss: 1.7553, F1 Micro: 0.2812, F1 Macro: 0.2391, Accuracy: 0.2812\n","Epoch 24, Train Loss: 1.6498, Val Loss: 1.6983, F1 Micro: 0.3542, F1 Macro: 0.2932, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.6396, Val Loss: 1.7974, F1 Micro: 0.2708, F1 Macro: 0.1849, Accuracy: 0.2708\n","Epoch 26, Train Loss: 1.6783, Val Loss: 1.7430, F1 Micro: 0.3125, F1 Macro: 0.2846, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.6308, Val Loss: 1.7272, F1 Micro: 0.2812, F1 Macro: 0.2676, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.6104, Val Loss: 1.7586, F1 Micro: 0.2917, F1 Macro: 0.2635, Accuracy: 0.2917\n","Epoch 29, Train Loss: 1.5835, Val Loss: 1.7410, F1 Micro: 0.3542, F1 Macro: 0.3237, Accuracy: 0.3542\n","Epoch 30, Train Loss: 1.5959, Val Loss: 1.7929, F1 Micro: 0.3021, F1 Macro: 0.2883, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.6019, Val Loss: 1.7582, F1 Micro: 0.3229, F1 Macro: 0.2712, Accuracy: 0.3229\n","Epoch 32, Train Loss: 1.6084, Val Loss: 1.7588, F1 Micro: 0.3438, F1 Macro: 0.3083, Accuracy: 0.3438\n","Epoch 33, Train Loss: 1.5798, Val Loss: 1.7990, F1 Micro: 0.3229, F1 Macro: 0.3041, Accuracy: 0.3229\n","Epoch 34, Train Loss: 1.6463, Val Loss: 1.7968, F1 Micro: 0.2604, F1 Macro: 0.1981, Accuracy: 0.2604\n","Epoch 35, Train Loss: 1.5856, Val Loss: 1.8180, F1 Micro: 0.3021, F1 Macro: 0.2959, Accuracy: 0.3021\n","Epoch 36, Train Loss: 1.5512, Val Loss: 1.7817, F1 Micro: 0.3021, F1 Macro: 0.2592, Accuracy: 0.3021\n","Epoch 37, Train Loss: 1.5044, Val Loss: 1.8398, F1 Micro: 0.2917, F1 Macro: 0.2249, Accuracy: 0.2917\n","Epoch 38, Train Loss: 1.5546, Val Loss: 1.7832, F1 Micro: 0.3229, F1 Macro: 0.2955, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.5418, Val Loss: 1.7951, F1 Micro: 0.3229, F1 Macro: 0.2811, Accuracy: 0.3229\n","Epoch 40, Train Loss: 1.5199, Val Loss: 1.8216, F1 Micro: 0.3438, F1 Macro: 0.3042, Accuracy: 0.3438\n","Epoch 41, Train Loss: 1.5034, Val Loss: 1.8925, F1 Micro: 0.2604, F1 Macro: 0.2154, Accuracy: 0.2604\n","Epoch 42, Train Loss: 1.5086, Val Loss: 1.7537, F1 Micro: 0.3229, F1 Macro: 0.3141, Accuracy: 0.3229\n","Epoch 43, Train Loss: 1.4765, Val Loss: 1.7745, F1 Micro: 0.3333, F1 Macro: 0.3012, Accuracy: 0.3333\n","Epoch 44, Train Loss: 1.5155, Val Loss: 1.8286, F1 Micro: 0.3125, F1 Macro: 0.2933, Accuracy: 0.3125\n","Epoch 45, Train Loss: 1.5171, Val Loss: 1.7676, F1 Micro: 0.2917, F1 Macro: 0.2906, Accuracy: 0.2917\n","Epoch 46, Train Loss: 1.4806, Val Loss: 1.8595, F1 Micro: 0.3229, F1 Macro: 0.3028, Accuracy: 0.3229\n","Epoch 47, Train Loss: 1.5067, Val Loss: 1.8343, F1 Micro: 0.3021, F1 Macro: 0.2718, Accuracy: 0.3021\n","Epoch 48, Train Loss: 1.5081, Val Loss: 1.8134, F1 Micro: 0.3021, F1 Macro: 0.2798, Accuracy: 0.3021\n","Epoch 49, Train Loss: 1.5669, Val Loss: 1.7988, F1 Micro: 0.3021, F1 Macro: 0.2650, Accuracy: 0.3021\n","Epoch 50, Train Loss: 1.5210, Val Loss: 1.7283, F1 Micro: 0.3646, F1 Macro: 0.3378, Accuracy: 0.3646\n","Epoch 51, Train Loss: 1.4918, Val Loss: 1.8164, F1 Micro: 0.3542, F1 Macro: 0.3277, Accuracy: 0.3542\n","Epoch 52, Train Loss: 1.4783, Val Loss: 1.9239, F1 Micro: 0.2812, F1 Macro: 0.2315, Accuracy: 0.2812\n","Epoch 53, Train Loss: 1.4964, Val Loss: 1.7896, F1 Micro: 0.2917, F1 Macro: 0.2743, Accuracy: 0.2917\n","Epoch 54, Train Loss: 1.4281, Val Loss: 1.7867, F1 Micro: 0.3438, F1 Macro: 0.3198, Accuracy: 0.3438\n","Epoch 55, Train Loss: 1.5028, Val Loss: 1.8004, F1 Micro: 0.2708, F1 Macro: 0.2362, Accuracy: 0.2708\n","Epoch 56, Train Loss: 1.4530, Val Loss: 1.8372, F1 Micro: 0.3229, F1 Macro: 0.3272, Accuracy: 0.3229\n","Epoch 57, Train Loss: 1.4262, Val Loss: 1.7691, F1 Micro: 0.3750, F1 Macro: 0.3718, Accuracy: 0.3750\n","Epoch 58, Train Loss: 1.4478, Val Loss: 1.7675, F1 Micro: 0.3750, F1 Macro: 0.3598, Accuracy: 0.3750\n","Epoch 59, Train Loss: 1.4714, Val Loss: 1.8003, F1 Micro: 0.2917, F1 Macro: 0.2731, Accuracy: 0.2917\n","Epoch 60, Train Loss: 1.4325, Val Loss: 1.7993, F1 Micro: 0.3438, F1 Macro: 0.3218, Accuracy: 0.3438\n","Epoch 61, Train Loss: 1.3874, Val Loss: 1.7646, F1 Micro: 0.3750, F1 Macro: 0.3620, Accuracy: 0.3750\n","Epoch 62, Train Loss: 1.3992, Val Loss: 1.7986, F1 Micro: 0.3125, F1 Macro: 0.3035, Accuracy: 0.3125\n","Epoch 63, Train Loss: 1.3805, Val Loss: 1.7557, F1 Micro: 0.2917, F1 Macro: 0.2781, Accuracy: 0.2917\n","Epoch 64, Train Loss: 1.4373, Val Loss: 1.7960, F1 Micro: 0.3438, F1 Macro: 0.3468, Accuracy: 0.3438\n","Epoch 65, Train Loss: 1.4132, Val Loss: 1.9129, F1 Micro: 0.3021, F1 Macro: 0.2805, Accuracy: 0.3021\n","Epoch 66, Train Loss: 1.4526, Val Loss: 1.7631, F1 Micro: 0.3229, F1 Macro: 0.3129, Accuracy: 0.3229\n","Epoch 67, Train Loss: 1.3913, Val Loss: 1.7916, F1 Micro: 0.3229, F1 Macro: 0.3044, Accuracy: 0.3229\n","Epoch 68, Train Loss: 1.4129, Val Loss: 1.7523, F1 Micro: 0.3646, F1 Macro: 0.3629, Accuracy: 0.3646\n","Epoch 69, Train Loss: 1.3752, Val Loss: 1.7530, F1 Micro: 0.3542, F1 Macro: 0.3193, Accuracy: 0.3542\n","Epoch 70, Train Loss: 1.4090, Val Loss: 1.7676, F1 Micro: 0.3854, F1 Macro: 0.3851, Accuracy: 0.3854\n","Epoch 71, Train Loss: 1.3381, Val Loss: 1.7829, F1 Micro: 0.3750, F1 Macro: 0.3632, Accuracy: 0.3750\n","Epoch 72, Train Loss: 1.3575, Val Loss: 1.7996, F1 Micro: 0.3750, F1 Macro: 0.3542, Accuracy: 0.3750\n","Epoch 73, Train Loss: 1.3709, Val Loss: 1.7257, F1 Micro: 0.3542, F1 Macro: 0.3469, Accuracy: 0.3542\n","Epoch 74, Train Loss: 1.4494, Val Loss: 1.7802, F1 Micro: 0.3542, F1 Macro: 0.3438, Accuracy: 0.3542\n","Epoch 75, Train Loss: 1.3990, Val Loss: 1.7467, F1 Micro: 0.3229, F1 Macro: 0.3216, Accuracy: 0.3229\n","Epoch 76, Train Loss: 1.4000, Val Loss: 1.7513, F1 Micro: 0.3229, F1 Macro: 0.3234, Accuracy: 0.3229\n","Epoch 77, Train Loss: 1.3127, Val Loss: 1.7966, F1 Micro: 0.4167, F1 Macro: 0.4059, Accuracy: 0.4167\n","Epoch 78, Train Loss: 1.3417, Val Loss: 1.7902, F1 Micro: 0.4167, F1 Macro: 0.3926, Accuracy: 0.4167\n","Epoch 79, Train Loss: 1.3273, Val Loss: 1.8164, F1 Micro: 0.3750, F1 Macro: 0.3633, Accuracy: 0.3750\n","Epoch 80, Train Loss: 1.3294, Val Loss: 1.7172, F1 Micro: 0.4271, F1 Macro: 0.3961, Accuracy: 0.4271\n","Epoch 81, Train Loss: 1.4007, Val Loss: 1.7963, F1 Micro: 0.3438, F1 Macro: 0.3351, Accuracy: 0.3438\n","Epoch 82, Train Loss: 1.3302, Val Loss: 1.7052, F1 Micro: 0.3854, F1 Macro: 0.3720, Accuracy: 0.3854\n","Epoch 83, Train Loss: 1.2896, Val Loss: 1.7812, F1 Micro: 0.3958, F1 Macro: 0.3566, Accuracy: 0.3958\n","Epoch 84, Train Loss: 1.3207, Val Loss: 1.7289, F1 Micro: 0.3750, F1 Macro: 0.3563, Accuracy: 0.3750\n","Epoch 85, Train Loss: 1.2710, Val Loss: 1.7254, F1 Micro: 0.3646, F1 Macro: 0.3487, Accuracy: 0.3646\n","Epoch 86, Train Loss: 1.2891, Val Loss: 1.7744, F1 Micro: 0.3958, F1 Macro: 0.3955, Accuracy: 0.3958\n","Epoch 87, Train Loss: 1.2876, Val Loss: 1.7677, F1 Micro: 0.3646, F1 Macro: 0.3475, Accuracy: 0.3646\n","Epoch 88, Train Loss: 1.3128, Val Loss: 1.7054, F1 Micro: 0.4375, F1 Macro: 0.4216, Accuracy: 0.4375\n","Epoch 89, Train Loss: 1.2620, Val Loss: 1.7491, F1 Micro: 0.3854, F1 Macro: 0.3678, Accuracy: 0.3854\n","Epoch 90, Train Loss: 1.2665, Val Loss: 1.7182, F1 Micro: 0.3958, F1 Macro: 0.3969, Accuracy: 0.3958\n","Epoch 91, Train Loss: 1.2342, Val Loss: 1.7922, F1 Micro: 0.4062, F1 Macro: 0.4082, Accuracy: 0.4062\n","Epoch 92, Train Loss: 1.2439, Val Loss: 1.7903, F1 Micro: 0.4167, F1 Macro: 0.4202, Accuracy: 0.4167\n","Epoch 93, Train Loss: 1.2474, Val Loss: 1.8287, F1 Micro: 0.3333, F1 Macro: 0.3090, Accuracy: 0.3333\n","Epoch 94, Train Loss: 1.2518, Val Loss: 1.7120, F1 Micro: 0.3750, F1 Macro: 0.3568, Accuracy: 0.3750\n","Epoch 95, Train Loss: 1.2928, Val Loss: 1.7448, F1 Micro: 0.4271, F1 Macro: 0.3988, Accuracy: 0.4271\n","Epoch 96, Train Loss: 1.2823, Val Loss: 1.7074, F1 Micro: 0.3958, F1 Macro: 0.3934, Accuracy: 0.3958\n","Epoch 97, Train Loss: 1.2101, Val Loss: 1.7229, F1 Micro: 0.4688, F1 Macro: 0.4389, Accuracy: 0.4688\n","Epoch 98, Train Loss: 1.2515, Val Loss: 1.6975, F1 Micro: 0.3854, F1 Macro: 0.3693, Accuracy: 0.3854\n","Epoch 99, Train Loss: 1.2157, Val Loss: 1.8020, F1 Micro: 0.4271, F1 Macro: 0.4158, Accuracy: 0.4271\n","Epoch 100, Train Loss: 1.2181, Val Loss: 1.7331, F1 Micro: 0.4062, F1 Macro: 0.3794, Accuracy: 0.4062\n","Epoch 101, Train Loss: 1.2294, Val Loss: 1.7828, F1 Micro: 0.4271, F1 Macro: 0.4140, Accuracy: 0.4271\n","Epoch 102, Train Loss: 1.2403, Val Loss: 1.7979, F1 Micro: 0.4167, F1 Macro: 0.3938, Accuracy: 0.4167\n","Epoch 103, Train Loss: 1.2349, Val Loss: 1.7436, F1 Micro: 0.4688, F1 Macro: 0.4341, Accuracy: 0.4688\n","Epoch 104, Train Loss: 1.2216, Val Loss: 1.8059, F1 Micro: 0.4062, F1 Macro: 0.3754, Accuracy: 0.4062\n","Epoch 105, Train Loss: 1.2730, Val Loss: 1.7355, F1 Micro: 0.4479, F1 Macro: 0.4470, Accuracy: 0.4479\n","Epoch 106, Train Loss: 1.2256, Val Loss: 1.7979, F1 Micro: 0.4062, F1 Macro: 0.3744, Accuracy: 0.4062\n","Epoch 107, Train Loss: 1.2284, Val Loss: 1.6969, F1 Micro: 0.4792, F1 Macro: 0.4644, Accuracy: 0.4792\n","Epoch 108, Train Loss: 1.1615, Val Loss: 1.8818, F1 Micro: 0.3854, F1 Macro: 0.3630, Accuracy: 0.3854\n","Epoch 109, Train Loss: 1.1829, Val Loss: 1.7954, F1 Micro: 0.4375, F1 Macro: 0.4276, Accuracy: 0.4375\n","Epoch 110, Train Loss: 1.1638, Val Loss: 1.7027, F1 Micro: 0.4896, F1 Macro: 0.4728, Accuracy: 0.4896\n","Epoch 111, Train Loss: 1.1628, Val Loss: 1.8810, F1 Micro: 0.3750, F1 Macro: 0.3581, Accuracy: 0.3750\n","Epoch 112, Train Loss: 1.2637, Val Loss: 1.6637, F1 Micro: 0.4583, F1 Macro: 0.4485, Accuracy: 0.4583\n","Epoch 113, Train Loss: 1.1704, Val Loss: 1.8134, F1 Micro: 0.3542, F1 Macro: 0.3451, Accuracy: 0.3542\n","Epoch 114, Train Loss: 1.1432, Val Loss: 1.7136, F1 Micro: 0.4583, F1 Macro: 0.4293, Accuracy: 0.4583\n","Epoch 115, Train Loss: 1.1611, Val Loss: 1.7961, F1 Micro: 0.3750, F1 Macro: 0.3654, Accuracy: 0.3750\n","Epoch 116, Train Loss: 1.1432, Val Loss: 1.7366, F1 Micro: 0.4167, F1 Macro: 0.3876, Accuracy: 0.4167\n","Epoch 117, Train Loss: 1.1167, Val Loss: 1.7148, F1 Micro: 0.4271, F1 Macro: 0.3929, Accuracy: 0.4271\n","Epoch 118, Train Loss: 1.1530, Val Loss: 1.7884, F1 Micro: 0.4583, F1 Macro: 0.4228, Accuracy: 0.4583\n","Epoch 119, Train Loss: 1.1083, Val Loss: 1.7318, F1 Micro: 0.4583, F1 Macro: 0.4553, Accuracy: 0.4583\n","Epoch 120, Train Loss: 1.1234, Val Loss: 1.7469, F1 Micro: 0.4375, F1 Macro: 0.4144, Accuracy: 0.4375\n","Epoch 121, Train Loss: 1.1174, Val Loss: 1.8101, F1 Micro: 0.4375, F1 Macro: 0.4178, Accuracy: 0.4375\n","Epoch 122, Train Loss: 1.1071, Val Loss: 1.7741, F1 Micro: 0.4688, F1 Macro: 0.4703, Accuracy: 0.4688\n","Epoch 123, Train Loss: 1.0663, Val Loss: 1.7589, F1 Micro: 0.4896, F1 Macro: 0.4833, Accuracy: 0.4896\n","Epoch 124, Train Loss: 1.0962, Val Loss: 1.7629, F1 Micro: 0.4375, F1 Macro: 0.4381, Accuracy: 0.4375\n","Epoch 125, Train Loss: 1.1087, Val Loss: 1.7260, F1 Micro: 0.4896, F1 Macro: 0.5058, Accuracy: 0.4896\n","Epoch 126, Train Loss: 1.0749, Val Loss: 1.8334, F1 Micro: 0.4479, F1 Macro: 0.4533, Accuracy: 0.4479\n","Epoch 127, Train Loss: 1.0935, Val Loss: 1.7706, F1 Micro: 0.4896, F1 Macro: 0.4775, Accuracy: 0.4896\n","Epoch 128, Train Loss: 1.1008, Val Loss: 1.7602, F1 Micro: 0.4479, F1 Macro: 0.4525, Accuracy: 0.4479\n","Epoch 129, Train Loss: 1.0933, Val Loss: 1.7601, F1 Micro: 0.4792, F1 Macro: 0.4788, Accuracy: 0.4792\n","Epoch 130, Train Loss: 1.0658, Val Loss: 1.9280, F1 Micro: 0.3958, F1 Macro: 0.3831, Accuracy: 0.3958\n","Epoch 131, Train Loss: 1.0706, Val Loss: 1.7344, F1 Micro: 0.5104, F1 Macro: 0.5011, Accuracy: 0.5104\n","Epoch 132, Train Loss: 1.1394, Val Loss: 1.9287, F1 Micro: 0.4062, F1 Macro: 0.4037, Accuracy: 0.4062\n","Epoch 133, Train Loss: 1.0574, Val Loss: 1.7253, F1 Micro: 0.4271, F1 Macro: 0.4027, Accuracy: 0.4271\n","Epoch 134, Train Loss: 1.0257, Val Loss: 1.8940, F1 Micro: 0.4375, F1 Macro: 0.4085, Accuracy: 0.4375\n","Epoch 135, Train Loss: 1.1488, Val Loss: 1.7590, F1 Micro: 0.4271, F1 Macro: 0.3890, Accuracy: 0.4271\n","Epoch 136, Train Loss: 1.0675, Val Loss: 1.8214, F1 Micro: 0.4479, F1 Macro: 0.4248, Accuracy: 0.4479\n","Epoch 137, Train Loss: 1.0401, Val Loss: 1.8260, F1 Micro: 0.4375, F1 Macro: 0.4104, Accuracy: 0.4375\n","Epoch 138, Train Loss: 1.0383, Val Loss: 1.7905, F1 Micro: 0.4583, F1 Macro: 0.4464, Accuracy: 0.4583\n","Epoch 139, Train Loss: 0.9959, Val Loss: 1.7888, F1 Micro: 0.4688, F1 Macro: 0.4651, Accuracy: 0.4688\n","Epoch 140, Train Loss: 1.0056, Val Loss: 1.7934, F1 Micro: 0.4688, F1 Macro: 0.4412, Accuracy: 0.4688\n","Epoch 141, Train Loss: 1.0124, Val Loss: 1.9160, F1 Micro: 0.4792, F1 Macro: 0.4925, Accuracy: 0.4792\n","Epoch 142, Train Loss: 0.9968, Val Loss: 1.7581, F1 Micro: 0.4479, F1 Macro: 0.4534, Accuracy: 0.4479\n","Epoch 143, Train Loss: 1.0004, Val Loss: 1.8022, F1 Micro: 0.4479, F1 Macro: 0.4557, Accuracy: 0.4479\n","Epoch 144, Train Loss: 1.0169, Val Loss: 1.7913, F1 Micro: 0.4792, F1 Macro: 0.4870, Accuracy: 0.4792\n","Epoch 145, Train Loss: 1.0086, Val Loss: 1.7632, F1 Micro: 0.4792, F1 Macro: 0.4715, Accuracy: 0.4792\n","Epoch 146, Train Loss: 1.0054, Val Loss: 1.7681, F1 Micro: 0.4896, F1 Macro: 0.4930, Accuracy: 0.4896\n","Epoch 147, Train Loss: 1.0268, Val Loss: 1.8216, F1 Micro: 0.4792, F1 Macro: 0.4649, Accuracy: 0.4792\n","Epoch 148, Train Loss: 0.9723, Val Loss: 1.9713, F1 Micro: 0.3646, F1 Macro: 0.3475, Accuracy: 0.3646\n","Epoch 149, Train Loss: 0.9812, Val Loss: 1.9422, F1 Micro: 0.4167, F1 Macro: 0.3961, Accuracy: 0.4167\n","Epoch 150, Train Loss: 1.0027, Val Loss: 1.8062, F1 Micro: 0.4583, F1 Macro: 0.4477, Accuracy: 0.4583\n","Epoch 151, Train Loss: 0.9697, Val Loss: 1.9164, F1 Micro: 0.4896, F1 Macro: 0.4593, Accuracy: 0.4896\n","Epoch 152, Train Loss: 1.0419, Val Loss: 1.7927, F1 Micro: 0.4375, F1 Macro: 0.4323, Accuracy: 0.4375\n","Epoch 153, Train Loss: 0.9714, Val Loss: 1.8282, F1 Micro: 0.4688, F1 Macro: 0.4736, Accuracy: 0.4688\n","Epoch 154, Train Loss: 0.9635, Val Loss: 1.8758, F1 Micro: 0.4688, F1 Macro: 0.4863, Accuracy: 0.4688\n","Epoch 155, Train Loss: 0.9296, Val Loss: 1.8859, F1 Micro: 0.4375, F1 Macro: 0.4385, Accuracy: 0.4375\n","Epoch 156, Train Loss: 0.9713, Val Loss: 1.8843, F1 Micro: 0.4271, F1 Macro: 0.4125, Accuracy: 0.4271\n","Epoch 157, Train Loss: 1.0033, Val Loss: 1.8383, F1 Micro: 0.4479, F1 Macro: 0.4405, Accuracy: 0.4479\n","Epoch 158, Train Loss: 0.9404, Val Loss: 1.8327, F1 Micro: 0.5000, F1 Macro: 0.4926, Accuracy: 0.5000\n","Epoch 159, Train Loss: 1.0181, Val Loss: 1.8478, F1 Micro: 0.5000, F1 Macro: 0.5025, Accuracy: 0.5000\n","Epoch 160, Train Loss: 1.0273, Val Loss: 1.9883, F1 Micro: 0.4375, F1 Macro: 0.4471, Accuracy: 0.4375\n","Epoch 161, Train Loss: 0.9405, Val Loss: 1.8567, F1 Micro: 0.4583, F1 Macro: 0.4364, Accuracy: 0.4583\n","Epoch 162, Train Loss: 0.9064, Val Loss: 1.8569, F1 Micro: 0.4896, F1 Macro: 0.4927, Accuracy: 0.4896\n","Epoch 163, Train Loss: 0.9092, Val Loss: 1.8067, F1 Micro: 0.4896, F1 Macro: 0.4681, Accuracy: 0.4896\n","Epoch 164, Train Loss: 0.9607, Val Loss: 1.7571, F1 Micro: 0.4896, F1 Macro: 0.4862, Accuracy: 0.4896\n","Epoch 165, Train Loss: 0.9343, Val Loss: 1.8647, F1 Micro: 0.5000, F1 Macro: 0.4915, Accuracy: 0.5000\n","Epoch 166, Train Loss: 0.9503, Val Loss: 1.8190, F1 Micro: 0.4271, F1 Macro: 0.4074, Accuracy: 0.4271\n","Epoch 167, Train Loss: 0.8915, Val Loss: 1.8747, F1 Micro: 0.4792, F1 Macro: 0.4617, Accuracy: 0.4792\n","Epoch 168, Train Loss: 0.8859, Val Loss: 1.9015, F1 Micro: 0.4896, F1 Macro: 0.4715, Accuracy: 0.4896\n","Epoch 169, Train Loss: 0.9498, Val Loss: 1.7956, F1 Micro: 0.4688, F1 Macro: 0.4780, Accuracy: 0.4688\n","Epoch 170, Train Loss: 0.9159, Val Loss: 1.8397, F1 Micro: 0.4479, F1 Macro: 0.4466, Accuracy: 0.4479\n","Epoch 171, Train Loss: 0.8874, Val Loss: 1.9799, F1 Micro: 0.4688, F1 Macro: 0.4698, Accuracy: 0.4688\n","Epoch 172, Train Loss: 0.9165, Val Loss: 1.8884, F1 Micro: 0.4479, F1 Macro: 0.4564, Accuracy: 0.4479\n","Epoch 173, Train Loss: 0.8697, Val Loss: 1.9227, F1 Micro: 0.4479, F1 Macro: 0.4489, Accuracy: 0.4479\n","Epoch 174, Train Loss: 0.9073, Val Loss: 1.9623, F1 Micro: 0.4688, F1 Macro: 0.4707, Accuracy: 0.4688\n","Epoch 175, Train Loss: 0.8591, Val Loss: 1.8437, F1 Micro: 0.4375, F1 Macro: 0.4466, Accuracy: 0.4375\n","Epoch 176, Train Loss: 0.9152, Val Loss: 1.8245, F1 Micro: 0.4688, F1 Macro: 0.4662, Accuracy: 0.4688\n","Epoch 177, Train Loss: 0.8647, Val Loss: 1.8838, F1 Micro: 0.5104, F1 Macro: 0.5209, Accuracy: 0.5104\n","Epoch 178, Train Loss: 0.9117, Val Loss: 1.9363, F1 Micro: 0.5104, F1 Macro: 0.4983, Accuracy: 0.5104\n","Epoch 179, Train Loss: 0.8796, Val Loss: 1.8779, F1 Micro: 0.4896, F1 Macro: 0.4994, Accuracy: 0.4896\n","Epoch 180, Train Loss: 0.8559, Val Loss: 1.9692, F1 Micro: 0.4583, F1 Macro: 0.4605, Accuracy: 0.4583\n","Epoch 181, Train Loss: 0.8524, Val Loss: 1.9801, F1 Micro: 0.4896, F1 Macro: 0.4849, Accuracy: 0.4896\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.5312499999999999\n","Best hyperparameters for Outer FOLD 4: (0.001, 8, 50) with score 0.5833333333333333\n","Epoch 1, Train Loss: 3.1290, Val Loss: 2.0448, F1 Micro: 0.2667, F1 Macro: 0.1935, Accuracy: 0.2667\n","Epoch 2, Train Loss: 2.2769, Val Loss: 1.8773, F1 Micro: 0.2417, F1 Macro: 0.1369, Accuracy: 0.2417\n","Epoch 3, Train Loss: 2.1800, Val Loss: 1.7758, F1 Micro: 0.2583, F1 Macro: 0.1909, Accuracy: 0.2583\n","Epoch 4, Train Loss: 1.9577, Val Loss: 1.9171, F1 Micro: 0.2250, F1 Macro: 0.1475, Accuracy: 0.2250\n","Epoch 5, Train Loss: 1.8273, Val Loss: 1.7011, F1 Micro: 0.2417, F1 Macro: 0.1692, Accuracy: 0.2417\n","Epoch 6, Train Loss: 1.8836, Val Loss: 1.7002, F1 Micro: 0.2417, F1 Macro: 0.1862, Accuracy: 0.2417\n","Epoch 7, Train Loss: 1.8086, Val Loss: 1.7177, F1 Micro: 0.2417, F1 Macro: 0.1860, Accuracy: 0.2417\n","Epoch 8, Train Loss: 1.7670, Val Loss: 1.7701, F1 Micro: 0.2333, F1 Macro: 0.1742, Accuracy: 0.2333\n","Epoch 9, Train Loss: 1.7257, Val Loss: 1.7773, F1 Micro: 0.2500, F1 Macro: 0.2144, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.7604, Val Loss: 1.6886, F1 Micro: 0.3000, F1 Macro: 0.2486, Accuracy: 0.3000\n","Epoch 11, Train Loss: 1.7362, Val Loss: 1.6802, F1 Micro: 0.2583, F1 Macro: 0.2166, Accuracy: 0.2583\n","Epoch 12, Train Loss: 1.7266, Val Loss: 1.7532, F1 Micro: 0.2583, F1 Macro: 0.2126, Accuracy: 0.2583\n","Epoch 13, Train Loss: 1.7000, Val Loss: 1.6370, F1 Micro: 0.3333, F1 Macro: 0.3040, Accuracy: 0.3333\n","Epoch 14, Train Loss: 1.7166, Val Loss: 1.6622, F1 Micro: 0.3417, F1 Macro: 0.2762, Accuracy: 0.3417\n","Epoch 15, Train Loss: 1.7179, Val Loss: 1.6313, F1 Micro: 0.3833, F1 Macro: 0.3763, Accuracy: 0.3833\n","Epoch 16, Train Loss: 1.7132, Val Loss: 1.6487, F1 Micro: 0.3167, F1 Macro: 0.2303, Accuracy: 0.3167\n","Epoch 17, Train Loss: 1.6687, Val Loss: 1.6277, F1 Micro: 0.3250, F1 Macro: 0.2588, Accuracy: 0.3250\n","Epoch 18, Train Loss: 1.6612, Val Loss: 1.6657, F1 Micro: 0.3417, F1 Macro: 0.2720, Accuracy: 0.3417\n","Epoch 19, Train Loss: 1.6359, Val Loss: 1.6340, F1 Micro: 0.3500, F1 Macro: 0.3067, Accuracy: 0.3500\n","Epoch 20, Train Loss: 1.6332, Val Loss: 1.6340, F1 Micro: 0.3333, F1 Macro: 0.2917, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.6254, Val Loss: 1.6735, F1 Micro: 0.2667, F1 Macro: 0.2569, Accuracy: 0.2667\n","Epoch 22, Train Loss: 1.6379, Val Loss: 1.6222, F1 Micro: 0.3667, F1 Macro: 0.3362, Accuracy: 0.3667\n","Epoch 23, Train Loss: 1.6034, Val Loss: 1.6886, F1 Micro: 0.2750, F1 Macro: 0.2189, Accuracy: 0.2750\n","Epoch 24, Train Loss: 1.6153, Val Loss: 1.6134, F1 Micro: 0.3250, F1 Macro: 0.2862, Accuracy: 0.3250\n","Epoch 25, Train Loss: 1.6118, Val Loss: 1.6473, F1 Micro: 0.3083, F1 Macro: 0.2678, Accuracy: 0.3083\n","Epoch 26, Train Loss: 1.5818, Val Loss: 1.6980, F1 Micro: 0.2667, F1 Macro: 0.2483, Accuracy: 0.2667\n","Epoch 27, Train Loss: 1.5865, Val Loss: 1.8598, F1 Micro: 0.2583, F1 Macro: 0.2097, Accuracy: 0.2583\n","Epoch 28, Train Loss: 1.5657, Val Loss: 1.5582, F1 Micro: 0.4083, F1 Macro: 0.3638, Accuracy: 0.4083\n","Epoch 29, Train Loss: 1.5387, Val Loss: 1.7212, F1 Micro: 0.3083, F1 Macro: 0.2942, Accuracy: 0.3083\n","Epoch 30, Train Loss: 1.6045, Val Loss: 1.5801, F1 Micro: 0.3500, F1 Macro: 0.3087, Accuracy: 0.3500\n","Epoch 31, Train Loss: 1.5971, Val Loss: 1.5923, F1 Micro: 0.3333, F1 Macro: 0.2790, Accuracy: 0.3333\n","Epoch 32, Train Loss: 1.5123, Val Loss: 1.8654, F1 Micro: 0.2500, F1 Macro: 0.2098, Accuracy: 0.2500\n","Epoch 33, Train Loss: 1.5866, Val Loss: 1.6524, F1 Micro: 0.2917, F1 Macro: 0.2655, Accuracy: 0.2917\n","Epoch 34, Train Loss: 1.5699, Val Loss: 1.7250, F1 Micro: 0.2833, F1 Macro: 0.2703, Accuracy: 0.2833\n","Epoch 35, Train Loss: 1.5415, Val Loss: 1.6303, F1 Micro: 0.3833, F1 Macro: 0.3166, Accuracy: 0.3833\n","Epoch 36, Train Loss: 1.5144, Val Loss: 1.5629, F1 Micro: 0.4250, F1 Macro: 0.4060, Accuracy: 0.4250\n","Epoch 37, Train Loss: 1.5145, Val Loss: 1.6648, F1 Micro: 0.3333, F1 Macro: 0.3086, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.5029, Val Loss: 1.6291, F1 Micro: 0.3583, F1 Macro: 0.3263, Accuracy: 0.3583\n","Epoch 39, Train Loss: 1.4951, Val Loss: 1.5748, F1 Micro: 0.3917, F1 Macro: 0.3286, Accuracy: 0.3917\n","Epoch 40, Train Loss: 1.4997, Val Loss: 1.5788, F1 Micro: 0.3500, F1 Macro: 0.2974, Accuracy: 0.3500\n","Epoch 41, Train Loss: 1.5237, Val Loss: 1.6043, F1 Micro: 0.3333, F1 Macro: 0.2985, Accuracy: 0.3333\n","Epoch 42, Train Loss: 1.5177, Val Loss: 1.6150, F1 Micro: 0.3750, F1 Macro: 0.3506, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.4659, Val Loss: 1.5521, F1 Micro: 0.4000, F1 Macro: 0.3659, Accuracy: 0.4000\n","Epoch 44, Train Loss: 1.4983, Val Loss: 1.5646, F1 Micro: 0.3500, F1 Macro: 0.3051, Accuracy: 0.3500\n","Epoch 45, Train Loss: 1.4990, Val Loss: 1.5484, F1 Micro: 0.4167, F1 Macro: 0.3992, Accuracy: 0.4167\n","Epoch 46, Train Loss: 1.5015, Val Loss: 1.4956, F1 Micro: 0.4250, F1 Macro: 0.4111, Accuracy: 0.4250\n","Epoch 47, Train Loss: 1.4414, Val Loss: 1.5225, F1 Micro: 0.4250, F1 Macro: 0.4250, Accuracy: 0.4250\n","Epoch 48, Train Loss: 1.4298, Val Loss: 1.6924, F1 Micro: 0.3250, F1 Macro: 0.3039, Accuracy: 0.3250\n","Epoch 49, Train Loss: 1.4648, Val Loss: 1.5007, F1 Micro: 0.3917, F1 Macro: 0.3723, Accuracy: 0.3917\n","Epoch 50, Train Loss: 1.4572, Val Loss: 1.5209, F1 Micro: 0.4417, F1 Macro: 0.4417, Accuracy: 0.4417\n","Epoch 51, Train Loss: 1.4343, Val Loss: 1.8804, F1 Micro: 0.2833, F1 Macro: 0.2639, Accuracy: 0.2833\n","Epoch 52, Train Loss: 1.4763, Val Loss: 1.4912, F1 Micro: 0.4167, F1 Macro: 0.4165, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.4263, Val Loss: 1.5258, F1 Micro: 0.4500, F1 Macro: 0.4330, Accuracy: 0.4500\n","Epoch 54, Train Loss: 1.4463, Val Loss: 1.5507, F1 Micro: 0.4250, F1 Macro: 0.3785, Accuracy: 0.4250\n","Epoch 55, Train Loss: 1.3707, Val Loss: 1.5626, F1 Micro: 0.4333, F1 Macro: 0.4241, Accuracy: 0.4333\n","Epoch 56, Train Loss: 1.3632, Val Loss: 1.5550, F1 Micro: 0.3667, F1 Macro: 0.3146, Accuracy: 0.3667\n","Epoch 57, Train Loss: 1.3750, Val Loss: 1.5180, F1 Micro: 0.4167, F1 Macro: 0.3929, Accuracy: 0.4167\n","Epoch 58, Train Loss: 1.3915, Val Loss: 1.8153, F1 Micro: 0.3167, F1 Macro: 0.2738, Accuracy: 0.3167\n","Epoch 59, Train Loss: 1.4136, Val Loss: 1.5537, F1 Micro: 0.4250, F1 Macro: 0.4109, Accuracy: 0.4250\n","Epoch 60, Train Loss: 1.4119, Val Loss: 1.5141, F1 Micro: 0.4250, F1 Macro: 0.3987, Accuracy: 0.4250\n","Epoch 61, Train Loss: 1.3538, Val Loss: 1.7101, F1 Micro: 0.3750, F1 Macro: 0.3486, Accuracy: 0.3750\n","Epoch 62, Train Loss: 1.3961, Val Loss: 1.6566, F1 Micro: 0.3750, F1 Macro: 0.3825, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.4084, Val Loss: 1.7727, F1 Micro: 0.3333, F1 Macro: 0.3185, Accuracy: 0.3333\n","Epoch 64, Train Loss: 1.3155, Val Loss: 1.5253, F1 Micro: 0.4333, F1 Macro: 0.4251, Accuracy: 0.4333\n","Epoch 65, Train Loss: 1.3547, Val Loss: 1.5491, F1 Micro: 0.4750, F1 Macro: 0.4643, Accuracy: 0.4750\n","Epoch 66, Train Loss: 1.3351, Val Loss: 1.5919, F1 Micro: 0.3833, F1 Macro: 0.3429, Accuracy: 0.3833\n","Epoch 67, Train Loss: 1.3524, Val Loss: 1.7334, F1 Micro: 0.3333, F1 Macro: 0.3158, Accuracy: 0.3333\n","Epoch 68, Train Loss: 1.3114, Val Loss: 1.6022, F1 Micro: 0.4000, F1 Macro: 0.3684, Accuracy: 0.4000\n","Epoch 69, Train Loss: 1.2836, Val Loss: 1.5549, F1 Micro: 0.4333, F1 Macro: 0.4064, Accuracy: 0.4333\n","Epoch 70, Train Loss: 1.2705, Val Loss: 1.5840, F1 Micro: 0.4250, F1 Macro: 0.4261, Accuracy: 0.4250\n","Epoch 71, Train Loss: 1.3076, Val Loss: 1.4769, F1 Micro: 0.4750, F1 Macro: 0.4603, Accuracy: 0.4750\n","Epoch 72, Train Loss: 1.2523, Val Loss: 1.6990, F1 Micro: 0.4000, F1 Macro: 0.3975, Accuracy: 0.4000\n","Epoch 73, Train Loss: 1.2872, Val Loss: 1.5708, F1 Micro: 0.3917, F1 Macro: 0.3578, Accuracy: 0.3917\n","Epoch 74, Train Loss: 1.2504, Val Loss: 1.6623, F1 Micro: 0.3917, F1 Macro: 0.3854, Accuracy: 0.3917\n","Epoch 75, Train Loss: 1.2785, Val Loss: 1.5004, F1 Micro: 0.4500, F1 Macro: 0.4485, Accuracy: 0.4500\n","Epoch 76, Train Loss: 1.2298, Val Loss: 1.5589, F1 Micro: 0.4917, F1 Macro: 0.4899, Accuracy: 0.4917\n","Epoch 77, Train Loss: 1.2748, Val Loss: 1.5016, F1 Micro: 0.4917, F1 Macro: 0.4844, Accuracy: 0.4917\n","Epoch 78, Train Loss: 1.2196, Val Loss: 1.4841, F1 Micro: 0.4917, F1 Macro: 0.4994, Accuracy: 0.4917\n","Epoch 79, Train Loss: 1.2174, Val Loss: 1.5438, F1 Micro: 0.5000, F1 Macro: 0.4974, Accuracy: 0.5000\n","Epoch 80, Train Loss: 1.2407, Val Loss: 1.5350, F1 Micro: 0.4917, F1 Macro: 0.4747, Accuracy: 0.4917\n","Epoch 81, Train Loss: 1.1665, Val Loss: 1.5553, F1 Micro: 0.4250, F1 Macro: 0.4033, Accuracy: 0.4250\n","Epoch 82, Train Loss: 1.1998, Val Loss: 1.5300, F1 Micro: 0.5083, F1 Macro: 0.5016, Accuracy: 0.5083\n","Epoch 83, Train Loss: 1.2314, Val Loss: 1.5776, F1 Micro: 0.4917, F1 Macro: 0.4872, Accuracy: 0.4917\n","Epoch 84, Train Loss: 1.2176, Val Loss: 1.6745, F1 Micro: 0.4167, F1 Macro: 0.3820, Accuracy: 0.4167\n","Epoch 85, Train Loss: 1.1910, Val Loss: 1.6486, F1 Micro: 0.4417, F1 Macro: 0.4429, Accuracy: 0.4417\n","Epoch 86, Train Loss: 1.1982, Val Loss: 1.4936, F1 Micro: 0.5000, F1 Macro: 0.4929, Accuracy: 0.5000\n","Epoch 87, Train Loss: 1.1562, Val Loss: 1.5773, F1 Micro: 0.4583, F1 Macro: 0.4458, Accuracy: 0.4583\n","Epoch 88, Train Loss: 1.1786, Val Loss: 1.6398, F1 Micro: 0.4417, F1 Macro: 0.4453, Accuracy: 0.4417\n","Epoch 89, Train Loss: 1.1087, Val Loss: 1.6427, F1 Micro: 0.4583, F1 Macro: 0.4646, Accuracy: 0.4583\n","Epoch 90, Train Loss: 1.1729, Val Loss: 1.7405, F1 Micro: 0.4250, F1 Macro: 0.4368, Accuracy: 0.4250\n","Epoch 91, Train Loss: 1.1277, Val Loss: 1.6849, F1 Micro: 0.4750, F1 Macro: 0.4724, Accuracy: 0.4750\n","Epoch 92, Train Loss: 1.1653, Val Loss: 1.6103, F1 Micro: 0.4750, F1 Macro: 0.4677, Accuracy: 0.4750\n","Epoch 93, Train Loss: 1.0919, Val Loss: 1.5591, F1 Micro: 0.4583, F1 Macro: 0.4477, Accuracy: 0.4583\n","Epoch 94, Train Loss: 1.1087, Val Loss: 1.6516, F1 Micro: 0.4333, F1 Macro: 0.4104, Accuracy: 0.4333\n","Epoch 95, Train Loss: 1.0731, Val Loss: 1.6343, F1 Micro: 0.4833, F1 Macro: 0.4688, Accuracy: 0.4833\n","Epoch 96, Train Loss: 1.1089, Val Loss: 1.5752, F1 Micro: 0.5083, F1 Macro: 0.5039, Accuracy: 0.5083\n","Epoch 97, Train Loss: 1.0926, Val Loss: 1.6697, F1 Micro: 0.4750, F1 Macro: 0.4725, Accuracy: 0.4750\n","Epoch 98, Train Loss: 1.1093, Val Loss: 1.6164, F1 Micro: 0.4667, F1 Macro: 0.4554, Accuracy: 0.4667\n","Epoch 99, Train Loss: 1.0946, Val Loss: 1.5502, F1 Micro: 0.5333, F1 Macro: 0.5216, Accuracy: 0.5333\n","Epoch 100, Train Loss: 1.0671, Val Loss: 1.6142, F1 Micro: 0.5083, F1 Macro: 0.5004, Accuracy: 0.5083\n","Epoch 101, Train Loss: 1.0955, Val Loss: 1.6985, F1 Micro: 0.5083, F1 Macro: 0.5155, Accuracy: 0.5083\n","Epoch 102, Train Loss: 1.0346, Val Loss: 1.5347, F1 Micro: 0.4833, F1 Macro: 0.4728, Accuracy: 0.4833\n","Epoch 103, Train Loss: 1.0508, Val Loss: 1.6316, F1 Micro: 0.5000, F1 Macro: 0.5017, Accuracy: 0.5000\n","Epoch 104, Train Loss: 1.0510, Val Loss: 1.5415, F1 Micro: 0.5000, F1 Macro: 0.4989, Accuracy: 0.5000\n","Epoch 105, Train Loss: 1.0534, Val Loss: 1.6390, F1 Micro: 0.4833, F1 Macro: 0.4766, Accuracy: 0.4833\n","Epoch 106, Train Loss: 1.0914, Val Loss: 1.5882, F1 Micro: 0.4667, F1 Macro: 0.4548, Accuracy: 0.4667\n","Epoch 107, Train Loss: 1.0349, Val Loss: 1.6670, F1 Micro: 0.4833, F1 Macro: 0.4700, Accuracy: 0.4833\n","Epoch 108, Train Loss: 0.9703, Val Loss: 1.6940, F1 Micro: 0.5250, F1 Macro: 0.5237, Accuracy: 0.5250\n","Epoch 109, Train Loss: 1.0042, Val Loss: 1.7295, F1 Micro: 0.5000, F1 Macro: 0.4946, Accuracy: 0.5000\n","Epoch 110, Train Loss: 0.9951, Val Loss: 1.5816, F1 Micro: 0.5250, F1 Macro: 0.5193, Accuracy: 0.5250\n","Epoch 111, Train Loss: 0.9605, Val Loss: 1.7922, F1 Micro: 0.4417, F1 Macro: 0.4406, Accuracy: 0.4417\n","Epoch 112, Train Loss: 0.9716, Val Loss: 1.5986, F1 Micro: 0.4833, F1 Macro: 0.4696, Accuracy: 0.4833\n","Epoch 113, Train Loss: 1.0013, Val Loss: 1.6182, F1 Micro: 0.5333, F1 Macro: 0.5376, Accuracy: 0.5333\n","Epoch 114, Train Loss: 1.0163, Val Loss: 1.6258, F1 Micro: 0.5333, F1 Macro: 0.5433, Accuracy: 0.5333\n","Epoch 115, Train Loss: 0.9841, Val Loss: 1.6377, F1 Micro: 0.4750, F1 Macro: 0.4727, Accuracy: 0.4750\n","Epoch 116, Train Loss: 0.9665, Val Loss: 1.6913, F1 Micro: 0.5250, F1 Macro: 0.5320, Accuracy: 0.5250\n","Epoch 117, Train Loss: 0.9752, Val Loss: 1.7078, F1 Micro: 0.4750, F1 Macro: 0.4480, Accuracy: 0.4750\n","Epoch 118, Train Loss: 0.9852, Val Loss: 1.5742, F1 Micro: 0.5250, F1 Macro: 0.5225, Accuracy: 0.5250\n","Epoch 119, Train Loss: 0.9263, Val Loss: 1.6685, F1 Micro: 0.5250, F1 Macro: 0.5168, Accuracy: 0.5250\n","Epoch 120, Train Loss: 0.9056, Val Loss: 1.6449, F1 Micro: 0.5083, F1 Macro: 0.5028, Accuracy: 0.5083\n","Epoch 121, Train Loss: 0.9282, Val Loss: 1.6738, F1 Micro: 0.5167, F1 Macro: 0.5152, Accuracy: 0.5167\n","Epoch 122, Train Loss: 1.0374, Val Loss: 1.7357, F1 Micro: 0.4583, F1 Macro: 0.4378, Accuracy: 0.4583\n","Epoch 123, Train Loss: 0.8766, Val Loss: 1.6778, F1 Micro: 0.4917, F1 Macro: 0.4905, Accuracy: 0.4917\n","Epoch 124, Train Loss: 0.8923, Val Loss: 1.7399, F1 Micro: 0.5000, F1 Macro: 0.5013, Accuracy: 0.5000\n","Epoch 125, Train Loss: 0.9838, Val Loss: 1.6314, F1 Micro: 0.5417, F1 Macro: 0.5383, Accuracy: 0.5417\n","Epoch 126, Train Loss: 0.9300, Val Loss: 1.6686, F1 Micro: 0.5083, F1 Macro: 0.4989, Accuracy: 0.5083\n","Epoch 127, Train Loss: 0.9589, Val Loss: 1.7401, F1 Micro: 0.4583, F1 Macro: 0.4533, Accuracy: 0.4583\n","Epoch 128, Train Loss: 0.9613, Val Loss: 1.8237, F1 Micro: 0.5083, F1 Macro: 0.4722, Accuracy: 0.5083\n","Epoch 129, Train Loss: 0.8945, Val Loss: 1.8365, F1 Micro: 0.4917, F1 Macro: 0.4961, Accuracy: 0.4917\n","Epoch 130, Train Loss: 0.8632, Val Loss: 1.7414, F1 Micro: 0.5500, F1 Macro: 0.5468, Accuracy: 0.5500\n","Epoch 131, Train Loss: 0.8070, Val Loss: 1.6479, F1 Micro: 0.5250, F1 Macro: 0.5221, Accuracy: 0.5250\n","Epoch 132, Train Loss: 0.9373, Val Loss: 1.6453, F1 Micro: 0.5833, F1 Macro: 0.5857, Accuracy: 0.5833\n","Epoch 133, Train Loss: 0.8707, Val Loss: 1.5987, F1 Micro: 0.5750, F1 Macro: 0.5733, Accuracy: 0.5750\n","Epoch 134, Train Loss: 0.8445, Val Loss: 1.8789, F1 Micro: 0.4583, F1 Macro: 0.4548, Accuracy: 0.4583\n","Epoch 135, Train Loss: 0.8273, Val Loss: 1.7992, F1 Micro: 0.4500, F1 Macro: 0.4465, Accuracy: 0.4500\n","Epoch 136, Train Loss: 0.8527, Val Loss: 1.7967, F1 Micro: 0.4750, F1 Macro: 0.4805, Accuracy: 0.4750\n","Epoch 137, Train Loss: 0.8599, Val Loss: 1.8417, F1 Micro: 0.4833, F1 Macro: 0.4821, Accuracy: 0.4833\n","Epoch 138, Train Loss: 0.8093, Val Loss: 1.7067, F1 Micro: 0.5500, F1 Macro: 0.5472, Accuracy: 0.5500\n","Epoch 139, Train Loss: 0.8083, Val Loss: 1.6983, F1 Micro: 0.5333, F1 Macro: 0.5348, Accuracy: 0.5333\n","Epoch 140, Train Loss: 0.8453, Val Loss: 1.5926, F1 Micro: 0.5917, F1 Macro: 0.5955, Accuracy: 0.5917\n","Epoch 141, Train Loss: 0.8457, Val Loss: 1.6890, F1 Micro: 0.5417, F1 Macro: 0.5384, Accuracy: 0.5417\n","Epoch 142, Train Loss: 0.7807, Val Loss: 1.7357, F1 Micro: 0.5417, F1 Macro: 0.5370, Accuracy: 0.5417\n","Epoch 143, Train Loss: 0.8319, Val Loss: 1.8690, F1 Micro: 0.5000, F1 Macro: 0.4832, Accuracy: 0.5000\n","Epoch 144, Train Loss: 0.7909, Val Loss: 1.7091, F1 Micro: 0.5167, F1 Macro: 0.5127, Accuracy: 0.5167\n","Epoch 145, Train Loss: 0.7886, Val Loss: 1.8263, F1 Micro: 0.4750, F1 Macro: 0.4619, Accuracy: 0.4750\n","Epoch 146, Train Loss: 0.8404, Val Loss: 1.6845, F1 Micro: 0.5583, F1 Macro: 0.5494, Accuracy: 0.5583\n","Epoch 147, Train Loss: 0.8216, Val Loss: 1.7132, F1 Micro: 0.5333, F1 Macro: 0.5358, Accuracy: 0.5333\n","Epoch 148, Train Loss: 0.7296, Val Loss: 1.7232, F1 Micro: 0.5583, F1 Macro: 0.5592, Accuracy: 0.5583\n","Epoch 149, Train Loss: 0.7688, Val Loss: 1.7707, F1 Micro: 0.5333, F1 Macro: 0.5238, Accuracy: 0.5333\n","Epoch 150, Train Loss: 0.7191, Val Loss: 1.7746, F1 Micro: 0.5667, F1 Macro: 0.5662, Accuracy: 0.5667\n","Epoch 151, Train Loss: 0.7946, Val Loss: 1.8606, F1 Micro: 0.5167, F1 Macro: 0.5216, Accuracy: 0.5167\n","Epoch 152, Train Loss: 0.7831, Val Loss: 1.6530, F1 Micro: 0.5500, F1 Macro: 0.5486, Accuracy: 0.5500\n","Epoch 153, Train Loss: 0.7800, Val Loss: 1.7078, F1 Micro: 0.5667, F1 Macro: 0.5666, Accuracy: 0.5667\n","Epoch 154, Train Loss: 0.7932, Val Loss: 1.7403, F1 Micro: 0.5750, F1 Macro: 0.5768, Accuracy: 0.5750\n","Epoch 155, Train Loss: 0.7572, Val Loss: 1.7826, F1 Micro: 0.5000, F1 Macro: 0.5072, Accuracy: 0.5000\n","Epoch 156, Train Loss: 0.7473, Val Loss: 1.7972, F1 Micro: 0.5000, F1 Macro: 0.4944, Accuracy: 0.5000\n","Epoch 157, Train Loss: 0.7073, Val Loss: 1.8296, F1 Micro: 0.5417, F1 Macro: 0.5350, Accuracy: 0.5417\n","Epoch 158, Train Loss: 0.7492, Val Loss: 1.9005, F1 Micro: 0.4917, F1 Macro: 0.4718, Accuracy: 0.4917\n","Epoch 159, Train Loss: 0.6942, Val Loss: 1.7816, F1 Micro: 0.5500, F1 Macro: 0.5458, Accuracy: 0.5500\n","Epoch 160, Train Loss: 0.6888, Val Loss: 2.0407, F1 Micro: 0.4667, F1 Macro: 0.4600, Accuracy: 0.4667\n","Epoch 161, Train Loss: 0.7616, Val Loss: 1.7274, F1 Micro: 0.5000, F1 Macro: 0.4987, Accuracy: 0.5000\n","Epoch 162, Train Loss: 0.7171, Val Loss: 1.8699, F1 Micro: 0.5417, F1 Macro: 0.5381, Accuracy: 0.5417\n","Epoch 163, Train Loss: 0.7427, Val Loss: 1.9364, F1 Micro: 0.5667, F1 Macro: 0.5639, Accuracy: 0.5667\n","Epoch 164, Train Loss: 0.7230, Val Loss: 1.7493, F1 Micro: 0.5833, F1 Macro: 0.5673, Accuracy: 0.5833\n","Epoch 165, Train Loss: 0.7022, Val Loss: 1.8151, F1 Micro: 0.5500, F1 Macro: 0.5511, Accuracy: 0.5500\n","Epoch 166, Train Loss: 0.6943, Val Loss: 1.8780, F1 Micro: 0.5333, F1 Macro: 0.5189, Accuracy: 0.5333\n","Epoch 167, Train Loss: 0.7334, Val Loss: 1.7894, F1 Micro: 0.5417, F1 Macro: 0.5388, Accuracy: 0.5417\n","Epoch 168, Train Loss: 0.7027, Val Loss: 1.8218, F1 Micro: 0.5500, F1 Macro: 0.5380, Accuracy: 0.5500\n","Epoch 169, Train Loss: 0.6731, Val Loss: 1.8061, F1 Micro: 0.5833, F1 Macro: 0.5776, Accuracy: 0.5833\n","Epoch 170, Train Loss: 0.6973, Val Loss: 1.8517, F1 Micro: 0.5583, F1 Macro: 0.5547, Accuracy: 0.5583\n","Epoch 171, Train Loss: 0.6274, Val Loss: 1.9298, F1 Micro: 0.5833, F1 Macro: 0.5829, Accuracy: 0.5833\n","Epoch 172, Train Loss: 0.6686, Val Loss: 1.7987, F1 Micro: 0.5667, F1 Macro: 0.5568, Accuracy: 0.5667\n","Epoch 173, Train Loss: 0.6470, Val Loss: 1.7242, F1 Micro: 0.5917, F1 Macro: 0.5963, Accuracy: 0.5917\n","Epoch 174, Train Loss: 0.6627, Val Loss: 1.7875, F1 Micro: 0.5833, F1 Macro: 0.5881, Accuracy: 0.5833\n","Epoch 175, Train Loss: 0.6536, Val Loss: 1.9121, F1 Micro: 0.5667, F1 Macro: 0.5660, Accuracy: 0.5667\n","Epoch 176, Train Loss: 0.6943, Val Loss: 1.9474, F1 Micro: 0.5500, F1 Macro: 0.5354, Accuracy: 0.5500\n","Epoch 177, Train Loss: 0.6288, Val Loss: 1.9317, F1 Micro: 0.5667, F1 Macro: 0.5669, Accuracy: 0.5667\n","Epoch 178, Train Loss: 0.6582, Val Loss: 1.8755, F1 Micro: 0.5667, F1 Macro: 0.5690, Accuracy: 0.5667\n","Epoch 179, Train Loss: 0.6690, Val Loss: 2.1231, F1 Micro: 0.4833, F1 Macro: 0.4717, Accuracy: 0.4833\n","Epoch 180, Train Loss: 0.7258, Val Loss: 1.8772, F1 Micro: 0.5667, F1 Macro: 0.5649, Accuracy: 0.5667\n","Epoch 181, Train Loss: 0.6591, Val Loss: 1.8679, F1 Micro: 0.6250, F1 Macro: 0.6275, Accuracy: 0.6250\n","Epoch 182, Train Loss: 0.6770, Val Loss: 1.8462, F1 Micro: 0.5833, F1 Macro: 0.5906, Accuracy: 0.5833\n","Epoch 183, Train Loss: 0.5981, Val Loss: 1.9501, F1 Micro: 0.5333, F1 Macro: 0.5211, Accuracy: 0.5333\n","Epoch 184, Train Loss: 0.6060, Val Loss: 2.1526, F1 Micro: 0.5250, F1 Macro: 0.5086, Accuracy: 0.5250\n","Epoch 185, Train Loss: 0.5522, Val Loss: 2.0145, F1 Micro: 0.6000, F1 Macro: 0.5997, Accuracy: 0.6000\n","Epoch 186, Train Loss: 0.5757, Val Loss: 1.9200, F1 Micro: 0.5667, F1 Macro: 0.5627, Accuracy: 0.5667\n","Epoch 187, Train Loss: 0.6108, Val Loss: 1.8310, F1 Micro: 0.6167, F1 Macro: 0.6172, Accuracy: 0.6167\n","Epoch 188, Train Loss: 0.5847, Val Loss: 1.8360, F1 Micro: 0.6250, F1 Macro: 0.6222, Accuracy: 0.6250\n","Epoch 189, Train Loss: 0.5770, Val Loss: 1.9839, F1 Micro: 0.5583, F1 Macro: 0.5563, Accuracy: 0.5583\n","Epoch 190, Train Loss: 0.5863, Val Loss: 1.9078, F1 Micro: 0.5917, F1 Macro: 0.5934, Accuracy: 0.5917\n","Epoch 191, Train Loss: 0.6188, Val Loss: 2.0152, F1 Micro: 0.5583, F1 Macro: 0.5514, Accuracy: 0.5583\n","Epoch 192, Train Loss: 0.6537, Val Loss: 1.8570, F1 Micro: 0.6500, F1 Macro: 0.6533, Accuracy: 0.6500\n","Epoch 193, Train Loss: 0.5742, Val Loss: 1.9675, F1 Micro: 0.5917, F1 Macro: 0.5867, Accuracy: 0.5917\n","Epoch 194, Train Loss: 0.6294, Val Loss: 1.9963, F1 Micro: 0.5333, F1 Macro: 0.5232, Accuracy: 0.5333\n","Epoch 195, Train Loss: 0.6357, Val Loss: 2.1357, F1 Micro: 0.5417, F1 Macro: 0.5448, Accuracy: 0.5417\n","Epoch 196, Train Loss: 0.6256, Val Loss: 1.8317, F1 Micro: 0.6083, F1 Macro: 0.6113, Accuracy: 0.6083\n","Epoch 197, Train Loss: 0.6334, Val Loss: 1.9707, F1 Micro: 0.5333, F1 Macro: 0.5209, Accuracy: 0.5333\n","Epoch 198, Train Loss: 0.6246, Val Loss: 1.9777, F1 Micro: 0.5750, F1 Macro: 0.5651, Accuracy: 0.5750\n","Epoch 199, Train Loss: 0.5595, Val Loss: 1.9702, F1 Micro: 0.5750, F1 Macro: 0.5733, Accuracy: 0.5750\n","Epoch 200, Train Loss: 0.5456, Val Loss: 1.9435, F1 Micro: 0.5583, F1 Macro: 0.5597, Accuracy: 0.5583\n","Test set evaluation - F1 Micro: 0.5583, F1 Macro: 0.5597, Accuracy: 0.5583\n"]}]},{"cell_type":"code","source":["print(np.mean(f1_micro_test_list))\n","print(np.mean(f1_macro_test_list))\n","print(np.mean(accuracy_test_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b27q8YjERS1V","executionInfo":{"status":"ok","timestamp":1711221272984,"user_tz":-60,"elapsed":1,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"1b0730e3-d74f-48b1-e7e1-4e7479828d2c"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5716666666666667\n","0.5658546749965786\n","0.5716666666666667\n"]}]},{"cell_type":"code","source":["# Initialize a dictionary to store metrics for different models\n","models_evaluation_metrics = {}\n","\n","# Example model identifiers\n","model_names = ['BasicGraphModel', 'GraphSAGEModel', 'GINModel']\n","\n","# Initialize metric dictionaries for each model\n","for model_name in model_names:\n","    models_evaluation_metrics[model_name] = {'f1_micro': [], 'f1_macro': [], 'accuracy': []}\n","\n","def update_model_metrics(model_name, f1_micro, f1_macro, accuracy):\n","    models_evaluation_metrics[model_name]['f1_micro'].append(f1_micro)\n","    models_evaluation_metrics[model_name]['f1_macro'].append(f1_macro)\n","    models_evaluation_metrics[model_name]['accuracy'].append(accuracy)\n","\n","#update_model_metrics('BasicGraphModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sF9Ju8uIR0ow","executionInfo":{"status":"ok","timestamp":1711312487931,"user_tz":-60,"elapsed":206,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"05b823de-8082-4bd3-e21d-dcddc92fb87a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"code","source":["models_evaluation_metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9NWRRgsDVvnn","executionInfo":{"status":"ok","timestamp":1711221283139,"user_tz":-60,"elapsed":243,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"22926f06-2d84-4ddb-d02e-d17ef86100ec"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'BasicGraphModel': {'f1_micro': [[0.5416666666666666,\n","    0.575,\n","    0.575,\n","    0.6083333333333333,\n","    0.5583333333333333]],\n","  'f1_macro': [[0.5216981751875497,\n","    0.5734944050949523,\n","    0.5641898378231431,\n","    0.6101596293233924,\n","    0.5597313275538554]],\n","  'accuracy': [[0.5416666666666666,\n","    0.575,\n","    0.575,\n","    0.6083333333333333,\n","    0.5583333333333333]]},\n"," 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []},\n"," 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["# Try the model GraphSAGE"],"metadata":{"id":"A8xIUJ4pBLhx"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.nn import SAGEConv, global_mean_pool\n","\n","class GraphSAGEModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout_rate=0.5):\n","        super(GraphSAGEModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.convs = nn.ModuleList()\n","        self.bns = nn.ModuleList()\n","        self.dropout_rate = dropout_rate\n","\n","        # Input layer\n","        self.convs.append(SAGEConv(input_dim, hidden_dim))\n","        self.bns.append(nn.BatchNorm1d(hidden_dim))\n","\n","        # Hidden layers\n","        for i in range(num_layers - 2):\n","            self.convs.append(SAGEConv(hidden_dim, hidden_dim))\n","            self.bns.append(nn.BatchNorm1d(hidden_dim))\n","\n","        # Output layer\n","        self.convs.append(SAGEConv(hidden_dim, output_dim))\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        # Go through the layers\n","        for i in range(self.num_layers - 1):\n","            x = self.convs[i](x, edge_index)\n","            x = self.bns[i](x)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n","\n","        # Output layer\n","        x = self.convs[-1](x, edge_index)\n","\n","        # Apply global mean pooling to get graph-level output\n","        x = global_mean_pool(x, data.batch)\n","\n","        return x\n"],"metadata":{"id":"dgrjdCXPBPe7","executionInfo":{"status":"ok","timestamp":1711378232697,"user_tz":-60,"elapsed":559,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list2 = []\n","f1_macro_test_list2 = []\n","accuracy_test_list2 = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_en)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_en[train_val_idx]\n","    test_dataset = dataset_en[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = GraphSAGEModel(\n","                input_dim=dataset_en.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_en.num_classes,\n","                num_layers=2,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = GraphSAGEModel(\n","                input_dim=dataset_en.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_en.num_classes,\n","                num_layers=2,\n","                dropout_rate=0.5\n","            ).to(device)\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list2.append(f1_micro_test)\n","    f1_macro_test_list2.append(f1_macro_test)\n","    accuracy_test_list2.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'GSAGE_fold_{fold}.pth')\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XwhqLwOmRaGH","executionInfo":{"status":"ok","timestamp":1711299543427,"user_tz":-60,"elapsed":877382,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"8e3b3796-d30e-424c-f42e-26cd9a457151"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 43, Train Loss: 1.2831, Val Loss: 2.1009, F1 Micro: 0.2292, F1 Macro: 0.2175, Accuracy: 0.2292\n","Epoch 44, Train Loss: 1.2897, Val Loss: 1.6548, F1 Micro: 0.3854, F1 Macro: 0.3455, Accuracy: 0.3854\n","Epoch 45, Train Loss: 1.2679, Val Loss: 1.6538, F1 Micro: 0.3438, F1 Macro: 0.3437, Accuracy: 0.3438\n","Epoch 46, Train Loss: 1.2413, Val Loss: 1.5623, F1 Micro: 0.4271, F1 Macro: 0.3948, Accuracy: 0.4271\n","Epoch 47, Train Loss: 1.2798, Val Loss: 1.6896, F1 Micro: 0.3854, F1 Macro: 0.3738, Accuracy: 0.3854\n","Epoch 48, Train Loss: 1.2218, Val Loss: 1.7280, F1 Micro: 0.3854, F1 Macro: 0.3005, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.2482, Val Loss: 1.8296, F1 Micro: 0.3542, F1 Macro: 0.2860, Accuracy: 0.3542\n","Epoch 50, Train Loss: 1.2382, Val Loss: 1.5301, F1 Micro: 0.3854, F1 Macro: 0.3441, Accuracy: 0.3854\n","Epoch 51, Train Loss: 1.2042, Val Loss: 1.6051, F1 Micro: 0.3333, F1 Macro: 0.3003, Accuracy: 0.3333\n","Epoch 52, Train Loss: 1.2035, Val Loss: 1.5547, F1 Micro: 0.4167, F1 Macro: 0.4124, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.1915, Val Loss: 1.6333, F1 Micro: 0.3854, F1 Macro: 0.3627, Accuracy: 0.3854\n","Epoch 54, Train Loss: 1.2027, Val Loss: 1.6446, F1 Micro: 0.3854, F1 Macro: 0.3662, Accuracy: 0.3854\n","Epoch 55, Train Loss: 1.1585, Val Loss: 1.6232, F1 Micro: 0.4167, F1 Macro: 0.3549, Accuracy: 0.4167\n","Epoch 56, Train Loss: 1.1878, Val Loss: 1.7444, F1 Micro: 0.3854, F1 Macro: 0.3479, Accuracy: 0.3854\n","Epoch 57, Train Loss: 1.1630, Val Loss: 1.6451, F1 Micro: 0.3438, F1 Macro: 0.3429, Accuracy: 0.3438\n","Epoch 58, Train Loss: 1.1509, Val Loss: 2.1309, F1 Micro: 0.2604, F1 Macro: 0.2239, Accuracy: 0.2604\n","Epoch 59, Train Loss: 1.1454, Val Loss: 1.4642, F1 Micro: 0.4167, F1 Macro: 0.3758, Accuracy: 0.4167\n","Epoch 60, Train Loss: 1.1650, Val Loss: 1.4970, F1 Micro: 0.4271, F1 Macro: 0.4205, Accuracy: 0.4271\n","Epoch 61, Train Loss: 1.1479, Val Loss: 1.5601, F1 Micro: 0.3646, F1 Macro: 0.3410, Accuracy: 0.3646\n","Epoch 62, Train Loss: 1.1649, Val Loss: 1.4804, F1 Micro: 0.4062, F1 Macro: 0.4011, Accuracy: 0.4062\n","Epoch 63, Train Loss: 1.1761, Val Loss: 1.5592, F1 Micro: 0.3750, F1 Macro: 0.2978, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.1720, Val Loss: 1.8627, F1 Micro: 0.3646, F1 Macro: 0.3399, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.1568, Val Loss: 1.5796, F1 Micro: 0.4062, F1 Macro: 0.3436, Accuracy: 0.4062\n","Epoch 66, Train Loss: 1.1161, Val Loss: 1.7523, F1 Micro: 0.3646, F1 Macro: 0.3354, Accuracy: 0.3646\n","Epoch 67, Train Loss: 1.1105, Val Loss: 1.6046, F1 Micro: 0.3958, F1 Macro: 0.3493, Accuracy: 0.3958\n","Epoch 68, Train Loss: 1.1502, Val Loss: 1.5057, F1 Micro: 0.4062, F1 Macro: 0.3608, Accuracy: 0.4062\n","Epoch 69, Train Loss: 1.1209, Val Loss: 1.6656, F1 Micro: 0.3958, F1 Macro: 0.3272, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.1368, Val Loss: 1.4278, F1 Micro: 0.4896, F1 Macro: 0.4807, Accuracy: 0.4896\n","Epoch 71, Train Loss: 1.0791, Val Loss: 1.4252, F1 Micro: 0.4167, F1 Macro: 0.3979, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.0707, Val Loss: 1.5391, F1 Micro: 0.4167, F1 Macro: 0.3884, Accuracy: 0.4167\n","Epoch 73, Train Loss: 1.0815, Val Loss: 1.6498, F1 Micro: 0.4167, F1 Macro: 0.4217, Accuracy: 0.4167\n","Epoch 74, Train Loss: 1.0818, Val Loss: 1.4942, F1 Micro: 0.4583, F1 Macro: 0.3850, Accuracy: 0.4583\n","Epoch 75, Train Loss: 1.0312, Val Loss: 1.6217, F1 Micro: 0.4167, F1 Macro: 0.3962, Accuracy: 0.4167\n","Epoch 76, Train Loss: 1.1146, Val Loss: 1.5094, F1 Micro: 0.4167, F1 Macro: 0.3728, Accuracy: 0.4167\n","Epoch 77, Train Loss: 1.1013, Val Loss: 1.7133, F1 Micro: 0.4062, F1 Macro: 0.3883, Accuracy: 0.4062\n","Epoch 78, Train Loss: 1.0570, Val Loss: 1.4512, F1 Micro: 0.4479, F1 Macro: 0.3920, Accuracy: 0.4479\n","Epoch 79, Train Loss: 1.0574, Val Loss: 1.4970, F1 Micro: 0.4271, F1 Macro: 0.4211, Accuracy: 0.4271\n","Epoch 80, Train Loss: 1.0315, Val Loss: 2.2289, F1 Micro: 0.2917, F1 Macro: 0.2578, Accuracy: 0.2917\n","Epoch 81, Train Loss: 1.0666, Val Loss: 1.5040, F1 Micro: 0.4479, F1 Macro: 0.4388, Accuracy: 0.4479\n","Epoch 82, Train Loss: 1.0621, Val Loss: 1.4970, F1 Micro: 0.4062, F1 Macro: 0.3518, Accuracy: 0.4062\n","Epoch 83, Train Loss: 1.0908, Val Loss: 1.5034, F1 Micro: 0.4271, F1 Macro: 0.3729, Accuracy: 0.4271\n","Epoch 84, Train Loss: 1.0477, Val Loss: 1.6284, F1 Micro: 0.4479, F1 Macro: 0.4385, Accuracy: 0.4479\n","Epoch 85, Train Loss: 1.0461, Val Loss: 1.5318, F1 Micro: 0.3958, F1 Macro: 0.3647, Accuracy: 0.3958\n","Epoch 86, Train Loss: 1.0089, Val Loss: 1.4307, F1 Micro: 0.4583, F1 Macro: 0.4369, Accuracy: 0.4583\n","Epoch 87, Train Loss: 1.0583, Val Loss: 1.6085, F1 Micro: 0.4375, F1 Macro: 0.4456, Accuracy: 0.4375\n","Epoch 88, Train Loss: 1.0345, Val Loss: 1.3481, F1 Micro: 0.4688, F1 Macro: 0.4552, Accuracy: 0.4688\n","Epoch 89, Train Loss: 1.0005, Val Loss: 1.5215, F1 Micro: 0.3750, F1 Macro: 0.3468, Accuracy: 0.3750\n","Epoch 90, Train Loss: 1.0082, Val Loss: 1.4689, F1 Micro: 0.4688, F1 Macro: 0.4458, Accuracy: 0.4688\n","Epoch 91, Train Loss: 0.9811, Val Loss: 1.8871, F1 Micro: 0.3646, F1 Macro: 0.3845, Accuracy: 0.3646\n","Epoch 92, Train Loss: 1.0015, Val Loss: 1.5701, F1 Micro: 0.3958, F1 Macro: 0.3596, Accuracy: 0.3958\n","Epoch 93, Train Loss: 0.9958, Val Loss: 1.6969, F1 Micro: 0.3958, F1 Macro: 0.3876, Accuracy: 0.3958\n","Epoch 94, Train Loss: 1.0260, Val Loss: 1.6576, F1 Micro: 0.3854, F1 Macro: 0.3487, Accuracy: 0.3854\n","Epoch 95, Train Loss: 1.0158, Val Loss: 1.7246, F1 Micro: 0.3750, F1 Macro: 0.3423, Accuracy: 0.3750\n","Epoch 96, Train Loss: 0.9945, Val Loss: 1.4334, F1 Micro: 0.4792, F1 Macro: 0.4273, Accuracy: 0.4792\n","Epoch 97, Train Loss: 0.9987, Val Loss: 1.5551, F1 Micro: 0.4062, F1 Macro: 0.3765, Accuracy: 0.4062\n","Epoch 98, Train Loss: 1.0243, Val Loss: 1.5922, F1 Micro: 0.4479, F1 Macro: 0.4051, Accuracy: 0.4479\n","Epoch 99, Train Loss: 1.0358, Val Loss: 1.5936, F1 Micro: 0.4583, F1 Macro: 0.3935, Accuracy: 0.4583\n","Epoch 100, Train Loss: 1.0028, Val Loss: 1.9093, F1 Micro: 0.3542, F1 Macro: 0.3512, Accuracy: 0.3542\n","Epoch 101, Train Loss: 1.0185, Val Loss: 1.7161, F1 Micro: 0.3438, F1 Macro: 0.2911, Accuracy: 0.3438\n","Epoch 102, Train Loss: 0.9812, Val Loss: 1.5266, F1 Micro: 0.4271, F1 Macro: 0.4073, Accuracy: 0.4271\n","Epoch 103, Train Loss: 0.9550, Val Loss: 1.4995, F1 Micro: 0.4583, F1 Macro: 0.4524, Accuracy: 0.4583\n","Epoch 104, Train Loss: 0.9584, Val Loss: 1.7117, F1 Micro: 0.3958, F1 Macro: 0.3498, Accuracy: 0.3958\n","Epoch 105, Train Loss: 0.9485, Val Loss: 1.4795, F1 Micro: 0.4583, F1 Macro: 0.4504, Accuracy: 0.4583\n","Epoch 106, Train Loss: 0.9308, Val Loss: 1.5685, F1 Micro: 0.4479, F1 Macro: 0.3718, Accuracy: 0.4479\n","Epoch 107, Train Loss: 1.0098, Val Loss: 1.5465, F1 Micro: 0.4271, F1 Macro: 0.4268, Accuracy: 0.4271\n","Epoch 108, Train Loss: 0.9976, Val Loss: 1.5373, F1 Micro: 0.4688, F1 Macro: 0.4259, Accuracy: 0.4688\n","Epoch 109, Train Loss: 0.9728, Val Loss: 1.6379, F1 Micro: 0.4271, F1 Macro: 0.3951, Accuracy: 0.4271\n","Epoch 110, Train Loss: 0.9738, Val Loss: 1.4612, F1 Micro: 0.4375, F1 Macro: 0.4467, Accuracy: 0.4375\n","Epoch 111, Train Loss: 0.9601, Val Loss: 1.6675, F1 Micro: 0.4271, F1 Macro: 0.3817, Accuracy: 0.4271\n","Epoch 112, Train Loss: 0.9108, Val Loss: 1.4006, F1 Micro: 0.5312, F1 Macro: 0.4935, Accuracy: 0.5312\n","Epoch 113, Train Loss: 0.9411, Val Loss: 1.4690, F1 Micro: 0.4583, F1 Macro: 0.3866, Accuracy: 0.4583\n","Epoch 114, Train Loss: 0.9529, Val Loss: 1.5705, F1 Micro: 0.4375, F1 Macro: 0.4386, Accuracy: 0.4375\n","Epoch 115, Train Loss: 0.9450, Val Loss: 1.5222, F1 Micro: 0.5208, F1 Macro: 0.4746, Accuracy: 0.5208\n","Epoch 116, Train Loss: 0.9182, Val Loss: 1.5139, F1 Micro: 0.5000, F1 Macro: 0.4296, Accuracy: 0.5000\n","Epoch 117, Train Loss: 0.9178, Val Loss: 1.5815, F1 Micro: 0.4271, F1 Macro: 0.4281, Accuracy: 0.4271\n","Epoch 118, Train Loss: 0.9391, Val Loss: 1.3852, F1 Micro: 0.5104, F1 Macro: 0.4923, Accuracy: 0.5104\n","Epoch 119, Train Loss: 0.9330, Val Loss: 1.3936, F1 Micro: 0.5000, F1 Macro: 0.4488, Accuracy: 0.5000\n","Epoch 120, Train Loss: 0.9107, Val Loss: 1.6368, F1 Micro: 0.5104, F1 Macro: 0.4785, Accuracy: 0.5104\n","Epoch 121, Train Loss: 0.9040, Val Loss: 1.3570, F1 Micro: 0.4688, F1 Macro: 0.4307, Accuracy: 0.4688\n","Epoch 122, Train Loss: 0.9472, Val Loss: 1.6704, F1 Micro: 0.4479, F1 Macro: 0.3844, Accuracy: 0.4479\n","Epoch 123, Train Loss: 0.8967, Val Loss: 1.7259, F1 Micro: 0.4792, F1 Macro: 0.4496, Accuracy: 0.4792\n","Epoch 124, Train Loss: 0.9120, Val Loss: 1.6838, F1 Micro: 0.4271, F1 Macro: 0.3651, Accuracy: 0.4271\n","Epoch 125, Train Loss: 0.9588, Val Loss: 1.6530, F1 Micro: 0.4792, F1 Macro: 0.4479, Accuracy: 0.4792\n","Epoch 126, Train Loss: 0.9443, Val Loss: 1.7453, F1 Micro: 0.4167, F1 Macro: 0.3369, Accuracy: 0.4167\n","Epoch 127, Train Loss: 0.9634, Val Loss: 1.9262, F1 Micro: 0.3542, F1 Macro: 0.3253, Accuracy: 0.3542\n","Epoch 128, Train Loss: 0.9003, Val Loss: 1.7455, F1 Micro: 0.4167, F1 Macro: 0.3536, Accuracy: 0.4167\n","Epoch 129, Train Loss: 1.0040, Val Loss: 1.5489, F1 Micro: 0.4792, F1 Macro: 0.4562, Accuracy: 0.4792\n","Epoch 130, Train Loss: 0.9189, Val Loss: 1.5585, F1 Micro: 0.5104, F1 Macro: 0.4615, Accuracy: 0.5104\n","Epoch 131, Train Loss: 0.9284, Val Loss: 1.3271, F1 Micro: 0.5000, F1 Macro: 0.4901, Accuracy: 0.5000\n","Epoch 132, Train Loss: 0.8687, Val Loss: 1.9748, F1 Micro: 0.3438, F1 Macro: 0.3174, Accuracy: 0.3438\n","Epoch 133, Train Loss: 0.9066, Val Loss: 1.4063, F1 Micro: 0.5208, F1 Macro: 0.4838, Accuracy: 0.5208\n","Epoch 134, Train Loss: 0.9212, Val Loss: 1.3830, F1 Micro: 0.4896, F1 Macro: 0.4264, Accuracy: 0.4896\n","Epoch 135, Train Loss: 0.9252, Val Loss: 2.0448, F1 Micro: 0.4062, F1 Macro: 0.3700, Accuracy: 0.4062\n","Epoch 136, Train Loss: 0.8803, Val Loss: 1.5520, F1 Micro: 0.4583, F1 Macro: 0.4423, Accuracy: 0.4583\n","Epoch 137, Train Loss: 0.8823, Val Loss: 1.3561, F1 Micro: 0.5000, F1 Macro: 0.4700, Accuracy: 0.5000\n","Epoch 138, Train Loss: 0.8252, Val Loss: 1.5472, F1 Micro: 0.4688, F1 Macro: 0.4336, Accuracy: 0.4688\n","Epoch 139, Train Loss: 0.9037, Val Loss: 1.6234, F1 Micro: 0.4583, F1 Macro: 0.4564, Accuracy: 0.4583\n","Epoch 140, Train Loss: 0.8865, Val Loss: 1.4680, F1 Micro: 0.4792, F1 Macro: 0.4498, Accuracy: 0.4792\n","Epoch 141, Train Loss: 0.9055, Val Loss: 1.5530, F1 Micro: 0.4792, F1 Macro: 0.4427, Accuracy: 0.4792\n","Epoch 142, Train Loss: 0.9047, Val Loss: 1.7947, F1 Micro: 0.4167, F1 Macro: 0.3818, Accuracy: 0.4167\n","Epoch 143, Train Loss: 0.8512, Val Loss: 1.4117, F1 Micro: 0.5312, F1 Macro: 0.4944, Accuracy: 0.5312\n","Epoch 144, Train Loss: 0.8753, Val Loss: 1.3807, F1 Micro: 0.5104, F1 Macro: 0.4950, Accuracy: 0.5104\n","Epoch 145, Train Loss: 0.8651, Val Loss: 2.3895, F1 Micro: 0.3438, F1 Macro: 0.3245, Accuracy: 0.3438\n","Epoch 146, Train Loss: 0.9071, Val Loss: 2.5339, F1 Micro: 0.3125, F1 Macro: 0.2389, Accuracy: 0.3125\n","Epoch 147, Train Loss: 0.8591, Val Loss: 1.5983, F1 Micro: 0.4896, F1 Macro: 0.4539, Accuracy: 0.4896\n","Epoch 148, Train Loss: 0.8575, Val Loss: 1.3698, F1 Micro: 0.4792, F1 Macro: 0.4666, Accuracy: 0.4792\n","Epoch 149, Train Loss: 0.8549, Val Loss: 1.3239, F1 Micro: 0.4896, F1 Macro: 0.4736, Accuracy: 0.4896\n","Epoch 150, Train Loss: 0.8567, Val Loss: 1.8185, F1 Micro: 0.3750, F1 Macro: 0.3637, Accuracy: 0.3750\n","Epoch 151, Train Loss: 0.8650, Val Loss: 1.4337, F1 Micro: 0.4688, F1 Macro: 0.4222, Accuracy: 0.4688\n","Epoch 152, Train Loss: 0.8544, Val Loss: 1.3539, F1 Micro: 0.5312, F1 Macro: 0.5101, Accuracy: 0.5312\n","Epoch 153, Train Loss: 0.8319, Val Loss: 1.4232, F1 Micro: 0.4896, F1 Macro: 0.4475, Accuracy: 0.4896\n","Epoch 154, Train Loss: 0.8032, Val Loss: 1.7077, F1 Micro: 0.3750, F1 Macro: 0.3517, Accuracy: 0.3750\n","Epoch 155, Train Loss: 0.8273, Val Loss: 1.4797, F1 Micro: 0.4583, F1 Macro: 0.4196, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.8700, Val Loss: 1.5118, F1 Micro: 0.4583, F1 Macro: 0.4194, Accuracy: 0.4583\n","Epoch 157, Train Loss: 0.8585, Val Loss: 1.6393, F1 Micro: 0.4479, F1 Macro: 0.4141, Accuracy: 0.4479\n","Epoch 158, Train Loss: 0.8083, Val Loss: 1.5820, F1 Micro: 0.4479, F1 Macro: 0.4292, Accuracy: 0.4479\n","Epoch 159, Train Loss: 0.8261, Val Loss: 1.6626, F1 Micro: 0.4583, F1 Macro: 0.3971, Accuracy: 0.4583\n","Epoch 160, Train Loss: 0.8487, Val Loss: 1.5163, F1 Micro: 0.5208, F1 Macro: 0.5035, Accuracy: 0.5208\n","Epoch 161, Train Loss: 0.8708, Val Loss: 1.7668, F1 Micro: 0.3958, F1 Macro: 0.3442, Accuracy: 0.3958\n","Epoch 162, Train Loss: 0.8619, Val Loss: 1.5892, F1 Micro: 0.4688, F1 Macro: 0.4388, Accuracy: 0.4688\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7585, Val Loss: 1.8639, F1 Micro: 0.1979, F1 Macro: 0.1660, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7373, Val Loss: 1.8192, F1 Micro: 0.1875, F1 Macro: 0.0984, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.6802, Val Loss: 1.7687, F1 Micro: 0.2500, F1 Macro: 0.2088, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.6618, Val Loss: 1.7970, F1 Micro: 0.2083, F1 Macro: 0.1809, Accuracy: 0.2083\n","Epoch 5, Train Loss: 1.6534, Val Loss: 1.7710, F1 Micro: 0.2812, F1 Macro: 0.2210, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.6286, Val Loss: 1.7857, F1 Micro: 0.2396, F1 Macro: 0.2090, Accuracy: 0.2396\n","Epoch 7, Train Loss: 1.6441, Val Loss: 1.7395, F1 Micro: 0.2396, F1 Macro: 0.2276, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6006, Val Loss: 1.7378, F1 Micro: 0.2708, F1 Macro: 0.2496, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.5918, Val Loss: 1.7172, F1 Micro: 0.2292, F1 Macro: 0.2143, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.5951, Val Loss: 1.6966, F1 Micro: 0.2812, F1 Macro: 0.2803, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.5727, Val Loss: 1.7312, F1 Micro: 0.2604, F1 Macro: 0.2259, Accuracy: 0.2604\n","Epoch 12, Train Loss: 1.5511, Val Loss: 1.6877, F1 Micro: 0.2396, F1 Macro: 0.2112, Accuracy: 0.2396\n","Epoch 13, Train Loss: 1.5338, Val Loss: 1.6849, F1 Micro: 0.2188, F1 Macro: 0.1993, Accuracy: 0.2188\n","Epoch 14, Train Loss: 1.5410, Val Loss: 1.6736, F1 Micro: 0.2292, F1 Macro: 0.2087, Accuracy: 0.2292\n","Epoch 15, Train Loss: 1.5507, Val Loss: 1.6850, F1 Micro: 0.2604, F1 Macro: 0.2290, Accuracy: 0.2604\n","Epoch 16, Train Loss: 1.5018, Val Loss: 1.7662, F1 Micro: 0.3125, F1 Macro: 0.2743, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.4807, Val Loss: 1.6764, F1 Micro: 0.2292, F1 Macro: 0.2182, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.5023, Val Loss: 1.7325, F1 Micro: 0.2917, F1 Macro: 0.2650, Accuracy: 0.2917\n","Epoch 19, Train Loss: 1.4941, Val Loss: 1.6576, F1 Micro: 0.2812, F1 Macro: 0.2664, Accuracy: 0.2812\n","Epoch 20, Train Loss: 1.4710, Val Loss: 1.7113, F1 Micro: 0.2083, F1 Macro: 0.2060, Accuracy: 0.2083\n","Epoch 21, Train Loss: 1.4567, Val Loss: 1.6571, F1 Micro: 0.3229, F1 Macro: 0.3061, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.4555, Val Loss: 1.7213, F1 Micro: 0.3125, F1 Macro: 0.2458, Accuracy: 0.3125\n","Epoch 23, Train Loss: 1.4049, Val Loss: 1.7425, F1 Micro: 0.3646, F1 Macro: 0.3497, Accuracy: 0.3646\n","Epoch 24, Train Loss: 1.4396, Val Loss: 1.7136, F1 Micro: 0.2812, F1 Macro: 0.2534, Accuracy: 0.2812\n","Epoch 25, Train Loss: 1.4189, Val Loss: 1.6555, F1 Micro: 0.3229, F1 Macro: 0.3086, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.3840, Val Loss: 1.6913, F1 Micro: 0.2500, F1 Macro: 0.2315, Accuracy: 0.2500\n","Epoch 27, Train Loss: 1.3982, Val Loss: 1.7253, F1 Micro: 0.3021, F1 Macro: 0.2778, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.4254, Val Loss: 1.6874, F1 Micro: 0.3125, F1 Macro: 0.2584, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.3893, Val Loss: 1.7549, F1 Micro: 0.3229, F1 Macro: 0.2733, Accuracy: 0.3229\n","Epoch 30, Train Loss: 1.3814, Val Loss: 1.7137, F1 Micro: 0.3021, F1 Macro: 0.2913, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.3628, Val Loss: 1.6149, F1 Micro: 0.3646, F1 Macro: 0.3615, Accuracy: 0.3646\n","Epoch 32, Train Loss: 1.3612, Val Loss: 1.7592, F1 Micro: 0.3021, F1 Macro: 0.2511, Accuracy: 0.3021\n","Epoch 33, Train Loss: 1.3566, Val Loss: 1.7944, F1 Micro: 0.3438, F1 Macro: 0.3309, Accuracy: 0.3438\n","Epoch 34, Train Loss: 1.3442, Val Loss: 1.6453, F1 Micro: 0.3646, F1 Macro: 0.3283, Accuracy: 0.3646\n","Epoch 35, Train Loss: 1.3547, Val Loss: 1.6782, F1 Micro: 0.3021, F1 Macro: 0.2717, Accuracy: 0.3021\n","Epoch 36, Train Loss: 1.3156, Val Loss: 1.8905, F1 Micro: 0.3646, F1 Macro: 0.3302, Accuracy: 0.3646\n","Epoch 37, Train Loss: 1.3414, Val Loss: 1.6458, F1 Micro: 0.3750, F1 Macro: 0.3418, Accuracy: 0.3750\n","Epoch 38, Train Loss: 1.3183, Val Loss: 1.8997, F1 Micro: 0.3229, F1 Macro: 0.2956, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.3522, Val Loss: 1.7010, F1 Micro: 0.3438, F1 Macro: 0.2736, Accuracy: 0.3438\n","Epoch 40, Train Loss: 1.3067, Val Loss: 1.7015, F1 Micro: 0.2708, F1 Macro: 0.2046, Accuracy: 0.2708\n","Epoch 41, Train Loss: 1.2675, Val Loss: 1.5826, F1 Micro: 0.3750, F1 Macro: 0.3589, Accuracy: 0.3750\n","Epoch 42, Train Loss: 1.2960, Val Loss: 1.6171, F1 Micro: 0.3750, F1 Macro: 0.3811, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.2818, Val Loss: 1.6993, F1 Micro: 0.4062, F1 Macro: 0.3671, Accuracy: 0.4062\n","Epoch 44, Train Loss: 1.2675, Val Loss: 1.6094, F1 Micro: 0.3333, F1 Macro: 0.2922, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.2404, Val Loss: 1.7316, F1 Micro: 0.3854, F1 Macro: 0.3891, Accuracy: 0.3854\n","Epoch 46, Train Loss: 1.2417, Val Loss: 1.6039, F1 Micro: 0.4271, F1 Macro: 0.4147, Accuracy: 0.4271\n","Epoch 47, Train Loss: 1.2065, Val Loss: 1.6160, F1 Micro: 0.3229, F1 Macro: 0.3094, Accuracy: 0.3229\n","Epoch 48, Train Loss: 1.2230, Val Loss: 1.6644, F1 Micro: 0.4167, F1 Macro: 0.3895, Accuracy: 0.4167\n","Epoch 49, Train Loss: 1.2311, Val Loss: 1.5998, F1 Micro: 0.3333, F1 Macro: 0.2846, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.2170, Val Loss: 1.7542, F1 Micro: 0.3438, F1 Macro: 0.2921, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.2509, Val Loss: 1.8806, F1 Micro: 0.3438, F1 Macro: 0.2764, Accuracy: 0.3438\n","Epoch 52, Train Loss: 1.2285, Val Loss: 2.0038, F1 Micro: 0.3229, F1 Macro: 0.2750, Accuracy: 0.3229\n","Epoch 53, Train Loss: 1.1749, Val Loss: 1.6542, F1 Micro: 0.3750, F1 Macro: 0.3369, Accuracy: 0.3750\n","Epoch 54, Train Loss: 1.2331, Val Loss: 1.8101, F1 Micro: 0.3542, F1 Macro: 0.3233, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.1674, Val Loss: 1.4933, F1 Micro: 0.4271, F1 Macro: 0.4179, Accuracy: 0.4271\n","Epoch 56, Train Loss: 1.1645, Val Loss: 1.6925, F1 Micro: 0.3854, F1 Macro: 0.3337, Accuracy: 0.3854\n","Epoch 57, Train Loss: 1.1684, Val Loss: 1.7219, F1 Micro: 0.3646, F1 Macro: 0.3050, Accuracy: 0.3646\n","Epoch 58, Train Loss: 1.1590, Val Loss: 1.7879, F1 Micro: 0.3125, F1 Macro: 0.3026, Accuracy: 0.3125\n","Epoch 59, Train Loss: 1.1822, Val Loss: 1.5375, F1 Micro: 0.4688, F1 Macro: 0.4472, Accuracy: 0.4688\n","Epoch 60, Train Loss: 1.1564, Val Loss: 1.6083, F1 Micro: 0.3542, F1 Macro: 0.3512, Accuracy: 0.3542\n","Epoch 61, Train Loss: 1.1472, Val Loss: 1.6609, F1 Micro: 0.3542, F1 Macro: 0.3001, Accuracy: 0.3542\n","Epoch 62, Train Loss: 1.1855, Val Loss: 1.5245, F1 Micro: 0.3750, F1 Macro: 0.3354, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.1311, Val Loss: 1.5970, F1 Micro: 0.4479, F1 Macro: 0.4082, Accuracy: 0.4479\n","Epoch 64, Train Loss: 1.1173, Val Loss: 1.5144, F1 Micro: 0.4792, F1 Macro: 0.4776, Accuracy: 0.4792\n","Epoch 65, Train Loss: 1.0841, Val Loss: 1.5483, F1 Micro: 0.3958, F1 Macro: 0.3948, Accuracy: 0.3958\n","Epoch 66, Train Loss: 1.1121, Val Loss: 1.8785, F1 Micro: 0.3542, F1 Macro: 0.3152, Accuracy: 0.3542\n","Epoch 67, Train Loss: 1.1022, Val Loss: 1.5254, F1 Micro: 0.4062, F1 Macro: 0.4099, Accuracy: 0.4062\n","Epoch 68, Train Loss: 1.1036, Val Loss: 1.6071, F1 Micro: 0.3958, F1 Macro: 0.3689, Accuracy: 0.3958\n","Epoch 69, Train Loss: 1.0996, Val Loss: 1.9078, F1 Micro: 0.2812, F1 Macro: 0.2548, Accuracy: 0.2812\n","Epoch 70, Train Loss: 1.0729, Val Loss: 1.8424, F1 Micro: 0.3333, F1 Macro: 0.3345, Accuracy: 0.3333\n","Epoch 71, Train Loss: 1.1133, Val Loss: 1.5720, F1 Micro: 0.4167, F1 Macro: 0.3897, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.1182, Val Loss: 1.7649, F1 Micro: 0.4375, F1 Macro: 0.4399, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.1058, Val Loss: 1.6128, F1 Micro: 0.3229, F1 Macro: 0.3029, Accuracy: 0.3229\n","Epoch 74, Train Loss: 1.0745, Val Loss: 1.5397, F1 Micro: 0.4479, F1 Macro: 0.4415, Accuracy: 0.4479\n","Epoch 75, Train Loss: 1.0735, Val Loss: 1.7316, F1 Micro: 0.3958, F1 Macro: 0.3859, Accuracy: 0.3958\n","Epoch 76, Train Loss: 1.0435, Val Loss: 1.6050, F1 Micro: 0.4896, F1 Macro: 0.4701, Accuracy: 0.4896\n","Epoch 77, Train Loss: 1.0950, Val Loss: 1.5473, F1 Micro: 0.4479, F1 Macro: 0.4427, Accuracy: 0.4479\n","Epoch 78, Train Loss: 1.0808, Val Loss: 1.7927, F1 Micro: 0.3229, F1 Macro: 0.3075, Accuracy: 0.3229\n","Epoch 79, Train Loss: 1.0994, Val Loss: 1.6110, F1 Micro: 0.4375, F1 Macro: 0.4412, Accuracy: 0.4375\n","Epoch 80, Train Loss: 1.0879, Val Loss: 1.6226, F1 Micro: 0.3958, F1 Macro: 0.3720, Accuracy: 0.3958\n","Epoch 81, Train Loss: 1.1033, Val Loss: 1.8631, F1 Micro: 0.3021, F1 Macro: 0.2640, Accuracy: 0.3021\n","Epoch 82, Train Loss: 1.0673, Val Loss: 1.5599, F1 Micro: 0.4583, F1 Macro: 0.4478, Accuracy: 0.4583\n","Epoch 83, Train Loss: 1.0159, Val Loss: 1.4883, F1 Micro: 0.4167, F1 Macro: 0.4203, Accuracy: 0.4167\n","Epoch 84, Train Loss: 1.0189, Val Loss: 1.5505, F1 Micro: 0.3646, F1 Macro: 0.3496, Accuracy: 0.3646\n","Epoch 85, Train Loss: 1.0550, Val Loss: 1.6623, F1 Micro: 0.3750, F1 Macro: 0.3662, Accuracy: 0.3750\n","Epoch 86, Train Loss: 1.0404, Val Loss: 1.6322, F1 Micro: 0.4062, F1 Macro: 0.4045, Accuracy: 0.4062\n","Epoch 87, Train Loss: 1.0142, Val Loss: 1.5747, F1 Micro: 0.3854, F1 Macro: 0.3291, Accuracy: 0.3854\n","Epoch 88, Train Loss: 1.0531, Val Loss: 1.5706, F1 Micro: 0.4479, F1 Macro: 0.4519, Accuracy: 0.4479\n","Epoch 89, Train Loss: 1.0703, Val Loss: 1.7690, F1 Micro: 0.4062, F1 Macro: 0.4042, Accuracy: 0.4062\n","Epoch 90, Train Loss: 1.0608, Val Loss: 1.4887, F1 Micro: 0.4792, F1 Macro: 0.4737, Accuracy: 0.4792\n","Epoch 91, Train Loss: 1.0425, Val Loss: 1.4793, F1 Micro: 0.4688, F1 Macro: 0.4271, Accuracy: 0.4688\n","Epoch 92, Train Loss: 0.9966, Val Loss: 1.7905, F1 Micro: 0.3854, F1 Macro: 0.3275, Accuracy: 0.3854\n","Epoch 93, Train Loss: 1.0257, Val Loss: 1.8222, F1 Micro: 0.3958, F1 Macro: 0.3440, Accuracy: 0.3958\n","Epoch 94, Train Loss: 1.0082, Val Loss: 1.4258, F1 Micro: 0.4583, F1 Macro: 0.4479, Accuracy: 0.4583\n","Epoch 95, Train Loss: 1.0337, Val Loss: 1.4948, F1 Micro: 0.4062, F1 Macro: 0.3918, Accuracy: 0.4062\n","Epoch 96, Train Loss: 0.9564, Val Loss: 1.6948, F1 Micro: 0.3958, F1 Macro: 0.3633, Accuracy: 0.3958\n","Epoch 97, Train Loss: 0.9895, Val Loss: 1.6596, F1 Micro: 0.3333, F1 Macro: 0.3162, Accuracy: 0.3333\n","Epoch 98, Train Loss: 1.0426, Val Loss: 1.4531, F1 Micro: 0.4375, F1 Macro: 0.4496, Accuracy: 0.4375\n","Epoch 99, Train Loss: 0.9757, Val Loss: 1.6551, F1 Micro: 0.3854, F1 Macro: 0.3733, Accuracy: 0.3854\n","Epoch 100, Train Loss: 1.0084, Val Loss: 1.7664, F1 Micro: 0.3646, F1 Macro: 0.3170, Accuracy: 0.3646\n","Epoch 101, Train Loss: 1.0464, Val Loss: 1.4141, F1 Micro: 0.5104, F1 Macro: 0.5080, Accuracy: 0.5104\n","Epoch 102, Train Loss: 1.0020, Val Loss: 1.4834, F1 Micro: 0.4271, F1 Macro: 0.4268, Accuracy: 0.4271\n","Epoch 103, Train Loss: 0.9597, Val Loss: 1.7478, F1 Micro: 0.4271, F1 Macro: 0.3892, Accuracy: 0.4271\n","Epoch 104, Train Loss: 0.9638, Val Loss: 1.5395, F1 Micro: 0.4062, F1 Macro: 0.3903, Accuracy: 0.4062\n","Epoch 105, Train Loss: 0.9429, Val Loss: 1.8759, F1 Micro: 0.3021, F1 Macro: 0.2465, Accuracy: 0.3021\n","Epoch 106, Train Loss: 1.0045, Val Loss: 1.5370, F1 Micro: 0.4271, F1 Macro: 0.4174, Accuracy: 0.4271\n","Epoch 107, Train Loss: 1.0313, Val Loss: 1.9172, F1 Micro: 0.3750, F1 Macro: 0.3476, Accuracy: 0.3750\n","Epoch 108, Train Loss: 0.9501, Val Loss: 1.6343, F1 Micro: 0.4167, F1 Macro: 0.3803, Accuracy: 0.4167\n","Epoch 109, Train Loss: 0.9824, Val Loss: 1.5373, F1 Micro: 0.4062, F1 Macro: 0.4054, Accuracy: 0.4062\n","Epoch 110, Train Loss: 0.9706, Val Loss: 1.8305, F1 Micro: 0.3750, F1 Macro: 0.3273, Accuracy: 0.3750\n","Epoch 111, Train Loss: 0.9465, Val Loss: 1.9502, F1 Micro: 0.3333, F1 Macro: 0.2897, Accuracy: 0.3333\n","Epoch 112, Train Loss: 0.9162, Val Loss: 1.6644, F1 Micro: 0.4688, F1 Macro: 0.4267, Accuracy: 0.4688\n","Epoch 113, Train Loss: 0.9504, Val Loss: 1.6351, F1 Micro: 0.4479, F1 Macro: 0.4488, Accuracy: 0.4479\n","Epoch 114, Train Loss: 0.9653, Val Loss: 1.4920, F1 Micro: 0.4167, F1 Macro: 0.4288, Accuracy: 0.4167\n","Epoch 115, Train Loss: 0.9267, Val Loss: 1.7158, F1 Micro: 0.5104, F1 Macro: 0.4938, Accuracy: 0.5104\n","Epoch 116, Train Loss: 0.9767, Val Loss: 1.8799, F1 Micro: 0.3125, F1 Macro: 0.2979, Accuracy: 0.3125\n","Epoch 117, Train Loss: 0.9707, Val Loss: 1.6537, F1 Micro: 0.3854, F1 Macro: 0.3608, Accuracy: 0.3854\n","Epoch 118, Train Loss: 0.9383, Val Loss: 1.4905, F1 Micro: 0.4479, F1 Macro: 0.4386, Accuracy: 0.4479\n","Epoch 119, Train Loss: 0.9114, Val Loss: 1.7611, F1 Micro: 0.3958, F1 Macro: 0.3451, Accuracy: 0.3958\n","Epoch 120, Train Loss: 0.9385, Val Loss: 1.6969, F1 Micro: 0.4375, F1 Macro: 0.3880, Accuracy: 0.4375\n","Epoch 121, Train Loss: 0.9154, Val Loss: 1.4061, F1 Micro: 0.5104, F1 Macro: 0.4762, Accuracy: 0.5104\n","Epoch 122, Train Loss: 0.9498, Val Loss: 1.4618, F1 Micro: 0.4583, F1 Macro: 0.4237, Accuracy: 0.4583\n","Epoch 123, Train Loss: 0.9434, Val Loss: 1.5379, F1 Micro: 0.4688, F1 Macro: 0.4679, Accuracy: 0.4688\n","Epoch 124, Train Loss: 0.8884, Val Loss: 1.3600, F1 Micro: 0.4896, F1 Macro: 0.4834, Accuracy: 0.4896\n","Epoch 125, Train Loss: 0.9116, Val Loss: 1.5026, F1 Micro: 0.5104, F1 Macro: 0.4712, Accuracy: 0.5104\n","Epoch 126, Train Loss: 0.9052, Val Loss: 1.3523, F1 Micro: 0.4896, F1 Macro: 0.4917, Accuracy: 0.4896\n","Epoch 127, Train Loss: 0.8943, Val Loss: 1.5012, F1 Micro: 0.5312, F1 Macro: 0.5246, Accuracy: 0.5312\n","Epoch 128, Train Loss: 0.8727, Val Loss: 1.5482, F1 Micro: 0.4792, F1 Macro: 0.4644, Accuracy: 0.4792\n","Epoch 129, Train Loss: 0.8997, Val Loss: 1.7055, F1 Micro: 0.4375, F1 Macro: 0.4246, Accuracy: 0.4375\n","Epoch 130, Train Loss: 0.8560, Val Loss: 1.5546, F1 Micro: 0.4896, F1 Macro: 0.4940, Accuracy: 0.4896\n","Epoch 131, Train Loss: 0.8495, Val Loss: 1.3385, F1 Micro: 0.5312, F1 Macro: 0.5293, Accuracy: 0.5312\n","Epoch 132, Train Loss: 0.9205, Val Loss: 1.7638, F1 Micro: 0.4375, F1 Macro: 0.4133, Accuracy: 0.4375\n","Epoch 133, Train Loss: 0.9087, Val Loss: 1.5983, F1 Micro: 0.4583, F1 Macro: 0.4463, Accuracy: 0.4583\n","Epoch 134, Train Loss: 0.8911, Val Loss: 1.7426, F1 Micro: 0.4479, F1 Macro: 0.4495, Accuracy: 0.4479\n","Epoch 135, Train Loss: 0.9459, Val Loss: 1.6481, F1 Micro: 0.3958, F1 Macro: 0.3811, Accuracy: 0.3958\n","Epoch 136, Train Loss: 0.8937, Val Loss: 1.9114, F1 Micro: 0.3958, F1 Macro: 0.3501, Accuracy: 0.3958\n","Epoch 137, Train Loss: 0.9455, Val Loss: 2.0350, F1 Micro: 0.4167, F1 Macro: 0.4053, Accuracy: 0.4167\n","Epoch 138, Train Loss: 0.8940, Val Loss: 1.6020, F1 Micro: 0.4479, F1 Macro: 0.3947, Accuracy: 0.4479\n","Epoch 139, Train Loss: 0.8790, Val Loss: 1.7013, F1 Micro: 0.4688, F1 Macro: 0.4527, Accuracy: 0.4688\n","Epoch 140, Train Loss: 0.8695, Val Loss: 1.3762, F1 Micro: 0.4688, F1 Macro: 0.4528, Accuracy: 0.4688\n","Epoch 141, Train Loss: 0.9094, Val Loss: 1.6355, F1 Micro: 0.5208, F1 Macro: 0.5082, Accuracy: 0.5208\n","Epoch 142, Train Loss: 0.9375, Val Loss: 1.4449, F1 Micro: 0.4479, F1 Macro: 0.4618, Accuracy: 0.4479\n","Epoch 143, Train Loss: 0.9007, Val Loss: 1.4177, F1 Micro: 0.5312, F1 Macro: 0.5164, Accuracy: 0.5312\n","Epoch 144, Train Loss: 0.8527, Val Loss: 1.5505, F1 Micro: 0.5208, F1 Macro: 0.5011, Accuracy: 0.5208\n","Epoch 145, Train Loss: 0.8745, Val Loss: 1.6522, F1 Micro: 0.4271, F1 Macro: 0.3976, Accuracy: 0.4271\n","Epoch 146, Train Loss: 0.8489, Val Loss: 1.5354, F1 Micro: 0.4688, F1 Macro: 0.4809, Accuracy: 0.4688\n","Epoch 147, Train Loss: 0.8390, Val Loss: 1.7501, F1 Micro: 0.4271, F1 Macro: 0.4049, Accuracy: 0.4271\n","Epoch 148, Train Loss: 0.8562, Val Loss: 1.7616, F1 Micro: 0.4688, F1 Macro: 0.4482, Accuracy: 0.4688\n","Epoch 149, Train Loss: 0.8431, Val Loss: 1.6155, F1 Micro: 0.4583, F1 Macro: 0.4373, Accuracy: 0.4583\n","Epoch 150, Train Loss: 0.8739, Val Loss: 1.3873, F1 Micro: 0.5208, F1 Macro: 0.5239, Accuracy: 0.5208\n","Epoch 151, Train Loss: 0.8183, Val Loss: 1.6726, F1 Micro: 0.4583, F1 Macro: 0.4387, Accuracy: 0.4583\n","Epoch 152, Train Loss: 0.8936, Val Loss: 2.3319, F1 Micro: 0.3333, F1 Macro: 0.2903, Accuracy: 0.3333\n","Epoch 153, Train Loss: 0.8388, Val Loss: 1.6589, F1 Micro: 0.4375, F1 Macro: 0.4416, Accuracy: 0.4375\n","Epoch 154, Train Loss: 0.8381, Val Loss: 1.5549, F1 Micro: 0.4792, F1 Macro: 0.4602, Accuracy: 0.4792\n","Epoch 155, Train Loss: 0.7995, Val Loss: 1.9053, F1 Micro: 0.3542, F1 Macro: 0.3002, Accuracy: 0.3542\n","Epoch 156, Train Loss: 0.9173, Val Loss: 1.3372, F1 Micro: 0.5938, F1 Macro: 0.5856, Accuracy: 0.5938\n","Epoch 157, Train Loss: 0.8045, Val Loss: 1.5995, F1 Micro: 0.4062, F1 Macro: 0.4283, Accuracy: 0.4062\n","Epoch 158, Train Loss: 0.8517, Val Loss: 1.7149, F1 Micro: 0.4375, F1 Macro: 0.4183, Accuracy: 0.4375\n","Epoch 159, Train Loss: 0.8490, Val Loss: 1.3371, F1 Micro: 0.5833, F1 Macro: 0.5730, Accuracy: 0.5833\n","Epoch 160, Train Loss: 0.8602, Val Loss: 1.5012, F1 Micro: 0.5208, F1 Macro: 0.5116, Accuracy: 0.5208\n","Epoch 161, Train Loss: 0.8122, Val Loss: 1.6190, F1 Micro: 0.4896, F1 Macro: 0.4467, Accuracy: 0.4896\n","Epoch 162, Train Loss: 0.7650, Val Loss: 1.5298, F1 Micro: 0.5000, F1 Macro: 0.5009, Accuracy: 0.5000\n","Epoch 163, Train Loss: 0.8104, Val Loss: 1.3844, F1 Micro: 0.5104, F1 Macro: 0.5087, Accuracy: 0.5104\n","Epoch 164, Train Loss: 0.7966, Val Loss: 1.5147, F1 Micro: 0.5208, F1 Macro: 0.5366, Accuracy: 0.5208\n","Epoch 165, Train Loss: 0.8525, Val Loss: 1.4421, F1 Micro: 0.5208, F1 Macro: 0.5129, Accuracy: 0.5208\n","Epoch 166, Train Loss: 0.8243, Val Loss: 1.3264, F1 Micro: 0.5312, F1 Macro: 0.5186, Accuracy: 0.5312\n","Epoch 167, Train Loss: 0.8453, Val Loss: 1.4719, F1 Micro: 0.5208, F1 Macro: 0.5001, Accuracy: 0.5208\n","Epoch 168, Train Loss: 0.8056, Val Loss: 1.6763, F1 Micro: 0.4792, F1 Macro: 0.4771, Accuracy: 0.4792\n","Epoch 169, Train Loss: 0.8978, Val Loss: 1.5145, F1 Micro: 0.4583, F1 Macro: 0.4701, Accuracy: 0.4583\n","Epoch 170, Train Loss: 0.7717, Val Loss: 1.5578, F1 Micro: 0.4792, F1 Macro: 0.4906, Accuracy: 0.4792\n","Epoch 171, Train Loss: 0.7860, Val Loss: 1.9142, F1 Micro: 0.4375, F1 Macro: 0.4524, Accuracy: 0.4375\n","Epoch 172, Train Loss: 0.7963, Val Loss: 1.7028, F1 Micro: 0.4062, F1 Macro: 0.3479, Accuracy: 0.4062\n","Epoch 173, Train Loss: 0.8302, Val Loss: 1.6925, F1 Micro: 0.4792, F1 Macro: 0.4893, Accuracy: 0.4792\n","Epoch 174, Train Loss: 0.8308, Val Loss: 1.5158, F1 Micro: 0.5104, F1 Macro: 0.4991, Accuracy: 0.5104\n","Epoch 175, Train Loss: 0.7544, Val Loss: 1.6407, F1 Micro: 0.4583, F1 Macro: 0.4540, Accuracy: 0.4583\n","Epoch 176, Train Loss: 0.7402, Val Loss: 1.3999, F1 Micro: 0.5208, F1 Macro: 0.5280, Accuracy: 0.5208\n","Epoch 177, Train Loss: 0.8196, Val Loss: 1.5448, F1 Micro: 0.4271, F1 Macro: 0.4458, Accuracy: 0.4271\n","Epoch 178, Train Loss: 0.8240, Val Loss: 1.5618, F1 Micro: 0.4271, F1 Macro: 0.4199, Accuracy: 0.4271\n","Epoch 179, Train Loss: 0.7821, Val Loss: 1.5324, F1 Micro: 0.5625, F1 Macro: 0.5467, Accuracy: 0.5625\n","Epoch 180, Train Loss: 0.7476, Val Loss: 1.4706, F1 Micro: 0.5104, F1 Macro: 0.4730, Accuracy: 0.5104\n","Epoch 181, Train Loss: 0.8033, Val Loss: 1.3721, F1 Micro: 0.5625, F1 Macro: 0.5520, Accuracy: 0.5625\n","Epoch 182, Train Loss: 0.7529, Val Loss: 1.9446, F1 Micro: 0.3958, F1 Macro: 0.3722, Accuracy: 0.3958\n","Epoch 183, Train Loss: 0.8215, Val Loss: 1.5571, F1 Micro: 0.5312, F1 Macro: 0.4986, Accuracy: 0.5312\n","Epoch 184, Train Loss: 0.7503, Val Loss: 1.4261, F1 Micro: 0.4688, F1 Macro: 0.4780, Accuracy: 0.4688\n","Epoch 185, Train Loss: 0.8022, Val Loss: 1.4276, F1 Micro: 0.5625, F1 Macro: 0.5595, Accuracy: 0.5625\n","Epoch 186, Train Loss: 0.8226, Val Loss: 1.4049, F1 Micro: 0.5625, F1 Macro: 0.5694, Accuracy: 0.5625\n","Epoch 187, Train Loss: 0.8272, Val Loss: 1.8867, F1 Micro: 0.3750, F1 Macro: 0.3053, Accuracy: 0.3750\n","Epoch 188, Train Loss: 0.7790, Val Loss: 1.8458, F1 Micro: 0.4688, F1 Macro: 0.4417, Accuracy: 0.4688\n","Epoch 189, Train Loss: 0.7729, Val Loss: 2.0107, F1 Micro: 0.3438, F1 Macro: 0.2768, Accuracy: 0.3438\n","Epoch 190, Train Loss: 0.8274, Val Loss: 1.6244, F1 Micro: 0.4896, F1 Macro: 0.4737, Accuracy: 0.4896\n","Epoch 191, Train Loss: 0.8424, Val Loss: 1.4999, F1 Micro: 0.5312, F1 Macro: 0.5446, Accuracy: 0.5312\n","Epoch 192, Train Loss: 0.7366, Val Loss: 1.4911, F1 Micro: 0.4583, F1 Macro: 0.4496, Accuracy: 0.4583\n","Epoch 193, Train Loss: 0.7363, Val Loss: 1.3594, F1 Micro: 0.5521, F1 Macro: 0.5569, Accuracy: 0.5521\n","Epoch 194, Train Loss: 0.8424, Val Loss: 1.4057, F1 Micro: 0.4688, F1 Macro: 0.4732, Accuracy: 0.4688\n","Epoch 195, Train Loss: 0.8138, Val Loss: 2.1941, F1 Micro: 0.4062, F1 Macro: 0.3747, Accuracy: 0.4062\n","Epoch 196, Train Loss: 0.7546, Val Loss: 1.5511, F1 Micro: 0.5312, F1 Macro: 0.5320, Accuracy: 0.5312\n","Epoch 197, Train Loss: 0.8044, Val Loss: 1.7238, F1 Micro: 0.4688, F1 Macro: 0.4157, Accuracy: 0.4688\n","Epoch 198, Train Loss: 0.7892, Val Loss: 1.8541, F1 Micro: 0.3958, F1 Macro: 0.3919, Accuracy: 0.3958\n","Epoch 199, Train Loss: 0.8342, Val Loss: 2.4952, F1 Micro: 0.3542, F1 Macro: 0.3556, Accuracy: 0.3542\n","Epoch 200, Train Loss: 0.8109, Val Loss: 1.5801, F1 Micro: 0.5208, F1 Macro: 0.5029, Accuracy: 0.5208\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8064, Val Loss: 1.6717, F1 Micro: 0.2292, F1 Macro: 0.1110, Accuracy: 0.2292\n","Epoch 2, Train Loss: 1.7347, Val Loss: 1.6385, F1 Micro: 0.3021, F1 Macro: 0.2360, Accuracy: 0.3021\n","Epoch 3, Train Loss: 1.7266, Val Loss: 1.6216, F1 Micro: 0.3125, F1 Macro: 0.2217, Accuracy: 0.3125\n","Epoch 4, Train Loss: 1.6764, Val Loss: 1.6064, F1 Micro: 0.3958, F1 Macro: 0.3825, Accuracy: 0.3958\n","Epoch 5, Train Loss: 1.6684, Val Loss: 1.6885, F1 Micro: 0.3021, F1 Macro: 0.2322, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.6763, Val Loss: 1.5866, F1 Micro: 0.3750, F1 Macro: 0.3463, Accuracy: 0.3750\n","Epoch 7, Train Loss: 1.6542, Val Loss: 1.6334, F1 Micro: 0.3021, F1 Macro: 0.2403, Accuracy: 0.3021\n","Epoch 8, Train Loss: 1.6245, Val Loss: 1.5754, F1 Micro: 0.4167, F1 Macro: 0.4305, Accuracy: 0.4167\n","Epoch 9, Train Loss: 1.6134, Val Loss: 1.5781, F1 Micro: 0.3125, F1 Macro: 0.2986, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.6086, Val Loss: 1.5759, F1 Micro: 0.3646, F1 Macro: 0.3369, Accuracy: 0.3646\n","Epoch 11, Train Loss: 1.6082, Val Loss: 1.5592, F1 Micro: 0.3750, F1 Macro: 0.3177, Accuracy: 0.3750\n","Epoch 12, Train Loss: 1.5711, Val Loss: 1.5211, F1 Micro: 0.4062, F1 Macro: 0.3749, Accuracy: 0.4062\n","Epoch 13, Train Loss: 1.5497, Val Loss: 1.5540, F1 Micro: 0.4062, F1 Macro: 0.3662, Accuracy: 0.4062\n","Epoch 14, Train Loss: 1.5540, Val Loss: 1.5627, F1 Micro: 0.3750, F1 Macro: 0.3241, Accuracy: 0.3750\n","Epoch 15, Train Loss: 1.5363, Val Loss: 1.5863, F1 Micro: 0.3750, F1 Macro: 0.3256, Accuracy: 0.3750\n","Epoch 16, Train Loss: 1.5333, Val Loss: 1.5419, F1 Micro: 0.3438, F1 Macro: 0.3294, Accuracy: 0.3438\n","Epoch 17, Train Loss: 1.5169, Val Loss: 1.5494, F1 Micro: 0.4271, F1 Macro: 0.3555, Accuracy: 0.4271\n","Epoch 18, Train Loss: 1.5067, Val Loss: 1.4833, F1 Micro: 0.4167, F1 Macro: 0.3950, Accuracy: 0.4167\n","Epoch 19, Train Loss: 1.5123, Val Loss: 1.5729, F1 Micro: 0.4688, F1 Macro: 0.4470, Accuracy: 0.4688\n","Epoch 20, Train Loss: 1.5093, Val Loss: 1.4847, F1 Micro: 0.4062, F1 Macro: 0.3558, Accuracy: 0.4062\n","Epoch 21, Train Loss: 1.5141, Val Loss: 1.6717, F1 Micro: 0.3125, F1 Macro: 0.2879, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.4597, Val Loss: 1.5215, F1 Micro: 0.4792, F1 Macro: 0.4075, Accuracy: 0.4792\n","Epoch 23, Train Loss: 1.4801, Val Loss: 1.5845, F1 Micro: 0.3958, F1 Macro: 0.3516, Accuracy: 0.3958\n","Epoch 24, Train Loss: 1.4530, Val Loss: 1.5134, F1 Micro: 0.4583, F1 Macro: 0.4323, Accuracy: 0.4583\n","Epoch 25, Train Loss: 1.4558, Val Loss: 1.4418, F1 Micro: 0.5208, F1 Macro: 0.5014, Accuracy: 0.5208\n","Epoch 26, Train Loss: 1.4593, Val Loss: 1.6000, F1 Micro: 0.5208, F1 Macro: 0.4492, Accuracy: 0.5208\n","Epoch 27, Train Loss: 1.4815, Val Loss: 1.4871, F1 Micro: 0.4271, F1 Macro: 0.4072, Accuracy: 0.4271\n","Epoch 28, Train Loss: 1.4036, Val Loss: 1.4578, F1 Micro: 0.5000, F1 Macro: 0.4836, Accuracy: 0.5000\n","Epoch 29, Train Loss: 1.3982, Val Loss: 1.4633, F1 Micro: 0.4896, F1 Macro: 0.4460, Accuracy: 0.4896\n","Epoch 30, Train Loss: 1.4171, Val Loss: 1.4698, F1 Micro: 0.4375, F1 Macro: 0.3870, Accuracy: 0.4375\n","Epoch 31, Train Loss: 1.4177, Val Loss: 1.5869, F1 Micro: 0.3854, F1 Macro: 0.3432, Accuracy: 0.3854\n","Epoch 32, Train Loss: 1.4111, Val Loss: 1.5315, F1 Micro: 0.4375, F1 Macro: 0.4200, Accuracy: 0.4375\n","Epoch 33, Train Loss: 1.3982, Val Loss: 1.4986, F1 Micro: 0.4167, F1 Macro: 0.3472, Accuracy: 0.4167\n","Epoch 34, Train Loss: 1.3911, Val Loss: 1.4063, F1 Micro: 0.4688, F1 Macro: 0.4416, Accuracy: 0.4688\n","Epoch 35, Train Loss: 1.3881, Val Loss: 1.6441, F1 Micro: 0.3438, F1 Macro: 0.3361, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.3743, Val Loss: 1.4360, F1 Micro: 0.4375, F1 Macro: 0.3858, Accuracy: 0.4375\n","Epoch 37, Train Loss: 1.3645, Val Loss: 1.4033, F1 Micro: 0.4688, F1 Macro: 0.4419, Accuracy: 0.4688\n","Epoch 38, Train Loss: 1.3563, Val Loss: 1.4984, F1 Micro: 0.4896, F1 Macro: 0.4502, Accuracy: 0.4896\n","Epoch 39, Train Loss: 1.3536, Val Loss: 1.4991, F1 Micro: 0.4271, F1 Macro: 0.4308, Accuracy: 0.4271\n","Epoch 40, Train Loss: 1.3744, Val Loss: 1.4739, F1 Micro: 0.4375, F1 Macro: 0.3822, Accuracy: 0.4375\n","Epoch 41, Train Loss: 1.3303, Val Loss: 1.5146, F1 Micro: 0.4583, F1 Macro: 0.3909, Accuracy: 0.4583\n","Epoch 42, Train Loss: 1.3536, Val Loss: 1.4595, F1 Micro: 0.3958, F1 Macro: 0.3970, Accuracy: 0.3958\n","Epoch 43, Train Loss: 1.3694, Val Loss: 1.7690, F1 Micro: 0.3333, F1 Macro: 0.3030, Accuracy: 0.3333\n","Epoch 44, Train Loss: 1.3451, Val Loss: 1.4464, F1 Micro: 0.5104, F1 Macro: 0.4505, Accuracy: 0.5104\n","Epoch 45, Train Loss: 1.2915, Val Loss: 1.3857, F1 Micro: 0.4792, F1 Macro: 0.4747, Accuracy: 0.4792\n","Epoch 46, Train Loss: 1.2993, Val Loss: 1.3852, F1 Micro: 0.5625, F1 Macro: 0.5409, Accuracy: 0.5625\n","Epoch 47, Train Loss: 1.3132, Val Loss: 1.3826, F1 Micro: 0.6146, F1 Macro: 0.5947, Accuracy: 0.6146\n","Epoch 48, Train Loss: 1.2736, Val Loss: 1.4878, F1 Micro: 0.5208, F1 Macro: 0.4983, Accuracy: 0.5208\n","Epoch 49, Train Loss: 1.2962, Val Loss: 1.4950, F1 Micro: 0.3333, F1 Macro: 0.3076, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.2972, Val Loss: 1.5198, F1 Micro: 0.4896, F1 Macro: 0.4906, Accuracy: 0.4896\n","Epoch 51, Train Loss: 1.2812, Val Loss: 1.6424, F1 Micro: 0.3229, F1 Macro: 0.3134, Accuracy: 0.3229\n","Epoch 52, Train Loss: 1.2748, Val Loss: 1.5825, F1 Micro: 0.5104, F1 Macro: 0.4855, Accuracy: 0.5104\n","Epoch 53, Train Loss: 1.2935, Val Loss: 1.8170, F1 Micro: 0.2812, F1 Macro: 0.2220, Accuracy: 0.2812\n","Epoch 54, Train Loss: 1.2596, Val Loss: 1.3823, F1 Micro: 0.5312, F1 Macro: 0.5236, Accuracy: 0.5312\n","Epoch 55, Train Loss: 1.2324, Val Loss: 1.2933, F1 Micro: 0.5625, F1 Macro: 0.5538, Accuracy: 0.5625\n","Epoch 56, Train Loss: 1.2422, Val Loss: 1.6290, F1 Micro: 0.3542, F1 Macro: 0.3125, Accuracy: 0.3542\n","Epoch 57, Train Loss: 1.2172, Val Loss: 1.3103, F1 Micro: 0.6146, F1 Macro: 0.6087, Accuracy: 0.6146\n","Epoch 58, Train Loss: 1.2474, Val Loss: 1.7201, F1 Micro: 0.3646, F1 Macro: 0.2775, Accuracy: 0.3646\n","Epoch 59, Train Loss: 1.2428, Val Loss: 1.7407, F1 Micro: 0.3542, F1 Macro: 0.3103, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.2164, Val Loss: 1.4045, F1 Micro: 0.5625, F1 Macro: 0.5552, Accuracy: 0.5625\n","Epoch 61, Train Loss: 1.2513, Val Loss: 1.4199, F1 Micro: 0.5938, F1 Macro: 0.5773, Accuracy: 0.5938\n","Epoch 62, Train Loss: 1.1736, Val Loss: 1.2755, F1 Micro: 0.5938, F1 Macro: 0.5860, Accuracy: 0.5938\n","Epoch 63, Train Loss: 1.2117, Val Loss: 1.3645, F1 Micro: 0.5000, F1 Macro: 0.4628, Accuracy: 0.5000\n","Epoch 64, Train Loss: 1.2047, Val Loss: 1.4939, F1 Micro: 0.3750, F1 Macro: 0.3026, Accuracy: 0.3750\n","Epoch 65, Train Loss: 1.2030, Val Loss: 1.3741, F1 Micro: 0.5312, F1 Macro: 0.5167, Accuracy: 0.5312\n","Epoch 66, Train Loss: 1.1935, Val Loss: 1.2826, F1 Micro: 0.5417, F1 Macro: 0.5432, Accuracy: 0.5417\n","Epoch 67, Train Loss: 1.1921, Val Loss: 1.3645, F1 Micro: 0.5000, F1 Macro: 0.4686, Accuracy: 0.5000\n","Epoch 68, Train Loss: 1.2123, Val Loss: 1.4842, F1 Micro: 0.5000, F1 Macro: 0.4767, Accuracy: 0.5000\n","Epoch 69, Train Loss: 1.1932, Val Loss: 1.5396, F1 Micro: 0.4688, F1 Macro: 0.4057, Accuracy: 0.4688\n","Epoch 70, Train Loss: 1.1959, Val Loss: 1.5202, F1 Micro: 0.4583, F1 Macro: 0.4215, Accuracy: 0.4583\n","Epoch 71, Train Loss: 1.1445, Val Loss: 1.4174, F1 Micro: 0.5312, F1 Macro: 0.4833, Accuracy: 0.5312\n","Epoch 72, Train Loss: 1.1474, Val Loss: 1.2994, F1 Micro: 0.6354, F1 Macro: 0.6275, Accuracy: 0.6354\n","Epoch 73, Train Loss: 1.1230, Val Loss: 1.2799, F1 Micro: 0.6042, F1 Macro: 0.5951, Accuracy: 0.6042\n","Epoch 74, Train Loss: 1.1483, Val Loss: 1.3301, F1 Micro: 0.5104, F1 Macro: 0.4829, Accuracy: 0.5104\n","Epoch 75, Train Loss: 1.1361, Val Loss: 1.5183, F1 Micro: 0.4688, F1 Macro: 0.4360, Accuracy: 0.4688\n","Epoch 76, Train Loss: 1.1327, Val Loss: 1.6771, F1 Micro: 0.4167, F1 Macro: 0.3727, Accuracy: 0.4167\n","Epoch 77, Train Loss: 1.1527, Val Loss: 1.3451, F1 Micro: 0.5729, F1 Macro: 0.5625, Accuracy: 0.5729\n","Epoch 78, Train Loss: 1.1352, Val Loss: 1.3693, F1 Micro: 0.5833, F1 Macro: 0.5760, Accuracy: 0.5833\n","Epoch 79, Train Loss: 1.1499, Val Loss: 1.6574, F1 Micro: 0.3854, F1 Macro: 0.3708, Accuracy: 0.3854\n","Epoch 80, Train Loss: 1.1299, Val Loss: 1.5104, F1 Micro: 0.4792, F1 Macro: 0.4876, Accuracy: 0.4792\n","Epoch 81, Train Loss: 1.0758, Val Loss: 1.3523, F1 Micro: 0.4896, F1 Macro: 0.4217, Accuracy: 0.4896\n","Epoch 82, Train Loss: 1.1061, Val Loss: 1.3329, F1 Micro: 0.5833, F1 Macro: 0.5835, Accuracy: 0.5833\n","Epoch 83, Train Loss: 1.1093, Val Loss: 1.3721, F1 Micro: 0.5104, F1 Macro: 0.4938, Accuracy: 0.5104\n","Epoch 84, Train Loss: 1.1326, Val Loss: 1.3839, F1 Micro: 0.5312, F1 Macro: 0.4990, Accuracy: 0.5312\n","Epoch 85, Train Loss: 1.0704, Val Loss: 1.3436, F1 Micro: 0.5521, F1 Macro: 0.5375, Accuracy: 0.5521\n","Epoch 86, Train Loss: 1.1139, Val Loss: 1.5985, F1 Micro: 0.4583, F1 Macro: 0.4064, Accuracy: 0.4583\n","Epoch 87, Train Loss: 1.0821, Val Loss: 1.5120, F1 Micro: 0.4375, F1 Macro: 0.4324, Accuracy: 0.4375\n","Epoch 88, Train Loss: 1.1118, Val Loss: 1.5908, F1 Micro: 0.4167, F1 Macro: 0.3879, Accuracy: 0.4167\n","Epoch 89, Train Loss: 1.1323, Val Loss: 1.3744, F1 Micro: 0.5417, F1 Macro: 0.5289, Accuracy: 0.5417\n","Epoch 90, Train Loss: 1.1089, Val Loss: 1.8437, F1 Micro: 0.4062, F1 Macro: 0.3586, Accuracy: 0.4062\n","Epoch 91, Train Loss: 1.1167, Val Loss: 1.2989, F1 Micro: 0.5938, F1 Macro: 0.5930, Accuracy: 0.5938\n","Epoch 92, Train Loss: 1.0299, Val Loss: 1.3537, F1 Micro: 0.5417, F1 Macro: 0.5353, Accuracy: 0.5417\n","Epoch 93, Train Loss: 1.1214, Val Loss: 1.2633, F1 Micro: 0.5833, F1 Macro: 0.5725, Accuracy: 0.5833\n","Epoch 94, Train Loss: 1.0806, Val Loss: 1.4890, F1 Micro: 0.3750, F1 Macro: 0.3703, Accuracy: 0.3750\n","Epoch 95, Train Loss: 1.0728, Val Loss: 1.3260, F1 Micro: 0.5000, F1 Macro: 0.4492, Accuracy: 0.5000\n","Epoch 96, Train Loss: 1.0708, Val Loss: 1.2552, F1 Micro: 0.5833, F1 Macro: 0.5864, Accuracy: 0.5833\n","Epoch 97, Train Loss: 1.0597, Val Loss: 1.3486, F1 Micro: 0.4896, F1 Macro: 0.4725, Accuracy: 0.4896\n","Epoch 98, Train Loss: 1.0596, Val Loss: 1.2406, F1 Micro: 0.6042, F1 Macro: 0.6095, Accuracy: 0.6042\n","Epoch 99, Train Loss: 1.0302, Val Loss: 1.2705, F1 Micro: 0.6042, F1 Macro: 0.5955, Accuracy: 0.6042\n","Epoch 100, Train Loss: 0.9955, Val Loss: 1.3781, F1 Micro: 0.5208, F1 Macro: 0.4695, Accuracy: 0.5208\n","Epoch 101, Train Loss: 1.0407, Val Loss: 1.6283, F1 Micro: 0.4271, F1 Macro: 0.4308, Accuracy: 0.4271\n","Epoch 102, Train Loss: 1.0130, Val Loss: 1.3798, F1 Micro: 0.5312, F1 Macro: 0.5026, Accuracy: 0.5312\n","Epoch 103, Train Loss: 0.9935, Val Loss: 1.2631, F1 Micro: 0.5208, F1 Macro: 0.5168, Accuracy: 0.5208\n","Epoch 104, Train Loss: 1.0269, Val Loss: 1.6357, F1 Micro: 0.4167, F1 Macro: 0.3928, Accuracy: 0.4167\n","Epoch 105, Train Loss: 1.0650, Val Loss: 1.3343, F1 Micro: 0.5729, F1 Macro: 0.5606, Accuracy: 0.5729\n","Epoch 106, Train Loss: 1.0205, Val Loss: 1.1968, F1 Micro: 0.6458, F1 Macro: 0.6370, Accuracy: 0.6458\n","Epoch 107, Train Loss: 0.9962, Val Loss: 1.4057, F1 Micro: 0.4375, F1 Macro: 0.4543, Accuracy: 0.4375\n","Epoch 108, Train Loss: 0.9880, Val Loss: 1.5027, F1 Micro: 0.4167, F1 Macro: 0.4081, Accuracy: 0.4167\n","Epoch 109, Train Loss: 1.0037, Val Loss: 1.8443, F1 Micro: 0.4583, F1 Macro: 0.4472, Accuracy: 0.4583\n","Epoch 110, Train Loss: 0.9893, Val Loss: 1.4757, F1 Micro: 0.4375, F1 Macro: 0.3687, Accuracy: 0.4375\n","Epoch 111, Train Loss: 1.0295, Val Loss: 1.2501, F1 Micro: 0.6042, F1 Macro: 0.5947, Accuracy: 0.6042\n","Epoch 112, Train Loss: 0.9939, Val Loss: 1.5583, F1 Micro: 0.5000, F1 Macro: 0.4877, Accuracy: 0.5000\n","Epoch 113, Train Loss: 0.9945, Val Loss: 1.7382, F1 Micro: 0.4479, F1 Macro: 0.4128, Accuracy: 0.4479\n","Epoch 114, Train Loss: 1.0306, Val Loss: 1.2914, F1 Micro: 0.5208, F1 Macro: 0.4744, Accuracy: 0.5208\n","Epoch 115, Train Loss: 1.0201, Val Loss: 1.8302, F1 Micro: 0.3333, F1 Macro: 0.3008, Accuracy: 0.3333\n","Epoch 116, Train Loss: 0.9795, Val Loss: 1.3657, F1 Micro: 0.6250, F1 Macro: 0.6193, Accuracy: 0.6250\n","Epoch 117, Train Loss: 0.9554, Val Loss: 1.3391, F1 Micro: 0.5417, F1 Macro: 0.5362, Accuracy: 0.5417\n","Epoch 118, Train Loss: 0.9611, Val Loss: 1.7400, F1 Micro: 0.3854, F1 Macro: 0.3612, Accuracy: 0.3854\n","Epoch 119, Train Loss: 0.9519, Val Loss: 1.4412, F1 Micro: 0.4792, F1 Macro: 0.4532, Accuracy: 0.4792\n","Epoch 120, Train Loss: 1.0022, Val Loss: 1.3188, F1 Micro: 0.5208, F1 Macro: 0.4664, Accuracy: 0.5208\n","Epoch 121, Train Loss: 0.9723, Val Loss: 1.3466, F1 Micro: 0.5625, F1 Macro: 0.5554, Accuracy: 0.5625\n","Epoch 122, Train Loss: 0.9819, Val Loss: 1.6141, F1 Micro: 0.5833, F1 Macro: 0.5158, Accuracy: 0.5833\n","Epoch 123, Train Loss: 0.9521, Val Loss: 1.4238, F1 Micro: 0.5833, F1 Macro: 0.5784, Accuracy: 0.5833\n","Epoch 124, Train Loss: 0.9372, Val Loss: 1.2393, F1 Micro: 0.5417, F1 Macro: 0.5308, Accuracy: 0.5417\n","Epoch 125, Train Loss: 0.9093, Val Loss: 1.3231, F1 Micro: 0.5625, F1 Macro: 0.5646, Accuracy: 0.5625\n","Epoch 126, Train Loss: 0.9835, Val Loss: 1.2130, F1 Micro: 0.6250, F1 Macro: 0.6214, Accuracy: 0.6250\n","Epoch 127, Train Loss: 0.9686, Val Loss: 1.3134, F1 Micro: 0.4792, F1 Macro: 0.4606, Accuracy: 0.4792\n","Epoch 128, Train Loss: 0.9257, Val Loss: 1.5710, F1 Micro: 0.4375, F1 Macro: 0.3780, Accuracy: 0.4375\n","Epoch 129, Train Loss: 0.9828, Val Loss: 1.3157, F1 Micro: 0.5729, F1 Macro: 0.5659, Accuracy: 0.5729\n","Epoch 130, Train Loss: 0.9878, Val Loss: 1.2517, F1 Micro: 0.5625, F1 Macro: 0.5755, Accuracy: 0.5625\n","Epoch 131, Train Loss: 0.9384, Val Loss: 1.4564, F1 Micro: 0.5417, F1 Macro: 0.4968, Accuracy: 0.5417\n","Epoch 132, Train Loss: 0.9499, Val Loss: 1.9310, F1 Micro: 0.3958, F1 Macro: 0.3704, Accuracy: 0.3958\n","Epoch 133, Train Loss: 0.9211, Val Loss: 1.1868, F1 Micro: 0.5521, F1 Macro: 0.5379, Accuracy: 0.5521\n","Epoch 134, Train Loss: 0.9649, Val Loss: 1.6081, F1 Micro: 0.4792, F1 Macro: 0.4261, Accuracy: 0.4792\n","Epoch 135, Train Loss: 0.9506, Val Loss: 1.5190, F1 Micro: 0.5417, F1 Macro: 0.5015, Accuracy: 0.5417\n","Epoch 136, Train Loss: 0.9048, Val Loss: 1.5358, F1 Micro: 0.4271, F1 Macro: 0.3864, Accuracy: 0.4271\n","Epoch 137, Train Loss: 0.8951, Val Loss: 1.3392, F1 Micro: 0.5729, F1 Macro: 0.5344, Accuracy: 0.5729\n","Epoch 138, Train Loss: 0.8743, Val Loss: 1.6830, F1 Micro: 0.4896, F1 Macro: 0.4848, Accuracy: 0.4896\n","Epoch 139, Train Loss: 0.9384, Val Loss: 1.4537, F1 Micro: 0.5417, F1 Macro: 0.5332, Accuracy: 0.5417\n","Epoch 140, Train Loss: 0.9393, Val Loss: 1.3629, F1 Micro: 0.5312, F1 Macro: 0.4983, Accuracy: 0.5312\n","Epoch 141, Train Loss: 0.9283, Val Loss: 1.4517, F1 Micro: 0.4688, F1 Macro: 0.4449, Accuracy: 0.4688\n","Epoch 142, Train Loss: 0.8919, Val Loss: 1.3150, F1 Micro: 0.4896, F1 Macro: 0.4898, Accuracy: 0.4896\n","Epoch 143, Train Loss: 0.9231, Val Loss: 1.4741, F1 Micro: 0.4688, F1 Macro: 0.4600, Accuracy: 0.4688\n","Epoch 144, Train Loss: 0.9156, Val Loss: 1.2810, F1 Micro: 0.6458, F1 Macro: 0.6175, Accuracy: 0.6458\n","Epoch 145, Train Loss: 0.8952, Val Loss: 1.4878, F1 Micro: 0.4688, F1 Macro: 0.4430, Accuracy: 0.4688\n","Epoch 146, Train Loss: 0.8515, Val Loss: 1.2060, F1 Micro: 0.6250, F1 Macro: 0.6307, Accuracy: 0.6250\n","Epoch 147, Train Loss: 0.9198, Val Loss: 1.2674, F1 Micro: 0.6562, F1 Macro: 0.6529, Accuracy: 0.6562\n","Epoch 148, Train Loss: 0.9006, Val Loss: 2.6302, F1 Micro: 0.2708, F1 Macro: 0.2371, Accuracy: 0.2708\n","Epoch 149, Train Loss: 0.9093, Val Loss: 1.1469, F1 Micro: 0.6667, F1 Macro: 0.6697, Accuracy: 0.6667\n","Epoch 150, Train Loss: 0.8320, Val Loss: 1.2912, F1 Micro: 0.5208, F1 Macro: 0.4850, Accuracy: 0.5208\n","Epoch 151, Train Loss: 0.8859, Val Loss: 1.6112, F1 Micro: 0.4896, F1 Macro: 0.4640, Accuracy: 0.4896\n","Epoch 152, Train Loss: 0.9269, Val Loss: 1.3911, F1 Micro: 0.5208, F1 Macro: 0.5075, Accuracy: 0.5208\n","Epoch 153, Train Loss: 0.8720, Val Loss: 1.1879, F1 Micro: 0.5312, F1 Macro: 0.5223, Accuracy: 0.5312\n","Epoch 154, Train Loss: 0.9222, Val Loss: 1.1542, F1 Micro: 0.5938, F1 Macro: 0.5815, Accuracy: 0.5938\n","Epoch 155, Train Loss: 0.8406, Val Loss: 1.2845, F1 Micro: 0.6146, F1 Macro: 0.6000, Accuracy: 0.6146\n","Epoch 156, Train Loss: 0.8682, Val Loss: 1.8477, F1 Micro: 0.5000, F1 Macro: 0.4637, Accuracy: 0.5000\n","Epoch 157, Train Loss: 0.8935, Val Loss: 1.2087, F1 Micro: 0.6146, F1 Macro: 0.6097, Accuracy: 0.6146\n","Epoch 158, Train Loss: 0.8347, Val Loss: 1.2103, F1 Micro: 0.5729, F1 Macro: 0.5615, Accuracy: 0.5729\n","Epoch 159, Train Loss: 0.8593, Val Loss: 1.3353, F1 Micro: 0.5417, F1 Macro: 0.5315, Accuracy: 0.5417\n","Epoch 160, Train Loss: 0.8178, Val Loss: 1.3387, F1 Micro: 0.4688, F1 Macro: 0.4065, Accuracy: 0.4688\n","Epoch 161, Train Loss: 0.8522, Val Loss: 1.4726, F1 Micro: 0.4688, F1 Macro: 0.4583, Accuracy: 0.4688\n","Epoch 162, Train Loss: 0.8632, Val Loss: 1.3681, F1 Micro: 0.5000, F1 Macro: 0.4920, Accuracy: 0.5000\n","Epoch 163, Train Loss: 0.8199, Val Loss: 1.2814, F1 Micro: 0.6146, F1 Macro: 0.6166, Accuracy: 0.6146\n","Epoch 164, Train Loss: 0.8518, Val Loss: 1.7916, F1 Micro: 0.3646, F1 Macro: 0.3286, Accuracy: 0.3646\n","Epoch 165, Train Loss: 0.8410, Val Loss: 1.5294, F1 Micro: 0.5208, F1 Macro: 0.4981, Accuracy: 0.5208\n","Epoch 166, Train Loss: 0.8730, Val Loss: 1.3030, F1 Micro: 0.5833, F1 Macro: 0.5753, Accuracy: 0.5833\n","Epoch 167, Train Loss: 0.8544, Val Loss: 1.6847, F1 Micro: 0.4792, F1 Macro: 0.4358, Accuracy: 0.4792\n","Epoch 168, Train Loss: 0.8790, Val Loss: 1.1599, F1 Micro: 0.6042, F1 Macro: 0.5992, Accuracy: 0.6042\n","Epoch 169, Train Loss: 0.9004, Val Loss: 1.6524, F1 Micro: 0.4479, F1 Macro: 0.4423, Accuracy: 0.4479\n","Epoch 170, Train Loss: 0.9032, Val Loss: 1.6335, F1 Micro: 0.4896, F1 Macro: 0.4536, Accuracy: 0.4896\n","Epoch 171, Train Loss: 0.8040, Val Loss: 1.3865, F1 Micro: 0.5208, F1 Macro: 0.5187, Accuracy: 0.5208\n","Epoch 172, Train Loss: 0.8489, Val Loss: 1.4311, F1 Micro: 0.4375, F1 Macro: 0.4105, Accuracy: 0.4375\n","Epoch 173, Train Loss: 0.8536, Val Loss: 1.2438, F1 Micro: 0.6458, F1 Macro: 0.6350, Accuracy: 0.6458\n","Epoch 174, Train Loss: 0.8587, Val Loss: 1.1250, F1 Micro: 0.7083, F1 Macro: 0.7028, Accuracy: 0.7083\n","Epoch 175, Train Loss: 0.8869, Val Loss: 1.1721, F1 Micro: 0.6250, F1 Macro: 0.6234, Accuracy: 0.6250\n","Epoch 176, Train Loss: 0.8229, Val Loss: 1.4038, F1 Micro: 0.4583, F1 Macro: 0.4276, Accuracy: 0.4583\n","Epoch 177, Train Loss: 0.8267, Val Loss: 1.8910, F1 Micro: 0.3958, F1 Macro: 0.3531, Accuracy: 0.3958\n","Epoch 178, Train Loss: 0.8276, Val Loss: 1.5217, F1 Micro: 0.5938, F1 Macro: 0.6116, Accuracy: 0.5938\n","Epoch 179, Train Loss: 0.8905, Val Loss: 1.5031, F1 Micro: 0.4062, F1 Macro: 0.3440, Accuracy: 0.4062\n","Epoch 180, Train Loss: 0.8205, Val Loss: 1.5258, F1 Micro: 0.5625, F1 Macro: 0.5525, Accuracy: 0.5625\n","Epoch 181, Train Loss: 0.7611, Val Loss: 1.1740, F1 Micro: 0.6667, F1 Macro: 0.6619, Accuracy: 0.6667\n","Epoch 182, Train Loss: 0.7935, Val Loss: 1.2916, F1 Micro: 0.5833, F1 Macro: 0.5659, Accuracy: 0.5833\n","Epoch 183, Train Loss: 0.7941, Val Loss: 1.4052, F1 Micro: 0.6042, F1 Macro: 0.5480, Accuracy: 0.6042\n","Epoch 184, Train Loss: 0.7679, Val Loss: 1.2081, F1 Micro: 0.6146, F1 Macro: 0.6047, Accuracy: 0.6146\n","Epoch 185, Train Loss: 0.8586, Val Loss: 1.7646, F1 Micro: 0.4688, F1 Macro: 0.4488, Accuracy: 0.4688\n","Epoch 186, Train Loss: 0.8301, Val Loss: 1.7063, F1 Micro: 0.4062, F1 Macro: 0.3768, Accuracy: 0.4062\n","Epoch 187, Train Loss: 0.8279, Val Loss: 1.6525, F1 Micro: 0.6146, F1 Macro: 0.5692, Accuracy: 0.6146\n","Epoch 188, Train Loss: 0.8463, Val Loss: 1.2477, F1 Micro: 0.5833, F1 Macro: 0.5864, Accuracy: 0.5833\n","Epoch 189, Train Loss: 0.8101, Val Loss: 1.5257, F1 Micro: 0.5625, F1 Macro: 0.5247, Accuracy: 0.5625\n","Epoch 190, Train Loss: 0.8033, Val Loss: 1.3668, F1 Micro: 0.5833, F1 Macro: 0.5786, Accuracy: 0.5833\n","Epoch 191, Train Loss: 0.7721, Val Loss: 1.1531, F1 Micro: 0.6354, F1 Macro: 0.6331, Accuracy: 0.6354\n","Epoch 192, Train Loss: 0.8051, Val Loss: 1.3074, F1 Micro: 0.5104, F1 Macro: 0.4752, Accuracy: 0.5104\n","Epoch 193, Train Loss: 0.8189, Val Loss: 1.4311, F1 Micro: 0.4688, F1 Macro: 0.4300, Accuracy: 0.4688\n","Epoch 194, Train Loss: 0.7537, Val Loss: 1.5372, F1 Micro: 0.4792, F1 Macro: 0.4589, Accuracy: 0.4792\n","Epoch 195, Train Loss: 0.8096, Val Loss: 1.1678, F1 Micro: 0.6562, F1 Macro: 0.6536, Accuracy: 0.6562\n","Epoch 196, Train Loss: 0.7807, Val Loss: 1.3641, F1 Micro: 0.5521, F1 Macro: 0.5407, Accuracy: 0.5521\n","Epoch 197, Train Loss: 0.7963, Val Loss: 1.3296, F1 Micro: 0.5312, F1 Macro: 0.4905, Accuracy: 0.5312\n","Epoch 198, Train Loss: 0.7704, Val Loss: 1.3677, F1 Micro: 0.5104, F1 Macro: 0.4915, Accuracy: 0.5104\n","Epoch 199, Train Loss: 0.8072, Val Loss: 1.4153, F1 Micro: 0.5312, F1 Macro: 0.5246, Accuracy: 0.5312\n","Epoch 200, Train Loss: 0.7509, Val Loss: 1.3062, F1 Micro: 0.5625, F1 Macro: 0.5516, Accuracy: 0.5625\n","Average Score for hyperparameters (0.001, 16, 50): 0.6020833333333333\n","Best hyperparameters for Outer FOLD 3: (0.01, 16, 50) with score 0.6500000000000001\n","Epoch 1, Train Loss: 2.1213, Val Loss: 2.1086, F1 Micro: 0.2583, F1 Macro: 0.1919, Accuracy: 0.2583\n","Epoch 2, Train Loss: 1.8099, Val Loss: 1.7186, F1 Micro: 0.2917, F1 Macro: 0.2725, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.7457, Val Loss: 1.9646, F1 Micro: 0.2500, F1 Macro: 0.1668, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.6671, Val Loss: 2.6661, F1 Micro: 0.2417, F1 Macro: 0.1612, Accuracy: 0.2417\n","Epoch 5, Train Loss: 1.6587, Val Loss: 1.7006, F1 Micro: 0.3083, F1 Macro: 0.2990, Accuracy: 0.3083\n","Epoch 6, Train Loss: 1.5870, Val Loss: 1.6840, F1 Micro: 0.3333, F1 Macro: 0.2896, Accuracy: 0.3333\n","Epoch 7, Train Loss: 1.5788, Val Loss: 1.6685, F1 Micro: 0.3833, F1 Macro: 0.3674, Accuracy: 0.3833\n","Epoch 8, Train Loss: 1.5811, Val Loss: 1.6157, F1 Micro: 0.4083, F1 Macro: 0.4010, Accuracy: 0.4083\n","Epoch 9, Train Loss: 1.5581, Val Loss: 1.8442, F1 Micro: 0.3417, F1 Macro: 0.2494, Accuracy: 0.3417\n","Epoch 10, Train Loss: 1.5483, Val Loss: 1.8299, F1 Micro: 0.3333, F1 Macro: 0.2497, Accuracy: 0.3333\n","Epoch 11, Train Loss: 1.4874, Val Loss: 1.6705, F1 Micro: 0.3417, F1 Macro: 0.3119, Accuracy: 0.3417\n","Epoch 12, Train Loss: 1.4605, Val Loss: 1.7907, F1 Micro: 0.3083, F1 Macro: 0.2905, Accuracy: 0.3083\n","Epoch 13, Train Loss: 1.4499, Val Loss: 1.7059, F1 Micro: 0.3250, F1 Macro: 0.3427, Accuracy: 0.3250\n","Epoch 14, Train Loss: 1.4388, Val Loss: 1.8093, F1 Micro: 0.3833, F1 Macro: 0.3377, Accuracy: 0.3833\n","Epoch 15, Train Loss: 1.4490, Val Loss: 1.7638, F1 Micro: 0.3250, F1 Macro: 0.2409, Accuracy: 0.3250\n","Epoch 16, Train Loss: 1.4318, Val Loss: 1.7550, F1 Micro: 0.3250, F1 Macro: 0.3333, Accuracy: 0.3250\n","Epoch 17, Train Loss: 1.3502, Val Loss: 1.6299, F1 Micro: 0.4583, F1 Macro: 0.4041, Accuracy: 0.4583\n","Epoch 18, Train Loss: 1.3436, Val Loss: 2.1275, F1 Micro: 0.3333, F1 Macro: 0.2876, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.3745, Val Loss: 2.5553, F1 Micro: 0.2750, F1 Macro: 0.2156, Accuracy: 0.2750\n","Epoch 20, Train Loss: 1.3822, Val Loss: 1.9744, F1 Micro: 0.4000, F1 Macro: 0.3105, Accuracy: 0.4000\n","Epoch 21, Train Loss: 1.4148, Val Loss: 1.8531, F1 Micro: 0.4167, F1 Macro: 0.3347, Accuracy: 0.4167\n","Epoch 22, Train Loss: 1.2818, Val Loss: 2.1095, F1 Micro: 0.3667, F1 Macro: 0.3256, Accuracy: 0.3667\n","Epoch 23, Train Loss: 1.3224, Val Loss: 2.1683, F1 Micro: 0.2583, F1 Macro: 0.1969, Accuracy: 0.2583\n","Epoch 24, Train Loss: 1.3435, Val Loss: 2.5444, F1 Micro: 0.3417, F1 Macro: 0.3279, Accuracy: 0.3417\n","Epoch 25, Train Loss: 1.3357, Val Loss: 1.8351, F1 Micro: 0.4000, F1 Macro: 0.4034, Accuracy: 0.4000\n","Epoch 26, Train Loss: 1.2653, Val Loss: 1.6727, F1 Micro: 0.4333, F1 Macro: 0.4283, Accuracy: 0.4333\n","Epoch 27, Train Loss: 1.3350, Val Loss: 2.6473, F1 Micro: 0.3583, F1 Macro: 0.2911, Accuracy: 0.3583\n","Epoch 28, Train Loss: 1.3093, Val Loss: 2.1142, F1 Micro: 0.3917, F1 Macro: 0.3101, Accuracy: 0.3917\n","Epoch 29, Train Loss: 1.2748, Val Loss: 1.6891, F1 Micro: 0.4500, F1 Macro: 0.4026, Accuracy: 0.4500\n","Epoch 30, Train Loss: 1.2416, Val Loss: 1.9112, F1 Micro: 0.4083, F1 Macro: 0.3973, Accuracy: 0.4083\n","Epoch 31, Train Loss: 1.2652, Val Loss: 1.9503, F1 Micro: 0.4417, F1 Macro: 0.3882, Accuracy: 0.4417\n","Epoch 32, Train Loss: 1.2218, Val Loss: 1.6518, F1 Micro: 0.4583, F1 Macro: 0.4075, Accuracy: 0.4583\n","Epoch 33, Train Loss: 1.2340, Val Loss: 1.9937, F1 Micro: 0.3750, F1 Macro: 0.3512, Accuracy: 0.3750\n","Epoch 34, Train Loss: 1.2204, Val Loss: 3.1965, F1 Micro: 0.2917, F1 Macro: 0.2873, Accuracy: 0.2917\n","Epoch 35, Train Loss: 1.1758, Val Loss: 1.8200, F1 Micro: 0.4250, F1 Macro: 0.3680, Accuracy: 0.4250\n","Epoch 36, Train Loss: 1.1328, Val Loss: 1.8614, F1 Micro: 0.4667, F1 Macro: 0.4661, Accuracy: 0.4667\n","Epoch 37, Train Loss: 1.1679, Val Loss: 2.0615, F1 Micro: 0.4250, F1 Macro: 0.3641, Accuracy: 0.4250\n","Epoch 38, Train Loss: 1.1773, Val Loss: 1.8628, F1 Micro: 0.4833, F1 Macro: 0.4181, Accuracy: 0.4833\n","Epoch 39, Train Loss: 1.0822, Val Loss: 3.3865, F1 Micro: 0.2833, F1 Macro: 0.2014, Accuracy: 0.2833\n","Epoch 40, Train Loss: 1.1473, Val Loss: 2.2767, F1 Micro: 0.3417, F1 Macro: 0.2995, Accuracy: 0.3417\n","Epoch 41, Train Loss: 1.1645, Val Loss: 1.7113, F1 Micro: 0.5083, F1 Macro: 0.4966, Accuracy: 0.5083\n","Epoch 42, Train Loss: 1.1527, Val Loss: 1.8629, F1 Micro: 0.4500, F1 Macro: 0.4344, Accuracy: 0.4500\n","Epoch 43, Train Loss: 1.0455, Val Loss: 2.4858, F1 Micro: 0.3083, F1 Macro: 0.2738, Accuracy: 0.3083\n","Epoch 44, Train Loss: 1.0304, Val Loss: 1.8699, F1 Micro: 0.4833, F1 Macro: 0.4742, Accuracy: 0.4833\n","Epoch 45, Train Loss: 1.0069, Val Loss: 1.7935, F1 Micro: 0.4667, F1 Macro: 0.4352, Accuracy: 0.4667\n","Epoch 46, Train Loss: 1.0375, Val Loss: 2.1881, F1 Micro: 0.3917, F1 Macro: 0.3630, Accuracy: 0.3917\n","Epoch 47, Train Loss: 1.0565, Val Loss: 1.6960, F1 Micro: 0.5167, F1 Macro: 0.4789, Accuracy: 0.5167\n","Epoch 48, Train Loss: 1.1651, Val Loss: 1.6625, F1 Micro: 0.5167, F1 Macro: 0.5144, Accuracy: 0.5167\n","Epoch 49, Train Loss: 1.0291, Val Loss: 1.8477, F1 Micro: 0.4917, F1 Macro: 0.4889, Accuracy: 0.4917\n","Epoch 50, Train Loss: 0.9726, Val Loss: 1.6552, F1 Micro: 0.5917, F1 Macro: 0.5789, Accuracy: 0.5917\n","Epoch 51, Train Loss: 0.9381, Val Loss: 1.7269, F1 Micro: 0.5500, F1 Macro: 0.5344, Accuracy: 0.5500\n","Epoch 52, Train Loss: 0.9587, Val Loss: 2.0576, F1 Micro: 0.4917, F1 Macro: 0.4475, Accuracy: 0.4917\n","Epoch 53, Train Loss: 0.9338, Val Loss: 1.7523, F1 Micro: 0.5333, F1 Macro: 0.4978, Accuracy: 0.5333\n","Epoch 54, Train Loss: 0.9934, Val Loss: 2.3521, F1 Micro: 0.4083, F1 Macro: 0.3777, Accuracy: 0.4083\n","Epoch 55, Train Loss: 1.0615, Val Loss: 2.1548, F1 Micro: 0.4333, F1 Macro: 0.4252, Accuracy: 0.4333\n","Epoch 56, Train Loss: 0.9969, Val Loss: 2.8137, F1 Micro: 0.3333, F1 Macro: 0.2804, Accuracy: 0.3333\n","Epoch 57, Train Loss: 1.0200, Val Loss: 1.7475, F1 Micro: 0.4833, F1 Macro: 0.4335, Accuracy: 0.4833\n","Epoch 58, Train Loss: 0.9637, Val Loss: 1.5580, F1 Micro: 0.5417, F1 Macro: 0.5157, Accuracy: 0.5417\n","Epoch 59, Train Loss: 0.9621, Val Loss: 2.4106, F1 Micro: 0.3833, F1 Macro: 0.3677, Accuracy: 0.3833\n","Epoch 60, Train Loss: 1.0212, Val Loss: 2.3679, F1 Micro: 0.3750, F1 Macro: 0.3377, Accuracy: 0.3750\n","Epoch 61, Train Loss: 0.9442, Val Loss: 1.6259, F1 Micro: 0.5333, F1 Macro: 0.5217, Accuracy: 0.5333\n","Epoch 62, Train Loss: 0.9255, Val Loss: 2.2636, F1 Micro: 0.3667, F1 Macro: 0.3090, Accuracy: 0.3667\n","Epoch 63, Train Loss: 0.8752, Val Loss: 1.6353, F1 Micro: 0.5667, F1 Macro: 0.5470, Accuracy: 0.5667\n","Epoch 64, Train Loss: 0.9036, Val Loss: 1.9724, F1 Micro: 0.5167, F1 Macro: 0.4516, Accuracy: 0.5167\n","Epoch 65, Train Loss: 0.9166, Val Loss: 1.5070, F1 Micro: 0.5583, F1 Macro: 0.5081, Accuracy: 0.5583\n","Epoch 66, Train Loss: 0.9709, Val Loss: 2.0827, F1 Micro: 0.5250, F1 Macro: 0.5353, Accuracy: 0.5250\n","Epoch 67, Train Loss: 0.9698, Val Loss: 2.2159, F1 Micro: 0.4000, F1 Macro: 0.3585, Accuracy: 0.4000\n","Epoch 68, Train Loss: 0.8786, Val Loss: 2.2061, F1 Micro: 0.5083, F1 Macro: 0.4634, Accuracy: 0.5083\n","Epoch 69, Train Loss: 0.9296, Val Loss: 1.7561, F1 Micro: 0.5250, F1 Macro: 0.5096, Accuracy: 0.5250\n","Epoch 70, Train Loss: 0.8248, Val Loss: 1.6879, F1 Micro: 0.5750, F1 Macro: 0.5592, Accuracy: 0.5750\n","Epoch 71, Train Loss: 0.9720, Val Loss: 2.0782, F1 Micro: 0.5250, F1 Macro: 0.5003, Accuracy: 0.5250\n","Epoch 72, Train Loss: 0.8802, Val Loss: 1.7605, F1 Micro: 0.4833, F1 Macro: 0.4619, Accuracy: 0.4833\n","Epoch 73, Train Loss: 0.8755, Val Loss: 2.1855, F1 Micro: 0.4917, F1 Macro: 0.4321, Accuracy: 0.4917\n","Epoch 74, Train Loss: 0.8401, Val Loss: 1.9503, F1 Micro: 0.4917, F1 Macro: 0.5017, Accuracy: 0.4917\n","Epoch 75, Train Loss: 0.9556, Val Loss: 2.3860, F1 Micro: 0.5083, F1 Macro: 0.4909, Accuracy: 0.5083\n","Epoch 76, Train Loss: 0.8871, Val Loss: 1.5837, F1 Micro: 0.6250, F1 Macro: 0.6070, Accuracy: 0.6250\n","Epoch 77, Train Loss: 0.9180, Val Loss: 2.6138, F1 Micro: 0.4083, F1 Macro: 0.3614, Accuracy: 0.4083\n","Epoch 78, Train Loss: 0.8079, Val Loss: 2.0606, F1 Micro: 0.5083, F1 Macro: 0.4433, Accuracy: 0.5083\n","Epoch 79, Train Loss: 0.8959, Val Loss: 1.7520, F1 Micro: 0.5167, F1 Macro: 0.4977, Accuracy: 0.5167\n","Epoch 80, Train Loss: 0.8045, Val Loss: 1.8124, F1 Micro: 0.5417, F1 Macro: 0.5279, Accuracy: 0.5417\n","Epoch 81, Train Loss: 0.8161, Val Loss: 2.1188, F1 Micro: 0.4167, F1 Macro: 0.3562, Accuracy: 0.4167\n","Epoch 82, Train Loss: 0.8424, Val Loss: 1.9244, F1 Micro: 0.4583, F1 Macro: 0.4276, Accuracy: 0.4583\n","Epoch 83, Train Loss: 0.8041, Val Loss: 2.3234, F1 Micro: 0.4667, F1 Macro: 0.4432, Accuracy: 0.4667\n","Epoch 84, Train Loss: 0.8174, Val Loss: 1.9333, F1 Micro: 0.4583, F1 Macro: 0.4205, Accuracy: 0.4583\n","Epoch 85, Train Loss: 0.8203, Val Loss: 2.3945, F1 Micro: 0.4250, F1 Macro: 0.4194, Accuracy: 0.4250\n","Epoch 86, Train Loss: 0.9474, Val Loss: 2.2097, F1 Micro: 0.4833, F1 Macro: 0.4443, Accuracy: 0.4833\n","Epoch 87, Train Loss: 0.8056, Val Loss: 2.6997, F1 Micro: 0.5750, F1 Macro: 0.5713, Accuracy: 0.5750\n","Epoch 88, Train Loss: 0.8171, Val Loss: 3.2315, F1 Micro: 0.3667, F1 Macro: 0.3099, Accuracy: 0.3667\n","Epoch 89, Train Loss: 0.8780, Val Loss: 2.3465, F1 Micro: 0.4917, F1 Macro: 0.4930, Accuracy: 0.4917\n","Epoch 90, Train Loss: 0.7967, Val Loss: 1.8028, F1 Micro: 0.6167, F1 Macro: 0.6039, Accuracy: 0.6167\n","Epoch 91, Train Loss: 0.7666, Val Loss: 1.7869, F1 Micro: 0.5750, F1 Macro: 0.5459, Accuracy: 0.5750\n","Epoch 92, Train Loss: 0.7222, Val Loss: 3.0128, F1 Micro: 0.3167, F1 Macro: 0.2644, Accuracy: 0.3167\n","Epoch 93, Train Loss: 0.7908, Val Loss: 2.3277, F1 Micro: 0.4917, F1 Macro: 0.5089, Accuracy: 0.4917\n","Epoch 94, Train Loss: 0.7839, Val Loss: 2.7976, F1 Micro: 0.4500, F1 Macro: 0.4019, Accuracy: 0.4500\n","Epoch 95, Train Loss: 0.8535, Val Loss: 4.1617, F1 Micro: 0.2667, F1 Macro: 0.2168, Accuracy: 0.2667\n","Epoch 96, Train Loss: 0.7990, Val Loss: 1.6129, F1 Micro: 0.5750, F1 Macro: 0.5552, Accuracy: 0.5750\n","Epoch 97, Train Loss: 0.9250, Val Loss: 1.9689, F1 Micro: 0.5583, F1 Macro: 0.5369, Accuracy: 0.5583\n","Epoch 98, Train Loss: 0.8088, Val Loss: 2.0809, F1 Micro: 0.5583, F1 Macro: 0.5337, Accuracy: 0.5583\n","Epoch 99, Train Loss: 0.7457, Val Loss: 1.6757, F1 Micro: 0.6333, F1 Macro: 0.6226, Accuracy: 0.6333\n","Epoch 100, Train Loss: 0.7733, Val Loss: 1.9726, F1 Micro: 0.5000, F1 Macro: 0.4737, Accuracy: 0.5000\n","Epoch 101, Train Loss: 0.8088, Val Loss: 2.0947, F1 Micro: 0.5583, F1 Macro: 0.5413, Accuracy: 0.5583\n","Epoch 102, Train Loss: 0.7534, Val Loss: 2.9415, F1 Micro: 0.3917, F1 Macro: 0.3301, Accuracy: 0.3917\n","Epoch 103, Train Loss: 0.6839, Val Loss: 1.6596, F1 Micro: 0.6167, F1 Macro: 0.6026, Accuracy: 0.6167\n","Epoch 104, Train Loss: 0.7262, Val Loss: 2.7210, F1 Micro: 0.4000, F1 Macro: 0.3613, Accuracy: 0.4000\n","Epoch 105, Train Loss: 0.6784, Val Loss: 1.7965, F1 Micro: 0.5500, F1 Macro: 0.5569, Accuracy: 0.5500\n","Epoch 106, Train Loss: 0.7801, Val Loss: 2.9457, F1 Micro: 0.4083, F1 Macro: 0.3775, Accuracy: 0.4083\n","Epoch 107, Train Loss: 0.7353, Val Loss: 1.8741, F1 Micro: 0.5333, F1 Macro: 0.5080, Accuracy: 0.5333\n","Epoch 108, Train Loss: 0.7013, Val Loss: 2.1353, F1 Micro: 0.4833, F1 Macro: 0.4709, Accuracy: 0.4833\n","Epoch 109, Train Loss: 0.7092, Val Loss: 2.3864, F1 Micro: 0.6083, F1 Macro: 0.6143, Accuracy: 0.6083\n","Epoch 110, Train Loss: 0.7104, Val Loss: 2.0366, F1 Micro: 0.6917, F1 Macro: 0.6811, Accuracy: 0.6917\n","Epoch 111, Train Loss: 0.7334, Val Loss: 1.8675, F1 Micro: 0.5917, F1 Macro: 0.5749, Accuracy: 0.5917\n","Epoch 112, Train Loss: 0.7696, Val Loss: 2.5371, F1 Micro: 0.4833, F1 Macro: 0.4470, Accuracy: 0.4833\n","Epoch 113, Train Loss: 0.7597, Val Loss: 1.9359, F1 Micro: 0.6167, F1 Macro: 0.5790, Accuracy: 0.6167\n","Epoch 114, Train Loss: 0.6926, Val Loss: 2.6263, F1 Micro: 0.4333, F1 Macro: 0.3959, Accuracy: 0.4333\n","Epoch 115, Train Loss: 0.8213, Val Loss: 2.0387, F1 Micro: 0.5250, F1 Macro: 0.5042, Accuracy: 0.5250\n","Epoch 116, Train Loss: 0.7627, Val Loss: 1.6560, F1 Micro: 0.6167, F1 Macro: 0.5974, Accuracy: 0.6167\n","Epoch 117, Train Loss: 0.6329, Val Loss: 2.0142, F1 Micro: 0.5583, F1 Macro: 0.5588, Accuracy: 0.5583\n","Epoch 118, Train Loss: 0.6878, Val Loss: 2.2622, F1 Micro: 0.5667, F1 Macro: 0.5089, Accuracy: 0.5667\n","Epoch 119, Train Loss: 0.6221, Val Loss: 2.2031, F1 Micro: 0.5167, F1 Macro: 0.5272, Accuracy: 0.5167\n","Epoch 120, Train Loss: 0.6987, Val Loss: 2.2852, F1 Micro: 0.5250, F1 Macro: 0.4981, Accuracy: 0.5250\n","Epoch 121, Train Loss: 0.6348, Val Loss: 2.0101, F1 Micro: 0.5417, F1 Macro: 0.5323, Accuracy: 0.5417\n","Epoch 122, Train Loss: 0.6622, Val Loss: 1.9632, F1 Micro: 0.5250, F1 Macro: 0.4957, Accuracy: 0.5250\n","Epoch 123, Train Loss: 0.6458, Val Loss: 1.9824, F1 Micro: 0.5500, F1 Macro: 0.5348, Accuracy: 0.5500\n","Epoch 124, Train Loss: 0.7272, Val Loss: 2.4331, F1 Micro: 0.4417, F1 Macro: 0.4440, Accuracy: 0.4417\n","Epoch 125, Train Loss: 0.6588, Val Loss: 2.4101, F1 Micro: 0.5000, F1 Macro: 0.5001, Accuracy: 0.5000\n","Epoch 126, Train Loss: 0.7035, Val Loss: 1.8634, F1 Micro: 0.6333, F1 Macro: 0.6234, Accuracy: 0.6333\n","Epoch 127, Train Loss: 0.6414, Val Loss: 3.2611, F1 Micro: 0.4167, F1 Macro: 0.3486, Accuracy: 0.4167\n","Epoch 128, Train Loss: 0.8488, Val Loss: 4.7558, F1 Micro: 0.2583, F1 Macro: 0.1887, Accuracy: 0.2583\n","Epoch 129, Train Loss: 0.7157, Val Loss: 1.7379, F1 Micro: 0.6250, F1 Macro: 0.6152, Accuracy: 0.6250\n","Epoch 130, Train Loss: 0.7200, Val Loss: 2.1410, F1 Micro: 0.5417, F1 Macro: 0.5303, Accuracy: 0.5417\n","Epoch 131, Train Loss: 0.6159, Val Loss: 2.8320, F1 Micro: 0.4500, F1 Macro: 0.4522, Accuracy: 0.4500\n","Epoch 132, Train Loss: 0.6435, Val Loss: 1.7993, F1 Micro: 0.6083, F1 Macro: 0.6024, Accuracy: 0.6083\n","Epoch 133, Train Loss: 0.5720, Val Loss: 2.4024, F1 Micro: 0.4750, F1 Macro: 0.4810, Accuracy: 0.4750\n","Epoch 134, Train Loss: 0.6752, Val Loss: 1.6749, F1 Micro: 0.6500, F1 Macro: 0.6483, Accuracy: 0.6500\n","Epoch 135, Train Loss: 0.6677, Val Loss: 2.0482, F1 Micro: 0.5500, F1 Macro: 0.5466, Accuracy: 0.5500\n","Epoch 136, Train Loss: 0.5924, Val Loss: 1.7908, F1 Micro: 0.5417, F1 Macro: 0.5348, Accuracy: 0.5417\n","Epoch 137, Train Loss: 0.6605, Val Loss: 1.7867, F1 Micro: 0.5500, F1 Macro: 0.5330, Accuracy: 0.5500\n","Epoch 138, Train Loss: 0.6465, Val Loss: 1.8687, F1 Micro: 0.5667, F1 Macro: 0.5506, Accuracy: 0.5667\n","Epoch 139, Train Loss: 0.5707, Val Loss: 1.5315, F1 Micro: 0.6500, F1 Macro: 0.6499, Accuracy: 0.6500\n","Epoch 140, Train Loss: 0.6641, Val Loss: 1.9921, F1 Micro: 0.5583, F1 Macro: 0.4985, Accuracy: 0.5583\n","Epoch 141, Train Loss: 0.6025, Val Loss: 1.8096, F1 Micro: 0.6167, F1 Macro: 0.5946, Accuracy: 0.6167\n","Epoch 142, Train Loss: 0.5743, Val Loss: 2.5087, F1 Micro: 0.5167, F1 Macro: 0.5105, Accuracy: 0.5167\n","Epoch 143, Train Loss: 0.5974, Val Loss: 2.4926, F1 Micro: 0.5417, F1 Macro: 0.5377, Accuracy: 0.5417\n","Epoch 144, Train Loss: 0.6376, Val Loss: 2.7120, F1 Micro: 0.4750, F1 Macro: 0.4646, Accuracy: 0.4750\n","Epoch 145, Train Loss: 0.5966, Val Loss: 1.9905, F1 Micro: 0.5833, F1 Macro: 0.5707, Accuracy: 0.5833\n","Epoch 146, Train Loss: 0.5454, Val Loss: 1.9834, F1 Micro: 0.6333, F1 Macro: 0.6185, Accuracy: 0.6333\n","Epoch 147, Train Loss: 0.5798, Val Loss: 2.2436, F1 Micro: 0.6500, F1 Macro: 0.6358, Accuracy: 0.6500\n","Epoch 148, Train Loss: 0.5600, Val Loss: 2.8666, F1 Micro: 0.5333, F1 Macro: 0.4684, Accuracy: 0.5333\n","Epoch 149, Train Loss: 0.5864, Val Loss: 3.0356, F1 Micro: 0.4583, F1 Macro: 0.4396, Accuracy: 0.4583\n","Epoch 150, Train Loss: 0.7376, Val Loss: 2.5045, F1 Micro: 0.5167, F1 Macro: 0.4871, Accuracy: 0.5167\n","Epoch 151, Train Loss: 0.6245, Val Loss: 2.1063, F1 Micro: 0.6250, F1 Macro: 0.6208, Accuracy: 0.6250\n","Epoch 152, Train Loss: 0.6033, Val Loss: 2.7227, F1 Micro: 0.5000, F1 Macro: 0.4680, Accuracy: 0.5000\n","Epoch 153, Train Loss: 0.6544, Val Loss: 1.8903, F1 Micro: 0.5667, F1 Macro: 0.5225, Accuracy: 0.5667\n","Epoch 154, Train Loss: 0.6455, Val Loss: 1.8309, F1 Micro: 0.6583, F1 Macro: 0.6504, Accuracy: 0.6583\n","Epoch 155, Train Loss: 0.5837, Val Loss: 2.4343, F1 Micro: 0.5583, F1 Macro: 0.5373, Accuracy: 0.5583\n","Epoch 156, Train Loss: 0.6322, Val Loss: 2.6573, F1 Micro: 0.5583, F1 Macro: 0.5319, Accuracy: 0.5583\n","Epoch 157, Train Loss: 0.6466, Val Loss: 2.3205, F1 Micro: 0.5500, F1 Macro: 0.5112, Accuracy: 0.5500\n","Epoch 158, Train Loss: 0.6135, Val Loss: 2.0359, F1 Micro: 0.5667, F1 Macro: 0.5419, Accuracy: 0.5667\n","Epoch 159, Train Loss: 0.6146, Val Loss: 2.3933, F1 Micro: 0.6333, F1 Macro: 0.6261, Accuracy: 0.6333\n","Epoch 160, Train Loss: 0.6047, Val Loss: 1.8458, F1 Micro: 0.6250, F1 Macro: 0.6093, Accuracy: 0.6250\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6250, F1 Macro: 0.6093, Accuracy: 0.6250\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.0838, Val Loss: 1.9412, F1 Micro: 0.2083, F1 Macro: 0.1245, Accuracy: 0.2083\n","Epoch 2, Train Loss: 1.9005, Val Loss: 1.7530, F1 Micro: 0.2292, F1 Macro: 0.2207, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.7385, Val Loss: 2.1092, F1 Micro: 0.1979, F1 Macro: 0.1263, Accuracy: 0.1979\n","Epoch 4, Train Loss: 1.7690, Val Loss: 2.0254, F1 Micro: 0.2396, F1 Macro: 0.2005, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.6438, Val Loss: 2.2296, F1 Micro: 0.2292, F1 Macro: 0.1659, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.6384, Val Loss: 1.9629, F1 Micro: 0.3021, F1 Macro: 0.2344, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.6284, Val Loss: 1.8631, F1 Micro: 0.3542, F1 Macro: 0.3614, Accuracy: 0.3542\n","Epoch 8, Train Loss: 1.6178, Val Loss: 1.9155, F1 Micro: 0.3229, F1 Macro: 0.2509, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.6361, Val Loss: 1.8910, F1 Micro: 0.2812, F1 Macro: 0.2767, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.5330, Val Loss: 1.9652, F1 Micro: 0.2917, F1 Macro: 0.2571, Accuracy: 0.2917\n","Epoch 11, Train Loss: 1.5362, Val Loss: 1.6607, F1 Micro: 0.3125, F1 Macro: 0.2785, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.4927, Val Loss: 1.9919, F1 Micro: 0.3542, F1 Macro: 0.3347, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.4783, Val Loss: 2.1499, F1 Micro: 0.3333, F1 Macro: 0.3276, Accuracy: 0.3333\n","Epoch 14, Train Loss: 1.4805, Val Loss: 1.7704, F1 Micro: 0.3021, F1 Macro: 0.2722, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.4690, Val Loss: 2.1312, F1 Micro: 0.3125, F1 Macro: 0.2886, Accuracy: 0.3125\n","Epoch 16, Train Loss: 1.4584, Val Loss: 2.0273, F1 Micro: 0.3021, F1 Macro: 0.2355, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.4501, Val Loss: 2.4070, F1 Micro: 0.3542, F1 Macro: 0.2490, Accuracy: 0.3542\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.2530, Val Loss: 1.9470, F1 Micro: 0.2604, F1 Macro: 0.2067, Accuracy: 0.2604\n","Epoch 2, Train Loss: 1.9134, Val Loss: 2.1910, F1 Micro: 0.1562, F1 Macro: 0.1290, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.8103, Val Loss: 2.6145, F1 Micro: 0.1562, F1 Macro: 0.0904, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7274, Val Loss: 1.7678, F1 Micro: 0.2292, F1 Macro: 0.1792, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.6747, Val Loss: 1.7412, F1 Micro: 0.3333, F1 Macro: 0.2808, Accuracy: 0.3333\n","Epoch 6, Train Loss: 1.6826, Val Loss: 1.8262, F1 Micro: 0.3125, F1 Macro: 0.2675, Accuracy: 0.3125\n","Epoch 7, Train Loss: 1.6772, Val Loss: 1.7929, F1 Micro: 0.3229, F1 Macro: 0.2607, Accuracy: 0.3229\n","Epoch 8, Train Loss: 1.6251, Val Loss: 1.7207, F1 Micro: 0.3229, F1 Macro: 0.2789, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.6046, Val Loss: 1.8231, F1 Micro: 0.2604, F1 Macro: 0.2046, Accuracy: 0.2604\n","Epoch 10, Train Loss: 1.6383, Val Loss: 2.3290, F1 Micro: 0.2812, F1 Macro: 0.2300, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.6686, Val Loss: 1.7445, F1 Micro: 0.2812, F1 Macro: 0.2580, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.5969, Val Loss: 1.6788, F1 Micro: 0.3854, F1 Macro: 0.3433, Accuracy: 0.3854\n","Epoch 13, Train Loss: 1.5670, Val Loss: 1.6804, F1 Micro: 0.3646, F1 Macro: 0.3442, Accuracy: 0.3646\n","Epoch 14, Train Loss: 1.6041, Val Loss: 1.9372, F1 Micro: 0.2604, F1 Macro: 0.2201, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.6319, Val Loss: 1.9470, F1 Micro: 0.3021, F1 Macro: 0.2101, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.5218, Val Loss: 1.4555, F1 Micro: 0.3854, F1 Macro: 0.3850, Accuracy: 0.3854\n","Epoch 17, Train Loss: 1.5271, Val Loss: 1.8361, F1 Micro: 0.3021, F1 Macro: 0.2139, Accuracy: 0.3021\n","Epoch 18, Train Loss: 1.4679, Val Loss: 1.5950, F1 Micro: 0.4167, F1 Macro: 0.3959, Accuracy: 0.4167\n","Epoch 19, Train Loss: 1.5393, Val Loss: 2.2714, F1 Micro: 0.2604, F1 Macro: 0.2156, Accuracy: 0.2604\n","Epoch 20, Train Loss: 1.4769, Val Loss: 1.7270, F1 Micro: 0.3229, F1 Macro: 0.2551, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.4445, Val Loss: 2.1262, F1 Micro: 0.3438, F1 Macro: 0.3446, Accuracy: 0.3438\n","Epoch 22, Train Loss: 1.5302, Val Loss: 1.9357, F1 Micro: 0.3021, F1 Macro: 0.2775, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.3729, Val Loss: 1.6836, F1 Micro: 0.3854, F1 Macro: 0.3873, Accuracy: 0.3854\n","Epoch 24, Train Loss: 1.4475, Val Loss: 2.1250, F1 Micro: 0.2917, F1 Macro: 0.2678, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.4228, Val Loss: 1.7802, F1 Micro: 0.3958, F1 Macro: 0.3468, Accuracy: 0.3958\n","Epoch 26, Train Loss: 1.3112, Val Loss: 1.8528, F1 Micro: 0.3854, F1 Macro: 0.3410, Accuracy: 0.3854\n","Epoch 27, Train Loss: 1.4559, Val Loss: 1.8945, F1 Micro: 0.2917, F1 Macro: 0.2775, Accuracy: 0.2917\n","Epoch 28, Train Loss: 1.4015, Val Loss: 1.6905, F1 Micro: 0.4583, F1 Macro: 0.4254, Accuracy: 0.4583\n","Epoch 29, Train Loss: 1.4275, Val Loss: 1.8884, F1 Micro: 0.4479, F1 Macro: 0.4168, Accuracy: 0.4479\n","Epoch 30, Train Loss: 1.3596, Val Loss: 1.5671, F1 Micro: 0.4062, F1 Macro: 0.3795, Accuracy: 0.4062\n","Epoch 31, Train Loss: 1.3828, Val Loss: 1.8000, F1 Micro: 0.2708, F1 Macro: 0.2694, Accuracy: 0.2708\n","Epoch 32, Train Loss: 1.2892, Val Loss: 2.2881, F1 Micro: 0.3125, F1 Macro: 0.2212, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.3675, Val Loss: 1.9467, F1 Micro: 0.3438, F1 Macro: 0.2652, Accuracy: 0.3438\n","Epoch 34, Train Loss: 1.2427, Val Loss: 1.6896, F1 Micro: 0.4167, F1 Macro: 0.3700, Accuracy: 0.4167\n","Epoch 35, Train Loss: 1.3124, Val Loss: 1.5710, F1 Micro: 0.5104, F1 Macro: 0.4877, Accuracy: 0.5104\n","Epoch 36, Train Loss: 1.2752, Val Loss: 2.2198, F1 Micro: 0.3958, F1 Macro: 0.3388, Accuracy: 0.3958\n","Epoch 37, Train Loss: 1.3714, Val Loss: 1.8187, F1 Micro: 0.4062, F1 Macro: 0.3710, Accuracy: 0.4062\n","Epoch 38, Train Loss: 1.2832, Val Loss: 1.8212, F1 Micro: 0.3750, F1 Macro: 0.3820, Accuracy: 0.3750\n","Epoch 39, Train Loss: 1.1541, Val Loss: 1.7082, F1 Micro: 0.4688, F1 Macro: 0.4192, Accuracy: 0.4688\n","Epoch 40, Train Loss: 1.1196, Val Loss: 1.5590, F1 Micro: 0.4479, F1 Macro: 0.4348, Accuracy: 0.4479\n","Epoch 41, Train Loss: 1.1728, Val Loss: 1.6497, F1 Micro: 0.4271, F1 Macro: 0.4231, Accuracy: 0.4271\n","Epoch 42, Train Loss: 1.1969, Val Loss: 1.6239, F1 Micro: 0.3750, F1 Macro: 0.3272, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.1238, Val Loss: 1.8835, F1 Micro: 0.4167, F1 Macro: 0.4064, Accuracy: 0.4167\n","Epoch 44, Train Loss: 1.1015, Val Loss: 4.3370, F1 Micro: 0.2188, F1 Macro: 0.1962, Accuracy: 0.2188\n","Epoch 45, Train Loss: 1.2014, Val Loss: 1.9607, F1 Micro: 0.4375, F1 Macro: 0.4137, Accuracy: 0.4375\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.2268, Val Loss: 1.8399, F1 Micro: 0.2188, F1 Macro: 0.1439, Accuracy: 0.2188\n","Epoch 2, Train Loss: 1.7837, Val Loss: 2.0442, F1 Micro: 0.2292, F1 Macro: 0.1021, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.9029, Val Loss: 2.8993, F1 Micro: 0.1146, F1 Macro: 0.0722, Accuracy: 0.1146\n","Epoch 4, Train Loss: 1.7132, Val Loss: 1.9424, F1 Micro: 0.2917, F1 Macro: 0.2131, Accuracy: 0.2917\n","Epoch 5, Train Loss: 1.7103, Val Loss: 2.0296, F1 Micro: 0.2083, F1 Macro: 0.1303, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.6445, Val Loss: 1.6877, F1 Micro: 0.3646, F1 Macro: 0.2561, Accuracy: 0.3646\n","Epoch 7, Train Loss: 1.5987, Val Loss: 1.7833, F1 Micro: 0.3229, F1 Macro: 0.2827, Accuracy: 0.3229\n","Epoch 8, Train Loss: 1.6366, Val Loss: 2.0154, F1 Micro: 0.3021, F1 Macro: 0.1918, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.6151, Val Loss: 1.9262, F1 Micro: 0.2812, F1 Macro: 0.2099, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.5785, Val Loss: 1.8387, F1 Micro: 0.3229, F1 Macro: 0.3249, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.5287, Val Loss: 2.2141, F1 Micro: 0.2500, F1 Macro: 0.1728, Accuracy: 0.2500\n","Epoch 12, Train Loss: 1.5563, Val Loss: 2.0587, F1 Micro: 0.2188, F1 Macro: 0.2159, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.5645, Val Loss: 2.2128, F1 Micro: 0.3125, F1 Macro: 0.1766, Accuracy: 0.3125\n","Epoch 14, Train Loss: 1.6485, Val Loss: 1.7377, F1 Micro: 0.3750, F1 Macro: 0.3314, Accuracy: 0.3750\n","Epoch 15, Train Loss: 1.5314, Val Loss: 1.9696, F1 Micro: 0.3542, F1 Macro: 0.3501, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5620, Val Loss: 2.2266, F1 Micro: 0.2917, F1 Macro: 0.2495, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.5002, Val Loss: 1.7949, F1 Micro: 0.3125, F1 Macro: 0.2563, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.4839, Val Loss: 1.7733, F1 Micro: 0.3125, F1 Macro: 0.2523, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.4943, Val Loss: 1.8456, F1 Micro: 0.4062, F1 Macro: 0.2789, Accuracy: 0.4062\n","Epoch 20, Train Loss: 1.5163, Val Loss: 1.7950, F1 Micro: 0.3229, F1 Macro: 0.2176, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.5135, Val Loss: 1.7490, F1 Micro: 0.4271, F1 Macro: 0.3963, Accuracy: 0.4271\n","Epoch 22, Train Loss: 1.4741, Val Loss: 1.8319, F1 Micro: 0.4375, F1 Macro: 0.3365, Accuracy: 0.4375\n","Epoch 23, Train Loss: 1.4379, Val Loss: 1.8581, F1 Micro: 0.3021, F1 Macro: 0.3165, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.3926, Val Loss: 1.8221, F1 Micro: 0.3333, F1 Macro: 0.2328, Accuracy: 0.3333\n","Epoch 25, Train Loss: 1.3910, Val Loss: 1.6621, F1 Micro: 0.4792, F1 Macro: 0.4422, Accuracy: 0.4792\n","Epoch 26, Train Loss: 1.4360, Val Loss: 2.0877, F1 Micro: 0.3958, F1 Macro: 0.2684, Accuracy: 0.3958\n","Epoch 27, Train Loss: 1.4233, Val Loss: 1.6918, F1 Micro: 0.4271, F1 Macro: 0.3812, Accuracy: 0.4271\n","Epoch 28, Train Loss: 1.4178, Val Loss: 1.7069, F1 Micro: 0.4271, F1 Macro: 0.3856, Accuracy: 0.4271\n","Epoch 29, Train Loss: 1.4203, Val Loss: 1.7897, F1 Micro: 0.3750, F1 Macro: 0.2901, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.3852, Val Loss: 1.8903, F1 Micro: 0.3958, F1 Macro: 0.3798, Accuracy: 0.3958\n","Epoch 31, Train Loss: 1.3460, Val Loss: 1.5940, F1 Micro: 0.5208, F1 Macro: 0.4922, Accuracy: 0.5208\n","Epoch 32, Train Loss: 1.3994, Val Loss: 1.7166, F1 Micro: 0.4688, F1 Macro: 0.4488, Accuracy: 0.4688\n","Epoch 33, Train Loss: 1.3026, Val Loss: 1.5691, F1 Micro: 0.4896, F1 Macro: 0.4521, Accuracy: 0.4896\n","Epoch 34, Train Loss: 1.2678, Val Loss: 1.8407, F1 Micro: 0.3958, F1 Macro: 0.3004, Accuracy: 0.3958\n","Epoch 35, Train Loss: 1.3217, Val Loss: 1.7543, F1 Micro: 0.3646, F1 Macro: 0.2771, Accuracy: 0.3646\n","Epoch 36, Train Loss: 1.2219, Val Loss: 2.5508, F1 Micro: 0.2708, F1 Macro: 0.2291, Accuracy: 0.2708\n","Epoch 37, Train Loss: 1.3222, Val Loss: 1.9137, F1 Micro: 0.3125, F1 Macro: 0.2504, Accuracy: 0.3125\n","Epoch 38, Train Loss: 1.2706, Val Loss: 1.7625, F1 Micro: 0.4167, F1 Macro: 0.3778, Accuracy: 0.4167\n","Epoch 39, Train Loss: 1.2704, Val Loss: 1.6023, F1 Micro: 0.4792, F1 Macro: 0.4550, Accuracy: 0.4792\n","Epoch 40, Train Loss: 1.2925, Val Loss: 2.0711, F1 Micro: 0.4479, F1 Macro: 0.3820, Accuracy: 0.4479\n","Epoch 41, Train Loss: 1.2785, Val Loss: 1.9030, F1 Micro: 0.4167, F1 Macro: 0.3995, Accuracy: 0.4167\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.1870, Val Loss: 2.3491, F1 Micro: 0.2917, F1 Macro: 0.1826, Accuracy: 0.2917\n","Epoch 2, Train Loss: 1.8786, Val Loss: 2.1797, F1 Micro: 0.2500, F1 Macro: 0.2210, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.8932, Val Loss: 2.0272, F1 Micro: 0.2188, F1 Macro: 0.1635, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.7240, Val Loss: 1.8557, F1 Micro: 0.2812, F1 Macro: 0.2294, Accuracy: 0.2812\n","Epoch 5, Train Loss: 1.7024, Val Loss: 2.0463, F1 Micro: 0.2188, F1 Macro: 0.1529, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.6591, Val Loss: 1.6888, F1 Micro: 0.3229, F1 Macro: 0.2794, Accuracy: 0.3229\n","Epoch 7, Train Loss: 1.6272, Val Loss: 1.7612, F1 Micro: 0.2396, F1 Macro: 0.1956, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6198, Val Loss: 1.8788, F1 Micro: 0.2917, F1 Macro: 0.2026, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.6160, Val Loss: 1.9088, F1 Micro: 0.2708, F1 Macro: 0.1936, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.6018, Val Loss: 2.5626, F1 Micro: 0.2083, F1 Macro: 0.1458, Accuracy: 0.2083\n","Epoch 11, Train Loss: 1.6030, Val Loss: 2.2349, F1 Micro: 0.1771, F1 Macro: 0.0853, Accuracy: 0.1771\n","Epoch 12, Train Loss: 1.5440, Val Loss: 1.7536, F1 Micro: 0.3542, F1 Macro: 0.3263, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.5903, Val Loss: 1.6896, F1 Micro: 0.3542, F1 Macro: 0.3006, Accuracy: 0.3542\n","Epoch 14, Train Loss: 1.5289, Val Loss: 1.7670, F1 Micro: 0.3750, F1 Macro: 0.3378, Accuracy: 0.3750\n","Epoch 15, Train Loss: 1.5538, Val Loss: 2.0820, F1 Micro: 0.2396, F1 Macro: 0.1637, Accuracy: 0.2396\n","Epoch 16, Train Loss: 1.5442, Val Loss: 2.0040, F1 Micro: 0.3229, F1 Macro: 0.2361, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.5326, Val Loss: 2.4968, F1 Micro: 0.1979, F1 Macro: 0.1149, Accuracy: 0.1979\n","Epoch 18, Train Loss: 1.5173, Val Loss: 1.6446, F1 Micro: 0.4062, F1 Macro: 0.3664, Accuracy: 0.4062\n","Epoch 19, Train Loss: 1.4784, Val Loss: 2.0103, F1 Micro: 0.2396, F1 Macro: 0.1567, Accuracy: 0.2396\n","Epoch 20, Train Loss: 1.5808, Val Loss: 1.6465, F1 Micro: 0.3854, F1 Macro: 0.3605, Accuracy: 0.3854\n","Epoch 21, Train Loss: 1.4797, Val Loss: 1.8190, F1 Micro: 0.3229, F1 Macro: 0.2635, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.4385, Val Loss: 2.0783, F1 Micro: 0.3542, F1 Macro: 0.2916, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.4823, Val Loss: 1.5901, F1 Micro: 0.4479, F1 Macro: 0.4253, Accuracy: 0.4479\n","Epoch 24, Train Loss: 1.4035, Val Loss: 1.5900, F1 Micro: 0.3542, F1 Macro: 0.3616, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.3668, Val Loss: 1.7431, F1 Micro: 0.3333, F1 Macro: 0.3167, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.4062, Val Loss: 1.5625, F1 Micro: 0.4479, F1 Macro: 0.4262, Accuracy: 0.4479\n","Epoch 27, Train Loss: 1.4408, Val Loss: 1.7190, F1 Micro: 0.3333, F1 Macro: 0.2876, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.4227, Val Loss: 1.6608, F1 Micro: 0.4271, F1 Macro: 0.3931, Accuracy: 0.4271\n","Epoch 29, Train Loss: 1.3761, Val Loss: 1.6499, F1 Micro: 0.4167, F1 Macro: 0.3815, Accuracy: 0.4167\n","Epoch 30, Train Loss: 1.3198, Val Loss: 1.6828, F1 Micro: 0.4062, F1 Macro: 0.3959, Accuracy: 0.4062\n","Epoch 31, Train Loss: 1.3497, Val Loss: 1.6455, F1 Micro: 0.3646, F1 Macro: 0.3257, Accuracy: 0.3646\n","Epoch 32, Train Loss: 1.3742, Val Loss: 1.8503, F1 Micro: 0.3542, F1 Macro: 0.2761, Accuracy: 0.3542\n","Epoch 33, Train Loss: 1.3753, Val Loss: 1.6873, F1 Micro: 0.3646, F1 Macro: 0.3213, Accuracy: 0.3646\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.1744, Val Loss: 2.0724, F1 Micro: 0.1667, F1 Macro: 0.0891, Accuracy: 0.1667\n","Epoch 2, Train Loss: 1.8790, Val Loss: 1.9020, F1 Micro: 0.2500, F1 Macro: 0.2410, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.7074, Val Loss: 1.7465, F1 Micro: 0.3021, F1 Macro: 0.2720, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.6705, Val Loss: 1.8234, F1 Micro: 0.3021, F1 Macro: 0.2354, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.7166, Val Loss: 2.0637, F1 Micro: 0.3021, F1 Macro: 0.1954, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.6909, Val Loss: 1.8454, F1 Micro: 0.3854, F1 Macro: 0.3850, Accuracy: 0.3854\n","Epoch 7, Train Loss: 1.5821, Val Loss: 1.6922, F1 Micro: 0.3958, F1 Macro: 0.3496, Accuracy: 0.3958\n","Epoch 8, Train Loss: 1.6299, Val Loss: 1.6361, F1 Micro: 0.3438, F1 Macro: 0.2975, Accuracy: 0.3438\n","Epoch 9, Train Loss: 1.5324, Val Loss: 1.6862, F1 Micro: 0.3542, F1 Macro: 0.3139, Accuracy: 0.3542\n","Epoch 10, Train Loss: 1.5772, Val Loss: 1.9498, F1 Micro: 0.3125, F1 Macro: 0.2772, Accuracy: 0.3125\n","Epoch 11, Train Loss: 1.5715, Val Loss: 1.7532, F1 Micro: 0.3333, F1 Macro: 0.2732, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.4754, Val Loss: 1.8480, F1 Micro: 0.3750, F1 Macro: 0.3371, Accuracy: 0.3750\n","Epoch 13, Train Loss: 1.5154, Val Loss: 1.8733, F1 Micro: 0.3750, F1 Macro: 0.3340, Accuracy: 0.3750\n","Epoch 14, Train Loss: 1.5651, Val Loss: 1.8449, F1 Micro: 0.3542, F1 Macro: 0.2758, Accuracy: 0.3542\n","Epoch 15, Train Loss: 1.4907, Val Loss: 1.7923, F1 Micro: 0.3854, F1 Macro: 0.3347, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.4879, Val Loss: 1.6521, F1 Micro: 0.3958, F1 Macro: 0.4005, Accuracy: 0.3958\n","Epoch 17, Train Loss: 1.4998, Val Loss: 1.7532, F1 Micro: 0.3646, F1 Macro: 0.3571, Accuracy: 0.3646\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.4458333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.2913, Val Loss: 2.4734, F1 Micro: 0.1667, F1 Macro: 0.0693, Accuracy: 0.1667\n","Epoch 2, Train Loss: 1.8512, Val Loss: 1.9608, F1 Micro: 0.2500, F1 Macro: 0.2307, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.7131, Val Loss: 1.6695, F1 Micro: 0.2917, F1 Macro: 0.2591, Accuracy: 0.2917\n","Epoch 4, Train Loss: 1.7353, Val Loss: 1.8914, F1 Micro: 0.2812, F1 Macro: 0.2553, Accuracy: 0.2812\n","Epoch 5, Train Loss: 1.6518, Val Loss: 1.7840, F1 Micro: 0.2917, F1 Macro: 0.2603, Accuracy: 0.2917\n","Epoch 6, Train Loss: 1.6157, Val Loss: 1.8153, F1 Micro: 0.3021, F1 Macro: 0.2776, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.5921, Val Loss: 1.8907, F1 Micro: 0.3021, F1 Macro: 0.3146, Accuracy: 0.3021\n","Epoch 8, Train Loss: 1.5986, Val Loss: 1.7900, F1 Micro: 0.2708, F1 Macro: 0.2290, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.5454, Val Loss: 1.9413, F1 Micro: 0.3646, F1 Macro: 0.2951, Accuracy: 0.3646\n","Epoch 10, Train Loss: 1.6133, Val Loss: 1.7853, F1 Micro: 0.3646, F1 Macro: 0.3291, Accuracy: 0.3646\n","Epoch 11, Train Loss: 1.5304, Val Loss: 1.8183, F1 Micro: 0.3542, F1 Macro: 0.3115, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.5293, Val Loss: 2.0375, F1 Micro: 0.3333, F1 Macro: 0.2969, Accuracy: 0.3333\n","Epoch 13, Train Loss: 1.4902, Val Loss: 2.5279, F1 Micro: 0.2812, F1 Macro: 0.1961, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.5138, Val Loss: 1.8168, F1 Micro: 0.3750, F1 Macro: 0.3569, Accuracy: 0.3750\n","Epoch 15, Train Loss: 1.4681, Val Loss: 2.9218, F1 Micro: 0.1875, F1 Macro: 0.1182, Accuracy: 0.1875\n","Epoch 16, Train Loss: 1.4728, Val Loss: 1.9996, F1 Micro: 0.2812, F1 Macro: 0.2298, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.4957, Val Loss: 1.6861, F1 Micro: 0.3229, F1 Macro: 0.3037, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.4005, Val Loss: 1.8197, F1 Micro: 0.2917, F1 Macro: 0.2394, Accuracy: 0.2917\n","Epoch 19, Train Loss: 1.4663, Val Loss: 1.9533, F1 Micro: 0.3438, F1 Macro: 0.3090, Accuracy: 0.3438\n","Epoch 20, Train Loss: 1.3843, Val Loss: 1.9397, F1 Micro: 0.3542, F1 Macro: 0.3259, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.3976, Val Loss: 1.9853, F1 Micro: 0.2812, F1 Macro: 0.2339, Accuracy: 0.2812\n","Epoch 22, Train Loss: 1.3354, Val Loss: 3.0578, F1 Micro: 0.2083, F1 Macro: 0.1659, Accuracy: 0.2083\n","Epoch 23, Train Loss: 1.3399, Val Loss: 1.9832, F1 Micro: 0.4167, F1 Macro: 0.3682, Accuracy: 0.4167\n","Epoch 24, Train Loss: 1.4072, Val Loss: 2.0578, F1 Micro: 0.3646, F1 Macro: 0.3816, Accuracy: 0.3646\n","Epoch 25, Train Loss: 1.3602, Val Loss: 1.9728, F1 Micro: 0.3542, F1 Macro: 0.3208, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.3234, Val Loss: 2.3517, F1 Micro: 0.3125, F1 Macro: 0.2623, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.2637, Val Loss: 1.8292, F1 Micro: 0.4271, F1 Macro: 0.4094, Accuracy: 0.4271\n","Epoch 28, Train Loss: 1.2649, Val Loss: 1.8061, F1 Micro: 0.3854, F1 Macro: 0.3840, Accuracy: 0.3854\n","Epoch 29, Train Loss: 1.2866, Val Loss: 2.0851, F1 Micro: 0.4688, F1 Macro: 0.4464, Accuracy: 0.4688\n","Epoch 30, Train Loss: 1.3533, Val Loss: 2.4793, F1 Micro: 0.2917, F1 Macro: 0.2957, Accuracy: 0.2917\n","Epoch 31, Train Loss: 1.2825, Val Loss: 2.0060, F1 Micro: 0.3646, F1 Macro: 0.3289, Accuracy: 0.3646\n","Epoch 32, Train Loss: 1.1992, Val Loss: 2.2194, F1 Micro: 0.4271, F1 Macro: 0.3669, Accuracy: 0.4271\n","Epoch 33, Train Loss: 1.2672, Val Loss: 1.8337, F1 Micro: 0.4062, F1 Macro: 0.3729, Accuracy: 0.4062\n","Epoch 34, Train Loss: 1.1807, Val Loss: 2.1167, F1 Micro: 0.4479, F1 Macro: 0.4268, Accuracy: 0.4479\n","Epoch 35, Train Loss: 1.2283, Val Loss: 2.2240, F1 Micro: 0.3438, F1 Macro: 0.3052, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.1014, Val Loss: 2.0702, F1 Micro: 0.3646, F1 Macro: 0.3428, Accuracy: 0.3646\n","Epoch 37, Train Loss: 1.1830, Val Loss: 2.9361, F1 Micro: 0.2396, F1 Macro: 0.2209, Accuracy: 0.2396\n","Epoch 38, Train Loss: 1.1916, Val Loss: 2.1205, F1 Micro: 0.3229, F1 Macro: 0.3051, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.1224, Val Loss: 1.8499, F1 Micro: 0.4375, F1 Macro: 0.3940, Accuracy: 0.4375\n","Epoch 40, Train Loss: 1.0921, Val Loss: 3.0344, F1 Micro: 0.3229, F1 Macro: 0.2584, Accuracy: 0.3229\n","Epoch 41, Train Loss: 1.0614, Val Loss: 2.5928, F1 Micro: 0.3750, F1 Macro: 0.3458, Accuracy: 0.3750\n","Epoch 42, Train Loss: 1.1071, Val Loss: 2.3913, F1 Micro: 0.3333, F1 Macro: 0.2836, Accuracy: 0.3333\n","Epoch 43, Train Loss: 1.1621, Val Loss: 2.5315, F1 Micro: 0.3750, F1 Macro: 0.3536, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.1171, Val Loss: 2.4538, F1 Micro: 0.3646, F1 Macro: 0.3301, Accuracy: 0.3646\n","Epoch 45, Train Loss: 1.1313, Val Loss: 2.1968, F1 Micro: 0.3750, F1 Macro: 0.3173, Accuracy: 0.3750\n","Epoch 46, Train Loss: 1.0776, Val Loss: 2.3804, F1 Micro: 0.3854, F1 Macro: 0.3465, Accuracy: 0.3854\n","Epoch 47, Train Loss: 1.0571, Val Loss: 1.6918, F1 Micro: 0.4896, F1 Macro: 0.4671, Accuracy: 0.4896\n","Epoch 48, Train Loss: 1.1610, Val Loss: 4.4731, F1 Micro: 0.2292, F1 Macro: 0.1800, Accuracy: 0.2292\n","Epoch 49, Train Loss: 1.0865, Val Loss: 2.8044, F1 Micro: 0.3021, F1 Macro: 0.2700, Accuracy: 0.3021\n","Epoch 50, Train Loss: 1.0888, Val Loss: 2.9204, F1 Micro: 0.3438, F1 Macro: 0.2785, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.0718, Val Loss: 2.3516, F1 Micro: 0.4375, F1 Macro: 0.3796, Accuracy: 0.4375\n","Epoch 52, Train Loss: 1.0092, Val Loss: 2.3786, F1 Micro: 0.3542, F1 Macro: 0.3329, Accuracy: 0.3542\n","Epoch 53, Train Loss: 1.0134, Val Loss: 2.1776, F1 Micro: 0.4688, F1 Macro: 0.4603, Accuracy: 0.4688\n","Epoch 54, Train Loss: 0.9963, Val Loss: 1.7748, F1 Micro: 0.4792, F1 Macro: 0.4268, Accuracy: 0.4792\n","Epoch 55, Train Loss: 0.9473, Val Loss: 2.0837, F1 Micro: 0.4896, F1 Macro: 0.4444, Accuracy: 0.4896\n","Epoch 56, Train Loss: 1.0733, Val Loss: 2.5605, F1 Micro: 0.3646, F1 Macro: 0.3649, Accuracy: 0.3646\n","Epoch 57, Train Loss: 1.0175, Val Loss: 2.0155, F1 Micro: 0.4896, F1 Macro: 0.4819, Accuracy: 0.4896\n","Epoch 58, Train Loss: 0.9705, Val Loss: 2.2577, F1 Micro: 0.4583, F1 Macro: 0.4511, Accuracy: 0.4583\n","Epoch 59, Train Loss: 1.0294, Val Loss: 2.0341, F1 Micro: 0.3958, F1 Macro: 0.3345, Accuracy: 0.3958\n","Epoch 60, Train Loss: 0.8975, Val Loss: 1.8428, F1 Micro: 0.4479, F1 Macro: 0.4342, Accuracy: 0.4479\n","Epoch 61, Train Loss: 0.9947, Val Loss: 2.4037, F1 Micro: 0.4792, F1 Macro: 0.4680, Accuracy: 0.4792\n","Epoch 62, Train Loss: 0.9389, Val Loss: 2.5222, F1 Micro: 0.3646, F1 Macro: 0.3124, Accuracy: 0.3646\n","Epoch 63, Train Loss: 0.9330, Val Loss: 2.4247, F1 Micro: 0.4688, F1 Macro: 0.4263, Accuracy: 0.4688\n","Epoch 64, Train Loss: 0.9436, Val Loss: 3.0036, F1 Micro: 0.4167, F1 Macro: 0.4164, Accuracy: 0.4167\n","Epoch 65, Train Loss: 0.8973, Val Loss: 2.5618, F1 Micro: 0.3333, F1 Macro: 0.2950, Accuracy: 0.3333\n","Epoch 66, Train Loss: 1.0057, Val Loss: 2.0796, F1 Micro: 0.4792, F1 Macro: 0.4532, Accuracy: 0.4792\n","Epoch 67, Train Loss: 0.9097, Val Loss: 2.2367, F1 Micro: 0.3958, F1 Macro: 0.3398, Accuracy: 0.3958\n","Epoch 68, Train Loss: 0.8996, Val Loss: 2.7340, F1 Micro: 0.4583, F1 Macro: 0.4836, Accuracy: 0.4583\n","Epoch 69, Train Loss: 0.8981, Val Loss: 1.9489, F1 Micro: 0.5000, F1 Macro: 0.4659, Accuracy: 0.5000\n","Epoch 70, Train Loss: 0.9152, Val Loss: 2.1068, F1 Micro: 0.4062, F1 Macro: 0.3376, Accuracy: 0.4062\n","Epoch 71, Train Loss: 0.8744, Val Loss: 1.8790, F1 Micro: 0.5208, F1 Macro: 0.4841, Accuracy: 0.5208\n","Epoch 72, Train Loss: 0.8772, Val Loss: 2.3446, F1 Micro: 0.4688, F1 Macro: 0.4523, Accuracy: 0.4688\n","Epoch 73, Train Loss: 0.9024, Val Loss: 2.5697, F1 Micro: 0.4896, F1 Macro: 0.4723, Accuracy: 0.4896\n","Epoch 74, Train Loss: 0.8137, Val Loss: 2.3665, F1 Micro: 0.4375, F1 Macro: 0.4620, Accuracy: 0.4375\n","Epoch 75, Train Loss: 0.8790, Val Loss: 2.5387, F1 Micro: 0.5312, F1 Macro: 0.5151, Accuracy: 0.5312\n","Epoch 76, Train Loss: 0.7831, Val Loss: 2.1462, F1 Micro: 0.5417, F1 Macro: 0.5147, Accuracy: 0.5417\n","Epoch 77, Train Loss: 0.8354, Val Loss: 2.3457, F1 Micro: 0.5208, F1 Macro: 0.5380, Accuracy: 0.5208\n","Epoch 78, Train Loss: 0.9037, Val Loss: 2.7629, F1 Micro: 0.4479, F1 Macro: 0.4424, Accuracy: 0.4479\n","Epoch 79, Train Loss: 0.8402, Val Loss: 2.4786, F1 Micro: 0.4375, F1 Macro: 0.4168, Accuracy: 0.4375\n","Epoch 80, Train Loss: 0.7747, Val Loss: 2.3024, F1 Micro: 0.5729, F1 Macro: 0.5667, Accuracy: 0.5729\n","Epoch 81, Train Loss: 0.8001, Val Loss: 3.0773, F1 Micro: 0.4792, F1 Macro: 0.4947, Accuracy: 0.4792\n","Epoch 82, Train Loss: 0.7425, Val Loss: 2.8034, F1 Micro: 0.4271, F1 Macro: 0.3951, Accuracy: 0.4271\n","Epoch 83, Train Loss: 0.8060, Val Loss: 3.0421, F1 Micro: 0.4792, F1 Macro: 0.4637, Accuracy: 0.4792\n","Epoch 84, Train Loss: 0.8376, Val Loss: 2.1848, F1 Micro: 0.4375, F1 Macro: 0.3830, Accuracy: 0.4375\n","Epoch 85, Train Loss: 0.8040, Val Loss: 3.1116, F1 Micro: 0.4583, F1 Macro: 0.4598, Accuracy: 0.4583\n","Epoch 86, Train Loss: 0.7899, Val Loss: 2.9053, F1 Micro: 0.4583, F1 Macro: 0.4552, Accuracy: 0.4583\n","Epoch 87, Train Loss: 0.8183, Val Loss: 3.8039, F1 Micro: 0.4271, F1 Macro: 0.3671, Accuracy: 0.4271\n","Epoch 88, Train Loss: 0.8018, Val Loss: 2.9110, F1 Micro: 0.5208, F1 Macro: 0.5315, Accuracy: 0.5208\n","Epoch 89, Train Loss: 0.8561, Val Loss: 2.6365, F1 Micro: 0.4688, F1 Macro: 0.4219, Accuracy: 0.4688\n","Epoch 90, Train Loss: 0.7250, Val Loss: 2.9046, F1 Micro: 0.4792, F1 Macro: 0.4468, Accuracy: 0.4792\n","Epoch 91, Train Loss: 0.8861, Val Loss: 2.6526, F1 Micro: 0.4375, F1 Macro: 0.4480, Accuracy: 0.4375\n","Epoch 92, Train Loss: 0.7391, Val Loss: 2.3231, F1 Micro: 0.3958, F1 Macro: 0.4085, Accuracy: 0.3958\n","Epoch 93, Train Loss: 0.8811, Val Loss: 3.3326, F1 Micro: 0.4688, F1 Macro: 0.4708, Accuracy: 0.4688\n","Epoch 94, Train Loss: 0.7017, Val Loss: 2.5689, F1 Micro: 0.4479, F1 Macro: 0.3950, Accuracy: 0.4479\n","Epoch 95, Train Loss: 0.7977, Val Loss: 2.1043, F1 Micro: 0.4896, F1 Macro: 0.4344, Accuracy: 0.4896\n","Epoch 96, Train Loss: 0.7228, Val Loss: 2.9370, F1 Micro: 0.4479, F1 Macro: 0.4361, Accuracy: 0.4479\n","Epoch 97, Train Loss: 0.7728, Val Loss: 3.4670, F1 Micro: 0.3958, F1 Macro: 0.3734, Accuracy: 0.3958\n","Epoch 98, Train Loss: 0.7098, Val Loss: 3.0938, F1 Micro: 0.4792, F1 Macro: 0.4781, Accuracy: 0.4792\n","Epoch 99, Train Loss: 0.7468, Val Loss: 2.5307, F1 Micro: 0.5417, F1 Macro: 0.4894, Accuracy: 0.5417\n","Epoch 100, Train Loss: 0.6805, Val Loss: 3.0841, F1 Micro: 0.5104, F1 Macro: 0.5153, Accuracy: 0.5104\n","Epoch 101, Train Loss: 0.7153, Val Loss: 2.5748, F1 Micro: 0.4583, F1 Macro: 0.4320, Accuracy: 0.4583\n","Epoch 102, Train Loss: 0.6954, Val Loss: 3.4484, F1 Micro: 0.4479, F1 Macro: 0.4459, Accuracy: 0.4479\n","Epoch 103, Train Loss: 0.6741, Val Loss: 2.7395, F1 Micro: 0.5417, F1 Macro: 0.5167, Accuracy: 0.5417\n","Epoch 104, Train Loss: 0.6743, Val Loss: 2.3640, F1 Micro: 0.5521, F1 Macro: 0.5444, Accuracy: 0.5521\n","Epoch 105, Train Loss: 0.8494, Val Loss: 3.9992, F1 Micro: 0.4896, F1 Macro: 0.4568, Accuracy: 0.4896\n","Epoch 106, Train Loss: 0.8472, Val Loss: 2.8199, F1 Micro: 0.5208, F1 Macro: 0.5005, Accuracy: 0.5208\n","Epoch 107, Train Loss: 0.6928, Val Loss: 2.2879, F1 Micro: 0.5729, F1 Macro: 0.5507, Accuracy: 0.5729\n","Epoch 108, Train Loss: 0.5981, Val Loss: 2.2707, F1 Micro: 0.5208, F1 Macro: 0.5173, Accuracy: 0.5208\n","Epoch 109, Train Loss: 0.6911, Val Loss: 2.5691, F1 Micro: 0.4271, F1 Macro: 0.4267, Accuracy: 0.4271\n","Epoch 110, Train Loss: 0.6000, Val Loss: 2.3212, F1 Micro: 0.4896, F1 Macro: 0.4797, Accuracy: 0.4896\n","Epoch 111, Train Loss: 0.6916, Val Loss: 2.4316, F1 Micro: 0.5521, F1 Macro: 0.5363, Accuracy: 0.5521\n","Epoch 112, Train Loss: 0.6151, Val Loss: 2.0911, F1 Micro: 0.4792, F1 Macro: 0.4432, Accuracy: 0.4792\n","Epoch 113, Train Loss: 0.6409, Val Loss: 3.9855, F1 Micro: 0.4792, F1 Macro: 0.4815, Accuracy: 0.4792\n","Epoch 114, Train Loss: 0.7080, Val Loss: 2.2109, F1 Micro: 0.5521, F1 Macro: 0.5472, Accuracy: 0.5521\n","Epoch 115, Train Loss: 0.7311, Val Loss: 2.5469, F1 Micro: 0.5521, F1 Macro: 0.5224, Accuracy: 0.5521\n","Epoch 116, Train Loss: 0.6516, Val Loss: 3.2913, F1 Micro: 0.4688, F1 Macro: 0.4158, Accuracy: 0.4688\n","Epoch 117, Train Loss: 0.7683, Val Loss: 2.9386, F1 Micro: 0.5000, F1 Macro: 0.4955, Accuracy: 0.5000\n","Epoch 118, Train Loss: 0.6697, Val Loss: 3.0432, F1 Micro: 0.4896, F1 Macro: 0.4705, Accuracy: 0.4896\n","Epoch 119, Train Loss: 0.6962, Val Loss: 3.0019, F1 Micro: 0.4896, F1 Macro: 0.4889, Accuracy: 0.4896\n","Epoch 120, Train Loss: 0.6501, Val Loss: 2.5543, F1 Micro: 0.4688, F1 Macro: 0.4448, Accuracy: 0.4688\n","Epoch 121, Train Loss: 0.6179, Val Loss: 2.5494, F1 Micro: 0.5104, F1 Macro: 0.4748, Accuracy: 0.5104\n","Epoch 122, Train Loss: 0.5624, Val Loss: 3.0909, F1 Micro: 0.5208, F1 Macro: 0.4657, Accuracy: 0.5208\n","Epoch 123, Train Loss: 0.6656, Val Loss: 2.6463, F1 Micro: 0.5417, F1 Macro: 0.5415, Accuracy: 0.5417\n","Epoch 124, Train Loss: 0.6841, Val Loss: 2.2954, F1 Micro: 0.5417, F1 Macro: 0.5422, Accuracy: 0.5417\n","Epoch 125, Train Loss: 0.6859, Val Loss: 3.5765, F1 Micro: 0.4167, F1 Macro: 0.3960, Accuracy: 0.4167\n","Epoch 126, Train Loss: 0.6047, Val Loss: 2.3758, F1 Micro: 0.4583, F1 Macro: 0.4402, Accuracy: 0.4583\n","Epoch 127, Train Loss: 0.5830, Val Loss: 2.5687, F1 Micro: 0.5104, F1 Macro: 0.5002, Accuracy: 0.5104\n","Epoch 128, Train Loss: 0.6356, Val Loss: 2.7991, F1 Micro: 0.4479, F1 Macro: 0.3569, Accuracy: 0.4479\n","Epoch 129, Train Loss: 0.6973, Val Loss: 2.6966, F1 Micro: 0.5104, F1 Macro: 0.4878, Accuracy: 0.5104\n","Epoch 130, Train Loss: 0.6804, Val Loss: 3.8789, F1 Micro: 0.4896, F1 Macro: 0.4716, Accuracy: 0.4896\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.0817, Val Loss: 1.8556, F1 Micro: 0.3646, F1 Macro: 0.2775, Accuracy: 0.3646\n","Epoch 2, Train Loss: 1.8863, Val Loss: 2.9683, F1 Micro: 0.1771, F1 Macro: 0.1070, Accuracy: 0.1771\n","Epoch 3, Train Loss: 1.9281, Val Loss: 1.7625, F1 Micro: 0.2396, F1 Macro: 0.1928, Accuracy: 0.2396\n","Epoch 4, Train Loss: 1.7849, Val Loss: 1.7993, F1 Micro: 0.2604, F1 Macro: 0.2105, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.7080, Val Loss: 1.9771, F1 Micro: 0.2292, F1 Macro: 0.2042, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.7185, Val Loss: 1.6517, F1 Micro: 0.3750, F1 Macro: 0.3324, Accuracy: 0.3750\n","Epoch 7, Train Loss: 1.6608, Val Loss: 1.8195, F1 Micro: 0.3854, F1 Macro: 0.3300, Accuracy: 0.3854\n","Epoch 8, Train Loss: 1.6315, Val Loss: 1.5751, F1 Micro: 0.4062, F1 Macro: 0.3541, Accuracy: 0.4062\n","Epoch 9, Train Loss: 1.6172, Val Loss: 1.5202, F1 Micro: 0.4271, F1 Macro: 0.3804, Accuracy: 0.4271\n","Epoch 10, Train Loss: 1.5887, Val Loss: 2.4133, F1 Micro: 0.2292, F1 Macro: 0.1907, Accuracy: 0.2292\n","Epoch 11, Train Loss: 1.6197, Val Loss: 1.7992, F1 Micro: 0.3542, F1 Macro: 0.2917, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.5840, Val Loss: 1.5226, F1 Micro: 0.4479, F1 Macro: 0.4010, Accuracy: 0.4479\n","Epoch 13, Train Loss: 1.5370, Val Loss: 2.5433, F1 Micro: 0.1771, F1 Macro: 0.1060, Accuracy: 0.1771\n","Epoch 14, Train Loss: 1.6617, Val Loss: 2.2818, F1 Micro: 0.1979, F1 Macro: 0.1526, Accuracy: 0.1979\n","Epoch 15, Train Loss: 1.5280, Val Loss: 1.4730, F1 Micro: 0.4375, F1 Macro: 0.4294, Accuracy: 0.4375\n","Epoch 16, Train Loss: 1.4892, Val Loss: 1.7106, F1 Micro: 0.3646, F1 Macro: 0.3452, Accuracy: 0.3646\n","Epoch 17, Train Loss: 1.5382, Val Loss: 1.6727, F1 Micro: 0.3438, F1 Macro: 0.2717, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5037, Val Loss: 1.7549, F1 Micro: 0.3542, F1 Macro: 0.3111, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.4595, Val Loss: 2.0759, F1 Micro: 0.2917, F1 Macro: 0.2414, Accuracy: 0.2917\n","Epoch 20, Train Loss: 1.4396, Val Loss: 2.0646, F1 Micro: 0.3333, F1 Macro: 0.3043, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.4975, Val Loss: 2.3587, F1 Micro: 0.3125, F1 Macro: 0.2674, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.4731, Val Loss: 1.7597, F1 Micro: 0.3958, F1 Macro: 0.3452, Accuracy: 0.3958\n","Epoch 23, Train Loss: 1.4846, Val Loss: 1.7929, F1 Micro: 0.4583, F1 Macro: 0.4552, Accuracy: 0.4583\n","Epoch 24, Train Loss: 1.4767, Val Loss: 1.5429, F1 Micro: 0.4375, F1 Macro: 0.3844, Accuracy: 0.4375\n","Epoch 25, Train Loss: 1.4575, Val Loss: 1.7391, F1 Micro: 0.3646, F1 Macro: 0.3063, Accuracy: 0.3646\n","Epoch 26, Train Loss: 1.3959, Val Loss: 1.5366, F1 Micro: 0.4479, F1 Macro: 0.4027, Accuracy: 0.4479\n","Epoch 27, Train Loss: 1.4006, Val Loss: 1.8951, F1 Micro: 0.3542, F1 Macro: 0.3309, Accuracy: 0.3542\n","Epoch 28, Train Loss: 1.3108, Val Loss: 1.7356, F1 Micro: 0.3125, F1 Macro: 0.3453, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.2681, Val Loss: 1.8667, F1 Micro: 0.3646, F1 Macro: 0.3560, Accuracy: 0.3646\n","Epoch 30, Train Loss: 1.3343, Val Loss: 1.7719, F1 Micro: 0.3021, F1 Macro: 0.2496, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.2950, Val Loss: 1.5755, F1 Micro: 0.4896, F1 Macro: 0.4598, Accuracy: 0.4896\n","Epoch 32, Train Loss: 1.3606, Val Loss: 1.7511, F1 Micro: 0.3750, F1 Macro: 0.3980, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.3625, Val Loss: 1.7580, F1 Micro: 0.4167, F1 Macro: 0.3400, Accuracy: 0.4167\n","Epoch 34, Train Loss: 1.2990, Val Loss: 1.5983, F1 Micro: 0.4375, F1 Macro: 0.4107, Accuracy: 0.4375\n","Epoch 35, Train Loss: 1.2369, Val Loss: 1.6222, F1 Micro: 0.4062, F1 Macro: 0.3619, Accuracy: 0.4062\n","Epoch 36, Train Loss: 1.2452, Val Loss: 1.7935, F1 Micro: 0.3854, F1 Macro: 0.3028, Accuracy: 0.3854\n","Epoch 37, Train Loss: 1.2209, Val Loss: 1.6642, F1 Micro: 0.3854, F1 Macro: 0.3778, Accuracy: 0.3854\n","Epoch 38, Train Loss: 1.2543, Val Loss: 1.7875, F1 Micro: 0.3750, F1 Macro: 0.3447, Accuracy: 0.3750\n","Epoch 39, Train Loss: 1.1639, Val Loss: 1.7563, F1 Micro: 0.4896, F1 Macro: 0.4499, Accuracy: 0.4896\n","Epoch 40, Train Loss: 1.1989, Val Loss: 1.5554, F1 Micro: 0.4896, F1 Macro: 0.4570, Accuracy: 0.4896\n","Epoch 41, Train Loss: 1.2582, Val Loss: 1.6836, F1 Micro: 0.4688, F1 Macro: 0.4364, Accuracy: 0.4688\n","Epoch 42, Train Loss: 1.1447, Val Loss: 1.4797, F1 Micro: 0.4792, F1 Macro: 0.4540, Accuracy: 0.4792\n","Epoch 43, Train Loss: 1.1531, Val Loss: 1.5371, F1 Micro: 0.5625, F1 Macro: 0.5656, Accuracy: 0.5625\n","Epoch 44, Train Loss: 1.2982, Val Loss: 3.3534, F1 Micro: 0.3021, F1 Macro: 0.2445, Accuracy: 0.3021\n","Epoch 45, Train Loss: 1.2689, Val Loss: 1.6984, F1 Micro: 0.4271, F1 Macro: 0.4038, Accuracy: 0.4271\n","Epoch 46, Train Loss: 1.1968, Val Loss: 2.0557, F1 Micro: 0.3229, F1 Macro: 0.2516, Accuracy: 0.3229\n","Epoch 47, Train Loss: 1.1215, Val Loss: 1.9711, F1 Micro: 0.3750, F1 Macro: 0.3303, Accuracy: 0.3750\n","Epoch 48, Train Loss: 1.1426, Val Loss: 1.8737, F1 Micro: 0.4271, F1 Macro: 0.3950, Accuracy: 0.4271\n","Epoch 49, Train Loss: 1.2559, Val Loss: 2.1172, F1 Micro: 0.3958, F1 Macro: 0.3490, Accuracy: 0.3958\n","Epoch 50, Train Loss: 1.2184, Val Loss: 1.7470, F1 Micro: 0.4479, F1 Macro: 0.4119, Accuracy: 0.4479\n","Epoch 51, Train Loss: 1.0655, Val Loss: 1.5971, F1 Micro: 0.4896, F1 Macro: 0.4326, Accuracy: 0.4896\n","Epoch 52, Train Loss: 1.0830, Val Loss: 2.2592, F1 Micro: 0.3333, F1 Macro: 0.3334, Accuracy: 0.3333\n","Epoch 53, Train Loss: 1.1046, Val Loss: 1.5855, F1 Micro: 0.4271, F1 Macro: 0.4012, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.1051, Val Loss: 1.6281, F1 Micro: 0.5729, F1 Macro: 0.5638, Accuracy: 0.5729\n","Epoch 55, Train Loss: 1.1315, Val Loss: 1.5494, F1 Micro: 0.5312, F1 Macro: 0.5091, Accuracy: 0.5312\n","Epoch 56, Train Loss: 1.0248, Val Loss: 1.8879, F1 Micro: 0.3854, F1 Macro: 0.3847, Accuracy: 0.3854\n","Epoch 57, Train Loss: 1.0339, Val Loss: 1.8656, F1 Micro: 0.3958, F1 Macro: 0.4019, Accuracy: 0.3958\n","Epoch 58, Train Loss: 1.0840, Val Loss: 1.8040, F1 Micro: 0.4167, F1 Macro: 0.3832, Accuracy: 0.4167\n","Epoch 59, Train Loss: 1.0345, Val Loss: 1.7476, F1 Micro: 0.4583, F1 Macro: 0.4334, Accuracy: 0.4583\n","Epoch 60, Train Loss: 1.0165, Val Loss: 1.6212, F1 Micro: 0.4583, F1 Macro: 0.4035, Accuracy: 0.4583\n","Epoch 61, Train Loss: 1.0369, Val Loss: 1.9126, F1 Micro: 0.4375, F1 Macro: 0.3921, Accuracy: 0.4375\n","Epoch 62, Train Loss: 1.0364, Val Loss: 1.9291, F1 Micro: 0.4271, F1 Macro: 0.4071, Accuracy: 0.4271\n","Epoch 63, Train Loss: 0.9793, Val Loss: 1.9769, F1 Micro: 0.3750, F1 Macro: 0.3685, Accuracy: 0.3750\n","Epoch 64, Train Loss: 0.9726, Val Loss: 2.0591, F1 Micro: 0.4688, F1 Macro: 0.4512, Accuracy: 0.4688\n","Epoch 65, Train Loss: 1.0110, Val Loss: 2.0604, F1 Micro: 0.3854, F1 Macro: 0.3583, Accuracy: 0.3854\n","Epoch 66, Train Loss: 0.9780, Val Loss: 1.7552, F1 Micro: 0.4583, F1 Macro: 0.4426, Accuracy: 0.4583\n","Epoch 67, Train Loss: 0.9844, Val Loss: 1.6770, F1 Micro: 0.5000, F1 Macro: 0.4482, Accuracy: 0.5000\n","Epoch 68, Train Loss: 0.9897, Val Loss: 1.7665, F1 Micro: 0.4062, F1 Macro: 0.3586, Accuracy: 0.4062\n","Epoch 69, Train Loss: 0.9877, Val Loss: 2.5870, F1 Micro: 0.3646, F1 Macro: 0.3350, Accuracy: 0.3646\n","Epoch 70, Train Loss: 1.0845, Val Loss: 1.5315, F1 Micro: 0.5521, F1 Macro: 0.5437, Accuracy: 0.5521\n","Epoch 71, Train Loss: 0.9745, Val Loss: 1.6632, F1 Micro: 0.4896, F1 Macro: 0.4948, Accuracy: 0.4896\n","Epoch 72, Train Loss: 1.0329, Val Loss: 1.5284, F1 Micro: 0.4896, F1 Macro: 0.4485, Accuracy: 0.4896\n","Epoch 73, Train Loss: 1.0177, Val Loss: 1.7996, F1 Micro: 0.4271, F1 Macro: 0.3917, Accuracy: 0.4271\n","Epoch 74, Train Loss: 0.9214, Val Loss: 2.1736, F1 Micro: 0.4062, F1 Macro: 0.3656, Accuracy: 0.4062\n","Epoch 75, Train Loss: 1.0215, Val Loss: 1.6782, F1 Micro: 0.4583, F1 Macro: 0.4493, Accuracy: 0.4583\n","Epoch 76, Train Loss: 0.8341, Val Loss: 1.5995, F1 Micro: 0.5417, F1 Macro: 0.5053, Accuracy: 0.5417\n","Epoch 77, Train Loss: 0.9612, Val Loss: 1.8816, F1 Micro: 0.5000, F1 Macro: 0.4734, Accuracy: 0.5000\n","Epoch 78, Train Loss: 0.9949, Val Loss: 1.8192, F1 Micro: 0.5417, F1 Macro: 0.5129, Accuracy: 0.5417\n","Epoch 79, Train Loss: 0.9837, Val Loss: 2.1012, F1 Micro: 0.4375, F1 Macro: 0.3931, Accuracy: 0.4375\n","Epoch 80, Train Loss: 1.0530, Val Loss: 1.8631, F1 Micro: 0.4271, F1 Macro: 0.4000, Accuracy: 0.4271\n","Epoch 81, Train Loss: 0.8926, Val Loss: 1.5618, F1 Micro: 0.4583, F1 Macro: 0.4561, Accuracy: 0.4583\n","Epoch 82, Train Loss: 0.9099, Val Loss: 1.4537, F1 Micro: 0.5312, F1 Macro: 0.4967, Accuracy: 0.5312\n","Epoch 83, Train Loss: 0.7520, Val Loss: 1.6966, F1 Micro: 0.4792, F1 Macro: 0.4714, Accuracy: 0.4792\n","Epoch 84, Train Loss: 0.9939, Val Loss: 1.8066, F1 Micro: 0.4375, F1 Macro: 0.3739, Accuracy: 0.4375\n","Epoch 85, Train Loss: 0.9193, Val Loss: 1.8556, F1 Micro: 0.4479, F1 Macro: 0.3645, Accuracy: 0.4479\n","Epoch 86, Train Loss: 0.9855, Val Loss: 1.6006, F1 Micro: 0.5729, F1 Macro: 0.5600, Accuracy: 0.5729\n","Epoch 87, Train Loss: 0.8751, Val Loss: 1.5864, F1 Micro: 0.5417, F1 Macro: 0.5290, Accuracy: 0.5417\n","Epoch 88, Train Loss: 0.8528, Val Loss: 1.7797, F1 Micro: 0.4792, F1 Macro: 0.4411, Accuracy: 0.4792\n","Epoch 89, Train Loss: 0.8056, Val Loss: 1.5453, F1 Micro: 0.5938, F1 Macro: 0.5821, Accuracy: 0.5938\n","Epoch 90, Train Loss: 0.8082, Val Loss: 2.0568, F1 Micro: 0.4583, F1 Macro: 0.4451, Accuracy: 0.4583\n","Epoch 91, Train Loss: 0.8636, Val Loss: 1.5769, F1 Micro: 0.5417, F1 Macro: 0.5139, Accuracy: 0.5417\n","Epoch 92, Train Loss: 0.8146, Val Loss: 1.9597, F1 Micro: 0.4792, F1 Macro: 0.4602, Accuracy: 0.4792\n","Epoch 93, Train Loss: 0.8599, Val Loss: 1.7706, F1 Micro: 0.5312, F1 Macro: 0.5233, Accuracy: 0.5312\n","Epoch 94, Train Loss: 0.8339, Val Loss: 1.8723, F1 Micro: 0.5208, F1 Macro: 0.4980, Accuracy: 0.5208\n","Epoch 95, Train Loss: 0.8273, Val Loss: 1.5705, F1 Micro: 0.5729, F1 Macro: 0.5395, Accuracy: 0.5729\n","Epoch 96, Train Loss: 0.9016, Val Loss: 1.9558, F1 Micro: 0.4062, F1 Macro: 0.3572, Accuracy: 0.4062\n","Epoch 97, Train Loss: 0.8846, Val Loss: 1.4831, F1 Micro: 0.6250, F1 Macro: 0.5953, Accuracy: 0.6250\n","Epoch 98, Train Loss: 0.8125, Val Loss: 2.0410, F1 Micro: 0.4583, F1 Macro: 0.4555, Accuracy: 0.4583\n","Epoch 99, Train Loss: 0.9366, Val Loss: 1.5056, F1 Micro: 0.5729, F1 Macro: 0.5665, Accuracy: 0.5729\n","Epoch 100, Train Loss: 0.7491, Val Loss: 1.9355, F1 Micro: 0.4583, F1 Macro: 0.4249, Accuracy: 0.4583\n","Epoch 101, Train Loss: 0.8113, Val Loss: 2.0167, F1 Micro: 0.4792, F1 Macro: 0.4431, Accuracy: 0.4792\n","Epoch 102, Train Loss: 0.9152, Val Loss: 1.5106, F1 Micro: 0.5417, F1 Macro: 0.5340, Accuracy: 0.5417\n","Epoch 103, Train Loss: 0.7976, Val Loss: 1.7948, F1 Micro: 0.5938, F1 Macro: 0.5745, Accuracy: 0.5938\n","Epoch 104, Train Loss: 0.8634, Val Loss: 1.8328, F1 Micro: 0.5208, F1 Macro: 0.5233, Accuracy: 0.5208\n","Epoch 105, Train Loss: 0.8408, Val Loss: 2.0446, F1 Micro: 0.4375, F1 Macro: 0.4477, Accuracy: 0.4375\n","Epoch 106, Train Loss: 0.9042, Val Loss: 2.0474, F1 Micro: 0.3854, F1 Macro: 0.3515, Accuracy: 0.3854\n","Epoch 107, Train Loss: 0.7854, Val Loss: 1.5614, F1 Micro: 0.5208, F1 Macro: 0.4812, Accuracy: 0.5208\n","Epoch 108, Train Loss: 0.7993, Val Loss: 2.0980, F1 Micro: 0.4271, F1 Macro: 0.4337, Accuracy: 0.4271\n","Epoch 109, Train Loss: 0.7432, Val Loss: 2.1912, F1 Micro: 0.4583, F1 Macro: 0.4386, Accuracy: 0.4583\n","Epoch 110, Train Loss: 0.8649, Val Loss: 1.7658, F1 Micro: 0.5729, F1 Macro: 0.5400, Accuracy: 0.5729\n","Epoch 111, Train Loss: 0.7366, Val Loss: 1.6086, F1 Micro: 0.6042, F1 Macro: 0.5882, Accuracy: 0.6042\n","Epoch 112, Train Loss: 0.7379, Val Loss: 1.9503, F1 Micro: 0.5000, F1 Macro: 0.4745, Accuracy: 0.5000\n","Epoch 113, Train Loss: 0.7749, Val Loss: 1.7686, F1 Micro: 0.4375, F1 Macro: 0.4298, Accuracy: 0.4375\n","Epoch 114, Train Loss: 0.6996, Val Loss: 2.0525, F1 Micro: 0.5417, F1 Macro: 0.4998, Accuracy: 0.5417\n","Epoch 115, Train Loss: 0.7994, Val Loss: 1.5820, F1 Micro: 0.5312, F1 Macro: 0.5095, Accuracy: 0.5312\n","Epoch 116, Train Loss: 0.7594, Val Loss: 1.8136, F1 Micro: 0.5625, F1 Macro: 0.5148, Accuracy: 0.5625\n","Epoch 117, Train Loss: 0.6974, Val Loss: 1.9398, F1 Micro: 0.4896, F1 Macro: 0.4875, Accuracy: 0.4896\n","Epoch 118, Train Loss: 0.7348, Val Loss: 2.3295, F1 Micro: 0.4375, F1 Macro: 0.3750, Accuracy: 0.4375\n","Epoch 119, Train Loss: 0.6922, Val Loss: 1.7231, F1 Micro: 0.5938, F1 Macro: 0.5878, Accuracy: 0.5938\n","Epoch 120, Train Loss: 0.6913, Val Loss: 1.6289, F1 Micro: 0.5625, F1 Macro: 0.5459, Accuracy: 0.5625\n","Epoch 121, Train Loss: 0.6615, Val Loss: 2.6649, F1 Micro: 0.4583, F1 Macro: 0.4562, Accuracy: 0.4583\n","Epoch 122, Train Loss: 0.7315, Val Loss: 1.6548, F1 Micro: 0.5417, F1 Macro: 0.5325, Accuracy: 0.5417\n","Epoch 123, Train Loss: 0.6618, Val Loss: 1.6541, F1 Micro: 0.5208, F1 Macro: 0.4990, Accuracy: 0.5208\n","Epoch 124, Train Loss: 0.6898, Val Loss: 1.4848, F1 Micro: 0.5833, F1 Macro: 0.5632, Accuracy: 0.5833\n","Epoch 125, Train Loss: 0.5892, Val Loss: 1.6670, F1 Micro: 0.5938, F1 Macro: 0.5949, Accuracy: 0.5938\n","Epoch 126, Train Loss: 0.7029, Val Loss: 1.7486, F1 Micro: 0.5208, F1 Macro: 0.5151, Accuracy: 0.5208\n","Epoch 127, Train Loss: 0.6586, Val Loss: 1.6875, F1 Micro: 0.5938, F1 Macro: 0.5866, Accuracy: 0.5938\n","Epoch 128, Train Loss: 0.7048, Val Loss: 2.0665, F1 Micro: 0.5000, F1 Macro: 0.4820, Accuracy: 0.5000\n","Epoch 129, Train Loss: 0.6861, Val Loss: 3.2469, F1 Micro: 0.3750, F1 Macro: 0.3732, Accuracy: 0.3750\n","Epoch 130, Train Loss: 0.6866, Val Loss: 3.5852, F1 Micro: 0.4271, F1 Macro: 0.3965, Accuracy: 0.4271\n","Epoch 131, Train Loss: 0.8296, Val Loss: 2.3378, F1 Micro: 0.4062, F1 Macro: 0.3846, Accuracy: 0.4062\n","Epoch 132, Train Loss: 0.7084, Val Loss: 2.6116, F1 Micro: 0.4167, F1 Macro: 0.3715, Accuracy: 0.4167\n","Epoch 133, Train Loss: 0.7529, Val Loss: 1.8628, F1 Micro: 0.5938, F1 Macro: 0.5841, Accuracy: 0.5938\n","Epoch 134, Train Loss: 0.7924, Val Loss: 1.9092, F1 Micro: 0.5312, F1 Macro: 0.5278, Accuracy: 0.5312\n","Epoch 135, Train Loss: 0.7390, Val Loss: 1.7235, F1 Micro: 0.5417, F1 Macro: 0.5234, Accuracy: 0.5417\n","Epoch 136, Train Loss: 0.6423, Val Loss: 1.7222, F1 Micro: 0.5208, F1 Macro: 0.4855, Accuracy: 0.5208\n","Epoch 137, Train Loss: 0.6909, Val Loss: 1.8971, F1 Micro: 0.4479, F1 Macro: 0.4281, Accuracy: 0.4479\n","Epoch 138, Train Loss: 0.6336, Val Loss: 2.2221, F1 Micro: 0.4688, F1 Macro: 0.4039, Accuracy: 0.4688\n","Epoch 139, Train Loss: 0.7622, Val Loss: 1.9507, F1 Micro: 0.6250, F1 Macro: 0.5998, Accuracy: 0.6250\n","Epoch 140, Train Loss: 0.6512, Val Loss: 2.0194, F1 Micro: 0.4062, F1 Macro: 0.3806, Accuracy: 0.4062\n","Epoch 141, Train Loss: 0.7111, Val Loss: 1.6433, F1 Micro: 0.5104, F1 Macro: 0.5046, Accuracy: 0.5104\n","Epoch 142, Train Loss: 0.5773, Val Loss: 2.2059, F1 Micro: 0.5312, F1 Macro: 0.5267, Accuracy: 0.5312\n","Epoch 143, Train Loss: 0.6695, Val Loss: 2.2338, F1 Micro: 0.3958, F1 Macro: 0.4224, Accuracy: 0.3958\n","Epoch 144, Train Loss: 0.6559, Val Loss: 2.2835, F1 Micro: 0.4583, F1 Macro: 0.4576, Accuracy: 0.4583\n","Epoch 145, Train Loss: 0.8056, Val Loss: 1.9143, F1 Micro: 0.5000, F1 Macro: 0.4556, Accuracy: 0.5000\n","Epoch 146, Train Loss: 0.6805, Val Loss: 2.0253, F1 Micro: 0.5521, F1 Macro: 0.5540, Accuracy: 0.5521\n","Epoch 147, Train Loss: 0.7345, Val Loss: 1.9969, F1 Micro: 0.5729, F1 Macro: 0.5457, Accuracy: 0.5729\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.2239, Val Loss: 2.0689, F1 Micro: 0.2500, F1 Macro: 0.1795, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.9440, Val Loss: 1.7053, F1 Micro: 0.2812, F1 Macro: 0.2377, Accuracy: 0.2812\n","Epoch 3, Train Loss: 1.7375, Val Loss: 1.6614, F1 Micro: 0.3438, F1 Macro: 0.2329, Accuracy: 0.3438\n","Epoch 4, Train Loss: 1.7610, Val Loss: 1.7363, F1 Micro: 0.3333, F1 Macro: 0.2355, Accuracy: 0.3333\n","Epoch 5, Train Loss: 1.7489, Val Loss: 1.7860, F1 Micro: 0.3021, F1 Macro: 0.1623, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.6528, Val Loss: 1.6524, F1 Micro: 0.3958, F1 Macro: 0.3239, Accuracy: 0.3958\n","Epoch 7, Train Loss: 1.6525, Val Loss: 1.8772, F1 Micro: 0.3333, F1 Macro: 0.2897, Accuracy: 0.3333\n","Epoch 8, Train Loss: 1.6726, Val Loss: 1.6634, F1 Micro: 0.3125, F1 Macro: 0.2539, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.6276, Val Loss: 2.1447, F1 Micro: 0.2396, F1 Macro: 0.1376, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.6459, Val Loss: 1.6672, F1 Micro: 0.4062, F1 Macro: 0.3680, Accuracy: 0.4062\n","Epoch 11, Train Loss: 1.5692, Val Loss: 1.7968, F1 Micro: 0.3750, F1 Macro: 0.3298, Accuracy: 0.3750\n","Epoch 12, Train Loss: 1.5747, Val Loss: 1.6835, F1 Micro: 0.3438, F1 Macro: 0.3104, Accuracy: 0.3438\n","Epoch 13, Train Loss: 1.5839, Val Loss: 1.7710, F1 Micro: 0.3646, F1 Macro: 0.3115, Accuracy: 0.3646\n","Epoch 14, Train Loss: 1.5626, Val Loss: 1.8511, F1 Micro: 0.4062, F1 Macro: 0.2956, Accuracy: 0.4062\n","Epoch 15, Train Loss: 1.6372, Val Loss: 1.9020, F1 Micro: 0.2292, F1 Macro: 0.1376, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.5489, Val Loss: 1.6769, F1 Micro: 0.4583, F1 Macro: 0.2860, Accuracy: 0.4583\n","Epoch 17, Train Loss: 1.5187, Val Loss: 1.6868, F1 Micro: 0.4062, F1 Macro: 0.3141, Accuracy: 0.4062\n","Epoch 18, Train Loss: 1.4855, Val Loss: 1.6934, F1 Micro: 0.3646, F1 Macro: 0.3283, Accuracy: 0.3646\n","Epoch 19, Train Loss: 1.4640, Val Loss: 1.8579, F1 Micro: 0.3021, F1 Macro: 0.2114, Accuracy: 0.3021\n","Epoch 20, Train Loss: 1.4913, Val Loss: 1.7166, F1 Micro: 0.3646, F1 Macro: 0.3248, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.4817, Val Loss: 1.6843, F1 Micro: 0.3854, F1 Macro: 0.3147, Accuracy: 0.3854\n","Epoch 22, Train Loss: 1.5101, Val Loss: 1.9440, F1 Micro: 0.3750, F1 Macro: 0.2865, Accuracy: 0.3750\n","Epoch 23, Train Loss: 1.4608, Val Loss: 1.8746, F1 Micro: 0.2708, F1 Macro: 0.1878, Accuracy: 0.2708\n","Epoch 24, Train Loss: 1.4778, Val Loss: 1.9258, F1 Micro: 0.3750, F1 Macro: 0.3369, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.4891, Val Loss: 1.7050, F1 Micro: 0.4583, F1 Macro: 0.4138, Accuracy: 0.4583\n","Epoch 26, Train Loss: 1.4200, Val Loss: 2.0863, F1 Micro: 0.2917, F1 Macro: 0.1832, Accuracy: 0.2917\n","Epoch 27, Train Loss: 1.3876, Val Loss: 1.5772, F1 Micro: 0.4479, F1 Macro: 0.3725, Accuracy: 0.4479\n","Epoch 28, Train Loss: 1.4048, Val Loss: 1.6282, F1 Micro: 0.4271, F1 Macro: 0.3467, Accuracy: 0.4271\n","Epoch 29, Train Loss: 1.4354, Val Loss: 1.6299, F1 Micro: 0.4583, F1 Macro: 0.4137, Accuracy: 0.4583\n","Epoch 30, Train Loss: 1.4554, Val Loss: 1.5888, F1 Micro: 0.4479, F1 Macro: 0.4104, Accuracy: 0.4479\n","Epoch 31, Train Loss: 1.3599, Val Loss: 1.6601, F1 Micro: 0.4479, F1 Macro: 0.3906, Accuracy: 0.4479\n","Epoch 32, Train Loss: 1.3913, Val Loss: 1.9515, F1 Micro: 0.3958, F1 Macro: 0.3751, Accuracy: 0.3958\n","Epoch 33, Train Loss: 1.4002, Val Loss: 1.6788, F1 Micro: 0.4375, F1 Macro: 0.3546, Accuracy: 0.4375\n","Epoch 34, Train Loss: 1.3800, Val Loss: 1.7627, F1 Micro: 0.4479, F1 Macro: 0.4249, Accuracy: 0.4479\n","Epoch 35, Train Loss: 1.3649, Val Loss: 1.7872, F1 Micro: 0.3854, F1 Macro: 0.3073, Accuracy: 0.3854\n","Epoch 36, Train Loss: 1.3179, Val Loss: 1.4387, F1 Micro: 0.5104, F1 Macro: 0.4556, Accuracy: 0.5104\n","Epoch 37, Train Loss: 1.3281, Val Loss: 1.5756, F1 Micro: 0.4271, F1 Macro: 0.3794, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.2560, Val Loss: 1.7721, F1 Micro: 0.3750, F1 Macro: 0.3520, Accuracy: 0.3750\n","Epoch 39, Train Loss: 1.3544, Val Loss: 1.7306, F1 Micro: 0.4375, F1 Macro: 0.3482, Accuracy: 0.4375\n","Epoch 40, Train Loss: 1.2601, Val Loss: 1.8807, F1 Micro: 0.5000, F1 Macro: 0.3587, Accuracy: 0.5000\n","Epoch 41, Train Loss: 1.2291, Val Loss: 1.9700, F1 Micro: 0.3958, F1 Macro: 0.3054, Accuracy: 0.3958\n","Epoch 42, Train Loss: 1.2008, Val Loss: 1.6729, F1 Micro: 0.4375, F1 Macro: 0.3733, Accuracy: 0.4375\n","Epoch 43, Train Loss: 1.2979, Val Loss: 1.7820, F1 Micro: 0.5000, F1 Macro: 0.4573, Accuracy: 0.5000\n","Epoch 44, Train Loss: 1.2423, Val Loss: 1.5335, F1 Micro: 0.5000, F1 Macro: 0.4353, Accuracy: 0.5000\n","Epoch 45, Train Loss: 1.2041, Val Loss: 1.4948, F1 Micro: 0.5417, F1 Macro: 0.5142, Accuracy: 0.5417\n","Epoch 46, Train Loss: 1.2471, Val Loss: 1.8035, F1 Micro: 0.3750, F1 Macro: 0.3466, Accuracy: 0.3750\n","Epoch 47, Train Loss: 1.2369, Val Loss: 1.6671, F1 Micro: 0.4271, F1 Macro: 0.3490, Accuracy: 0.4271\n","Epoch 48, Train Loss: 1.1913, Val Loss: 1.4314, F1 Micro: 0.5729, F1 Macro: 0.5419, Accuracy: 0.5729\n","Epoch 49, Train Loss: 1.1452, Val Loss: 1.5076, F1 Micro: 0.5417, F1 Macro: 0.5193, Accuracy: 0.5417\n","Epoch 50, Train Loss: 1.2100, Val Loss: 2.0137, F1 Micro: 0.4583, F1 Macro: 0.3991, Accuracy: 0.4583\n","Epoch 51, Train Loss: 1.2715, Val Loss: 1.5370, F1 Micro: 0.4896, F1 Macro: 0.4269, Accuracy: 0.4896\n","Epoch 52, Train Loss: 1.2047, Val Loss: 1.8274, F1 Micro: 0.4792, F1 Macro: 0.3880, Accuracy: 0.4792\n","Epoch 53, Train Loss: 1.1707, Val Loss: 1.6547, F1 Micro: 0.4271, F1 Macro: 0.4155, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.2006, Val Loss: 1.8548, F1 Micro: 0.4479, F1 Macro: 0.4146, Accuracy: 0.4479\n","Epoch 55, Train Loss: 1.1638, Val Loss: 1.6815, F1 Micro: 0.4479, F1 Macro: 0.4022, Accuracy: 0.4479\n","Epoch 56, Train Loss: 1.1323, Val Loss: 1.5167, F1 Micro: 0.5104, F1 Macro: 0.4722, Accuracy: 0.5104\n","Epoch 57, Train Loss: 1.0856, Val Loss: 1.6023, F1 Micro: 0.5104, F1 Macro: 0.4452, Accuracy: 0.5104\n","Epoch 58, Train Loss: 1.1358, Val Loss: 1.5744, F1 Micro: 0.5208, F1 Macro: 0.4390, Accuracy: 0.5208\n","Epoch 59, Train Loss: 1.1244, Val Loss: 1.5126, F1 Micro: 0.5104, F1 Macro: 0.4425, Accuracy: 0.5104\n","Epoch 60, Train Loss: 1.1447, Val Loss: 1.6855, F1 Micro: 0.5208, F1 Macro: 0.4784, Accuracy: 0.5208\n","Epoch 61, Train Loss: 1.1392, Val Loss: 1.4446, F1 Micro: 0.5521, F1 Macro: 0.5401, Accuracy: 0.5521\n","Epoch 62, Train Loss: 1.1898, Val Loss: 1.6279, F1 Micro: 0.4688, F1 Macro: 0.4288, Accuracy: 0.4688\n","Epoch 63, Train Loss: 1.1221, Val Loss: 1.6171, F1 Micro: 0.5521, F1 Macro: 0.5366, Accuracy: 0.5521\n","Epoch 64, Train Loss: 1.0866, Val Loss: 1.7588, F1 Micro: 0.4375, F1 Macro: 0.3703, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.1074, Val Loss: 1.5711, F1 Micro: 0.4896, F1 Macro: 0.4432, Accuracy: 0.4896\n","Epoch 66, Train Loss: 1.0183, Val Loss: 1.6666, F1 Micro: 0.4479, F1 Macro: 0.3755, Accuracy: 0.4479\n","Epoch 67, Train Loss: 1.0817, Val Loss: 2.0832, F1 Micro: 0.4167, F1 Macro: 0.3897, Accuracy: 0.4167\n","Epoch 68, Train Loss: 1.0087, Val Loss: 1.6885, F1 Micro: 0.5104, F1 Macro: 0.5023, Accuracy: 0.5104\n","Epoch 69, Train Loss: 1.0295, Val Loss: 1.8786, F1 Micro: 0.4583, F1 Macro: 0.3431, Accuracy: 0.4583\n","Epoch 70, Train Loss: 1.2003, Val Loss: 1.6137, F1 Micro: 0.6042, F1 Macro: 0.5722, Accuracy: 0.6042\n","Epoch 71, Train Loss: 1.0603, Val Loss: 1.8418, F1 Micro: 0.4167, F1 Macro: 0.3977, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.0062, Val Loss: 1.7823, F1 Micro: 0.4375, F1 Macro: 0.3691, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.0736, Val Loss: 1.9022, F1 Micro: 0.4271, F1 Macro: 0.3736, Accuracy: 0.4271\n","Epoch 74, Train Loss: 1.0067, Val Loss: 1.6534, F1 Micro: 0.5521, F1 Macro: 0.5348, Accuracy: 0.5521\n","Epoch 75, Train Loss: 1.0347, Val Loss: 1.4400, F1 Micro: 0.5521, F1 Macro: 0.4977, Accuracy: 0.5521\n","Epoch 76, Train Loss: 1.0030, Val Loss: 1.5739, F1 Micro: 0.5625, F1 Macro: 0.5174, Accuracy: 0.5625\n","Epoch 77, Train Loss: 1.0544, Val Loss: 1.8976, F1 Micro: 0.4375, F1 Macro: 0.3795, Accuracy: 0.4375\n","Epoch 78, Train Loss: 1.0364, Val Loss: 1.6719, F1 Micro: 0.5312, F1 Macro: 0.5082, Accuracy: 0.5312\n","Epoch 79, Train Loss: 1.0116, Val Loss: 1.6457, F1 Micro: 0.5000, F1 Macro: 0.4810, Accuracy: 0.5000\n","Epoch 80, Train Loss: 1.0624, Val Loss: 1.8417, F1 Micro: 0.3854, F1 Macro: 0.3002, Accuracy: 0.3854\n","Epoch 81, Train Loss: 0.9430, Val Loss: 1.7210, F1 Micro: 0.5104, F1 Macro: 0.4451, Accuracy: 0.5104\n","Epoch 82, Train Loss: 0.9569, Val Loss: 1.9024, F1 Micro: 0.4688, F1 Macro: 0.4409, Accuracy: 0.4688\n","Epoch 83, Train Loss: 0.9235, Val Loss: 2.2566, F1 Micro: 0.4688, F1 Macro: 0.3685, Accuracy: 0.4688\n","Epoch 84, Train Loss: 1.1200, Val Loss: 2.0086, F1 Micro: 0.4271, F1 Macro: 0.3657, Accuracy: 0.4271\n","Epoch 85, Train Loss: 1.0282, Val Loss: 1.6426, F1 Micro: 0.5000, F1 Macro: 0.4925, Accuracy: 0.5000\n","Epoch 86, Train Loss: 0.9739, Val Loss: 1.4357, F1 Micro: 0.5833, F1 Macro: 0.5646, Accuracy: 0.5833\n","Epoch 87, Train Loss: 0.9275, Val Loss: 1.5311, F1 Micro: 0.5417, F1 Macro: 0.4777, Accuracy: 0.5417\n","Epoch 88, Train Loss: 0.8978, Val Loss: 1.4088, F1 Micro: 0.5521, F1 Macro: 0.4964, Accuracy: 0.5521\n","Epoch 89, Train Loss: 0.9214, Val Loss: 1.8455, F1 Micro: 0.4583, F1 Macro: 0.3928, Accuracy: 0.4583\n","Epoch 90, Train Loss: 0.8752, Val Loss: 2.1629, F1 Micro: 0.4375, F1 Macro: 0.3499, Accuracy: 0.4375\n","Epoch 91, Train Loss: 0.9268, Val Loss: 1.3870, F1 Micro: 0.6042, F1 Macro: 0.5687, Accuracy: 0.6042\n","Epoch 92, Train Loss: 1.0158, Val Loss: 2.0349, F1 Micro: 0.4688, F1 Macro: 0.4173, Accuracy: 0.4688\n","Epoch 93, Train Loss: 0.9849, Val Loss: 1.3680, F1 Micro: 0.5938, F1 Macro: 0.5520, Accuracy: 0.5938\n","Epoch 94, Train Loss: 0.8869, Val Loss: 1.7050, F1 Micro: 0.5208, F1 Macro: 0.4395, Accuracy: 0.5208\n","Epoch 95, Train Loss: 1.0428, Val Loss: 1.7207, F1 Micro: 0.4583, F1 Macro: 0.3763, Accuracy: 0.4583\n","Epoch 96, Train Loss: 1.1595, Val Loss: 1.8603, F1 Micro: 0.4896, F1 Macro: 0.4624, Accuracy: 0.4896\n","Epoch 97, Train Loss: 0.8981, Val Loss: 1.5003, F1 Micro: 0.5000, F1 Macro: 0.4592, Accuracy: 0.5000\n","Epoch 98, Train Loss: 0.8657, Val Loss: 1.5118, F1 Micro: 0.5417, F1 Macro: 0.4743, Accuracy: 0.5417\n","Epoch 99, Train Loss: 0.7928, Val Loss: 1.6130, F1 Micro: 0.4896, F1 Macro: 0.4622, Accuracy: 0.4896\n","Epoch 100, Train Loss: 0.9564, Val Loss: 1.7652, F1 Micro: 0.5521, F1 Macro: 0.5296, Accuracy: 0.5521\n","Epoch 101, Train Loss: 0.9573, Val Loss: 1.7311, F1 Micro: 0.5312, F1 Macro: 0.4675, Accuracy: 0.5312\n","Epoch 102, Train Loss: 0.8931, Val Loss: 1.6476, F1 Micro: 0.5208, F1 Macro: 0.4783, Accuracy: 0.5208\n","Epoch 103, Train Loss: 0.9212, Val Loss: 1.7095, F1 Micro: 0.5938, F1 Macro: 0.5616, Accuracy: 0.5938\n","Epoch 104, Train Loss: 0.8391, Val Loss: 1.8583, F1 Micro: 0.4792, F1 Macro: 0.4277, Accuracy: 0.4792\n","Epoch 105, Train Loss: 0.8680, Val Loss: 1.6283, F1 Micro: 0.5521, F1 Macro: 0.4917, Accuracy: 0.5521\n","Epoch 106, Train Loss: 0.8036, Val Loss: 1.7115, F1 Micro: 0.5312, F1 Macro: 0.5022, Accuracy: 0.5312\n","Epoch 107, Train Loss: 0.7576, Val Loss: 2.0872, F1 Micro: 0.4792, F1 Macro: 0.4379, Accuracy: 0.4792\n","Epoch 108, Train Loss: 0.8288, Val Loss: 1.6225, F1 Micro: 0.5938, F1 Macro: 0.5035, Accuracy: 0.5938\n","Epoch 109, Train Loss: 0.8212, Val Loss: 1.8259, F1 Micro: 0.5208, F1 Macro: 0.4635, Accuracy: 0.5208\n","Epoch 110, Train Loss: 0.8262, Val Loss: 1.4930, F1 Micro: 0.5938, F1 Macro: 0.5086, Accuracy: 0.5938\n","Epoch 111, Train Loss: 0.9067, Val Loss: 1.5604, F1 Micro: 0.5729, F1 Macro: 0.4823, Accuracy: 0.5729\n","Epoch 112, Train Loss: 0.8730, Val Loss: 1.5578, F1 Micro: 0.5417, F1 Macro: 0.5073, Accuracy: 0.5417\n","Epoch 113, Train Loss: 0.8321, Val Loss: 1.5800, F1 Micro: 0.5208, F1 Macro: 0.4849, Accuracy: 0.5208\n","Epoch 114, Train Loss: 0.8225, Val Loss: 1.8867, F1 Micro: 0.4792, F1 Macro: 0.4562, Accuracy: 0.4792\n","Epoch 115, Train Loss: 0.7824, Val Loss: 1.5144, F1 Micro: 0.5625, F1 Macro: 0.5030, Accuracy: 0.5625\n","Epoch 116, Train Loss: 0.7887, Val Loss: 1.6494, F1 Micro: 0.5729, F1 Macro: 0.5411, Accuracy: 0.5729\n","Epoch 117, Train Loss: 0.8038, Val Loss: 1.6408, F1 Micro: 0.5417, F1 Macro: 0.5052, Accuracy: 0.5417\n","Epoch 118, Train Loss: 0.8822, Val Loss: 2.3464, F1 Micro: 0.5417, F1 Macro: 0.4940, Accuracy: 0.5417\n","Epoch 119, Train Loss: 0.8500, Val Loss: 1.7782, F1 Micro: 0.5000, F1 Macro: 0.4563, Accuracy: 0.5000\n","Epoch 120, Train Loss: 0.7354, Val Loss: 1.9638, F1 Micro: 0.5104, F1 Macro: 0.4813, Accuracy: 0.5104\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.2151, Val Loss: 2.2125, F1 Micro: 0.2188, F1 Macro: 0.1505, Accuracy: 0.2188\n","Epoch 2, Train Loss: 1.8534, Val Loss: 2.2922, F1 Micro: 0.1667, F1 Macro: 0.0656, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.9128, Val Loss: 1.9703, F1 Micro: 0.2604, F1 Macro: 0.2163, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.7614, Val Loss: 1.8963, F1 Micro: 0.3021, F1 Macro: 0.2687, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.6933, Val Loss: 1.6837, F1 Micro: 0.3646, F1 Macro: 0.3522, Accuracy: 0.3646\n","Epoch 6, Train Loss: 1.6502, Val Loss: 2.0099, F1 Micro: 0.3021, F1 Macro: 0.2480, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.6406, Val Loss: 1.8105, F1 Micro: 0.2812, F1 Macro: 0.2490, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6094, Val Loss: 2.1118, F1 Micro: 0.2500, F1 Macro: 0.1943, Accuracy: 0.2500\n","Epoch 9, Train Loss: 1.5894, Val Loss: 1.6954, F1 Micro: 0.2917, F1 Macro: 0.2404, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.5545, Val Loss: 1.7895, F1 Micro: 0.2500, F1 Macro: 0.1764, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.5486, Val Loss: 1.7638, F1 Micro: 0.3021, F1 Macro: 0.2295, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.6049, Val Loss: 1.6143, F1 Micro: 0.3958, F1 Macro: 0.3794, Accuracy: 0.3958\n","Epoch 13, Train Loss: 1.5598, Val Loss: 1.6458, F1 Micro: 0.3750, F1 Macro: 0.3857, Accuracy: 0.3750\n","Epoch 14, Train Loss: 1.5630, Val Loss: 1.7952, F1 Micro: 0.2604, F1 Macro: 0.1925, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.5334, Val Loss: 1.8761, F1 Micro: 0.3854, F1 Macro: 0.3461, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.4898, Val Loss: 1.7871, F1 Micro: 0.3750, F1 Macro: 0.3196, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.5202, Val Loss: 1.6723, F1 Micro: 0.3438, F1 Macro: 0.3234, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.4100, Val Loss: 2.8530, F1 Micro: 0.1771, F1 Macro: 0.1125, Accuracy: 0.1771\n","Epoch 19, Train Loss: 1.4596, Val Loss: 2.4882, F1 Micro: 0.2917, F1 Macro: 0.1938, Accuracy: 0.2917\n","Epoch 20, Train Loss: 1.4946, Val Loss: 1.7868, F1 Micro: 0.3229, F1 Macro: 0.3061, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.4749, Val Loss: 1.7094, F1 Micro: 0.3229, F1 Macro: 0.2898, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.4542, Val Loss: 1.7608, F1 Micro: 0.3229, F1 Macro: 0.2592, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.5065, Val Loss: 1.8266, F1 Micro: 0.3854, F1 Macro: 0.3545, Accuracy: 0.3854\n","Epoch 24, Train Loss: 1.4287, Val Loss: 1.8780, F1 Micro: 0.3229, F1 Macro: 0.2657, Accuracy: 0.3229\n","Epoch 25, Train Loss: 1.3819, Val Loss: 2.0472, F1 Micro: 0.3125, F1 Macro: 0.2752, Accuracy: 0.3125\n","Epoch 26, Train Loss: 1.3526, Val Loss: 2.1093, F1 Micro: 0.2812, F1 Macro: 0.2251, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.4472, Val Loss: 1.7279, F1 Micro: 0.3438, F1 Macro: 0.3045, Accuracy: 0.3438\n","Epoch 28, Train Loss: 1.4210, Val Loss: 1.8211, F1 Micro: 0.3542, F1 Macro: 0.3195, Accuracy: 0.3542\n","Epoch 29, Train Loss: 1.3282, Val Loss: 1.8336, F1 Micro: 0.3542, F1 Macro: 0.3405, Accuracy: 0.3542\n","Epoch 30, Train Loss: 1.3288, Val Loss: 1.7562, F1 Micro: 0.3438, F1 Macro: 0.3359, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.3832, Val Loss: 2.0045, F1 Micro: 0.2708, F1 Macro: 0.2411, Accuracy: 0.2708\n","Epoch 32, Train Loss: 1.3397, Val Loss: 1.6891, F1 Micro: 0.4271, F1 Macro: 0.3753, Accuracy: 0.4271\n","Epoch 33, Train Loss: 1.3101, Val Loss: 1.7047, F1 Micro: 0.3333, F1 Macro: 0.2789, Accuracy: 0.3333\n","Epoch 34, Train Loss: 1.2684, Val Loss: 1.5850, F1 Micro: 0.3646, F1 Macro: 0.3358, Accuracy: 0.3646\n","Epoch 35, Train Loss: 1.2647, Val Loss: 1.8921, F1 Micro: 0.4271, F1 Macro: 0.3424, Accuracy: 0.4271\n","Epoch 36, Train Loss: 1.3029, Val Loss: 1.5722, F1 Micro: 0.4688, F1 Macro: 0.4652, Accuracy: 0.4688\n","Epoch 37, Train Loss: 1.2941, Val Loss: 1.6720, F1 Micro: 0.3854, F1 Macro: 0.3567, Accuracy: 0.3854\n","Epoch 38, Train Loss: 1.2414, Val Loss: 2.0209, F1 Micro: 0.2812, F1 Macro: 0.2758, Accuracy: 0.2812\n","Epoch 39, Train Loss: 1.2703, Val Loss: 1.8214, F1 Micro: 0.3542, F1 Macro: 0.3402, Accuracy: 0.3542\n","Epoch 40, Train Loss: 1.3376, Val Loss: 1.6616, F1 Micro: 0.4479, F1 Macro: 0.4142, Accuracy: 0.4479\n","Epoch 41, Train Loss: 1.2337, Val Loss: 1.7600, F1 Micro: 0.3438, F1 Macro: 0.3396, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.2467, Val Loss: 1.7728, F1 Micro: 0.3854, F1 Macro: 0.3728, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.1689, Val Loss: 1.5415, F1 Micro: 0.3750, F1 Macro: 0.3662, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.2484, Val Loss: 1.8670, F1 Micro: 0.2917, F1 Macro: 0.2734, Accuracy: 0.2917\n","Epoch 45, Train Loss: 1.2117, Val Loss: 2.5637, F1 Micro: 0.3333, F1 Macro: 0.3024, Accuracy: 0.3333\n","Epoch 46, Train Loss: 1.2003, Val Loss: 1.6567, F1 Micro: 0.4167, F1 Macro: 0.4187, Accuracy: 0.4167\n","Epoch 47, Train Loss: 1.1864, Val Loss: 1.6337, F1 Micro: 0.4271, F1 Macro: 0.3902, Accuracy: 0.4271\n","Epoch 48, Train Loss: 1.1551, Val Loss: 1.5377, F1 Micro: 0.4688, F1 Macro: 0.4409, Accuracy: 0.4688\n","Epoch 49, Train Loss: 1.1669, Val Loss: 1.7058, F1 Micro: 0.3333, F1 Macro: 0.2927, Accuracy: 0.3333\n","Epoch 50, Train Loss: 1.1218, Val Loss: 1.9287, F1 Micro: 0.4479, F1 Macro: 0.3936, Accuracy: 0.4479\n","Epoch 51, Train Loss: 1.1650, Val Loss: 2.0177, F1 Micro: 0.4062, F1 Macro: 0.3747, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.0885, Val Loss: 1.6411, F1 Micro: 0.4167, F1 Macro: 0.3811, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.0925, Val Loss: 2.0660, F1 Micro: 0.4062, F1 Macro: 0.3832, Accuracy: 0.4062\n","Epoch 54, Train Loss: 1.1338, Val Loss: 1.4631, F1 Micro: 0.5104, F1 Macro: 0.5120, Accuracy: 0.5104\n","Epoch 55, Train Loss: 1.1218, Val Loss: 1.8037, F1 Micro: 0.4479, F1 Macro: 0.4528, Accuracy: 0.4479\n","Epoch 56, Train Loss: 1.1730, Val Loss: 1.4461, F1 Micro: 0.4896, F1 Macro: 0.4899, Accuracy: 0.4896\n","Epoch 57, Train Loss: 1.1850, Val Loss: 3.2948, F1 Micro: 0.3125, F1 Macro: 0.2707, Accuracy: 0.3125\n","Epoch 58, Train Loss: 1.2470, Val Loss: 1.8485, F1 Micro: 0.3750, F1 Macro: 0.3816, Accuracy: 0.3750\n","Epoch 59, Train Loss: 1.1574, Val Loss: 1.6131, F1 Micro: 0.4583, F1 Macro: 0.4523, Accuracy: 0.4583\n","Epoch 60, Train Loss: 1.1250, Val Loss: 1.6034, F1 Micro: 0.4792, F1 Macro: 0.4743, Accuracy: 0.4792\n","Epoch 61, Train Loss: 1.1097, Val Loss: 1.5819, F1 Micro: 0.4583, F1 Macro: 0.4321, Accuracy: 0.4583\n","Epoch 62, Train Loss: 1.0116, Val Loss: 2.0535, F1 Micro: 0.3333, F1 Macro: 0.2303, Accuracy: 0.3333\n","Epoch 63, Train Loss: 1.1352, Val Loss: 1.9912, F1 Micro: 0.4375, F1 Macro: 0.3907, Accuracy: 0.4375\n","Epoch 64, Train Loss: 1.0136, Val Loss: 1.8048, F1 Micro: 0.4375, F1 Macro: 0.4026, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.0610, Val Loss: 2.0104, F1 Micro: 0.3854, F1 Macro: 0.3773, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.1782, Val Loss: 2.4757, F1 Micro: 0.3229, F1 Macro: 0.2694, Accuracy: 0.3229\n","Epoch 67, Train Loss: 1.0471, Val Loss: 1.7247, F1 Micro: 0.4688, F1 Macro: 0.4283, Accuracy: 0.4688\n","Epoch 68, Train Loss: 1.0614, Val Loss: 1.6765, F1 Micro: 0.4583, F1 Macro: 0.4518, Accuracy: 0.4583\n","Epoch 69, Train Loss: 1.0192, Val Loss: 1.4109, F1 Micro: 0.5521, F1 Macro: 0.5402, Accuracy: 0.5521\n","Epoch 70, Train Loss: 0.9345, Val Loss: 1.6415, F1 Micro: 0.5208, F1 Macro: 0.5112, Accuracy: 0.5208\n","Epoch 71, Train Loss: 0.9422, Val Loss: 1.6850, F1 Micro: 0.5312, F1 Macro: 0.5270, Accuracy: 0.5312\n","Epoch 72, Train Loss: 1.0009, Val Loss: 1.5058, F1 Micro: 0.5104, F1 Macro: 0.5134, Accuracy: 0.5104\n","Epoch 73, Train Loss: 1.0067, Val Loss: 2.3500, F1 Micro: 0.3854, F1 Macro: 0.3235, Accuracy: 0.3854\n","Epoch 74, Train Loss: 0.9674, Val Loss: 1.9445, F1 Micro: 0.4688, F1 Macro: 0.4395, Accuracy: 0.4688\n","Epoch 75, Train Loss: 1.0237, Val Loss: 1.7783, F1 Micro: 0.3438, F1 Macro: 0.3435, Accuracy: 0.3438\n","Epoch 76, Train Loss: 1.0793, Val Loss: 2.2929, F1 Micro: 0.4583, F1 Macro: 0.4280, Accuracy: 0.4583\n","Epoch 77, Train Loss: 1.0714, Val Loss: 2.4926, F1 Micro: 0.2812, F1 Macro: 0.2248, Accuracy: 0.2812\n","Epoch 78, Train Loss: 0.9669, Val Loss: 1.4008, F1 Micro: 0.4896, F1 Macro: 0.4784, Accuracy: 0.4896\n","Epoch 79, Train Loss: 0.9172, Val Loss: 1.6429, F1 Micro: 0.5417, F1 Macro: 0.5121, Accuracy: 0.5417\n","Epoch 80, Train Loss: 0.9880, Val Loss: 2.2426, F1 Micro: 0.3021, F1 Macro: 0.2631, Accuracy: 0.3021\n","Epoch 81, Train Loss: 1.0097, Val Loss: 2.3827, F1 Micro: 0.4062, F1 Macro: 0.4072, Accuracy: 0.4062\n","Epoch 82, Train Loss: 0.9508, Val Loss: 1.8578, F1 Micro: 0.4688, F1 Macro: 0.4453, Accuracy: 0.4688\n","Epoch 83, Train Loss: 0.9165, Val Loss: 1.5181, F1 Micro: 0.4688, F1 Macro: 0.4573, Accuracy: 0.4688\n","Epoch 84, Train Loss: 0.9703, Val Loss: 1.6576, F1 Micro: 0.5729, F1 Macro: 0.5596, Accuracy: 0.5729\n","Epoch 85, Train Loss: 0.9171, Val Loss: 1.6290, F1 Micro: 0.4583, F1 Macro: 0.4368, Accuracy: 0.4583\n","Epoch 86, Train Loss: 0.9494, Val Loss: 1.7265, F1 Micro: 0.4792, F1 Macro: 0.4693, Accuracy: 0.4792\n","Epoch 87, Train Loss: 0.9835, Val Loss: 1.9389, F1 Micro: 0.4375, F1 Macro: 0.4055, Accuracy: 0.4375\n","Epoch 88, Train Loss: 0.9672, Val Loss: 2.1720, F1 Micro: 0.4062, F1 Macro: 0.3626, Accuracy: 0.4062\n","Epoch 89, Train Loss: 1.0431, Val Loss: 1.6753, F1 Micro: 0.5312, F1 Macro: 0.4905, Accuracy: 0.5312\n","Epoch 90, Train Loss: 0.8312, Val Loss: 1.8671, F1 Micro: 0.3854, F1 Macro: 0.3609, Accuracy: 0.3854\n","Epoch 91, Train Loss: 0.9347, Val Loss: 2.5395, F1 Micro: 0.3333, F1 Macro: 0.2722, Accuracy: 0.3333\n","Epoch 92, Train Loss: 0.8374, Val Loss: 1.5945, F1 Micro: 0.4688, F1 Macro: 0.4605, Accuracy: 0.4688\n","Epoch 93, Train Loss: 0.8289, Val Loss: 1.7480, F1 Micro: 0.5104, F1 Macro: 0.4845, Accuracy: 0.5104\n","Epoch 94, Train Loss: 0.9073, Val Loss: 2.3606, F1 Micro: 0.3542, F1 Macro: 0.3243, Accuracy: 0.3542\n","Epoch 95, Train Loss: 0.9002, Val Loss: 1.6566, F1 Micro: 0.5000, F1 Macro: 0.4829, Accuracy: 0.5000\n","Epoch 96, Train Loss: 0.8647, Val Loss: 1.6129, F1 Micro: 0.5208, F1 Macro: 0.5149, Accuracy: 0.5208\n","Epoch 97, Train Loss: 0.9356, Val Loss: 1.8432, F1 Micro: 0.4479, F1 Macro: 0.4385, Accuracy: 0.4479\n","Epoch 98, Train Loss: 0.8495, Val Loss: 2.2784, F1 Micro: 0.3958, F1 Macro: 0.3694, Accuracy: 0.3958\n","Epoch 99, Train Loss: 0.9206, Val Loss: 1.6981, F1 Micro: 0.4896, F1 Macro: 0.5007, Accuracy: 0.4896\n","Epoch 100, Train Loss: 0.9005, Val Loss: 1.7177, F1 Micro: 0.5208, F1 Macro: 0.5462, Accuracy: 0.5208\n","Epoch 101, Train Loss: 0.8708, Val Loss: 1.7552, F1 Micro: 0.5312, F1 Macro: 0.5000, Accuracy: 0.5312\n","Epoch 102, Train Loss: 0.7330, Val Loss: 1.4331, F1 Micro: 0.6042, F1 Macro: 0.6054, Accuracy: 0.6042\n","Epoch 103, Train Loss: 0.7574, Val Loss: 1.5991, F1 Micro: 0.5625, F1 Macro: 0.5510, Accuracy: 0.5625\n","Epoch 104, Train Loss: 0.7673, Val Loss: 1.7520, F1 Micro: 0.5000, F1 Macro: 0.4858, Accuracy: 0.5000\n","Epoch 105, Train Loss: 0.8242, Val Loss: 1.7914, F1 Micro: 0.5417, F1 Macro: 0.5328, Accuracy: 0.5417\n","Epoch 106, Train Loss: 0.8212, Val Loss: 1.5480, F1 Micro: 0.5208, F1 Macro: 0.5228, Accuracy: 0.5208\n","Epoch 107, Train Loss: 0.8051, Val Loss: 2.0994, F1 Micro: 0.4375, F1 Macro: 0.4513, Accuracy: 0.4375\n","Epoch 108, Train Loss: 0.8740, Val Loss: 1.8549, F1 Micro: 0.4479, F1 Macro: 0.4192, Accuracy: 0.4479\n","Epoch 109, Train Loss: 0.8360, Val Loss: 2.2676, F1 Micro: 0.4167, F1 Macro: 0.3706, Accuracy: 0.4167\n","Epoch 110, Train Loss: 0.8012, Val Loss: 2.0955, F1 Micro: 0.5312, F1 Macro: 0.5058, Accuracy: 0.5312\n","Epoch 111, Train Loss: 0.7870, Val Loss: 1.5808, F1 Micro: 0.5312, F1 Macro: 0.5496, Accuracy: 0.5312\n","Epoch 112, Train Loss: 0.8180, Val Loss: 1.6504, F1 Micro: 0.5938, F1 Macro: 0.5746, Accuracy: 0.5938\n","Epoch 113, Train Loss: 0.9673, Val Loss: 2.1020, F1 Micro: 0.3958, F1 Macro: 0.3873, Accuracy: 0.3958\n","Epoch 114, Train Loss: 0.8373, Val Loss: 1.4788, F1 Micro: 0.5417, F1 Macro: 0.5484, Accuracy: 0.5417\n","Epoch 115, Train Loss: 0.7912, Val Loss: 2.1543, F1 Micro: 0.4688, F1 Macro: 0.4528, Accuracy: 0.4688\n","Epoch 116, Train Loss: 0.7548, Val Loss: 1.5535, F1 Micro: 0.5521, F1 Macro: 0.5545, Accuracy: 0.5521\n","Epoch 117, Train Loss: 0.8172, Val Loss: 2.2988, F1 Micro: 0.5104, F1 Macro: 0.4860, Accuracy: 0.5104\n","Epoch 118, Train Loss: 0.8709, Val Loss: 1.5211, F1 Micro: 0.6042, F1 Macro: 0.6118, Accuracy: 0.6042\n","Epoch 119, Train Loss: 0.7401, Val Loss: 1.4989, F1 Micro: 0.6042, F1 Macro: 0.5954, Accuracy: 0.6042\n","Epoch 120, Train Loss: 0.8053, Val Loss: 1.8049, F1 Micro: 0.5104, F1 Macro: 0.5100, Accuracy: 0.5104\n","Epoch 121, Train Loss: 0.7133, Val Loss: 1.7634, F1 Micro: 0.4896, F1 Macro: 0.4711, Accuracy: 0.4896\n","Epoch 122, Train Loss: 0.7577, Val Loss: 1.6581, F1 Micro: 0.5833, F1 Macro: 0.5715, Accuracy: 0.5833\n","Epoch 123, Train Loss: 0.8126, Val Loss: 2.5973, F1 Micro: 0.5208, F1 Macro: 0.5173, Accuracy: 0.5208\n","Epoch 124, Train Loss: 0.8472, Val Loss: 1.5641, F1 Micro: 0.5625, F1 Macro: 0.5645, Accuracy: 0.5625\n","Epoch 125, Train Loss: 0.6651, Val Loss: 1.5482, F1 Micro: 0.5833, F1 Macro: 0.5905, Accuracy: 0.5833\n","Epoch 126, Train Loss: 0.9571, Val Loss: 2.3935, F1 Micro: 0.4479, F1 Macro: 0.4528, Accuracy: 0.4479\n","Epoch 127, Train Loss: 0.7267, Val Loss: 1.7745, F1 Micro: 0.5104, F1 Macro: 0.4711, Accuracy: 0.5104\n","Epoch 128, Train Loss: 0.6774, Val Loss: 1.6699, F1 Micro: 0.5729, F1 Macro: 0.5784, Accuracy: 0.5729\n","Epoch 129, Train Loss: 0.6728, Val Loss: 1.5721, F1 Micro: 0.5208, F1 Macro: 0.5150, Accuracy: 0.5208\n","Epoch 130, Train Loss: 0.6483, Val Loss: 1.7165, F1 Micro: 0.5208, F1 Macro: 0.5005, Accuracy: 0.5208\n","Epoch 131, Train Loss: 0.7062, Val Loss: 1.7401, F1 Micro: 0.5729, F1 Macro: 0.5655, Accuracy: 0.5729\n","Epoch 132, Train Loss: 0.7386, Val Loss: 2.0463, F1 Micro: 0.4896, F1 Macro: 0.4476, Accuracy: 0.4896\n","Epoch 133, Train Loss: 0.8405, Val Loss: 2.4721, F1 Micro: 0.4583, F1 Macro: 0.4491, Accuracy: 0.4583\n","Epoch 134, Train Loss: 0.7938, Val Loss: 1.5046, F1 Micro: 0.6354, F1 Macro: 0.6246, Accuracy: 0.6354\n","Epoch 135, Train Loss: 0.6729, Val Loss: 1.4588, F1 Micro: 0.5417, F1 Macro: 0.5232, Accuracy: 0.5417\n","Epoch 136, Train Loss: 0.7192, Val Loss: 1.9506, F1 Micro: 0.5208, F1 Macro: 0.5162, Accuracy: 0.5208\n","Epoch 137, Train Loss: 0.7717, Val Loss: 1.4583, F1 Micro: 0.5208, F1 Macro: 0.5145, Accuracy: 0.5208\n","Epoch 138, Train Loss: 0.7976, Val Loss: 3.0162, F1 Micro: 0.3958, F1 Macro: 0.3594, Accuracy: 0.3958\n","Epoch 139, Train Loss: 0.7429, Val Loss: 1.9210, F1 Micro: 0.5000, F1 Macro: 0.4689, Accuracy: 0.5000\n","Epoch 140, Train Loss: 0.6685, Val Loss: 1.4936, F1 Micro: 0.6458, F1 Macro: 0.6470, Accuracy: 0.6458\n","Epoch 141, Train Loss: 0.6165, Val Loss: 1.5624, F1 Micro: 0.6250, F1 Macro: 0.6190, Accuracy: 0.6250\n","Epoch 142, Train Loss: 0.7351, Val Loss: 2.4069, F1 Micro: 0.3646, F1 Macro: 0.3650, Accuracy: 0.3646\n","Epoch 143, Train Loss: 0.6762, Val Loss: 1.6936, F1 Micro: 0.5833, F1 Macro: 0.5808, Accuracy: 0.5833\n","Epoch 144, Train Loss: 0.7974, Val Loss: 1.9081, F1 Micro: 0.4896, F1 Macro: 0.4947, Accuracy: 0.4896\n","Epoch 145, Train Loss: 0.7208, Val Loss: 1.7329, F1 Micro: 0.4688, F1 Macro: 0.4467, Accuracy: 0.4688\n","Epoch 146, Train Loss: 0.7184, Val Loss: 1.5926, F1 Micro: 0.5625, F1 Macro: 0.5770, Accuracy: 0.5625\n","Epoch 147, Train Loss: 0.6690, Val Loss: 2.0998, F1 Micro: 0.4479, F1 Macro: 0.4489, Accuracy: 0.4479\n","Epoch 148, Train Loss: 0.6913, Val Loss: 1.6030, F1 Micro: 0.6458, F1 Macro: 0.6447, Accuracy: 0.6458\n","Epoch 149, Train Loss: 0.7146, Val Loss: 1.7054, F1 Micro: 0.5312, F1 Macro: 0.5375, Accuracy: 0.5312\n","Epoch 150, Train Loss: 0.7648, Val Loss: 2.2543, F1 Micro: 0.4479, F1 Macro: 0.4246, Accuracy: 0.4479\n","Epoch 151, Train Loss: 0.7899, Val Loss: 1.9100, F1 Micro: 0.4896, F1 Macro: 0.4951, Accuracy: 0.4896\n","Epoch 152, Train Loss: 0.8146, Val Loss: 1.6105, F1 Micro: 0.5938, F1 Macro: 0.5794, Accuracy: 0.5938\n","Epoch 153, Train Loss: 0.6648, Val Loss: 1.8997, F1 Micro: 0.5312, F1 Macro: 0.5010, Accuracy: 0.5312\n","Epoch 154, Train Loss: 0.6600, Val Loss: 2.5597, F1 Micro: 0.4583, F1 Macro: 0.4684, Accuracy: 0.4583\n","Epoch 155, Train Loss: 0.7247, Val Loss: 1.9970, F1 Micro: 0.4896, F1 Macro: 0.4785, Accuracy: 0.4896\n","Epoch 156, Train Loss: 0.6808, Val Loss: 2.4492, F1 Micro: 0.4375, F1 Macro: 0.4483, Accuracy: 0.4375\n","Epoch 157, Train Loss: 0.6534, Val Loss: 2.3055, F1 Micro: 0.4688, F1 Macro: 0.4321, Accuracy: 0.4688\n","Epoch 158, Train Loss: 0.6668, Val Loss: 1.5810, F1 Micro: 0.6354, F1 Macro: 0.6257, Accuracy: 0.6354\n","Epoch 159, Train Loss: 0.8773, Val Loss: 3.1742, F1 Micro: 0.3021, F1 Macro: 0.2902, Accuracy: 0.3021\n","Epoch 160, Train Loss: 0.7668, Val Loss: 1.9461, F1 Micro: 0.4583, F1 Macro: 0.4521, Accuracy: 0.4583\n","Epoch 161, Train Loss: 0.6769, Val Loss: 1.7119, F1 Micro: 0.5312, F1 Macro: 0.5507, Accuracy: 0.5312\n","Epoch 162, Train Loss: 0.6167, Val Loss: 1.6788, F1 Micro: 0.5521, F1 Macro: 0.5569, Accuracy: 0.5521\n","Epoch 163, Train Loss: 0.6420, Val Loss: 1.6097, F1 Micro: 0.6458, F1 Macro: 0.6516, Accuracy: 0.6458\n","Epoch 164, Train Loss: 0.6117, Val Loss: 1.7227, F1 Micro: 0.5521, F1 Macro: 0.5629, Accuracy: 0.5521\n","Epoch 165, Train Loss: 0.6253, Val Loss: 2.2943, F1 Micro: 0.5521, F1 Macro: 0.5073, Accuracy: 0.5521\n","Epoch 166, Train Loss: 0.6427, Val Loss: 1.6384, F1 Micro: 0.5938, F1 Macro: 0.5935, Accuracy: 0.5938\n","Epoch 167, Train Loss: 0.6153, Val Loss: 1.8962, F1 Micro: 0.5833, F1 Macro: 0.5874, Accuracy: 0.5833\n","Epoch 168, Train Loss: 0.6488, Val Loss: 1.6568, F1 Micro: 0.5833, F1 Macro: 0.5763, Accuracy: 0.5833\n","Epoch 169, Train Loss: 0.6152, Val Loss: 1.9556, F1 Micro: 0.5312, F1 Macro: 0.5067, Accuracy: 0.5312\n","Epoch 170, Train Loss: 0.6016, Val Loss: 2.1517, F1 Micro: 0.4583, F1 Macro: 0.4431, Accuracy: 0.4583\n","Epoch 171, Train Loss: 0.5746, Val Loss: 1.6539, F1 Micro: 0.6250, F1 Macro: 0.6237, Accuracy: 0.6250\n","Epoch 172, Train Loss: 0.6122, Val Loss: 2.1153, F1 Micro: 0.5000, F1 Macro: 0.4948, Accuracy: 0.5000\n","Epoch 173, Train Loss: 0.5302, Val Loss: 1.7127, F1 Micro: 0.5625, F1 Macro: 0.5526, Accuracy: 0.5625\n","Epoch 174, Train Loss: 0.7181, Val Loss: 2.5802, F1 Micro: 0.4271, F1 Macro: 0.4038, Accuracy: 0.4271\n","Epoch 175, Train Loss: 0.7095, Val Loss: 3.0708, F1 Micro: 0.3646, F1 Macro: 0.3180, Accuracy: 0.3646\n","Epoch 176, Train Loss: 0.7527, Val Loss: 1.6399, F1 Micro: 0.5729, F1 Macro: 0.5805, Accuracy: 0.5729\n","Epoch 177, Train Loss: 0.5910, Val Loss: 1.7433, F1 Micro: 0.6042, F1 Macro: 0.6066, Accuracy: 0.6042\n","Epoch 178, Train Loss: 0.6033, Val Loss: 1.7714, F1 Micro: 0.5625, F1 Macro: 0.5630, Accuracy: 0.5625\n","Epoch 179, Train Loss: 0.6373, Val Loss: 1.8263, F1 Micro: 0.5833, F1 Macro: 0.5903, Accuracy: 0.5833\n","Epoch 180, Train Loss: 0.5628, Val Loss: 1.7570, F1 Micro: 0.5833, F1 Macro: 0.5857, Accuracy: 0.5833\n","Epoch 181, Train Loss: 0.5904, Val Loss: 2.0754, F1 Micro: 0.4688, F1 Macro: 0.4647, Accuracy: 0.4688\n","Epoch 182, Train Loss: 0.6125, Val Loss: 1.4464, F1 Micro: 0.5729, F1 Macro: 0.5804, Accuracy: 0.5729\n","Epoch 183, Train Loss: 0.5992, Val Loss: 2.1007, F1 Micro: 0.4688, F1 Macro: 0.4881, Accuracy: 0.4688\n","Epoch 184, Train Loss: 0.5979, Val Loss: 2.8662, F1 Micro: 0.4167, F1 Macro: 0.4170, Accuracy: 0.4167\n","Epoch 185, Train Loss: 0.8052, Val Loss: 1.9498, F1 Micro: 0.5521, F1 Macro: 0.5368, Accuracy: 0.5521\n","Epoch 186, Train Loss: 0.6028, Val Loss: 1.9255, F1 Micro: 0.5312, F1 Macro: 0.5432, Accuracy: 0.5312\n","Epoch 187, Train Loss: 0.5179, Val Loss: 1.5391, F1 Micro: 0.6250, F1 Macro: 0.6295, Accuracy: 0.6250\n","Epoch 188, Train Loss: 0.5934, Val Loss: 2.0466, F1 Micro: 0.5417, F1 Macro: 0.5339, Accuracy: 0.5417\n","Epoch 189, Train Loss: 0.4985, Val Loss: 1.9735, F1 Micro: 0.6458, F1 Macro: 0.6225, Accuracy: 0.6458\n","Epoch 190, Train Loss: 0.6009, Val Loss: 2.3918, F1 Micro: 0.3750, F1 Macro: 0.3341, Accuracy: 0.3750\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.1482, Val Loss: 1.7842, F1 Micro: 0.2812, F1 Macro: 0.2349, Accuracy: 0.2812\n","Epoch 2, Train Loss: 1.8289, Val Loss: 1.9601, F1 Micro: 0.2292, F1 Macro: 0.1546, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.7647, Val Loss: 1.7436, F1 Micro: 0.2917, F1 Macro: 0.2512, Accuracy: 0.2917\n","Epoch 4, Train Loss: 1.7179, Val Loss: 1.6952, F1 Micro: 0.3021, F1 Macro: 0.2501, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.7233, Val Loss: 1.7636, F1 Micro: 0.2812, F1 Macro: 0.2202, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.6312, Val Loss: 1.8552, F1 Micro: 0.3438, F1 Macro: 0.2794, Accuracy: 0.3438\n","Epoch 7, Train Loss: 1.6618, Val Loss: 1.7170, F1 Micro: 0.3438, F1 Macro: 0.3035, Accuracy: 0.3438\n","Epoch 8, Train Loss: 1.5723, Val Loss: 1.9720, F1 Micro: 0.2917, F1 Macro: 0.2362, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.6431, Val Loss: 1.7676, F1 Micro: 0.3021, F1 Macro: 0.2415, Accuracy: 0.3021\n","Epoch 10, Train Loss: 1.5817, Val Loss: 1.7589, F1 Micro: 0.4167, F1 Macro: 0.3661, Accuracy: 0.4167\n","Epoch 11, Train Loss: 1.5778, Val Loss: 1.8259, F1 Micro: 0.3229, F1 Macro: 0.2460, Accuracy: 0.3229\n","Epoch 12, Train Loss: 1.5192, Val Loss: 1.9364, F1 Micro: 0.3229, F1 Macro: 0.3036, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.5384, Val Loss: 1.6679, F1 Micro: 0.3958, F1 Macro: 0.3776, Accuracy: 0.3958\n","Epoch 14, Train Loss: 1.4868, Val Loss: 1.8072, F1 Micro: 0.2917, F1 Macro: 0.2395, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.4628, Val Loss: 1.7995, F1 Micro: 0.3542, F1 Macro: 0.2588, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.4375, Val Loss: 1.9167, F1 Micro: 0.2917, F1 Macro: 0.2464, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.4782, Val Loss: 1.9699, F1 Micro: 0.2708, F1 Macro: 0.2133, Accuracy: 0.2708\n","Epoch 18, Train Loss: 1.4841, Val Loss: 1.7883, F1 Micro: 0.3542, F1 Macro: 0.2885, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.4657, Val Loss: 1.9098, F1 Micro: 0.3125, F1 Macro: 0.3129, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.4544, Val Loss: 1.7271, F1 Micro: 0.4271, F1 Macro: 0.4165, Accuracy: 0.4271\n","Epoch 21, Train Loss: 1.4106, Val Loss: 1.6162, F1 Micro: 0.4167, F1 Macro: 0.4063, Accuracy: 0.4167\n","Epoch 22, Train Loss: 1.3988, Val Loss: 1.6589, F1 Micro: 0.4583, F1 Macro: 0.3931, Accuracy: 0.4583\n","Epoch 23, Train Loss: 1.3295, Val Loss: 1.6310, F1 Micro: 0.3854, F1 Macro: 0.3793, Accuracy: 0.3854\n","Epoch 24, Train Loss: 1.4817, Val Loss: 1.6123, F1 Micro: 0.4062, F1 Macro: 0.3969, Accuracy: 0.4062\n","Epoch 25, Train Loss: 1.3898, Val Loss: 2.0167, F1 Micro: 0.3854, F1 Macro: 0.3483, Accuracy: 0.3854\n","Epoch 26, Train Loss: 1.4105, Val Loss: 1.7793, F1 Micro: 0.3542, F1 Macro: 0.3195, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.2984, Val Loss: 1.7529, F1 Micro: 0.4271, F1 Macro: 0.3979, Accuracy: 0.4271\n","Epoch 28, Train Loss: 1.3660, Val Loss: 1.7875, F1 Micro: 0.4062, F1 Macro: 0.3445, Accuracy: 0.4062\n","Epoch 29, Train Loss: 1.3998, Val Loss: 1.6129, F1 Micro: 0.4167, F1 Macro: 0.3928, Accuracy: 0.4167\n","Epoch 30, Train Loss: 1.3384, Val Loss: 2.2913, F1 Micro: 0.3958, F1 Macro: 0.3449, Accuracy: 0.3958\n","Epoch 31, Train Loss: 1.3605, Val Loss: 1.9232, F1 Micro: 0.4062, F1 Macro: 0.3602, Accuracy: 0.4062\n","Epoch 32, Train Loss: 1.3371, Val Loss: 2.3889, F1 Micro: 0.2917, F1 Macro: 0.2044, Accuracy: 0.2917\n","Epoch 33, Train Loss: 1.2851, Val Loss: 1.6472, F1 Micro: 0.4479, F1 Macro: 0.4057, Accuracy: 0.4479\n","Epoch 34, Train Loss: 1.2709, Val Loss: 1.6924, F1 Micro: 0.4271, F1 Macro: 0.3968, Accuracy: 0.4271\n","Epoch 35, Train Loss: 1.2528, Val Loss: 1.8335, F1 Micro: 0.3958, F1 Macro: 0.3630, Accuracy: 0.3958\n","Epoch 36, Train Loss: 1.2205, Val Loss: 1.9691, F1 Micro: 0.4792, F1 Macro: 0.4464, Accuracy: 0.4792\n","Epoch 37, Train Loss: 1.2211, Val Loss: 1.5769, F1 Micro: 0.4271, F1 Macro: 0.4282, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.2556, Val Loss: 1.6819, F1 Micro: 0.3958, F1 Macro: 0.3830, Accuracy: 0.3958\n","Epoch 39, Train Loss: 1.2476, Val Loss: 2.6610, F1 Micro: 0.3229, F1 Macro: 0.2533, Accuracy: 0.3229\n","Epoch 40, Train Loss: 1.2940, Val Loss: 1.5655, F1 Micro: 0.4896, F1 Macro: 0.4759, Accuracy: 0.4896\n","Epoch 41, Train Loss: 1.2885, Val Loss: 1.8183, F1 Micro: 0.3958, F1 Macro: 0.3738, Accuracy: 0.3958\n","Epoch 42, Train Loss: 1.2418, Val Loss: 1.8626, F1 Micro: 0.3750, F1 Macro: 0.3828, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.1597, Val Loss: 1.5699, F1 Micro: 0.4688, F1 Macro: 0.4620, Accuracy: 0.4688\n","Epoch 44, Train Loss: 1.2016, Val Loss: 1.6719, F1 Micro: 0.4375, F1 Macro: 0.4067, Accuracy: 0.4375\n","Epoch 45, Train Loss: 1.1607, Val Loss: 3.0109, F1 Micro: 0.3021, F1 Macro: 0.2284, Accuracy: 0.3021\n","Epoch 46, Train Loss: 1.2261, Val Loss: 2.0628, F1 Micro: 0.3854, F1 Macro: 0.3650, Accuracy: 0.3854\n","Epoch 47, Train Loss: 1.1201, Val Loss: 1.5583, F1 Micro: 0.5312, F1 Macro: 0.5257, Accuracy: 0.5312\n","Epoch 48, Train Loss: 1.1460, Val Loss: 1.8523, F1 Micro: 0.4167, F1 Macro: 0.3729, Accuracy: 0.4167\n","Epoch 49, Train Loss: 1.1837, Val Loss: 1.7186, F1 Micro: 0.5208, F1 Macro: 0.5271, Accuracy: 0.5208\n","Epoch 50, Train Loss: 1.1580, Val Loss: 1.6615, F1 Micro: 0.5208, F1 Macro: 0.4976, Accuracy: 0.5208\n","Epoch 51, Train Loss: 1.0772, Val Loss: 1.6427, F1 Micro: 0.5104, F1 Macro: 0.4876, Accuracy: 0.5104\n","Epoch 52, Train Loss: 1.1142, Val Loss: 1.5442, F1 Micro: 0.5417, F1 Macro: 0.5391, Accuracy: 0.5417\n","Epoch 53, Train Loss: 1.1815, Val Loss: 2.1778, F1 Micro: 0.3438, F1 Macro: 0.2905, Accuracy: 0.3438\n","Epoch 54, Train Loss: 1.1845, Val Loss: 1.6230, F1 Micro: 0.5104, F1 Macro: 0.5257, Accuracy: 0.5104\n","Epoch 55, Train Loss: 1.0468, Val Loss: 1.5792, F1 Micro: 0.4271, F1 Macro: 0.4336, Accuracy: 0.4271\n","Epoch 56, Train Loss: 1.1084, Val Loss: 2.0266, F1 Micro: 0.3854, F1 Macro: 0.3701, Accuracy: 0.3854\n","Epoch 57, Train Loss: 0.9994, Val Loss: 2.0776, F1 Micro: 0.3438, F1 Macro: 0.2882, Accuracy: 0.3438\n","Epoch 58, Train Loss: 1.1757, Val Loss: 1.6319, F1 Micro: 0.5000, F1 Macro: 0.4899, Accuracy: 0.5000\n","Epoch 59, Train Loss: 1.1582, Val Loss: 2.0170, F1 Micro: 0.4688, F1 Macro: 0.4449, Accuracy: 0.4688\n","Epoch 60, Train Loss: 1.2392, Val Loss: 1.7480, F1 Micro: 0.4271, F1 Macro: 0.4161, Accuracy: 0.4271\n","Epoch 61, Train Loss: 1.0575, Val Loss: 1.6536, F1 Micro: 0.5000, F1 Macro: 0.4600, Accuracy: 0.5000\n","Epoch 62, Train Loss: 1.0630, Val Loss: 1.5335, F1 Micro: 0.5521, F1 Macro: 0.5466, Accuracy: 0.5521\n","Epoch 63, Train Loss: 1.0452, Val Loss: 1.9170, F1 Micro: 0.5104, F1 Macro: 0.4925, Accuracy: 0.5104\n","Epoch 64, Train Loss: 0.9751, Val Loss: 1.7860, F1 Micro: 0.5417, F1 Macro: 0.5538, Accuracy: 0.5417\n","Epoch 65, Train Loss: 1.0107, Val Loss: 1.4722, F1 Micro: 0.5938, F1 Macro: 0.5918, Accuracy: 0.5938\n","Epoch 66, Train Loss: 0.9690, Val Loss: 1.8924, F1 Micro: 0.5208, F1 Macro: 0.4808, Accuracy: 0.5208\n","Epoch 67, Train Loss: 1.0794, Val Loss: 1.6015, F1 Micro: 0.5833, F1 Macro: 0.5782, Accuracy: 0.5833\n","Epoch 68, Train Loss: 0.9525, Val Loss: 1.5945, F1 Micro: 0.4792, F1 Macro: 0.4758, Accuracy: 0.4792\n","Epoch 69, Train Loss: 0.9814, Val Loss: 1.5081, F1 Micro: 0.5729, F1 Macro: 0.5468, Accuracy: 0.5729\n","Epoch 70, Train Loss: 1.0254, Val Loss: 1.6188, F1 Micro: 0.5521, F1 Macro: 0.5067, Accuracy: 0.5521\n","Epoch 71, Train Loss: 0.9428, Val Loss: 1.8857, F1 Micro: 0.5625, F1 Macro: 0.5603, Accuracy: 0.5625\n","Epoch 72, Train Loss: 0.9249, Val Loss: 2.4425, F1 Micro: 0.4896, F1 Macro: 0.4736, Accuracy: 0.4896\n","Epoch 73, Train Loss: 0.9665, Val Loss: 2.2040, F1 Micro: 0.3646, F1 Macro: 0.3557, Accuracy: 0.3646\n","Epoch 74, Train Loss: 1.0891, Val Loss: 2.1823, F1 Micro: 0.4479, F1 Macro: 0.4090, Accuracy: 0.4479\n","Epoch 75, Train Loss: 1.1292, Val Loss: 1.9829, F1 Micro: 0.4062, F1 Macro: 0.3497, Accuracy: 0.4062\n","Epoch 76, Train Loss: 1.0912, Val Loss: 1.6714, F1 Micro: 0.5000, F1 Macro: 0.5029, Accuracy: 0.5000\n","Epoch 77, Train Loss: 1.0571, Val Loss: 1.6857, F1 Micro: 0.5625, F1 Macro: 0.5539, Accuracy: 0.5625\n","Epoch 78, Train Loss: 0.9689, Val Loss: 1.9827, F1 Micro: 0.4583, F1 Macro: 0.4254, Accuracy: 0.4583\n","Epoch 79, Train Loss: 0.9523, Val Loss: 1.6599, F1 Micro: 0.4271, F1 Macro: 0.3844, Accuracy: 0.4271\n","Epoch 80, Train Loss: 0.9353, Val Loss: 1.4526, F1 Micro: 0.5312, F1 Macro: 0.5178, Accuracy: 0.5312\n","Epoch 81, Train Loss: 0.9506, Val Loss: 1.8891, F1 Micro: 0.4479, F1 Macro: 0.4051, Accuracy: 0.4479\n","Epoch 82, Train Loss: 0.9055, Val Loss: 1.5606, F1 Micro: 0.5625, F1 Macro: 0.5580, Accuracy: 0.5625\n","Epoch 83, Train Loss: 0.8497, Val Loss: 1.9976, F1 Micro: 0.5104, F1 Macro: 0.4978, Accuracy: 0.5104\n","Epoch 84, Train Loss: 1.0281, Val Loss: 1.7618, F1 Micro: 0.4688, F1 Macro: 0.4857, Accuracy: 0.4688\n","Epoch 85, Train Loss: 0.9959, Val Loss: 2.0306, F1 Micro: 0.4688, F1 Macro: 0.4515, Accuracy: 0.4688\n","Epoch 86, Train Loss: 0.9654, Val Loss: 1.9549, F1 Micro: 0.4062, F1 Macro: 0.3877, Accuracy: 0.4062\n","Epoch 87, Train Loss: 1.0005, Val Loss: 1.4808, F1 Micro: 0.6146, F1 Macro: 0.6129, Accuracy: 0.6146\n","Epoch 88, Train Loss: 0.9758, Val Loss: 1.6175, F1 Micro: 0.5104, F1 Macro: 0.4836, Accuracy: 0.5104\n","Epoch 89, Train Loss: 0.9228, Val Loss: 1.5160, F1 Micro: 0.6250, F1 Macro: 0.6216, Accuracy: 0.6250\n","Epoch 90, Train Loss: 0.9294, Val Loss: 2.0666, F1 Micro: 0.5104, F1 Macro: 0.4962, Accuracy: 0.5104\n","Epoch 91, Train Loss: 0.9585, Val Loss: 1.4069, F1 Micro: 0.6146, F1 Macro: 0.6150, Accuracy: 0.6146\n","Epoch 92, Train Loss: 0.9051, Val Loss: 1.4880, F1 Micro: 0.5521, F1 Macro: 0.5628, Accuracy: 0.5521\n","Epoch 93, Train Loss: 0.8353, Val Loss: 1.4442, F1 Micro: 0.5938, F1 Macro: 0.5915, Accuracy: 0.5938\n","Epoch 94, Train Loss: 0.9249, Val Loss: 1.4942, F1 Micro: 0.6250, F1 Macro: 0.6152, Accuracy: 0.6250\n","Epoch 95, Train Loss: 0.8215, Val Loss: 1.5911, F1 Micro: 0.5521, F1 Macro: 0.5034, Accuracy: 0.5521\n","Epoch 96, Train Loss: 0.8530, Val Loss: 1.4967, F1 Micro: 0.6042, F1 Macro: 0.6005, Accuracy: 0.6042\n","Epoch 97, Train Loss: 0.8458, Val Loss: 1.4350, F1 Micro: 0.5521, F1 Macro: 0.5478, Accuracy: 0.5521\n","Epoch 98, Train Loss: 0.8599, Val Loss: 1.7898, F1 Micro: 0.5208, F1 Macro: 0.5225, Accuracy: 0.5208\n","Epoch 99, Train Loss: 0.9690, Val Loss: 1.6470, F1 Micro: 0.5521, F1 Macro: 0.5494, Accuracy: 0.5521\n","Epoch 100, Train Loss: 0.9388, Val Loss: 2.2399, F1 Micro: 0.4792, F1 Macro: 0.4300, Accuracy: 0.4792\n","Epoch 101, Train Loss: 0.9880, Val Loss: 1.6822, F1 Micro: 0.5417, F1 Macro: 0.5192, Accuracy: 0.5417\n","Epoch 102, Train Loss: 0.9133, Val Loss: 1.6161, F1 Micro: 0.5312, F1 Macro: 0.5065, Accuracy: 0.5312\n","Epoch 103, Train Loss: 0.8925, Val Loss: 1.4389, F1 Micro: 0.5625, F1 Macro: 0.5627, Accuracy: 0.5625\n","Epoch 104, Train Loss: 0.8856, Val Loss: 1.6954, F1 Micro: 0.5521, F1 Macro: 0.5197, Accuracy: 0.5521\n","Epoch 105, Train Loss: 0.9089, Val Loss: 1.4909, F1 Micro: 0.5417, F1 Macro: 0.5245, Accuracy: 0.5417\n","Epoch 106, Train Loss: 0.8775, Val Loss: 1.6883, F1 Micro: 0.5521, F1 Macro: 0.5302, Accuracy: 0.5521\n","Epoch 107, Train Loss: 0.8083, Val Loss: 1.6059, F1 Micro: 0.5625, F1 Macro: 0.5244, Accuracy: 0.5625\n","Epoch 108, Train Loss: 0.7830, Val Loss: 1.6374, F1 Micro: 0.5417, F1 Macro: 0.5367, Accuracy: 0.5417\n","Epoch 109, Train Loss: 0.8079, Val Loss: 1.7119, F1 Micro: 0.5625, F1 Macro: 0.5354, Accuracy: 0.5625\n","Epoch 110, Train Loss: 0.8252, Val Loss: 1.7324, F1 Micro: 0.5521, F1 Macro: 0.5400, Accuracy: 0.5521\n","Epoch 111, Train Loss: 0.7518, Val Loss: 1.5510, F1 Micro: 0.5833, F1 Macro: 0.5776, Accuracy: 0.5833\n","Epoch 112, Train Loss: 0.7762, Val Loss: 2.0723, F1 Micro: 0.4062, F1 Macro: 0.3980, Accuracy: 0.4062\n","Epoch 113, Train Loss: 0.8348, Val Loss: 1.5422, F1 Micro: 0.5104, F1 Macro: 0.5230, Accuracy: 0.5104\n","Epoch 114, Train Loss: 0.7368, Val Loss: 1.7050, F1 Micro: 0.4896, F1 Macro: 0.4897, Accuracy: 0.4896\n","Epoch 115, Train Loss: 0.7547, Val Loss: 1.5000, F1 Micro: 0.6354, F1 Macro: 0.6216, Accuracy: 0.6354\n","Epoch 116, Train Loss: 0.7127, Val Loss: 1.4740, F1 Micro: 0.5729, F1 Macro: 0.5644, Accuracy: 0.5729\n","Epoch 117, Train Loss: 0.8327, Val Loss: 1.6165, F1 Micro: 0.5833, F1 Macro: 0.5677, Accuracy: 0.5833\n","Epoch 118, Train Loss: 0.6970, Val Loss: 1.8672, F1 Micro: 0.6146, F1 Macro: 0.5895, Accuracy: 0.6146\n","Epoch 119, Train Loss: 0.7142, Val Loss: 2.0262, F1 Micro: 0.5000, F1 Macro: 0.4985, Accuracy: 0.5000\n","Epoch 120, Train Loss: 0.8116, Val Loss: 1.8097, F1 Micro: 0.6042, F1 Macro: 0.5975, Accuracy: 0.6042\n","Epoch 121, Train Loss: 0.8699, Val Loss: 2.5924, F1 Micro: 0.4688, F1 Macro: 0.4599, Accuracy: 0.4688\n","Epoch 122, Train Loss: 0.8121, Val Loss: 2.1481, F1 Micro: 0.5000, F1 Macro: 0.4821, Accuracy: 0.5000\n","Epoch 123, Train Loss: 0.7238, Val Loss: 1.7270, F1 Micro: 0.5521, F1 Macro: 0.5417, Accuracy: 0.5521\n","Epoch 124, Train Loss: 0.8687, Val Loss: 2.0798, F1 Micro: 0.4583, F1 Macro: 0.4479, Accuracy: 0.4583\n","Epoch 125, Train Loss: 0.7483, Val Loss: 1.7857, F1 Micro: 0.5521, F1 Macro: 0.5433, Accuracy: 0.5521\n","Epoch 126, Train Loss: 0.7300, Val Loss: 1.5376, F1 Micro: 0.6354, F1 Macro: 0.6408, Accuracy: 0.6354\n","Epoch 127, Train Loss: 0.7239, Val Loss: 1.6681, F1 Micro: 0.5833, F1 Macro: 0.5758, Accuracy: 0.5833\n","Epoch 128, Train Loss: 0.7576, Val Loss: 1.7151, F1 Micro: 0.5729, F1 Macro: 0.5625, Accuracy: 0.5729\n","Epoch 129, Train Loss: 0.8527, Val Loss: 1.9271, F1 Micro: 0.5938, F1 Macro: 0.5904, Accuracy: 0.5938\n","Epoch 130, Train Loss: 0.7626, Val Loss: 1.9438, F1 Micro: 0.4896, F1 Macro: 0.4540, Accuracy: 0.4896\n","Epoch 131, Train Loss: 0.7093, Val Loss: 1.6199, F1 Micro: 0.6250, F1 Macro: 0.6000, Accuracy: 0.6250\n","Epoch 132, Train Loss: 0.7133, Val Loss: 1.5378, F1 Micro: 0.6562, F1 Macro: 0.6626, Accuracy: 0.6562\n","Epoch 133, Train Loss: 0.6745, Val Loss: 1.7767, F1 Micro: 0.6042, F1 Macro: 0.5869, Accuracy: 0.6042\n","Epoch 134, Train Loss: 0.7378, Val Loss: 1.5925, F1 Micro: 0.6146, F1 Macro: 0.5968, Accuracy: 0.6146\n","Epoch 135, Train Loss: 0.5691, Val Loss: 1.7084, F1 Micro: 0.5104, F1 Macro: 0.4939, Accuracy: 0.5104\n","Epoch 136, Train Loss: 0.6642, Val Loss: 1.8986, F1 Micro: 0.5521, F1 Macro: 0.4873, Accuracy: 0.5521\n","Epoch 137, Train Loss: 0.7998, Val Loss: 1.8669, F1 Micro: 0.5625, F1 Macro: 0.5642, Accuracy: 0.5625\n","Epoch 138, Train Loss: 0.7403, Val Loss: 1.7127, F1 Micro: 0.5521, F1 Macro: 0.5603, Accuracy: 0.5521\n","Epoch 139, Train Loss: 0.7357, Val Loss: 1.6739, F1 Micro: 0.5938, F1 Macro: 0.5802, Accuracy: 0.5938\n","Epoch 140, Train Loss: 0.6094, Val Loss: 1.5575, F1 Micro: 0.6250, F1 Macro: 0.6015, Accuracy: 0.6250\n","Epoch 141, Train Loss: 0.6029, Val Loss: 1.4092, F1 Micro: 0.6250, F1 Macro: 0.6047, Accuracy: 0.6250\n","Epoch 142, Train Loss: 0.6728, Val Loss: 3.1538, F1 Micro: 0.4167, F1 Macro: 0.3939, Accuracy: 0.4167\n","Epoch 143, Train Loss: 0.6661, Val Loss: 2.6677, F1 Micro: 0.4167, F1 Macro: 0.3761, Accuracy: 0.4167\n","Epoch 144, Train Loss: 0.8335, Val Loss: 1.6660, F1 Micro: 0.5000, F1 Macro: 0.4720, Accuracy: 0.5000\n","Epoch 145, Train Loss: 0.7674, Val Loss: 1.5248, F1 Micro: 0.5833, F1 Macro: 0.5874, Accuracy: 0.5833\n","Epoch 146, Train Loss: 0.7376, Val Loss: 1.6092, F1 Micro: 0.5625, F1 Macro: 0.5573, Accuracy: 0.5625\n","Epoch 147, Train Loss: 0.7442, Val Loss: 1.8207, F1 Micro: 0.5208, F1 Macro: 0.4734, Accuracy: 0.5208\n","Epoch 148, Train Loss: 0.8343, Val Loss: 1.8710, F1 Micro: 0.5938, F1 Macro: 0.5784, Accuracy: 0.5938\n","Epoch 149, Train Loss: 0.8030, Val Loss: 1.7082, F1 Micro: 0.5521, F1 Macro: 0.5394, Accuracy: 0.5521\n","Epoch 150, Train Loss: 0.8296, Val Loss: 1.5439, F1 Micro: 0.6042, F1 Macro: 0.6036, Accuracy: 0.6042\n","Epoch 151, Train Loss: 0.8070, Val Loss: 1.9404, F1 Micro: 0.5521, F1 Macro: 0.5341, Accuracy: 0.5521\n","Epoch 152, Train Loss: 0.6791, Val Loss: 1.4931, F1 Micro: 0.5833, F1 Macro: 0.5585, Accuracy: 0.5833\n","Epoch 153, Train Loss: 0.7181, Val Loss: 1.3716, F1 Micro: 0.5938, F1 Macro: 0.5905, Accuracy: 0.5938\n","Epoch 154, Train Loss: 0.6922, Val Loss: 2.0204, F1 Micro: 0.4792, F1 Macro: 0.4445, Accuracy: 0.4792\n","Epoch 155, Train Loss: 0.6159, Val Loss: 2.0026, F1 Micro: 0.5208, F1 Macro: 0.5326, Accuracy: 0.5208\n","Epoch 156, Train Loss: 0.6025, Val Loss: 1.7538, F1 Micro: 0.5521, F1 Macro: 0.5527, Accuracy: 0.5521\n","Epoch 157, Train Loss: 0.7036, Val Loss: 1.8563, F1 Micro: 0.5625, F1 Macro: 0.5549, Accuracy: 0.5625\n","Epoch 158, Train Loss: 0.6818, Val Loss: 1.4323, F1 Micro: 0.5833, F1 Macro: 0.5644, Accuracy: 0.5833\n","Epoch 159, Train Loss: 0.6353, Val Loss: 1.5886, F1 Micro: 0.5625, F1 Macro: 0.5537, Accuracy: 0.5625\n","Epoch 160, Train Loss: 0.6414, Val Loss: 1.6707, F1 Micro: 0.6146, F1 Macro: 0.6234, Accuracy: 0.6146\n","Epoch 161, Train Loss: 0.6923, Val Loss: 1.6201, F1 Micro: 0.6146, F1 Macro: 0.5866, Accuracy: 0.6146\n","Epoch 162, Train Loss: 0.6533, Val Loss: 2.1729, F1 Micro: 0.5208, F1 Macro: 0.5049, Accuracy: 0.5208\n","Epoch 163, Train Loss: 0.7054, Val Loss: 1.5996, F1 Micro: 0.6042, F1 Macro: 0.6119, Accuracy: 0.6042\n","Epoch 164, Train Loss: 0.5922, Val Loss: 1.4097, F1 Micro: 0.6146, F1 Macro: 0.6135, Accuracy: 0.6146\n","Epoch 165, Train Loss: 0.6765, Val Loss: 2.3778, F1 Micro: 0.5312, F1 Macro: 0.5327, Accuracy: 0.5312\n","Epoch 166, Train Loss: 0.6697, Val Loss: 1.4034, F1 Micro: 0.6146, F1 Macro: 0.6095, Accuracy: 0.6146\n","Epoch 167, Train Loss: 0.6135, Val Loss: 1.2858, F1 Micro: 0.6354, F1 Macro: 0.6364, Accuracy: 0.6354\n","Epoch 168, Train Loss: 0.6506, Val Loss: 1.6258, F1 Micro: 0.6042, F1 Macro: 0.5829, Accuracy: 0.6042\n","Epoch 169, Train Loss: 0.6705, Val Loss: 1.4832, F1 Micro: 0.6042, F1 Macro: 0.5769, Accuracy: 0.6042\n","Epoch 170, Train Loss: 0.6475, Val Loss: 1.7822, F1 Micro: 0.6354, F1 Macro: 0.6103, Accuracy: 0.6354\n","Epoch 171, Train Loss: 0.6447, Val Loss: 1.7022, F1 Micro: 0.6562, F1 Macro: 0.6496, Accuracy: 0.6562\n","Epoch 172, Train Loss: 0.5722, Val Loss: 1.5922, F1 Micro: 0.6042, F1 Macro: 0.5960, Accuracy: 0.6042\n","Epoch 173, Train Loss: 0.5731, Val Loss: 1.5526, F1 Micro: 0.6250, F1 Macro: 0.6131, Accuracy: 0.6250\n","Epoch 174, Train Loss: 0.6457, Val Loss: 1.6559, F1 Micro: 0.6354, F1 Macro: 0.6277, Accuracy: 0.6354\n","Epoch 175, Train Loss: 0.5604, Val Loss: 1.8630, F1 Micro: 0.5625, F1 Macro: 0.5328, Accuracy: 0.5625\n","Epoch 176, Train Loss: 0.5522, Val Loss: 1.8632, F1 Micro: 0.6875, F1 Macro: 0.6838, Accuracy: 0.6875\n","Epoch 177, Train Loss: 0.6476, Val Loss: 1.8456, F1 Micro: 0.6458, F1 Macro: 0.6332, Accuracy: 0.6458\n","Epoch 178, Train Loss: 0.5853, Val Loss: 2.2013, F1 Micro: 0.5417, F1 Macro: 0.5496, Accuracy: 0.5417\n","Epoch 179, Train Loss: 0.5935, Val Loss: 1.4439, F1 Micro: 0.6562, F1 Macro: 0.6495, Accuracy: 0.6562\n","Epoch 180, Train Loss: 0.5291, Val Loss: 1.8987, F1 Micro: 0.5521, F1 Macro: 0.5289, Accuracy: 0.5521\n","Epoch 181, Train Loss: 0.5257, Val Loss: 1.6609, F1 Micro: 0.6042, F1 Macro: 0.6093, Accuracy: 0.6042\n","Epoch 182, Train Loss: 0.5145, Val Loss: 1.7292, F1 Micro: 0.5938, F1 Macro: 0.5812, Accuracy: 0.5938\n","Epoch 183, Train Loss: 0.5943, Val Loss: 2.2201, F1 Micro: 0.5938, F1 Macro: 0.5635, Accuracy: 0.5938\n","Epoch 184, Train Loss: 0.6656, Val Loss: 1.6465, F1 Micro: 0.6146, F1 Macro: 0.6022, Accuracy: 0.6146\n","Epoch 185, Train Loss: 0.6392, Val Loss: 1.6801, F1 Micro: 0.6042, F1 Macro: 0.5849, Accuracy: 0.6042\n","Epoch 186, Train Loss: 0.6421, Val Loss: 1.7864, F1 Micro: 0.6146, F1 Macro: 0.6117, Accuracy: 0.6146\n","Epoch 187, Train Loss: 0.6409, Val Loss: 1.5960, F1 Micro: 0.6042, F1 Macro: 0.6020, Accuracy: 0.6042\n","Epoch 188, Train Loss: 0.5805, Val Loss: 1.7578, F1 Micro: 0.5833, F1 Macro: 0.5811, Accuracy: 0.5833\n","Epoch 189, Train Loss: 0.6910, Val Loss: 2.0521, F1 Micro: 0.4792, F1 Macro: 0.4530, Accuracy: 0.4792\n","Epoch 190, Train Loss: 0.6703, Val Loss: 1.6861, F1 Micro: 0.5521, F1 Macro: 0.5424, Accuracy: 0.5521\n","Epoch 191, Train Loss: 0.5437, Val Loss: 1.7271, F1 Micro: 0.5833, F1 Macro: 0.6021, Accuracy: 0.5833\n","Epoch 192, Train Loss: 0.6456, Val Loss: 1.8113, F1 Micro: 0.6146, F1 Macro: 0.6004, Accuracy: 0.6146\n","Epoch 193, Train Loss: 0.5632, Val Loss: 1.8616, F1 Micro: 0.5312, F1 Macro: 0.5032, Accuracy: 0.5312\n","Epoch 194, Train Loss: 0.6725, Val Loss: 3.9356, F1 Micro: 0.5521, F1 Macro: 0.5191, Accuracy: 0.5521\n","Epoch 195, Train Loss: 0.7592, Val Loss: 2.0008, F1 Micro: 0.5521, F1 Macro: 0.5441, Accuracy: 0.5521\n","Epoch 196, Train Loss: 0.6021, Val Loss: 1.3710, F1 Micro: 0.5833, F1 Macro: 0.5702, Accuracy: 0.5833\n","Epoch 197, Train Loss: 0.6960, Val Loss: 1.7325, F1 Micro: 0.6250, F1 Macro: 0.6153, Accuracy: 0.6250\n","Epoch 198, Train Loss: 0.7874, Val Loss: 1.8176, F1 Micro: 0.5833, F1 Macro: 0.5817, Accuracy: 0.5833\n","Epoch 199, Train Loss: 0.7382, Val Loss: 1.9151, F1 Micro: 0.5208, F1 Macro: 0.4817, Accuracy: 0.5208\n","Epoch 200, Train Loss: 0.6376, Val Loss: 1.7057, F1 Micro: 0.6146, F1 Macro: 0.6138, Accuracy: 0.6146\n","Average Score for hyperparameters (0.01, 8, 50): 0.6270833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 2.1554, Val Loss: 2.1106, F1 Micro: 0.1979, F1 Macro: 0.1131, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.8202, Val Loss: 2.0578, F1 Micro: 0.2812, F1 Macro: 0.2521, Accuracy: 0.2812\n","Epoch 3, Train Loss: 1.7707, Val Loss: 1.9985, F1 Micro: 0.2708, F1 Macro: 0.2091, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.6777, Val Loss: 2.0785, F1 Micro: 0.2396, F1 Macro: 0.2072, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.6597, Val Loss: 1.7331, F1 Micro: 0.3438, F1 Macro: 0.2987, Accuracy: 0.3438\n","Epoch 6, Train Loss: 1.6658, Val Loss: 1.8222, F1 Micro: 0.3229, F1 Macro: 0.2960, Accuracy: 0.3229\n","Epoch 7, Train Loss: 1.6156, Val Loss: 1.6928, F1 Micro: 0.3125, F1 Macro: 0.2708, Accuracy: 0.3125\n","Epoch 8, Train Loss: 1.6041, Val Loss: 1.7405, F1 Micro: 0.3229, F1 Macro: 0.2901, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.5344, Val Loss: 1.8411, F1 Micro: 0.3229, F1 Macro: 0.2727, Accuracy: 0.3229\n","Epoch 10, Train Loss: 1.5210, Val Loss: 2.6594, F1 Micro: 0.2396, F1 Macro: 0.1909, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.4933, Val Loss: 2.8410, F1 Micro: 0.1979, F1 Macro: 0.1378, Accuracy: 0.1979\n","Epoch 12, Train Loss: 1.4879, Val Loss: 1.7931, F1 Micro: 0.3021, F1 Macro: 0.2927, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.4408, Val Loss: 1.7574, F1 Micro: 0.3021, F1 Macro: 0.2626, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.4334, Val Loss: 2.2155, F1 Micro: 0.2396, F1 Macro: 0.1989, Accuracy: 0.2396\n","Epoch 15, Train Loss: 1.4300, Val Loss: 1.8059, F1 Micro: 0.3854, F1 Macro: 0.3849, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.4035, Val Loss: 1.7668, F1 Micro: 0.3438, F1 Macro: 0.3110, Accuracy: 0.3438\n","Epoch 17, Train Loss: 1.4127, Val Loss: 1.9551, F1 Micro: 0.3542, F1 Macro: 0.2894, Accuracy: 0.3542\n","Epoch 18, Train Loss: 1.3027, Val Loss: 2.0638, F1 Micro: 0.2812, F1 Macro: 0.2719, Accuracy: 0.2812\n","Epoch 19, Train Loss: 1.3564, Val Loss: 2.0002, F1 Micro: 0.2708, F1 Macro: 0.2533, Accuracy: 0.2708\n","Epoch 20, Train Loss: 1.3241, Val Loss: 1.9189, F1 Micro: 0.3333, F1 Macro: 0.2694, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.3173, Val Loss: 1.8100, F1 Micro: 0.3750, F1 Macro: 0.3554, Accuracy: 0.3750\n","Epoch 22, Train Loss: 1.2654, Val Loss: 1.7363, F1 Micro: 0.3542, F1 Macro: 0.3094, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.2717, Val Loss: 1.6941, F1 Micro: 0.3958, F1 Macro: 0.3695, Accuracy: 0.3958\n","Epoch 24, Train Loss: 1.2411, Val Loss: 2.0273, F1 Micro: 0.4062, F1 Macro: 0.3404, Accuracy: 0.4062\n","Epoch 25, Train Loss: 1.2629, Val Loss: 2.2179, F1 Micro: 0.3438, F1 Macro: 0.2702, Accuracy: 0.3438\n","Epoch 26, Train Loss: 1.2480, Val Loss: 1.7138, F1 Micro: 0.4271, F1 Macro: 0.4364, Accuracy: 0.4271\n","Epoch 27, Train Loss: 1.2051, Val Loss: 4.0332, F1 Micro: 0.1875, F1 Macro: 0.1218, Accuracy: 0.1875\n","Epoch 28, Train Loss: 1.2290, Val Loss: 2.2544, F1 Micro: 0.3333, F1 Macro: 0.2992, Accuracy: 0.3333\n","Epoch 29, Train Loss: 1.2507, Val Loss: 1.9416, F1 Micro: 0.3854, F1 Macro: 0.3524, Accuracy: 0.3854\n","Epoch 30, Train Loss: 1.2170, Val Loss: 2.0799, F1 Micro: 0.3542, F1 Macro: 0.3366, Accuracy: 0.3542\n","Epoch 31, Train Loss: 1.1973, Val Loss: 2.4627, F1 Micro: 0.3542, F1 Macro: 0.3121, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.1708, Val Loss: 2.4302, F1 Micro: 0.3333, F1 Macro: 0.2956, Accuracy: 0.3333\n","Epoch 33, Train Loss: 1.1778, Val Loss: 2.5205, F1 Micro: 0.2708, F1 Macro: 0.2710, Accuracy: 0.2708\n","Epoch 34, Train Loss: 1.1174, Val Loss: 2.5432, F1 Micro: 0.3750, F1 Macro: 0.3217, Accuracy: 0.3750\n","Epoch 35, Train Loss: 1.0930, Val Loss: 1.9944, F1 Micro: 0.2604, F1 Macro: 0.2197, Accuracy: 0.2604\n","Epoch 36, Train Loss: 1.0394, Val Loss: 2.2330, F1 Micro: 0.4062, F1 Macro: 0.4051, Accuracy: 0.4062\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.9943, Val Loss: 2.5888, F1 Micro: 0.2500, F1 Macro: 0.1184, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.8150, Val Loss: 1.8691, F1 Micro: 0.2917, F1 Macro: 0.1464, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.7958, Val Loss: 1.8945, F1 Micro: 0.2292, F1 Macro: 0.1655, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.6874, Val Loss: 1.8703, F1 Micro: 0.2396, F1 Macro: 0.1815, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.6994, Val Loss: 2.0619, F1 Micro: 0.3229, F1 Macro: 0.2878, Accuracy: 0.3229\n","Epoch 6, Train Loss: 1.6482, Val Loss: 1.9075, F1 Micro: 0.3125, F1 Macro: 0.2313, Accuracy: 0.3125\n","Epoch 7, Train Loss: 1.6630, Val Loss: 1.7956, F1 Micro: 0.2083, F1 Macro: 0.1705, Accuracy: 0.2083\n","Epoch 8, Train Loss: 1.6146, Val Loss: 1.9083, F1 Micro: 0.2917, F1 Macro: 0.1995, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.6590, Val Loss: 1.9209, F1 Micro: 0.2604, F1 Macro: 0.2306, Accuracy: 0.2604\n","Epoch 10, Train Loss: 1.5681, Val Loss: 1.6265, F1 Micro: 0.4271, F1 Macro: 0.3526, Accuracy: 0.4271\n","Epoch 11, Train Loss: 1.5890, Val Loss: 1.6478, F1 Micro: 0.3542, F1 Macro: 0.2848, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.5056, Val Loss: 2.0306, F1 Micro: 0.2917, F1 Macro: 0.2728, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.5418, Val Loss: 1.8514, F1 Micro: 0.2917, F1 Macro: 0.2068, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.4889, Val Loss: 1.9063, F1 Micro: 0.2708, F1 Macro: 0.2289, Accuracy: 0.2708\n","Epoch 15, Train Loss: 1.5025, Val Loss: 3.0664, F1 Micro: 0.2083, F1 Macro: 0.1841, Accuracy: 0.2083\n","Epoch 16, Train Loss: 1.5184, Val Loss: 2.0894, F1 Micro: 0.3438, F1 Macro: 0.2944, Accuracy: 0.3438\n","Epoch 17, Train Loss: 1.5293, Val Loss: 1.8397, F1 Micro: 0.3333, F1 Macro: 0.3228, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.4626, Val Loss: 2.2855, F1 Micro: 0.3021, F1 Macro: 0.2698, Accuracy: 0.3021\n","Epoch 19, Train Loss: 1.4044, Val Loss: 1.6522, F1 Micro: 0.4479, F1 Macro: 0.3892, Accuracy: 0.4479\n","Epoch 20, Train Loss: 1.4155, Val Loss: 1.7497, F1 Micro: 0.3438, F1 Macro: 0.2963, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.3609, Val Loss: 1.5667, F1 Micro: 0.4062, F1 Macro: 0.3407, Accuracy: 0.4062\n","Epoch 22, Train Loss: 1.3266, Val Loss: 1.6946, F1 Micro: 0.3542, F1 Macro: 0.3031, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.3320, Val Loss: 1.9908, F1 Micro: 0.2708, F1 Macro: 0.2458, Accuracy: 0.2708\n","Epoch 24, Train Loss: 1.3512, Val Loss: 1.6942, F1 Micro: 0.3854, F1 Macro: 0.3787, Accuracy: 0.3854\n","Epoch 25, Train Loss: 1.3088, Val Loss: 1.7133, F1 Micro: 0.4792, F1 Macro: 0.4413, Accuracy: 0.4792\n","Epoch 26, Train Loss: 1.3754, Val Loss: 1.9539, F1 Micro: 0.3750, F1 Macro: 0.3012, Accuracy: 0.3750\n","Epoch 27, Train Loss: 1.3847, Val Loss: 1.6070, F1 Micro: 0.4688, F1 Macro: 0.4385, Accuracy: 0.4688\n","Epoch 28, Train Loss: 1.2641, Val Loss: 2.9078, F1 Micro: 0.2604, F1 Macro: 0.2075, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.3130, Val Loss: 1.4581, F1 Micro: 0.5000, F1 Macro: 0.4897, Accuracy: 0.5000\n","Epoch 30, Train Loss: 1.2594, Val Loss: 2.5838, F1 Micro: 0.3125, F1 Macro: 0.2994, Accuracy: 0.3125\n","Epoch 31, Train Loss: 1.2899, Val Loss: 1.5740, F1 Micro: 0.4271, F1 Macro: 0.4040, Accuracy: 0.4271\n","Epoch 32, Train Loss: 1.2393, Val Loss: 1.6804, F1 Micro: 0.4271, F1 Macro: 0.4029, Accuracy: 0.4271\n","Epoch 33, Train Loss: 1.2130, Val Loss: 1.6324, F1 Micro: 0.3542, F1 Macro: 0.3704, Accuracy: 0.3542\n","Epoch 34, Train Loss: 1.2103, Val Loss: 1.5975, F1 Micro: 0.4479, F1 Macro: 0.4010, Accuracy: 0.4479\n","Epoch 35, Train Loss: 1.2111, Val Loss: 2.3202, F1 Micro: 0.2708, F1 Macro: 0.2782, Accuracy: 0.2708\n","Epoch 36, Train Loss: 1.1975, Val Loss: 1.6282, F1 Micro: 0.4062, F1 Macro: 0.3563, Accuracy: 0.4062\n","Epoch 37, Train Loss: 1.1573, Val Loss: 1.5716, F1 Micro: 0.4271, F1 Macro: 0.4002, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.0990, Val Loss: 2.2604, F1 Micro: 0.3229, F1 Macro: 0.2639, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.2298, Val Loss: 2.7437, F1 Micro: 0.3333, F1 Macro: 0.2549, Accuracy: 0.3333\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 2.0485, Val Loss: 2.0880, F1 Micro: 0.2292, F1 Macro: 0.0797, Accuracy: 0.2292\n","Epoch 2, Train Loss: 1.9657, Val Loss: 1.9367, F1 Micro: 0.2188, F1 Macro: 0.1796, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7550, Val Loss: 1.9839, F1 Micro: 0.2083, F1 Macro: 0.1352, Accuracy: 0.2083\n","Epoch 4, Train Loss: 1.6677, Val Loss: 1.8921, F1 Micro: 0.2708, F1 Macro: 0.2188, Accuracy: 0.2708\n","Epoch 5, Train Loss: 1.6301, Val Loss: 2.1657, F1 Micro: 0.2083, F1 Macro: 0.1299, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.6411, Val Loss: 1.8285, F1 Micro: 0.2812, F1 Macro: 0.2765, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.5392, Val Loss: 1.8655, F1 Micro: 0.2812, F1 Macro: 0.2213, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6107, Val Loss: 2.1522, F1 Micro: 0.2292, F1 Macro: 0.1239, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.6163, Val Loss: 2.0894, F1 Micro: 0.2500, F1 Macro: 0.2137, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.5484, Val Loss: 2.1914, F1 Micro: 0.2396, F1 Macro: 0.1122, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.5895, Val Loss: 1.7190, F1 Micro: 0.3542, F1 Macro: 0.2694, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.5167, Val Loss: 1.8357, F1 Micro: 0.3750, F1 Macro: 0.3556, Accuracy: 0.3750\n","Epoch 13, Train Loss: 1.5278, Val Loss: 1.7840, F1 Micro: 0.3542, F1 Macro: 0.3145, Accuracy: 0.3542\n","Epoch 14, Train Loss: 1.4670, Val Loss: 1.7590, F1 Micro: 0.4062, F1 Macro: 0.2971, Accuracy: 0.4062\n","Epoch 15, Train Loss: 1.4160, Val Loss: 1.9160, F1 Micro: 0.3542, F1 Macro: 0.3182, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5623, Val Loss: 2.2955, F1 Micro: 0.3021, F1 Macro: 0.2487, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.4274, Val Loss: 1.8369, F1 Micro: 0.3333, F1 Macro: 0.2434, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.4162, Val Loss: 2.5878, F1 Micro: 0.1979, F1 Macro: 0.1981, Accuracy: 0.1979\n","Epoch 19, Train Loss: 1.4042, Val Loss: 2.1010, F1 Micro: 0.3438, F1 Macro: 0.2678, Accuracy: 0.3438\n","Epoch 20, Train Loss: 1.3802, Val Loss: 1.8228, F1 Micro: 0.3646, F1 Macro: 0.2712, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.3807, Val Loss: 2.0193, F1 Micro: 0.2917, F1 Macro: 0.2346, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.3700, Val Loss: 1.6518, F1 Micro: 0.3750, F1 Macro: 0.2825, Accuracy: 0.3750\n","Epoch 23, Train Loss: 1.3332, Val Loss: 1.6197, F1 Micro: 0.4271, F1 Macro: 0.3236, Accuracy: 0.4271\n","Epoch 24, Train Loss: 1.3486, Val Loss: 1.8560, F1 Micro: 0.4062, F1 Macro: 0.3490, Accuracy: 0.4062\n","Epoch 25, Train Loss: 1.3347, Val Loss: 1.5625, F1 Micro: 0.4479, F1 Macro: 0.3839, Accuracy: 0.4479\n","Epoch 26, Train Loss: 1.3418, Val Loss: 2.0588, F1 Micro: 0.3542, F1 Macro: 0.2548, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.3566, Val Loss: 1.5180, F1 Micro: 0.4583, F1 Macro: 0.3325, Accuracy: 0.4583\n","Epoch 28, Train Loss: 1.3274, Val Loss: 1.8688, F1 Micro: 0.3854, F1 Macro: 0.3367, Accuracy: 0.3854\n","Epoch 29, Train Loss: 1.3381, Val Loss: 1.8990, F1 Micro: 0.3542, F1 Macro: 0.2514, Accuracy: 0.3542\n","Epoch 30, Train Loss: 1.2896, Val Loss: 1.4956, F1 Micro: 0.5000, F1 Macro: 0.4475, Accuracy: 0.5000\n","Epoch 31, Train Loss: 1.2634, Val Loss: 1.5627, F1 Micro: 0.5312, F1 Macro: 0.4371, Accuracy: 0.5312\n","Epoch 32, Train Loss: 1.2747, Val Loss: 1.6305, F1 Micro: 0.4375, F1 Macro: 0.3915, Accuracy: 0.4375\n","Epoch 33, Train Loss: 1.2397, Val Loss: 2.1081, F1 Micro: 0.3854, F1 Macro: 0.3107, Accuracy: 0.3854\n","Epoch 34, Train Loss: 1.2623, Val Loss: 2.0159, F1 Micro: 0.3958, F1 Macro: 0.3239, Accuracy: 0.3958\n","Epoch 35, Train Loss: 1.2106, Val Loss: 1.4711, F1 Micro: 0.4896, F1 Macro: 0.4677, Accuracy: 0.4896\n","Epoch 36, Train Loss: 1.2376, Val Loss: 1.7507, F1 Micro: 0.4062, F1 Macro: 0.3566, Accuracy: 0.4062\n","Epoch 37, Train Loss: 1.2935, Val Loss: 1.5641, F1 Micro: 0.4792, F1 Macro: 0.3966, Accuracy: 0.4792\n","Epoch 38, Train Loss: 1.2338, Val Loss: 1.6398, F1 Micro: 0.3958, F1 Macro: 0.3269, Accuracy: 0.3958\n","Epoch 39, Train Loss: 1.1476, Val Loss: 1.7190, F1 Micro: 0.4375, F1 Macro: 0.3608, Accuracy: 0.4375\n","Epoch 40, Train Loss: 1.1987, Val Loss: 1.6196, F1 Micro: 0.3958, F1 Macro: 0.3505, Accuracy: 0.3958\n","Epoch 41, Train Loss: 1.1666, Val Loss: 2.3470, F1 Micro: 0.3021, F1 Macro: 0.2154, Accuracy: 0.3021\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 2.0293, Val Loss: 2.6938, F1 Micro: 0.1979, F1 Macro: 0.0987, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.8572, Val Loss: 2.2209, F1 Micro: 0.1979, F1 Macro: 0.1120, Accuracy: 0.1979\n","Epoch 3, Train Loss: 1.8817, Val Loss: 2.0483, F1 Micro: 0.2292, F1 Macro: 0.1884, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.7182, Val Loss: 1.7737, F1 Micro: 0.2708, F1 Macro: 0.2122, Accuracy: 0.2708\n","Epoch 5, Train Loss: 1.7119, Val Loss: 2.0424, F1 Micro: 0.2292, F1 Macro: 0.1509, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.6233, Val Loss: 1.7750, F1 Micro: 0.3333, F1 Macro: 0.2605, Accuracy: 0.3333\n","Epoch 7, Train Loss: 1.6232, Val Loss: 2.0759, F1 Micro: 0.2083, F1 Macro: 0.1313, Accuracy: 0.2083\n","Epoch 8, Train Loss: 1.6433, Val Loss: 1.9299, F1 Micro: 0.2396, F1 Macro: 0.1892, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.5615, Val Loss: 2.5031, F1 Micro: 0.2292, F1 Macro: 0.1963, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.5054, Val Loss: 1.8216, F1 Micro: 0.3229, F1 Macro: 0.2645, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.5924, Val Loss: 1.9986, F1 Micro: 0.3125, F1 Macro: 0.2584, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.5990, Val Loss: 2.0339, F1 Micro: 0.2708, F1 Macro: 0.2156, Accuracy: 0.2708\n","Epoch 13, Train Loss: 1.4988, Val Loss: 1.6050, F1 Micro: 0.3646, F1 Macro: 0.3314, Accuracy: 0.3646\n","Epoch 14, Train Loss: 1.4814, Val Loss: 1.6526, F1 Micro: 0.3229, F1 Macro: 0.3229, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.4821, Val Loss: 2.8942, F1 Micro: 0.1979, F1 Macro: 0.1027, Accuracy: 0.1979\n","Epoch 16, Train Loss: 1.4881, Val Loss: 1.6538, F1 Micro: 0.3750, F1 Macro: 0.3438, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.4619, Val Loss: 1.6473, F1 Micro: 0.3021, F1 Macro: 0.2692, Accuracy: 0.3021\n","Epoch 18, Train Loss: 1.3854, Val Loss: 1.5785, F1 Micro: 0.3646, F1 Macro: 0.3737, Accuracy: 0.3646\n","Epoch 19, Train Loss: 1.4052, Val Loss: 1.9798, F1 Micro: 0.2604, F1 Macro: 0.2045, Accuracy: 0.2604\n","Epoch 20, Train Loss: 1.4711, Val Loss: 2.0254, F1 Micro: 0.2917, F1 Macro: 0.2287, Accuracy: 0.2917\n","Epoch 21, Train Loss: 1.5028, Val Loss: 1.7980, F1 Micro: 0.3333, F1 Macro: 0.3225, Accuracy: 0.3333\n","Epoch 22, Train Loss: 1.3558, Val Loss: 1.7784, F1 Micro: 0.3125, F1 Macro: 0.2738, Accuracy: 0.3125\n","Epoch 23, Train Loss: 1.3894, Val Loss: 1.6381, F1 Micro: 0.4375, F1 Macro: 0.4087, Accuracy: 0.4375\n","Epoch 24, Train Loss: 1.4358, Val Loss: 2.4402, F1 Micro: 0.2708, F1 Macro: 0.1966, Accuracy: 0.2708\n","Epoch 25, Train Loss: 1.4400, Val Loss: 1.8328, F1 Micro: 0.3229, F1 Macro: 0.2573, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.3739, Val Loss: 1.8441, F1 Micro: 0.2812, F1 Macro: 0.2391, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.2950, Val Loss: 1.6447, F1 Micro: 0.4271, F1 Macro: 0.4050, Accuracy: 0.4271\n","Epoch 28, Train Loss: 1.3134, Val Loss: 1.8984, F1 Micro: 0.3646, F1 Macro: 0.3281, Accuracy: 0.3646\n","Epoch 29, Train Loss: 1.2778, Val Loss: 1.9972, F1 Micro: 0.2708, F1 Macro: 0.2136, Accuracy: 0.2708\n","Epoch 30, Train Loss: 1.3188, Val Loss: 4.4997, F1 Micro: 0.1979, F1 Macro: 0.1068, Accuracy: 0.1979\n","Epoch 31, Train Loss: 1.2441, Val Loss: 1.6836, F1 Micro: 0.4167, F1 Macro: 0.3770, Accuracy: 0.4167\n","Epoch 32, Train Loss: 1.2623, Val Loss: 1.8879, F1 Micro: 0.3854, F1 Macro: 0.3330, Accuracy: 0.3854\n","Epoch 33, Train Loss: 1.2670, Val Loss: 1.6519, F1 Micro: 0.4479, F1 Macro: 0.4062, Accuracy: 0.4479\n","Epoch 34, Train Loss: 1.2863, Val Loss: 1.8738, F1 Micro: 0.3229, F1 Macro: 0.2744, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.2573, Val Loss: 2.0535, F1 Micro: 0.3542, F1 Macro: 0.3217, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.3622, Val Loss: 1.6045, F1 Micro: 0.3958, F1 Macro: 0.3912, Accuracy: 0.3958\n","Epoch 37, Train Loss: 1.3010, Val Loss: 2.1015, F1 Micro: 0.3333, F1 Macro: 0.2775, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.3103, Val Loss: 2.5297, F1 Micro: 0.1771, F1 Macro: 0.1145, Accuracy: 0.1771\n","Epoch 39, Train Loss: 1.2499, Val Loss: 2.1493, F1 Micro: 0.3646, F1 Macro: 0.3068, Accuracy: 0.3646\n","Epoch 40, Train Loss: 1.2646, Val Loss: 1.6408, F1 Micro: 0.4479, F1 Macro: 0.4173, Accuracy: 0.4479\n","Epoch 41, Train Loss: 1.2674, Val Loss: 1.7097, F1 Micro: 0.4062, F1 Macro: 0.3680, Accuracy: 0.4062\n","Epoch 42, Train Loss: 1.1867, Val Loss: 2.0686, F1 Micro: 0.4062, F1 Macro: 0.3464, Accuracy: 0.4062\n","Epoch 43, Train Loss: 1.2339, Val Loss: 1.9715, F1 Micro: 0.4062, F1 Macro: 0.3783, Accuracy: 0.4062\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 2.1480, Val Loss: 1.7824, F1 Micro: 0.2708, F1 Macro: 0.1894, Accuracy: 0.2708\n","Epoch 2, Train Loss: 1.8758, Val Loss: 1.9320, F1 Micro: 0.1562, F1 Macro: 0.1303, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7548, Val Loss: 1.8215, F1 Micro: 0.2604, F1 Macro: 0.2224, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.6697, Val Loss: 2.0344, F1 Micro: 0.2604, F1 Macro: 0.1472, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.6662, Val Loss: 1.8040, F1 Micro: 0.3125, F1 Macro: 0.2734, Accuracy: 0.3125\n","Epoch 6, Train Loss: 1.6266, Val Loss: 1.8001, F1 Micro: 0.3229, F1 Macro: 0.2879, Accuracy: 0.3229\n","Epoch 7, Train Loss: 1.6025, Val Loss: 1.8041, F1 Micro: 0.2708, F1 Macro: 0.2029, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.6374, Val Loss: 2.0494, F1 Micro: 0.3125, F1 Macro: 0.2469, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.5476, Val Loss: 1.8226, F1 Micro: 0.2708, F1 Macro: 0.2846, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.5132, Val Loss: 1.6871, F1 Micro: 0.3542, F1 Macro: 0.3019, Accuracy: 0.3542\n","Epoch 11, Train Loss: 1.5071, Val Loss: 1.8433, F1 Micro: 0.2812, F1 Macro: 0.2564, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.4542, Val Loss: 1.7681, F1 Micro: 0.3438, F1 Macro: 0.3059, Accuracy: 0.3438\n","Epoch 13, Train Loss: 1.4589, Val Loss: 1.9948, F1 Micro: 0.2917, F1 Macro: 0.2448, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.4797, Val Loss: 2.0339, F1 Micro: 0.3021, F1 Macro: 0.2645, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.4758, Val Loss: 2.0207, F1 Micro: 0.3438, F1 Macro: 0.3070, Accuracy: 0.3438\n","Epoch 16, Train Loss: 1.4446, Val Loss: 1.8817, F1 Micro: 0.4062, F1 Macro: 0.3902, Accuracy: 0.4062\n","Epoch 17, Train Loss: 1.5239, Val Loss: 1.8419, F1 Micro: 0.3333, F1 Macro: 0.2765, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.3872, Val Loss: 1.8825, F1 Micro: 0.3125, F1 Macro: 0.2756, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.4004, Val Loss: 1.8036, F1 Micro: 0.4062, F1 Macro: 0.4187, Accuracy: 0.4062\n","Epoch 20, Train Loss: 1.4369, Val Loss: 1.7785, F1 Micro: 0.3958, F1 Macro: 0.3807, Accuracy: 0.3958\n","Epoch 21, Train Loss: 1.3448, Val Loss: 1.7271, F1 Micro: 0.3854, F1 Macro: 0.3812, Accuracy: 0.3854\n","Epoch 22, Train Loss: 1.3763, Val Loss: 1.8783, F1 Micro: 0.3333, F1 Macro: 0.2764, Accuracy: 0.3333\n","Epoch 23, Train Loss: 1.3323, Val Loss: 3.8096, F1 Micro: 0.2292, F1 Macro: 0.1434, Accuracy: 0.2292\n","Epoch 24, Train Loss: 1.3995, Val Loss: 2.9011, F1 Micro: 0.2604, F1 Macro: 0.1645, Accuracy: 0.2604\n","Epoch 25, Train Loss: 1.3479, Val Loss: 1.7715, F1 Micro: 0.4271, F1 Macro: 0.3644, Accuracy: 0.4271\n","Epoch 26, Train Loss: 1.3783, Val Loss: 2.0898, F1 Micro: 0.3542, F1 Macro: 0.3151, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.3106, Val Loss: 1.8563, F1 Micro: 0.3958, F1 Macro: 0.3784, Accuracy: 0.3958\n","Epoch 28, Train Loss: 1.2758, Val Loss: 2.1374, F1 Micro: 0.3438, F1 Macro: 0.3037, Accuracy: 0.3438\n","Epoch 29, Train Loss: 1.2695, Val Loss: 1.8547, F1 Micro: 0.3750, F1 Macro: 0.3363, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.2476, Val Loss: 1.8386, F1 Micro: 0.4271, F1 Macro: 0.4131, Accuracy: 0.4271\n","Epoch 31, Train Loss: 1.2002, Val Loss: 1.7092, F1 Micro: 0.4479, F1 Macro: 0.4392, Accuracy: 0.4479\n","Epoch 32, Train Loss: 1.2812, Val Loss: 1.8539, F1 Micro: 0.3125, F1 Macro: 0.2319, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.2260, Val Loss: 1.7740, F1 Micro: 0.4896, F1 Macro: 0.5054, Accuracy: 0.4896\n","Epoch 34, Train Loss: 1.2192, Val Loss: 2.0160, F1 Micro: 0.4583, F1 Macro: 0.3787, Accuracy: 0.4583\n","Epoch 35, Train Loss: 1.2185, Val Loss: 1.8738, F1 Micro: 0.3438, F1 Macro: 0.3019, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.2409, Val Loss: 1.6492, F1 Micro: 0.4167, F1 Macro: 0.3905, Accuracy: 0.4167\n","Epoch 37, Train Loss: 1.2264, Val Loss: 2.1421, F1 Micro: 0.3438, F1 Macro: 0.3013, Accuracy: 0.3438\n","Epoch 38, Train Loss: 1.2030, Val Loss: 1.7498, F1 Micro: 0.4479, F1 Macro: 0.4178, Accuracy: 0.4479\n","Epoch 39, Train Loss: 1.1796, Val Loss: 2.8878, F1 Micro: 0.2708, F1 Macro: 0.2125, Accuracy: 0.2708\n","Epoch 40, Train Loss: 1.1523, Val Loss: 1.7249, F1 Micro: 0.4688, F1 Macro: 0.4400, Accuracy: 0.4688\n","Epoch 41, Train Loss: 1.1872, Val Loss: 1.7470, F1 Micro: 0.4583, F1 Macro: 0.4098, Accuracy: 0.4583\n","Epoch 42, Train Loss: 1.1742, Val Loss: 1.8049, F1 Micro: 0.3854, F1 Macro: 0.3586, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.2125, Val Loss: 2.3795, F1 Micro: 0.3542, F1 Macro: 0.3008, Accuracy: 0.3542\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.4791666666666667\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.1092, Val Loss: 2.3442, F1 Micro: 0.2292, F1 Macro: 0.1339, Accuracy: 0.2292\n","Epoch 2, Train Loss: 1.9446, Val Loss: 2.0066, F1 Micro: 0.2396, F1 Macro: 0.1541, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7640, Val Loss: 1.9850, F1 Micro: 0.3125, F1 Macro: 0.2397, Accuracy: 0.3125\n","Epoch 4, Train Loss: 1.6548, Val Loss: 1.9420, F1 Micro: 0.2500, F1 Macro: 0.2343, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.6543, Val Loss: 1.9644, F1 Micro: 0.2396, F1 Macro: 0.1890, Accuracy: 0.2396\n","Epoch 6, Train Loss: 1.6169, Val Loss: 1.8196, F1 Micro: 0.3125, F1 Macro: 0.2461, Accuracy: 0.3125\n","Epoch 7, Train Loss: 1.5836, Val Loss: 2.7208, F1 Micro: 0.2188, F1 Macro: 0.1636, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.5663, Val Loss: 1.8618, F1 Micro: 0.2708, F1 Macro: 0.2263, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.5848, Val Loss: 1.8224, F1 Micro: 0.3750, F1 Macro: 0.3383, Accuracy: 0.3750\n","Epoch 10, Train Loss: 1.5329, Val Loss: 2.3062, F1 Micro: 0.2917, F1 Macro: 0.2721, Accuracy: 0.2917\n","Epoch 11, Train Loss: 1.4608, Val Loss: 1.6160, F1 Micro: 0.3542, F1 Macro: 0.3000, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.4677, Val Loss: 2.2053, F1 Micro: 0.2812, F1 Macro: 0.1998, Accuracy: 0.2812\n","Epoch 13, Train Loss: 1.4155, Val Loss: 2.5667, F1 Micro: 0.1979, F1 Macro: 0.1313, Accuracy: 0.1979\n","Epoch 14, Train Loss: 1.4952, Val Loss: 2.4756, F1 Micro: 0.2292, F1 Macro: 0.1752, Accuracy: 0.2292\n","Epoch 15, Train Loss: 1.3822, Val Loss: 1.7256, F1 Micro: 0.3125, F1 Macro: 0.2683, Accuracy: 0.3125\n","Epoch 16, Train Loss: 1.3650, Val Loss: 1.9254, F1 Micro: 0.3229, F1 Macro: 0.2839, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.3668, Val Loss: 2.0363, F1 Micro: 0.2917, F1 Macro: 0.2752, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.3910, Val Loss: 1.8639, F1 Micro: 0.3229, F1 Macro: 0.2596, Accuracy: 0.3229\n","Epoch 19, Train Loss: 1.3275, Val Loss: 1.6361, F1 Micro: 0.3958, F1 Macro: 0.4053, Accuracy: 0.3958\n","Epoch 20, Train Loss: 1.3123, Val Loss: 2.2180, F1 Micro: 0.2500, F1 Macro: 0.2117, Accuracy: 0.2500\n","Epoch 21, Train Loss: 1.3374, Val Loss: 2.9237, F1 Micro: 0.3125, F1 Macro: 0.2257, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.4426, Val Loss: 1.9411, F1 Micro: 0.2396, F1 Macro: 0.1907, Accuracy: 0.2396\n","Epoch 23, Train Loss: 1.2874, Val Loss: 1.8406, F1 Micro: 0.4062, F1 Macro: 0.3233, Accuracy: 0.4062\n","Epoch 24, Train Loss: 1.2600, Val Loss: 2.2973, F1 Micro: 0.3229, F1 Macro: 0.3188, Accuracy: 0.3229\n","Epoch 25, Train Loss: 1.3374, Val Loss: 1.9839, F1 Micro: 0.3542, F1 Macro: 0.3381, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.2902, Val Loss: 2.0084, F1 Micro: 0.2917, F1 Macro: 0.2369, Accuracy: 0.2917\n","Epoch 27, Train Loss: 1.2325, Val Loss: 1.7219, F1 Micro: 0.3333, F1 Macro: 0.3072, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.1564, Val Loss: 2.0437, F1 Micro: 0.3854, F1 Macro: 0.3418, Accuracy: 0.3854\n","Epoch 29, Train Loss: 1.1896, Val Loss: 2.1076, F1 Micro: 0.3958, F1 Macro: 0.3641, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.2198, Val Loss: 2.2359, F1 Micro: 0.3438, F1 Macro: 0.3058, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.1262, Val Loss: 2.2100, F1 Micro: 0.3542, F1 Macro: 0.3692, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.1040, Val Loss: 1.8211, F1 Micro: 0.5000, F1 Macro: 0.4929, Accuracy: 0.5000\n","Epoch 33, Train Loss: 1.1110, Val Loss: 2.1798, F1 Micro: 0.3854, F1 Macro: 0.3471, Accuracy: 0.3854\n","Epoch 34, Train Loss: 1.0888, Val Loss: 2.1213, F1 Micro: 0.3125, F1 Macro: 0.2742, Accuracy: 0.3125\n","Epoch 35, Train Loss: 1.0480, Val Loss: 2.6815, F1 Micro: 0.3750, F1 Macro: 0.3327, Accuracy: 0.3750\n","Epoch 36, Train Loss: 1.1548, Val Loss: 2.2848, F1 Micro: 0.4167, F1 Macro: 0.3452, Accuracy: 0.4167\n","Epoch 37, Train Loss: 1.0713, Val Loss: 2.1064, F1 Micro: 0.3750, F1 Macro: 0.3782, Accuracy: 0.3750\n","Epoch 38, Train Loss: 1.2308, Val Loss: 2.6431, F1 Micro: 0.3021, F1 Macro: 0.2360, Accuracy: 0.3021\n","Epoch 39, Train Loss: 1.1318, Val Loss: 2.3619, F1 Micro: 0.3021, F1 Macro: 0.2534, Accuracy: 0.3021\n","Epoch 40, Train Loss: 1.0374, Val Loss: 1.9009, F1 Micro: 0.4792, F1 Macro: 0.4642, Accuracy: 0.4792\n","Epoch 41, Train Loss: 1.0323, Val Loss: 2.2142, F1 Micro: 0.3542, F1 Macro: 0.2920, Accuracy: 0.3542\n","Epoch 42, Train Loss: 1.0771, Val Loss: 2.0301, F1 Micro: 0.3958, F1 Macro: 0.3980, Accuracy: 0.3958\n","Epoch 43, Train Loss: 1.0183, Val Loss: 2.0544, F1 Micro: 0.3854, F1 Macro: 0.3562, Accuracy: 0.3854\n","Epoch 44, Train Loss: 1.1289, Val Loss: 2.0134, F1 Micro: 0.4271, F1 Macro: 0.3596, Accuracy: 0.4271\n","Epoch 45, Train Loss: 1.0346, Val Loss: 2.8311, F1 Micro: 0.3333, F1 Macro: 0.2612, Accuracy: 0.3333\n","Epoch 46, Train Loss: 1.0512, Val Loss: 1.8030, F1 Micro: 0.4375, F1 Macro: 0.3959, Accuracy: 0.4375\n","Epoch 47, Train Loss: 1.0096, Val Loss: 2.3222, F1 Micro: 0.3438, F1 Macro: 0.3023, Accuracy: 0.3438\n","Epoch 48, Train Loss: 1.0150, Val Loss: 2.2747, F1 Micro: 0.3438, F1 Macro: 0.2913, Accuracy: 0.3438\n","Epoch 49, Train Loss: 1.0088, Val Loss: 1.9582, F1 Micro: 0.3958, F1 Macro: 0.3627, Accuracy: 0.3958\n","Epoch 50, Train Loss: 0.9969, Val Loss: 2.2738, F1 Micro: 0.4062, F1 Macro: 0.3448, Accuracy: 0.4062\n","Epoch 51, Train Loss: 0.9636, Val Loss: 3.3769, F1 Micro: 0.2812, F1 Macro: 0.1992, Accuracy: 0.2812\n","Epoch 52, Train Loss: 1.0586, Val Loss: 4.1109, F1 Micro: 0.2396, F1 Macro: 0.1782, Accuracy: 0.2396\n","Epoch 53, Train Loss: 1.0430, Val Loss: 2.2767, F1 Micro: 0.3646, F1 Macro: 0.3362, Accuracy: 0.3646\n","Epoch 54, Train Loss: 0.9656, Val Loss: 1.7679, F1 Micro: 0.5000, F1 Macro: 0.4801, Accuracy: 0.5000\n","Epoch 55, Train Loss: 0.9295, Val Loss: 1.9336, F1 Micro: 0.4792, F1 Macro: 0.4433, Accuracy: 0.4792\n","Epoch 56, Train Loss: 0.9286, Val Loss: 1.9926, F1 Micro: 0.4167, F1 Macro: 0.3596, Accuracy: 0.4167\n","Epoch 57, Train Loss: 0.8986, Val Loss: 2.7484, F1 Micro: 0.4479, F1 Macro: 0.4170, Accuracy: 0.4479\n","Epoch 58, Train Loss: 0.9109, Val Loss: 1.9012, F1 Micro: 0.4583, F1 Macro: 0.4486, Accuracy: 0.4583\n","Epoch 59, Train Loss: 0.8814, Val Loss: 2.4482, F1 Micro: 0.3958, F1 Macro: 0.4122, Accuracy: 0.3958\n","Epoch 60, Train Loss: 0.8080, Val Loss: 2.7000, F1 Micro: 0.3229, F1 Macro: 0.3024, Accuracy: 0.3229\n","Epoch 61, Train Loss: 0.8436, Val Loss: 2.0821, F1 Micro: 0.4062, F1 Macro: 0.4023, Accuracy: 0.4062\n","Epoch 62, Train Loss: 0.8461, Val Loss: 2.1449, F1 Micro: 0.4583, F1 Macro: 0.4091, Accuracy: 0.4583\n","Epoch 63, Train Loss: 0.9404, Val Loss: 3.0323, F1 Micro: 0.3229, F1 Macro: 0.3192, Accuracy: 0.3229\n","Epoch 64, Train Loss: 0.9332, Val Loss: 1.8718, F1 Micro: 0.4792, F1 Macro: 0.4856, Accuracy: 0.4792\n","Epoch 65, Train Loss: 0.8929, Val Loss: 2.7145, F1 Micro: 0.4375, F1 Macro: 0.4141, Accuracy: 0.4375\n","Epoch 66, Train Loss: 0.8487, Val Loss: 2.1348, F1 Micro: 0.4271, F1 Macro: 0.3649, Accuracy: 0.4271\n","Epoch 67, Train Loss: 0.8716, Val Loss: 4.7857, F1 Micro: 0.2292, F1 Macro: 0.1627, Accuracy: 0.2292\n","Epoch 68, Train Loss: 0.9417, Val Loss: 2.8623, F1 Micro: 0.3021, F1 Macro: 0.2678, Accuracy: 0.3021\n","Epoch 69, Train Loss: 0.8418, Val Loss: 1.8668, F1 Micro: 0.4583, F1 Macro: 0.3891, Accuracy: 0.4583\n","Epoch 70, Train Loss: 0.7844, Val Loss: 2.2579, F1 Micro: 0.3646, F1 Macro: 0.3436, Accuracy: 0.3646\n","Epoch 71, Train Loss: 0.7990, Val Loss: 2.0467, F1 Micro: 0.4688, F1 Macro: 0.4490, Accuracy: 0.4688\n","Epoch 72, Train Loss: 0.8208, Val Loss: 2.2557, F1 Micro: 0.4688, F1 Macro: 0.4146, Accuracy: 0.4688\n","Epoch 73, Train Loss: 0.8179, Val Loss: 2.0777, F1 Micro: 0.4271, F1 Macro: 0.3781, Accuracy: 0.4271\n","Epoch 74, Train Loss: 0.7927, Val Loss: 2.3942, F1 Micro: 0.3750, F1 Macro: 0.3297, Accuracy: 0.3750\n","Epoch 75, Train Loss: 0.7077, Val Loss: 1.9260, F1 Micro: 0.5104, F1 Macro: 0.4954, Accuracy: 0.5104\n","Epoch 76, Train Loss: 0.8222, Val Loss: 2.8069, F1 Micro: 0.4583, F1 Macro: 0.4611, Accuracy: 0.4583\n","Epoch 77, Train Loss: 0.7291, Val Loss: 4.1358, F1 Micro: 0.2604, F1 Macro: 0.2118, Accuracy: 0.2604\n","Epoch 78, Train Loss: 0.8030, Val Loss: 2.4198, F1 Micro: 0.4688, F1 Macro: 0.4572, Accuracy: 0.4688\n","Epoch 79, Train Loss: 0.7417, Val Loss: 2.8849, F1 Micro: 0.3229, F1 Macro: 0.2510, Accuracy: 0.3229\n","Epoch 80, Train Loss: 0.7641, Val Loss: 2.0039, F1 Micro: 0.5000, F1 Macro: 0.4738, Accuracy: 0.5000\n","Epoch 81, Train Loss: 0.7082, Val Loss: 2.2806, F1 Micro: 0.4375, F1 Macro: 0.3936, Accuracy: 0.4375\n","Epoch 82, Train Loss: 0.7742, Val Loss: 2.2292, F1 Micro: 0.4479, F1 Macro: 0.4065, Accuracy: 0.4479\n","Epoch 83, Train Loss: 0.7366, Val Loss: 2.2363, F1 Micro: 0.4375, F1 Macro: 0.3764, Accuracy: 0.4375\n","Epoch 84, Train Loss: 0.6884, Val Loss: 2.1123, F1 Micro: 0.5417, F1 Macro: 0.5194, Accuracy: 0.5417\n","Epoch 85, Train Loss: 0.6821, Val Loss: 2.2585, F1 Micro: 0.5104, F1 Macro: 0.5031, Accuracy: 0.5104\n","Epoch 86, Train Loss: 0.7094, Val Loss: 2.1084, F1 Micro: 0.5104, F1 Macro: 0.4823, Accuracy: 0.5104\n","Epoch 87, Train Loss: 0.7215, Val Loss: 2.0524, F1 Micro: 0.5208, F1 Macro: 0.4768, Accuracy: 0.5208\n","Epoch 88, Train Loss: 0.6694, Val Loss: 2.0534, F1 Micro: 0.3958, F1 Macro: 0.3763, Accuracy: 0.3958\n","Epoch 89, Train Loss: 0.6897, Val Loss: 2.1677, F1 Micro: 0.4792, F1 Macro: 0.4835, Accuracy: 0.4792\n","Epoch 90, Train Loss: 0.7200, Val Loss: 3.1193, F1 Micro: 0.3438, F1 Macro: 0.3111, Accuracy: 0.3438\n","Epoch 91, Train Loss: 0.6826, Val Loss: 2.2990, F1 Micro: 0.3646, F1 Macro: 0.3185, Accuracy: 0.3646\n","Epoch 92, Train Loss: 0.6529, Val Loss: 2.2870, F1 Micro: 0.4583, F1 Macro: 0.3696, Accuracy: 0.4583\n","Epoch 93, Train Loss: 0.7256, Val Loss: 2.2649, F1 Micro: 0.4583, F1 Macro: 0.4469, Accuracy: 0.4583\n","Epoch 94, Train Loss: 0.7058, Val Loss: 2.8462, F1 Micro: 0.5104, F1 Macro: 0.4905, Accuracy: 0.5104\n","Epoch 95, Train Loss: 0.6752, Val Loss: 2.5505, F1 Micro: 0.4479, F1 Macro: 0.4245, Accuracy: 0.4479\n","Epoch 96, Train Loss: 0.6825, Val Loss: 1.9158, F1 Micro: 0.5208, F1 Macro: 0.5002, Accuracy: 0.5208\n","Epoch 97, Train Loss: 0.6545, Val Loss: 2.3268, F1 Micro: 0.4896, F1 Macro: 0.4503, Accuracy: 0.4896\n","Epoch 98, Train Loss: 0.6401, Val Loss: 2.1032, F1 Micro: 0.4896, F1 Macro: 0.4396, Accuracy: 0.4896\n","Epoch 99, Train Loss: 0.7039, Val Loss: 2.8113, F1 Micro: 0.4688, F1 Macro: 0.4444, Accuracy: 0.4688\n","Epoch 100, Train Loss: 0.6422, Val Loss: 3.1964, F1 Micro: 0.3958, F1 Macro: 0.3324, Accuracy: 0.3958\n","Epoch 101, Train Loss: 0.6006, Val Loss: 3.3233, F1 Micro: 0.3542, F1 Macro: 0.3024, Accuracy: 0.3542\n","Epoch 102, Train Loss: 0.6453, Val Loss: 2.0627, F1 Micro: 0.4896, F1 Macro: 0.4895, Accuracy: 0.4896\n","Epoch 103, Train Loss: 0.6889, Val Loss: 3.5448, F1 Micro: 0.4896, F1 Macro: 0.4398, Accuracy: 0.4896\n","Epoch 104, Train Loss: 0.6584, Val Loss: 2.2785, F1 Micro: 0.5208, F1 Macro: 0.5271, Accuracy: 0.5208\n","Epoch 105, Train Loss: 0.7078, Val Loss: 2.8155, F1 Micro: 0.5000, F1 Macro: 0.5234, Accuracy: 0.5000\n","Epoch 106, Train Loss: 0.6863, Val Loss: 2.4709, F1 Micro: 0.4792, F1 Macro: 0.4010, Accuracy: 0.4792\n","Epoch 107, Train Loss: 0.6695, Val Loss: 3.0617, F1 Micro: 0.3854, F1 Macro: 0.3454, Accuracy: 0.3854\n","Epoch 108, Train Loss: 0.6500, Val Loss: 2.6156, F1 Micro: 0.4271, F1 Macro: 0.3805, Accuracy: 0.4271\n","Epoch 109, Train Loss: 0.6303, Val Loss: 2.4716, F1 Micro: 0.4375, F1 Macro: 0.4464, Accuracy: 0.4375\n","Epoch 110, Train Loss: 0.7199, Val Loss: 2.7791, F1 Micro: 0.3542, F1 Macro: 0.3193, Accuracy: 0.3542\n","Epoch 111, Train Loss: 0.5602, Val Loss: 2.6729, F1 Micro: 0.4479, F1 Macro: 0.4225, Accuracy: 0.4479\n","Epoch 112, Train Loss: 0.5980, Val Loss: 2.6918, F1 Micro: 0.5000, F1 Macro: 0.5017, Accuracy: 0.5000\n","Epoch 113, Train Loss: 0.5529, Val Loss: 2.8528, F1 Micro: 0.4167, F1 Macro: 0.4258, Accuracy: 0.4167\n","Epoch 114, Train Loss: 0.6389, Val Loss: 2.4341, F1 Micro: 0.5104, F1 Macro: 0.5085, Accuracy: 0.5104\n","Epoch 115, Train Loss: 0.5957, Val Loss: 2.1051, F1 Micro: 0.4896, F1 Macro: 0.4387, Accuracy: 0.4896\n","Epoch 116, Train Loss: 0.6723, Val Loss: 2.2399, F1 Micro: 0.5625, F1 Macro: 0.5075, Accuracy: 0.5625\n","Epoch 117, Train Loss: 0.6756, Val Loss: 2.4058, F1 Micro: 0.5104, F1 Macro: 0.4490, Accuracy: 0.5104\n","Epoch 118, Train Loss: 0.5568, Val Loss: 2.2431, F1 Micro: 0.5104, F1 Macro: 0.4869, Accuracy: 0.5104\n","Epoch 119, Train Loss: 0.5810, Val Loss: 2.8820, F1 Micro: 0.4062, F1 Macro: 0.3669, Accuracy: 0.4062\n","Epoch 120, Train Loss: 0.5419, Val Loss: 1.8087, F1 Micro: 0.5208, F1 Macro: 0.5294, Accuracy: 0.5208\n","Epoch 121, Train Loss: 0.5323, Val Loss: 2.3006, F1 Micro: 0.5417, F1 Macro: 0.5121, Accuracy: 0.5417\n","Epoch 122, Train Loss: 0.5570, Val Loss: 2.7833, F1 Micro: 0.4792, F1 Macro: 0.4933, Accuracy: 0.4792\n","Epoch 123, Train Loss: 0.5138, Val Loss: 2.6955, F1 Micro: 0.4688, F1 Macro: 0.4204, Accuracy: 0.4688\n","Epoch 124, Train Loss: 0.5508, Val Loss: 2.6917, F1 Micro: 0.4167, F1 Macro: 0.3705, Accuracy: 0.4167\n","Epoch 125, Train Loss: 0.5989, Val Loss: 3.0630, F1 Micro: 0.5417, F1 Macro: 0.5278, Accuracy: 0.5417\n","Epoch 126, Train Loss: 0.5568, Val Loss: 2.9590, F1 Micro: 0.4688, F1 Macro: 0.4633, Accuracy: 0.4688\n","Epoch 127, Train Loss: 0.5240, Val Loss: 3.3266, F1 Micro: 0.4167, F1 Macro: 0.3513, Accuracy: 0.4167\n","Epoch 128, Train Loss: 0.5277, Val Loss: 1.8901, F1 Micro: 0.5312, F1 Macro: 0.5027, Accuracy: 0.5312\n","Epoch 129, Train Loss: 0.5862, Val Loss: 2.9913, F1 Micro: 0.4271, F1 Macro: 0.4134, Accuracy: 0.4271\n","Epoch 130, Train Loss: 0.5315, Val Loss: 3.4341, F1 Micro: 0.3750, F1 Macro: 0.3454, Accuracy: 0.3750\n","Epoch 131, Train Loss: 0.6283, Val Loss: 3.1426, F1 Micro: 0.3958, F1 Macro: 0.3517, Accuracy: 0.3958\n","Epoch 132, Train Loss: 0.6297, Val Loss: 2.5549, F1 Micro: 0.3958, F1 Macro: 0.3701, Accuracy: 0.3958\n","Epoch 133, Train Loss: 0.5286, Val Loss: 2.3638, F1 Micro: 0.5521, F1 Macro: 0.5572, Accuracy: 0.5521\n","Epoch 134, Train Loss: 0.5700, Val Loss: 2.3216, F1 Micro: 0.4479, F1 Macro: 0.4256, Accuracy: 0.4479\n","Epoch 135, Train Loss: 0.5313, Val Loss: 2.8492, F1 Micro: 0.5312, F1 Macro: 0.4800, Accuracy: 0.5312\n","Epoch 136, Train Loss: 0.5417, Val Loss: 2.8742, F1 Micro: 0.4688, F1 Macro: 0.4659, Accuracy: 0.4688\n","Epoch 137, Train Loss: 0.5769, Val Loss: 3.2709, F1 Micro: 0.3438, F1 Macro: 0.3517, Accuracy: 0.3438\n","Epoch 138, Train Loss: 0.4938, Val Loss: 2.9934, F1 Micro: 0.5000, F1 Macro: 0.5035, Accuracy: 0.5000\n","Epoch 139, Train Loss: 0.5046, Val Loss: 3.7004, F1 Micro: 0.3854, F1 Macro: 0.3999, Accuracy: 0.3854\n","Epoch 140, Train Loss: 0.5239, Val Loss: 3.0387, F1 Micro: 0.4062, F1 Macro: 0.3692, Accuracy: 0.4062\n","Epoch 141, Train Loss: 0.5028, Val Loss: 2.4840, F1 Micro: 0.4583, F1 Macro: 0.4219, Accuracy: 0.4583\n","Epoch 142, Train Loss: 0.5102, Val Loss: 2.6841, F1 Micro: 0.5521, F1 Macro: 0.5440, Accuracy: 0.5521\n","Epoch 143, Train Loss: 0.4473, Val Loss: 2.1793, F1 Micro: 0.5104, F1 Macro: 0.5128, Accuracy: 0.5104\n","Epoch 144, Train Loss: 0.5821, Val Loss: 2.5949, F1 Micro: 0.4167, F1 Macro: 0.4321, Accuracy: 0.4167\n","Epoch 145, Train Loss: 0.5042, Val Loss: 3.6741, F1 Micro: 0.3958, F1 Macro: 0.3697, Accuracy: 0.3958\n","Epoch 146, Train Loss: 0.5382, Val Loss: 2.3013, F1 Micro: 0.4792, F1 Macro: 0.4713, Accuracy: 0.4792\n","Epoch 147, Train Loss: 0.4884, Val Loss: 4.7645, F1 Micro: 0.3750, F1 Macro: 0.3181, Accuracy: 0.3750\n","Epoch 148, Train Loss: 0.5268, Val Loss: 2.9354, F1 Micro: 0.5417, F1 Macro: 0.5198, Accuracy: 0.5417\n","Epoch 149, Train Loss: 0.5079, Val Loss: 2.5867, F1 Micro: 0.5208, F1 Macro: 0.5103, Accuracy: 0.5208\n","Epoch 150, Train Loss: 0.5048, Val Loss: 2.7587, F1 Micro: 0.4688, F1 Macro: 0.4623, Accuracy: 0.4688\n","Epoch 151, Train Loss: 0.4537, Val Loss: 2.6312, F1 Micro: 0.5625, F1 Macro: 0.5435, Accuracy: 0.5625\n","Epoch 152, Train Loss: 0.4515, Val Loss: 2.4623, F1 Micro: 0.4896, F1 Macro: 0.4508, Accuracy: 0.4896\n","Epoch 153, Train Loss: 0.5177, Val Loss: 2.9124, F1 Micro: 0.5000, F1 Macro: 0.4552, Accuracy: 0.5000\n","Epoch 154, Train Loss: 0.5130, Val Loss: 2.9830, F1 Micro: 0.5208, F1 Macro: 0.5135, Accuracy: 0.5208\n","Epoch 155, Train Loss: 0.5004, Val Loss: 2.5120, F1 Micro: 0.5417, F1 Macro: 0.5029, Accuracy: 0.5417\n","Epoch 156, Train Loss: 0.5039, Val Loss: 2.6399, F1 Micro: 0.5312, F1 Macro: 0.5040, Accuracy: 0.5312\n","Epoch 157, Train Loss: 0.4688, Val Loss: 4.0624, F1 Micro: 0.4062, F1 Macro: 0.3393, Accuracy: 0.4062\n","Epoch 158, Train Loss: 0.5163, Val Loss: 3.2689, F1 Micro: 0.5104, F1 Macro: 0.4934, Accuracy: 0.5104\n","Epoch 159, Train Loss: 0.4685, Val Loss: 2.2672, F1 Micro: 0.5833, F1 Macro: 0.5573, Accuracy: 0.5833\n","Epoch 160, Train Loss: 0.4796, Val Loss: 2.8037, F1 Micro: 0.5417, F1 Macro: 0.5165, Accuracy: 0.5417\n","Epoch 161, Train Loss: 0.4194, Val Loss: 2.3717, F1 Micro: 0.5000, F1 Macro: 0.4805, Accuracy: 0.5000\n","Epoch 162, Train Loss: 0.4714, Val Loss: 2.8610, F1 Micro: 0.5208, F1 Macro: 0.5235, Accuracy: 0.5208\n","Epoch 163, Train Loss: 0.4557, Val Loss: 2.9451, F1 Micro: 0.5104, F1 Macro: 0.4789, Accuracy: 0.5104\n","Epoch 164, Train Loss: 0.4411, Val Loss: 2.6314, F1 Micro: 0.6042, F1 Macro: 0.5875, Accuracy: 0.6042\n","Epoch 165, Train Loss: 0.4501, Val Loss: 3.3063, F1 Micro: 0.4688, F1 Macro: 0.4747, Accuracy: 0.4688\n","Epoch 166, Train Loss: 0.4906, Val Loss: 2.7265, F1 Micro: 0.5729, F1 Macro: 0.5892, Accuracy: 0.5729\n","Epoch 167, Train Loss: 0.4688, Val Loss: 4.1310, F1 Micro: 0.3958, F1 Macro: 0.3696, Accuracy: 0.3958\n","Epoch 168, Train Loss: 0.4740, Val Loss: 2.4403, F1 Micro: 0.5938, F1 Macro: 0.5662, Accuracy: 0.5938\n","Epoch 169, Train Loss: 0.4454, Val Loss: 3.0246, F1 Micro: 0.5833, F1 Macro: 0.5775, Accuracy: 0.5833\n","Epoch 170, Train Loss: 0.4631, Val Loss: 2.6535, F1 Micro: 0.4792, F1 Macro: 0.4756, Accuracy: 0.4792\n","Epoch 171, Train Loss: 0.4193, Val Loss: 1.9992, F1 Micro: 0.6146, F1 Macro: 0.5976, Accuracy: 0.6146\n","Epoch 172, Train Loss: 0.3906, Val Loss: 2.1647, F1 Micro: 0.5625, F1 Macro: 0.5571, Accuracy: 0.5625\n","Epoch 173, Train Loss: 0.3772, Val Loss: 2.7222, F1 Micro: 0.4792, F1 Macro: 0.4672, Accuracy: 0.4792\n","Epoch 174, Train Loss: 0.5559, Val Loss: 2.7343, F1 Micro: 0.5625, F1 Macro: 0.5468, Accuracy: 0.5625\n","Epoch 175, Train Loss: 0.5090, Val Loss: 2.7964, F1 Micro: 0.5000, F1 Macro: 0.4629, Accuracy: 0.5000\n","Epoch 176, Train Loss: 0.4356, Val Loss: 2.4821, F1 Micro: 0.4792, F1 Macro: 0.4291, Accuracy: 0.4792\n","Epoch 177, Train Loss: 0.4390, Val Loss: 2.0551, F1 Micro: 0.5833, F1 Macro: 0.5721, Accuracy: 0.5833\n","Epoch 178, Train Loss: 0.3917, Val Loss: 2.5023, F1 Micro: 0.6146, F1 Macro: 0.6045, Accuracy: 0.6146\n","Epoch 179, Train Loss: 0.4324, Val Loss: 2.8750, F1 Micro: 0.4688, F1 Macro: 0.4638, Accuracy: 0.4688\n","Epoch 180, Train Loss: 0.5032, Val Loss: 2.3689, F1 Micro: 0.5521, F1 Macro: 0.5621, Accuracy: 0.5521\n","Epoch 181, Train Loss: 0.4710, Val Loss: 3.0551, F1 Micro: 0.5312, F1 Macro: 0.4848, Accuracy: 0.5312\n","Epoch 182, Train Loss: 0.4409, Val Loss: 1.9512, F1 Micro: 0.5729, F1 Macro: 0.5482, Accuracy: 0.5729\n","Epoch 183, Train Loss: 0.3590, Val Loss: 2.1571, F1 Micro: 0.5625, F1 Macro: 0.5553, Accuracy: 0.5625\n","Epoch 184, Train Loss: 0.4713, Val Loss: 3.6262, F1 Micro: 0.4896, F1 Macro: 0.4711, Accuracy: 0.4896\n","Epoch 185, Train Loss: 0.3945, Val Loss: 3.0788, F1 Micro: 0.5104, F1 Macro: 0.5240, Accuracy: 0.5104\n","Epoch 186, Train Loss: 0.3888, Val Loss: 4.3589, F1 Micro: 0.3333, F1 Macro: 0.2583, Accuracy: 0.3333\n","Epoch 187, Train Loss: 0.4581, Val Loss: 4.3669, F1 Micro: 0.3021, F1 Macro: 0.2625, Accuracy: 0.3021\n","Epoch 188, Train Loss: 0.4275, Val Loss: 3.0772, F1 Micro: 0.4271, F1 Macro: 0.3920, Accuracy: 0.4271\n","Epoch 189, Train Loss: 0.4124, Val Loss: 2.2891, F1 Micro: 0.5000, F1 Macro: 0.4458, Accuracy: 0.5000\n","Epoch 190, Train Loss: 0.3628, Val Loss: 2.7123, F1 Micro: 0.4688, F1 Macro: 0.4627, Accuracy: 0.4688\n","Epoch 191, Train Loss: 0.3664, Val Loss: 2.4760, F1 Micro: 0.5000, F1 Macro: 0.4719, Accuracy: 0.5000\n","Epoch 192, Train Loss: 0.4277, Val Loss: 2.4922, F1 Micro: 0.5833, F1 Macro: 0.5784, Accuracy: 0.5833\n","Epoch 193, Train Loss: 0.4595, Val Loss: 3.6966, F1 Micro: 0.4896, F1 Macro: 0.4721, Accuracy: 0.4896\n","Epoch 194, Train Loss: 0.4178, Val Loss: 2.7516, F1 Micro: 0.5312, F1 Macro: 0.5294, Accuracy: 0.5312\n","Epoch 195, Train Loss: 0.3727, Val Loss: 3.3467, F1 Micro: 0.4896, F1 Macro: 0.4464, Accuracy: 0.4896\n","Epoch 196, Train Loss: 0.4429, Val Loss: 5.2954, F1 Micro: 0.3750, F1 Macro: 0.3208, Accuracy: 0.3750\n","Epoch 197, Train Loss: 0.4977, Val Loss: 3.3202, F1 Micro: 0.5417, F1 Macro: 0.5237, Accuracy: 0.5417\n","Epoch 198, Train Loss: 0.3534, Val Loss: 3.8540, F1 Micro: 0.4167, F1 Macro: 0.3631, Accuracy: 0.4167\n","Epoch 199, Train Loss: 0.4303, Val Loss: 2.9063, F1 Micro: 0.5000, F1 Macro: 0.5173, Accuracy: 0.5000\n","Epoch 200, Train Loss: 0.4453, Val Loss: 3.4972, F1 Micro: 0.4688, F1 Macro: 0.4659, Accuracy: 0.4688\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.0981, Val Loss: 2.1104, F1 Micro: 0.1667, F1 Macro: 0.0999, Accuracy: 0.1667\n","Epoch 2, Train Loss: 1.7782, Val Loss: 1.9034, F1 Micro: 0.3229, F1 Macro: 0.2685, Accuracy: 0.3229\n","Epoch 3, Train Loss: 1.7981, Val Loss: 2.0857, F1 Micro: 0.3021, F1 Macro: 0.2724, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.8269, Val Loss: 2.2617, F1 Micro: 0.1250, F1 Macro: 0.0618, Accuracy: 0.1250\n","Epoch 5, Train Loss: 1.6750, Val Loss: 1.8095, F1 Micro: 0.2604, F1 Macro: 0.2103, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.7027, Val Loss: 1.6577, F1 Micro: 0.3542, F1 Macro: 0.2925, Accuracy: 0.3542\n","Epoch 7, Train Loss: 1.6772, Val Loss: 1.6373, F1 Micro: 0.3021, F1 Macro: 0.3052, Accuracy: 0.3021\n","Epoch 8, Train Loss: 1.6179, Val Loss: 2.0593, F1 Micro: 0.2292, F1 Macro: 0.2116, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.6046, Val Loss: 1.6581, F1 Micro: 0.2917, F1 Macro: 0.2281, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.5875, Val Loss: 1.7844, F1 Micro: 0.3333, F1 Macro: 0.2704, Accuracy: 0.3333\n","Epoch 11, Train Loss: 1.5462, Val Loss: 2.0149, F1 Micro: 0.2708, F1 Macro: 0.2170, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.5376, Val Loss: 1.7988, F1 Micro: 0.3542, F1 Macro: 0.2950, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.5164, Val Loss: 1.8767, F1 Micro: 0.2917, F1 Macro: 0.2599, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.4813, Val Loss: 2.7606, F1 Micro: 0.2812, F1 Macro: 0.1843, Accuracy: 0.2812\n","Epoch 15, Train Loss: 1.5776, Val Loss: 1.7494, F1 Micro: 0.3438, F1 Macro: 0.3292, Accuracy: 0.3438\n","Epoch 16, Train Loss: 1.4848, Val Loss: 1.6230, F1 Micro: 0.3646, F1 Macro: 0.3203, Accuracy: 0.3646\n","Epoch 17, Train Loss: 1.4767, Val Loss: 2.3232, F1 Micro: 0.2812, F1 Macro: 0.2531, Accuracy: 0.2812\n","Epoch 18, Train Loss: 1.4934, Val Loss: 1.5680, F1 Micro: 0.4688, F1 Macro: 0.4267, Accuracy: 0.4688\n","Epoch 19, Train Loss: 1.4812, Val Loss: 2.0161, F1 Micro: 0.3125, F1 Macro: 0.2350, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.4388, Val Loss: 2.6574, F1 Micro: 0.2188, F1 Macro: 0.1955, Accuracy: 0.2188\n","Epoch 21, Train Loss: 1.3978, Val Loss: 1.8745, F1 Micro: 0.3646, F1 Macro: 0.3015, Accuracy: 0.3646\n","Epoch 22, Train Loss: 1.3416, Val Loss: 1.9646, F1 Micro: 0.2604, F1 Macro: 0.2359, Accuracy: 0.2604\n","Epoch 23, Train Loss: 1.3656, Val Loss: 1.9292, F1 Micro: 0.3021, F1 Macro: 0.2927, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.4067, Val Loss: 2.4184, F1 Micro: 0.1979, F1 Macro: 0.1375, Accuracy: 0.1979\n","Epoch 25, Train Loss: 1.3358, Val Loss: 1.9593, F1 Micro: 0.3229, F1 Macro: 0.3241, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.3768, Val Loss: 2.1580, F1 Micro: 0.2396, F1 Macro: 0.1961, Accuracy: 0.2396\n","Epoch 27, Train Loss: 1.2664, Val Loss: 1.6324, F1 Micro: 0.3854, F1 Macro: 0.3372, Accuracy: 0.3854\n","Epoch 28, Train Loss: 1.3571, Val Loss: 1.6987, F1 Micro: 0.4688, F1 Macro: 0.4644, Accuracy: 0.4688\n","Epoch 29, Train Loss: 1.2640, Val Loss: 1.9430, F1 Micro: 0.3646, F1 Macro: 0.3257, Accuracy: 0.3646\n","Epoch 30, Train Loss: 1.2645, Val Loss: 1.9452, F1 Micro: 0.3646, F1 Macro: 0.3112, Accuracy: 0.3646\n","Epoch 31, Train Loss: 1.2431, Val Loss: 2.1789, F1 Micro: 0.2812, F1 Macro: 0.2890, Accuracy: 0.2812\n","Epoch 32, Train Loss: 1.1865, Val Loss: 3.1991, F1 Micro: 0.2188, F1 Macro: 0.1744, Accuracy: 0.2188\n","Epoch 33, Train Loss: 1.2594, Val Loss: 2.0289, F1 Micro: 0.3854, F1 Macro: 0.3286, Accuracy: 0.3854\n","Epoch 34, Train Loss: 1.2375, Val Loss: 2.2988, F1 Micro: 0.3958, F1 Macro: 0.3086, Accuracy: 0.3958\n","Epoch 35, Train Loss: 1.2456, Val Loss: 2.2403, F1 Micro: 0.3542, F1 Macro: 0.3474, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.2066, Val Loss: 1.7220, F1 Micro: 0.4062, F1 Macro: 0.3718, Accuracy: 0.4062\n","Epoch 37, Train Loss: 1.1150, Val Loss: 1.6117, F1 Micro: 0.4375, F1 Macro: 0.3902, Accuracy: 0.4375\n","Epoch 38, Train Loss: 1.1459, Val Loss: 1.9904, F1 Micro: 0.2917, F1 Macro: 0.2190, Accuracy: 0.2917\n","Epoch 39, Train Loss: 1.2110, Val Loss: 1.7195, F1 Micro: 0.4479, F1 Macro: 0.4396, Accuracy: 0.4479\n","Epoch 40, Train Loss: 1.1539, Val Loss: 1.8338, F1 Micro: 0.4062, F1 Macro: 0.3573, Accuracy: 0.4062\n","Epoch 41, Train Loss: 1.2236, Val Loss: 2.1189, F1 Micro: 0.3438, F1 Macro: 0.2977, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.0787, Val Loss: 2.1576, F1 Micro: 0.2917, F1 Macro: 0.3134, Accuracy: 0.2917\n","Epoch 43, Train Loss: 1.0407, Val Loss: 2.2514, F1 Micro: 0.2917, F1 Macro: 0.2811, Accuracy: 0.2917\n","Epoch 44, Train Loss: 1.0573, Val Loss: 1.8580, F1 Micro: 0.3854, F1 Macro: 0.3660, Accuracy: 0.3854\n","Epoch 45, Train Loss: 1.1524, Val Loss: 1.8221, F1 Micro: 0.3958, F1 Macro: 0.4148, Accuracy: 0.3958\n","Epoch 46, Train Loss: 1.0715, Val Loss: 2.1290, F1 Micro: 0.3333, F1 Macro: 0.3036, Accuracy: 0.3333\n","Epoch 47, Train Loss: 1.0393, Val Loss: 2.2932, F1 Micro: 0.2917, F1 Macro: 0.2265, Accuracy: 0.2917\n","Epoch 48, Train Loss: 1.0690, Val Loss: 1.7950, F1 Micro: 0.4479, F1 Macro: 0.3967, Accuracy: 0.4479\n","Epoch 49, Train Loss: 1.0489, Val Loss: 2.7799, F1 Micro: 0.2292, F1 Macro: 0.1955, Accuracy: 0.2292\n","Epoch 50, Train Loss: 1.0598, Val Loss: 1.5030, F1 Micro: 0.5729, F1 Macro: 0.5628, Accuracy: 0.5729\n","Epoch 51, Train Loss: 1.0731, Val Loss: 1.9132, F1 Micro: 0.3958, F1 Macro: 0.4081, Accuracy: 0.3958\n","Epoch 52, Train Loss: 1.0601, Val Loss: 2.2556, F1 Micro: 0.3438, F1 Macro: 0.3135, Accuracy: 0.3438\n","Epoch 53, Train Loss: 1.0219, Val Loss: 1.9322, F1 Micro: 0.4375, F1 Macro: 0.4527, Accuracy: 0.4375\n","Epoch 54, Train Loss: 0.9644, Val Loss: 1.7167, F1 Micro: 0.4688, F1 Macro: 0.4285, Accuracy: 0.4688\n","Epoch 55, Train Loss: 1.0153, Val Loss: 1.7121, F1 Micro: 0.4896, F1 Macro: 0.4339, Accuracy: 0.4896\n","Epoch 56, Train Loss: 0.9664, Val Loss: 1.8398, F1 Micro: 0.3750, F1 Macro: 0.3688, Accuracy: 0.3750\n","Epoch 57, Train Loss: 1.0768, Val Loss: 1.8742, F1 Micro: 0.3333, F1 Macro: 0.3031, Accuracy: 0.3333\n","Epoch 58, Train Loss: 1.0557, Val Loss: 2.4087, F1 Micro: 0.3750, F1 Macro: 0.3018, Accuracy: 0.3750\n","Epoch 59, Train Loss: 0.9373, Val Loss: 1.7929, F1 Micro: 0.4062, F1 Macro: 0.3923, Accuracy: 0.4062\n","Epoch 60, Train Loss: 0.9819, Val Loss: 2.6976, F1 Micro: 0.3438, F1 Macro: 0.2818, Accuracy: 0.3438\n","Epoch 61, Train Loss: 0.9361, Val Loss: 2.6420, F1 Micro: 0.3958, F1 Macro: 0.3905, Accuracy: 0.3958\n","Epoch 62, Train Loss: 0.9639, Val Loss: 1.6918, F1 Micro: 0.4583, F1 Macro: 0.4288, Accuracy: 0.4583\n","Epoch 63, Train Loss: 1.0327, Val Loss: 2.0420, F1 Micro: 0.3229, F1 Macro: 0.3148, Accuracy: 0.3229\n","Epoch 64, Train Loss: 1.0252, Val Loss: 1.6857, F1 Micro: 0.4792, F1 Macro: 0.4715, Accuracy: 0.4792\n","Epoch 65, Train Loss: 0.9879, Val Loss: 1.7708, F1 Micro: 0.5312, F1 Macro: 0.5118, Accuracy: 0.5312\n","Epoch 66, Train Loss: 0.9249, Val Loss: 1.5471, F1 Micro: 0.5104, F1 Macro: 0.4585, Accuracy: 0.5104\n","Epoch 67, Train Loss: 0.9205, Val Loss: 1.6217, F1 Micro: 0.5312, F1 Macro: 0.5313, Accuracy: 0.5312\n","Epoch 68, Train Loss: 0.8670, Val Loss: 2.0312, F1 Micro: 0.3854, F1 Macro: 0.3630, Accuracy: 0.3854\n","Epoch 69, Train Loss: 0.9368, Val Loss: 2.3548, F1 Micro: 0.3646, F1 Macro: 0.2530, Accuracy: 0.3646\n","Epoch 70, Train Loss: 0.9934, Val Loss: 1.6980, F1 Micro: 0.4479, F1 Macro: 0.4068, Accuracy: 0.4479\n","Epoch 71, Train Loss: 0.8568, Val Loss: 1.6875, F1 Micro: 0.4688, F1 Macro: 0.4058, Accuracy: 0.4688\n","Epoch 72, Train Loss: 0.7896, Val Loss: 1.6474, F1 Micro: 0.4583, F1 Macro: 0.4026, Accuracy: 0.4583\n","Epoch 73, Train Loss: 0.8169, Val Loss: 1.6120, F1 Micro: 0.4792, F1 Macro: 0.4877, Accuracy: 0.4792\n","Epoch 74, Train Loss: 0.8621, Val Loss: 1.9710, F1 Micro: 0.5208, F1 Macro: 0.5096, Accuracy: 0.5208\n","Epoch 75, Train Loss: 0.7573, Val Loss: 1.6147, F1 Micro: 0.4583, F1 Macro: 0.4251, Accuracy: 0.4583\n","Epoch 76, Train Loss: 0.7847, Val Loss: 1.7338, F1 Micro: 0.4271, F1 Macro: 0.4296, Accuracy: 0.4271\n","Epoch 77, Train Loss: 0.7380, Val Loss: 2.4157, F1 Micro: 0.3542, F1 Macro: 0.3429, Accuracy: 0.3542\n","Epoch 78, Train Loss: 0.9138, Val Loss: 1.9797, F1 Micro: 0.4167, F1 Macro: 0.3895, Accuracy: 0.4167\n","Epoch 79, Train Loss: 0.8800, Val Loss: 2.3591, F1 Micro: 0.4062, F1 Macro: 0.3368, Accuracy: 0.4062\n","Epoch 80, Train Loss: 0.8699, Val Loss: 1.5102, F1 Micro: 0.5000, F1 Macro: 0.4704, Accuracy: 0.5000\n","Epoch 81, Train Loss: 0.8627, Val Loss: 1.7394, F1 Micro: 0.4792, F1 Macro: 0.4664, Accuracy: 0.4792\n","Epoch 82, Train Loss: 0.8633, Val Loss: 1.7021, F1 Micro: 0.5000, F1 Macro: 0.4444, Accuracy: 0.5000\n","Epoch 83, Train Loss: 0.7529, Val Loss: 1.8754, F1 Micro: 0.4583, F1 Macro: 0.4375, Accuracy: 0.4583\n","Epoch 84, Train Loss: 0.8044, Val Loss: 1.7678, F1 Micro: 0.4375, F1 Macro: 0.4648, Accuracy: 0.4375\n","Epoch 85, Train Loss: 0.7260, Val Loss: 1.9128, F1 Micro: 0.4479, F1 Macro: 0.4089, Accuracy: 0.4479\n","Epoch 86, Train Loss: 0.6855, Val Loss: 1.7459, F1 Micro: 0.4792, F1 Macro: 0.4936, Accuracy: 0.4792\n","Epoch 87, Train Loss: 0.7309, Val Loss: 1.4780, F1 Micro: 0.5833, F1 Macro: 0.5590, Accuracy: 0.5833\n","Epoch 88, Train Loss: 0.6852, Val Loss: 1.4214, F1 Micro: 0.5625, F1 Macro: 0.5308, Accuracy: 0.5625\n","Epoch 89, Train Loss: 0.7062, Val Loss: 1.7038, F1 Micro: 0.5208, F1 Macro: 0.5191, Accuracy: 0.5208\n","Epoch 90, Train Loss: 0.8156, Val Loss: 1.9057, F1 Micro: 0.4583, F1 Macro: 0.4292, Accuracy: 0.4583\n","Epoch 91, Train Loss: 0.8310, Val Loss: 2.6987, F1 Micro: 0.3125, F1 Macro: 0.3387, Accuracy: 0.3125\n","Epoch 92, Train Loss: 0.8020, Val Loss: 1.9746, F1 Micro: 0.4583, F1 Macro: 0.4467, Accuracy: 0.4583\n","Epoch 93, Train Loss: 0.7909, Val Loss: 1.9882, F1 Micro: 0.4583, F1 Macro: 0.4326, Accuracy: 0.4583\n","Epoch 94, Train Loss: 0.8439, Val Loss: 3.2310, F1 Micro: 0.3125, F1 Macro: 0.2658, Accuracy: 0.3125\n","Epoch 95, Train Loss: 0.7760, Val Loss: 1.7981, F1 Micro: 0.4688, F1 Macro: 0.4664, Accuracy: 0.4688\n","Epoch 96, Train Loss: 0.7345, Val Loss: 1.5820, F1 Micro: 0.5208, F1 Macro: 0.4967, Accuracy: 0.5208\n","Epoch 97, Train Loss: 0.7390, Val Loss: 3.4272, F1 Micro: 0.3021, F1 Macro: 0.2617, Accuracy: 0.3021\n","Epoch 98, Train Loss: 0.9596, Val Loss: 2.2450, F1 Micro: 0.4062, F1 Macro: 0.3632, Accuracy: 0.4062\n","Epoch 99, Train Loss: 0.8862, Val Loss: 1.6644, F1 Micro: 0.4271, F1 Macro: 0.3727, Accuracy: 0.4271\n","Epoch 100, Train Loss: 0.7060, Val Loss: 1.7829, F1 Micro: 0.4896, F1 Macro: 0.4611, Accuracy: 0.4896\n","Epoch 101, Train Loss: 0.6714, Val Loss: 2.3987, F1 Micro: 0.3542, F1 Macro: 0.3035, Accuracy: 0.3542\n","Epoch 102, Train Loss: 0.7429, Val Loss: 1.3723, F1 Micro: 0.5417, F1 Macro: 0.5162, Accuracy: 0.5417\n","Epoch 103, Train Loss: 0.8128, Val Loss: 2.0814, F1 Micro: 0.4896, F1 Macro: 0.4738, Accuracy: 0.4896\n","Epoch 104, Train Loss: 0.6755, Val Loss: 1.5186, F1 Micro: 0.4583, F1 Macro: 0.4628, Accuracy: 0.4583\n","Epoch 105, Train Loss: 0.6676, Val Loss: 2.1072, F1 Micro: 0.3333, F1 Macro: 0.3443, Accuracy: 0.3333\n","Epoch 106, Train Loss: 0.6575, Val Loss: 1.4728, F1 Micro: 0.5312, F1 Macro: 0.4953, Accuracy: 0.5312\n","Epoch 107, Train Loss: 0.7334, Val Loss: 1.7889, F1 Micro: 0.4583, F1 Macro: 0.4140, Accuracy: 0.4583\n","Epoch 108, Train Loss: 0.7448, Val Loss: 1.9582, F1 Micro: 0.4896, F1 Macro: 0.4411, Accuracy: 0.4896\n","Epoch 109, Train Loss: 0.6935, Val Loss: 2.3362, F1 Micro: 0.3750, F1 Macro: 0.3264, Accuracy: 0.3750\n","Epoch 110, Train Loss: 0.7359, Val Loss: 2.0872, F1 Micro: 0.3958, F1 Macro: 0.3913, Accuracy: 0.3958\n","Epoch 111, Train Loss: 0.6555, Val Loss: 2.1113, F1 Micro: 0.4167, F1 Macro: 0.3812, Accuracy: 0.4167\n","Epoch 112, Train Loss: 0.6251, Val Loss: 1.8803, F1 Micro: 0.4271, F1 Macro: 0.4192, Accuracy: 0.4271\n","Epoch 113, Train Loss: 0.5747, Val Loss: 2.4011, F1 Micro: 0.4896, F1 Macro: 0.4604, Accuracy: 0.4896\n","Epoch 114, Train Loss: 0.5921, Val Loss: 2.5044, F1 Micro: 0.4167, F1 Macro: 0.3987, Accuracy: 0.4167\n","Epoch 115, Train Loss: 0.6004, Val Loss: 2.3125, F1 Micro: 0.3750, F1 Macro: 0.3265, Accuracy: 0.3750\n","Epoch 116, Train Loss: 0.6309, Val Loss: 2.8610, F1 Micro: 0.2812, F1 Macro: 0.2569, Accuracy: 0.2812\n","Epoch 117, Train Loss: 0.6004, Val Loss: 2.2088, F1 Micro: 0.4583, F1 Macro: 0.4205, Accuracy: 0.4583\n","Epoch 118, Train Loss: 0.6431, Val Loss: 1.6774, F1 Micro: 0.4688, F1 Macro: 0.4536, Accuracy: 0.4688\n","Epoch 119, Train Loss: 0.6916, Val Loss: 2.1910, F1 Micro: 0.5000, F1 Macro: 0.4769, Accuracy: 0.5000\n","Epoch 120, Train Loss: 0.6192, Val Loss: 2.3074, F1 Micro: 0.4479, F1 Macro: 0.3975, Accuracy: 0.4479\n","Epoch 121, Train Loss: 0.7126, Val Loss: 3.4778, F1 Micro: 0.3854, F1 Macro: 0.3676, Accuracy: 0.3854\n","Epoch 122, Train Loss: 0.6982, Val Loss: 1.9448, F1 Micro: 0.4896, F1 Macro: 0.4647, Accuracy: 0.4896\n","Epoch 123, Train Loss: 0.5491, Val Loss: 1.7304, F1 Micro: 0.5417, F1 Macro: 0.4831, Accuracy: 0.5417\n","Epoch 124, Train Loss: 0.6251, Val Loss: 1.9909, F1 Micro: 0.5104, F1 Macro: 0.4930, Accuracy: 0.5104\n","Epoch 125, Train Loss: 0.7364, Val Loss: 3.2781, F1 Micro: 0.3542, F1 Macro: 0.2962, Accuracy: 0.3542\n","Epoch 126, Train Loss: 0.6658, Val Loss: 1.9237, F1 Micro: 0.5208, F1 Macro: 0.5008, Accuracy: 0.5208\n","Epoch 127, Train Loss: 0.6416, Val Loss: 2.1514, F1 Micro: 0.5000, F1 Macro: 0.4805, Accuracy: 0.5000\n","Epoch 128, Train Loss: 0.5786, Val Loss: 1.8275, F1 Micro: 0.5521, F1 Macro: 0.5461, Accuracy: 0.5521\n","Epoch 129, Train Loss: 0.6593, Val Loss: 2.1227, F1 Micro: 0.3958, F1 Macro: 0.3843, Accuracy: 0.3958\n","Epoch 130, Train Loss: 0.6597, Val Loss: 2.3280, F1 Micro: 0.3958, F1 Macro: 0.3506, Accuracy: 0.3958\n","Epoch 131, Train Loss: 0.5483, Val Loss: 1.6050, F1 Micro: 0.5521, F1 Macro: 0.5330, Accuracy: 0.5521\n","Epoch 132, Train Loss: 0.5998, Val Loss: 2.2042, F1 Micro: 0.4792, F1 Macro: 0.4711, Accuracy: 0.4792\n","Epoch 133, Train Loss: 0.5130, Val Loss: 2.0449, F1 Micro: 0.5000, F1 Macro: 0.5020, Accuracy: 0.5000\n","Epoch 134, Train Loss: 0.5051, Val Loss: 2.2414, F1 Micro: 0.4375, F1 Macro: 0.4158, Accuracy: 0.4375\n","Epoch 135, Train Loss: 0.6830, Val Loss: 2.1936, F1 Micro: 0.4583, F1 Macro: 0.4479, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.6030, Val Loss: 1.7968, F1 Micro: 0.5521, F1 Macro: 0.5331, Accuracy: 0.5521\n","Epoch 137, Train Loss: 0.6423, Val Loss: 1.9279, F1 Micro: 0.4792, F1 Macro: 0.4442, Accuracy: 0.4792\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.0408, Val Loss: 1.9748, F1 Micro: 0.2917, F1 Macro: 0.2029, Accuracy: 0.2917\n","Epoch 2, Train Loss: 1.8204, Val Loss: 2.0120, F1 Micro: 0.2812, F1 Macro: 0.1783, Accuracy: 0.2812\n","Epoch 3, Train Loss: 1.7310, Val Loss: 1.9524, F1 Micro: 0.2188, F1 Macro: 0.1871, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.7514, Val Loss: 1.9806, F1 Micro: 0.2500, F1 Macro: 0.1983, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.6908, Val Loss: 1.8132, F1 Micro: 0.3542, F1 Macro: 0.3020, Accuracy: 0.3542\n","Epoch 6, Train Loss: 1.6431, Val Loss: 1.7149, F1 Micro: 0.3646, F1 Macro: 0.2751, Accuracy: 0.3646\n","Epoch 7, Train Loss: 1.6000, Val Loss: 2.2621, F1 Micro: 0.2604, F1 Macro: 0.2137, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6660, Val Loss: 2.0583, F1 Micro: 0.2708, F1 Macro: 0.2161, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.5882, Val Loss: 1.8862, F1 Micro: 0.3333, F1 Macro: 0.3082, Accuracy: 0.3333\n","Epoch 10, Train Loss: 1.6012, Val Loss: 1.7542, F1 Micro: 0.3438, F1 Macro: 0.3216, Accuracy: 0.3438\n","Epoch 11, Train Loss: 1.5459, Val Loss: 1.6711, F1 Micro: 0.4062, F1 Macro: 0.3666, Accuracy: 0.4062\n","Epoch 12, Train Loss: 1.5805, Val Loss: 2.2447, F1 Micro: 0.2292, F1 Macro: 0.2267, Accuracy: 0.2292\n","Epoch 13, Train Loss: 1.5163, Val Loss: 1.7686, F1 Micro: 0.3958, F1 Macro: 0.3110, Accuracy: 0.3958\n","Epoch 14, Train Loss: 1.4993, Val Loss: 1.7074, F1 Micro: 0.3750, F1 Macro: 0.3216, Accuracy: 0.3750\n","Epoch 15, Train Loss: 1.4690, Val Loss: 2.0709, F1 Micro: 0.2396, F1 Macro: 0.1293, Accuracy: 0.2396\n","Epoch 16, Train Loss: 1.4758, Val Loss: 1.8672, F1 Micro: 0.3646, F1 Macro: 0.3472, Accuracy: 0.3646\n","Epoch 17, Train Loss: 1.4996, Val Loss: 1.6657, F1 Micro: 0.4271, F1 Macro: 0.2950, Accuracy: 0.4271\n","Epoch 18, Train Loss: 1.4581, Val Loss: 2.1197, F1 Micro: 0.2292, F1 Macro: 0.1819, Accuracy: 0.2292\n","Epoch 19, Train Loss: 1.4187, Val Loss: 1.4882, F1 Micro: 0.5000, F1 Macro: 0.4066, Accuracy: 0.5000\n","Epoch 20, Train Loss: 1.4190, Val Loss: 1.5216, F1 Micro: 0.4896, F1 Macro: 0.4272, Accuracy: 0.4896\n","Epoch 21, Train Loss: 1.3755, Val Loss: 2.0369, F1 Micro: 0.2917, F1 Macro: 0.2041, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.3912, Val Loss: 1.7719, F1 Micro: 0.3646, F1 Macro: 0.3222, Accuracy: 0.3646\n","Epoch 23, Train Loss: 1.3934, Val Loss: 1.7650, F1 Micro: 0.3750, F1 Macro: 0.3697, Accuracy: 0.3750\n","Epoch 24, Train Loss: 1.3825, Val Loss: 1.6054, F1 Micro: 0.4062, F1 Macro: 0.3640, Accuracy: 0.4062\n","Epoch 25, Train Loss: 1.3095, Val Loss: 2.2891, F1 Micro: 0.2500, F1 Macro: 0.2206, Accuracy: 0.2500\n","Epoch 26, Train Loss: 1.3513, Val Loss: 1.6423, F1 Micro: 0.3958, F1 Macro: 0.2945, Accuracy: 0.3958\n","Epoch 27, Train Loss: 1.3412, Val Loss: 2.0977, F1 Micro: 0.2812, F1 Macro: 0.1793, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.3281, Val Loss: 1.8547, F1 Micro: 0.3438, F1 Macro: 0.2615, Accuracy: 0.3438\n","Epoch 29, Train Loss: 1.3361, Val Loss: 2.0787, F1 Micro: 0.3438, F1 Macro: 0.3179, Accuracy: 0.3438\n","Epoch 30, Train Loss: 1.3486, Val Loss: 1.4264, F1 Micro: 0.4792, F1 Macro: 0.4367, Accuracy: 0.4792\n","Epoch 31, Train Loss: 1.3578, Val Loss: 1.6907, F1 Micro: 0.3750, F1 Macro: 0.2828, Accuracy: 0.3750\n","Epoch 32, Train Loss: 1.2544, Val Loss: 1.8990, F1 Micro: 0.3958, F1 Macro: 0.3707, Accuracy: 0.3958\n","Epoch 33, Train Loss: 1.2824, Val Loss: 1.6281, F1 Micro: 0.4271, F1 Macro: 0.3130, Accuracy: 0.4271\n","Epoch 34, Train Loss: 1.2763, Val Loss: 1.7352, F1 Micro: 0.4583, F1 Macro: 0.4011, Accuracy: 0.4583\n","Epoch 35, Train Loss: 1.2847, Val Loss: 1.7723, F1 Micro: 0.4792, F1 Macro: 0.4042, Accuracy: 0.4792\n","Epoch 36, Train Loss: 1.2441, Val Loss: 1.7058, F1 Micro: 0.3750, F1 Macro: 0.3292, Accuracy: 0.3750\n","Epoch 37, Train Loss: 1.2115, Val Loss: 1.6791, F1 Micro: 0.4271, F1 Macro: 0.3729, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.2524, Val Loss: 1.8563, F1 Micro: 0.3125, F1 Macro: 0.2034, Accuracy: 0.3125\n","Epoch 39, Train Loss: 1.4089, Val Loss: 1.9269, F1 Micro: 0.3854, F1 Macro: 0.2906, Accuracy: 0.3854\n","Epoch 40, Train Loss: 1.2129, Val Loss: 1.9005, F1 Micro: 0.3333, F1 Macro: 0.2862, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.1274, Val Loss: 2.1531, F1 Micro: 0.2708, F1 Macro: 0.2515, Accuracy: 0.2708\n","Epoch 42, Train Loss: 1.2595, Val Loss: 1.8678, F1 Micro: 0.3958, F1 Macro: 0.3751, Accuracy: 0.3958\n","Epoch 43, Train Loss: 1.2176, Val Loss: 1.7117, F1 Micro: 0.4375, F1 Macro: 0.4076, Accuracy: 0.4375\n","Epoch 44, Train Loss: 1.1514, Val Loss: 1.5504, F1 Micro: 0.4688, F1 Macro: 0.3938, Accuracy: 0.4688\n","Epoch 45, Train Loss: 1.1558, Val Loss: 1.9348, F1 Micro: 0.3750, F1 Macro: 0.2737, Accuracy: 0.3750\n","Epoch 46, Train Loss: 1.1882, Val Loss: 1.4990, F1 Micro: 0.4375, F1 Macro: 0.4134, Accuracy: 0.4375\n","Epoch 47, Train Loss: 1.0779, Val Loss: 1.4179, F1 Micro: 0.5104, F1 Macro: 0.4718, Accuracy: 0.5104\n","Epoch 48, Train Loss: 1.0826, Val Loss: 1.7832, F1 Micro: 0.4062, F1 Macro: 0.3720, Accuracy: 0.4062\n","Epoch 49, Train Loss: 1.0812, Val Loss: 1.7366, F1 Micro: 0.4583, F1 Macro: 0.4166, Accuracy: 0.4583\n","Epoch 50, Train Loss: 1.0722, Val Loss: 1.5549, F1 Micro: 0.4688, F1 Macro: 0.3812, Accuracy: 0.4688\n","Epoch 51, Train Loss: 0.9946, Val Loss: 1.8164, F1 Micro: 0.4583, F1 Macro: 0.3310, Accuracy: 0.4583\n","Epoch 52, Train Loss: 1.0722, Val Loss: 2.0578, F1 Micro: 0.3958, F1 Macro: 0.3595, Accuracy: 0.3958\n","Epoch 53, Train Loss: 1.1408, Val Loss: 1.6296, F1 Micro: 0.5104, F1 Macro: 0.4411, Accuracy: 0.5104\n","Epoch 54, Train Loss: 1.1632, Val Loss: 1.7432, F1 Micro: 0.4062, F1 Macro: 0.3039, Accuracy: 0.4062\n","Epoch 55, Train Loss: 1.0513, Val Loss: 1.4321, F1 Micro: 0.4896, F1 Macro: 0.4275, Accuracy: 0.4896\n","Epoch 56, Train Loss: 0.9842, Val Loss: 1.5614, F1 Micro: 0.5312, F1 Macro: 0.4482, Accuracy: 0.5312\n","Epoch 57, Train Loss: 1.0210, Val Loss: 2.8973, F1 Micro: 0.2604, F1 Macro: 0.1872, Accuracy: 0.2604\n","Epoch 58, Train Loss: 0.9940, Val Loss: 1.5539, F1 Micro: 0.4271, F1 Macro: 0.3524, Accuracy: 0.4271\n","Epoch 59, Train Loss: 1.0426, Val Loss: 2.5356, F1 Micro: 0.2604, F1 Macro: 0.2314, Accuracy: 0.2604\n","Epoch 60, Train Loss: 1.0511, Val Loss: 1.9659, F1 Micro: 0.4688, F1 Macro: 0.3732, Accuracy: 0.4688\n","Epoch 61, Train Loss: 1.0107, Val Loss: 1.9701, F1 Micro: 0.3958, F1 Macro: 0.3598, Accuracy: 0.3958\n","Epoch 62, Train Loss: 0.9841, Val Loss: 1.2983, F1 Micro: 0.5833, F1 Macro: 0.5160, Accuracy: 0.5833\n","Epoch 63, Train Loss: 0.9457, Val Loss: 1.6249, F1 Micro: 0.5208, F1 Macro: 0.4939, Accuracy: 0.5208\n","Epoch 64, Train Loss: 0.9984, Val Loss: 1.7332, F1 Micro: 0.5104, F1 Macro: 0.4940, Accuracy: 0.5104\n","Epoch 65, Train Loss: 1.0328, Val Loss: 1.5938, F1 Micro: 0.5000, F1 Macro: 0.4786, Accuracy: 0.5000\n","Epoch 66, Train Loss: 0.9847, Val Loss: 2.9532, F1 Micro: 0.2917, F1 Macro: 0.2734, Accuracy: 0.2917\n","Epoch 67, Train Loss: 0.9473, Val Loss: 1.4211, F1 Micro: 0.5833, F1 Macro: 0.5580, Accuracy: 0.5833\n","Epoch 68, Train Loss: 1.0014, Val Loss: 1.4255, F1 Micro: 0.4479, F1 Macro: 0.3967, Accuracy: 0.4479\n","Epoch 69, Train Loss: 0.9726, Val Loss: 1.5910, F1 Micro: 0.5104, F1 Macro: 0.4384, Accuracy: 0.5104\n","Epoch 70, Train Loss: 1.0283, Val Loss: 2.7849, F1 Micro: 0.4062, F1 Macro: 0.3167, Accuracy: 0.4062\n","Epoch 71, Train Loss: 1.1969, Val Loss: 1.7187, F1 Micro: 0.5000, F1 Macro: 0.4267, Accuracy: 0.5000\n","Epoch 72, Train Loss: 1.0074, Val Loss: 1.6429, F1 Micro: 0.4271, F1 Macro: 0.3848, Accuracy: 0.4271\n","Epoch 73, Train Loss: 0.9428, Val Loss: 1.4305, F1 Micro: 0.5417, F1 Macro: 0.5203, Accuracy: 0.5417\n","Epoch 74, Train Loss: 0.9365, Val Loss: 1.9450, F1 Micro: 0.4583, F1 Macro: 0.3835, Accuracy: 0.4583\n","Epoch 75, Train Loss: 0.9483, Val Loss: 1.1754, F1 Micro: 0.6562, F1 Macro: 0.5898, Accuracy: 0.6562\n","Epoch 76, Train Loss: 0.9156, Val Loss: 1.7118, F1 Micro: 0.4479, F1 Macro: 0.3950, Accuracy: 0.4479\n","Epoch 77, Train Loss: 0.9722, Val Loss: 1.6297, F1 Micro: 0.5208, F1 Macro: 0.4342, Accuracy: 0.5208\n","Epoch 78, Train Loss: 0.9123, Val Loss: 1.8009, F1 Micro: 0.3854, F1 Macro: 0.3432, Accuracy: 0.3854\n","Epoch 79, Train Loss: 0.8407, Val Loss: 1.4546, F1 Micro: 0.5521, F1 Macro: 0.5101, Accuracy: 0.5521\n","Epoch 80, Train Loss: 0.8702, Val Loss: 1.2834, F1 Micro: 0.5938, F1 Macro: 0.5269, Accuracy: 0.5938\n","Epoch 81, Train Loss: 0.8443, Val Loss: 1.7201, F1 Micro: 0.4583, F1 Macro: 0.4344, Accuracy: 0.4583\n","Epoch 82, Train Loss: 0.8392, Val Loss: 1.3922, F1 Micro: 0.5625, F1 Macro: 0.5527, Accuracy: 0.5625\n","Epoch 83, Train Loss: 0.7737, Val Loss: 1.4055, F1 Micro: 0.5312, F1 Macro: 0.4685, Accuracy: 0.5312\n","Epoch 84, Train Loss: 0.7674, Val Loss: 1.9565, F1 Micro: 0.5208, F1 Macro: 0.4575, Accuracy: 0.5208\n","Epoch 85, Train Loss: 0.8086, Val Loss: 1.5812, F1 Micro: 0.5208, F1 Macro: 0.4558, Accuracy: 0.5208\n","Epoch 86, Train Loss: 0.8337, Val Loss: 1.9497, F1 Micro: 0.5521, F1 Macro: 0.4163, Accuracy: 0.5521\n","Epoch 87, Train Loss: 0.9265, Val Loss: 1.6549, F1 Micro: 0.5521, F1 Macro: 0.5283, Accuracy: 0.5521\n","Epoch 88, Train Loss: 0.9722, Val Loss: 1.9532, F1 Micro: 0.4792, F1 Macro: 0.3861, Accuracy: 0.4792\n","Epoch 89, Train Loss: 0.9461, Val Loss: 1.7566, F1 Micro: 0.5000, F1 Macro: 0.4716, Accuracy: 0.5000\n","Epoch 90, Train Loss: 0.9293, Val Loss: 1.5372, F1 Micro: 0.5000, F1 Macro: 0.4209, Accuracy: 0.5000\n","Epoch 91, Train Loss: 0.8120, Val Loss: 1.3744, F1 Micro: 0.6250, F1 Macro: 0.5993, Accuracy: 0.6250\n","Epoch 92, Train Loss: 0.8011, Val Loss: 1.3362, F1 Micro: 0.6146, F1 Macro: 0.5855, Accuracy: 0.6146\n","Epoch 93, Train Loss: 0.8133, Val Loss: 2.5074, F1 Micro: 0.3646, F1 Macro: 0.3218, Accuracy: 0.3646\n","Epoch 94, Train Loss: 0.8102, Val Loss: 1.8070, F1 Micro: 0.5104, F1 Macro: 0.4560, Accuracy: 0.5104\n","Epoch 95, Train Loss: 0.7892, Val Loss: 1.5770, F1 Micro: 0.5833, F1 Macro: 0.5515, Accuracy: 0.5833\n","Epoch 96, Train Loss: 0.8183, Val Loss: 1.6078, F1 Micro: 0.5000, F1 Macro: 0.3766, Accuracy: 0.5000\n","Epoch 97, Train Loss: 0.7286, Val Loss: 1.9898, F1 Micro: 0.4896, F1 Macro: 0.3742, Accuracy: 0.4896\n","Epoch 98, Train Loss: 0.7082, Val Loss: 1.6862, F1 Micro: 0.5104, F1 Macro: 0.5109, Accuracy: 0.5104\n","Epoch 99, Train Loss: 0.7532, Val Loss: 1.9740, F1 Micro: 0.5000, F1 Macro: 0.4449, Accuracy: 0.5000\n","Epoch 100, Train Loss: 0.8516, Val Loss: 1.5398, F1 Micro: 0.6042, F1 Macro: 0.5761, Accuracy: 0.6042\n","Epoch 101, Train Loss: 0.7516, Val Loss: 1.5256, F1 Micro: 0.5625, F1 Macro: 0.5008, Accuracy: 0.5625\n","Epoch 102, Train Loss: 0.7878, Val Loss: 1.9795, F1 Micro: 0.4896, F1 Macro: 0.4317, Accuracy: 0.4896\n","Epoch 103, Train Loss: 0.7655, Val Loss: 1.9189, F1 Micro: 0.4167, F1 Macro: 0.4238, Accuracy: 0.4167\n","Epoch 104, Train Loss: 0.7079, Val Loss: 1.3713, F1 Micro: 0.6562, F1 Macro: 0.6407, Accuracy: 0.6562\n","Epoch 105, Train Loss: 0.7187, Val Loss: 1.9571, F1 Micro: 0.5312, F1 Macro: 0.5305, Accuracy: 0.5312\n","Epoch 106, Train Loss: 0.8627, Val Loss: 2.5235, F1 Micro: 0.4688, F1 Macro: 0.3087, Accuracy: 0.4688\n","Epoch 107, Train Loss: 0.8941, Val Loss: 1.6966, F1 Micro: 0.4896, F1 Macro: 0.4102, Accuracy: 0.4896\n","Epoch 108, Train Loss: 0.7484, Val Loss: 1.2345, F1 Micro: 0.6250, F1 Macro: 0.6101, Accuracy: 0.6250\n","Epoch 109, Train Loss: 0.6761, Val Loss: 1.3339, F1 Micro: 0.5938, F1 Macro: 0.5355, Accuracy: 0.5938\n","Epoch 110, Train Loss: 0.6481, Val Loss: 1.2848, F1 Micro: 0.6354, F1 Macro: 0.5862, Accuracy: 0.6354\n","Epoch 111, Train Loss: 0.6556, Val Loss: 1.7511, F1 Micro: 0.5104, F1 Macro: 0.4420, Accuracy: 0.5104\n","Epoch 112, Train Loss: 0.7159, Val Loss: 1.6873, F1 Micro: 0.5312, F1 Macro: 0.4866, Accuracy: 0.5312\n","Epoch 113, Train Loss: 0.6304, Val Loss: 1.2844, F1 Micro: 0.6146, F1 Macro: 0.5904, Accuracy: 0.6146\n","Epoch 114, Train Loss: 0.6537, Val Loss: 1.3768, F1 Micro: 0.5521, F1 Macro: 0.5103, Accuracy: 0.5521\n","Epoch 115, Train Loss: 0.6266, Val Loss: 1.2700, F1 Micro: 0.6146, F1 Macro: 0.5729, Accuracy: 0.6146\n","Epoch 116, Train Loss: 0.8608, Val Loss: 1.9502, F1 Micro: 0.5000, F1 Macro: 0.4546, Accuracy: 0.5000\n","Epoch 117, Train Loss: 0.7288, Val Loss: 1.4237, F1 Micro: 0.6562, F1 Macro: 0.6165, Accuracy: 0.6562\n","Epoch 118, Train Loss: 0.7508, Val Loss: 2.5627, F1 Micro: 0.2917, F1 Macro: 0.2278, Accuracy: 0.2917\n","Epoch 119, Train Loss: 0.8872, Val Loss: 2.4637, F1 Micro: 0.4583, F1 Macro: 0.4303, Accuracy: 0.4583\n","Epoch 120, Train Loss: 0.8125, Val Loss: 1.4202, F1 Micro: 0.5625, F1 Macro: 0.5159, Accuracy: 0.5625\n","Epoch 121, Train Loss: 0.7016, Val Loss: 1.9520, F1 Micro: 0.5312, F1 Macro: 0.4752, Accuracy: 0.5312\n","Epoch 122, Train Loss: 0.6523, Val Loss: 1.4634, F1 Micro: 0.5833, F1 Macro: 0.5534, Accuracy: 0.5833\n","Epoch 123, Train Loss: 0.6933, Val Loss: 1.9924, F1 Micro: 0.4583, F1 Macro: 0.4065, Accuracy: 0.4583\n","Epoch 124, Train Loss: 0.6764, Val Loss: 1.3164, F1 Micro: 0.6667, F1 Macro: 0.6414, Accuracy: 0.6667\n","Epoch 125, Train Loss: 0.7747, Val Loss: 2.2320, F1 Micro: 0.5938, F1 Macro: 0.4734, Accuracy: 0.5938\n","Epoch 126, Train Loss: 0.7598, Val Loss: 2.6281, F1 Micro: 0.4583, F1 Macro: 0.4154, Accuracy: 0.4583\n","Epoch 127, Train Loss: 0.6791, Val Loss: 1.4758, F1 Micro: 0.6250, F1 Macro: 0.6067, Accuracy: 0.6250\n","Epoch 128, Train Loss: 0.6186, Val Loss: 1.2896, F1 Micro: 0.6458, F1 Macro: 0.6275, Accuracy: 0.6458\n","Epoch 129, Train Loss: 0.7369, Val Loss: 2.2932, F1 Micro: 0.4062, F1 Macro: 0.3415, Accuracy: 0.4062\n","Epoch 130, Train Loss: 0.7737, Val Loss: 2.4342, F1 Micro: 0.3854, F1 Macro: 0.3833, Accuracy: 0.3854\n","Epoch 131, Train Loss: 0.6871, Val Loss: 1.9095, F1 Micro: 0.5312, F1 Macro: 0.3883, Accuracy: 0.5312\n","Epoch 132, Train Loss: 0.8295, Val Loss: 1.2995, F1 Micro: 0.5833, F1 Macro: 0.5340, Accuracy: 0.5833\n","Epoch 133, Train Loss: 0.7765, Val Loss: 1.7389, F1 Micro: 0.5521, F1 Macro: 0.4392, Accuracy: 0.5521\n","Epoch 134, Train Loss: 0.7743, Val Loss: 1.4125, F1 Micro: 0.5833, F1 Macro: 0.5372, Accuracy: 0.5833\n","Epoch 135, Train Loss: 0.6955, Val Loss: 1.4893, F1 Micro: 0.5625, F1 Macro: 0.5342, Accuracy: 0.5625\n","Epoch 136, Train Loss: 0.6250, Val Loss: 1.4126, F1 Micro: 0.5729, F1 Macro: 0.5545, Accuracy: 0.5729\n","Epoch 137, Train Loss: 0.7141, Val Loss: 1.4004, F1 Micro: 0.6354, F1 Macro: 0.5505, Accuracy: 0.6354\n","Epoch 138, Train Loss: 0.6438, Val Loss: 1.5115, F1 Micro: 0.6354, F1 Macro: 0.6144, Accuracy: 0.6354\n","Epoch 139, Train Loss: 0.6868, Val Loss: 2.3408, F1 Micro: 0.4375, F1 Macro: 0.3292, Accuracy: 0.4375\n","Epoch 140, Train Loss: 0.8277, Val Loss: 1.6332, F1 Micro: 0.5729, F1 Macro: 0.5524, Accuracy: 0.5729\n","Epoch 141, Train Loss: 0.6419, Val Loss: 1.4562, F1 Micro: 0.6146, F1 Macro: 0.6091, Accuracy: 0.6146\n","Epoch 142, Train Loss: 0.5615, Val Loss: 1.4655, F1 Micro: 0.5625, F1 Macro: 0.5176, Accuracy: 0.5625\n","Epoch 143, Train Loss: 0.5652, Val Loss: 1.9527, F1 Micro: 0.4896, F1 Macro: 0.4638, Accuracy: 0.4896\n","Epoch 144, Train Loss: 0.5905, Val Loss: 2.0814, F1 Micro: 0.4479, F1 Macro: 0.4480, Accuracy: 0.4479\n","Epoch 145, Train Loss: 0.6296, Val Loss: 1.4989, F1 Micro: 0.6354, F1 Macro: 0.5743, Accuracy: 0.6354\n","Epoch 146, Train Loss: 0.7337, Val Loss: 1.5753, F1 Micro: 0.5729, F1 Macro: 0.5500, Accuracy: 0.5729\n","Epoch 147, Train Loss: 0.7570, Val Loss: 1.6166, F1 Micro: 0.5729, F1 Macro: 0.5768, Accuracy: 0.5729\n","Epoch 148, Train Loss: 0.5957, Val Loss: 1.5011, F1 Micro: 0.6354, F1 Macro: 0.6250, Accuracy: 0.6354\n","Epoch 149, Train Loss: 0.6847, Val Loss: 4.1407, F1 Micro: 0.4479, F1 Macro: 0.3624, Accuracy: 0.4479\n","Epoch 150, Train Loss: 0.7192, Val Loss: 1.7956, F1 Micro: 0.5729, F1 Macro: 0.5465, Accuracy: 0.5729\n","Epoch 151, Train Loss: 0.6812, Val Loss: 3.1883, F1 Micro: 0.3542, F1 Macro: 0.2291, Accuracy: 0.3542\n","Epoch 152, Train Loss: 0.8102, Val Loss: 2.6982, F1 Micro: 0.4062, F1 Macro: 0.3251, Accuracy: 0.4062\n","Epoch 153, Train Loss: 0.7401, Val Loss: 1.6768, F1 Micro: 0.5521, F1 Macro: 0.5317, Accuracy: 0.5521\n","Epoch 154, Train Loss: 0.6149, Val Loss: 2.1889, F1 Micro: 0.4583, F1 Macro: 0.4368, Accuracy: 0.4583\n","Epoch 155, Train Loss: 0.5880, Val Loss: 1.9843, F1 Micro: 0.5208, F1 Macro: 0.4604, Accuracy: 0.5208\n","Epoch 156, Train Loss: 0.5204, Val Loss: 2.0242, F1 Micro: 0.4896, F1 Macro: 0.4649, Accuracy: 0.4896\n","Epoch 157, Train Loss: 0.6979, Val Loss: 1.9807, F1 Micro: 0.5208, F1 Macro: 0.4526, Accuracy: 0.5208\n","Epoch 158, Train Loss: 0.6475, Val Loss: 1.4723, F1 Micro: 0.5625, F1 Macro: 0.5288, Accuracy: 0.5625\n","Epoch 159, Train Loss: 0.6433, Val Loss: 2.0745, F1 Micro: 0.5000, F1 Macro: 0.4451, Accuracy: 0.5000\n","Epoch 160, Train Loss: 0.5392, Val Loss: 1.3478, F1 Micro: 0.6250, F1 Macro: 0.6064, Accuracy: 0.6250\n","Epoch 161, Train Loss: 0.5281, Val Loss: 1.5564, F1 Micro: 0.6042, F1 Macro: 0.5870, Accuracy: 0.6042\n","Epoch 162, Train Loss: 0.5370, Val Loss: 1.7716, F1 Micro: 0.5208, F1 Macro: 0.4868, Accuracy: 0.5208\n","Epoch 163, Train Loss: 0.5535, Val Loss: 2.2798, F1 Micro: 0.5208, F1 Macro: 0.4299, Accuracy: 0.5208\n","Epoch 164, Train Loss: 0.7110, Val Loss: 1.5041, F1 Micro: 0.6354, F1 Macro: 0.6006, Accuracy: 0.6354\n","Epoch 165, Train Loss: 0.5829, Val Loss: 1.5378, F1 Micro: 0.5833, F1 Macro: 0.5120, Accuracy: 0.5833\n","Epoch 166, Train Loss: 0.5007, Val Loss: 1.5068, F1 Micro: 0.6250, F1 Macro: 0.6047, Accuracy: 0.6250\n","Epoch 167, Train Loss: 0.5064, Val Loss: 1.9974, F1 Micro: 0.5000, F1 Macro: 0.4147, Accuracy: 0.5000\n","Epoch 168, Train Loss: 0.5724, Val Loss: 1.6468, F1 Micro: 0.5312, F1 Macro: 0.4712, Accuracy: 0.5312\n","Epoch 169, Train Loss: 0.6372, Val Loss: 1.8243, F1 Micro: 0.4792, F1 Macro: 0.4589, Accuracy: 0.4792\n","Epoch 170, Train Loss: 0.5196, Val Loss: 1.8372, F1 Micro: 0.5208, F1 Macro: 0.4985, Accuracy: 0.5208\n","Epoch 171, Train Loss: 0.6431, Val Loss: 2.9366, F1 Micro: 0.3542, F1 Macro: 0.3123, Accuracy: 0.3542\n","Epoch 172, Train Loss: 0.7472, Val Loss: 2.3387, F1 Micro: 0.4375, F1 Macro: 0.4105, Accuracy: 0.4375\n","Epoch 173, Train Loss: 0.5212, Val Loss: 1.4397, F1 Micro: 0.6354, F1 Macro: 0.6272, Accuracy: 0.6354\n","Epoch 174, Train Loss: 0.4821, Val Loss: 1.3862, F1 Micro: 0.5833, F1 Macro: 0.5439, Accuracy: 0.5833\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.2151, Val Loss: 2.3693, F1 Micro: 0.2396, F1 Macro: 0.1193, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.8437, Val Loss: 1.8954, F1 Micro: 0.2188, F1 Macro: 0.1334, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7816, Val Loss: 1.7791, F1 Micro: 0.2292, F1 Macro: 0.1603, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.7548, Val Loss: 2.0576, F1 Micro: 0.2396, F1 Macro: 0.1826, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.6639, Val Loss: 1.8167, F1 Micro: 0.2396, F1 Macro: 0.1907, Accuracy: 0.2396\n","Epoch 6, Train Loss: 1.6517, Val Loss: 2.0642, F1 Micro: 0.2812, F1 Macro: 0.2558, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.6098, Val Loss: 1.7343, F1 Micro: 0.3021, F1 Macro: 0.2555, Accuracy: 0.3021\n","Epoch 8, Train Loss: 1.5509, Val Loss: 1.8455, F1 Micro: 0.3333, F1 Macro: 0.3115, Accuracy: 0.3333\n","Epoch 9, Train Loss: 1.5137, Val Loss: 1.8039, F1 Micro: 0.2812, F1 Macro: 0.2608, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.4844, Val Loss: 2.1432, F1 Micro: 0.2396, F1 Macro: 0.1647, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.5402, Val Loss: 1.7352, F1 Micro: 0.3021, F1 Macro: 0.2588, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.5087, Val Loss: 2.0398, F1 Micro: 0.2500, F1 Macro: 0.1926, Accuracy: 0.2500\n","Epoch 13, Train Loss: 1.5014, Val Loss: 1.7662, F1 Micro: 0.2396, F1 Macro: 0.1928, Accuracy: 0.2396\n","Epoch 14, Train Loss: 1.5011, Val Loss: 1.6464, F1 Micro: 0.3542, F1 Macro: 0.3013, Accuracy: 0.3542\n","Epoch 15, Train Loss: 1.4458, Val Loss: 2.2301, F1 Micro: 0.3542, F1 Macro: 0.2833, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5357, Val Loss: 1.8848, F1 Micro: 0.3646, F1 Macro: 0.3416, Accuracy: 0.3646\n","Epoch 17, Train Loss: 1.4151, Val Loss: 1.6251, F1 Micro: 0.3854, F1 Macro: 0.3368, Accuracy: 0.3854\n","Epoch 18, Train Loss: 1.4268, Val Loss: 2.0397, F1 Micro: 0.2500, F1 Macro: 0.1917, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.4294, Val Loss: 1.8667, F1 Micro: 0.3750, F1 Macro: 0.3403, Accuracy: 0.3750\n","Epoch 20, Train Loss: 1.4067, Val Loss: 1.6640, F1 Micro: 0.3229, F1 Macro: 0.2897, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.3399, Val Loss: 1.7555, F1 Micro: 0.3229, F1 Macro: 0.2888, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.3485, Val Loss: 1.8485, F1 Micro: 0.3021, F1 Macro: 0.2300, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.3388, Val Loss: 2.4114, F1 Micro: 0.2917, F1 Macro: 0.2576, Accuracy: 0.2917\n","Epoch 24, Train Loss: 1.4576, Val Loss: 1.7298, F1 Micro: 0.3542, F1 Macro: 0.3016, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.4502, Val Loss: 2.0314, F1 Micro: 0.2917, F1 Macro: 0.2555, Accuracy: 0.2917\n","Epoch 26, Train Loss: 1.3467, Val Loss: 2.8349, F1 Micro: 0.1979, F1 Macro: 0.1499, Accuracy: 0.1979\n","Epoch 27, Train Loss: 1.3358, Val Loss: 1.9322, F1 Micro: 0.2917, F1 Macro: 0.2537, Accuracy: 0.2917\n","Epoch 28, Train Loss: 1.3272, Val Loss: 1.6105, F1 Micro: 0.4062, F1 Macro: 0.3922, Accuracy: 0.4062\n","Epoch 29, Train Loss: 1.2931, Val Loss: 1.5601, F1 Micro: 0.4062, F1 Macro: 0.3899, Accuracy: 0.4062\n","Epoch 30, Train Loss: 1.2925, Val Loss: 1.8125, F1 Micro: 0.3750, F1 Macro: 0.3046, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.2779, Val Loss: 1.4752, F1 Micro: 0.5000, F1 Macro: 0.4859, Accuracy: 0.5000\n","Epoch 32, Train Loss: 1.2665, Val Loss: 2.0154, F1 Micro: 0.2812, F1 Macro: 0.2579, Accuracy: 0.2812\n","Epoch 33, Train Loss: 1.2266, Val Loss: 1.5439, F1 Micro: 0.4271, F1 Macro: 0.4348, Accuracy: 0.4271\n","Epoch 34, Train Loss: 1.3222, Val Loss: 1.7046, F1 Micro: 0.3750, F1 Macro: 0.3090, Accuracy: 0.3750\n","Epoch 35, Train Loss: 1.2751, Val Loss: 1.6879, F1 Micro: 0.4062, F1 Macro: 0.3483, Accuracy: 0.4062\n","Epoch 36, Train Loss: 1.2233, Val Loss: 2.1032, F1 Micro: 0.2917, F1 Macro: 0.2078, Accuracy: 0.2917\n","Epoch 37, Train Loss: 1.2523, Val Loss: 1.5998, F1 Micro: 0.3854, F1 Macro: 0.3730, Accuracy: 0.3854\n","Epoch 38, Train Loss: 1.2291, Val Loss: 2.0846, F1 Micro: 0.2812, F1 Macro: 0.2307, Accuracy: 0.2812\n","Epoch 39, Train Loss: 1.2989, Val Loss: 2.0493, F1 Micro: 0.3750, F1 Macro: 0.3376, Accuracy: 0.3750\n","Epoch 40, Train Loss: 1.2621, Val Loss: 1.4279, F1 Micro: 0.4896, F1 Macro: 0.4695, Accuracy: 0.4896\n","Epoch 41, Train Loss: 1.1242, Val Loss: 1.7285, F1 Micro: 0.4167, F1 Macro: 0.3995, Accuracy: 0.4167\n","Epoch 42, Train Loss: 1.1230, Val Loss: 2.0772, F1 Micro: 0.3750, F1 Macro: 0.3448, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.1213, Val Loss: 2.4270, F1 Micro: 0.2708, F1 Macro: 0.2213, Accuracy: 0.2708\n","Epoch 44, Train Loss: 1.1564, Val Loss: 2.4978, F1 Micro: 0.3229, F1 Macro: 0.2678, Accuracy: 0.3229\n","Epoch 45, Train Loss: 1.1727, Val Loss: 2.5936, F1 Micro: 0.2188, F1 Macro: 0.1688, Accuracy: 0.2188\n","Epoch 46, Train Loss: 1.0445, Val Loss: 1.6427, F1 Micro: 0.3438, F1 Macro: 0.3380, Accuracy: 0.3438\n","Epoch 47, Train Loss: 1.1018, Val Loss: 1.6679, F1 Micro: 0.4375, F1 Macro: 0.4127, Accuracy: 0.4375\n","Epoch 48, Train Loss: 1.1039, Val Loss: 1.6748, F1 Micro: 0.3958, F1 Macro: 0.3291, Accuracy: 0.3958\n","Epoch 49, Train Loss: 1.0624, Val Loss: 1.7756, F1 Micro: 0.3750, F1 Macro: 0.3670, Accuracy: 0.3750\n","Epoch 50, Train Loss: 1.0142, Val Loss: 1.5541, F1 Micro: 0.4479, F1 Macro: 0.4182, Accuracy: 0.4479\n","Epoch 51, Train Loss: 0.9866, Val Loss: 2.1217, F1 Micro: 0.4167, F1 Macro: 0.3811, Accuracy: 0.4167\n","Epoch 52, Train Loss: 1.0011, Val Loss: 1.5132, F1 Micro: 0.4583, F1 Macro: 0.4544, Accuracy: 0.4583\n","Epoch 53, Train Loss: 1.0600, Val Loss: 2.1307, F1 Micro: 0.3438, F1 Macro: 0.3210, Accuracy: 0.3438\n","Epoch 54, Train Loss: 1.0709, Val Loss: 2.6672, F1 Micro: 0.3854, F1 Macro: 0.2956, Accuracy: 0.3854\n","Epoch 55, Train Loss: 1.0609, Val Loss: 2.2172, F1 Micro: 0.3333, F1 Macro: 0.3066, Accuracy: 0.3333\n","Epoch 56, Train Loss: 1.0416, Val Loss: 2.4228, F1 Micro: 0.3646, F1 Macro: 0.3148, Accuracy: 0.3646\n","Epoch 57, Train Loss: 1.0664, Val Loss: 3.0851, F1 Micro: 0.3854, F1 Macro: 0.3644, Accuracy: 0.3854\n","Epoch 58, Train Loss: 1.0202, Val Loss: 1.5449, F1 Micro: 0.5104, F1 Macro: 0.5126, Accuracy: 0.5104\n","Epoch 59, Train Loss: 1.1194, Val Loss: 3.1322, F1 Micro: 0.3542, F1 Macro: 0.2929, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.1038, Val Loss: 1.8484, F1 Micro: 0.4167, F1 Macro: 0.4028, Accuracy: 0.4167\n","Epoch 61, Train Loss: 1.0154, Val Loss: 1.5862, F1 Micro: 0.4896, F1 Macro: 0.4514, Accuracy: 0.4896\n","Epoch 62, Train Loss: 1.0281, Val Loss: 2.2176, F1 Micro: 0.4167, F1 Macro: 0.3676, Accuracy: 0.4167\n","Epoch 63, Train Loss: 1.0153, Val Loss: 1.3304, F1 Micro: 0.5625, F1 Macro: 0.5558, Accuracy: 0.5625\n","Epoch 64, Train Loss: 0.9906, Val Loss: 2.8648, F1 Micro: 0.2708, F1 Macro: 0.2061, Accuracy: 0.2708\n","Epoch 65, Train Loss: 1.0559, Val Loss: 3.0169, F1 Micro: 0.3021, F1 Macro: 0.2455, Accuracy: 0.3021\n","Epoch 66, Train Loss: 1.0016, Val Loss: 1.8900, F1 Micro: 0.4375, F1 Macro: 0.3943, Accuracy: 0.4375\n","Epoch 67, Train Loss: 0.9550, Val Loss: 1.7259, F1 Micro: 0.4479, F1 Macro: 0.4178, Accuracy: 0.4479\n","Epoch 68, Train Loss: 0.9374, Val Loss: 1.5546, F1 Micro: 0.4792, F1 Macro: 0.4215, Accuracy: 0.4792\n","Epoch 69, Train Loss: 0.9702, Val Loss: 3.0095, F1 Micro: 0.3958, F1 Macro: 0.3655, Accuracy: 0.3958\n","Epoch 70, Train Loss: 0.9017, Val Loss: 2.1101, F1 Micro: 0.3229, F1 Macro: 0.3079, Accuracy: 0.3229\n","Epoch 71, Train Loss: 0.9038, Val Loss: 2.2105, F1 Micro: 0.3125, F1 Macro: 0.2652, Accuracy: 0.3125\n","Epoch 72, Train Loss: 0.9868, Val Loss: 1.8387, F1 Micro: 0.4583, F1 Macro: 0.4173, Accuracy: 0.4583\n","Epoch 73, Train Loss: 1.0342, Val Loss: 1.6732, F1 Micro: 0.4688, F1 Macro: 0.4602, Accuracy: 0.4688\n","Epoch 74, Train Loss: 0.9958, Val Loss: 1.4475, F1 Micro: 0.4792, F1 Macro: 0.4487, Accuracy: 0.4792\n","Epoch 75, Train Loss: 1.1756, Val Loss: 6.5190, F1 Micro: 0.2083, F1 Macro: 0.1537, Accuracy: 0.2083\n","Epoch 76, Train Loss: 1.1932, Val Loss: 1.8791, F1 Micro: 0.4792, F1 Macro: 0.4538, Accuracy: 0.4792\n","Epoch 77, Train Loss: 0.9766, Val Loss: 1.4531, F1 Micro: 0.5000, F1 Macro: 0.4823, Accuracy: 0.5000\n","Epoch 78, Train Loss: 1.0113, Val Loss: 1.4445, F1 Micro: 0.5104, F1 Macro: 0.5192, Accuracy: 0.5104\n","Epoch 79, Train Loss: 0.8834, Val Loss: 2.3088, F1 Micro: 0.3333, F1 Macro: 0.2900, Accuracy: 0.3333\n","Epoch 80, Train Loss: 0.8785, Val Loss: 1.6453, F1 Micro: 0.4583, F1 Macro: 0.4336, Accuracy: 0.4583\n","Epoch 81, Train Loss: 0.8781, Val Loss: 2.0893, F1 Micro: 0.3646, F1 Macro: 0.3550, Accuracy: 0.3646\n","Epoch 82, Train Loss: 0.8057, Val Loss: 1.9284, F1 Micro: 0.4688, F1 Macro: 0.4385, Accuracy: 0.4688\n","Epoch 83, Train Loss: 0.8441, Val Loss: 1.8646, F1 Micro: 0.4167, F1 Macro: 0.3656, Accuracy: 0.4167\n","Epoch 84, Train Loss: 0.8815, Val Loss: 2.7460, F1 Micro: 0.3750, F1 Macro: 0.3472, Accuracy: 0.3750\n","Epoch 85, Train Loss: 0.8973, Val Loss: 2.7967, F1 Micro: 0.3958, F1 Macro: 0.3399, Accuracy: 0.3958\n","Epoch 86, Train Loss: 0.7917, Val Loss: 1.8473, F1 Micro: 0.5000, F1 Macro: 0.4735, Accuracy: 0.5000\n","Epoch 87, Train Loss: 0.8197, Val Loss: 1.6395, F1 Micro: 0.4688, F1 Macro: 0.4514, Accuracy: 0.4688\n","Epoch 88, Train Loss: 0.7774, Val Loss: 1.9194, F1 Micro: 0.4583, F1 Macro: 0.4223, Accuracy: 0.4583\n","Epoch 89, Train Loss: 0.7596, Val Loss: 1.9879, F1 Micro: 0.4062, F1 Macro: 0.3686, Accuracy: 0.4062\n","Epoch 90, Train Loss: 0.8176, Val Loss: 2.8459, F1 Micro: 0.3646, F1 Macro: 0.3205, Accuracy: 0.3646\n","Epoch 91, Train Loss: 0.8718, Val Loss: 1.8005, F1 Micro: 0.5208, F1 Macro: 0.4931, Accuracy: 0.5208\n","Epoch 92, Train Loss: 0.8948, Val Loss: 2.2158, F1 Micro: 0.3750, F1 Macro: 0.3652, Accuracy: 0.3750\n","Epoch 93, Train Loss: 0.8275, Val Loss: 1.6142, F1 Micro: 0.4479, F1 Macro: 0.4133, Accuracy: 0.4479\n","Epoch 94, Train Loss: 0.7307, Val Loss: 1.5756, F1 Micro: 0.4583, F1 Macro: 0.4418, Accuracy: 0.4583\n","Epoch 95, Train Loss: 0.7806, Val Loss: 1.7561, F1 Micro: 0.4896, F1 Macro: 0.4838, Accuracy: 0.4896\n","Epoch 96, Train Loss: 0.8144, Val Loss: 1.5948, F1 Micro: 0.5938, F1 Macro: 0.5808, Accuracy: 0.5938\n","Epoch 97, Train Loss: 0.7341, Val Loss: 1.9106, F1 Micro: 0.4062, F1 Macro: 0.3852, Accuracy: 0.4062\n","Epoch 98, Train Loss: 0.7745, Val Loss: 1.8925, F1 Micro: 0.4583, F1 Macro: 0.4285, Accuracy: 0.4583\n","Epoch 99, Train Loss: 0.9232, Val Loss: 2.9088, F1 Micro: 0.3438, F1 Macro: 0.2709, Accuracy: 0.3438\n","Epoch 100, Train Loss: 0.8168, Val Loss: 1.7564, F1 Micro: 0.5000, F1 Macro: 0.4723, Accuracy: 0.5000\n","Epoch 101, Train Loss: 0.7399, Val Loss: 1.7842, F1 Micro: 0.4792, F1 Macro: 0.4728, Accuracy: 0.4792\n","Epoch 102, Train Loss: 0.7176, Val Loss: 2.5219, F1 Micro: 0.3958, F1 Macro: 0.3896, Accuracy: 0.3958\n","Epoch 103, Train Loss: 0.8271, Val Loss: 2.8101, F1 Micro: 0.3542, F1 Macro: 0.3110, Accuracy: 0.3542\n","Epoch 104, Train Loss: 0.8250, Val Loss: 1.6976, F1 Micro: 0.4583, F1 Macro: 0.4423, Accuracy: 0.4583\n","Epoch 105, Train Loss: 0.7396, Val Loss: 1.6143, F1 Micro: 0.5208, F1 Macro: 0.4895, Accuracy: 0.5208\n","Epoch 106, Train Loss: 0.7392, Val Loss: 1.5411, F1 Micro: 0.4062, F1 Macro: 0.3991, Accuracy: 0.4062\n","Epoch 107, Train Loss: 0.6798, Val Loss: 1.7830, F1 Micro: 0.4375, F1 Macro: 0.4281, Accuracy: 0.4375\n","Epoch 108, Train Loss: 0.7251, Val Loss: 3.2810, F1 Micro: 0.3646, F1 Macro: 0.3664, Accuracy: 0.3646\n","Epoch 109, Train Loss: 0.7756, Val Loss: 2.5681, F1 Micro: 0.3542, F1 Macro: 0.2854, Accuracy: 0.3542\n","Epoch 110, Train Loss: 0.7161, Val Loss: 1.8740, F1 Micro: 0.4792, F1 Macro: 0.4736, Accuracy: 0.4792\n","Epoch 111, Train Loss: 0.7193, Val Loss: 1.7998, F1 Micro: 0.5104, F1 Macro: 0.5107, Accuracy: 0.5104\n","Epoch 112, Train Loss: 0.7046, Val Loss: 2.2694, F1 Micro: 0.3854, F1 Macro: 0.3757, Accuracy: 0.3854\n","Epoch 113, Train Loss: 0.7011, Val Loss: 1.7954, F1 Micro: 0.4896, F1 Macro: 0.4659, Accuracy: 0.4896\n","Epoch 114, Train Loss: 0.6630, Val Loss: 1.9257, F1 Micro: 0.4062, F1 Macro: 0.4024, Accuracy: 0.4062\n","Epoch 115, Train Loss: 0.7101, Val Loss: 3.2086, F1 Micro: 0.3125, F1 Macro: 0.2991, Accuracy: 0.3125\n","Epoch 116, Train Loss: 0.7475, Val Loss: 1.4829, F1 Micro: 0.5312, F1 Macro: 0.5106, Accuracy: 0.5312\n","Epoch 117, Train Loss: 0.6795, Val Loss: 1.5121, F1 Micro: 0.5938, F1 Macro: 0.5756, Accuracy: 0.5938\n","Epoch 118, Train Loss: 0.5828, Val Loss: 1.8849, F1 Micro: 0.4479, F1 Macro: 0.4213, Accuracy: 0.4479\n","Epoch 119, Train Loss: 0.7877, Val Loss: 1.9453, F1 Micro: 0.5417, F1 Macro: 0.5144, Accuracy: 0.5417\n","Epoch 120, Train Loss: 0.7237, Val Loss: 1.7386, F1 Micro: 0.5417, F1 Macro: 0.5280, Accuracy: 0.5417\n","Epoch 121, Train Loss: 0.6686, Val Loss: 1.2613, F1 Micro: 0.5938, F1 Macro: 0.6060, Accuracy: 0.5938\n","Epoch 122, Train Loss: 0.7021, Val Loss: 4.0979, F1 Micro: 0.3958, F1 Macro: 0.3587, Accuracy: 0.3958\n","Epoch 123, Train Loss: 0.8911, Val Loss: 3.8486, F1 Micro: 0.3646, F1 Macro: 0.3211, Accuracy: 0.3646\n","Epoch 124, Train Loss: 0.8332, Val Loss: 1.5337, F1 Micro: 0.5938, F1 Macro: 0.5940, Accuracy: 0.5938\n","Epoch 125, Train Loss: 0.8960, Val Loss: 5.4815, F1 Micro: 0.2917, F1 Macro: 0.2384, Accuracy: 0.2917\n","Epoch 126, Train Loss: 0.9863, Val Loss: 1.7847, F1 Micro: 0.5312, F1 Macro: 0.4928, Accuracy: 0.5312\n","Epoch 127, Train Loss: 0.7277, Val Loss: 1.5642, F1 Micro: 0.5417, F1 Macro: 0.5382, Accuracy: 0.5417\n","Epoch 128, Train Loss: 0.6852, Val Loss: 1.4432, F1 Micro: 0.5729, F1 Macro: 0.5786, Accuracy: 0.5729\n","Epoch 129, Train Loss: 0.6304, Val Loss: 1.5341, F1 Micro: 0.5729, F1 Macro: 0.5779, Accuracy: 0.5729\n","Epoch 130, Train Loss: 0.6210, Val Loss: 1.3611, F1 Micro: 0.5833, F1 Macro: 0.5949, Accuracy: 0.5833\n","Epoch 131, Train Loss: 0.6107, Val Loss: 1.9275, F1 Micro: 0.5208, F1 Macro: 0.5225, Accuracy: 0.5208\n","Epoch 132, Train Loss: 0.5991, Val Loss: 1.8267, F1 Micro: 0.4792, F1 Macro: 0.4909, Accuracy: 0.4792\n","Epoch 133, Train Loss: 0.8404, Val Loss: 2.9613, F1 Micro: 0.3646, F1 Macro: 0.3425, Accuracy: 0.3646\n","Epoch 134, Train Loss: 0.7770, Val Loss: 2.0072, F1 Micro: 0.4583, F1 Macro: 0.4232, Accuracy: 0.4583\n","Epoch 135, Train Loss: 0.6517, Val Loss: 1.4800, F1 Micro: 0.5833, F1 Macro: 0.5918, Accuracy: 0.5833\n","Epoch 136, Train Loss: 0.6429, Val Loss: 2.0853, F1 Micro: 0.4375, F1 Macro: 0.4297, Accuracy: 0.4375\n","Epoch 137, Train Loss: 0.6227, Val Loss: 1.8004, F1 Micro: 0.4792, F1 Macro: 0.4882, Accuracy: 0.4792\n","Epoch 138, Train Loss: 0.6112, Val Loss: 2.4004, F1 Micro: 0.4896, F1 Macro: 0.4447, Accuracy: 0.4896\n","Epoch 139, Train Loss: 0.5689, Val Loss: 1.7748, F1 Micro: 0.5625, F1 Macro: 0.5198, Accuracy: 0.5625\n","Epoch 140, Train Loss: 0.5792, Val Loss: 1.8236, F1 Micro: 0.4688, F1 Macro: 0.4944, Accuracy: 0.4688\n","Epoch 141, Train Loss: 0.5788, Val Loss: 2.2963, F1 Micro: 0.4062, F1 Macro: 0.3960, Accuracy: 0.4062\n","Epoch 142, Train Loss: 0.6434, Val Loss: 1.8538, F1 Micro: 0.5104, F1 Macro: 0.5101, Accuracy: 0.5104\n","Epoch 143, Train Loss: 0.6059, Val Loss: 1.3968, F1 Micro: 0.6250, F1 Macro: 0.6201, Accuracy: 0.6250\n","Epoch 144, Train Loss: 0.6102, Val Loss: 1.9173, F1 Micro: 0.5312, F1 Macro: 0.5220, Accuracy: 0.5312\n","Epoch 145, Train Loss: 0.6118, Val Loss: 1.5832, F1 Micro: 0.6042, F1 Macro: 0.6036, Accuracy: 0.6042\n","Epoch 146, Train Loss: 0.6716, Val Loss: 1.6240, F1 Micro: 0.5208, F1 Macro: 0.5290, Accuracy: 0.5208\n","Epoch 147, Train Loss: 0.6886, Val Loss: 2.6333, F1 Micro: 0.4896, F1 Macro: 0.4781, Accuracy: 0.4896\n","Epoch 148, Train Loss: 0.7592, Val Loss: 2.3792, F1 Micro: 0.4167, F1 Macro: 0.3805, Accuracy: 0.4167\n","Epoch 149, Train Loss: 0.7336, Val Loss: 1.5829, F1 Micro: 0.5312, F1 Macro: 0.5334, Accuracy: 0.5312\n","Epoch 150, Train Loss: 0.6668, Val Loss: 1.8034, F1 Micro: 0.4583, F1 Macro: 0.4294, Accuracy: 0.4583\n","Epoch 151, Train Loss: 0.6451, Val Loss: 1.3684, F1 Micro: 0.6042, F1 Macro: 0.6100, Accuracy: 0.6042\n","Epoch 152, Train Loss: 0.6566, Val Loss: 1.3248, F1 Micro: 0.6146, F1 Macro: 0.6161, Accuracy: 0.6146\n","Epoch 153, Train Loss: 0.6163, Val Loss: 2.1122, F1 Micro: 0.3750, F1 Macro: 0.3473, Accuracy: 0.3750\n","Epoch 154, Train Loss: 0.6873, Val Loss: 2.7523, F1 Micro: 0.4688, F1 Macro: 0.4050, Accuracy: 0.4688\n","Epoch 155, Train Loss: 0.6700, Val Loss: 1.6455, F1 Micro: 0.6146, F1 Macro: 0.6114, Accuracy: 0.6146\n","Epoch 156, Train Loss: 0.6072, Val Loss: 1.7632, F1 Micro: 0.5104, F1 Macro: 0.5051, Accuracy: 0.5104\n","Epoch 157, Train Loss: 0.5703, Val Loss: 1.9124, F1 Micro: 0.4896, F1 Macro: 0.4809, Accuracy: 0.4896\n","Epoch 158, Train Loss: 0.5356, Val Loss: 2.0358, F1 Micro: 0.5938, F1 Macro: 0.5880, Accuracy: 0.5938\n","Epoch 159, Train Loss: 0.5896, Val Loss: 2.5536, F1 Micro: 0.3854, F1 Macro: 0.3906, Accuracy: 0.3854\n","Epoch 160, Train Loss: 0.6379, Val Loss: 1.9516, F1 Micro: 0.5312, F1 Macro: 0.5306, Accuracy: 0.5312\n","Epoch 161, Train Loss: 0.5443, Val Loss: 1.8268, F1 Micro: 0.5104, F1 Macro: 0.4808, Accuracy: 0.5104\n","Epoch 162, Train Loss: 0.4792, Val Loss: 1.5463, F1 Micro: 0.5417, F1 Macro: 0.5569, Accuracy: 0.5417\n","Epoch 163, Train Loss: 0.5016, Val Loss: 1.6599, F1 Micro: 0.6042, F1 Macro: 0.6040, Accuracy: 0.6042\n","Epoch 164, Train Loss: 0.5036, Val Loss: 1.9798, F1 Micro: 0.5625, F1 Macro: 0.5315, Accuracy: 0.5625\n","Epoch 165, Train Loss: 0.5288, Val Loss: 2.0070, F1 Micro: 0.5104, F1 Macro: 0.4794, Accuracy: 0.5104\n","Epoch 166, Train Loss: 0.5466, Val Loss: 1.9579, F1 Micro: 0.5521, F1 Macro: 0.5388, Accuracy: 0.5521\n","Epoch 167, Train Loss: 0.5775, Val Loss: 2.3620, F1 Micro: 0.4375, F1 Macro: 0.4322, Accuracy: 0.4375\n","Epoch 168, Train Loss: 0.5592, Val Loss: 1.8030, F1 Micro: 0.5833, F1 Macro: 0.5883, Accuracy: 0.5833\n","Epoch 169, Train Loss: 0.4758, Val Loss: 2.6471, F1 Micro: 0.4375, F1 Macro: 0.4282, Accuracy: 0.4375\n","Epoch 170, Train Loss: 0.5098, Val Loss: 1.8495, F1 Micro: 0.6146, F1 Macro: 0.6100, Accuracy: 0.6146\n","Epoch 171, Train Loss: 0.5387, Val Loss: 2.4391, F1 Micro: 0.4479, F1 Macro: 0.4107, Accuracy: 0.4479\n","Epoch 172, Train Loss: 0.5499, Val Loss: 2.1086, F1 Micro: 0.5208, F1 Macro: 0.5046, Accuracy: 0.5208\n","Epoch 173, Train Loss: 0.5178, Val Loss: 2.2687, F1 Micro: 0.3854, F1 Macro: 0.3586, Accuracy: 0.3854\n","Epoch 174, Train Loss: 0.5124, Val Loss: 1.8771, F1 Micro: 0.5521, F1 Macro: 0.5309, Accuracy: 0.5521\n","Epoch 175, Train Loss: 0.4806, Val Loss: 2.0638, F1 Micro: 0.5208, F1 Macro: 0.5187, Accuracy: 0.5208\n","Epoch 176, Train Loss: 0.4899, Val Loss: 1.8882, F1 Micro: 0.5417, F1 Macro: 0.5465, Accuracy: 0.5417\n","Epoch 177, Train Loss: 0.5274, Val Loss: 1.6168, F1 Micro: 0.5729, F1 Macro: 0.5880, Accuracy: 0.5729\n","Epoch 178, Train Loss: 0.4932, Val Loss: 2.4471, F1 Micro: 0.4688, F1 Macro: 0.4327, Accuracy: 0.4688\n","Epoch 179, Train Loss: 0.4667, Val Loss: 2.1071, F1 Micro: 0.4062, F1 Macro: 0.4059, Accuracy: 0.4062\n","Epoch 180, Train Loss: 0.5011, Val Loss: 1.5197, F1 Micro: 0.6146, F1 Macro: 0.6207, Accuracy: 0.6146\n","Epoch 181, Train Loss: 0.6279, Val Loss: 1.8198, F1 Micro: 0.5625, F1 Macro: 0.5519, Accuracy: 0.5625\n","Epoch 182, Train Loss: 0.6218, Val Loss: 1.6900, F1 Micro: 0.5833, F1 Macro: 0.5802, Accuracy: 0.5833\n","Epoch 183, Train Loss: 0.4672, Val Loss: 1.7362, F1 Micro: 0.5833, F1 Macro: 0.5584, Accuracy: 0.5833\n","Epoch 184, Train Loss: 0.5131, Val Loss: 1.5849, F1 Micro: 0.5521, F1 Macro: 0.5580, Accuracy: 0.5521\n","Epoch 185, Train Loss: 0.5421, Val Loss: 1.8316, F1 Micro: 0.5104, F1 Macro: 0.5157, Accuracy: 0.5104\n","Epoch 186, Train Loss: 0.5175, Val Loss: 2.3029, F1 Micro: 0.5104, F1 Macro: 0.4971, Accuracy: 0.5104\n","Epoch 187, Train Loss: 0.4973, Val Loss: 1.9495, F1 Micro: 0.4896, F1 Macro: 0.4796, Accuracy: 0.4896\n","Epoch 188, Train Loss: 0.5305, Val Loss: 2.0114, F1 Micro: 0.5521, F1 Macro: 0.5393, Accuracy: 0.5521\n","Epoch 189, Train Loss: 0.5182, Val Loss: 1.6767, F1 Micro: 0.6562, F1 Macro: 0.6560, Accuracy: 0.6562\n","Epoch 190, Train Loss: 0.5307, Val Loss: 2.3909, F1 Micro: 0.5312, F1 Macro: 0.5090, Accuracy: 0.5312\n","Epoch 191, Train Loss: 0.4732, Val Loss: 1.7329, F1 Micro: 0.6562, F1 Macro: 0.6462, Accuracy: 0.6562\n","Epoch 192, Train Loss: 0.4517, Val Loss: 1.6762, F1 Micro: 0.6042, F1 Macro: 0.6024, Accuracy: 0.6042\n","Epoch 193, Train Loss: 0.4092, Val Loss: 1.5824, F1 Micro: 0.6875, F1 Macro: 0.6830, Accuracy: 0.6875\n","Epoch 194, Train Loss: 0.4374, Val Loss: 2.8709, F1 Micro: 0.4479, F1 Macro: 0.4334, Accuracy: 0.4479\n","Epoch 195, Train Loss: 0.5243, Val Loss: 2.0020, F1 Micro: 0.5104, F1 Macro: 0.5323, Accuracy: 0.5104\n","Epoch 196, Train Loss: 0.5935, Val Loss: 2.6606, F1 Micro: 0.4375, F1 Macro: 0.3851, Accuracy: 0.4375\n","Epoch 197, Train Loss: 0.6756, Val Loss: 2.9529, F1 Micro: 0.4583, F1 Macro: 0.4281, Accuracy: 0.4583\n","Epoch 198, Train Loss: 0.6024, Val Loss: 2.5310, F1 Micro: 0.4792, F1 Macro: 0.4571, Accuracy: 0.4792\n","Epoch 199, Train Loss: 0.6349, Val Loss: 2.1640, F1 Micro: 0.5000, F1 Macro: 0.4572, Accuracy: 0.5000\n","Epoch 200, Train Loss: 0.5554, Val Loss: 1.7652, F1 Micro: 0.6146, F1 Macro: 0.6078, Accuracy: 0.6146\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.0765, Val Loss: 2.9612, F1 Micro: 0.2396, F1 Macro: 0.1187, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.9559, Val Loss: 1.8362, F1 Micro: 0.2396, F1 Macro: 0.2101, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7597, Val Loss: 1.8539, F1 Micro: 0.2812, F1 Macro: 0.2362, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.6922, Val Loss: 2.1145, F1 Micro: 0.2292, F1 Macro: 0.1711, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.7095, Val Loss: 1.8442, F1 Micro: 0.2708, F1 Macro: 0.1803, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.5830, Val Loss: 1.7511, F1 Micro: 0.3125, F1 Macro: 0.2604, Accuracy: 0.3125\n","Epoch 7, Train Loss: 1.5378, Val Loss: 2.1788, F1 Micro: 0.1875, F1 Macro: 0.1416, Accuracy: 0.1875\n","Epoch 8, Train Loss: 1.6563, Val Loss: 2.0411, F1 Micro: 0.2396, F1 Macro: 0.1658, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.5977, Val Loss: 1.9669, F1 Micro: 0.3333, F1 Macro: 0.2956, Accuracy: 0.3333\n","Epoch 10, Train Loss: 1.5672, Val Loss: 2.1960, F1 Micro: 0.1667, F1 Macro: 0.0712, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.5719, Val Loss: 1.7232, F1 Micro: 0.3750, F1 Macro: 0.3237, Accuracy: 0.3750\n","Epoch 12, Train Loss: 1.4907, Val Loss: 1.8218, F1 Micro: 0.3229, F1 Macro: 0.2618, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.4960, Val Loss: 2.4552, F1 Micro: 0.3229, F1 Macro: 0.2436, Accuracy: 0.3229\n","Epoch 14, Train Loss: 1.4860, Val Loss: 1.8105, F1 Micro: 0.3125, F1 Macro: 0.2516, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.4063, Val Loss: 1.6944, F1 Micro: 0.3542, F1 Macro: 0.3259, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.4374, Val Loss: 1.9988, F1 Micro: 0.3229, F1 Macro: 0.2565, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.4337, Val Loss: 1.8083, F1 Micro: 0.4062, F1 Macro: 0.3666, Accuracy: 0.4062\n","Epoch 18, Train Loss: 1.4369, Val Loss: 1.6372, F1 Micro: 0.3854, F1 Macro: 0.3739, Accuracy: 0.3854\n","Epoch 19, Train Loss: 1.4052, Val Loss: 1.7736, F1 Micro: 0.3542, F1 Macro: 0.3399, Accuracy: 0.3542\n","Epoch 20, Train Loss: 1.3637, Val Loss: 1.8236, F1 Micro: 0.3333, F1 Macro: 0.2634, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.3063, Val Loss: 1.8078, F1 Micro: 0.3333, F1 Macro: 0.2725, Accuracy: 0.3333\n","Epoch 22, Train Loss: 1.3165, Val Loss: 1.9926, F1 Micro: 0.3333, F1 Macro: 0.2712, Accuracy: 0.3333\n","Epoch 23, Train Loss: 1.3188, Val Loss: 1.9901, F1 Micro: 0.3125, F1 Macro: 0.2685, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.3384, Val Loss: 2.0913, F1 Micro: 0.4271, F1 Macro: 0.3734, Accuracy: 0.4271\n","Epoch 25, Train Loss: 1.3175, Val Loss: 1.8612, F1 Micro: 0.3854, F1 Macro: 0.3127, Accuracy: 0.3854\n","Epoch 26, Train Loss: 1.2440, Val Loss: 1.8046, F1 Micro: 0.3750, F1 Macro: 0.3218, Accuracy: 0.3750\n","Epoch 27, Train Loss: 1.2381, Val Loss: 1.9681, F1 Micro: 0.3125, F1 Macro: 0.3064, Accuracy: 0.3125\n","Epoch 28, Train Loss: 1.2457, Val Loss: 1.9958, F1 Micro: 0.3438, F1 Macro: 0.2804, Accuracy: 0.3438\n","Epoch 29, Train Loss: 1.2809, Val Loss: 1.7875, F1 Micro: 0.3750, F1 Macro: 0.3642, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.3238, Val Loss: 2.9615, F1 Micro: 0.3125, F1 Macro: 0.2334, Accuracy: 0.3125\n","Epoch 31, Train Loss: 1.3370, Val Loss: 1.7132, F1 Micro: 0.3750, F1 Macro: 0.3799, Accuracy: 0.3750\n","Epoch 32, Train Loss: 1.2446, Val Loss: 2.7910, F1 Micro: 0.2708, F1 Macro: 0.2132, Accuracy: 0.2708\n","Epoch 33, Train Loss: 1.1877, Val Loss: 2.1167, F1 Micro: 0.4479, F1 Macro: 0.4026, Accuracy: 0.4479\n","Epoch 34, Train Loss: 1.1597, Val Loss: 1.9201, F1 Micro: 0.4375, F1 Macro: 0.3685, Accuracy: 0.4375\n","Epoch 35, Train Loss: 1.1703, Val Loss: 2.4333, F1 Micro: 0.4167, F1 Macro: 0.3786, Accuracy: 0.4167\n","Epoch 36, Train Loss: 1.1790, Val Loss: 2.0357, F1 Micro: 0.3958, F1 Macro: 0.3432, Accuracy: 0.3958\n","Epoch 37, Train Loss: 1.2564, Val Loss: 1.7685, F1 Micro: 0.3854, F1 Macro: 0.3618, Accuracy: 0.3854\n","Epoch 38, Train Loss: 1.1588, Val Loss: 2.2985, F1 Micro: 0.3333, F1 Macro: 0.2382, Accuracy: 0.3333\n","Epoch 39, Train Loss: 1.1812, Val Loss: 1.8665, F1 Micro: 0.3958, F1 Macro: 0.3939, Accuracy: 0.3958\n","Epoch 40, Train Loss: 1.1594, Val Loss: 1.7107, F1 Micro: 0.4583, F1 Macro: 0.4587, Accuracy: 0.4583\n","Epoch 41, Train Loss: 1.1682, Val Loss: 1.4880, F1 Micro: 0.5208, F1 Macro: 0.5025, Accuracy: 0.5208\n","Epoch 42, Train Loss: 1.1553, Val Loss: 2.5436, F1 Micro: 0.3646, F1 Macro: 0.3513, Accuracy: 0.3646\n","Epoch 43, Train Loss: 1.1697, Val Loss: 2.7248, F1 Micro: 0.3021, F1 Macro: 0.2149, Accuracy: 0.3021\n","Epoch 44, Train Loss: 1.2218, Val Loss: 1.8571, F1 Micro: 0.3958, F1 Macro: 0.3666, Accuracy: 0.3958\n","Epoch 45, Train Loss: 1.0673, Val Loss: 1.7533, F1 Micro: 0.4792, F1 Macro: 0.4509, Accuracy: 0.4792\n","Epoch 46, Train Loss: 0.9840, Val Loss: 1.9154, F1 Micro: 0.3958, F1 Macro: 0.3785, Accuracy: 0.3958\n","Epoch 47, Train Loss: 1.0242, Val Loss: 1.8308, F1 Micro: 0.4479, F1 Macro: 0.4425, Accuracy: 0.4479\n","Epoch 48, Train Loss: 1.1888, Val Loss: 1.6301, F1 Micro: 0.4896, F1 Macro: 0.4693, Accuracy: 0.4896\n","Epoch 49, Train Loss: 1.0984, Val Loss: 1.7252, F1 Micro: 0.4479, F1 Macro: 0.4371, Accuracy: 0.4479\n","Epoch 50, Train Loss: 1.0487, Val Loss: 1.9436, F1 Micro: 0.4271, F1 Macro: 0.3924, Accuracy: 0.4271\n","Epoch 51, Train Loss: 1.0649, Val Loss: 1.7816, F1 Micro: 0.5625, F1 Macro: 0.5555, Accuracy: 0.5625\n","Epoch 52, Train Loss: 1.1108, Val Loss: 2.1650, F1 Micro: 0.3854, F1 Macro: 0.3710, Accuracy: 0.3854\n","Epoch 53, Train Loss: 1.0254, Val Loss: 2.2404, F1 Micro: 0.4271, F1 Macro: 0.3574, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.0616, Val Loss: 1.7704, F1 Micro: 0.4896, F1 Macro: 0.4631, Accuracy: 0.4896\n","Epoch 55, Train Loss: 1.0107, Val Loss: 2.5151, F1 Micro: 0.3854, F1 Macro: 0.3638, Accuracy: 0.3854\n","Epoch 56, Train Loss: 0.9187, Val Loss: 1.7466, F1 Micro: 0.4688, F1 Macro: 0.4716, Accuracy: 0.4688\n","Epoch 57, Train Loss: 0.9093, Val Loss: 1.6962, F1 Micro: 0.4583, F1 Macro: 0.4551, Accuracy: 0.4583\n","Epoch 58, Train Loss: 0.9292, Val Loss: 1.6685, F1 Micro: 0.5000, F1 Macro: 0.4597, Accuracy: 0.5000\n","Epoch 59, Train Loss: 0.9110, Val Loss: 1.8191, F1 Micro: 0.4896, F1 Macro: 0.4686, Accuracy: 0.4896\n","Epoch 60, Train Loss: 0.9294, Val Loss: 1.9711, F1 Micro: 0.4375, F1 Macro: 0.4020, Accuracy: 0.4375\n","Epoch 61, Train Loss: 0.9860, Val Loss: 2.5382, F1 Micro: 0.4062, F1 Macro: 0.4086, Accuracy: 0.4062\n","Epoch 62, Train Loss: 1.0155, Val Loss: 1.6709, F1 Micro: 0.5625, F1 Macro: 0.5630, Accuracy: 0.5625\n","Epoch 63, Train Loss: 0.9960, Val Loss: 1.6606, F1 Micro: 0.4583, F1 Macro: 0.4327, Accuracy: 0.4583\n","Epoch 64, Train Loss: 0.9887, Val Loss: 3.3062, F1 Micro: 0.2708, F1 Macro: 0.2124, Accuracy: 0.2708\n","Epoch 65, Train Loss: 0.9253, Val Loss: 2.4231, F1 Micro: 0.3646, F1 Macro: 0.3424, Accuracy: 0.3646\n","Epoch 66, Train Loss: 0.9430, Val Loss: 1.4872, F1 Micro: 0.5312, F1 Macro: 0.5207, Accuracy: 0.5312\n","Epoch 67, Train Loss: 0.9649, Val Loss: 1.9353, F1 Micro: 0.4896, F1 Macro: 0.4636, Accuracy: 0.4896\n","Epoch 68, Train Loss: 0.9256, Val Loss: 1.8493, F1 Micro: 0.4271, F1 Macro: 0.3992, Accuracy: 0.4271\n","Epoch 69, Train Loss: 0.9626, Val Loss: 3.0179, F1 Micro: 0.3542, F1 Macro: 0.2712, Accuracy: 0.3542\n","Epoch 70, Train Loss: 1.0316, Val Loss: 1.9226, F1 Micro: 0.4062, F1 Macro: 0.3726, Accuracy: 0.4062\n","Epoch 71, Train Loss: 0.8962, Val Loss: 1.7878, F1 Micro: 0.5104, F1 Macro: 0.5017, Accuracy: 0.5104\n","Epoch 72, Train Loss: 0.8754, Val Loss: 1.7589, F1 Micro: 0.4688, F1 Macro: 0.4565, Accuracy: 0.4688\n","Epoch 73, Train Loss: 0.8715, Val Loss: 2.1705, F1 Micro: 0.4479, F1 Macro: 0.4467, Accuracy: 0.4479\n","Epoch 74, Train Loss: 0.9236, Val Loss: 1.6598, F1 Micro: 0.5104, F1 Macro: 0.5154, Accuracy: 0.5104\n","Epoch 75, Train Loss: 0.9021, Val Loss: 1.8509, F1 Micro: 0.4896, F1 Macro: 0.4576, Accuracy: 0.4896\n","Epoch 76, Train Loss: 0.9333, Val Loss: 2.1733, F1 Micro: 0.4375, F1 Macro: 0.3991, Accuracy: 0.4375\n","Epoch 77, Train Loss: 0.9308, Val Loss: 1.9184, F1 Micro: 0.4479, F1 Macro: 0.4691, Accuracy: 0.4479\n","Epoch 78, Train Loss: 0.9391, Val Loss: 3.9879, F1 Micro: 0.2500, F1 Macro: 0.1830, Accuracy: 0.2500\n","Epoch 79, Train Loss: 0.9387, Val Loss: 2.5580, F1 Micro: 0.3646, F1 Macro: 0.3278, Accuracy: 0.3646\n","Epoch 80, Train Loss: 0.9149, Val Loss: 1.9779, F1 Micro: 0.4271, F1 Macro: 0.4317, Accuracy: 0.4271\n","Epoch 81, Train Loss: 0.8085, Val Loss: 1.9045, F1 Micro: 0.5000, F1 Macro: 0.5026, Accuracy: 0.5000\n","Epoch 82, Train Loss: 0.9444, Val Loss: 2.6090, F1 Micro: 0.4375, F1 Macro: 0.3807, Accuracy: 0.4375\n","Epoch 83, Train Loss: 0.8855, Val Loss: 1.7218, F1 Micro: 0.5000, F1 Macro: 0.4420, Accuracy: 0.5000\n","Epoch 84, Train Loss: 0.8585, Val Loss: 1.7505, F1 Micro: 0.5417, F1 Macro: 0.5238, Accuracy: 0.5417\n","Epoch 85, Train Loss: 0.8142, Val Loss: 2.1153, F1 Micro: 0.4792, F1 Macro: 0.4564, Accuracy: 0.4792\n","Epoch 86, Train Loss: 0.8070, Val Loss: 1.7924, F1 Micro: 0.5104, F1 Macro: 0.4735, Accuracy: 0.5104\n","Epoch 87, Train Loss: 0.8182, Val Loss: 1.6468, F1 Micro: 0.5104, F1 Macro: 0.4922, Accuracy: 0.5104\n","Epoch 88, Train Loss: 0.9001, Val Loss: 2.0233, F1 Micro: 0.4375, F1 Macro: 0.3939, Accuracy: 0.4375\n","Epoch 89, Train Loss: 0.9794, Val Loss: 2.2064, F1 Micro: 0.4167, F1 Macro: 0.4032, Accuracy: 0.4167\n","Epoch 90, Train Loss: 0.8128, Val Loss: 1.9088, F1 Micro: 0.4896, F1 Macro: 0.5022, Accuracy: 0.4896\n","Epoch 91, Train Loss: 0.8128, Val Loss: 1.8412, F1 Micro: 0.5729, F1 Macro: 0.5623, Accuracy: 0.5729\n","Epoch 92, Train Loss: 0.7803, Val Loss: 1.4777, F1 Micro: 0.6042, F1 Macro: 0.6050, Accuracy: 0.6042\n","Epoch 93, Train Loss: 0.7547, Val Loss: 1.5912, F1 Micro: 0.5938, F1 Macro: 0.5859, Accuracy: 0.5938\n","Epoch 94, Train Loss: 0.7393, Val Loss: 1.8261, F1 Micro: 0.5833, F1 Macro: 0.5626, Accuracy: 0.5833\n","Epoch 95, Train Loss: 0.7773, Val Loss: 1.9250, F1 Micro: 0.5208, F1 Macro: 0.5008, Accuracy: 0.5208\n","Epoch 96, Train Loss: 0.7890, Val Loss: 2.3838, F1 Micro: 0.4375, F1 Macro: 0.4113, Accuracy: 0.4375\n","Epoch 97, Train Loss: 0.7336, Val Loss: 1.8867, F1 Micro: 0.5000, F1 Macro: 0.4764, Accuracy: 0.5000\n","Epoch 98, Train Loss: 0.8589, Val Loss: 1.9633, F1 Micro: 0.4792, F1 Macro: 0.4678, Accuracy: 0.4792\n","Epoch 99, Train Loss: 0.7903, Val Loss: 1.9275, F1 Micro: 0.5417, F1 Macro: 0.5304, Accuracy: 0.5417\n","Epoch 100, Train Loss: 0.7779, Val Loss: 1.8712, F1 Micro: 0.5208, F1 Macro: 0.5112, Accuracy: 0.5208\n","Epoch 101, Train Loss: 0.7872, Val Loss: 2.1705, F1 Micro: 0.3854, F1 Macro: 0.3742, Accuracy: 0.3854\n","Epoch 102, Train Loss: 0.7256, Val Loss: 1.6403, F1 Micro: 0.5938, F1 Macro: 0.5935, Accuracy: 0.5938\n","Epoch 103, Train Loss: 0.7465, Val Loss: 1.9879, F1 Micro: 0.5833, F1 Macro: 0.5552, Accuracy: 0.5833\n","Epoch 104, Train Loss: 0.7912, Val Loss: 1.8125, F1 Micro: 0.5312, F1 Macro: 0.4931, Accuracy: 0.5312\n","Epoch 105, Train Loss: 0.6672, Val Loss: 1.6392, F1 Micro: 0.5208, F1 Macro: 0.4829, Accuracy: 0.5208\n","Epoch 106, Train Loss: 0.7043, Val Loss: 2.7566, F1 Micro: 0.4271, F1 Macro: 0.3989, Accuracy: 0.4271\n","Epoch 107, Train Loss: 0.8323, Val Loss: 2.0746, F1 Micro: 0.4688, F1 Macro: 0.4587, Accuracy: 0.4688\n","Epoch 108, Train Loss: 0.6972, Val Loss: 1.6930, F1 Micro: 0.5312, F1 Macro: 0.5414, Accuracy: 0.5312\n","Epoch 109, Train Loss: 0.6557, Val Loss: 1.7380, F1 Micro: 0.5729, F1 Macro: 0.5650, Accuracy: 0.5729\n","Epoch 110, Train Loss: 0.8078, Val Loss: 2.0212, F1 Micro: 0.4896, F1 Macro: 0.4720, Accuracy: 0.4896\n","Epoch 111, Train Loss: 0.7612, Val Loss: 1.4597, F1 Micro: 0.5833, F1 Macro: 0.5881, Accuracy: 0.5833\n","Epoch 112, Train Loss: 0.7814, Val Loss: 1.6957, F1 Micro: 0.5521, F1 Macro: 0.5496, Accuracy: 0.5521\n","Epoch 113, Train Loss: 0.6983, Val Loss: 2.0554, F1 Micro: 0.6042, F1 Macro: 0.5999, Accuracy: 0.6042\n","Epoch 114, Train Loss: 0.6591, Val Loss: 2.1312, F1 Micro: 0.5417, F1 Macro: 0.5036, Accuracy: 0.5417\n","Epoch 115, Train Loss: 0.6344, Val Loss: 2.0449, F1 Micro: 0.4479, F1 Macro: 0.4526, Accuracy: 0.4479\n","Epoch 116, Train Loss: 0.7147, Val Loss: 2.0427, F1 Micro: 0.5208, F1 Macro: 0.4959, Accuracy: 0.5208\n","Epoch 117, Train Loss: 0.7766, Val Loss: 1.5690, F1 Micro: 0.5104, F1 Macro: 0.4959, Accuracy: 0.5104\n","Epoch 118, Train Loss: 0.7510, Val Loss: 1.7355, F1 Micro: 0.5625, F1 Macro: 0.5732, Accuracy: 0.5625\n","Epoch 119, Train Loss: 0.8174, Val Loss: 1.8253, F1 Micro: 0.5625, F1 Macro: 0.5606, Accuracy: 0.5625\n","Epoch 120, Train Loss: 0.6803, Val Loss: 1.6887, F1 Micro: 0.5625, F1 Macro: 0.5722, Accuracy: 0.5625\n","Epoch 121, Train Loss: 0.6830, Val Loss: 1.8534, F1 Micro: 0.5833, F1 Macro: 0.5777, Accuracy: 0.5833\n","Epoch 122, Train Loss: 0.5870, Val Loss: 1.8596, F1 Micro: 0.5729, F1 Macro: 0.5945, Accuracy: 0.5729\n","Epoch 123, Train Loss: 0.6734, Val Loss: 1.6017, F1 Micro: 0.5625, F1 Macro: 0.5433, Accuracy: 0.5625\n","Epoch 124, Train Loss: 0.7309, Val Loss: 1.9872, F1 Micro: 0.5208, F1 Macro: 0.5306, Accuracy: 0.5208\n","Epoch 125, Train Loss: 0.7370, Val Loss: 1.9084, F1 Micro: 0.5833, F1 Macro: 0.5794, Accuracy: 0.5833\n","Epoch 126, Train Loss: 0.7306, Val Loss: 1.7917, F1 Micro: 0.5417, F1 Macro: 0.5048, Accuracy: 0.5417\n","Epoch 127, Train Loss: 0.6793, Val Loss: 2.3112, F1 Micro: 0.5000, F1 Macro: 0.4772, Accuracy: 0.5000\n","Epoch 128, Train Loss: 0.7189, Val Loss: 1.7734, F1 Micro: 0.5938, F1 Macro: 0.5949, Accuracy: 0.5938\n","Epoch 129, Train Loss: 0.6485, Val Loss: 1.6356, F1 Micro: 0.5938, F1 Macro: 0.5904, Accuracy: 0.5938\n","Epoch 130, Train Loss: 0.5850, Val Loss: 1.9286, F1 Micro: 0.5000, F1 Macro: 0.4977, Accuracy: 0.5000\n","Epoch 131, Train Loss: 0.6229, Val Loss: 1.6526, F1 Micro: 0.6354, F1 Macro: 0.6356, Accuracy: 0.6354\n","Epoch 132, Train Loss: 0.6348, Val Loss: 2.2983, F1 Micro: 0.4688, F1 Macro: 0.4484, Accuracy: 0.4688\n","Epoch 133, Train Loss: 0.6508, Val Loss: 1.7836, F1 Micro: 0.5729, F1 Macro: 0.5668, Accuracy: 0.5729\n","Epoch 134, Train Loss: 0.7464, Val Loss: 1.9086, F1 Micro: 0.5521, F1 Macro: 0.5292, Accuracy: 0.5521\n","Epoch 135, Train Loss: 0.7354, Val Loss: 1.9142, F1 Micro: 0.5417, F1 Macro: 0.5424, Accuracy: 0.5417\n","Epoch 136, Train Loss: 0.6993, Val Loss: 2.3059, F1 Micro: 0.5000, F1 Macro: 0.4730, Accuracy: 0.5000\n","Epoch 137, Train Loss: 0.6523, Val Loss: 1.9571, F1 Micro: 0.5521, F1 Macro: 0.5236, Accuracy: 0.5521\n","Epoch 138, Train Loss: 0.6138, Val Loss: 1.8067, F1 Micro: 0.5729, F1 Macro: 0.5482, Accuracy: 0.5729\n","Epoch 139, Train Loss: 0.6785, Val Loss: 1.5628, F1 Micro: 0.5938, F1 Macro: 0.6032, Accuracy: 0.5938\n","Epoch 140, Train Loss: 0.5652, Val Loss: 1.7365, F1 Micro: 0.6875, F1 Macro: 0.6872, Accuracy: 0.6875\n","Epoch 141, Train Loss: 0.6338, Val Loss: 1.5942, F1 Micro: 0.5521, F1 Macro: 0.5485, Accuracy: 0.5521\n","Epoch 142, Train Loss: 0.5540, Val Loss: 1.6088, F1 Micro: 0.5625, F1 Macro: 0.5567, Accuracy: 0.5625\n","Epoch 143, Train Loss: 0.5643, Val Loss: 1.8436, F1 Micro: 0.5729, F1 Macro: 0.5388, Accuracy: 0.5729\n","Epoch 144, Train Loss: 0.5895, Val Loss: 1.8886, F1 Micro: 0.5938, F1 Macro: 0.5846, Accuracy: 0.5938\n","Epoch 145, Train Loss: 0.5953, Val Loss: 1.9478, F1 Micro: 0.5521, F1 Macro: 0.5307, Accuracy: 0.5521\n","Epoch 146, Train Loss: 0.5567, Val Loss: 2.1895, F1 Micro: 0.5208, F1 Macro: 0.4814, Accuracy: 0.5208\n","Epoch 147, Train Loss: 0.6534, Val Loss: 2.8877, F1 Micro: 0.4375, F1 Macro: 0.4318, Accuracy: 0.4375\n","Epoch 148, Train Loss: 0.6864, Val Loss: 2.0916, F1 Micro: 0.5833, F1 Macro: 0.5465, Accuracy: 0.5833\n","Epoch 149, Train Loss: 0.7004, Val Loss: 2.3000, F1 Micro: 0.5729, F1 Macro: 0.5501, Accuracy: 0.5729\n","Epoch 150, Train Loss: 0.6315, Val Loss: 1.6801, F1 Micro: 0.6562, F1 Macro: 0.6487, Accuracy: 0.6562\n","Epoch 151, Train Loss: 0.6310, Val Loss: 1.7039, F1 Micro: 0.5729, F1 Macro: 0.5445, Accuracy: 0.5729\n","Epoch 152, Train Loss: 0.7719, Val Loss: 2.5870, F1 Micro: 0.4375, F1 Macro: 0.3946, Accuracy: 0.4375\n","Epoch 153, Train Loss: 0.5994, Val Loss: 2.1072, F1 Micro: 0.5312, F1 Macro: 0.4945, Accuracy: 0.5312\n","Epoch 154, Train Loss: 0.5384, Val Loss: 1.7068, F1 Micro: 0.5104, F1 Macro: 0.5112, Accuracy: 0.5104\n","Epoch 155, Train Loss: 0.5796, Val Loss: 1.6635, F1 Micro: 0.5729, F1 Macro: 0.5513, Accuracy: 0.5729\n","Epoch 156, Train Loss: 0.6466, Val Loss: 2.1375, F1 Micro: 0.5729, F1 Macro: 0.5565, Accuracy: 0.5729\n","Epoch 157, Train Loss: 0.5068, Val Loss: 1.7458, F1 Micro: 0.5521, F1 Macro: 0.5446, Accuracy: 0.5521\n","Epoch 158, Train Loss: 0.5123, Val Loss: 1.8877, F1 Micro: 0.4583, F1 Macro: 0.4217, Accuracy: 0.4583\n","Epoch 159, Train Loss: 0.5587, Val Loss: 2.4015, F1 Micro: 0.5104, F1 Macro: 0.5140, Accuracy: 0.5104\n","Epoch 160, Train Loss: 0.4762, Val Loss: 2.4268, F1 Micro: 0.5625, F1 Macro: 0.5089, Accuracy: 0.5625\n","Epoch 161, Train Loss: 0.5539, Val Loss: 1.5053, F1 Micro: 0.6354, F1 Macro: 0.6355, Accuracy: 0.6354\n","Epoch 162, Train Loss: 0.5206, Val Loss: 1.4695, F1 Micro: 0.6042, F1 Macro: 0.6086, Accuracy: 0.6042\n","Epoch 163, Train Loss: 0.5297, Val Loss: 1.6732, F1 Micro: 0.6042, F1 Macro: 0.5610, Accuracy: 0.6042\n","Epoch 164, Train Loss: 0.5273, Val Loss: 1.6446, F1 Micro: 0.6250, F1 Macro: 0.6205, Accuracy: 0.6250\n","Epoch 165, Train Loss: 0.4678, Val Loss: 1.9036, F1 Micro: 0.5833, F1 Macro: 0.5523, Accuracy: 0.5833\n","Epoch 166, Train Loss: 0.4880, Val Loss: 1.8734, F1 Micro: 0.5938, F1 Macro: 0.5645, Accuracy: 0.5938\n","Epoch 167, Train Loss: 0.5041, Val Loss: 1.6731, F1 Micro: 0.6458, F1 Macro: 0.6349, Accuracy: 0.6458\n","Epoch 168, Train Loss: 0.4511, Val Loss: 1.6540, F1 Micro: 0.5938, F1 Macro: 0.5846, Accuracy: 0.5938\n","Epoch 169, Train Loss: 0.6918, Val Loss: 2.8518, F1 Micro: 0.4688, F1 Macro: 0.4633, Accuracy: 0.4688\n","Epoch 170, Train Loss: 0.5672, Val Loss: 1.6359, F1 Micro: 0.5833, F1 Macro: 0.5918, Accuracy: 0.5833\n","Epoch 171, Train Loss: 0.5752, Val Loss: 1.9603, F1 Micro: 0.5417, F1 Macro: 0.5393, Accuracy: 0.5417\n","Epoch 172, Train Loss: 0.5964, Val Loss: 2.8521, F1 Micro: 0.4271, F1 Macro: 0.3769, Accuracy: 0.4271\n","Epoch 173, Train Loss: 0.6360, Val Loss: 2.4070, F1 Micro: 0.4896, F1 Macro: 0.4779, Accuracy: 0.4896\n","Epoch 174, Train Loss: 0.6268, Val Loss: 1.9351, F1 Micro: 0.5312, F1 Macro: 0.4801, Accuracy: 0.5312\n","Epoch 175, Train Loss: 0.6256, Val Loss: 2.1038, F1 Micro: 0.5417, F1 Macro: 0.5092, Accuracy: 0.5417\n","Epoch 176, Train Loss: 0.5559, Val Loss: 1.7523, F1 Micro: 0.6042, F1 Macro: 0.5987, Accuracy: 0.6042\n","Epoch 177, Train Loss: 0.4758, Val Loss: 1.5262, F1 Micro: 0.6042, F1 Macro: 0.6080, Accuracy: 0.6042\n","Epoch 178, Train Loss: 0.5287, Val Loss: 1.8461, F1 Micro: 0.5833, F1 Macro: 0.5685, Accuracy: 0.5833\n","Epoch 179, Train Loss: 0.4921, Val Loss: 1.9033, F1 Micro: 0.5729, F1 Macro: 0.5538, Accuracy: 0.5729\n","Epoch 180, Train Loss: 0.4969, Val Loss: 1.7158, F1 Micro: 0.6042, F1 Macro: 0.5932, Accuracy: 0.6042\n","Epoch 181, Train Loss: 0.5333, Val Loss: 2.9988, F1 Micro: 0.5000, F1 Macro: 0.4401, Accuracy: 0.5000\n","Epoch 182, Train Loss: 0.5887, Val Loss: 2.0570, F1 Micro: 0.5312, F1 Macro: 0.5328, Accuracy: 0.5312\n","Epoch 183, Train Loss: 0.6005, Val Loss: 2.7543, F1 Micro: 0.4792, F1 Macro: 0.4236, Accuracy: 0.4792\n","Epoch 184, Train Loss: 0.6332, Val Loss: 1.7938, F1 Micro: 0.6146, F1 Macro: 0.5990, Accuracy: 0.6146\n","Epoch 185, Train Loss: 0.5121, Val Loss: 1.5584, F1 Micro: 0.5521, F1 Macro: 0.5365, Accuracy: 0.5521\n","Epoch 186, Train Loss: 0.5039, Val Loss: 1.7854, F1 Micro: 0.5938, F1 Macro: 0.5718, Accuracy: 0.5938\n","Epoch 187, Train Loss: 0.4579, Val Loss: 2.1893, F1 Micro: 0.4896, F1 Macro: 0.4889, Accuracy: 0.4896\n","Epoch 188, Train Loss: 0.4947, Val Loss: 2.4925, F1 Micro: 0.5104, F1 Macro: 0.4911, Accuracy: 0.5104\n","Epoch 189, Train Loss: 0.5430, Val Loss: 2.5155, F1 Micro: 0.4271, F1 Macro: 0.4221, Accuracy: 0.4271\n","Epoch 190, Train Loss: 0.5392, Val Loss: 1.8172, F1 Micro: 0.5833, F1 Macro: 0.5590, Accuracy: 0.5833\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.6479166666666667\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8318, Val Loss: 1.7757, F1 Micro: 0.2396, F1 Macro: 0.2103, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7508, Val Loss: 1.7101, F1 Micro: 0.3125, F1 Macro: 0.2127, Accuracy: 0.3125\n","Epoch 3, Train Loss: 1.7110, Val Loss: 1.7443, F1 Micro: 0.1979, F1 Macro: 0.1797, Accuracy: 0.1979\n","Epoch 4, Train Loss: 1.6999, Val Loss: 1.6928, F1 Micro: 0.2812, F1 Macro: 0.2522, Accuracy: 0.2812\n","Epoch 5, Train Loss: 1.6941, Val Loss: 1.7220, F1 Micro: 0.2396, F1 Macro: 0.2559, Accuracy: 0.2396\n","Epoch 6, Train Loss: 1.6341, Val Loss: 1.7576, F1 Micro: 0.2292, F1 Macro: 0.2126, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.6179, Val Loss: 1.7466, F1 Micro: 0.2812, F1 Macro: 0.2294, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6424, Val Loss: 1.7144, F1 Micro: 0.2292, F1 Macro: 0.2215, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.6376, Val Loss: 1.6883, F1 Micro: 0.2917, F1 Macro: 0.2431, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.5739, Val Loss: 1.6985, F1 Micro: 0.3125, F1 Macro: 0.2761, Accuracy: 0.3125\n","Epoch 11, Train Loss: 1.5918, Val Loss: 1.6711, F1 Micro: 0.2812, F1 Macro: 0.2414, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.5567, Val Loss: 1.8481, F1 Micro: 0.3021, F1 Macro: 0.2634, Accuracy: 0.3021\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8066, Val Loss: 1.7921, F1 Micro: 0.2500, F1 Macro: 0.1421, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.7561, Val Loss: 1.7452, F1 Micro: 0.2604, F1 Macro: 0.1732, Accuracy: 0.2604\n","Epoch 3, Train Loss: 1.7651, Val Loss: 1.7284, F1 Micro: 0.2604, F1 Macro: 0.2067, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.6887, Val Loss: 1.7575, F1 Micro: 0.2604, F1 Macro: 0.2013, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.6942, Val Loss: 1.6666, F1 Micro: 0.2708, F1 Macro: 0.1927, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.6938, Val Loss: 1.6483, F1 Micro: 0.4167, F1 Macro: 0.3386, Accuracy: 0.4167\n","Epoch 7, Train Loss: 1.6652, Val Loss: 1.6717, F1 Micro: 0.3438, F1 Macro: 0.3056, Accuracy: 0.3438\n","Epoch 8, Train Loss: 1.6378, Val Loss: 1.6136, F1 Micro: 0.3438, F1 Macro: 0.2958, Accuracy: 0.3438\n","Epoch 9, Train Loss: 1.6326, Val Loss: 1.6390, F1 Micro: 0.3438, F1 Macro: 0.3013, Accuracy: 0.3438\n","Epoch 10, Train Loss: 1.6573, Val Loss: 1.6467, F1 Micro: 0.3229, F1 Macro: 0.3173, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.5993, Val Loss: 1.5885, F1 Micro: 0.3646, F1 Macro: 0.3267, Accuracy: 0.3646\n","Epoch 12, Train Loss: 1.6292, Val Loss: 1.6023, F1 Micro: 0.3438, F1 Macro: 0.3451, Accuracy: 0.3438\n","Epoch 13, Train Loss: 1.5987, Val Loss: 1.6418, F1 Micro: 0.3021, F1 Macro: 0.2539, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.5694, Val Loss: 2.0291, F1 Micro: 0.2500, F1 Macro: 0.1747, Accuracy: 0.2500\n","Epoch 15, Train Loss: 1.5565, Val Loss: 1.6212, F1 Micro: 0.3854, F1 Macro: 0.3585, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.5764, Val Loss: 1.7918, F1 Micro: 0.2812, F1 Macro: 0.2356, Accuracy: 0.2812\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8074, Val Loss: 1.7588, F1 Micro: 0.2500, F1 Macro: 0.2149, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.7405, Val Loss: 1.8032, F1 Micro: 0.1771, F1 Macro: 0.1342, Accuracy: 0.1771\n","Epoch 3, Train Loss: 1.6977, Val Loss: 1.8037, F1 Micro: 0.1562, F1 Macro: 0.1547, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.6907, Val Loss: 1.7326, F1 Micro: 0.3125, F1 Macro: 0.3001, Accuracy: 0.3125\n","Epoch 5, Train Loss: 1.6837, Val Loss: 1.8108, F1 Micro: 0.2188, F1 Macro: 0.1822, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.6757, Val Loss: 1.7076, F1 Micro: 0.2917, F1 Macro: 0.2508, Accuracy: 0.2917\n","Epoch 7, Train Loss: 1.6549, Val Loss: 1.6924, F1 Micro: 0.2812, F1 Macro: 0.2390, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6432, Val Loss: 1.6952, F1 Micro: 0.3438, F1 Macro: 0.2432, Accuracy: 0.3438\n","Epoch 9, Train Loss: 1.5984, Val Loss: 1.7366, F1 Micro: 0.3438, F1 Macro: 0.3382, Accuracy: 0.3438\n","Epoch 10, Train Loss: 1.6253, Val Loss: 1.7196, F1 Micro: 0.2708, F1 Macro: 0.2247, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.6158, Val Loss: 1.6790, F1 Micro: 0.3646, F1 Macro: 0.3289, Accuracy: 0.3646\n","Epoch 12, Train Loss: 1.5682, Val Loss: 1.7749, F1 Micro: 0.2917, F1 Macro: 0.2445, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.5512, Val Loss: 1.7308, F1 Micro: 0.3854, F1 Macro: 0.2569, Accuracy: 0.3854\n","Epoch 14, Train Loss: 1.5767, Val Loss: 1.6986, F1 Micro: 0.3021, F1 Macro: 0.2742, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.5246, Val Loss: 1.6696, F1 Micro: 0.3438, F1 Macro: 0.2944, Accuracy: 0.3438\n","Epoch 16, Train Loss: 1.5212, Val Loss: 1.6547, F1 Micro: 0.3750, F1 Macro: 0.3028, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.5199, Val Loss: 1.6657, F1 Micro: 0.3229, F1 Macro: 0.3288, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.5401, Val Loss: 1.6828, F1 Micro: 0.3750, F1 Macro: 0.3690, Accuracy: 0.3750\n","Epoch 19, Train Loss: 1.4994, Val Loss: 1.6155, F1 Micro: 0.3542, F1 Macro: 0.3161, Accuracy: 0.3542\n","Epoch 20, Train Loss: 1.5325, Val Loss: 1.5890, F1 Micro: 0.4375, F1 Macro: 0.3959, Accuracy: 0.4375\n","Epoch 21, Train Loss: 1.4939, Val Loss: 1.7081, F1 Micro: 0.2812, F1 Macro: 0.2476, Accuracy: 0.2812\n","Epoch 22, Train Loss: 1.4972, Val Loss: 1.7068, F1 Micro: 0.3438, F1 Macro: 0.2759, Accuracy: 0.3438\n","Epoch 23, Train Loss: 1.4700, Val Loss: 1.6416, F1 Micro: 0.3542, F1 Macro: 0.2767, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.4438, Val Loss: 1.7185, F1 Micro: 0.3542, F1 Macro: 0.3293, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.4821, Val Loss: 1.6703, F1 Micro: 0.3542, F1 Macro: 0.3081, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.4182, Val Loss: 1.6620, F1 Micro: 0.3646, F1 Macro: 0.2782, Accuracy: 0.3646\n","Epoch 27, Train Loss: 1.4246, Val Loss: 1.5699, F1 Micro: 0.4271, F1 Macro: 0.4102, Accuracy: 0.4271\n","Epoch 28, Train Loss: 1.4159, Val Loss: 1.6930, F1 Micro: 0.3438, F1 Macro: 0.3199, Accuracy: 0.3438\n","Epoch 29, Train Loss: 1.4106, Val Loss: 1.5369, F1 Micro: 0.4792, F1 Macro: 0.4023, Accuracy: 0.4792\n","Epoch 30, Train Loss: 1.4119, Val Loss: 1.7732, F1 Micro: 0.2917, F1 Macro: 0.3035, Accuracy: 0.2917\n","Epoch 31, Train Loss: 1.4013, Val Loss: 1.9687, F1 Micro: 0.3333, F1 Macro: 0.2939, Accuracy: 0.3333\n","Epoch 32, Train Loss: 1.3896, Val Loss: 2.0303, F1 Micro: 0.2917, F1 Macro: 0.2115, Accuracy: 0.2917\n","Epoch 33, Train Loss: 1.3708, Val Loss: 1.5580, F1 Micro: 0.4583, F1 Macro: 0.4340, Accuracy: 0.4583\n","Epoch 34, Train Loss: 1.3905, Val Loss: 1.5510, F1 Micro: 0.4271, F1 Macro: 0.3682, Accuracy: 0.4271\n","Epoch 35, Train Loss: 1.3609, Val Loss: 1.5933, F1 Micro: 0.4375, F1 Macro: 0.3569, Accuracy: 0.4375\n","Epoch 36, Train Loss: 1.3530, Val Loss: 1.6947, F1 Micro: 0.4062, F1 Macro: 0.3548, Accuracy: 0.4062\n","Epoch 37, Train Loss: 1.3558, Val Loss: 1.5972, F1 Micro: 0.4167, F1 Macro: 0.3516, Accuracy: 0.4167\n","Epoch 38, Train Loss: 1.3436, Val Loss: 1.5269, F1 Micro: 0.4271, F1 Macro: 0.4147, Accuracy: 0.4271\n","Epoch 39, Train Loss: 1.3017, Val Loss: 1.5580, F1 Micro: 0.4271, F1 Macro: 0.3855, Accuracy: 0.4271\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8079, Val Loss: 1.7673, F1 Micro: 0.2188, F1 Macro: 0.1468, Accuracy: 0.2188\n","Epoch 2, Train Loss: 1.7273, Val Loss: 1.7463, F1 Micro: 0.1979, F1 Macro: 0.1435, Accuracy: 0.1979\n","Epoch 3, Train Loss: 1.6736, Val Loss: 1.7648, F1 Micro: 0.2812, F1 Macro: 0.1958, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.7111, Val Loss: 1.7668, F1 Micro: 0.2292, F1 Macro: 0.1609, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.6768, Val Loss: 1.8388, F1 Micro: 0.3021, F1 Macro: 0.2511, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.6471, Val Loss: 1.7593, F1 Micro: 0.2292, F1 Macro: 0.2005, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.6340, Val Loss: 1.7841, F1 Micro: 0.2396, F1 Macro: 0.1789, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6508, Val Loss: 1.7659, F1 Micro: 0.2292, F1 Macro: 0.1753, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.6178, Val Loss: 1.6858, F1 Micro: 0.4062, F1 Macro: 0.3946, Accuracy: 0.4062\n","Epoch 10, Train Loss: 1.5992, Val Loss: 1.6825, F1 Micro: 0.3229, F1 Macro: 0.3033, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.5834, Val Loss: 1.7250, F1 Micro: 0.2708, F1 Macro: 0.2343, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.5603, Val Loss: 1.6897, F1 Micro: 0.3229, F1 Macro: 0.3063, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.5204, Val Loss: 1.6570, F1 Micro: 0.3438, F1 Macro: 0.3379, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.5266, Val Loss: 1.6591, F1 Micro: 0.3229, F1 Macro: 0.2602, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.5242, Val Loss: 1.6452, F1 Micro: 0.3542, F1 Macro: 0.3323, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5671, Val Loss: 1.7245, F1 Micro: 0.3333, F1 Macro: 0.2555, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.4994, Val Loss: 1.7155, F1 Micro: 0.3333, F1 Macro: 0.2848, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.5087, Val Loss: 1.6600, F1 Micro: 0.3333, F1 Macro: 0.2829, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.4963, Val Loss: 1.6843, F1 Micro: 0.3438, F1 Macro: 0.3215, Accuracy: 0.3438\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8021, Val Loss: 1.6785, F1 Micro: 0.2812, F1 Macro: 0.1916, Accuracy: 0.2812\n","Epoch 2, Train Loss: 1.7483, Val Loss: 1.7164, F1 Micro: 0.2500, F1 Macro: 0.1792, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.7172, Val Loss: 1.7350, F1 Micro: 0.2708, F1 Macro: 0.2583, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.6748, Val Loss: 1.6701, F1 Micro: 0.3021, F1 Macro: 0.2889, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.6739, Val Loss: 1.6682, F1 Micro: 0.3750, F1 Macro: 0.3548, Accuracy: 0.3750\n","Epoch 6, Train Loss: 1.6307, Val Loss: 1.6957, F1 Micro: 0.3750, F1 Macro: 0.3618, Accuracy: 0.3750\n","Epoch 7, Train Loss: 1.6340, Val Loss: 1.7436, F1 Micro: 0.2604, F1 Macro: 0.2322, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6094, Val Loss: 1.6688, F1 Micro: 0.3542, F1 Macro: 0.3119, Accuracy: 0.3542\n","Epoch 9, Train Loss: 1.6006, Val Loss: 1.7171, F1 Micro: 0.3125, F1 Macro: 0.3216, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.5486, Val Loss: 1.7326, F1 Micro: 0.3438, F1 Macro: 0.3042, Accuracy: 0.3438\n","Epoch 11, Train Loss: 1.5458, Val Loss: 1.7012, F1 Micro: 0.3125, F1 Macro: 0.3029, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.5454, Val Loss: 1.7271, F1 Micro: 0.2708, F1 Macro: 0.2166, Accuracy: 0.2708\n","Epoch 13, Train Loss: 1.5173, Val Loss: 1.6998, F1 Micro: 0.3854, F1 Macro: 0.3853, Accuracy: 0.3854\n","Epoch 14, Train Loss: 1.4989, Val Loss: 1.7022, F1 Micro: 0.3542, F1 Macro: 0.3340, Accuracy: 0.3542\n","Epoch 15, Train Loss: 1.4934, Val Loss: 1.7438, F1 Micro: 0.3542, F1 Macro: 0.2968, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5001, Val Loss: 1.7362, F1 Micro: 0.3438, F1 Macro: 0.3193, Accuracy: 0.3438\n","Epoch 17, Train Loss: 1.4375, Val Loss: 1.7058, F1 Micro: 0.3542, F1 Macro: 0.2925, Accuracy: 0.3542\n","Epoch 18, Train Loss: 1.5354, Val Loss: 1.6799, F1 Micro: 0.3542, F1 Macro: 0.3590, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.4684, Val Loss: 1.7452, F1 Micro: 0.3333, F1 Macro: 0.3121, Accuracy: 0.3333\n","Epoch 20, Train Loss: 1.4638, Val Loss: 1.7965, F1 Micro: 0.3646, F1 Macro: 0.3491, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.4653, Val Loss: 1.7397, F1 Micro: 0.3750, F1 Macro: 0.3797, Accuracy: 0.3750\n","Epoch 22, Train Loss: 1.4458, Val Loss: 1.7835, F1 Micro: 0.2917, F1 Macro: 0.2585, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.4571, Val Loss: 1.7318, F1 Micro: 0.3854, F1 Macro: 0.3575, Accuracy: 0.3854\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.4\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.7913, Val Loss: 1.6786, F1 Micro: 0.3229, F1 Macro: 0.2530, Accuracy: 0.3229\n","Epoch 2, Train Loss: 1.7402, Val Loss: 1.7343, F1 Micro: 0.2083, F1 Macro: 0.1603, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.7333, Val Loss: 1.6704, F1 Micro: 0.3229, F1 Macro: 0.3184, Accuracy: 0.3229\n","Epoch 4, Train Loss: 1.7029, Val Loss: 1.7406, F1 Micro: 0.3125, F1 Macro: 0.2784, Accuracy: 0.3125\n","Epoch 5, Train Loss: 1.6681, Val Loss: 1.6963, F1 Micro: 0.3229, F1 Macro: 0.3025, Accuracy: 0.3229\n","Epoch 6, Train Loss: 1.6550, Val Loss: 1.7594, F1 Micro: 0.2917, F1 Macro: 0.2457, Accuracy: 0.2917\n","Epoch 7, Train Loss: 1.6333, Val Loss: 1.7131, F1 Micro: 0.3438, F1 Macro: 0.3361, Accuracy: 0.3438\n","Epoch 8, Train Loss: 1.6286, Val Loss: 1.7885, F1 Micro: 0.2396, F1 Macro: 0.1775, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.6154, Val Loss: 1.7418, F1 Micro: 0.2917, F1 Macro: 0.2909, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.5862, Val Loss: 1.7179, F1 Micro: 0.3125, F1 Macro: 0.3091, Accuracy: 0.3125\n","Epoch 11, Train Loss: 1.5552, Val Loss: 1.6853, F1 Micro: 0.2500, F1 Macro: 0.1984, Accuracy: 0.2500\n","Epoch 12, Train Loss: 1.5487, Val Loss: 1.7126, F1 Micro: 0.3333, F1 Macro: 0.3018, Accuracy: 0.3333\n","Epoch 13, Train Loss: 1.5582, Val Loss: 1.6299, F1 Micro: 0.4062, F1 Macro: 0.4083, Accuracy: 0.4062\n","Epoch 14, Train Loss: 1.5500, Val Loss: 1.6760, F1 Micro: 0.3021, F1 Macro: 0.2604, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.5429, Val Loss: 1.8419, F1 Micro: 0.3438, F1 Macro: 0.3239, Accuracy: 0.3438\n","Epoch 16, Train Loss: 1.5282, Val Loss: 1.6558, F1 Micro: 0.3333, F1 Macro: 0.3097, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.4875, Val Loss: 1.7040, F1 Micro: 0.3021, F1 Macro: 0.2671, Accuracy: 0.3021\n","Epoch 18, Train Loss: 1.4907, Val Loss: 1.6553, F1 Micro: 0.3646, F1 Macro: 0.3576, Accuracy: 0.3646\n","Epoch 19, Train Loss: 1.4874, Val Loss: 1.7283, F1 Micro: 0.3438, F1 Macro: 0.3320, Accuracy: 0.3438\n","Epoch 20, Train Loss: 1.4845, Val Loss: 1.6643, F1 Micro: 0.3438, F1 Macro: 0.3272, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.4694, Val Loss: 1.5800, F1 Micro: 0.3229, F1 Macro: 0.2768, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.4363, Val Loss: 1.5799, F1 Micro: 0.3438, F1 Macro: 0.2898, Accuracy: 0.3438\n","Epoch 23, Train Loss: 1.4226, Val Loss: 1.6637, F1 Micro: 0.3854, F1 Macro: 0.3422, Accuracy: 0.3854\n","Epoch 24, Train Loss: 1.4426, Val Loss: 1.6896, F1 Micro: 0.3438, F1 Macro: 0.2318, Accuracy: 0.3438\n","Epoch 25, Train Loss: 1.4138, Val Loss: 1.6415, F1 Micro: 0.3750, F1 Macro: 0.3457, Accuracy: 0.3750\n","Epoch 26, Train Loss: 1.4215, Val Loss: 1.6114, F1 Micro: 0.3750, F1 Macro: 0.3497, Accuracy: 0.3750\n","Epoch 27, Train Loss: 1.3790, Val Loss: 1.5493, F1 Micro: 0.3854, F1 Macro: 0.3837, Accuracy: 0.3854\n","Epoch 28, Train Loss: 1.4157, Val Loss: 1.6670, F1 Micro: 0.3333, F1 Macro: 0.3121, Accuracy: 0.3333\n","Epoch 29, Train Loss: 1.3644, Val Loss: 1.8264, F1 Micro: 0.3958, F1 Macro: 0.3463, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.3598, Val Loss: 1.6796, F1 Micro: 0.3333, F1 Macro: 0.3127, Accuracy: 0.3333\n","Epoch 31, Train Loss: 1.3177, Val Loss: 1.7307, F1 Micro: 0.3542, F1 Macro: 0.2825, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.3818, Val Loss: 1.6916, F1 Micro: 0.3438, F1 Macro: 0.3185, Accuracy: 0.3438\n","Epoch 33, Train Loss: 1.3430, Val Loss: 1.6542, F1 Micro: 0.3646, F1 Macro: 0.3536, Accuracy: 0.3646\n","Epoch 34, Train Loss: 1.3275, Val Loss: 1.9716, F1 Micro: 0.3333, F1 Macro: 0.3298, Accuracy: 0.3333\n","Epoch 35, Train Loss: 1.3517, Val Loss: 1.6923, F1 Micro: 0.3958, F1 Macro: 0.3047, Accuracy: 0.3958\n","Epoch 36, Train Loss: 1.3559, Val Loss: 2.0252, F1 Micro: 0.3021, F1 Macro: 0.2253, Accuracy: 0.3021\n","Epoch 37, Train Loss: 1.3118, Val Loss: 1.8213, F1 Micro: 0.2708, F1 Macro: 0.2194, Accuracy: 0.2708\n","Epoch 38, Train Loss: 1.2790, Val Loss: 1.9134, F1 Micro: 0.3333, F1 Macro: 0.2987, Accuracy: 0.3333\n","Epoch 39, Train Loss: 1.2734, Val Loss: 1.6627, F1 Micro: 0.4271, F1 Macro: 0.4141, Accuracy: 0.4271\n","Epoch 40, Train Loss: 1.2865, Val Loss: 1.7572, F1 Micro: 0.3854, F1 Macro: 0.3321, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.2941, Val Loss: 1.7880, F1 Micro: 0.3438, F1 Macro: 0.3324, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.2900, Val Loss: 1.7975, F1 Micro: 0.3438, F1 Macro: 0.3470, Accuracy: 0.3438\n","Epoch 43, Train Loss: 1.2701, Val Loss: 2.2564, F1 Micro: 0.2917, F1 Macro: 0.2407, Accuracy: 0.2917\n","Epoch 44, Train Loss: 1.2411, Val Loss: 1.5591, F1 Micro: 0.4583, F1 Macro: 0.4658, Accuracy: 0.4583\n","Epoch 45, Train Loss: 1.2606, Val Loss: 1.6877, F1 Micro: 0.4271, F1 Macro: 0.4121, Accuracy: 0.4271\n","Epoch 46, Train Loss: 1.2378, Val Loss: 1.9124, F1 Micro: 0.2708, F1 Macro: 0.2358, Accuracy: 0.2708\n","Epoch 47, Train Loss: 1.2784, Val Loss: 1.7611, F1 Micro: 0.3646, F1 Macro: 0.3444, Accuracy: 0.3646\n","Epoch 48, Train Loss: 1.2338, Val Loss: 1.6713, F1 Micro: 0.4062, F1 Macro: 0.4178, Accuracy: 0.4062\n","Epoch 49, Train Loss: 1.2288, Val Loss: 1.6539, F1 Micro: 0.3854, F1 Macro: 0.3412, Accuracy: 0.3854\n","Epoch 50, Train Loss: 1.2152, Val Loss: 1.7841, F1 Micro: 0.3854, F1 Macro: 0.3255, Accuracy: 0.3854\n","Epoch 51, Train Loss: 1.1725, Val Loss: 1.6904, F1 Micro: 0.3438, F1 Macro: 0.3001, Accuracy: 0.3438\n","Epoch 52, Train Loss: 1.2005, Val Loss: 1.9004, F1 Micro: 0.3125, F1 Macro: 0.2508, Accuracy: 0.3125\n","Epoch 53, Train Loss: 1.2063, Val Loss: 1.6051, F1 Micro: 0.4271, F1 Macro: 0.4154, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.2659, Val Loss: 1.6237, F1 Micro: 0.3958, F1 Macro: 0.3426, Accuracy: 0.3958\n","Epoch 55, Train Loss: 1.1817, Val Loss: 1.7182, F1 Micro: 0.3958, F1 Macro: 0.3951, Accuracy: 0.3958\n","Epoch 56, Train Loss: 1.1978, Val Loss: 1.7176, F1 Micro: 0.3646, F1 Macro: 0.3078, Accuracy: 0.3646\n","Epoch 57, Train Loss: 1.1932, Val Loss: 1.5328, F1 Micro: 0.5208, F1 Macro: 0.5367, Accuracy: 0.5208\n","Epoch 58, Train Loss: 1.1642, Val Loss: 1.7860, F1 Micro: 0.3229, F1 Macro: 0.3230, Accuracy: 0.3229\n","Epoch 59, Train Loss: 1.1967, Val Loss: 1.7143, F1 Micro: 0.4271, F1 Macro: 0.3998, Accuracy: 0.4271\n","Epoch 60, Train Loss: 1.1698, Val Loss: 1.7003, F1 Micro: 0.3958, F1 Macro: 0.3745, Accuracy: 0.3958\n","Epoch 61, Train Loss: 1.1584, Val Loss: 1.7083, F1 Micro: 0.4167, F1 Macro: 0.3442, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.1412, Val Loss: 1.8366, F1 Micro: 0.4479, F1 Macro: 0.4240, Accuracy: 0.4479\n","Epoch 63, Train Loss: 1.1747, Val Loss: 2.1137, F1 Micro: 0.3854, F1 Macro: 0.3413, Accuracy: 0.3854\n","Epoch 64, Train Loss: 1.1396, Val Loss: 1.6500, F1 Micro: 0.4167, F1 Macro: 0.3964, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.1245, Val Loss: 1.8057, F1 Micro: 0.3229, F1 Macro: 0.3199, Accuracy: 0.3229\n","Epoch 66, Train Loss: 1.1427, Val Loss: 2.3462, F1 Micro: 0.3750, F1 Macro: 0.3528, Accuracy: 0.3750\n","Epoch 67, Train Loss: 1.1215, Val Loss: 1.6661, F1 Micro: 0.4167, F1 Macro: 0.3400, Accuracy: 0.4167\n","Epoch 68, Train Loss: 1.0687, Val Loss: 1.9016, F1 Micro: 0.3958, F1 Macro: 0.3425, Accuracy: 0.3958\n","Epoch 69, Train Loss: 1.1033, Val Loss: 1.8400, F1 Micro: 0.3646, F1 Macro: 0.3668, Accuracy: 0.3646\n","Epoch 70, Train Loss: 1.1162, Val Loss: 1.7478, F1 Micro: 0.3542, F1 Macro: 0.3526, Accuracy: 0.3542\n","Epoch 71, Train Loss: 1.1194, Val Loss: 1.8055, F1 Micro: 0.3854, F1 Macro: 0.3683, Accuracy: 0.3854\n","Epoch 72, Train Loss: 1.0893, Val Loss: 1.8135, F1 Micro: 0.3750, F1 Macro: 0.3935, Accuracy: 0.3750\n","Epoch 73, Train Loss: 1.0621, Val Loss: 1.5823, F1 Micro: 0.4583, F1 Macro: 0.4062, Accuracy: 0.4583\n","Epoch 74, Train Loss: 1.0741, Val Loss: 2.0434, F1 Micro: 0.4167, F1 Macro: 0.3704, Accuracy: 0.4167\n","Epoch 75, Train Loss: 1.0394, Val Loss: 1.7671, F1 Micro: 0.3750, F1 Macro: 0.3774, Accuracy: 0.3750\n","Epoch 76, Train Loss: 1.0735, Val Loss: 1.7716, F1 Micro: 0.3958, F1 Macro: 0.3499, Accuracy: 0.3958\n","Epoch 77, Train Loss: 1.0968, Val Loss: 1.8277, F1 Micro: 0.4167, F1 Macro: 0.4139, Accuracy: 0.4167\n","Epoch 78, Train Loss: 1.0613, Val Loss: 1.6634, F1 Micro: 0.4062, F1 Macro: 0.3628, Accuracy: 0.4062\n","Epoch 79, Train Loss: 1.0685, Val Loss: 1.7261, F1 Micro: 0.4688, F1 Macro: 0.4556, Accuracy: 0.4688\n","Epoch 80, Train Loss: 1.0927, Val Loss: 2.1173, F1 Micro: 0.3958, F1 Macro: 0.3720, Accuracy: 0.3958\n","Epoch 81, Train Loss: 1.0728, Val Loss: 1.8098, F1 Micro: 0.3646, F1 Macro: 0.3810, Accuracy: 0.3646\n","Epoch 82, Train Loss: 1.0993, Val Loss: 1.7482, F1 Micro: 0.3854, F1 Macro: 0.3906, Accuracy: 0.3854\n","Epoch 83, Train Loss: 1.0413, Val Loss: 1.6186, F1 Micro: 0.5000, F1 Macro: 0.4927, Accuracy: 0.5000\n","Epoch 84, Train Loss: 1.0363, Val Loss: 1.7583, F1 Micro: 0.4688, F1 Macro: 0.4619, Accuracy: 0.4688\n","Epoch 85, Train Loss: 1.0396, Val Loss: 2.1230, F1 Micro: 0.3854, F1 Macro: 0.3953, Accuracy: 0.3854\n","Epoch 86, Train Loss: 1.0405, Val Loss: 1.5697, F1 Micro: 0.5208, F1 Macro: 0.5214, Accuracy: 0.5208\n","Epoch 87, Train Loss: 0.9844, Val Loss: 1.7594, F1 Micro: 0.5104, F1 Macro: 0.4705, Accuracy: 0.5104\n","Epoch 88, Train Loss: 1.0164, Val Loss: 1.9472, F1 Micro: 0.3958, F1 Macro: 0.3881, Accuracy: 0.3958\n","Epoch 89, Train Loss: 1.0838, Val Loss: 1.7135, F1 Micro: 0.4375, F1 Macro: 0.3872, Accuracy: 0.4375\n","Epoch 90, Train Loss: 1.0376, Val Loss: 1.9447, F1 Micro: 0.4062, F1 Macro: 0.3909, Accuracy: 0.4062\n","Epoch 91, Train Loss: 0.9938, Val Loss: 1.6752, F1 Micro: 0.4688, F1 Macro: 0.4846, Accuracy: 0.4688\n","Epoch 92, Train Loss: 0.9808, Val Loss: 1.6853, F1 Micro: 0.4688, F1 Macro: 0.4539, Accuracy: 0.4688\n","Epoch 93, Train Loss: 0.9818, Val Loss: 1.7158, F1 Micro: 0.4375, F1 Macro: 0.4147, Accuracy: 0.4375\n","Epoch 94, Train Loss: 1.0103, Val Loss: 1.8022, F1 Micro: 0.3958, F1 Macro: 0.3821, Accuracy: 0.3958\n","Epoch 95, Train Loss: 1.0147, Val Loss: 1.7339, F1 Micro: 0.4479, F1 Macro: 0.4384, Accuracy: 0.4479\n","Epoch 96, Train Loss: 0.9528, Val Loss: 1.8772, F1 Micro: 0.3958, F1 Macro: 0.4066, Accuracy: 0.3958\n","Epoch 97, Train Loss: 1.0068, Val Loss: 1.8204, F1 Micro: 0.3854, F1 Macro: 0.3282, Accuracy: 0.3854\n","Epoch 98, Train Loss: 0.9759, Val Loss: 1.5558, F1 Micro: 0.5000, F1 Macro: 0.4910, Accuracy: 0.5000\n","Epoch 99, Train Loss: 1.0359, Val Loss: 1.7709, F1 Micro: 0.4062, F1 Macro: 0.3975, Accuracy: 0.4062\n","Epoch 100, Train Loss: 0.9847, Val Loss: 1.5776, F1 Micro: 0.5208, F1 Macro: 0.5008, Accuracy: 0.5208\n","Epoch 101, Train Loss: 1.0163, Val Loss: 1.6837, F1 Micro: 0.5000, F1 Macro: 0.5127, Accuracy: 0.5000\n","Epoch 102, Train Loss: 1.0242, Val Loss: 1.5951, F1 Micro: 0.4583, F1 Macro: 0.4238, Accuracy: 0.4583\n","Epoch 103, Train Loss: 0.9944, Val Loss: 1.8270, F1 Micro: 0.4583, F1 Macro: 0.4236, Accuracy: 0.4583\n","Epoch 104, Train Loss: 0.9839, Val Loss: 1.6232, F1 Micro: 0.5104, F1 Macro: 0.4941, Accuracy: 0.5104\n","Epoch 105, Train Loss: 0.9291, Val Loss: 1.7922, F1 Micro: 0.4792, F1 Macro: 0.4578, Accuracy: 0.4792\n","Epoch 106, Train Loss: 1.0031, Val Loss: 1.6356, F1 Micro: 0.5104, F1 Macro: 0.4926, Accuracy: 0.5104\n","Epoch 107, Train Loss: 0.9193, Val Loss: 1.6730, F1 Micro: 0.5000, F1 Macro: 0.4924, Accuracy: 0.5000\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8278, Val Loss: 1.7968, F1 Micro: 0.1979, F1 Macro: 0.1155, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7746, Val Loss: 1.7436, F1 Micro: 0.3021, F1 Macro: 0.2536, Accuracy: 0.3021\n","Epoch 3, Train Loss: 1.7123, Val Loss: 1.7373, F1 Micro: 0.3229, F1 Macro: 0.2717, Accuracy: 0.3229\n","Epoch 4, Train Loss: 1.6840, Val Loss: 1.7944, F1 Micro: 0.2396, F1 Macro: 0.2096, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.7120, Val Loss: 1.6881, F1 Micro: 0.3333, F1 Macro: 0.2993, Accuracy: 0.3333\n","Epoch 6, Train Loss: 1.6587, Val Loss: 1.6876, F1 Micro: 0.3646, F1 Macro: 0.3452, Accuracy: 0.3646\n","Epoch 7, Train Loss: 1.6638, Val Loss: 1.6632, F1 Micro: 0.2917, F1 Macro: 0.2901, Accuracy: 0.2917\n","Epoch 8, Train Loss: 1.6737, Val Loss: 1.6186, F1 Micro: 0.3229, F1 Macro: 0.3042, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.6304, Val Loss: 1.5794, F1 Micro: 0.3750, F1 Macro: 0.2946, Accuracy: 0.3750\n","Epoch 10, Train Loss: 1.6185, Val Loss: 1.6522, F1 Micro: 0.3750, F1 Macro: 0.3686, Accuracy: 0.3750\n","Epoch 11, Train Loss: 1.6127, Val Loss: 1.5337, F1 Micro: 0.4271, F1 Macro: 0.4034, Accuracy: 0.4271\n","Epoch 12, Train Loss: 1.6193, Val Loss: 1.6369, F1 Micro: 0.3854, F1 Macro: 0.3475, Accuracy: 0.3854\n","Epoch 13, Train Loss: 1.5900, Val Loss: 1.6306, F1 Micro: 0.3021, F1 Macro: 0.2671, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.5417, Val Loss: 1.5691, F1 Micro: 0.4583, F1 Macro: 0.4015, Accuracy: 0.4583\n","Epoch 15, Train Loss: 1.5670, Val Loss: 1.5482, F1 Micro: 0.4271, F1 Macro: 0.4017, Accuracy: 0.4271\n","Epoch 16, Train Loss: 1.5937, Val Loss: 1.6178, F1 Micro: 0.3542, F1 Macro: 0.3112, Accuracy: 0.3542\n","Epoch 17, Train Loss: 1.5198, Val Loss: 1.5965, F1 Micro: 0.3646, F1 Macro: 0.3273, Accuracy: 0.3646\n","Epoch 18, Train Loss: 1.5096, Val Loss: 1.5123, F1 Micro: 0.4375, F1 Macro: 0.4138, Accuracy: 0.4375\n","Epoch 19, Train Loss: 1.4795, Val Loss: 1.8087, F1 Micro: 0.2812, F1 Macro: 0.2308, Accuracy: 0.2812\n","Epoch 20, Train Loss: 1.5026, Val Loss: 1.5163, F1 Micro: 0.3958, F1 Macro: 0.3340, Accuracy: 0.3958\n","Epoch 21, Train Loss: 1.4911, Val Loss: 1.6001, F1 Micro: 0.3646, F1 Macro: 0.3139, Accuracy: 0.3646\n","Epoch 22, Train Loss: 1.5057, Val Loss: 1.5359, F1 Micro: 0.3958, F1 Macro: 0.3839, Accuracy: 0.3958\n","Epoch 23, Train Loss: 1.5043, Val Loss: 1.7131, F1 Micro: 0.3021, F1 Macro: 0.3030, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.4545, Val Loss: 1.5720, F1 Micro: 0.4167, F1 Macro: 0.3825, Accuracy: 0.4167\n","Epoch 25, Train Loss: 1.4591, Val Loss: 1.5968, F1 Micro: 0.3646, F1 Macro: 0.3373, Accuracy: 0.3646\n","Epoch 26, Train Loss: 1.4529, Val Loss: 1.5150, F1 Micro: 0.3542, F1 Macro: 0.3143, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.4197, Val Loss: 1.9698, F1 Micro: 0.2188, F1 Macro: 0.1908, Accuracy: 0.2188\n","Epoch 28, Train Loss: 1.4617, Val Loss: 1.4732, F1 Micro: 0.4792, F1 Macro: 0.4304, Accuracy: 0.4792\n","Epoch 29, Train Loss: 1.4433, Val Loss: 1.4924, F1 Micro: 0.3750, F1 Macro: 0.3562, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.3778, Val Loss: 1.7316, F1 Micro: 0.4062, F1 Macro: 0.4201, Accuracy: 0.4062\n","Epoch 31, Train Loss: 1.4449, Val Loss: 1.7958, F1 Micro: 0.3438, F1 Macro: 0.3498, Accuracy: 0.3438\n","Epoch 32, Train Loss: 1.4118, Val Loss: 1.5174, F1 Micro: 0.4167, F1 Macro: 0.4489, Accuracy: 0.4167\n","Epoch 33, Train Loss: 1.3482, Val Loss: 1.5366, F1 Micro: 0.3646, F1 Macro: 0.3057, Accuracy: 0.3646\n","Epoch 34, Train Loss: 1.3362, Val Loss: 1.5897, F1 Micro: 0.4062, F1 Macro: 0.3749, Accuracy: 0.4062\n","Epoch 35, Train Loss: 1.3540, Val Loss: 1.8386, F1 Micro: 0.2812, F1 Macro: 0.2429, Accuracy: 0.2812\n","Epoch 36, Train Loss: 1.3548, Val Loss: 1.9026, F1 Micro: 0.3750, F1 Macro: 0.3783, Accuracy: 0.3750\n","Epoch 37, Train Loss: 1.3564, Val Loss: 1.5078, F1 Micro: 0.4896, F1 Macro: 0.4461, Accuracy: 0.4896\n","Epoch 38, Train Loss: 1.3390, Val Loss: 1.7200, F1 Micro: 0.4167, F1 Macro: 0.3594, Accuracy: 0.4167\n","Epoch 39, Train Loss: 1.3223, Val Loss: 1.5286, F1 Micro: 0.3854, F1 Macro: 0.3253, Accuracy: 0.3854\n","Epoch 40, Train Loss: 1.3369, Val Loss: 1.7462, F1 Micro: 0.3854, F1 Macro: 0.3074, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.3157, Val Loss: 1.4344, F1 Micro: 0.4688, F1 Macro: 0.4350, Accuracy: 0.4688\n","Epoch 42, Train Loss: 1.3442, Val Loss: 1.6436, F1 Micro: 0.3438, F1 Macro: 0.3157, Accuracy: 0.3438\n","Epoch 43, Train Loss: 1.2760, Val Loss: 1.6832, F1 Micro: 0.3958, F1 Macro: 0.3246, Accuracy: 0.3958\n","Epoch 44, Train Loss: 1.2777, Val Loss: 1.4973, F1 Micro: 0.4792, F1 Macro: 0.4652, Accuracy: 0.4792\n","Epoch 45, Train Loss: 1.3379, Val Loss: 1.5723, F1 Micro: 0.4583, F1 Macro: 0.4027, Accuracy: 0.4583\n","Epoch 46, Train Loss: 1.2451, Val Loss: 1.6777, F1 Micro: 0.3750, F1 Macro: 0.3046, Accuracy: 0.3750\n","Epoch 47, Train Loss: 1.2918, Val Loss: 1.6003, F1 Micro: 0.4271, F1 Macro: 0.3877, Accuracy: 0.4271\n","Epoch 48, Train Loss: 1.2668, Val Loss: 1.6072, F1 Micro: 0.4062, F1 Macro: 0.3992, Accuracy: 0.4062\n","Epoch 49, Train Loss: 1.2614, Val Loss: 1.9252, F1 Micro: 0.2396, F1 Macro: 0.2214, Accuracy: 0.2396\n","Epoch 50, Train Loss: 1.2764, Val Loss: 1.5044, F1 Micro: 0.4688, F1 Macro: 0.4411, Accuracy: 0.4688\n","Epoch 51, Train Loss: 1.2577, Val Loss: 1.6291, F1 Micro: 0.3750, F1 Macro: 0.3757, Accuracy: 0.3750\n","Epoch 52, Train Loss: 1.2699, Val Loss: 1.4606, F1 Micro: 0.5417, F1 Macro: 0.4951, Accuracy: 0.5417\n","Epoch 53, Train Loss: 1.2340, Val Loss: 1.7589, F1 Micro: 0.3125, F1 Macro: 0.3081, Accuracy: 0.3125\n","Epoch 54, Train Loss: 1.2229, Val Loss: 1.7282, F1 Micro: 0.3542, F1 Macro: 0.3104, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.2293, Val Loss: 1.5940, F1 Micro: 0.3750, F1 Macro: 0.3239, Accuracy: 0.3750\n","Epoch 56, Train Loss: 1.1548, Val Loss: 1.5948, F1 Micro: 0.4792, F1 Macro: 0.4612, Accuracy: 0.4792\n","Epoch 57, Train Loss: 1.2118, Val Loss: 1.4630, F1 Micro: 0.5312, F1 Macro: 0.4996, Accuracy: 0.5312\n","Epoch 58, Train Loss: 1.2190, Val Loss: 1.6331, F1 Micro: 0.3958, F1 Macro: 0.3256, Accuracy: 0.3958\n","Epoch 59, Train Loss: 1.2108, Val Loss: 1.6961, F1 Micro: 0.4375, F1 Macro: 0.3899, Accuracy: 0.4375\n","Epoch 60, Train Loss: 1.1878, Val Loss: 1.4246, F1 Micro: 0.5208, F1 Macro: 0.5266, Accuracy: 0.5208\n","Epoch 61, Train Loss: 1.2325, Val Loss: 1.8910, F1 Micro: 0.2917, F1 Macro: 0.2775, Accuracy: 0.2917\n","Epoch 62, Train Loss: 1.1832, Val Loss: 1.6454, F1 Micro: 0.4167, F1 Macro: 0.3560, Accuracy: 0.4167\n","Epoch 63, Train Loss: 1.1790, Val Loss: 1.5135, F1 Micro: 0.5104, F1 Macro: 0.4663, Accuracy: 0.5104\n","Epoch 64, Train Loss: 1.1700, Val Loss: 1.6026, F1 Micro: 0.4583, F1 Macro: 0.4025, Accuracy: 0.4583\n","Epoch 65, Train Loss: 1.1650, Val Loss: 1.5232, F1 Micro: 0.4375, F1 Macro: 0.4143, Accuracy: 0.4375\n","Epoch 66, Train Loss: 1.1756, Val Loss: 1.4686, F1 Micro: 0.5312, F1 Macro: 0.5037, Accuracy: 0.5312\n","Epoch 67, Train Loss: 1.1025, Val Loss: 1.5986, F1 Micro: 0.4896, F1 Macro: 0.4247, Accuracy: 0.4896\n","Epoch 68, Train Loss: 1.1457, Val Loss: 1.9570, F1 Micro: 0.4062, F1 Macro: 0.3187, Accuracy: 0.4062\n","Epoch 69, Train Loss: 1.1562, Val Loss: 1.6700, F1 Micro: 0.4167, F1 Macro: 0.3976, Accuracy: 0.4167\n","Epoch 70, Train Loss: 1.1529, Val Loss: 2.1211, F1 Micro: 0.2917, F1 Macro: 0.2329, Accuracy: 0.2917\n","Epoch 71, Train Loss: 1.1345, Val Loss: 1.5824, F1 Micro: 0.4583, F1 Macro: 0.3967, Accuracy: 0.4583\n","Epoch 72, Train Loss: 1.1682, Val Loss: 1.5823, F1 Micro: 0.4792, F1 Macro: 0.4285, Accuracy: 0.4792\n","Epoch 73, Train Loss: 1.1254, Val Loss: 1.5302, F1 Micro: 0.4271, F1 Macro: 0.4048, Accuracy: 0.4271\n","Epoch 74, Train Loss: 1.1643, Val Loss: 1.9269, F1 Micro: 0.2812, F1 Macro: 0.2699, Accuracy: 0.2812\n","Epoch 75, Train Loss: 1.0946, Val Loss: 1.6605, F1 Micro: 0.4167, F1 Macro: 0.3502, Accuracy: 0.4167\n","Epoch 76, Train Loss: 1.0890, Val Loss: 1.5936, F1 Micro: 0.4271, F1 Macro: 0.4146, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.1385, Val Loss: 1.7929, F1 Micro: 0.3229, F1 Macro: 0.2600, Accuracy: 0.3229\n","Epoch 78, Train Loss: 1.0889, Val Loss: 1.7304, F1 Micro: 0.3333, F1 Macro: 0.3104, Accuracy: 0.3333\n","Epoch 79, Train Loss: 1.0997, Val Loss: 1.4499, F1 Micro: 0.4792, F1 Macro: 0.4450, Accuracy: 0.4792\n","Epoch 80, Train Loss: 1.0997, Val Loss: 1.6318, F1 Micro: 0.4792, F1 Macro: 0.4305, Accuracy: 0.4792\n","Epoch 81, Train Loss: 1.1183, Val Loss: 1.6697, F1 Micro: 0.4271, F1 Macro: 0.3751, Accuracy: 0.4271\n","Epoch 82, Train Loss: 1.1222, Val Loss: 1.4342, F1 Micro: 0.5208, F1 Macro: 0.4853, Accuracy: 0.5208\n","Epoch 83, Train Loss: 1.1372, Val Loss: 1.6066, F1 Micro: 0.4688, F1 Macro: 0.4171, Accuracy: 0.4688\n","Epoch 84, Train Loss: 1.1130, Val Loss: 1.4693, F1 Micro: 0.4583, F1 Macro: 0.4427, Accuracy: 0.4583\n","Epoch 85, Train Loss: 1.0332, Val Loss: 1.7326, F1 Micro: 0.4167, F1 Macro: 0.4079, Accuracy: 0.4167\n","Epoch 86, Train Loss: 1.0697, Val Loss: 1.5975, F1 Micro: 0.4792, F1 Macro: 0.4458, Accuracy: 0.4792\n","Epoch 87, Train Loss: 1.0549, Val Loss: 1.5453, F1 Micro: 0.4896, F1 Macro: 0.4578, Accuracy: 0.4896\n","Epoch 88, Train Loss: 1.0906, Val Loss: 1.5008, F1 Micro: 0.5000, F1 Macro: 0.4749, Accuracy: 0.5000\n","Epoch 89, Train Loss: 1.1498, Val Loss: 1.9769, F1 Micro: 0.3333, F1 Macro: 0.3260, Accuracy: 0.3333\n","Epoch 90, Train Loss: 1.0522, Val Loss: 1.6628, F1 Micro: 0.3854, F1 Macro: 0.3537, Accuracy: 0.3854\n","Epoch 91, Train Loss: 1.0205, Val Loss: 2.0999, F1 Micro: 0.2917, F1 Macro: 0.2800, Accuracy: 0.2917\n","Epoch 92, Train Loss: 1.0187, Val Loss: 1.6824, F1 Micro: 0.3750, F1 Macro: 0.3481, Accuracy: 0.3750\n","Epoch 93, Train Loss: 1.0536, Val Loss: 1.6615, F1 Micro: 0.4062, F1 Macro: 0.3927, Accuracy: 0.4062\n","Epoch 94, Train Loss: 1.0318, Val Loss: 1.6441, F1 Micro: 0.4479, F1 Macro: 0.4294, Accuracy: 0.4479\n","Epoch 95, Train Loss: 1.0537, Val Loss: 1.7728, F1 Micro: 0.3333, F1 Macro: 0.2884, Accuracy: 0.3333\n","Epoch 96, Train Loss: 0.9747, Val Loss: 1.4370, F1 Micro: 0.5104, F1 Macro: 0.4723, Accuracy: 0.5104\n","Epoch 97, Train Loss: 1.0612, Val Loss: 1.4800, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 98, Train Loss: 1.0573, Val Loss: 1.8101, F1 Micro: 0.3438, F1 Macro: 0.3082, Accuracy: 0.3438\n","Epoch 99, Train Loss: 1.0186, Val Loss: 1.4278, F1 Micro: 0.4896, F1 Macro: 0.4659, Accuracy: 0.4896\n","Epoch 100, Train Loss: 1.0238, Val Loss: 1.6966, F1 Micro: 0.3333, F1 Macro: 0.3023, Accuracy: 0.3333\n","Epoch 101, Train Loss: 1.0086, Val Loss: 1.6159, F1 Micro: 0.5000, F1 Macro: 0.5131, Accuracy: 0.5000\n","Epoch 102, Train Loss: 0.9959, Val Loss: 1.5432, F1 Micro: 0.4583, F1 Macro: 0.4198, Accuracy: 0.4583\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8128, Val Loss: 1.8195, F1 Micro: 0.1250, F1 Macro: 0.0763, Accuracy: 0.1250\n","Epoch 2, Train Loss: 1.7610, Val Loss: 1.7154, F1 Micro: 0.2917, F1 Macro: 0.2157, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.6834, Val Loss: 1.7677, F1 Micro: 0.2500, F1 Macro: 0.2054, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.6901, Val Loss: 1.8076, F1 Micro: 0.1875, F1 Macro: 0.1638, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.6870, Val Loss: 1.7713, F1 Micro: 0.2604, F1 Macro: 0.2344, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.6466, Val Loss: 1.7185, F1 Micro: 0.2812, F1 Macro: 0.2107, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.6360, Val Loss: 1.7668, F1 Micro: 0.2812, F1 Macro: 0.1986, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6199, Val Loss: 1.6688, F1 Micro: 0.3229, F1 Macro: 0.2440, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.6043, Val Loss: 1.7016, F1 Micro: 0.2917, F1 Macro: 0.2587, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.6211, Val Loss: 1.8093, F1 Micro: 0.2292, F1 Macro: 0.2071, Accuracy: 0.2292\n","Epoch 11, Train Loss: 1.5436, Val Loss: 1.6254, F1 Micro: 0.3542, F1 Macro: 0.2849, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.5951, Val Loss: 1.6955, F1 Micro: 0.3542, F1 Macro: 0.3271, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.5375, Val Loss: 1.6825, F1 Micro: 0.3438, F1 Macro: 0.2814, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.5345, Val Loss: 1.5944, F1 Micro: 0.4062, F1 Macro: 0.3109, Accuracy: 0.4062\n","Epoch 15, Train Loss: 1.5319, Val Loss: 1.7185, F1 Micro: 0.3646, F1 Macro: 0.2204, Accuracy: 0.3646\n","Epoch 16, Train Loss: 1.5298, Val Loss: 1.6552, F1 Micro: 0.4479, F1 Macro: 0.4174, Accuracy: 0.4479\n","Epoch 17, Train Loss: 1.4992, Val Loss: 1.6699, F1 Micro: 0.3438, F1 Macro: 0.2898, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5554, Val Loss: 1.6460, F1 Micro: 0.3542, F1 Macro: 0.3532, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.5391, Val Loss: 1.6717, F1 Micro: 0.3750, F1 Macro: 0.2744, Accuracy: 0.3750\n","Epoch 20, Train Loss: 1.5253, Val Loss: 1.7410, F1 Micro: 0.3125, F1 Macro: 0.2496, Accuracy: 0.3125\n","Epoch 21, Train Loss: 1.5247, Val Loss: 1.5469, F1 Micro: 0.4167, F1 Macro: 0.3372, Accuracy: 0.4167\n","Epoch 22, Train Loss: 1.4735, Val Loss: 1.6143, F1 Micro: 0.4375, F1 Macro: 0.4181, Accuracy: 0.4375\n","Epoch 23, Train Loss: 1.4778, Val Loss: 1.6145, F1 Micro: 0.3646, F1 Macro: 0.3471, Accuracy: 0.3646\n","Epoch 24, Train Loss: 1.4442, Val Loss: 1.5687, F1 Micro: 0.3958, F1 Macro: 0.3520, Accuracy: 0.3958\n","Epoch 25, Train Loss: 1.4552, Val Loss: 1.6087, F1 Micro: 0.3542, F1 Macro: 0.2725, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.3742, Val Loss: 1.5878, F1 Micro: 0.4062, F1 Macro: 0.3355, Accuracy: 0.4062\n","Epoch 27, Train Loss: 1.4358, Val Loss: 1.7294, F1 Micro: 0.3021, F1 Macro: 0.2633, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.4218, Val Loss: 1.6053, F1 Micro: 0.4271, F1 Macro: 0.3934, Accuracy: 0.4271\n","Epoch 29, Train Loss: 1.4206, Val Loss: 1.6979, F1 Micro: 0.3958, F1 Macro: 0.3777, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.4254, Val Loss: 1.5141, F1 Micro: 0.4792, F1 Macro: 0.4322, Accuracy: 0.4792\n","Epoch 31, Train Loss: 1.3917, Val Loss: 1.5969, F1 Micro: 0.4375, F1 Macro: 0.4238, Accuracy: 0.4375\n","Epoch 32, Train Loss: 1.3999, Val Loss: 1.6526, F1 Micro: 0.3646, F1 Macro: 0.3525, Accuracy: 0.3646\n","Epoch 33, Train Loss: 1.3977, Val Loss: 1.8046, F1 Micro: 0.3229, F1 Macro: 0.3433, Accuracy: 0.3229\n","Epoch 34, Train Loss: 1.3318, Val Loss: 1.4923, F1 Micro: 0.4583, F1 Macro: 0.3449, Accuracy: 0.4583\n","Epoch 35, Train Loss: 1.4171, Val Loss: 1.5685, F1 Micro: 0.4479, F1 Macro: 0.3629, Accuracy: 0.4479\n","Epoch 36, Train Loss: 1.3436, Val Loss: 1.5358, F1 Micro: 0.4375, F1 Macro: 0.4117, Accuracy: 0.4375\n","Epoch 37, Train Loss: 1.3853, Val Loss: 1.6119, F1 Micro: 0.3958, F1 Macro: 0.4003, Accuracy: 0.3958\n","Epoch 38, Train Loss: 1.3124, Val Loss: 1.6353, F1 Micro: 0.3854, F1 Macro: 0.3577, Accuracy: 0.3854\n","Epoch 39, Train Loss: 1.3457, Val Loss: 1.6032, F1 Micro: 0.3646, F1 Macro: 0.3344, Accuracy: 0.3646\n","Epoch 40, Train Loss: 1.3576, Val Loss: 1.5265, F1 Micro: 0.4479, F1 Macro: 0.4222, Accuracy: 0.4479\n","Epoch 41, Train Loss: 1.3149, Val Loss: 1.5611, F1 Micro: 0.4583, F1 Macro: 0.4127, Accuracy: 0.4583\n","Epoch 42, Train Loss: 1.3372, Val Loss: 1.7396, F1 Micro: 0.3854, F1 Macro: 0.3125, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.2990, Val Loss: 1.6944, F1 Micro: 0.4062, F1 Macro: 0.3773, Accuracy: 0.4062\n","Epoch 44, Train Loss: 1.3602, Val Loss: 1.5870, F1 Micro: 0.4896, F1 Macro: 0.4648, Accuracy: 0.4896\n","Epoch 45, Train Loss: 1.3271, Val Loss: 1.5868, F1 Micro: 0.4271, F1 Macro: 0.3828, Accuracy: 0.4271\n","Epoch 46, Train Loss: 1.2693, Val Loss: 1.4667, F1 Micro: 0.4688, F1 Macro: 0.4014, Accuracy: 0.4688\n","Epoch 47, Train Loss: 1.2554, Val Loss: 1.6512, F1 Micro: 0.3854, F1 Macro: 0.3506, Accuracy: 0.3854\n","Epoch 48, Train Loss: 1.2801, Val Loss: 1.6239, F1 Micro: 0.4062, F1 Macro: 0.3864, Accuracy: 0.4062\n","Epoch 49, Train Loss: 1.2820, Val Loss: 1.5213, F1 Micro: 0.5104, F1 Macro: 0.4814, Accuracy: 0.5104\n","Epoch 50, Train Loss: 1.2848, Val Loss: 1.6768, F1 Micro: 0.4271, F1 Macro: 0.3460, Accuracy: 0.4271\n","Epoch 51, Train Loss: 1.2932, Val Loss: 1.5341, F1 Micro: 0.4583, F1 Macro: 0.4288, Accuracy: 0.4583\n","Epoch 52, Train Loss: 1.2522, Val Loss: 1.5606, F1 Micro: 0.4792, F1 Macro: 0.4351, Accuracy: 0.4792\n","Epoch 53, Train Loss: 1.2394, Val Loss: 1.6018, F1 Micro: 0.4896, F1 Macro: 0.4241, Accuracy: 0.4896\n","Epoch 54, Train Loss: 1.2937, Val Loss: 1.4732, F1 Micro: 0.5000, F1 Macro: 0.4742, Accuracy: 0.5000\n","Epoch 55, Train Loss: 1.2765, Val Loss: 1.7066, F1 Micro: 0.3542, F1 Macro: 0.3359, Accuracy: 0.3542\n","Epoch 56, Train Loss: 1.2159, Val Loss: 1.4094, F1 Micro: 0.5417, F1 Macro: 0.4885, Accuracy: 0.5417\n","Epoch 57, Train Loss: 1.2310, Val Loss: 1.6781, F1 Micro: 0.4167, F1 Macro: 0.3758, Accuracy: 0.4167\n","Epoch 58, Train Loss: 1.2247, Val Loss: 1.5333, F1 Micro: 0.4583, F1 Macro: 0.4297, Accuracy: 0.4583\n","Epoch 59, Train Loss: 1.2303, Val Loss: 1.6061, F1 Micro: 0.4375, F1 Macro: 0.3448, Accuracy: 0.4375\n","Epoch 60, Train Loss: 1.2217, Val Loss: 1.4927, F1 Micro: 0.4062, F1 Macro: 0.3633, Accuracy: 0.4062\n","Epoch 61, Train Loss: 1.2126, Val Loss: 1.8289, F1 Micro: 0.3229, F1 Macro: 0.2300, Accuracy: 0.3229\n","Epoch 62, Train Loss: 1.2317, Val Loss: 1.4195, F1 Micro: 0.4479, F1 Macro: 0.4013, Accuracy: 0.4479\n","Epoch 63, Train Loss: 1.1691, Val Loss: 1.6075, F1 Micro: 0.4688, F1 Macro: 0.4065, Accuracy: 0.4688\n","Epoch 64, Train Loss: 1.2720, Val Loss: 1.4662, F1 Micro: 0.4688, F1 Macro: 0.4091, Accuracy: 0.4688\n","Epoch 65, Train Loss: 1.2420, Val Loss: 1.4452, F1 Micro: 0.4792, F1 Macro: 0.4458, Accuracy: 0.4792\n","Epoch 66, Train Loss: 1.1962, Val Loss: 1.4773, F1 Micro: 0.4479, F1 Macro: 0.4425, Accuracy: 0.4479\n","Epoch 67, Train Loss: 1.2038, Val Loss: 1.4636, F1 Micro: 0.5000, F1 Macro: 0.4702, Accuracy: 0.5000\n","Epoch 68, Train Loss: 1.2146, Val Loss: 1.3788, F1 Micro: 0.5625, F1 Macro: 0.5168, Accuracy: 0.5625\n","Epoch 69, Train Loss: 1.1656, Val Loss: 1.4354, F1 Micro: 0.4896, F1 Macro: 0.4770, Accuracy: 0.4896\n","Epoch 70, Train Loss: 1.1530, Val Loss: 1.4056, F1 Micro: 0.4792, F1 Macro: 0.4605, Accuracy: 0.4792\n","Epoch 71, Train Loss: 1.1239, Val Loss: 1.6141, F1 Micro: 0.4583, F1 Macro: 0.3955, Accuracy: 0.4583\n","Epoch 72, Train Loss: 1.1517, Val Loss: 1.4149, F1 Micro: 0.5000, F1 Macro: 0.4845, Accuracy: 0.5000\n","Epoch 73, Train Loss: 1.1155, Val Loss: 1.5435, F1 Micro: 0.4688, F1 Macro: 0.4360, Accuracy: 0.4688\n","Epoch 74, Train Loss: 1.1587, Val Loss: 1.5268, F1 Micro: 0.4375, F1 Macro: 0.4144, Accuracy: 0.4375\n","Epoch 75, Train Loss: 1.1294, Val Loss: 1.4543, F1 Micro: 0.5312, F1 Macro: 0.4973, Accuracy: 0.5312\n","Epoch 76, Train Loss: 1.1225, Val Loss: 1.5035, F1 Micro: 0.4688, F1 Macro: 0.4072, Accuracy: 0.4688\n","Epoch 77, Train Loss: 1.0989, Val Loss: 1.6769, F1 Micro: 0.4271, F1 Macro: 0.3907, Accuracy: 0.4271\n","Epoch 78, Train Loss: 1.1140, Val Loss: 1.4705, F1 Micro: 0.5417, F1 Macro: 0.4856, Accuracy: 0.5417\n","Epoch 79, Train Loss: 1.1894, Val Loss: 2.1410, F1 Micro: 0.3229, F1 Macro: 0.2702, Accuracy: 0.3229\n","Epoch 80, Train Loss: 1.1169, Val Loss: 1.5671, F1 Micro: 0.4167, F1 Macro: 0.3847, Accuracy: 0.4167\n","Epoch 81, Train Loss: 1.1741, Val Loss: 1.5666, F1 Micro: 0.4688, F1 Macro: 0.4759, Accuracy: 0.4688\n","Epoch 82, Train Loss: 1.1163, Val Loss: 1.3822, F1 Micro: 0.4896, F1 Macro: 0.4483, Accuracy: 0.4896\n","Epoch 83, Train Loss: 1.1287, Val Loss: 1.5321, F1 Micro: 0.4583, F1 Macro: 0.4077, Accuracy: 0.4583\n","Epoch 84, Train Loss: 1.1081, Val Loss: 1.5746, F1 Micro: 0.4896, F1 Macro: 0.4656, Accuracy: 0.4896\n","Epoch 85, Train Loss: 1.1397, Val Loss: 1.4525, F1 Micro: 0.5417, F1 Macro: 0.5207, Accuracy: 0.5417\n","Epoch 86, Train Loss: 1.0328, Val Loss: 1.7189, F1 Micro: 0.3646, F1 Macro: 0.3576, Accuracy: 0.3646\n","Epoch 87, Train Loss: 1.0544, Val Loss: 1.6322, F1 Micro: 0.5000, F1 Macro: 0.4419, Accuracy: 0.5000\n","Epoch 88, Train Loss: 1.1300, Val Loss: 1.5149, F1 Micro: 0.4792, F1 Macro: 0.4412, Accuracy: 0.4792\n","Epoch 89, Train Loss: 1.0961, Val Loss: 1.5383, F1 Micro: 0.4479, F1 Macro: 0.3933, Accuracy: 0.4479\n","Epoch 90, Train Loss: 1.0769, Val Loss: 1.5686, F1 Micro: 0.5104, F1 Macro: 0.5068, Accuracy: 0.5104\n","Epoch 91, Train Loss: 1.0926, Val Loss: 1.7344, F1 Micro: 0.3750, F1 Macro: 0.3630, Accuracy: 0.3750\n","Epoch 92, Train Loss: 1.0410, Val Loss: 1.5952, F1 Micro: 0.4479, F1 Macro: 0.4386, Accuracy: 0.4479\n","Epoch 93, Train Loss: 1.0838, Val Loss: 1.6576, F1 Micro: 0.4688, F1 Macro: 0.4403, Accuracy: 0.4688\n","Epoch 94, Train Loss: 1.1464, Val Loss: 1.4704, F1 Micro: 0.5104, F1 Macro: 0.4757, Accuracy: 0.5104\n","Epoch 95, Train Loss: 1.0857, Val Loss: 1.4832, F1 Micro: 0.4688, F1 Macro: 0.4247, Accuracy: 0.4688\n","Epoch 96, Train Loss: 1.0397, Val Loss: 1.3778, F1 Micro: 0.5208, F1 Macro: 0.4897, Accuracy: 0.5208\n","Epoch 97, Train Loss: 1.1125, Val Loss: 1.7257, F1 Micro: 0.4062, F1 Macro: 0.4275, Accuracy: 0.4062\n","Epoch 98, Train Loss: 1.1309, Val Loss: 1.5383, F1 Micro: 0.5000, F1 Macro: 0.4699, Accuracy: 0.5000\n","Epoch 99, Train Loss: 1.0567, Val Loss: 1.4496, F1 Micro: 0.4583, F1 Macro: 0.4422, Accuracy: 0.4583\n","Epoch 100, Train Loss: 1.0500, Val Loss: 1.5187, F1 Micro: 0.5312, F1 Macro: 0.4877, Accuracy: 0.5312\n","Epoch 101, Train Loss: 1.0275, Val Loss: 1.5305, F1 Micro: 0.4688, F1 Macro: 0.4405, Accuracy: 0.4688\n","Epoch 102, Train Loss: 1.0386, Val Loss: 1.5227, F1 Micro: 0.4583, F1 Macro: 0.4318, Accuracy: 0.4583\n","Epoch 103, Train Loss: 1.0133, Val Loss: 1.3850, F1 Micro: 0.5000, F1 Macro: 0.4758, Accuracy: 0.5000\n","Epoch 104, Train Loss: 1.0183, Val Loss: 1.4950, F1 Micro: 0.5104, F1 Macro: 0.4959, Accuracy: 0.5104\n","Epoch 105, Train Loss: 1.0053, Val Loss: 1.5393, F1 Micro: 0.5104, F1 Macro: 0.5085, Accuracy: 0.5104\n","Epoch 106, Train Loss: 1.0453, Val Loss: 1.4394, F1 Micro: 0.4792, F1 Macro: 0.4569, Accuracy: 0.4792\n","Epoch 107, Train Loss: 1.0133, Val Loss: 1.4296, F1 Micro: 0.5000, F1 Macro: 0.4666, Accuracy: 0.5000\n","Epoch 108, Train Loss: 1.0411, Val Loss: 1.6531, F1 Micro: 0.4479, F1 Macro: 0.4611, Accuracy: 0.4479\n","Epoch 109, Train Loss: 1.0671, Val Loss: 1.4443, F1 Micro: 0.5312, F1 Macro: 0.4846, Accuracy: 0.5312\n","Epoch 110, Train Loss: 1.1055, Val Loss: 1.6840, F1 Micro: 0.4479, F1 Macro: 0.4055, Accuracy: 0.4479\n","Epoch 111, Train Loss: 1.0248, Val Loss: 1.4168, F1 Micro: 0.5104, F1 Macro: 0.4903, Accuracy: 0.5104\n","Epoch 112, Train Loss: 1.0685, Val Loss: 1.4745, F1 Micro: 0.5208, F1 Macro: 0.4764, Accuracy: 0.5208\n","Epoch 113, Train Loss: 1.0445, Val Loss: 1.4439, F1 Micro: 0.5417, F1 Macro: 0.5188, Accuracy: 0.5417\n","Epoch 114, Train Loss: 1.0031, Val Loss: 1.7133, F1 Micro: 0.4792, F1 Macro: 0.4277, Accuracy: 0.4792\n","Epoch 115, Train Loss: 0.9439, Val Loss: 1.4088, F1 Micro: 0.5521, F1 Macro: 0.5280, Accuracy: 0.5521\n","Epoch 116, Train Loss: 0.9449, Val Loss: 1.4772, F1 Micro: 0.5938, F1 Macro: 0.5636, Accuracy: 0.5938\n","Epoch 117, Train Loss: 0.9979, Val Loss: 1.4322, F1 Micro: 0.5104, F1 Macro: 0.4980, Accuracy: 0.5104\n","Epoch 118, Train Loss: 1.0184, Val Loss: 1.4245, F1 Micro: 0.5312, F1 Macro: 0.4862, Accuracy: 0.5312\n","Epoch 119, Train Loss: 1.1090, Val Loss: 1.8661, F1 Micro: 0.3958, F1 Macro: 0.3366, Accuracy: 0.3958\n","Epoch 120, Train Loss: 1.0456, Val Loss: 1.4073, F1 Micro: 0.5208, F1 Macro: 0.4914, Accuracy: 0.5208\n","Epoch 121, Train Loss: 0.9873, Val Loss: 1.3631, F1 Micro: 0.5833, F1 Macro: 0.5639, Accuracy: 0.5833\n","Epoch 122, Train Loss: 0.9909, Val Loss: 1.4993, F1 Micro: 0.5104, F1 Macro: 0.5095, Accuracy: 0.5104\n","Epoch 123, Train Loss: 0.9687, Val Loss: 1.4040, F1 Micro: 0.5208, F1 Macro: 0.4924, Accuracy: 0.5208\n","Epoch 124, Train Loss: 0.9488, Val Loss: 1.6281, F1 Micro: 0.4583, F1 Macro: 0.4460, Accuracy: 0.4583\n","Epoch 125, Train Loss: 0.9757, Val Loss: 1.3572, F1 Micro: 0.5521, F1 Macro: 0.5410, Accuracy: 0.5521\n","Epoch 126, Train Loss: 0.9702, Val Loss: 1.6867, F1 Micro: 0.4792, F1 Macro: 0.4497, Accuracy: 0.4792\n","Epoch 127, Train Loss: 0.9671, Val Loss: 1.5121, F1 Micro: 0.5312, F1 Macro: 0.4725, Accuracy: 0.5312\n","Epoch 128, Train Loss: 0.9898, Val Loss: 1.5531, F1 Micro: 0.4792, F1 Macro: 0.4516, Accuracy: 0.4792\n","Epoch 129, Train Loss: 0.9752, Val Loss: 1.4169, F1 Micro: 0.4896, F1 Macro: 0.4405, Accuracy: 0.4896\n","Epoch 130, Train Loss: 0.9659, Val Loss: 1.5177, F1 Micro: 0.5104, F1 Macro: 0.5037, Accuracy: 0.5104\n","Epoch 131, Train Loss: 0.9923, Val Loss: 1.7498, F1 Micro: 0.4167, F1 Macro: 0.3572, Accuracy: 0.4167\n","Epoch 132, Train Loss: 1.0061, Val Loss: 1.3430, F1 Micro: 0.5417, F1 Macro: 0.5293, Accuracy: 0.5417\n","Epoch 133, Train Loss: 0.9689, Val Loss: 1.5719, F1 Micro: 0.4167, F1 Macro: 0.4027, Accuracy: 0.4167\n","Epoch 134, Train Loss: 0.9411, Val Loss: 1.5121, F1 Micro: 0.4896, F1 Macro: 0.4484, Accuracy: 0.4896\n","Epoch 135, Train Loss: 0.9645, Val Loss: 1.4922, F1 Micro: 0.4792, F1 Macro: 0.4240, Accuracy: 0.4792\n","Epoch 136, Train Loss: 0.9513, Val Loss: 1.4783, F1 Micro: 0.5208, F1 Macro: 0.4796, Accuracy: 0.5208\n","Epoch 137, Train Loss: 1.0005, Val Loss: 1.4818, F1 Micro: 0.5417, F1 Macro: 0.4941, Accuracy: 0.5417\n","Epoch 138, Train Loss: 1.0170, Val Loss: 1.3687, F1 Micro: 0.6250, F1 Macro: 0.5794, Accuracy: 0.6250\n","Epoch 139, Train Loss: 0.9512, Val Loss: 1.3858, F1 Micro: 0.5104, F1 Macro: 0.4717, Accuracy: 0.5104\n","Epoch 140, Train Loss: 0.9175, Val Loss: 1.8329, F1 Micro: 0.4375, F1 Macro: 0.4018, Accuracy: 0.4375\n","Epoch 141, Train Loss: 1.0133, Val Loss: 1.5612, F1 Micro: 0.4896, F1 Macro: 0.4586, Accuracy: 0.4896\n","Epoch 142, Train Loss: 0.9984, Val Loss: 1.4283, F1 Micro: 0.5208, F1 Macro: 0.4943, Accuracy: 0.5208\n","Epoch 143, Train Loss: 0.9080, Val Loss: 1.3918, F1 Micro: 0.5312, F1 Macro: 0.4881, Accuracy: 0.5312\n","Epoch 144, Train Loss: 0.9001, Val Loss: 1.3188, F1 Micro: 0.5521, F1 Macro: 0.5153, Accuracy: 0.5521\n","Epoch 145, Train Loss: 0.9485, Val Loss: 1.6191, F1 Micro: 0.4271, F1 Macro: 0.3991, Accuracy: 0.4271\n","Epoch 146, Train Loss: 0.9756, Val Loss: 1.4844, F1 Micro: 0.5625, F1 Macro: 0.4987, Accuracy: 0.5625\n","Epoch 147, Train Loss: 1.0045, Val Loss: 1.6436, F1 Micro: 0.5000, F1 Macro: 0.4715, Accuracy: 0.5000\n","Epoch 148, Train Loss: 1.0295, Val Loss: 1.8513, F1 Micro: 0.4896, F1 Macro: 0.4470, Accuracy: 0.4896\n","Epoch 149, Train Loss: 0.9271, Val Loss: 1.4276, F1 Micro: 0.5833, F1 Macro: 0.5702, Accuracy: 0.5833\n","Epoch 150, Train Loss: 0.9541, Val Loss: 1.4464, F1 Micro: 0.4688, F1 Macro: 0.4402, Accuracy: 0.4688\n","Epoch 151, Train Loss: 0.9107, Val Loss: 1.2979, F1 Micro: 0.5833, F1 Macro: 0.5520, Accuracy: 0.5833\n","Epoch 152, Train Loss: 0.9400, Val Loss: 1.5920, F1 Micro: 0.5104, F1 Macro: 0.4662, Accuracy: 0.5104\n","Epoch 153, Train Loss: 0.9265, Val Loss: 1.8597, F1 Micro: 0.3750, F1 Macro: 0.3824, Accuracy: 0.3750\n","Epoch 154, Train Loss: 1.0323, Val Loss: 1.3304, F1 Micro: 0.5625, F1 Macro: 0.5291, Accuracy: 0.5625\n","Epoch 155, Train Loss: 0.9786, Val Loss: 1.3748, F1 Micro: 0.5521, F1 Macro: 0.5257, Accuracy: 0.5521\n","Epoch 156, Train Loss: 0.9283, Val Loss: 1.3690, F1 Micro: 0.5000, F1 Macro: 0.4738, Accuracy: 0.5000\n","Epoch 157, Train Loss: 0.9360, Val Loss: 1.5552, F1 Micro: 0.5000, F1 Macro: 0.4596, Accuracy: 0.5000\n","Epoch 158, Train Loss: 0.9467, Val Loss: 1.4511, F1 Micro: 0.5208, F1 Macro: 0.4722, Accuracy: 0.5208\n","Epoch 159, Train Loss: 0.9273, Val Loss: 1.5256, F1 Micro: 0.5000, F1 Macro: 0.4745, Accuracy: 0.5000\n","Epoch 160, Train Loss: 0.9341, Val Loss: 1.5503, F1 Micro: 0.4688, F1 Macro: 0.4547, Accuracy: 0.4688\n","Epoch 161, Train Loss: 0.8879, Val Loss: 1.3565, F1 Micro: 0.5938, F1 Macro: 0.5513, Accuracy: 0.5938\n","Epoch 162, Train Loss: 0.9188, Val Loss: 1.6183, F1 Micro: 0.4688, F1 Macro: 0.4588, Accuracy: 0.4688\n","Epoch 163, Train Loss: 0.8905, Val Loss: 1.7122, F1 Micro: 0.5000, F1 Macro: 0.4843, Accuracy: 0.5000\n","Epoch 164, Train Loss: 0.9629, Val Loss: 1.4926, F1 Micro: 0.5000, F1 Macro: 0.4860, Accuracy: 0.5000\n","Epoch 165, Train Loss: 0.8617, Val Loss: 1.3964, F1 Micro: 0.5729, F1 Macro: 0.5466, Accuracy: 0.5729\n","Epoch 166, Train Loss: 0.8691, Val Loss: 1.5970, F1 Micro: 0.4583, F1 Macro: 0.4336, Accuracy: 0.4583\n","Epoch 167, Train Loss: 0.8460, Val Loss: 1.2983, F1 Micro: 0.5625, F1 Macro: 0.5382, Accuracy: 0.5625\n","Epoch 168, Train Loss: 0.9183, Val Loss: 1.7845, F1 Micro: 0.4167, F1 Macro: 0.3870, Accuracy: 0.4167\n","Epoch 169, Train Loss: 0.9069, Val Loss: 1.7197, F1 Micro: 0.4792, F1 Macro: 0.4122, Accuracy: 0.4792\n","Epoch 170, Train Loss: 0.9746, Val Loss: 1.4145, F1 Micro: 0.5625, F1 Macro: 0.5435, Accuracy: 0.5625\n","Epoch 171, Train Loss: 0.9073, Val Loss: 1.4727, F1 Micro: 0.5208, F1 Macro: 0.4782, Accuracy: 0.5208\n","Epoch 172, Train Loss: 0.9134, Val Loss: 1.4218, F1 Micro: 0.5208, F1 Macro: 0.4925, Accuracy: 0.5208\n","Epoch 173, Train Loss: 0.9154, Val Loss: 1.3428, F1 Micro: 0.5521, F1 Macro: 0.5261, Accuracy: 0.5521\n","Epoch 174, Train Loss: 0.8768, Val Loss: 1.3549, F1 Micro: 0.5625, F1 Macro: 0.5200, Accuracy: 0.5625\n","Epoch 175, Train Loss: 0.9156, Val Loss: 1.4343, F1 Micro: 0.5312, F1 Macro: 0.5154, Accuracy: 0.5312\n","Epoch 176, Train Loss: 0.9259, Val Loss: 1.6646, F1 Micro: 0.5729, F1 Macro: 0.5066, Accuracy: 0.5729\n","Epoch 177, Train Loss: 0.8918, Val Loss: 1.3343, F1 Micro: 0.5729, F1 Macro: 0.5502, Accuracy: 0.5729\n","Epoch 178, Train Loss: 0.8814, Val Loss: 1.3447, F1 Micro: 0.5104, F1 Macro: 0.4796, Accuracy: 0.5104\n","Epoch 179, Train Loss: 0.8506, Val Loss: 1.3643, F1 Micro: 0.5208, F1 Macro: 0.4866, Accuracy: 0.5208\n","Epoch 180, Train Loss: 0.9176, Val Loss: 1.5015, F1 Micro: 0.5312, F1 Macro: 0.4530, Accuracy: 0.5312\n","Epoch 181, Train Loss: 0.8304, Val Loss: 1.3270, F1 Micro: 0.5729, F1 Macro: 0.5243, Accuracy: 0.5729\n","Epoch 182, Train Loss: 0.8070, Val Loss: 1.4983, F1 Micro: 0.4896, F1 Macro: 0.4873, Accuracy: 0.4896\n","Epoch 183, Train Loss: 0.9110, Val Loss: 1.2866, F1 Micro: 0.5729, F1 Macro: 0.5510, Accuracy: 0.5729\n","Epoch 184, Train Loss: 0.8535, Val Loss: 1.3050, F1 Micro: 0.6250, F1 Macro: 0.5898, Accuracy: 0.6250\n","Epoch 185, Train Loss: 0.8467, Val Loss: 1.3273, F1 Micro: 0.5729, F1 Macro: 0.5630, Accuracy: 0.5729\n","Epoch 186, Train Loss: 0.9131, Val Loss: 2.4023, F1 Micro: 0.3854, F1 Macro: 0.3129, Accuracy: 0.3854\n","Epoch 187, Train Loss: 0.9136, Val Loss: 1.4279, F1 Micro: 0.5000, F1 Macro: 0.4670, Accuracy: 0.5000\n","Epoch 188, Train Loss: 0.8455, Val Loss: 1.6600, F1 Micro: 0.4479, F1 Macro: 0.3775, Accuracy: 0.4479\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8039, Val Loss: 1.8170, F1 Micro: 0.1771, F1 Macro: 0.0934, Accuracy: 0.1771\n","Epoch 2, Train Loss: 1.7665, Val Loss: 1.7466, F1 Micro: 0.2917, F1 Macro: 0.2413, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.7126, Val Loss: 1.7796, F1 Micro: 0.2604, F1 Macro: 0.2075, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.6737, Val Loss: 1.8612, F1 Micro: 0.2500, F1 Macro: 0.1622, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.6553, Val Loss: 1.7244, F1 Micro: 0.3125, F1 Macro: 0.2729, Accuracy: 0.3125\n","Epoch 6, Train Loss: 1.6432, Val Loss: 1.7565, F1 Micro: 0.1875, F1 Macro: 0.1367, Accuracy: 0.1875\n","Epoch 7, Train Loss: 1.6603, Val Loss: 1.7361, F1 Micro: 0.2396, F1 Macro: 0.1950, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6155, Val Loss: 1.7316, F1 Micro: 0.3229, F1 Macro: 0.2895, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.5969, Val Loss: 1.6995, F1 Micro: 0.2917, F1 Macro: 0.2157, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.5736, Val Loss: 1.7031, F1 Micro: 0.2604, F1 Macro: 0.1929, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.5797, Val Loss: 1.6815, F1 Micro: 0.2708, F1 Macro: 0.2325, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.5632, Val Loss: 1.7213, F1 Micro: 0.3125, F1 Macro: 0.2642, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.6119, Val Loss: 1.7498, F1 Micro: 0.3333, F1 Macro: 0.2408, Accuracy: 0.3333\n","Epoch 14, Train Loss: 1.5363, Val Loss: 1.7401, F1 Micro: 0.3229, F1 Macro: 0.2802, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.5574, Val Loss: 1.6409, F1 Micro: 0.3125, F1 Macro: 0.2894, Accuracy: 0.3125\n","Epoch 16, Train Loss: 1.5104, Val Loss: 1.6864, F1 Micro: 0.2917, F1 Macro: 0.2372, Accuracy: 0.2917\n","Epoch 17, Train Loss: 1.4725, Val Loss: 1.6756, F1 Micro: 0.3646, F1 Macro: 0.3273, Accuracy: 0.3646\n","Epoch 18, Train Loss: 1.4984, Val Loss: 1.6840, F1 Micro: 0.2917, F1 Macro: 0.2439, Accuracy: 0.2917\n","Epoch 19, Train Loss: 1.4842, Val Loss: 1.6503, F1 Micro: 0.3958, F1 Macro: 0.3718, Accuracy: 0.3958\n","Epoch 20, Train Loss: 1.4966, Val Loss: 1.6897, F1 Micro: 0.3125, F1 Macro: 0.2855, Accuracy: 0.3125\n","Epoch 21, Train Loss: 1.5140, Val Loss: 1.6040, F1 Micro: 0.3542, F1 Macro: 0.3564, Accuracy: 0.3542\n","Epoch 22, Train Loss: 1.4710, Val Loss: 1.8546, F1 Micro: 0.3438, F1 Macro: 0.2738, Accuracy: 0.3438\n","Epoch 23, Train Loss: 1.4673, Val Loss: 1.6664, F1 Micro: 0.4271, F1 Macro: 0.3956, Accuracy: 0.4271\n","Epoch 24, Train Loss: 1.4433, Val Loss: 1.6406, F1 Micro: 0.4271, F1 Macro: 0.3945, Accuracy: 0.4271\n","Epoch 25, Train Loss: 1.4216, Val Loss: 1.5847, F1 Micro: 0.4167, F1 Macro: 0.3717, Accuracy: 0.4167\n","Epoch 26, Train Loss: 1.4488, Val Loss: 1.6222, F1 Micro: 0.3646, F1 Macro: 0.3240, Accuracy: 0.3646\n","Epoch 27, Train Loss: 1.4157, Val Loss: 1.6158, F1 Micro: 0.4167, F1 Macro: 0.3979, Accuracy: 0.4167\n","Epoch 28, Train Loss: 1.4171, Val Loss: 1.6937, F1 Micro: 0.3229, F1 Macro: 0.2771, Accuracy: 0.3229\n","Epoch 29, Train Loss: 1.4095, Val Loss: 1.8457, F1 Micro: 0.2917, F1 Macro: 0.2331, Accuracy: 0.2917\n","Epoch 30, Train Loss: 1.3986, Val Loss: 1.6684, F1 Micro: 0.3333, F1 Macro: 0.3046, Accuracy: 0.3333\n","Epoch 31, Train Loss: 1.4092, Val Loss: 1.6564, F1 Micro: 0.3750, F1 Macro: 0.3273, Accuracy: 0.3750\n","Epoch 32, Train Loss: 1.3607, Val Loss: 2.0004, F1 Micro: 0.1875, F1 Macro: 0.1349, Accuracy: 0.1875\n","Epoch 33, Train Loss: 1.3603, Val Loss: 1.7466, F1 Micro: 0.2396, F1 Macro: 0.1876, Accuracy: 0.2396\n","Epoch 34, Train Loss: 1.3708, Val Loss: 1.7918, F1 Micro: 0.3021, F1 Macro: 0.2693, Accuracy: 0.3021\n","Epoch 35, Train Loss: 1.3807, Val Loss: 1.7153, F1 Micro: 0.3021, F1 Macro: 0.2205, Accuracy: 0.3021\n","Epoch 36, Train Loss: 1.3446, Val Loss: 1.7530, F1 Micro: 0.3125, F1 Macro: 0.2328, Accuracy: 0.3125\n","Epoch 37, Train Loss: 1.3651, Val Loss: 1.7028, F1 Micro: 0.3542, F1 Macro: 0.3264, Accuracy: 0.3542\n","Epoch 38, Train Loss: 1.3421, Val Loss: 2.0546, F1 Micro: 0.2292, F1 Macro: 0.1874, Accuracy: 0.2292\n","Epoch 39, Train Loss: 1.3391, Val Loss: 1.5415, F1 Micro: 0.4688, F1 Macro: 0.4573, Accuracy: 0.4688\n","Epoch 40, Train Loss: 1.3416, Val Loss: 1.4740, F1 Micro: 0.3958, F1 Macro: 0.3801, Accuracy: 0.3958\n","Epoch 41, Train Loss: 1.3175, Val Loss: 1.5439, F1 Micro: 0.3958, F1 Macro: 0.3813, Accuracy: 0.3958\n","Epoch 42, Train Loss: 1.2561, Val Loss: 1.5314, F1 Micro: 0.3958, F1 Macro: 0.3722, Accuracy: 0.3958\n","Epoch 43, Train Loss: 1.3233, Val Loss: 1.5575, F1 Micro: 0.4167, F1 Macro: 0.3916, Accuracy: 0.4167\n","Epoch 44, Train Loss: 1.3067, Val Loss: 1.5531, F1 Micro: 0.3646, F1 Macro: 0.3522, Accuracy: 0.3646\n","Epoch 45, Train Loss: 1.2881, Val Loss: 1.5493, F1 Micro: 0.3750, F1 Macro: 0.3492, Accuracy: 0.3750\n","Epoch 46, Train Loss: 1.2690, Val Loss: 1.9491, F1 Micro: 0.3333, F1 Macro: 0.2789, Accuracy: 0.3333\n","Epoch 47, Train Loss: 1.2459, Val Loss: 1.6976, F1 Micro: 0.4375, F1 Macro: 0.3921, Accuracy: 0.4375\n","Epoch 48, Train Loss: 1.2275, Val Loss: 1.8442, F1 Micro: 0.3333, F1 Macro: 0.2894, Accuracy: 0.3333\n","Epoch 49, Train Loss: 1.2798, Val Loss: 1.4237, F1 Micro: 0.4479, F1 Macro: 0.4402, Accuracy: 0.4479\n","Epoch 50, Train Loss: 1.2558, Val Loss: 1.7427, F1 Micro: 0.3542, F1 Macro: 0.3086, Accuracy: 0.3542\n","Epoch 51, Train Loss: 1.2597, Val Loss: 1.6404, F1 Micro: 0.3958, F1 Macro: 0.3612, Accuracy: 0.3958\n","Epoch 52, Train Loss: 1.2442, Val Loss: 1.7002, F1 Micro: 0.3750, F1 Macro: 0.3265, Accuracy: 0.3750\n","Epoch 53, Train Loss: 1.2107, Val Loss: 1.5101, F1 Micro: 0.4479, F1 Macro: 0.4389, Accuracy: 0.4479\n","Epoch 54, Train Loss: 1.2146, Val Loss: 1.6614, F1 Micro: 0.3750, F1 Macro: 0.3383, Accuracy: 0.3750\n","Epoch 55, Train Loss: 1.2481, Val Loss: 1.8114, F1 Micro: 0.3125, F1 Macro: 0.2841, Accuracy: 0.3125\n","Epoch 56, Train Loss: 1.2406, Val Loss: 1.6129, F1 Micro: 0.3333, F1 Macro: 0.3117, Accuracy: 0.3333\n","Epoch 57, Train Loss: 1.2135, Val Loss: 1.4894, F1 Micro: 0.4375, F1 Macro: 0.4004, Accuracy: 0.4375\n","Epoch 58, Train Loss: 1.2355, Val Loss: 1.4701, F1 Micro: 0.4271, F1 Macro: 0.4286, Accuracy: 0.4271\n","Epoch 59, Train Loss: 1.2406, Val Loss: 1.5609, F1 Micro: 0.3958, F1 Macro: 0.3834, Accuracy: 0.3958\n","Epoch 60, Train Loss: 1.2074, Val Loss: 1.7390, F1 Micro: 0.3333, F1 Macro: 0.3061, Accuracy: 0.3333\n","Epoch 61, Train Loss: 1.2033, Val Loss: 1.7002, F1 Micro: 0.3646, F1 Macro: 0.3239, Accuracy: 0.3646\n","Epoch 62, Train Loss: 1.2168, Val Loss: 2.0208, F1 Micro: 0.2812, F1 Macro: 0.2458, Accuracy: 0.2812\n","Epoch 63, Train Loss: 1.1398, Val Loss: 1.5605, F1 Micro: 0.4167, F1 Macro: 0.4064, Accuracy: 0.4167\n","Epoch 64, Train Loss: 1.1911, Val Loss: 1.7091, F1 Micro: 0.3646, F1 Macro: 0.3453, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.1785, Val Loss: 1.7007, F1 Micro: 0.3854, F1 Macro: 0.3537, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.1442, Val Loss: 1.6086, F1 Micro: 0.4062, F1 Macro: 0.3866, Accuracy: 0.4062\n","Epoch 67, Train Loss: 1.1296, Val Loss: 1.5002, F1 Micro: 0.4792, F1 Macro: 0.4609, Accuracy: 0.4792\n","Epoch 68, Train Loss: 1.1570, Val Loss: 1.7639, F1 Micro: 0.3958, F1 Macro: 0.3871, Accuracy: 0.3958\n","Epoch 69, Train Loss: 1.1683, Val Loss: 1.7460, F1 Micro: 0.3958, F1 Macro: 0.3636, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.1906, Val Loss: 1.7109, F1 Micro: 0.3750, F1 Macro: 0.3434, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.1883, Val Loss: 1.5106, F1 Micro: 0.4375, F1 Macro: 0.3975, Accuracy: 0.4375\n","Epoch 72, Train Loss: 1.1635, Val Loss: 1.6203, F1 Micro: 0.3958, F1 Macro: 0.3608, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.1310, Val Loss: 1.4356, F1 Micro: 0.4896, F1 Macro: 0.4856, Accuracy: 0.4896\n","Epoch 74, Train Loss: 1.1797, Val Loss: 1.5642, F1 Micro: 0.4167, F1 Macro: 0.4284, Accuracy: 0.4167\n","Epoch 75, Train Loss: 1.1458, Val Loss: 1.6969, F1 Micro: 0.4167, F1 Macro: 0.3617, Accuracy: 0.4167\n","Epoch 76, Train Loss: 1.0707, Val Loss: 1.5975, F1 Micro: 0.4167, F1 Macro: 0.4053, Accuracy: 0.4167\n","Epoch 77, Train Loss: 1.1101, Val Loss: 1.6409, F1 Micro: 0.3646, F1 Macro: 0.3098, Accuracy: 0.3646\n","Epoch 78, Train Loss: 1.1097, Val Loss: 1.4269, F1 Micro: 0.4479, F1 Macro: 0.4314, Accuracy: 0.4479\n","Epoch 79, Train Loss: 1.1085, Val Loss: 1.5111, F1 Micro: 0.4583, F1 Macro: 0.4181, Accuracy: 0.4583\n","Epoch 80, Train Loss: 1.0474, Val Loss: 1.4768, F1 Micro: 0.4062, F1 Macro: 0.3895, Accuracy: 0.4062\n","Epoch 81, Train Loss: 1.0699, Val Loss: 1.6274, F1 Micro: 0.3542, F1 Macro: 0.3190, Accuracy: 0.3542\n","Epoch 82, Train Loss: 1.1192, Val Loss: 1.4997, F1 Micro: 0.4062, F1 Macro: 0.3694, Accuracy: 0.4062\n","Epoch 83, Train Loss: 1.1006, Val Loss: 1.4379, F1 Micro: 0.4479, F1 Macro: 0.4409, Accuracy: 0.4479\n","Epoch 84, Train Loss: 1.0524, Val Loss: 1.9289, F1 Micro: 0.3229, F1 Macro: 0.2660, Accuracy: 0.3229\n","Epoch 85, Train Loss: 1.0518, Val Loss: 1.6160, F1 Micro: 0.4167, F1 Macro: 0.3841, Accuracy: 0.4167\n","Epoch 86, Train Loss: 1.1058, Val Loss: 1.5871, F1 Micro: 0.4792, F1 Macro: 0.4701, Accuracy: 0.4792\n","Epoch 87, Train Loss: 1.0870, Val Loss: 1.5437, F1 Micro: 0.4792, F1 Macro: 0.4632, Accuracy: 0.4792\n","Epoch 88, Train Loss: 1.0605, Val Loss: 1.4264, F1 Micro: 0.5208, F1 Macro: 0.4958, Accuracy: 0.5208\n","Epoch 89, Train Loss: 1.0691, Val Loss: 2.2499, F1 Micro: 0.3646, F1 Macro: 0.3361, Accuracy: 0.3646\n","Epoch 90, Train Loss: 1.0987, Val Loss: 1.4104, F1 Micro: 0.4688, F1 Macro: 0.4647, Accuracy: 0.4688\n","Epoch 91, Train Loss: 1.0398, Val Loss: 1.7751, F1 Micro: 0.3750, F1 Macro: 0.3585, Accuracy: 0.3750\n","Epoch 92, Train Loss: 1.0516, Val Loss: 1.5199, F1 Micro: 0.4688, F1 Macro: 0.4767, Accuracy: 0.4688\n","Epoch 93, Train Loss: 1.0493, Val Loss: 1.4213, F1 Micro: 0.4688, F1 Macro: 0.4535, Accuracy: 0.4688\n","Epoch 94, Train Loss: 1.0613, Val Loss: 1.3668, F1 Micro: 0.5208, F1 Macro: 0.5008, Accuracy: 0.5208\n","Epoch 95, Train Loss: 1.0569, Val Loss: 1.5653, F1 Micro: 0.3854, F1 Macro: 0.3693, Accuracy: 0.3854\n","Epoch 96, Train Loss: 1.0694, Val Loss: 1.4760, F1 Micro: 0.5208, F1 Macro: 0.5215, Accuracy: 0.5208\n","Epoch 97, Train Loss: 1.0434, Val Loss: 1.3864, F1 Micro: 0.4583, F1 Macro: 0.4537, Accuracy: 0.4583\n","Epoch 98, Train Loss: 1.0921, Val Loss: 1.6277, F1 Micro: 0.3750, F1 Macro: 0.3654, Accuracy: 0.3750\n","Epoch 99, Train Loss: 1.0623, Val Loss: 1.4163, F1 Micro: 0.4479, F1 Macro: 0.4359, Accuracy: 0.4479\n","Epoch 100, Train Loss: 0.9926, Val Loss: 1.5230, F1 Micro: 0.4271, F1 Macro: 0.4341, Accuracy: 0.4271\n","Epoch 101, Train Loss: 1.0426, Val Loss: 2.0627, F1 Micro: 0.3021, F1 Macro: 0.2684, Accuracy: 0.3021\n","Epoch 102, Train Loss: 1.0576, Val Loss: 1.7151, F1 Micro: 0.4375, F1 Macro: 0.4075, Accuracy: 0.4375\n","Epoch 103, Train Loss: 1.0425, Val Loss: 1.7282, F1 Micro: 0.4375, F1 Macro: 0.3868, Accuracy: 0.4375\n","Epoch 104, Train Loss: 1.0190, Val Loss: 1.7273, F1 Micro: 0.4167, F1 Macro: 0.4185, Accuracy: 0.4167\n","Epoch 105, Train Loss: 0.9921, Val Loss: 1.5516, F1 Micro: 0.4271, F1 Macro: 0.4275, Accuracy: 0.4271\n","Epoch 106, Train Loss: 1.0511, Val Loss: 2.0811, F1 Micro: 0.4375, F1 Macro: 0.3815, Accuracy: 0.4375\n","Epoch 107, Train Loss: 1.0719, Val Loss: 1.5421, F1 Micro: 0.4583, F1 Macro: 0.4515, Accuracy: 0.4583\n","Epoch 108, Train Loss: 0.9629, Val Loss: 1.5384, F1 Micro: 0.4375, F1 Macro: 0.4270, Accuracy: 0.4375\n","Epoch 109, Train Loss: 1.0431, Val Loss: 1.4194, F1 Micro: 0.4792, F1 Macro: 0.4576, Accuracy: 0.4792\n","Epoch 110, Train Loss: 1.0397, Val Loss: 1.7124, F1 Micro: 0.4271, F1 Macro: 0.3850, Accuracy: 0.4271\n","Epoch 111, Train Loss: 1.0088, Val Loss: 1.3328, F1 Micro: 0.5208, F1 Macro: 0.5074, Accuracy: 0.5208\n","Epoch 112, Train Loss: 0.9669, Val Loss: 1.6027, F1 Micro: 0.4062, F1 Macro: 0.3674, Accuracy: 0.4062\n","Epoch 113, Train Loss: 0.9890, Val Loss: 1.5525, F1 Micro: 0.4167, F1 Macro: 0.3861, Accuracy: 0.4167\n","Epoch 114, Train Loss: 1.0223, Val Loss: 1.6214, F1 Micro: 0.3854, F1 Macro: 0.3408, Accuracy: 0.3854\n","Epoch 115, Train Loss: 1.0334, Val Loss: 1.5257, F1 Micro: 0.4583, F1 Macro: 0.4357, Accuracy: 0.4583\n","Epoch 116, Train Loss: 0.9993, Val Loss: 1.4811, F1 Micro: 0.4792, F1 Macro: 0.4367, Accuracy: 0.4792\n","Epoch 117, Train Loss: 1.0339, Val Loss: 1.9962, F1 Micro: 0.3646, F1 Macro: 0.3178, Accuracy: 0.3646\n","Epoch 118, Train Loss: 0.9659, Val Loss: 1.3736, F1 Micro: 0.5417, F1 Macro: 0.5378, Accuracy: 0.5417\n","Epoch 119, Train Loss: 1.0175, Val Loss: 1.3983, F1 Micro: 0.5312, F1 Macro: 0.5378, Accuracy: 0.5312\n","Epoch 120, Train Loss: 0.9874, Val Loss: 1.5562, F1 Micro: 0.5000, F1 Macro: 0.4888, Accuracy: 0.5000\n","Epoch 121, Train Loss: 0.9958, Val Loss: 1.6062, F1 Micro: 0.4583, F1 Macro: 0.4009, Accuracy: 0.4583\n","Epoch 122, Train Loss: 0.9605, Val Loss: 1.5459, F1 Micro: 0.4792, F1 Macro: 0.4682, Accuracy: 0.4792\n","Epoch 123, Train Loss: 0.9918, Val Loss: 1.3958, F1 Micro: 0.5312, F1 Macro: 0.5345, Accuracy: 0.5312\n","Epoch 124, Train Loss: 0.9563, Val Loss: 1.5097, F1 Micro: 0.4375, F1 Macro: 0.4121, Accuracy: 0.4375\n","Epoch 125, Train Loss: 0.9598, Val Loss: 1.3544, F1 Micro: 0.4896, F1 Macro: 0.4680, Accuracy: 0.4896\n","Epoch 126, Train Loss: 0.9352, Val Loss: 1.4347, F1 Micro: 0.4688, F1 Macro: 0.4398, Accuracy: 0.4688\n","Epoch 127, Train Loss: 0.9134, Val Loss: 1.4829, F1 Micro: 0.4792, F1 Macro: 0.4591, Accuracy: 0.4792\n","Epoch 128, Train Loss: 0.8975, Val Loss: 1.7359, F1 Micro: 0.4479, F1 Macro: 0.4430, Accuracy: 0.4479\n","Epoch 129, Train Loss: 0.9557, Val Loss: 1.4981, F1 Micro: 0.5000, F1 Macro: 0.5117, Accuracy: 0.5000\n","Epoch 130, Train Loss: 1.0204, Val Loss: 1.4296, F1 Micro: 0.5208, F1 Macro: 0.5067, Accuracy: 0.5208\n","Epoch 131, Train Loss: 1.0200, Val Loss: 1.5231, F1 Micro: 0.5000, F1 Macro: 0.4828, Accuracy: 0.5000\n","Epoch 132, Train Loss: 0.9229, Val Loss: 1.4543, F1 Micro: 0.4792, F1 Macro: 0.4712, Accuracy: 0.4792\n","Epoch 133, Train Loss: 1.0007, Val Loss: 1.6021, F1 Micro: 0.5417, F1 Macro: 0.5014, Accuracy: 0.5417\n","Epoch 134, Train Loss: 0.9717, Val Loss: 1.7449, F1 Micro: 0.4271, F1 Macro: 0.3897, Accuracy: 0.4271\n","Epoch 135, Train Loss: 0.9660, Val Loss: 1.7838, F1 Micro: 0.3958, F1 Macro: 0.3525, Accuracy: 0.3958\n","Epoch 136, Train Loss: 1.0304, Val Loss: 1.4311, F1 Micro: 0.4688, F1 Macro: 0.4238, Accuracy: 0.4688\n","Epoch 137, Train Loss: 0.9004, Val Loss: 1.4168, F1 Micro: 0.4792, F1 Macro: 0.4666, Accuracy: 0.4792\n","Epoch 138, Train Loss: 0.8797, Val Loss: 1.4508, F1 Micro: 0.4792, F1 Macro: 0.4838, Accuracy: 0.4792\n","Epoch 139, Train Loss: 0.9690, Val Loss: 1.4265, F1 Micro: 0.5312, F1 Macro: 0.5087, Accuracy: 0.5312\n","Epoch 140, Train Loss: 0.9495, Val Loss: 1.6357, F1 Micro: 0.3854, F1 Macro: 0.3578, Accuracy: 0.3854\n","Epoch 141, Train Loss: 0.9220, Val Loss: 1.3371, F1 Micro: 0.4896, F1 Macro: 0.4823, Accuracy: 0.4896\n","Epoch 142, Train Loss: 0.9549, Val Loss: 1.6080, F1 Micro: 0.5208, F1 Macro: 0.5081, Accuracy: 0.5208\n","Epoch 143, Train Loss: 0.9260, Val Loss: 1.5731, F1 Micro: 0.4688, F1 Macro: 0.4356, Accuracy: 0.4688\n","Epoch 144, Train Loss: 0.9602, Val Loss: 1.4573, F1 Micro: 0.4688, F1 Macro: 0.4419, Accuracy: 0.4688\n","Epoch 145, Train Loss: 0.9036, Val Loss: 1.9056, F1 Micro: 0.4271, F1 Macro: 0.3723, Accuracy: 0.4271\n","Epoch 146, Train Loss: 0.9349, Val Loss: 1.3970, F1 Micro: 0.5729, F1 Macro: 0.5474, Accuracy: 0.5729\n","Epoch 147, Train Loss: 0.9479, Val Loss: 1.6946, F1 Micro: 0.3958, F1 Macro: 0.3905, Accuracy: 0.3958\n","Epoch 148, Train Loss: 0.9473, Val Loss: 1.5870, F1 Micro: 0.4688, F1 Macro: 0.4403, Accuracy: 0.4688\n","Epoch 149, Train Loss: 0.8790, Val Loss: 1.7850, F1 Micro: 0.4479, F1 Macro: 0.4098, Accuracy: 0.4479\n","Epoch 150, Train Loss: 0.9439, Val Loss: 1.6988, F1 Micro: 0.4479, F1 Macro: 0.3981, Accuracy: 0.4479\n","Epoch 151, Train Loss: 0.9601, Val Loss: 1.5986, F1 Micro: 0.4271, F1 Macro: 0.4415, Accuracy: 0.4271\n","Epoch 152, Train Loss: 0.9524, Val Loss: 1.8168, F1 Micro: 0.4271, F1 Macro: 0.3928, Accuracy: 0.4271\n","Epoch 153, Train Loss: 0.9572, Val Loss: 1.8226, F1 Micro: 0.3646, F1 Macro: 0.3575, Accuracy: 0.3646\n","Epoch 154, Train Loss: 0.9048, Val Loss: 1.8889, F1 Micro: 0.3646, F1 Macro: 0.3389, Accuracy: 0.3646\n","Epoch 155, Train Loss: 0.9148, Val Loss: 1.3840, F1 Micro: 0.5729, F1 Macro: 0.5781, Accuracy: 0.5729\n","Epoch 156, Train Loss: 0.9390, Val Loss: 1.3826, F1 Micro: 0.4583, F1 Macro: 0.4588, Accuracy: 0.4583\n","Epoch 157, Train Loss: 0.8640, Val Loss: 1.5843, F1 Micro: 0.4792, F1 Macro: 0.4542, Accuracy: 0.4792\n","Epoch 158, Train Loss: 0.8896, Val Loss: 1.3343, F1 Micro: 0.5625, F1 Macro: 0.5666, Accuracy: 0.5625\n","Epoch 159, Train Loss: 0.9081, Val Loss: 1.3081, F1 Micro: 0.5104, F1 Macro: 0.5165, Accuracy: 0.5104\n","Epoch 160, Train Loss: 0.9037, Val Loss: 1.3968, F1 Micro: 0.5521, F1 Macro: 0.5423, Accuracy: 0.5521\n","Epoch 161, Train Loss: 0.8183, Val Loss: 1.3712, F1 Micro: 0.5000, F1 Macro: 0.4982, Accuracy: 0.5000\n","Epoch 162, Train Loss: 0.8598, Val Loss: 1.4182, F1 Micro: 0.4271, F1 Macro: 0.4112, Accuracy: 0.4271\n","Epoch 163, Train Loss: 0.8857, Val Loss: 1.7141, F1 Micro: 0.3750, F1 Macro: 0.3228, Accuracy: 0.3750\n","Epoch 164, Train Loss: 0.8668, Val Loss: 1.3457, F1 Micro: 0.5208, F1 Macro: 0.5151, Accuracy: 0.5208\n","Epoch 165, Train Loss: 0.8520, Val Loss: 1.4626, F1 Micro: 0.4792, F1 Macro: 0.4882, Accuracy: 0.4792\n","Epoch 166, Train Loss: 0.8387, Val Loss: 1.4096, F1 Micro: 0.5938, F1 Macro: 0.6017, Accuracy: 0.5938\n","Epoch 167, Train Loss: 0.9048, Val Loss: 1.4629, F1 Micro: 0.4479, F1 Macro: 0.4554, Accuracy: 0.4479\n","Epoch 168, Train Loss: 0.8522, Val Loss: 1.5165, F1 Micro: 0.4583, F1 Macro: 0.4433, Accuracy: 0.4583\n","Epoch 169, Train Loss: 0.7857, Val Loss: 1.6070, F1 Micro: 0.4271, F1 Macro: 0.3860, Accuracy: 0.4271\n","Epoch 170, Train Loss: 0.8538, Val Loss: 1.5352, F1 Micro: 0.4688, F1 Macro: 0.4455, Accuracy: 0.4688\n","Epoch 171, Train Loss: 0.9171, Val Loss: 1.6974, F1 Micro: 0.4583, F1 Macro: 0.4212, Accuracy: 0.4583\n","Epoch 172, Train Loss: 0.9036, Val Loss: 1.5433, F1 Micro: 0.4896, F1 Macro: 0.4594, Accuracy: 0.4896\n","Epoch 173, Train Loss: 0.9225, Val Loss: 1.4117, F1 Micro: 0.4583, F1 Macro: 0.4619, Accuracy: 0.4583\n","Epoch 174, Train Loss: 0.8661, Val Loss: 1.3813, F1 Micro: 0.5000, F1 Macro: 0.5148, Accuracy: 0.5000\n","Epoch 175, Train Loss: 0.8776, Val Loss: 1.4562, F1 Micro: 0.5000, F1 Macro: 0.4766, Accuracy: 0.5000\n","Epoch 176, Train Loss: 0.8763, Val Loss: 1.4043, F1 Micro: 0.4271, F1 Macro: 0.4040, Accuracy: 0.4271\n","Epoch 177, Train Loss: 0.9386, Val Loss: 1.9407, F1 Micro: 0.5312, F1 Macro: 0.4914, Accuracy: 0.5312\n","Epoch 178, Train Loss: 0.9298, Val Loss: 1.5818, F1 Micro: 0.4271, F1 Macro: 0.4394, Accuracy: 0.4271\n","Epoch 179, Train Loss: 0.8461, Val Loss: 1.5794, F1 Micro: 0.5104, F1 Macro: 0.5014, Accuracy: 0.5104\n","Epoch 180, Train Loss: 0.8230, Val Loss: 1.4225, F1 Micro: 0.5417, F1 Macro: 0.5230, Accuracy: 0.5417\n","Epoch 181, Train Loss: 0.8881, Val Loss: 1.6151, F1 Micro: 0.4688, F1 Macro: 0.4435, Accuracy: 0.4688\n","Epoch 182, Train Loss: 0.8963, Val Loss: 1.2769, F1 Micro: 0.5729, F1 Macro: 0.5691, Accuracy: 0.5729\n","Epoch 183, Train Loss: 0.8449, Val Loss: 2.0829, F1 Micro: 0.3958, F1 Macro: 0.3154, Accuracy: 0.3958\n","Epoch 184, Train Loss: 0.8478, Val Loss: 1.5435, F1 Micro: 0.4688, F1 Macro: 0.4821, Accuracy: 0.4688\n","Epoch 185, Train Loss: 0.7899, Val Loss: 1.5933, F1 Micro: 0.4271, F1 Macro: 0.4000, Accuracy: 0.4271\n","Epoch 186, Train Loss: 0.8563, Val Loss: 2.0134, F1 Micro: 0.4167, F1 Macro: 0.3842, Accuracy: 0.4167\n","Epoch 187, Train Loss: 0.8922, Val Loss: 1.2861, F1 Micro: 0.5104, F1 Macro: 0.5076, Accuracy: 0.5104\n","Epoch 188, Train Loss: 0.8295, Val Loss: 1.5649, F1 Micro: 0.4688, F1 Macro: 0.4350, Accuracy: 0.4688\n","Epoch 189, Train Loss: 0.8496, Val Loss: 1.4821, F1 Micro: 0.5104, F1 Macro: 0.5130, Accuracy: 0.5104\n","Epoch 190, Train Loss: 0.8020, Val Loss: 1.4791, F1 Micro: 0.4479, F1 Macro: 0.4208, Accuracy: 0.4479\n","Epoch 191, Train Loss: 0.8595, Val Loss: 1.8391, F1 Micro: 0.4583, F1 Macro: 0.4307, Accuracy: 0.4583\n","Epoch 192, Train Loss: 0.8477, Val Loss: 1.3390, F1 Micro: 0.5000, F1 Macro: 0.5090, Accuracy: 0.5000\n","Epoch 193, Train Loss: 0.8493, Val Loss: 1.5302, F1 Micro: 0.4896, F1 Macro: 0.4902, Accuracy: 0.4896\n","Epoch 194, Train Loss: 0.8561, Val Loss: 1.3061, F1 Micro: 0.5104, F1 Macro: 0.5178, Accuracy: 0.5104\n","Epoch 195, Train Loss: 0.8708, Val Loss: 1.5425, F1 Micro: 0.5104, F1 Macro: 0.5105, Accuracy: 0.5104\n","Epoch 196, Train Loss: 0.9060, Val Loss: 1.3703, F1 Micro: 0.4583, F1 Macro: 0.4571, Accuracy: 0.4583\n","Epoch 197, Train Loss: 0.8460, Val Loss: 1.4508, F1 Micro: 0.4792, F1 Macro: 0.4695, Accuracy: 0.4792\n","Epoch 198, Train Loss: 0.8084, Val Loss: 1.8723, F1 Micro: 0.3438, F1 Macro: 0.3354, Accuracy: 0.3438\n","Epoch 199, Train Loss: 0.7908, Val Loss: 1.2945, F1 Micro: 0.5521, F1 Macro: 0.5454, Accuracy: 0.5521\n","Epoch 200, Train Loss: 0.8676, Val Loss: 1.6270, F1 Micro: 0.4583, F1 Macro: 0.4521, Accuracy: 0.4583\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8369, Val Loss: 1.7295, F1 Micro: 0.3021, F1 Macro: 0.2341, Accuracy: 0.3021\n","Epoch 2, Train Loss: 1.7666, Val Loss: 1.6959, F1 Micro: 0.3021, F1 Macro: 0.2582, Accuracy: 0.3021\n","Epoch 3, Train Loss: 1.7321, Val Loss: 1.7117, F1 Micro: 0.2917, F1 Macro: 0.2480, Accuracy: 0.2917\n","Epoch 4, Train Loss: 1.7031, Val Loss: 1.7015, F1 Micro: 0.3333, F1 Macro: 0.2395, Accuracy: 0.3333\n","Epoch 5, Train Loss: 1.6716, Val Loss: 1.7287, F1 Micro: 0.2812, F1 Macro: 0.2364, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.6421, Val Loss: 1.6981, F1 Micro: 0.3646, F1 Macro: 0.3529, Accuracy: 0.3646\n","Epoch 7, Train Loss: 1.6205, Val Loss: 1.7083, F1 Micro: 0.3438, F1 Macro: 0.2755, Accuracy: 0.3438\n","Epoch 8, Train Loss: 1.6227, Val Loss: 1.6627, F1 Micro: 0.3646, F1 Macro: 0.3391, Accuracy: 0.3646\n","Epoch 9, Train Loss: 1.5815, Val Loss: 1.6938, F1 Micro: 0.3021, F1 Macro: 0.2353, Accuracy: 0.3021\n","Epoch 10, Train Loss: 1.6088, Val Loss: 1.6608, F1 Micro: 0.3229, F1 Macro: 0.2983, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.5810, Val Loss: 1.7185, F1 Micro: 0.3646, F1 Macro: 0.3428, Accuracy: 0.3646\n","Epoch 12, Train Loss: 1.5481, Val Loss: 1.6837, F1 Micro: 0.3958, F1 Macro: 0.3981, Accuracy: 0.3958\n","Epoch 13, Train Loss: 1.5472, Val Loss: 1.7029, F1 Micro: 0.3646, F1 Macro: 0.3379, Accuracy: 0.3646\n","Epoch 14, Train Loss: 1.5408, Val Loss: 1.7865, F1 Micro: 0.3125, F1 Macro: 0.2729, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.5110, Val Loss: 1.7506, F1 Micro: 0.3542, F1 Macro: 0.2699, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5429, Val Loss: 1.6804, F1 Micro: 0.3854, F1 Macro: 0.3734, Accuracy: 0.3854\n","Epoch 17, Train Loss: 1.5111, Val Loss: 1.6738, F1 Micro: 0.4062, F1 Macro: 0.3985, Accuracy: 0.4062\n","Epoch 18, Train Loss: 1.4931, Val Loss: 1.7411, F1 Micro: 0.3125, F1 Macro: 0.2693, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.4608, Val Loss: 1.6753, F1 Micro: 0.3854, F1 Macro: 0.3840, Accuracy: 0.3854\n","Epoch 20, Train Loss: 1.5016, Val Loss: 1.7745, F1 Micro: 0.3021, F1 Macro: 0.2458, Accuracy: 0.3021\n","Epoch 21, Train Loss: 1.4282, Val Loss: 1.6983, F1 Micro: 0.3750, F1 Macro: 0.3462, Accuracy: 0.3750\n","Epoch 22, Train Loss: 1.4186, Val Loss: 1.7401, F1 Micro: 0.3646, F1 Macro: 0.3754, Accuracy: 0.3646\n","Epoch 23, Train Loss: 1.4305, Val Loss: 1.8893, F1 Micro: 0.3021, F1 Macro: 0.2737, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.4345, Val Loss: 1.7130, F1 Micro: 0.3438, F1 Macro: 0.3140, Accuracy: 0.3438\n","Epoch 25, Train Loss: 1.4083, Val Loss: 1.6605, F1 Micro: 0.4062, F1 Macro: 0.4069, Accuracy: 0.4062\n","Epoch 26, Train Loss: 1.3871, Val Loss: 1.7903, F1 Micro: 0.3438, F1 Macro: 0.3141, Accuracy: 0.3438\n","Epoch 27, Train Loss: 1.4014, Val Loss: 1.7399, F1 Micro: 0.3750, F1 Macro: 0.3606, Accuracy: 0.3750\n","Epoch 28, Train Loss: 1.3814, Val Loss: 1.6762, F1 Micro: 0.3750, F1 Macro: 0.3713, Accuracy: 0.3750\n","Epoch 29, Train Loss: 1.3718, Val Loss: 1.6806, F1 Micro: 0.3958, F1 Macro: 0.3787, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.4638, Val Loss: 1.7331, F1 Micro: 0.3542, F1 Macro: 0.3255, Accuracy: 0.3542\n","Epoch 31, Train Loss: 1.3973, Val Loss: 1.6372, F1 Micro: 0.4583, F1 Macro: 0.4149, Accuracy: 0.4583\n","Epoch 32, Train Loss: 1.3428, Val Loss: 1.6915, F1 Micro: 0.3438, F1 Macro: 0.3301, Accuracy: 0.3438\n","Epoch 33, Train Loss: 1.4096, Val Loss: 1.9303, F1 Micro: 0.3229, F1 Macro: 0.3094, Accuracy: 0.3229\n","Epoch 34, Train Loss: 1.3533, Val Loss: 1.7835, F1 Micro: 0.2917, F1 Macro: 0.2429, Accuracy: 0.2917\n","Epoch 35, Train Loss: 1.3790, Val Loss: 1.5918, F1 Micro: 0.3958, F1 Macro: 0.3902, Accuracy: 0.3958\n","Epoch 36, Train Loss: 1.2956, Val Loss: 1.6946, F1 Micro: 0.4375, F1 Macro: 0.4171, Accuracy: 0.4375\n","Epoch 37, Train Loss: 1.3247, Val Loss: 1.7333, F1 Micro: 0.4271, F1 Macro: 0.3836, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.3543, Val Loss: 1.7901, F1 Micro: 0.3646, F1 Macro: 0.3645, Accuracy: 0.3646\n","Epoch 39, Train Loss: 1.3049, Val Loss: 1.6598, F1 Micro: 0.3958, F1 Macro: 0.3985, Accuracy: 0.3958\n","Epoch 40, Train Loss: 1.2966, Val Loss: 1.6115, F1 Micro: 0.4688, F1 Macro: 0.4725, Accuracy: 0.4688\n","Epoch 41, Train Loss: 1.3007, Val Loss: 1.7789, F1 Micro: 0.3646, F1 Macro: 0.3664, Accuracy: 0.3646\n","Epoch 42, Train Loss: 1.2964, Val Loss: 1.6246, F1 Micro: 0.4062, F1 Macro: 0.3837, Accuracy: 0.4062\n","Epoch 43, Train Loss: 1.3137, Val Loss: 1.8955, F1 Micro: 0.3646, F1 Macro: 0.3297, Accuracy: 0.3646\n","Epoch 44, Train Loss: 1.2559, Val Loss: 1.7930, F1 Micro: 0.3854, F1 Macro: 0.3063, Accuracy: 0.3854\n","Epoch 45, Train Loss: 1.2421, Val Loss: 1.9310, F1 Micro: 0.3125, F1 Macro: 0.2827, Accuracy: 0.3125\n","Epoch 46, Train Loss: 1.2367, Val Loss: 1.7927, F1 Micro: 0.3750, F1 Macro: 0.3530, Accuracy: 0.3750\n","Epoch 47, Train Loss: 1.2437, Val Loss: 1.5915, F1 Micro: 0.4271, F1 Macro: 0.4284, Accuracy: 0.4271\n","Epoch 48, Train Loss: 1.2422, Val Loss: 1.5160, F1 Micro: 0.4375, F1 Macro: 0.4189, Accuracy: 0.4375\n","Epoch 49, Train Loss: 1.2750, Val Loss: 1.5574, F1 Micro: 0.4583, F1 Macro: 0.4638, Accuracy: 0.4583\n","Epoch 50, Train Loss: 1.2194, Val Loss: 1.7441, F1 Micro: 0.4062, F1 Macro: 0.3733, Accuracy: 0.4062\n","Epoch 51, Train Loss: 1.2027, Val Loss: 1.5801, F1 Micro: 0.4896, F1 Macro: 0.4750, Accuracy: 0.4896\n","Epoch 52, Train Loss: 1.2006, Val Loss: 1.7703, F1 Micro: 0.3542, F1 Macro: 0.3058, Accuracy: 0.3542\n","Epoch 53, Train Loss: 1.2660, Val Loss: 1.7831, F1 Micro: 0.3750, F1 Macro: 0.3614, Accuracy: 0.3750\n","Epoch 54, Train Loss: 1.1960, Val Loss: 1.7534, F1 Micro: 0.4583, F1 Macro: 0.4609, Accuracy: 0.4583\n","Epoch 55, Train Loss: 1.2389, Val Loss: 1.8988, F1 Micro: 0.3438, F1 Macro: 0.3325, Accuracy: 0.3438\n","Epoch 56, Train Loss: 1.2195, Val Loss: 1.6368, F1 Micro: 0.4271, F1 Macro: 0.4190, Accuracy: 0.4271\n","Epoch 57, Train Loss: 1.2003, Val Loss: 1.7291, F1 Micro: 0.4167, F1 Macro: 0.4062, Accuracy: 0.4167\n","Epoch 58, Train Loss: 1.2015, Val Loss: 1.6708, F1 Micro: 0.4062, F1 Macro: 0.3807, Accuracy: 0.4062\n","Epoch 59, Train Loss: 1.2129, Val Loss: 1.7187, F1 Micro: 0.4583, F1 Macro: 0.4137, Accuracy: 0.4583\n","Epoch 60, Train Loss: 1.1814, Val Loss: 1.5422, F1 Micro: 0.4688, F1 Macro: 0.4615, Accuracy: 0.4688\n","Epoch 61, Train Loss: 1.1467, Val Loss: 1.6860, F1 Micro: 0.4167, F1 Macro: 0.3986, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.2039, Val Loss: 1.7481, F1 Micro: 0.3646, F1 Macro: 0.3398, Accuracy: 0.3646\n","Epoch 63, Train Loss: 1.1915, Val Loss: 1.6846, F1 Micro: 0.4375, F1 Macro: 0.4269, Accuracy: 0.4375\n","Epoch 64, Train Loss: 1.2097, Val Loss: 1.8094, F1 Micro: 0.3333, F1 Macro: 0.2978, Accuracy: 0.3333\n","Epoch 65, Train Loss: 1.1480, Val Loss: 1.6694, F1 Micro: 0.3958, F1 Macro: 0.3707, Accuracy: 0.3958\n","Epoch 66, Train Loss: 1.1923, Val Loss: 1.5824, F1 Micro: 0.4896, F1 Macro: 0.5002, Accuracy: 0.4896\n","Epoch 67, Train Loss: 1.1979, Val Loss: 1.5102, F1 Micro: 0.5000, F1 Macro: 0.4969, Accuracy: 0.5000\n","Epoch 68, Train Loss: 1.1762, Val Loss: 1.5590, F1 Micro: 0.4583, F1 Macro: 0.4529, Accuracy: 0.4583\n","Epoch 69, Train Loss: 1.1333, Val Loss: 1.6862, F1 Micro: 0.4583, F1 Macro: 0.4461, Accuracy: 0.4583\n","Epoch 70, Train Loss: 1.1474, Val Loss: 1.8335, F1 Micro: 0.3438, F1 Macro: 0.3104, Accuracy: 0.3438\n","Epoch 71, Train Loss: 1.1884, Val Loss: 1.7658, F1 Micro: 0.4271, F1 Macro: 0.3929, Accuracy: 0.4271\n","Epoch 72, Train Loss: 1.1582, Val Loss: 1.5991, F1 Micro: 0.4479, F1 Macro: 0.4607, Accuracy: 0.4479\n","Epoch 73, Train Loss: 1.1723, Val Loss: 1.8149, F1 Micro: 0.4167, F1 Macro: 0.3930, Accuracy: 0.4167\n","Epoch 74, Train Loss: 1.1775, Val Loss: 1.9806, F1 Micro: 0.4271, F1 Macro: 0.4236, Accuracy: 0.4271\n","Epoch 75, Train Loss: 1.1375, Val Loss: 1.4544, F1 Micro: 0.5208, F1 Macro: 0.5210, Accuracy: 0.5208\n","Epoch 76, Train Loss: 1.1056, Val Loss: 1.7757, F1 Micro: 0.4271, F1 Macro: 0.4077, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.1180, Val Loss: 1.4756, F1 Micro: 0.5417, F1 Macro: 0.5163, Accuracy: 0.5417\n","Epoch 78, Train Loss: 1.0821, Val Loss: 1.5529, F1 Micro: 0.4792, F1 Macro: 0.4542, Accuracy: 0.4792\n","Epoch 79, Train Loss: 1.0796, Val Loss: 1.8040, F1 Micro: 0.4479, F1 Macro: 0.4191, Accuracy: 0.4479\n","Epoch 80, Train Loss: 1.1048, Val Loss: 1.7588, F1 Micro: 0.3542, F1 Macro: 0.3071, Accuracy: 0.3542\n","Epoch 81, Train Loss: 1.1072, Val Loss: 1.5464, F1 Micro: 0.5312, F1 Macro: 0.5345, Accuracy: 0.5312\n","Epoch 82, Train Loss: 1.0702, Val Loss: 1.6413, F1 Micro: 0.4688, F1 Macro: 0.4719, Accuracy: 0.4688\n","Epoch 83, Train Loss: 1.0940, Val Loss: 1.6013, F1 Micro: 0.4271, F1 Macro: 0.3594, Accuracy: 0.4271\n","Epoch 84, Train Loss: 1.0483, Val Loss: 1.6371, F1 Micro: 0.5104, F1 Macro: 0.5143, Accuracy: 0.5104\n","Epoch 85, Train Loss: 1.1173, Val Loss: 1.6467, F1 Micro: 0.5104, F1 Macro: 0.4876, Accuracy: 0.5104\n","Epoch 86, Train Loss: 1.1026, Val Loss: 1.5261, F1 Micro: 0.4688, F1 Macro: 0.4188, Accuracy: 0.4688\n","Epoch 87, Train Loss: 1.0532, Val Loss: 1.5712, F1 Micro: 0.4688, F1 Macro: 0.4318, Accuracy: 0.4688\n","Epoch 88, Train Loss: 1.0505, Val Loss: 1.7097, F1 Micro: 0.4479, F1 Macro: 0.4152, Accuracy: 0.4479\n","Epoch 89, Train Loss: 1.0322, Val Loss: 1.6433, F1 Micro: 0.4896, F1 Macro: 0.4782, Accuracy: 0.4896\n","Epoch 90, Train Loss: 1.0880, Val Loss: 1.5507, F1 Micro: 0.5000, F1 Macro: 0.4962, Accuracy: 0.5000\n","Epoch 91, Train Loss: 1.0064, Val Loss: 1.6180, F1 Micro: 0.4375, F1 Macro: 0.4271, Accuracy: 0.4375\n","Epoch 92, Train Loss: 1.0674, Val Loss: 1.9782, F1 Micro: 0.4062, F1 Macro: 0.3913, Accuracy: 0.4062\n","Epoch 93, Train Loss: 1.0675, Val Loss: 1.6038, F1 Micro: 0.4583, F1 Macro: 0.4428, Accuracy: 0.4583\n","Epoch 94, Train Loss: 1.0646, Val Loss: 1.5815, F1 Micro: 0.5521, F1 Macro: 0.5468, Accuracy: 0.5521\n","Epoch 95, Train Loss: 1.0410, Val Loss: 1.7139, F1 Micro: 0.4375, F1 Macro: 0.4368, Accuracy: 0.4375\n","Epoch 96, Train Loss: 1.0628, Val Loss: 1.7269, F1 Micro: 0.4167, F1 Macro: 0.4005, Accuracy: 0.4167\n","Epoch 97, Train Loss: 1.0387, Val Loss: 1.5357, F1 Micro: 0.5625, F1 Macro: 0.5468, Accuracy: 0.5625\n","Epoch 98, Train Loss: 1.0819, Val Loss: 1.5645, F1 Micro: 0.4896, F1 Macro: 0.4767, Accuracy: 0.4896\n","Epoch 99, Train Loss: 1.0512, Val Loss: 1.5434, F1 Micro: 0.5312, F1 Macro: 0.5319, Accuracy: 0.5312\n","Epoch 100, Train Loss: 1.0157, Val Loss: 1.5660, F1 Micro: 0.5000, F1 Macro: 0.5014, Accuracy: 0.5000\n","Epoch 101, Train Loss: 1.0675, Val Loss: 1.5607, F1 Micro: 0.5000, F1 Macro: 0.5027, Accuracy: 0.5000\n","Epoch 102, Train Loss: 1.0493, Val Loss: 1.5508, F1 Micro: 0.5312, F1 Macro: 0.5450, Accuracy: 0.5312\n","Epoch 103, Train Loss: 1.0322, Val Loss: 1.4547, F1 Micro: 0.5208, F1 Macro: 0.4954, Accuracy: 0.5208\n","Epoch 104, Train Loss: 0.9810, Val Loss: 1.6358, F1 Micro: 0.4792, F1 Macro: 0.4792, Accuracy: 0.4792\n","Epoch 105, Train Loss: 0.9884, Val Loss: 1.9015, F1 Micro: 0.4167, F1 Macro: 0.3796, Accuracy: 0.4167\n","Epoch 106, Train Loss: 1.0072, Val Loss: 1.7657, F1 Micro: 0.4062, F1 Macro: 0.4088, Accuracy: 0.4062\n","Epoch 107, Train Loss: 1.0416, Val Loss: 1.5665, F1 Micro: 0.5417, F1 Macro: 0.5380, Accuracy: 0.5417\n","Epoch 108, Train Loss: 0.9673, Val Loss: 1.6197, F1 Micro: 0.5000, F1 Macro: 0.4869, Accuracy: 0.5000\n","Epoch 109, Train Loss: 1.0406, Val Loss: 1.5237, F1 Micro: 0.4792, F1 Macro: 0.4639, Accuracy: 0.4792\n","Epoch 110, Train Loss: 0.9457, Val Loss: 1.8216, F1 Micro: 0.4271, F1 Macro: 0.3918, Accuracy: 0.4271\n","Epoch 111, Train Loss: 1.0536, Val Loss: 1.6994, F1 Micro: 0.4792, F1 Macro: 0.4638, Accuracy: 0.4792\n","Epoch 112, Train Loss: 1.0246, Val Loss: 1.5540, F1 Micro: 0.4688, F1 Macro: 0.4591, Accuracy: 0.4688\n","Epoch 113, Train Loss: 0.9897, Val Loss: 2.2884, F1 Micro: 0.3750, F1 Macro: 0.3666, Accuracy: 0.3750\n","Epoch 114, Train Loss: 0.9998, Val Loss: 1.5400, F1 Micro: 0.5312, F1 Macro: 0.5306, Accuracy: 0.5312\n","Epoch 115, Train Loss: 1.0120, Val Loss: 1.5217, F1 Micro: 0.5104, F1 Macro: 0.5142, Accuracy: 0.5104\n","Epoch 116, Train Loss: 0.9653, Val Loss: 1.5307, F1 Micro: 0.4688, F1 Macro: 0.4606, Accuracy: 0.4688\n","Epoch 117, Train Loss: 0.9621, Val Loss: 1.8971, F1 Micro: 0.3958, F1 Macro: 0.3779, Accuracy: 0.3958\n","Epoch 118, Train Loss: 0.9504, Val Loss: 1.9161, F1 Micro: 0.4271, F1 Macro: 0.3772, Accuracy: 0.4271\n","Epoch 119, Train Loss: 0.9219, Val Loss: 1.4142, F1 Micro: 0.5521, F1 Macro: 0.5380, Accuracy: 0.5521\n","Epoch 120, Train Loss: 1.0290, Val Loss: 1.6337, F1 Micro: 0.4271, F1 Macro: 0.3854, Accuracy: 0.4271\n","Epoch 121, Train Loss: 0.9681, Val Loss: 2.1734, F1 Micro: 0.3542, F1 Macro: 0.3257, Accuracy: 0.3542\n","Epoch 122, Train Loss: 1.0140, Val Loss: 1.4926, F1 Micro: 0.5312, F1 Macro: 0.4991, Accuracy: 0.5312\n","Epoch 123, Train Loss: 0.9309, Val Loss: 1.6551, F1 Micro: 0.4479, F1 Macro: 0.4075, Accuracy: 0.4479\n","Epoch 124, Train Loss: 0.9266, Val Loss: 1.6367, F1 Micro: 0.5312, F1 Macro: 0.5175, Accuracy: 0.5312\n","Epoch 125, Train Loss: 1.0044, Val Loss: 1.4816, F1 Micro: 0.5625, F1 Macro: 0.5674, Accuracy: 0.5625\n","Epoch 126, Train Loss: 0.9547, Val Loss: 1.5945, F1 Micro: 0.4583, F1 Macro: 0.4205, Accuracy: 0.4583\n","Epoch 127, Train Loss: 0.9629, Val Loss: 1.4034, F1 Micro: 0.5729, F1 Macro: 0.5708, Accuracy: 0.5729\n","Epoch 128, Train Loss: 0.9837, Val Loss: 1.4955, F1 Micro: 0.5208, F1 Macro: 0.5194, Accuracy: 0.5208\n","Epoch 129, Train Loss: 0.9439, Val Loss: 1.5833, F1 Micro: 0.5208, F1 Macro: 0.4965, Accuracy: 0.5208\n","Epoch 130, Train Loss: 0.9409, Val Loss: 1.4511, F1 Micro: 0.5417, F1 Macro: 0.5337, Accuracy: 0.5417\n","Epoch 131, Train Loss: 1.0035, Val Loss: 2.0835, F1 Micro: 0.4167, F1 Macro: 0.4044, Accuracy: 0.4167\n","Epoch 132, Train Loss: 1.0099, Val Loss: 1.9321, F1 Micro: 0.4062, F1 Macro: 0.3895, Accuracy: 0.4062\n","Epoch 133, Train Loss: 1.0111, Val Loss: 1.6527, F1 Micro: 0.5000, F1 Macro: 0.4765, Accuracy: 0.5000\n","Epoch 134, Train Loss: 1.0044, Val Loss: 1.8266, F1 Micro: 0.4792, F1 Macro: 0.4552, Accuracy: 0.4792\n","Epoch 135, Train Loss: 0.9578, Val Loss: 1.4666, F1 Micro: 0.5417, F1 Macro: 0.5389, Accuracy: 0.5417\n","Epoch 136, Train Loss: 0.9396, Val Loss: 1.4293, F1 Micro: 0.5938, F1 Macro: 0.5898, Accuracy: 0.5938\n","Epoch 137, Train Loss: 0.9301, Val Loss: 1.7336, F1 Micro: 0.4792, F1 Macro: 0.4458, Accuracy: 0.4792\n","Epoch 138, Train Loss: 0.9035, Val Loss: 1.5459, F1 Micro: 0.5208, F1 Macro: 0.5156, Accuracy: 0.5208\n","Epoch 139, Train Loss: 0.8514, Val Loss: 1.4956, F1 Micro: 0.5521, F1 Macro: 0.5551, Accuracy: 0.5521\n","Epoch 140, Train Loss: 0.9156, Val Loss: 1.4395, F1 Micro: 0.5521, F1 Macro: 0.5481, Accuracy: 0.5521\n","Epoch 141, Train Loss: 0.9591, Val Loss: 1.4970, F1 Micro: 0.5625, F1 Macro: 0.5374, Accuracy: 0.5625\n","Epoch 142, Train Loss: 0.8668, Val Loss: 1.5037, F1 Micro: 0.5417, F1 Macro: 0.5563, Accuracy: 0.5417\n","Epoch 143, Train Loss: 0.8672, Val Loss: 1.6964, F1 Micro: 0.4479, F1 Macro: 0.4208, Accuracy: 0.4479\n","Epoch 144, Train Loss: 0.8618, Val Loss: 1.4989, F1 Micro: 0.5625, F1 Macro: 0.5527, Accuracy: 0.5625\n","Epoch 145, Train Loss: 0.9292, Val Loss: 1.5568, F1 Micro: 0.4896, F1 Macro: 0.4799, Accuracy: 0.4896\n","Epoch 146, Train Loss: 0.9725, Val Loss: 1.6263, F1 Micro: 0.5312, F1 Macro: 0.5346, Accuracy: 0.5312\n","Epoch 147, Train Loss: 0.9452, Val Loss: 1.5529, F1 Micro: 0.5000, F1 Macro: 0.4969, Accuracy: 0.5000\n","Epoch 148, Train Loss: 0.8991, Val Loss: 1.4696, F1 Micro: 0.5417, F1 Macro: 0.5477, Accuracy: 0.5417\n","Epoch 149, Train Loss: 0.9072, Val Loss: 1.4740, F1 Micro: 0.5312, F1 Macro: 0.5262, Accuracy: 0.5312\n","Epoch 150, Train Loss: 0.8603, Val Loss: 1.6615, F1 Micro: 0.5312, F1 Macro: 0.5385, Accuracy: 0.5312\n","Epoch 151, Train Loss: 0.8718, Val Loss: 1.4719, F1 Micro: 0.5833, F1 Macro: 0.5890, Accuracy: 0.5833\n","Epoch 152, Train Loss: 0.8870, Val Loss: 1.7721, F1 Micro: 0.5104, F1 Macro: 0.5007, Accuracy: 0.5104\n","Epoch 153, Train Loss: 0.9171, Val Loss: 1.7463, F1 Micro: 0.4688, F1 Macro: 0.4246, Accuracy: 0.4688\n","Epoch 154, Train Loss: 0.8735, Val Loss: 1.5753, F1 Micro: 0.4792, F1 Macro: 0.4657, Accuracy: 0.4792\n","Epoch 155, Train Loss: 0.8790, Val Loss: 1.5985, F1 Micro: 0.5000, F1 Macro: 0.5069, Accuracy: 0.5000\n","Epoch 156, Train Loss: 0.8367, Val Loss: 1.5889, F1 Micro: 0.4896, F1 Macro: 0.4719, Accuracy: 0.4896\n","Epoch 157, Train Loss: 0.8710, Val Loss: 1.6431, F1 Micro: 0.5000, F1 Macro: 0.5047, Accuracy: 0.5000\n","Epoch 158, Train Loss: 0.8994, Val Loss: 1.6473, F1 Micro: 0.4896, F1 Macro: 0.4815, Accuracy: 0.4896\n","Epoch 159, Train Loss: 0.9190, Val Loss: 1.5589, F1 Micro: 0.5625, F1 Macro: 0.5755, Accuracy: 0.5625\n","Epoch 160, Train Loss: 0.8932, Val Loss: 2.0962, F1 Micro: 0.4583, F1 Macro: 0.4321, Accuracy: 0.4583\n","Epoch 161, Train Loss: 0.8877, Val Loss: 1.5633, F1 Micro: 0.5312, F1 Macro: 0.5418, Accuracy: 0.5312\n","Epoch 162, Train Loss: 0.9285, Val Loss: 1.5783, F1 Micro: 0.5417, F1 Macro: 0.5500, Accuracy: 0.5417\n","Epoch 163, Train Loss: 0.8856, Val Loss: 1.8425, F1 Micro: 0.4583, F1 Macro: 0.4679, Accuracy: 0.4583\n","Epoch 164, Train Loss: 0.8319, Val Loss: 1.4595, F1 Micro: 0.5417, F1 Macro: 0.5314, Accuracy: 0.5417\n","Epoch 165, Train Loss: 0.9239, Val Loss: 1.5667, F1 Micro: 0.5312, F1 Macro: 0.5284, Accuracy: 0.5312\n","Epoch 166, Train Loss: 0.8673, Val Loss: 1.5386, F1 Micro: 0.5208, F1 Macro: 0.5147, Accuracy: 0.5208\n","Epoch 167, Train Loss: 0.8497, Val Loss: 1.4366, F1 Micro: 0.5833, F1 Macro: 0.5853, Accuracy: 0.5833\n","Epoch 168, Train Loss: 0.8597, Val Loss: 1.3899, F1 Micro: 0.5938, F1 Macro: 0.6017, Accuracy: 0.5938\n","Epoch 169, Train Loss: 0.9280, Val Loss: 1.5872, F1 Micro: 0.5312, F1 Macro: 0.5511, Accuracy: 0.5312\n","Epoch 170, Train Loss: 0.8312, Val Loss: 1.6627, F1 Micro: 0.5625, F1 Macro: 0.5729, Accuracy: 0.5625\n","Epoch 171, Train Loss: 0.9052, Val Loss: 1.6954, F1 Micro: 0.4375, F1 Macro: 0.4031, Accuracy: 0.4375\n","Epoch 172, Train Loss: 0.9265, Val Loss: 1.5884, F1 Micro: 0.5417, F1 Macro: 0.5452, Accuracy: 0.5417\n","Epoch 173, Train Loss: 0.8931, Val Loss: 1.4164, F1 Micro: 0.5729, F1 Macro: 0.5847, Accuracy: 0.5729\n","Epoch 174, Train Loss: 0.8770, Val Loss: 1.4138, F1 Micro: 0.5312, F1 Macro: 0.5358, Accuracy: 0.5312\n","Epoch 175, Train Loss: 0.9140, Val Loss: 1.5379, F1 Micro: 0.4688, F1 Macro: 0.4637, Accuracy: 0.4688\n","Epoch 176, Train Loss: 0.8924, Val Loss: 1.5920, F1 Micro: 0.4896, F1 Macro: 0.4852, Accuracy: 0.4896\n","Epoch 177, Train Loss: 0.8626, Val Loss: 1.6752, F1 Micro: 0.5208, F1 Macro: 0.4953, Accuracy: 0.5208\n","Epoch 178, Train Loss: 0.8451, Val Loss: 1.5239, F1 Micro: 0.5938, F1 Macro: 0.6036, Accuracy: 0.5938\n","Epoch 179, Train Loss: 0.9102, Val Loss: 1.9575, F1 Micro: 0.4896, F1 Macro: 0.4975, Accuracy: 0.4896\n","Epoch 180, Train Loss: 0.9075, Val Loss: 1.5936, F1 Micro: 0.5521, F1 Macro: 0.5558, Accuracy: 0.5521\n","Epoch 181, Train Loss: 0.9345, Val Loss: 1.7288, F1 Micro: 0.4375, F1 Macro: 0.4469, Accuracy: 0.4375\n","Epoch 182, Train Loss: 0.8974, Val Loss: 1.9831, F1 Micro: 0.5000, F1 Macro: 0.4670, Accuracy: 0.5000\n","Epoch 183, Train Loss: 0.8576, Val Loss: 1.4773, F1 Micro: 0.5938, F1 Macro: 0.6103, Accuracy: 0.5938\n","Epoch 184, Train Loss: 0.8156, Val Loss: 1.3940, F1 Micro: 0.6042, F1 Macro: 0.6085, Accuracy: 0.6042\n","Epoch 185, Train Loss: 0.8074, Val Loss: 1.5240, F1 Micro: 0.5521, F1 Macro: 0.5463, Accuracy: 0.5521\n","Epoch 186, Train Loss: 0.8266, Val Loss: 1.6585, F1 Micro: 0.5208, F1 Macro: 0.5262, Accuracy: 0.5208\n","Epoch 187, Train Loss: 0.8117, Val Loss: 1.4999, F1 Micro: 0.5312, F1 Macro: 0.5224, Accuracy: 0.5312\n","Epoch 188, Train Loss: 0.8650, Val Loss: 1.3660, F1 Micro: 0.5938, F1 Macro: 0.6009, Accuracy: 0.5938\n","Epoch 189, Train Loss: 0.8546, Val Loss: 1.5468, F1 Micro: 0.5104, F1 Macro: 0.5033, Accuracy: 0.5104\n","Epoch 190, Train Loss: 0.8719, Val Loss: 1.3512, F1 Micro: 0.6042, F1 Macro: 0.6141, Accuracy: 0.6042\n","Epoch 191, Train Loss: 0.8503, Val Loss: 1.5195, F1 Micro: 0.5104, F1 Macro: 0.4962, Accuracy: 0.5104\n","Epoch 192, Train Loss: 0.8173, Val Loss: 1.6991, F1 Micro: 0.4896, F1 Macro: 0.4975, Accuracy: 0.4896\n","Epoch 193, Train Loss: 0.8689, Val Loss: 1.5933, F1 Micro: 0.5625, F1 Macro: 0.5439, Accuracy: 0.5625\n","Epoch 194, Train Loss: 0.8255, Val Loss: 1.4023, F1 Micro: 0.5625, F1 Macro: 0.5558, Accuracy: 0.5625\n","Epoch 195, Train Loss: 0.8424, Val Loss: 1.4656, F1 Micro: 0.5312, F1 Macro: 0.5396, Accuracy: 0.5312\n","Epoch 196, Train Loss: 0.8396, Val Loss: 1.5389, F1 Micro: 0.5625, F1 Macro: 0.5360, Accuracy: 0.5625\n","Epoch 197, Train Loss: 0.8263, Val Loss: 1.4349, F1 Micro: 0.5417, F1 Macro: 0.5333, Accuracy: 0.5417\n","Epoch 198, Train Loss: 0.7843, Val Loss: 1.4939, F1 Micro: 0.5729, F1 Macro: 0.5682, Accuracy: 0.5729\n","Epoch 199, Train Loss: 0.8670, Val Loss: 1.8650, F1 Micro: 0.5312, F1 Macro: 0.5009, Accuracy: 0.5312\n","Epoch 200, Train Loss: 0.8349, Val Loss: 1.6806, F1 Micro: 0.5417, F1 Macro: 0.5145, Accuracy: 0.5417\n","Average Score for hyperparameters (0.001, 8, 50): 0.5770833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8045, Val Loss: 1.6901, F1 Micro: 0.2396, F1 Macro: 0.2097, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7403, Val Loss: 1.7562, F1 Micro: 0.2604, F1 Macro: 0.1945, Accuracy: 0.2604\n","Epoch 3, Train Loss: 1.6948, Val Loss: 1.6705, F1 Micro: 0.3021, F1 Macro: 0.2619, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.6720, Val Loss: 1.7183, F1 Micro: 0.3333, F1 Macro: 0.3081, Accuracy: 0.3333\n","Epoch 5, Train Loss: 1.6585, Val Loss: 1.6634, F1 Micro: 0.3229, F1 Macro: 0.3066, Accuracy: 0.3229\n","Epoch 6, Train Loss: 1.6195, Val Loss: 1.6691, F1 Micro: 0.2812, F1 Macro: 0.2554, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.6303, Val Loss: 1.6571, F1 Micro: 0.3646, F1 Macro: 0.3463, Accuracy: 0.3646\n","Epoch 8, Train Loss: 1.6026, Val Loss: 1.6566, F1 Micro: 0.3125, F1 Macro: 0.3048, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.5902, Val Loss: 1.6543, F1 Micro: 0.3333, F1 Macro: 0.3026, Accuracy: 0.3333\n","Epoch 10, Train Loss: 1.5666, Val Loss: 1.6628, F1 Micro: 0.3021, F1 Macro: 0.2772, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.5638, Val Loss: 1.6640, F1 Micro: 0.3333, F1 Macro: 0.2847, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.5485, Val Loss: 1.6901, F1 Micro: 0.3229, F1 Macro: 0.3290, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.5262, Val Loss: 1.6815, F1 Micro: 0.3646, F1 Macro: 0.3370, Accuracy: 0.3646\n","Epoch 14, Train Loss: 1.5566, Val Loss: 1.7320, F1 Micro: 0.3125, F1 Macro: 0.3003, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.5252, Val Loss: 1.6411, F1 Micro: 0.3854, F1 Macro: 0.3476, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.5176, Val Loss: 1.6846, F1 Micro: 0.3333, F1 Macro: 0.2673, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.5151, Val Loss: 1.6545, F1 Micro: 0.3125, F1 Macro: 0.2983, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.4825, Val Loss: 1.6232, F1 Micro: 0.3750, F1 Macro: 0.3465, Accuracy: 0.3750\n","Epoch 19, Train Loss: 1.4663, Val Loss: 1.6632, F1 Micro: 0.3125, F1 Macro: 0.3196, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.4446, Val Loss: 1.6621, F1 Micro: 0.3021, F1 Macro: 0.2626, Accuracy: 0.3021\n","Epoch 21, Train Loss: 1.4282, Val Loss: 1.6187, F1 Micro: 0.3438, F1 Macro: 0.3427, Accuracy: 0.3438\n","Epoch 22, Train Loss: 1.4300, Val Loss: 1.7537, F1 Micro: 0.2917, F1 Macro: 0.2432, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.4346, Val Loss: 1.6437, F1 Micro: 0.3542, F1 Macro: 0.3139, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.3879, Val Loss: 1.6572, F1 Micro: 0.3333, F1 Macro: 0.3418, Accuracy: 0.3333\n","Epoch 25, Train Loss: 1.4039, Val Loss: 1.7913, F1 Micro: 0.3021, F1 Macro: 0.2632, Accuracy: 0.3021\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8103, Val Loss: 1.7588, F1 Micro: 0.2396, F1 Macro: 0.1351, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7326, Val Loss: 1.7947, F1 Micro: 0.1667, F1 Macro: 0.1467, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.7058, Val Loss: 1.6885, F1 Micro: 0.3125, F1 Macro: 0.2748, Accuracy: 0.3125\n","Epoch 4, Train Loss: 1.6937, Val Loss: 1.7275, F1 Micro: 0.2500, F1 Macro: 0.1668, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.6788, Val Loss: 1.6977, F1 Micro: 0.3125, F1 Macro: 0.2973, Accuracy: 0.3125\n","Epoch 6, Train Loss: 1.6689, Val Loss: 1.6528, F1 Micro: 0.3333, F1 Macro: 0.2723, Accuracy: 0.3333\n","Epoch 7, Train Loss: 1.6474, Val Loss: 1.6613, F1 Micro: 0.3333, F1 Macro: 0.2988, Accuracy: 0.3333\n","Epoch 8, Train Loss: 1.6272, Val Loss: 1.5948, F1 Micro: 0.3854, F1 Macro: 0.3476, Accuracy: 0.3854\n","Epoch 9, Train Loss: 1.6230, Val Loss: 1.6716, F1 Micro: 0.3438, F1 Macro: 0.3237, Accuracy: 0.3438\n","Epoch 10, Train Loss: 1.6040, Val Loss: 1.6091, F1 Micro: 0.3854, F1 Macro: 0.3116, Accuracy: 0.3854\n","Epoch 11, Train Loss: 1.6104, Val Loss: 1.6179, F1 Micro: 0.3438, F1 Macro: 0.2890, Accuracy: 0.3438\n","Epoch 12, Train Loss: 1.5934, Val Loss: 1.6406, F1 Micro: 0.3125, F1 Macro: 0.2837, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.5950, Val Loss: 1.5986, F1 Micro: 0.3438, F1 Macro: 0.2825, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.6009, Val Loss: 1.5915, F1 Micro: 0.3958, F1 Macro: 0.3317, Accuracy: 0.3958\n","Epoch 15, Train Loss: 1.5704, Val Loss: 1.5968, F1 Micro: 0.3646, F1 Macro: 0.3180, Accuracy: 0.3646\n","Epoch 16, Train Loss: 1.5533, Val Loss: 1.5370, F1 Micro: 0.4062, F1 Macro: 0.3679, Accuracy: 0.4062\n","Epoch 17, Train Loss: 1.5543, Val Loss: 1.6534, F1 Micro: 0.3125, F1 Macro: 0.2817, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.5507, Val Loss: 1.5646, F1 Micro: 0.3750, F1 Macro: 0.3983, Accuracy: 0.3750\n","Epoch 19, Train Loss: 1.4958, Val Loss: 1.5708, F1 Micro: 0.3750, F1 Macro: 0.3428, Accuracy: 0.3750\n","Epoch 20, Train Loss: 1.5106, Val Loss: 1.5697, F1 Micro: 0.3958, F1 Macro: 0.3380, Accuracy: 0.3958\n","Epoch 21, Train Loss: 1.4826, Val Loss: 1.5906, F1 Micro: 0.3542, F1 Macro: 0.2860, Accuracy: 0.3542\n","Epoch 22, Train Loss: 1.4610, Val Loss: 1.6302, F1 Micro: 0.3542, F1 Macro: 0.3211, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.4685, Val Loss: 1.4748, F1 Micro: 0.4167, F1 Macro: 0.3621, Accuracy: 0.4167\n","Epoch 24, Train Loss: 1.4223, Val Loss: 1.6126, F1 Micro: 0.3333, F1 Macro: 0.2972, Accuracy: 0.3333\n","Epoch 25, Train Loss: 1.4395, Val Loss: 1.5404, F1 Micro: 0.4375, F1 Macro: 0.4146, Accuracy: 0.4375\n","Epoch 26, Train Loss: 1.4172, Val Loss: 1.6322, F1 Micro: 0.3229, F1 Macro: 0.2902, Accuracy: 0.3229\n","Epoch 27, Train Loss: 1.4202, Val Loss: 1.4847, F1 Micro: 0.4792, F1 Macro: 0.4322, Accuracy: 0.4792\n","Epoch 28, Train Loss: 1.4207, Val Loss: 2.0357, F1 Micro: 0.2396, F1 Macro: 0.1699, Accuracy: 0.2396\n","Epoch 29, Train Loss: 1.4438, Val Loss: 1.5782, F1 Micro: 0.3958, F1 Macro: 0.3499, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.4074, Val Loss: 1.4810, F1 Micro: 0.4583, F1 Macro: 0.4304, Accuracy: 0.4583\n","Epoch 31, Train Loss: 1.3866, Val Loss: 1.4917, F1 Micro: 0.3958, F1 Macro: 0.3376, Accuracy: 0.3958\n","Epoch 32, Train Loss: 1.3308, Val Loss: 1.4713, F1 Micro: 0.4792, F1 Macro: 0.4673, Accuracy: 0.4792\n","Epoch 33, Train Loss: 1.3418, Val Loss: 1.6036, F1 Micro: 0.3646, F1 Macro: 0.3938, Accuracy: 0.3646\n","Epoch 34, Train Loss: 1.3326, Val Loss: 1.4566, F1 Micro: 0.4271, F1 Macro: 0.3870, Accuracy: 0.4271\n","Epoch 35, Train Loss: 1.3629, Val Loss: 1.5908, F1 Micro: 0.4792, F1 Macro: 0.4230, Accuracy: 0.4792\n","Epoch 36, Train Loss: 1.3680, Val Loss: 1.7130, F1 Micro: 0.3646, F1 Macro: 0.3459, Accuracy: 0.3646\n","Epoch 37, Train Loss: 1.3391, Val Loss: 1.4821, F1 Micro: 0.4896, F1 Macro: 0.4522, Accuracy: 0.4896\n","Epoch 38, Train Loss: 1.3301, Val Loss: 1.6918, F1 Micro: 0.2917, F1 Macro: 0.2913, Accuracy: 0.2917\n","Epoch 39, Train Loss: 1.3002, Val Loss: 1.9552, F1 Micro: 0.2708, F1 Macro: 0.2694, Accuracy: 0.2708\n","Epoch 40, Train Loss: 1.3068, Val Loss: 1.8120, F1 Micro: 0.3438, F1 Macro: 0.2926, Accuracy: 0.3438\n","Epoch 41, Train Loss: 1.3292, Val Loss: 1.6830, F1 Micro: 0.3125, F1 Macro: 0.2704, Accuracy: 0.3125\n","Epoch 42, Train Loss: 1.2692, Val Loss: 1.6293, F1 Micro: 0.4375, F1 Macro: 0.3793, Accuracy: 0.4375\n","Epoch 43, Train Loss: 1.3124, Val Loss: 1.5176, F1 Micro: 0.4688, F1 Macro: 0.4429, Accuracy: 0.4688\n","Epoch 44, Train Loss: 1.2665, Val Loss: 1.6212, F1 Micro: 0.3646, F1 Macro: 0.3307, Accuracy: 0.3646\n","Epoch 45, Train Loss: 1.2900, Val Loss: 1.5515, F1 Micro: 0.3958, F1 Macro: 0.3752, Accuracy: 0.3958\n","Epoch 46, Train Loss: 1.2526, Val Loss: 1.6915, F1 Micro: 0.3750, F1 Macro: 0.3949, Accuracy: 0.3750\n","Epoch 47, Train Loss: 1.2642, Val Loss: 1.5401, F1 Micro: 0.3854, F1 Macro: 0.3286, Accuracy: 0.3854\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8008, Val Loss: 1.7901, F1 Micro: 0.2188, F1 Macro: 0.1539, Accuracy: 0.2188\n","Epoch 2, Train Loss: 1.7123, Val Loss: 1.7810, F1 Micro: 0.1875, F1 Macro: 0.1773, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.6856, Val Loss: 1.7223, F1 Micro: 0.2708, F1 Macro: 0.2321, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.6816, Val Loss: 1.7652, F1 Micro: 0.1979, F1 Macro: 0.1281, Accuracy: 0.1979\n","Epoch 5, Train Loss: 1.6739, Val Loss: 1.8013, F1 Micro: 0.2708, F1 Macro: 0.2582, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.6295, Val Loss: 1.7132, F1 Micro: 0.2812, F1 Macro: 0.2208, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.6367, Val Loss: 1.8236, F1 Micro: 0.2604, F1 Macro: 0.2039, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6162, Val Loss: 1.7232, F1 Micro: 0.2812, F1 Macro: 0.2281, Accuracy: 0.2812\n","Epoch 9, Train Loss: 1.6206, Val Loss: 1.7306, F1 Micro: 0.2708, F1 Macro: 0.2209, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.5735, Val Loss: 1.6652, F1 Micro: 0.3958, F1 Macro: 0.3574, Accuracy: 0.3958\n","Epoch 11, Train Loss: 1.6220, Val Loss: 1.7342, F1 Micro: 0.2917, F1 Macro: 0.2497, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.5751, Val Loss: 1.6488, F1 Micro: 0.3646, F1 Macro: 0.3392, Accuracy: 0.3646\n","Epoch 13, Train Loss: 1.5653, Val Loss: 1.7937, F1 Micro: 0.2604, F1 Macro: 0.2651, Accuracy: 0.2604\n","Epoch 14, Train Loss: 1.5810, Val Loss: 1.6468, F1 Micro: 0.3229, F1 Macro: 0.2443, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.5758, Val Loss: 1.7252, F1 Micro: 0.3542, F1 Macro: 0.3256, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5279, Val Loss: 1.7396, F1 Micro: 0.2812, F1 Macro: 0.2750, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.5405, Val Loss: 1.6509, F1 Micro: 0.3229, F1 Macro: 0.2415, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.5052, Val Loss: 1.6882, F1 Micro: 0.3438, F1 Macro: 0.3207, Accuracy: 0.3438\n","Epoch 19, Train Loss: 1.5213, Val Loss: 1.6251, F1 Micro: 0.3854, F1 Macro: 0.3207, Accuracy: 0.3854\n","Epoch 20, Train Loss: 1.4790, Val Loss: 1.5849, F1 Micro: 0.4062, F1 Macro: 0.3712, Accuracy: 0.4062\n","Epoch 21, Train Loss: 1.4915, Val Loss: 1.6278, F1 Micro: 0.3542, F1 Macro: 0.2976, Accuracy: 0.3542\n","Epoch 22, Train Loss: 1.4634, Val Loss: 1.6360, F1 Micro: 0.3750, F1 Macro: 0.3161, Accuracy: 0.3750\n","Epoch 23, Train Loss: 1.4643, Val Loss: 1.7396, F1 Micro: 0.3021, F1 Macro: 0.2886, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.4887, Val Loss: 1.6703, F1 Micro: 0.3854, F1 Macro: 0.3245, Accuracy: 0.3854\n","Epoch 25, Train Loss: 1.4386, Val Loss: 1.5939, F1 Micro: 0.4167, F1 Macro: 0.3765, Accuracy: 0.4167\n","Epoch 26, Train Loss: 1.4123, Val Loss: 1.6071, F1 Micro: 0.4062, F1 Macro: 0.3160, Accuracy: 0.4062\n","Epoch 27, Train Loss: 1.4377, Val Loss: 1.6544, F1 Micro: 0.3750, F1 Macro: 0.3152, Accuracy: 0.3750\n","Epoch 28, Train Loss: 1.4730, Val Loss: 1.6345, F1 Micro: 0.3438, F1 Macro: 0.3022, Accuracy: 0.3438\n","Epoch 29, Train Loss: 1.4055, Val Loss: 1.5343, F1 Micro: 0.4375, F1 Macro: 0.3739, Accuracy: 0.4375\n","Epoch 30, Train Loss: 1.4124, Val Loss: 1.5777, F1 Micro: 0.4167, F1 Macro: 0.3880, Accuracy: 0.4167\n","Epoch 31, Train Loss: 1.3816, Val Loss: 1.5494, F1 Micro: 0.3958, F1 Macro: 0.3366, Accuracy: 0.3958\n","Epoch 32, Train Loss: 1.4096, Val Loss: 1.5687, F1 Micro: 0.3854, F1 Macro: 0.3139, Accuracy: 0.3854\n","Epoch 33, Train Loss: 1.3900, Val Loss: 1.5248, F1 Micro: 0.4167, F1 Macro: 0.3638, Accuracy: 0.4167\n","Epoch 34, Train Loss: 1.3657, Val Loss: 1.5649, F1 Micro: 0.4896, F1 Macro: 0.4657, Accuracy: 0.4896\n","Epoch 35, Train Loss: 1.3700, Val Loss: 1.7730, F1 Micro: 0.3646, F1 Macro: 0.3242, Accuracy: 0.3646\n","Epoch 36, Train Loss: 1.3907, Val Loss: 1.5442, F1 Micro: 0.4271, F1 Macro: 0.3853, Accuracy: 0.4271\n","Epoch 37, Train Loss: 1.3267, Val Loss: 1.5854, F1 Micro: 0.4271, F1 Macro: 0.4111, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.3293, Val Loss: 1.5967, F1 Micro: 0.3958, F1 Macro: 0.3553, Accuracy: 0.3958\n","Epoch 39, Train Loss: 1.3263, Val Loss: 1.5881, F1 Micro: 0.3958, F1 Macro: 0.3804, Accuracy: 0.3958\n","Epoch 40, Train Loss: 1.3285, Val Loss: 1.5912, F1 Micro: 0.4062, F1 Macro: 0.3898, Accuracy: 0.4062\n","Epoch 41, Train Loss: 1.3030, Val Loss: 1.6819, F1 Micro: 0.3438, F1 Macro: 0.3180, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.2944, Val Loss: 1.5388, F1 Micro: 0.4479, F1 Macro: 0.4221, Accuracy: 0.4479\n","Epoch 43, Train Loss: 1.2756, Val Loss: 1.6052, F1 Micro: 0.4375, F1 Macro: 0.4053, Accuracy: 0.4375\n","Epoch 44, Train Loss: 1.3062, Val Loss: 1.6616, F1 Micro: 0.3646, F1 Macro: 0.3128, Accuracy: 0.3646\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8218, Val Loss: 1.7871, F1 Micro: 0.2083, F1 Macro: 0.1160, Accuracy: 0.2083\n","Epoch 2, Train Loss: 1.7215, Val Loss: 1.7466, F1 Micro: 0.2292, F1 Macro: 0.1844, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.6910, Val Loss: 1.7420, F1 Micro: 0.2604, F1 Macro: 0.2046, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.6740, Val Loss: 1.7234, F1 Micro: 0.2708, F1 Macro: 0.2325, Accuracy: 0.2708\n","Epoch 5, Train Loss: 1.6651, Val Loss: 1.7189, F1 Micro: 0.2292, F1 Macro: 0.2085, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.6247, Val Loss: 1.7212, F1 Micro: 0.3125, F1 Macro: 0.2494, Accuracy: 0.3125\n","Epoch 7, Train Loss: 1.6514, Val Loss: 1.6992, F1 Micro: 0.3229, F1 Macro: 0.3281, Accuracy: 0.3229\n","Epoch 8, Train Loss: 1.6014, Val Loss: 1.7090, F1 Micro: 0.2604, F1 Macro: 0.2559, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.6030, Val Loss: 1.7055, F1 Micro: 0.3438, F1 Macro: 0.2993, Accuracy: 0.3438\n","Epoch 10, Train Loss: 1.6043, Val Loss: 1.7200, F1 Micro: 0.2604, F1 Macro: 0.1940, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.5761, Val Loss: 1.6814, F1 Micro: 0.3438, F1 Macro: 0.3099, Accuracy: 0.3438\n","Epoch 12, Train Loss: 1.5872, Val Loss: 1.6717, F1 Micro: 0.2917, F1 Macro: 0.2793, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.5436, Val Loss: 1.6659, F1 Micro: 0.3125, F1 Macro: 0.2567, Accuracy: 0.3125\n","Epoch 14, Train Loss: 1.5536, Val Loss: 1.6756, F1 Micro: 0.3229, F1 Macro: 0.3152, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.5423, Val Loss: 1.6982, F1 Micro: 0.2396, F1 Macro: 0.1850, Accuracy: 0.2396\n","Epoch 16, Train Loss: 1.5552, Val Loss: 1.6470, F1 Micro: 0.3750, F1 Macro: 0.3426, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.5216, Val Loss: 1.6338, F1 Micro: 0.2917, F1 Macro: 0.2597, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.4880, Val Loss: 1.6400, F1 Micro: 0.3646, F1 Macro: 0.3418, Accuracy: 0.3646\n","Epoch 19, Train Loss: 1.5051, Val Loss: 1.6730, F1 Micro: 0.2812, F1 Macro: 0.2117, Accuracy: 0.2812\n","Epoch 20, Train Loss: 1.4713, Val Loss: 1.7063, F1 Micro: 0.3854, F1 Macro: 0.3528, Accuracy: 0.3854\n","Epoch 21, Train Loss: 1.4696, Val Loss: 1.6393, F1 Micro: 0.3125, F1 Macro: 0.2800, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.4600, Val Loss: 1.6685, F1 Micro: 0.2917, F1 Macro: 0.2447, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.4700, Val Loss: 1.5870, F1 Micro: 0.3958, F1 Macro: 0.3636, Accuracy: 0.3958\n","Epoch 24, Train Loss: 1.4392, Val Loss: 1.5981, F1 Micro: 0.3542, F1 Macro: 0.3120, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.4525, Val Loss: 1.6504, F1 Micro: 0.3958, F1 Macro: 0.3338, Accuracy: 0.3958\n","Epoch 26, Train Loss: 1.4310, Val Loss: 1.5852, F1 Micro: 0.3438, F1 Macro: 0.3357, Accuracy: 0.3438\n","Epoch 27, Train Loss: 1.4018, Val Loss: 1.6067, F1 Micro: 0.3854, F1 Macro: 0.3432, Accuracy: 0.3854\n","Epoch 28, Train Loss: 1.3849, Val Loss: 1.7024, F1 Micro: 0.3125, F1 Macro: 0.2528, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.3996, Val Loss: 1.7059, F1 Micro: 0.3229, F1 Macro: 0.2698, Accuracy: 0.3229\n","Epoch 30, Train Loss: 1.4259, Val Loss: 1.5629, F1 Micro: 0.3958, F1 Macro: 0.4010, Accuracy: 0.3958\n","Epoch 31, Train Loss: 1.3849, Val Loss: 1.6205, F1 Micro: 0.3854, F1 Macro: 0.3660, Accuracy: 0.3854\n","Epoch 32, Train Loss: 1.3703, Val Loss: 1.6178, F1 Micro: 0.3646, F1 Macro: 0.3497, Accuracy: 0.3646\n","Epoch 33, Train Loss: 1.3933, Val Loss: 1.5909, F1 Micro: 0.3646, F1 Macro: 0.3186, Accuracy: 0.3646\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.7949, Val Loss: 1.7303, F1 Micro: 0.2708, F1 Macro: 0.2227, Accuracy: 0.2708\n","Epoch 2, Train Loss: 1.7317, Val Loss: 1.6854, F1 Micro: 0.2917, F1 Macro: 0.2416, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.7116, Val Loss: 1.6874, F1 Micro: 0.3333, F1 Macro: 0.3229, Accuracy: 0.3333\n","Epoch 4, Train Loss: 1.6753, Val Loss: 1.7152, F1 Micro: 0.2500, F1 Macro: 0.2339, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.6651, Val Loss: 1.6873, F1 Micro: 0.3125, F1 Macro: 0.2505, Accuracy: 0.3125\n","Epoch 6, Train Loss: 1.6402, Val Loss: 1.6996, F1 Micro: 0.3021, F1 Macro: 0.2718, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.5919, Val Loss: 1.7043, F1 Micro: 0.2812, F1 Macro: 0.2662, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6163, Val Loss: 1.6719, F1 Micro: 0.3333, F1 Macro: 0.3076, Accuracy: 0.3333\n","Epoch 9, Train Loss: 1.5978, Val Loss: 1.6711, F1 Micro: 0.3438, F1 Macro: 0.3412, Accuracy: 0.3438\n","Epoch 10, Train Loss: 1.5525, Val Loss: 1.6794, F1 Micro: 0.3125, F1 Macro: 0.3062, Accuracy: 0.3125\n","Epoch 11, Train Loss: 1.5332, Val Loss: 1.6873, F1 Micro: 0.3542, F1 Macro: 0.3659, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.5354, Val Loss: 1.6830, F1 Micro: 0.3438, F1 Macro: 0.3273, Accuracy: 0.3438\n","Epoch 13, Train Loss: 1.5524, Val Loss: 1.7515, F1 Micro: 0.3021, F1 Macro: 0.2570, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.5306, Val Loss: 1.6993, F1 Micro: 0.3854, F1 Macro: 0.3378, Accuracy: 0.3854\n","Epoch 15, Train Loss: 1.5229, Val Loss: 1.6778, F1 Micro: 0.3854, F1 Macro: 0.3887, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.4873, Val Loss: 1.6980, F1 Micro: 0.3333, F1 Macro: 0.3312, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.4649, Val Loss: 1.6913, F1 Micro: 0.3646, F1 Macro: 0.3784, Accuracy: 0.3646\n","Epoch 18, Train Loss: 1.4348, Val Loss: 1.6984, F1 Micro: 0.3854, F1 Macro: 0.3593, Accuracy: 0.3854\n","Epoch 19, Train Loss: 1.4351, Val Loss: 1.6739, F1 Micro: 0.3542, F1 Macro: 0.3268, Accuracy: 0.3542\n","Epoch 20, Train Loss: 1.4527, Val Loss: 1.7141, F1 Micro: 0.3958, F1 Macro: 0.3652, Accuracy: 0.3958\n","Epoch 21, Train Loss: 1.4315, Val Loss: 1.7596, F1 Micro: 0.2917, F1 Macro: 0.2453, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.4100, Val Loss: 1.6662, F1 Micro: 0.3646, F1 Macro: 0.3411, Accuracy: 0.3646\n","Epoch 23, Train Loss: 1.4119, Val Loss: 1.6842, F1 Micro: 0.3438, F1 Macro: 0.3453, Accuracy: 0.3438\n","Epoch 24, Train Loss: 1.4069, Val Loss: 1.6757, F1 Micro: 0.4167, F1 Macro: 0.4270, Accuracy: 0.4167\n","Epoch 25, Train Loss: 1.3817, Val Loss: 1.6668, F1 Micro: 0.4375, F1 Macro: 0.4334, Accuracy: 0.4375\n","Epoch 26, Train Loss: 1.3804, Val Loss: 1.6928, F1 Micro: 0.3854, F1 Macro: 0.3613, Accuracy: 0.3854\n","Epoch 27, Train Loss: 1.3686, Val Loss: 1.6755, F1 Micro: 0.4062, F1 Macro: 0.4117, Accuracy: 0.4062\n","Epoch 28, Train Loss: 1.3631, Val Loss: 1.6583, F1 Micro: 0.4375, F1 Macro: 0.4187, Accuracy: 0.4375\n","Epoch 29, Train Loss: 1.3232, Val Loss: 1.7324, F1 Micro: 0.3333, F1 Macro: 0.2939, Accuracy: 0.3333\n","Epoch 30, Train Loss: 1.3822, Val Loss: 1.7851, F1 Micro: 0.3750, F1 Macro: 0.3083, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.3310, Val Loss: 1.7009, F1 Micro: 0.4062, F1 Macro: 0.3701, Accuracy: 0.4062\n","Epoch 32, Train Loss: 1.3071, Val Loss: 1.7810, F1 Micro: 0.3750, F1 Macro: 0.3786, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.3613, Val Loss: 1.6656, F1 Micro: 0.3646, F1 Macro: 0.3757, Accuracy: 0.3646\n","Epoch 34, Train Loss: 1.2819, Val Loss: 1.6749, F1 Micro: 0.3646, F1 Macro: 0.3451, Accuracy: 0.3646\n","Epoch 35, Train Loss: 1.3219, Val Loss: 1.6694, F1 Micro: 0.3958, F1 Macro: 0.4019, Accuracy: 0.3958\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.4395833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8422, Val Loss: 1.7659, F1 Micro: 0.2917, F1 Macro: 0.2138, Accuracy: 0.2917\n","Epoch 2, Train Loss: 1.7567, Val Loss: 1.7431, F1 Micro: 0.2396, F1 Macro: 0.1823, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7186, Val Loss: 1.7279, F1 Micro: 0.2708, F1 Macro: 0.2126, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.7022, Val Loss: 1.6894, F1 Micro: 0.3021, F1 Macro: 0.2621, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.6799, Val Loss: 1.6927, F1 Micro: 0.3125, F1 Macro: 0.2927, Accuracy: 0.3125\n","Epoch 6, Train Loss: 1.6568, Val Loss: 1.6940, F1 Micro: 0.3021, F1 Macro: 0.2996, Accuracy: 0.3021\n","Epoch 7, Train Loss: 1.6496, Val Loss: 1.7021, F1 Micro: 0.2812, F1 Macro: 0.2461, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6182, Val Loss: 1.7105, F1 Micro: 0.3021, F1 Macro: 0.2818, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.6066, Val Loss: 1.6637, F1 Micro: 0.3333, F1 Macro: 0.3044, Accuracy: 0.3333\n","Epoch 10, Train Loss: 1.6139, Val Loss: 1.6415, F1 Micro: 0.3750, F1 Macro: 0.3607, Accuracy: 0.3750\n","Epoch 11, Train Loss: 1.5606, Val Loss: 1.6606, F1 Micro: 0.3438, F1 Macro: 0.3540, Accuracy: 0.3438\n","Epoch 12, Train Loss: 1.5607, Val Loss: 1.6584, F1 Micro: 0.3229, F1 Macro: 0.2906, Accuracy: 0.3229\n","Epoch 13, Train Loss: 1.5517, Val Loss: 1.6857, F1 Micro: 0.3021, F1 Macro: 0.3049, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.5308, Val Loss: 1.7006, F1 Micro: 0.2500, F1 Macro: 0.2180, Accuracy: 0.2500\n","Epoch 15, Train Loss: 1.5429, Val Loss: 1.6566, F1 Micro: 0.3333, F1 Macro: 0.3101, Accuracy: 0.3333\n","Epoch 16, Train Loss: 1.5322, Val Loss: 1.7047, F1 Micro: 0.3333, F1 Macro: 0.3041, Accuracy: 0.3333\n","Epoch 17, Train Loss: 1.4915, Val Loss: 1.6802, F1 Micro: 0.3646, F1 Macro: 0.3264, Accuracy: 0.3646\n","Epoch 18, Train Loss: 1.4711, Val Loss: 1.6750, F1 Micro: 0.3333, F1 Macro: 0.3431, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.4728, Val Loss: 1.6359, F1 Micro: 0.3646, F1 Macro: 0.3263, Accuracy: 0.3646\n","Epoch 20, Train Loss: 1.4439, Val Loss: 1.6343, F1 Micro: 0.3438, F1 Macro: 0.3282, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.4553, Val Loss: 1.6683, F1 Micro: 0.3125, F1 Macro: 0.3054, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.4528, Val Loss: 1.7454, F1 Micro: 0.3229, F1 Macro: 0.2957, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.4251, Val Loss: 1.6355, F1 Micro: 0.3229, F1 Macro: 0.3190, Accuracy: 0.3229\n","Epoch 24, Train Loss: 1.3986, Val Loss: 1.6668, F1 Micro: 0.3438, F1 Macro: 0.3745, Accuracy: 0.3438\n","Epoch 25, Train Loss: 1.3770, Val Loss: 1.6382, F1 Micro: 0.3438, F1 Macro: 0.3093, Accuracy: 0.3438\n","Epoch 26, Train Loss: 1.4077, Val Loss: 1.7233, F1 Micro: 0.3646, F1 Macro: 0.3312, Accuracy: 0.3646\n","Epoch 27, Train Loss: 1.4112, Val Loss: 1.6956, F1 Micro: 0.3229, F1 Macro: 0.2612, Accuracy: 0.3229\n","Epoch 28, Train Loss: 1.3822, Val Loss: 1.6230, F1 Micro: 0.3646, F1 Macro: 0.3299, Accuracy: 0.3646\n","Epoch 29, Train Loss: 1.3731, Val Loss: 1.6731, F1 Micro: 0.3958, F1 Macro: 0.3648, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.3543, Val Loss: 1.8757, F1 Micro: 0.3125, F1 Macro: 0.2878, Accuracy: 0.3125\n","Epoch 31, Train Loss: 1.3435, Val Loss: 1.6175, F1 Micro: 0.4167, F1 Macro: 0.3543, Accuracy: 0.4167\n","Epoch 32, Train Loss: 1.3775, Val Loss: 1.7265, F1 Micro: 0.3542, F1 Macro: 0.3858, Accuracy: 0.3542\n","Epoch 33, Train Loss: 1.3468, Val Loss: 1.5766, F1 Micro: 0.4167, F1 Macro: 0.4115, Accuracy: 0.4167\n","Epoch 34, Train Loss: 1.3073, Val Loss: 1.6222, F1 Micro: 0.3646, F1 Macro: 0.3517, Accuracy: 0.3646\n","Epoch 35, Train Loss: 1.3571, Val Loss: 1.6704, F1 Micro: 0.3542, F1 Macro: 0.3755, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.3407, Val Loss: 1.8556, F1 Micro: 0.3646, F1 Macro: 0.3608, Accuracy: 0.3646\n","Epoch 37, Train Loss: 1.3161, Val Loss: 1.6176, F1 Micro: 0.4375, F1 Macro: 0.3970, Accuracy: 0.4375\n","Epoch 38, Train Loss: 1.2747, Val Loss: 1.6171, F1 Micro: 0.3750, F1 Macro: 0.3699, Accuracy: 0.3750\n","Epoch 39, Train Loss: 1.2627, Val Loss: 1.7972, F1 Micro: 0.3646, F1 Macro: 0.3466, Accuracy: 0.3646\n","Epoch 40, Train Loss: 1.2931, Val Loss: 1.6979, F1 Micro: 0.3958, F1 Macro: 0.3680, Accuracy: 0.3958\n","Epoch 41, Train Loss: 1.2581, Val Loss: 1.5911, F1 Micro: 0.3750, F1 Macro: 0.3556, Accuracy: 0.3750\n","Epoch 42, Train Loss: 1.2389, Val Loss: 1.6007, F1 Micro: 0.4479, F1 Macro: 0.4161, Accuracy: 0.4479\n","Epoch 43, Train Loss: 1.2456, Val Loss: 2.1184, F1 Micro: 0.2396, F1 Macro: 0.1857, Accuracy: 0.2396\n","Epoch 44, Train Loss: 1.2683, Val Loss: 1.6985, F1 Micro: 0.3438, F1 Macro: 0.2970, Accuracy: 0.3438\n","Epoch 45, Train Loss: 1.2387, Val Loss: 2.0132, F1 Micro: 0.2812, F1 Macro: 0.2275, Accuracy: 0.2812\n","Epoch 46, Train Loss: 1.2298, Val Loss: 1.6725, F1 Micro: 0.3438, F1 Macro: 0.2671, Accuracy: 0.3438\n","Epoch 47, Train Loss: 1.2492, Val Loss: 1.6335, F1 Micro: 0.4375, F1 Macro: 0.4220, Accuracy: 0.4375\n","Epoch 48, Train Loss: 1.2270, Val Loss: 1.6335, F1 Micro: 0.3958, F1 Macro: 0.3862, Accuracy: 0.3958\n","Epoch 49, Train Loss: 1.2130, Val Loss: 1.7742, F1 Micro: 0.4271, F1 Macro: 0.3815, Accuracy: 0.4271\n","Epoch 50, Train Loss: 1.1707, Val Loss: 1.6764, F1 Micro: 0.4062, F1 Macro: 0.3969, Accuracy: 0.4062\n","Epoch 51, Train Loss: 1.1879, Val Loss: 1.7040, F1 Micro: 0.4062, F1 Macro: 0.4065, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.1941, Val Loss: 1.7054, F1 Micro: 0.3958, F1 Macro: 0.4045, Accuracy: 0.3958\n","Epoch 53, Train Loss: 1.1608, Val Loss: 2.3939, F1 Micro: 0.2396, F1 Macro: 0.2137, Accuracy: 0.2396\n","Epoch 54, Train Loss: 1.1738, Val Loss: 1.8909, F1 Micro: 0.3542, F1 Macro: 0.3511, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.1481, Val Loss: 1.7890, F1 Micro: 0.3646, F1 Macro: 0.3152, Accuracy: 0.3646\n","Epoch 56, Train Loss: 1.1971, Val Loss: 1.7819, F1 Micro: 0.3646, F1 Macro: 0.3427, Accuracy: 0.3646\n","Epoch 57, Train Loss: 1.1354, Val Loss: 1.9063, F1 Micro: 0.3438, F1 Macro: 0.3396, Accuracy: 0.3438\n","Epoch 58, Train Loss: 1.1393, Val Loss: 1.6490, F1 Micro: 0.4167, F1 Macro: 0.3973, Accuracy: 0.4167\n","Epoch 59, Train Loss: 1.1309, Val Loss: 1.5814, F1 Micro: 0.4479, F1 Macro: 0.4598, Accuracy: 0.4479\n","Epoch 60, Train Loss: 1.1501, Val Loss: 1.9167, F1 Micro: 0.4375, F1 Macro: 0.4071, Accuracy: 0.4375\n","Epoch 61, Train Loss: 1.1598, Val Loss: 1.6444, F1 Micro: 0.4375, F1 Macro: 0.4184, Accuracy: 0.4375\n","Epoch 62, Train Loss: 1.1245, Val Loss: 1.5482, F1 Micro: 0.4688, F1 Macro: 0.4671, Accuracy: 0.4688\n","Epoch 63, Train Loss: 1.1248, Val Loss: 1.9973, F1 Micro: 0.3750, F1 Macro: 0.2912, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.1125, Val Loss: 1.8163, F1 Micro: 0.4271, F1 Macro: 0.3834, Accuracy: 0.4271\n","Epoch 65, Train Loss: 1.0922, Val Loss: 1.8326, F1 Micro: 0.3958, F1 Macro: 0.3716, Accuracy: 0.3958\n","Epoch 66, Train Loss: 1.1446, Val Loss: 1.8685, F1 Micro: 0.4167, F1 Macro: 0.3830, Accuracy: 0.4167\n","Epoch 67, Train Loss: 1.1093, Val Loss: 1.8450, F1 Micro: 0.4271, F1 Macro: 0.3855, Accuracy: 0.4271\n","Epoch 68, Train Loss: 1.0903, Val Loss: 1.8009, F1 Micro: 0.4167, F1 Macro: 0.3694, Accuracy: 0.4167\n","Epoch 69, Train Loss: 1.0824, Val Loss: 1.7017, F1 Micro: 0.3958, F1 Macro: 0.4177, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.0999, Val Loss: 1.5972, F1 Micro: 0.4792, F1 Macro: 0.4378, Accuracy: 0.4792\n","Epoch 71, Train Loss: 1.0855, Val Loss: 2.2243, F1 Micro: 0.2812, F1 Macro: 0.2401, Accuracy: 0.2812\n","Epoch 72, Train Loss: 1.0891, Val Loss: 1.8160, F1 Micro: 0.4271, F1 Macro: 0.3892, Accuracy: 0.4271\n","Epoch 73, Train Loss: 1.0574, Val Loss: 1.6814, F1 Micro: 0.4583, F1 Macro: 0.4069, Accuracy: 0.4583\n","Epoch 74, Train Loss: 1.1029, Val Loss: 2.8379, F1 Micro: 0.2708, F1 Macro: 0.2259, Accuracy: 0.2708\n","Epoch 75, Train Loss: 1.0764, Val Loss: 1.6014, F1 Micro: 0.4583, F1 Macro: 0.4456, Accuracy: 0.4583\n","Epoch 76, Train Loss: 1.0534, Val Loss: 1.6573, F1 Micro: 0.4688, F1 Macro: 0.4902, Accuracy: 0.4688\n","Epoch 77, Train Loss: 1.0760, Val Loss: 1.6991, F1 Micro: 0.4167, F1 Macro: 0.3845, Accuracy: 0.4167\n","Epoch 78, Train Loss: 1.0324, Val Loss: 1.7625, F1 Micro: 0.4271, F1 Macro: 0.4075, Accuracy: 0.4271\n","Epoch 79, Train Loss: 1.0515, Val Loss: 1.6420, F1 Micro: 0.3958, F1 Macro: 0.3985, Accuracy: 0.3958\n","Epoch 80, Train Loss: 1.0213, Val Loss: 2.0480, F1 Micro: 0.3646, F1 Macro: 0.3581, Accuracy: 0.3646\n","Epoch 81, Train Loss: 1.0803, Val Loss: 1.6585, F1 Micro: 0.5208, F1 Macro: 0.4954, Accuracy: 0.5208\n","Epoch 82, Train Loss: 1.0112, Val Loss: 1.9117, F1 Micro: 0.3333, F1 Macro: 0.3301, Accuracy: 0.3333\n","Epoch 83, Train Loss: 1.1081, Val Loss: 1.8848, F1 Micro: 0.3333, F1 Macro: 0.3226, Accuracy: 0.3333\n","Epoch 84, Train Loss: 1.0354, Val Loss: 2.0276, F1 Micro: 0.3542, F1 Macro: 0.3311, Accuracy: 0.3542\n","Epoch 85, Train Loss: 1.0698, Val Loss: 1.6793, F1 Micro: 0.3958, F1 Macro: 0.4113, Accuracy: 0.3958\n","Epoch 86, Train Loss: 1.0596, Val Loss: 2.6569, F1 Micro: 0.2604, F1 Macro: 0.2143, Accuracy: 0.2604\n","Epoch 87, Train Loss: 1.0674, Val Loss: 1.7610, F1 Micro: 0.4792, F1 Macro: 0.4689, Accuracy: 0.4792\n","Epoch 88, Train Loss: 1.0480, Val Loss: 2.2012, F1 Micro: 0.3750, F1 Macro: 0.3636, Accuracy: 0.3750\n","Epoch 89, Train Loss: 1.0397, Val Loss: 1.9738, F1 Micro: 0.4792, F1 Macro: 0.4551, Accuracy: 0.4792\n","Epoch 90, Train Loss: 1.0679, Val Loss: 1.6180, F1 Micro: 0.4896, F1 Macro: 0.4747, Accuracy: 0.4896\n","Epoch 91, Train Loss: 1.0352, Val Loss: 1.9553, F1 Micro: 0.4062, F1 Macro: 0.3815, Accuracy: 0.4062\n","Epoch 92, Train Loss: 0.9807, Val Loss: 1.9409, F1 Micro: 0.4167, F1 Macro: 0.4029, Accuracy: 0.4167\n","Epoch 93, Train Loss: 0.9821, Val Loss: 1.6840, F1 Micro: 0.4688, F1 Macro: 0.4391, Accuracy: 0.4688\n","Epoch 94, Train Loss: 1.0435, Val Loss: 1.7963, F1 Micro: 0.3750, F1 Macro: 0.3579, Accuracy: 0.3750\n","Epoch 95, Train Loss: 0.9575, Val Loss: 1.9428, F1 Micro: 0.3750, F1 Macro: 0.3588, Accuracy: 0.3750\n","Epoch 96, Train Loss: 0.9338, Val Loss: 2.1268, F1 Micro: 0.4062, F1 Macro: 0.3300, Accuracy: 0.4062\n","Epoch 97, Train Loss: 0.9605, Val Loss: 1.4971, F1 Micro: 0.5417, F1 Macro: 0.5319, Accuracy: 0.5417\n","Epoch 98, Train Loss: 0.9798, Val Loss: 2.1577, F1 Micro: 0.4375, F1 Macro: 0.4081, Accuracy: 0.4375\n","Epoch 99, Train Loss: 0.9649, Val Loss: 1.6069, F1 Micro: 0.5521, F1 Macro: 0.5542, Accuracy: 0.5521\n","Epoch 100, Train Loss: 0.9556, Val Loss: 1.6408, F1 Micro: 0.4688, F1 Macro: 0.4602, Accuracy: 0.4688\n","Epoch 101, Train Loss: 0.9188, Val Loss: 2.0973, F1 Micro: 0.3750, F1 Macro: 0.3018, Accuracy: 0.3750\n","Epoch 102, Train Loss: 0.9448, Val Loss: 1.7265, F1 Micro: 0.4479, F1 Macro: 0.4452, Accuracy: 0.4479\n","Epoch 103, Train Loss: 0.9742, Val Loss: 2.2273, F1 Micro: 0.4167, F1 Macro: 0.3597, Accuracy: 0.4167\n","Epoch 104, Train Loss: 0.9588, Val Loss: 1.8773, F1 Micro: 0.3750, F1 Macro: 0.3382, Accuracy: 0.3750\n","Epoch 105, Train Loss: 0.9470, Val Loss: 2.1855, F1 Micro: 0.4062, F1 Macro: 0.4143, Accuracy: 0.4062\n","Epoch 106, Train Loss: 0.9135, Val Loss: 1.5625, F1 Micro: 0.5000, F1 Macro: 0.4765, Accuracy: 0.5000\n","Epoch 107, Train Loss: 0.9512, Val Loss: 1.6014, F1 Micro: 0.4896, F1 Macro: 0.4747, Accuracy: 0.4896\n","Epoch 108, Train Loss: 0.9719, Val Loss: 1.6997, F1 Micro: 0.4792, F1 Macro: 0.4540, Accuracy: 0.4792\n","Epoch 109, Train Loss: 0.9576, Val Loss: 2.0950, F1 Micro: 0.3021, F1 Macro: 0.2723, Accuracy: 0.3021\n","Epoch 110, Train Loss: 0.9508, Val Loss: 1.8610, F1 Micro: 0.4271, F1 Macro: 0.3539, Accuracy: 0.4271\n","Epoch 111, Train Loss: 0.9396, Val Loss: 1.6079, F1 Micro: 0.4688, F1 Macro: 0.4800, Accuracy: 0.4688\n","Epoch 112, Train Loss: 0.9118, Val Loss: 1.7739, F1 Micro: 0.4479, F1 Macro: 0.4657, Accuracy: 0.4479\n","Epoch 113, Train Loss: 0.9165, Val Loss: 1.7895, F1 Micro: 0.4792, F1 Macro: 0.4488, Accuracy: 0.4792\n","Epoch 114, Train Loss: 0.9336, Val Loss: 2.4116, F1 Micro: 0.3438, F1 Macro: 0.3378, Accuracy: 0.3438\n","Epoch 115, Train Loss: 0.9468, Val Loss: 1.8753, F1 Micro: 0.3854, F1 Macro: 0.4004, Accuracy: 0.3854\n","Epoch 116, Train Loss: 0.9063, Val Loss: 1.7890, F1 Micro: 0.5000, F1 Macro: 0.4614, Accuracy: 0.5000\n","Epoch 117, Train Loss: 0.8609, Val Loss: 1.6088, F1 Micro: 0.5312, F1 Macro: 0.5071, Accuracy: 0.5312\n","Epoch 118, Train Loss: 0.8976, Val Loss: 2.8295, F1 Micro: 0.2500, F1 Macro: 0.2234, Accuracy: 0.2500\n","Epoch 119, Train Loss: 0.9179, Val Loss: 1.7171, F1 Micro: 0.4896, F1 Macro: 0.4905, Accuracy: 0.4896\n","Epoch 120, Train Loss: 0.8770, Val Loss: 1.6959, F1 Micro: 0.4896, F1 Macro: 0.4965, Accuracy: 0.4896\n","Epoch 121, Train Loss: 0.8801, Val Loss: 1.5556, F1 Micro: 0.5000, F1 Macro: 0.5079, Accuracy: 0.5000\n","Epoch 122, Train Loss: 0.8646, Val Loss: 1.6983, F1 Micro: 0.4479, F1 Macro: 0.4825, Accuracy: 0.4479\n","Epoch 123, Train Loss: 0.8649, Val Loss: 1.4915, F1 Micro: 0.5312, F1 Macro: 0.5218, Accuracy: 0.5312\n","Epoch 124, Train Loss: 0.8656, Val Loss: 2.3310, F1 Micro: 0.3750, F1 Macro: 0.3575, Accuracy: 0.3750\n","Epoch 125, Train Loss: 0.9134, Val Loss: 1.9661, F1 Micro: 0.3750, F1 Macro: 0.3570, Accuracy: 0.3750\n","Epoch 126, Train Loss: 0.8438, Val Loss: 1.8379, F1 Micro: 0.4062, F1 Macro: 0.4168, Accuracy: 0.4062\n","Epoch 127, Train Loss: 0.8832, Val Loss: 1.9468, F1 Micro: 0.4688, F1 Macro: 0.4359, Accuracy: 0.4688\n","Epoch 128, Train Loss: 0.8943, Val Loss: 2.0770, F1 Micro: 0.3854, F1 Macro: 0.4214, Accuracy: 0.3854\n","Epoch 129, Train Loss: 0.9111, Val Loss: 2.3606, F1 Micro: 0.3438, F1 Macro: 0.2988, Accuracy: 0.3438\n","Epoch 130, Train Loss: 0.8875, Val Loss: 1.8757, F1 Micro: 0.4688, F1 Macro: 0.4085, Accuracy: 0.4688\n","Epoch 131, Train Loss: 0.8354, Val Loss: 2.1548, F1 Micro: 0.3542, F1 Macro: 0.3372, Accuracy: 0.3542\n","Epoch 132, Train Loss: 0.8471, Val Loss: 1.8404, F1 Micro: 0.4896, F1 Macro: 0.4360, Accuracy: 0.4896\n","Epoch 133, Train Loss: 0.8505, Val Loss: 1.9648, F1 Micro: 0.4479, F1 Macro: 0.4625, Accuracy: 0.4479\n","Epoch 134, Train Loss: 0.8150, Val Loss: 1.7348, F1 Micro: 0.4479, F1 Macro: 0.4182, Accuracy: 0.4479\n","Epoch 135, Train Loss: 0.8817, Val Loss: 2.6702, F1 Micro: 0.3021, F1 Macro: 0.2725, Accuracy: 0.3021\n","Epoch 136, Train Loss: 0.8736, Val Loss: 2.3100, F1 Micro: 0.3646, F1 Macro: 0.3542, Accuracy: 0.3646\n","Epoch 137, Train Loss: 0.8437, Val Loss: 1.9441, F1 Micro: 0.4167, F1 Macro: 0.4003, Accuracy: 0.4167\n","Epoch 138, Train Loss: 0.8765, Val Loss: 1.6006, F1 Micro: 0.5208, F1 Macro: 0.4736, Accuracy: 0.5208\n","Epoch 139, Train Loss: 0.8270, Val Loss: 2.0497, F1 Micro: 0.4375, F1 Macro: 0.4647, Accuracy: 0.4375\n","Epoch 140, Train Loss: 0.8492, Val Loss: 1.6684, F1 Micro: 0.5417, F1 Macro: 0.5457, Accuracy: 0.5417\n","Epoch 141, Train Loss: 0.8742, Val Loss: 1.8104, F1 Micro: 0.4479, F1 Macro: 0.4187, Accuracy: 0.4479\n","Epoch 142, Train Loss: 0.8651, Val Loss: 2.3412, F1 Micro: 0.4375, F1 Macro: 0.4033, Accuracy: 0.4375\n","Epoch 143, Train Loss: 0.8972, Val Loss: 2.3407, F1 Micro: 0.4375, F1 Macro: 0.4447, Accuracy: 0.4375\n","Epoch 144, Train Loss: 0.8708, Val Loss: 1.8743, F1 Micro: 0.4375, F1 Macro: 0.4236, Accuracy: 0.4375\n","Epoch 145, Train Loss: 0.8491, Val Loss: 1.7099, F1 Micro: 0.4792, F1 Macro: 0.4592, Accuracy: 0.4792\n","Epoch 146, Train Loss: 0.8116, Val Loss: 2.2573, F1 Micro: 0.4792, F1 Macro: 0.4439, Accuracy: 0.4792\n","Epoch 147, Train Loss: 0.8077, Val Loss: 1.6805, F1 Micro: 0.5208, F1 Macro: 0.5121, Accuracy: 0.5208\n","Epoch 148, Train Loss: 0.8084, Val Loss: 1.6634, F1 Micro: 0.5000, F1 Macro: 0.4420, Accuracy: 0.5000\n","Epoch 149, Train Loss: 0.8410, Val Loss: 1.9342, F1 Micro: 0.4375, F1 Macro: 0.3937, Accuracy: 0.4375\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7894, Val Loss: 1.7943, F1 Micro: 0.1042, F1 Macro: 0.0584, Accuracy: 0.1042\n","Epoch 2, Train Loss: 1.7358, Val Loss: 1.7179, F1 Micro: 0.2917, F1 Macro: 0.2056, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.6970, Val Loss: 1.7068, F1 Micro: 0.2708, F1 Macro: 0.2120, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.7009, Val Loss: 1.6458, F1 Micro: 0.3542, F1 Macro: 0.3277, Accuracy: 0.3542\n","Epoch 5, Train Loss: 1.6756, Val Loss: 1.6651, F1 Micro: 0.4062, F1 Macro: 0.4183, Accuracy: 0.4062\n","Epoch 6, Train Loss: 1.6676, Val Loss: 1.6583, F1 Micro: 0.3854, F1 Macro: 0.3361, Accuracy: 0.3854\n","Epoch 7, Train Loss: 1.6552, Val Loss: 1.6743, F1 Micro: 0.2708, F1 Macro: 0.2501, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.6275, Val Loss: 1.6541, F1 Micro: 0.3125, F1 Macro: 0.2831, Accuracy: 0.3125\n","Epoch 9, Train Loss: 1.6310, Val Loss: 1.6271, F1 Micro: 0.3854, F1 Macro: 0.3768, Accuracy: 0.3854\n","Epoch 10, Train Loss: 1.6290, Val Loss: 1.6438, F1 Micro: 0.3646, F1 Macro: 0.3420, Accuracy: 0.3646\n","Epoch 11, Train Loss: 1.6168, Val Loss: 1.6128, F1 Micro: 0.3646, F1 Macro: 0.2723, Accuracy: 0.3646\n","Epoch 12, Train Loss: 1.6389, Val Loss: 1.6218, F1 Micro: 0.3542, F1 Macro: 0.3105, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.5727, Val Loss: 1.5568, F1 Micro: 0.3438, F1 Macro: 0.3196, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.5668, Val Loss: 1.6066, F1 Micro: 0.3542, F1 Macro: 0.2936, Accuracy: 0.3542\n","Epoch 15, Train Loss: 1.5773, Val Loss: 1.6658, F1 Micro: 0.2917, F1 Macro: 0.2622, Accuracy: 0.2917\n","Epoch 16, Train Loss: 1.5634, Val Loss: 1.5504, F1 Micro: 0.3750, F1 Macro: 0.3363, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.5383, Val Loss: 1.5229, F1 Micro: 0.4583, F1 Macro: 0.4508, Accuracy: 0.4583\n","Epoch 18, Train Loss: 1.5548, Val Loss: 1.6011, F1 Micro: 0.3438, F1 Macro: 0.2935, Accuracy: 0.3438\n","Epoch 19, Train Loss: 1.5139, Val Loss: 1.4952, F1 Micro: 0.4479, F1 Macro: 0.3517, Accuracy: 0.4479\n","Epoch 20, Train Loss: 1.5139, Val Loss: 1.5201, F1 Micro: 0.4271, F1 Macro: 0.4331, Accuracy: 0.4271\n","Epoch 21, Train Loss: 1.5434, Val Loss: 1.5242, F1 Micro: 0.4479, F1 Macro: 0.4066, Accuracy: 0.4479\n","Epoch 22, Train Loss: 1.4984, Val Loss: 1.5390, F1 Micro: 0.3958, F1 Macro: 0.3480, Accuracy: 0.3958\n","Epoch 23, Train Loss: 1.4527, Val Loss: 1.5902, F1 Micro: 0.3958, F1 Macro: 0.3493, Accuracy: 0.3958\n","Epoch 24, Train Loss: 1.4824, Val Loss: 1.5274, F1 Micro: 0.4375, F1 Macro: 0.3946, Accuracy: 0.4375\n","Epoch 25, Train Loss: 1.4815, Val Loss: 1.5136, F1 Micro: 0.3750, F1 Macro: 0.3701, Accuracy: 0.3750\n","Epoch 26, Train Loss: 1.4395, Val Loss: 1.4857, F1 Micro: 0.5000, F1 Macro: 0.4873, Accuracy: 0.5000\n","Epoch 27, Train Loss: 1.4145, Val Loss: 1.5559, F1 Micro: 0.4688, F1 Macro: 0.4218, Accuracy: 0.4688\n","Epoch 28, Train Loss: 1.4254, Val Loss: 1.6816, F1 Micro: 0.3750, F1 Macro: 0.3232, Accuracy: 0.3750\n","Epoch 29, Train Loss: 1.4166, Val Loss: 1.5301, F1 Micro: 0.4271, F1 Macro: 0.3656, Accuracy: 0.4271\n","Epoch 30, Train Loss: 1.4060, Val Loss: 1.5380, F1 Micro: 0.4167, F1 Macro: 0.3964, Accuracy: 0.4167\n","Epoch 31, Train Loss: 1.3898, Val Loss: 1.7103, F1 Micro: 0.3021, F1 Macro: 0.2623, Accuracy: 0.3021\n","Epoch 32, Train Loss: 1.3941, Val Loss: 1.4291, F1 Micro: 0.4792, F1 Macro: 0.4707, Accuracy: 0.4792\n","Epoch 33, Train Loss: 1.3768, Val Loss: 1.5296, F1 Micro: 0.3750, F1 Macro: 0.3308, Accuracy: 0.3750\n","Epoch 34, Train Loss: 1.3763, Val Loss: 1.5454, F1 Micro: 0.3750, F1 Macro: 0.3245, Accuracy: 0.3750\n","Epoch 35, Train Loss: 1.3915, Val Loss: 1.6101, F1 Micro: 0.3750, F1 Macro: 0.3662, Accuracy: 0.3750\n","Epoch 36, Train Loss: 1.3342, Val Loss: 1.4888, F1 Micro: 0.4375, F1 Macro: 0.3967, Accuracy: 0.4375\n","Epoch 37, Train Loss: 1.3782, Val Loss: 1.5427, F1 Micro: 0.3958, F1 Macro: 0.3562, Accuracy: 0.3958\n","Epoch 38, Train Loss: 1.3196, Val Loss: 1.4819, F1 Micro: 0.4583, F1 Macro: 0.3740, Accuracy: 0.4583\n","Epoch 39, Train Loss: 1.3223, Val Loss: 1.4330, F1 Micro: 0.5312, F1 Macro: 0.4964, Accuracy: 0.5312\n","Epoch 40, Train Loss: 1.3000, Val Loss: 1.6172, F1 Micro: 0.3958, F1 Macro: 0.3535, Accuracy: 0.3958\n","Epoch 41, Train Loss: 1.2977, Val Loss: 1.6827, F1 Micro: 0.3854, F1 Macro: 0.3401, Accuracy: 0.3854\n","Epoch 42, Train Loss: 1.3187, Val Loss: 1.5464, F1 Micro: 0.4062, F1 Macro: 0.3792, Accuracy: 0.4062\n","Epoch 43, Train Loss: 1.2948, Val Loss: 1.5479, F1 Micro: 0.3958, F1 Macro: 0.3555, Accuracy: 0.3958\n","Epoch 44, Train Loss: 1.3010, Val Loss: 1.6724, F1 Micro: 0.3646, F1 Macro: 0.3333, Accuracy: 0.3646\n","Epoch 45, Train Loss: 1.2762, Val Loss: 1.4997, F1 Micro: 0.4792, F1 Macro: 0.4202, Accuracy: 0.4792\n","Epoch 46, Train Loss: 1.2625, Val Loss: 1.8741, F1 Micro: 0.3021, F1 Macro: 0.2702, Accuracy: 0.3021\n","Epoch 47, Train Loss: 1.2995, Val Loss: 1.4834, F1 Micro: 0.5104, F1 Macro: 0.4845, Accuracy: 0.5104\n","Epoch 48, Train Loss: 1.2586, Val Loss: 1.6770, F1 Micro: 0.3646, F1 Macro: 0.3599, Accuracy: 0.3646\n","Epoch 49, Train Loss: 1.2793, Val Loss: 1.5186, F1 Micro: 0.4792, F1 Macro: 0.4444, Accuracy: 0.4792\n","Epoch 50, Train Loss: 1.2415, Val Loss: 1.6155, F1 Micro: 0.3229, F1 Macro: 0.2893, Accuracy: 0.3229\n","Epoch 51, Train Loss: 1.2445, Val Loss: 1.5427, F1 Micro: 0.4062, F1 Macro: 0.4190, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.2335, Val Loss: 1.5415, F1 Micro: 0.4062, F1 Macro: 0.3500, Accuracy: 0.4062\n","Epoch 53, Train Loss: 1.2464, Val Loss: 1.4157, F1 Micro: 0.4896, F1 Macro: 0.4278, Accuracy: 0.4896\n","Epoch 54, Train Loss: 1.2090, Val Loss: 1.5031, F1 Micro: 0.3958, F1 Macro: 0.4005, Accuracy: 0.3958\n","Epoch 55, Train Loss: 1.2328, Val Loss: 1.5240, F1 Micro: 0.4375, F1 Macro: 0.4270, Accuracy: 0.4375\n","Epoch 56, Train Loss: 1.2166, Val Loss: 1.4828, F1 Micro: 0.4479, F1 Macro: 0.3696, Accuracy: 0.4479\n","Epoch 57, Train Loss: 1.2099, Val Loss: 1.5501, F1 Micro: 0.4479, F1 Macro: 0.3851, Accuracy: 0.4479\n","Epoch 58, Train Loss: 1.2205, Val Loss: 1.5236, F1 Micro: 0.4479, F1 Macro: 0.3891, Accuracy: 0.4479\n","Epoch 59, Train Loss: 1.1910, Val Loss: 1.4680, F1 Micro: 0.4792, F1 Macro: 0.4439, Accuracy: 0.4792\n","Epoch 60, Train Loss: 1.2125, Val Loss: 1.4618, F1 Micro: 0.4792, F1 Macro: 0.4399, Accuracy: 0.4792\n","Epoch 61, Train Loss: 1.1760, Val Loss: 1.6632, F1 Micro: 0.4271, F1 Macro: 0.3576, Accuracy: 0.4271\n","Epoch 62, Train Loss: 1.1688, Val Loss: 1.5315, F1 Micro: 0.4583, F1 Macro: 0.3988, Accuracy: 0.4583\n","Epoch 63, Train Loss: 1.1445, Val Loss: 1.6495, F1 Micro: 0.3750, F1 Macro: 0.3285, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.1889, Val Loss: 1.4349, F1 Micro: 0.4479, F1 Macro: 0.4204, Accuracy: 0.4479\n","Epoch 65, Train Loss: 1.1369, Val Loss: 1.5131, F1 Micro: 0.4688, F1 Macro: 0.4458, Accuracy: 0.4688\n","Epoch 66, Train Loss: 1.1193, Val Loss: 1.6375, F1 Micro: 0.4062, F1 Macro: 0.3246, Accuracy: 0.4062\n","Epoch 67, Train Loss: 1.1603, Val Loss: 1.5727, F1 Micro: 0.4062, F1 Macro: 0.3671, Accuracy: 0.4062\n","Epoch 68, Train Loss: 1.0990, Val Loss: 1.4278, F1 Micro: 0.5000, F1 Macro: 0.4515, Accuracy: 0.5000\n","Epoch 69, Train Loss: 1.1151, Val Loss: 1.6003, F1 Micro: 0.3750, F1 Macro: 0.3900, Accuracy: 0.3750\n","Epoch 70, Train Loss: 1.1460, Val Loss: 1.4851, F1 Micro: 0.4583, F1 Macro: 0.4005, Accuracy: 0.4583\n","Epoch 71, Train Loss: 1.0956, Val Loss: 1.5979, F1 Micro: 0.5000, F1 Macro: 0.4435, Accuracy: 0.5000\n","Epoch 72, Train Loss: 1.1224, Val Loss: 2.5277, F1 Micro: 0.2604, F1 Macro: 0.2261, Accuracy: 0.2604\n","Epoch 73, Train Loss: 1.1297, Val Loss: 1.5166, F1 Micro: 0.4375, F1 Macro: 0.4149, Accuracy: 0.4375\n","Epoch 74, Train Loss: 1.1120, Val Loss: 1.4040, F1 Micro: 0.5208, F1 Macro: 0.5075, Accuracy: 0.5208\n","Epoch 75, Train Loss: 1.1121, Val Loss: 1.4617, F1 Micro: 0.4688, F1 Macro: 0.4222, Accuracy: 0.4688\n","Epoch 76, Train Loss: 1.1227, Val Loss: 1.6237, F1 Micro: 0.4271, F1 Macro: 0.4119, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.1008, Val Loss: 1.7030, F1 Micro: 0.4062, F1 Macro: 0.3279, Accuracy: 0.4062\n","Epoch 78, Train Loss: 1.0986, Val Loss: 1.4533, F1 Micro: 0.4792, F1 Macro: 0.4852, Accuracy: 0.4792\n","Epoch 79, Train Loss: 1.1318, Val Loss: 1.4597, F1 Micro: 0.5000, F1 Macro: 0.4707, Accuracy: 0.5000\n","Epoch 80, Train Loss: 1.0927, Val Loss: 1.6276, F1 Micro: 0.4167, F1 Macro: 0.3831, Accuracy: 0.4167\n","Epoch 81, Train Loss: 1.0572, Val Loss: 1.3544, F1 Micro: 0.5521, F1 Macro: 0.5341, Accuracy: 0.5521\n","Epoch 82, Train Loss: 1.0669, Val Loss: 1.7527, F1 Micro: 0.4167, F1 Macro: 0.4008, Accuracy: 0.4167\n","Epoch 83, Train Loss: 1.1188, Val Loss: 1.4662, F1 Micro: 0.4896, F1 Macro: 0.4387, Accuracy: 0.4896\n","Epoch 84, Train Loss: 1.0597, Val Loss: 2.1879, F1 Micro: 0.2708, F1 Macro: 0.2052, Accuracy: 0.2708\n","Epoch 85, Train Loss: 1.0468, Val Loss: 1.3488, F1 Micro: 0.5312, F1 Macro: 0.5369, Accuracy: 0.5312\n","Epoch 86, Train Loss: 1.0299, Val Loss: 1.7457, F1 Micro: 0.3854, F1 Macro: 0.2957, Accuracy: 0.3854\n","Epoch 87, Train Loss: 1.0746, Val Loss: 1.4456, F1 Micro: 0.4896, F1 Macro: 0.4528, Accuracy: 0.4896\n","Epoch 88, Train Loss: 1.0186, Val Loss: 1.9049, F1 Micro: 0.3229, F1 Macro: 0.3046, Accuracy: 0.3229\n","Epoch 89, Train Loss: 1.0545, Val Loss: 1.5360, F1 Micro: 0.4062, F1 Macro: 0.3737, Accuracy: 0.4062\n","Epoch 90, Train Loss: 1.0781, Val Loss: 1.7357, F1 Micro: 0.4271, F1 Macro: 0.3913, Accuracy: 0.4271\n","Epoch 91, Train Loss: 1.0054, Val Loss: 1.3400, F1 Micro: 0.5938, F1 Macro: 0.5807, Accuracy: 0.5938\n","Epoch 92, Train Loss: 1.0159, Val Loss: 1.4179, F1 Micro: 0.4688, F1 Macro: 0.4406, Accuracy: 0.4688\n","Epoch 93, Train Loss: 1.0074, Val Loss: 1.4388, F1 Micro: 0.4896, F1 Macro: 0.4427, Accuracy: 0.4896\n","Epoch 94, Train Loss: 1.0110, Val Loss: 1.5903, F1 Micro: 0.4688, F1 Macro: 0.4340, Accuracy: 0.4688\n","Epoch 95, Train Loss: 0.9824, Val Loss: 1.6960, F1 Micro: 0.4583, F1 Macro: 0.3694, Accuracy: 0.4583\n","Epoch 96, Train Loss: 1.0208, Val Loss: 2.0161, F1 Micro: 0.3333, F1 Macro: 0.2882, Accuracy: 0.3333\n","Epoch 97, Train Loss: 1.0446, Val Loss: 1.8261, F1 Micro: 0.3021, F1 Macro: 0.2711, Accuracy: 0.3021\n","Epoch 98, Train Loss: 1.0185, Val Loss: 1.2652, F1 Micro: 0.6250, F1 Macro: 0.6014, Accuracy: 0.6250\n","Epoch 99, Train Loss: 0.9791, Val Loss: 1.5075, F1 Micro: 0.4583, F1 Macro: 0.4535, Accuracy: 0.4583\n","Epoch 100, Train Loss: 1.0342, Val Loss: 1.6406, F1 Micro: 0.4792, F1 Macro: 0.4443, Accuracy: 0.4792\n","Epoch 101, Train Loss: 1.0156, Val Loss: 1.5741, F1 Micro: 0.4271, F1 Macro: 0.3814, Accuracy: 0.4271\n","Epoch 102, Train Loss: 1.0355, Val Loss: 1.5667, F1 Micro: 0.3958, F1 Macro: 0.4078, Accuracy: 0.3958\n","Epoch 103, Train Loss: 1.0044, Val Loss: 1.4380, F1 Micro: 0.5417, F1 Macro: 0.4847, Accuracy: 0.5417\n","Epoch 104, Train Loss: 0.9755, Val Loss: 1.5448, F1 Micro: 0.4375, F1 Macro: 0.3679, Accuracy: 0.4375\n","Epoch 105, Train Loss: 0.9376, Val Loss: 1.7272, F1 Micro: 0.4062, F1 Macro: 0.3899, Accuracy: 0.4062\n","Epoch 106, Train Loss: 0.9962, Val Loss: 1.5890, F1 Micro: 0.3854, F1 Macro: 0.3910, Accuracy: 0.3854\n","Epoch 107, Train Loss: 1.0500, Val Loss: 1.5616, F1 Micro: 0.5000, F1 Macro: 0.4423, Accuracy: 0.5000\n","Epoch 108, Train Loss: 1.0196, Val Loss: 1.8817, F1 Micro: 0.4271, F1 Macro: 0.3801, Accuracy: 0.4271\n","Epoch 109, Train Loss: 0.9597, Val Loss: 1.4002, F1 Micro: 0.5312, F1 Macro: 0.5220, Accuracy: 0.5312\n","Epoch 110, Train Loss: 0.9515, Val Loss: 1.6123, F1 Micro: 0.4375, F1 Macro: 0.3777, Accuracy: 0.4375\n","Epoch 111, Train Loss: 0.9826, Val Loss: 1.4839, F1 Micro: 0.3958, F1 Macro: 0.3607, Accuracy: 0.3958\n","Epoch 112, Train Loss: 0.9552, Val Loss: 1.9085, F1 Micro: 0.3646, F1 Macro: 0.2862, Accuracy: 0.3646\n","Epoch 113, Train Loss: 0.9849, Val Loss: 1.3877, F1 Micro: 0.5208, F1 Macro: 0.4917, Accuracy: 0.5208\n","Epoch 114, Train Loss: 0.9551, Val Loss: 1.5486, F1 Micro: 0.4271, F1 Macro: 0.4037, Accuracy: 0.4271\n","Epoch 115, Train Loss: 0.9373, Val Loss: 1.3150, F1 Micro: 0.5208, F1 Macro: 0.5132, Accuracy: 0.5208\n","Epoch 116, Train Loss: 0.9661, Val Loss: 1.5914, F1 Micro: 0.5000, F1 Macro: 0.4232, Accuracy: 0.5000\n","Epoch 117, Train Loss: 0.9315, Val Loss: 1.4566, F1 Micro: 0.4688, F1 Macro: 0.4480, Accuracy: 0.4688\n","Epoch 118, Train Loss: 0.9491, Val Loss: 1.3307, F1 Micro: 0.5208, F1 Macro: 0.4893, Accuracy: 0.5208\n","Epoch 119, Train Loss: 0.8877, Val Loss: 1.9391, F1 Micro: 0.4062, F1 Macro: 0.3676, Accuracy: 0.4062\n","Epoch 120, Train Loss: 0.9741, Val Loss: 1.6568, F1 Micro: 0.4479, F1 Macro: 0.4299, Accuracy: 0.4479\n","Epoch 121, Train Loss: 0.9408, Val Loss: 1.3639, F1 Micro: 0.5000, F1 Macro: 0.4695, Accuracy: 0.5000\n","Epoch 122, Train Loss: 0.9044, Val Loss: 2.2360, F1 Micro: 0.3021, F1 Macro: 0.2275, Accuracy: 0.3021\n","Epoch 123, Train Loss: 0.9777, Val Loss: 1.4468, F1 Micro: 0.4688, F1 Macro: 0.4625, Accuracy: 0.4688\n","Epoch 124, Train Loss: 0.9251, Val Loss: 1.2642, F1 Micro: 0.5938, F1 Macro: 0.5712, Accuracy: 0.5938\n","Epoch 125, Train Loss: 0.9630, Val Loss: 1.5954, F1 Micro: 0.4167, F1 Macro: 0.3610, Accuracy: 0.4167\n","Epoch 126, Train Loss: 0.9017, Val Loss: 1.4689, F1 Micro: 0.5000, F1 Macro: 0.4532, Accuracy: 0.5000\n","Epoch 127, Train Loss: 0.9221, Val Loss: 1.5358, F1 Micro: 0.4583, F1 Macro: 0.4408, Accuracy: 0.4583\n","Epoch 128, Train Loss: 0.9467, Val Loss: 2.3266, F1 Micro: 0.3438, F1 Macro: 0.2781, Accuracy: 0.3438\n","Epoch 129, Train Loss: 0.9192, Val Loss: 1.6713, F1 Micro: 0.4375, F1 Macro: 0.4222, Accuracy: 0.4375\n","Epoch 130, Train Loss: 0.8849, Val Loss: 1.8024, F1 Micro: 0.3333, F1 Macro: 0.2672, Accuracy: 0.3333\n","Epoch 131, Train Loss: 0.9268, Val Loss: 1.8613, F1 Micro: 0.3750, F1 Macro: 0.3256, Accuracy: 0.3750\n","Epoch 132, Train Loss: 0.9196, Val Loss: 1.4757, F1 Micro: 0.4583, F1 Macro: 0.4877, Accuracy: 0.4583\n","Epoch 133, Train Loss: 0.9493, Val Loss: 1.3535, F1 Micro: 0.5625, F1 Macro: 0.5503, Accuracy: 0.5625\n","Epoch 134, Train Loss: 0.8992, Val Loss: 1.7153, F1 Micro: 0.3854, F1 Macro: 0.3287, Accuracy: 0.3854\n","Epoch 135, Train Loss: 0.9280, Val Loss: 1.3831, F1 Micro: 0.5625, F1 Macro: 0.5301, Accuracy: 0.5625\n","Epoch 136, Train Loss: 0.8726, Val Loss: 1.8787, F1 Micro: 0.3958, F1 Macro: 0.3572, Accuracy: 0.3958\n","Epoch 137, Train Loss: 0.8945, Val Loss: 1.4337, F1 Micro: 0.5312, F1 Macro: 0.4927, Accuracy: 0.5312\n","Epoch 138, Train Loss: 0.8423, Val Loss: 1.3890, F1 Micro: 0.5417, F1 Macro: 0.5115, Accuracy: 0.5417\n","Epoch 139, Train Loss: 0.8536, Val Loss: 1.7470, F1 Micro: 0.3438, F1 Macro: 0.3431, Accuracy: 0.3438\n","Epoch 140, Train Loss: 0.9077, Val Loss: 1.5078, F1 Micro: 0.5000, F1 Macro: 0.4473, Accuracy: 0.5000\n","Epoch 141, Train Loss: 0.8930, Val Loss: 1.9134, F1 Micro: 0.3854, F1 Macro: 0.3863, Accuracy: 0.3854\n","Epoch 142, Train Loss: 0.9188, Val Loss: 1.4346, F1 Micro: 0.4375, F1 Macro: 0.4647, Accuracy: 0.4375\n","Epoch 143, Train Loss: 0.8544, Val Loss: 1.4524, F1 Micro: 0.5104, F1 Macro: 0.4577, Accuracy: 0.5104\n","Epoch 144, Train Loss: 0.8685, Val Loss: 1.4516, F1 Micro: 0.5312, F1 Macro: 0.4875, Accuracy: 0.5312\n","Epoch 145, Train Loss: 0.8907, Val Loss: 1.7658, F1 Micro: 0.4583, F1 Macro: 0.4119, Accuracy: 0.4583\n","Epoch 146, Train Loss: 0.8266, Val Loss: 1.3643, F1 Micro: 0.5729, F1 Macro: 0.5434, Accuracy: 0.5729\n","Epoch 147, Train Loss: 0.8494, Val Loss: 1.8422, F1 Micro: 0.3958, F1 Macro: 0.3373, Accuracy: 0.3958\n","Epoch 148, Train Loss: 0.8361, Val Loss: 1.3989, F1 Micro: 0.4896, F1 Macro: 0.4815, Accuracy: 0.4896\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8069, Val Loss: 1.8051, F1 Micro: 0.1771, F1 Macro: 0.1630, Accuracy: 0.1771\n","Epoch 2, Train Loss: 1.7271, Val Loss: 1.8255, F1 Micro: 0.1458, F1 Macro: 0.1264, Accuracy: 0.1458\n","Epoch 3, Train Loss: 1.6845, Val Loss: 1.7565, F1 Micro: 0.1979, F1 Macro: 0.1381, Accuracy: 0.1979\n","Epoch 4, Train Loss: 1.6721, Val Loss: 1.7479, F1 Micro: 0.2188, F1 Macro: 0.1974, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.6709, Val Loss: 1.7350, F1 Micro: 0.2500, F1 Macro: 0.2079, Accuracy: 0.2500\n","Epoch 6, Train Loss: 1.6410, Val Loss: 1.7645, F1 Micro: 0.2083, F1 Macro: 0.1774, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.6311, Val Loss: 1.7409, F1 Micro: 0.2396, F1 Macro: 0.2079, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6175, Val Loss: 1.6619, F1 Micro: 0.3229, F1 Macro: 0.2795, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.6121, Val Loss: 1.7226, F1 Micro: 0.2812, F1 Macro: 0.2515, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.5853, Val Loss: 1.7528, F1 Micro: 0.2188, F1 Macro: 0.1866, Accuracy: 0.2188\n","Epoch 11, Train Loss: 1.5974, Val Loss: 1.6417, F1 Micro: 0.3333, F1 Macro: 0.2581, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.5742, Val Loss: 1.7560, F1 Micro: 0.3021, F1 Macro: 0.2576, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.5470, Val Loss: 1.7450, F1 Micro: 0.2917, F1 Macro: 0.2561, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.5563, Val Loss: 1.7279, F1 Micro: 0.3542, F1 Macro: 0.3081, Accuracy: 0.3542\n","Epoch 15, Train Loss: 1.5134, Val Loss: 1.7218, F1 Micro: 0.2708, F1 Macro: 0.2567, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.5455, Val Loss: 1.6721, F1 Micro: 0.2812, F1 Macro: 0.2203, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.5071, Val Loss: 1.6302, F1 Micro: 0.4167, F1 Macro: 0.3953, Accuracy: 0.4167\n","Epoch 18, Train Loss: 1.4901, Val Loss: 1.7402, F1 Micro: 0.3125, F1 Macro: 0.2627, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.5077, Val Loss: 1.6217, F1 Micro: 0.3542, F1 Macro: 0.3345, Accuracy: 0.3542\n","Epoch 20, Train Loss: 1.4721, Val Loss: 1.6015, F1 Micro: 0.3646, F1 Macro: 0.3384, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.4888, Val Loss: 1.6194, F1 Micro: 0.4062, F1 Macro: 0.3628, Accuracy: 0.4062\n","Epoch 22, Train Loss: 1.4829, Val Loss: 1.6269, F1 Micro: 0.3750, F1 Macro: 0.3206, Accuracy: 0.3750\n","Epoch 23, Train Loss: 1.4616, Val Loss: 1.5867, F1 Micro: 0.4167, F1 Macro: 0.4031, Accuracy: 0.4167\n","Epoch 24, Train Loss: 1.4458, Val Loss: 1.6039, F1 Micro: 0.3750, F1 Macro: 0.3701, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.4483, Val Loss: 1.5444, F1 Micro: 0.4479, F1 Macro: 0.3662, Accuracy: 0.4479\n","Epoch 26, Train Loss: 1.4327, Val Loss: 1.6622, F1 Micro: 0.3646, F1 Macro: 0.3290, Accuracy: 0.3646\n","Epoch 27, Train Loss: 1.4133, Val Loss: 1.6170, F1 Micro: 0.3542, F1 Macro: 0.2609, Accuracy: 0.3542\n","Epoch 28, Train Loss: 1.3977, Val Loss: 1.7245, F1 Micro: 0.3438, F1 Macro: 0.2923, Accuracy: 0.3438\n","Epoch 29, Train Loss: 1.3788, Val Loss: 1.7359, F1 Micro: 0.3854, F1 Macro: 0.2825, Accuracy: 0.3854\n","Epoch 30, Train Loss: 1.4193, Val Loss: 1.6592, F1 Micro: 0.3854, F1 Macro: 0.3483, Accuracy: 0.3854\n","Epoch 31, Train Loss: 1.3515, Val Loss: 1.6740, F1 Micro: 0.3542, F1 Macro: 0.3063, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.3614, Val Loss: 1.5218, F1 Micro: 0.4583, F1 Macro: 0.4114, Accuracy: 0.4583\n","Epoch 33, Train Loss: 1.3784, Val Loss: 1.6182, F1 Micro: 0.3854, F1 Macro: 0.3847, Accuracy: 0.3854\n","Epoch 34, Train Loss: 1.3532, Val Loss: 1.6044, F1 Micro: 0.4271, F1 Macro: 0.4197, Accuracy: 0.4271\n","Epoch 35, Train Loss: 1.3481, Val Loss: 1.6430, F1 Micro: 0.3958, F1 Macro: 0.3766, Accuracy: 0.3958\n","Epoch 36, Train Loss: 1.3807, Val Loss: 1.5792, F1 Micro: 0.3854, F1 Macro: 0.2862, Accuracy: 0.3854\n","Epoch 37, Train Loss: 1.3338, Val Loss: 1.5123, F1 Micro: 0.4271, F1 Macro: 0.3820, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.3097, Val Loss: 1.5155, F1 Micro: 0.4062, F1 Macro: 0.3744, Accuracy: 0.4062\n","Epoch 39, Train Loss: 1.3280, Val Loss: 1.5069, F1 Micro: 0.5104, F1 Macro: 0.4752, Accuracy: 0.5104\n","Epoch 40, Train Loss: 1.3142, Val Loss: 1.5660, F1 Micro: 0.4792, F1 Macro: 0.3905, Accuracy: 0.4792\n","Epoch 41, Train Loss: 1.2934, Val Loss: 1.6103, F1 Micro: 0.3958, F1 Macro: 0.3510, Accuracy: 0.3958\n","Epoch 42, Train Loss: 1.2909, Val Loss: 1.6419, F1 Micro: 0.3750, F1 Macro: 0.3813, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.3191, Val Loss: 1.6419, F1 Micro: 0.3750, F1 Macro: 0.3121, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.2946, Val Loss: 1.6836, F1 Micro: 0.3854, F1 Macro: 0.3095, Accuracy: 0.3854\n","Epoch 45, Train Loss: 1.2554, Val Loss: 1.5009, F1 Micro: 0.4375, F1 Macro: 0.4048, Accuracy: 0.4375\n","Epoch 46, Train Loss: 1.2506, Val Loss: 1.6645, F1 Micro: 0.3333, F1 Macro: 0.3467, Accuracy: 0.3333\n","Epoch 47, Train Loss: 1.2565, Val Loss: 1.5732, F1 Micro: 0.4271, F1 Macro: 0.3569, Accuracy: 0.4271\n","Epoch 48, Train Loss: 1.2446, Val Loss: 1.5724, F1 Micro: 0.4062, F1 Macro: 0.3777, Accuracy: 0.4062\n","Epoch 49, Train Loss: 1.2624, Val Loss: 2.3029, F1 Micro: 0.2500, F1 Macro: 0.1611, Accuracy: 0.2500\n","Epoch 50, Train Loss: 1.3004, Val Loss: 1.6322, F1 Micro: 0.4271, F1 Macro: 0.3179, Accuracy: 0.4271\n","Epoch 51, Train Loss: 1.2435, Val Loss: 1.6923, F1 Micro: 0.3750, F1 Macro: 0.3778, Accuracy: 0.3750\n","Epoch 52, Train Loss: 1.2340, Val Loss: 1.7024, F1 Micro: 0.3542, F1 Macro: 0.2738, Accuracy: 0.3542\n","Epoch 53, Train Loss: 1.2889, Val Loss: 1.4632, F1 Micro: 0.5000, F1 Macro: 0.4717, Accuracy: 0.5000\n","Epoch 54, Train Loss: 1.2295, Val Loss: 1.4534, F1 Micro: 0.4688, F1 Macro: 0.4326, Accuracy: 0.4688\n","Epoch 55, Train Loss: 1.2371, Val Loss: 1.5300, F1 Micro: 0.4479, F1 Macro: 0.3461, Accuracy: 0.4479\n","Epoch 56, Train Loss: 1.2363, Val Loss: 1.6295, F1 Micro: 0.3750, F1 Macro: 0.3611, Accuracy: 0.3750\n","Epoch 57, Train Loss: 1.2364, Val Loss: 1.6559, F1 Micro: 0.3854, F1 Macro: 0.3462, Accuracy: 0.3854\n","Epoch 58, Train Loss: 1.2220, Val Loss: 1.4508, F1 Micro: 0.4688, F1 Macro: 0.4075, Accuracy: 0.4688\n","Epoch 59, Train Loss: 1.2128, Val Loss: 1.8460, F1 Micro: 0.3438, F1 Macro: 0.2904, Accuracy: 0.3438\n","Epoch 60, Train Loss: 1.1713, Val Loss: 1.4879, F1 Micro: 0.4167, F1 Macro: 0.3820, Accuracy: 0.4167\n","Epoch 61, Train Loss: 1.1889, Val Loss: 1.5244, F1 Micro: 0.4583, F1 Macro: 0.4066, Accuracy: 0.4583\n","Epoch 62, Train Loss: 1.1843, Val Loss: 1.4089, F1 Micro: 0.5417, F1 Macro: 0.5156, Accuracy: 0.5417\n","Epoch 63, Train Loss: 1.1322, Val Loss: 1.5134, F1 Micro: 0.4583, F1 Macro: 0.4184, Accuracy: 0.4583\n","Epoch 64, Train Loss: 1.1448, Val Loss: 1.6117, F1 Micro: 0.4375, F1 Macro: 0.3880, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.1319, Val Loss: 1.8635, F1 Micro: 0.3750, F1 Macro: 0.3197, Accuracy: 0.3750\n","Epoch 66, Train Loss: 1.1880, Val Loss: 1.7293, F1 Micro: 0.4375, F1 Macro: 0.3809, Accuracy: 0.4375\n","Epoch 67, Train Loss: 1.1292, Val Loss: 1.8068, F1 Micro: 0.3750, F1 Macro: 0.3542, Accuracy: 0.3750\n","Epoch 68, Train Loss: 1.1566, Val Loss: 1.5133, F1 Micro: 0.4375, F1 Macro: 0.3865, Accuracy: 0.4375\n","Epoch 69, Train Loss: 1.1473, Val Loss: 1.5920, F1 Micro: 0.4583, F1 Macro: 0.3612, Accuracy: 0.4583\n","Epoch 70, Train Loss: 1.1668, Val Loss: 1.6331, F1 Micro: 0.5000, F1 Macro: 0.4605, Accuracy: 0.5000\n","Epoch 71, Train Loss: 1.1088, Val Loss: 1.5988, F1 Micro: 0.4479, F1 Macro: 0.3989, Accuracy: 0.4479\n","Epoch 72, Train Loss: 1.1379, Val Loss: 1.5279, F1 Micro: 0.4375, F1 Macro: 0.4245, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.1473, Val Loss: 1.5298, F1 Micro: 0.4688, F1 Macro: 0.4366, Accuracy: 0.4688\n","Epoch 74, Train Loss: 1.1481, Val Loss: 1.5073, F1 Micro: 0.4896, F1 Macro: 0.4615, Accuracy: 0.4896\n","Epoch 75, Train Loss: 1.0810, Val Loss: 1.4904, F1 Micro: 0.5000, F1 Macro: 0.4612, Accuracy: 0.5000\n","Epoch 76, Train Loss: 1.1056, Val Loss: 1.7868, F1 Micro: 0.4271, F1 Macro: 0.3651, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.1170, Val Loss: 1.5444, F1 Micro: 0.4375, F1 Macro: 0.4162, Accuracy: 0.4375\n","Epoch 78, Train Loss: 1.1227, Val Loss: 1.6012, F1 Micro: 0.3958, F1 Macro: 0.3813, Accuracy: 0.3958\n","Epoch 79, Train Loss: 1.0700, Val Loss: 1.4670, F1 Micro: 0.5104, F1 Macro: 0.4757, Accuracy: 0.5104\n","Epoch 80, Train Loss: 1.1371, Val Loss: 1.4785, F1 Micro: 0.5521, F1 Macro: 0.5218, Accuracy: 0.5521\n","Epoch 81, Train Loss: 1.0437, Val Loss: 1.4893, F1 Micro: 0.4583, F1 Macro: 0.3886, Accuracy: 0.4583\n","Epoch 82, Train Loss: 1.0648, Val Loss: 1.5655, F1 Micro: 0.3854, F1 Macro: 0.3747, Accuracy: 0.3854\n","Epoch 83, Train Loss: 1.0893, Val Loss: 1.5611, F1 Micro: 0.4479, F1 Macro: 0.4036, Accuracy: 0.4479\n","Epoch 84, Train Loss: 1.0597, Val Loss: 1.6418, F1 Micro: 0.4271, F1 Macro: 0.4216, Accuracy: 0.4271\n","Epoch 85, Train Loss: 1.0702, Val Loss: 1.4343, F1 Micro: 0.5000, F1 Macro: 0.4796, Accuracy: 0.5000\n","Epoch 86, Train Loss: 1.0341, Val Loss: 1.4173, F1 Micro: 0.5625, F1 Macro: 0.5283, Accuracy: 0.5625\n","Epoch 87, Train Loss: 1.0550, Val Loss: 1.3461, F1 Micro: 0.5521, F1 Macro: 0.5200, Accuracy: 0.5521\n","Epoch 88, Train Loss: 1.0356, Val Loss: 1.3364, F1 Micro: 0.5938, F1 Macro: 0.5768, Accuracy: 0.5938\n","Epoch 89, Train Loss: 1.0069, Val Loss: 1.5115, F1 Micro: 0.4583, F1 Macro: 0.4287, Accuracy: 0.4583\n","Epoch 90, Train Loss: 1.0687, Val Loss: 1.8122, F1 Micro: 0.3542, F1 Macro: 0.3271, Accuracy: 0.3542\n","Epoch 91, Train Loss: 1.0549, Val Loss: 1.4246, F1 Micro: 0.5208, F1 Macro: 0.4524, Accuracy: 0.5208\n","Epoch 92, Train Loss: 1.0463, Val Loss: 1.3998, F1 Micro: 0.5417, F1 Macro: 0.5059, Accuracy: 0.5417\n","Epoch 93, Train Loss: 1.0382, Val Loss: 1.6551, F1 Micro: 0.4271, F1 Macro: 0.3844, Accuracy: 0.4271\n","Epoch 94, Train Loss: 1.0201, Val Loss: 1.3894, F1 Micro: 0.5833, F1 Macro: 0.5774, Accuracy: 0.5833\n","Epoch 95, Train Loss: 1.0221, Val Loss: 1.4666, F1 Micro: 0.5312, F1 Macro: 0.5257, Accuracy: 0.5312\n","Epoch 96, Train Loss: 1.0383, Val Loss: 1.3705, F1 Micro: 0.5833, F1 Macro: 0.5349, Accuracy: 0.5833\n","Epoch 97, Train Loss: 1.0160, Val Loss: 1.6687, F1 Micro: 0.4167, F1 Macro: 0.4163, Accuracy: 0.4167\n","Epoch 98, Train Loss: 1.0364, Val Loss: 1.4925, F1 Micro: 0.4896, F1 Macro: 0.4225, Accuracy: 0.4896\n","Epoch 99, Train Loss: 1.0431, Val Loss: 1.4807, F1 Micro: 0.5104, F1 Macro: 0.4468, Accuracy: 0.5104\n","Epoch 100, Train Loss: 1.0039, Val Loss: 1.7838, F1 Micro: 0.3750, F1 Macro: 0.3611, Accuracy: 0.3750\n","Epoch 101, Train Loss: 1.0384, Val Loss: 1.8285, F1 Micro: 0.4062, F1 Macro: 0.3066, Accuracy: 0.4062\n","Epoch 102, Train Loss: 1.0450, Val Loss: 1.4664, F1 Micro: 0.4792, F1 Macro: 0.4085, Accuracy: 0.4792\n","Epoch 103, Train Loss: 0.9683, Val Loss: 1.4051, F1 Micro: 0.5938, F1 Macro: 0.5473, Accuracy: 0.5938\n","Epoch 104, Train Loss: 1.0239, Val Loss: 1.4573, F1 Micro: 0.4896, F1 Macro: 0.4689, Accuracy: 0.4896\n","Epoch 105, Train Loss: 1.0055, Val Loss: 1.3748, F1 Micro: 0.5000, F1 Macro: 0.4769, Accuracy: 0.5000\n","Epoch 106, Train Loss: 0.9776, Val Loss: 1.2690, F1 Micro: 0.6354, F1 Macro: 0.6035, Accuracy: 0.6354\n","Epoch 107, Train Loss: 1.0383, Val Loss: 1.4981, F1 Micro: 0.5104, F1 Macro: 0.4565, Accuracy: 0.5104\n","Epoch 108, Train Loss: 0.9511, Val Loss: 1.4219, F1 Micro: 0.4479, F1 Macro: 0.3972, Accuracy: 0.4479\n","Epoch 109, Train Loss: 0.9621, Val Loss: 1.4005, F1 Micro: 0.5417, F1 Macro: 0.5113, Accuracy: 0.5417\n","Epoch 110, Train Loss: 0.9332, Val Loss: 1.3777, F1 Micro: 0.5312, F1 Macro: 0.4946, Accuracy: 0.5312\n","Epoch 111, Train Loss: 0.9854, Val Loss: 1.6392, F1 Micro: 0.4688, F1 Macro: 0.3640, Accuracy: 0.4688\n","Epoch 112, Train Loss: 0.9864, Val Loss: 1.4541, F1 Micro: 0.5625, F1 Macro: 0.5377, Accuracy: 0.5625\n","Epoch 113, Train Loss: 0.9672, Val Loss: 1.4033, F1 Micro: 0.5104, F1 Macro: 0.4717, Accuracy: 0.5104\n","Epoch 114, Train Loss: 0.9953, Val Loss: 1.4875, F1 Micro: 0.4896, F1 Macro: 0.4725, Accuracy: 0.4896\n","Epoch 115, Train Loss: 0.9429, Val Loss: 1.5020, F1 Micro: 0.4167, F1 Macro: 0.4149, Accuracy: 0.4167\n","Epoch 116, Train Loss: 0.9768, Val Loss: 1.3715, F1 Micro: 0.5312, F1 Macro: 0.4995, Accuracy: 0.5312\n","Epoch 117, Train Loss: 0.9434, Val Loss: 1.3127, F1 Micro: 0.5208, F1 Macro: 0.4927, Accuracy: 0.5208\n","Epoch 118, Train Loss: 0.9663, Val Loss: 1.6308, F1 Micro: 0.4896, F1 Macro: 0.4710, Accuracy: 0.4896\n","Epoch 119, Train Loss: 0.9662, Val Loss: 1.4892, F1 Micro: 0.5312, F1 Macro: 0.5133, Accuracy: 0.5312\n","Epoch 120, Train Loss: 0.9504, Val Loss: 1.6298, F1 Micro: 0.3958, F1 Macro: 0.3940, Accuracy: 0.3958\n","Epoch 121, Train Loss: 0.9610, Val Loss: 1.3245, F1 Micro: 0.6250, F1 Macro: 0.5827, Accuracy: 0.6250\n","Epoch 122, Train Loss: 0.8927, Val Loss: 1.4145, F1 Micro: 0.5208, F1 Macro: 0.4975, Accuracy: 0.5208\n","Epoch 123, Train Loss: 0.9523, Val Loss: 1.5419, F1 Micro: 0.4583, F1 Macro: 0.4692, Accuracy: 0.4583\n","Epoch 124, Train Loss: 0.8861, Val Loss: 1.5163, F1 Micro: 0.4792, F1 Macro: 0.4500, Accuracy: 0.4792\n","Epoch 125, Train Loss: 0.9250, Val Loss: 1.4281, F1 Micro: 0.5625, F1 Macro: 0.5078, Accuracy: 0.5625\n","Epoch 126, Train Loss: 1.0224, Val Loss: 1.7928, F1 Micro: 0.4375, F1 Macro: 0.3638, Accuracy: 0.4375\n","Epoch 127, Train Loss: 0.9531, Val Loss: 1.3411, F1 Micro: 0.5833, F1 Macro: 0.5489, Accuracy: 0.5833\n","Epoch 128, Train Loss: 0.9484, Val Loss: 1.5756, F1 Micro: 0.5208, F1 Macro: 0.4154, Accuracy: 0.5208\n","Epoch 129, Train Loss: 0.9769, Val Loss: 1.7606, F1 Micro: 0.3854, F1 Macro: 0.3770, Accuracy: 0.3854\n","Epoch 130, Train Loss: 0.9171, Val Loss: 1.4684, F1 Micro: 0.5104, F1 Macro: 0.4634, Accuracy: 0.5104\n","Epoch 131, Train Loss: 0.8892, Val Loss: 1.4640, F1 Micro: 0.4583, F1 Macro: 0.4059, Accuracy: 0.4583\n","Epoch 132, Train Loss: 0.9251, Val Loss: 1.4682, F1 Micro: 0.5208, F1 Macro: 0.4751, Accuracy: 0.5208\n","Epoch 133, Train Loss: 0.9059, Val Loss: 1.3884, F1 Micro: 0.5625, F1 Macro: 0.4799, Accuracy: 0.5625\n","Epoch 134, Train Loss: 0.8996, Val Loss: 1.2696, F1 Micro: 0.5938, F1 Macro: 0.5694, Accuracy: 0.5938\n","Epoch 135, Train Loss: 0.9826, Val Loss: 1.3817, F1 Micro: 0.5104, F1 Macro: 0.4895, Accuracy: 0.5104\n","Epoch 136, Train Loss: 0.9195, Val Loss: 1.8092, F1 Micro: 0.4167, F1 Macro: 0.4164, Accuracy: 0.4167\n","Epoch 137, Train Loss: 0.9229, Val Loss: 2.6360, F1 Micro: 0.2604, F1 Macro: 0.2841, Accuracy: 0.2604\n","Epoch 138, Train Loss: 0.9593, Val Loss: 1.7129, F1 Micro: 0.4583, F1 Macro: 0.3732, Accuracy: 0.4583\n","Epoch 139, Train Loss: 0.9889, Val Loss: 1.3229, F1 Micro: 0.5312, F1 Macro: 0.5170, Accuracy: 0.5312\n","Epoch 140, Train Loss: 0.8712, Val Loss: 1.3341, F1 Micro: 0.5625, F1 Macro: 0.5572, Accuracy: 0.5625\n","Epoch 141, Train Loss: 0.8407, Val Loss: 1.3410, F1 Micro: 0.5208, F1 Macro: 0.4834, Accuracy: 0.5208\n","Epoch 142, Train Loss: 0.9127, Val Loss: 1.4111, F1 Micro: 0.5417, F1 Macro: 0.5168, Accuracy: 0.5417\n","Epoch 143, Train Loss: 0.8864, Val Loss: 1.5529, F1 Micro: 0.4792, F1 Macro: 0.4275, Accuracy: 0.4792\n","Epoch 144, Train Loss: 0.9328, Val Loss: 1.4991, F1 Micro: 0.4896, F1 Macro: 0.4005, Accuracy: 0.4896\n","Epoch 145, Train Loss: 0.9439, Val Loss: 1.5855, F1 Micro: 0.4688, F1 Macro: 0.4403, Accuracy: 0.4688\n","Epoch 146, Train Loss: 0.9057, Val Loss: 1.4069, F1 Micro: 0.4896, F1 Macro: 0.4614, Accuracy: 0.4896\n","Epoch 147, Train Loss: 0.9082, Val Loss: 1.8993, F1 Micro: 0.4062, F1 Macro: 0.3422, Accuracy: 0.4062\n","Epoch 148, Train Loss: 0.9252, Val Loss: 1.6960, F1 Micro: 0.4583, F1 Macro: 0.4330, Accuracy: 0.4583\n","Epoch 149, Train Loss: 0.8799, Val Loss: 1.4757, F1 Micro: 0.5312, F1 Macro: 0.4693, Accuracy: 0.5312\n","Epoch 150, Train Loss: 0.9472, Val Loss: 1.5222, F1 Micro: 0.4583, F1 Macro: 0.4457, Accuracy: 0.4583\n","Epoch 151, Train Loss: 0.8941, Val Loss: 1.4767, F1 Micro: 0.5208, F1 Macro: 0.4690, Accuracy: 0.5208\n","Epoch 152, Train Loss: 0.8802, Val Loss: 1.4788, F1 Micro: 0.5312, F1 Macro: 0.5007, Accuracy: 0.5312\n","Epoch 153, Train Loss: 0.8566, Val Loss: 1.5843, F1 Micro: 0.4583, F1 Macro: 0.4658, Accuracy: 0.4583\n","Epoch 154, Train Loss: 0.8686, Val Loss: 1.6443, F1 Micro: 0.5104, F1 Macro: 0.4967, Accuracy: 0.5104\n","Epoch 155, Train Loss: 0.8603, Val Loss: 1.6056, F1 Micro: 0.4583, F1 Macro: 0.4404, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.8441, Val Loss: 1.6038, F1 Micro: 0.5104, F1 Macro: 0.4967, Accuracy: 0.5104\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7692, Val Loss: 1.7821, F1 Micro: 0.2500, F1 Macro: 0.2058, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.7375, Val Loss: 1.7674, F1 Micro: 0.2188, F1 Macro: 0.1554, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7076, Val Loss: 1.7512, F1 Micro: 0.2188, F1 Macro: 0.1724, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.6955, Val Loss: 1.7533, F1 Micro: 0.2708, F1 Macro: 0.2421, Accuracy: 0.2708\n","Epoch 5, Train Loss: 1.6705, Val Loss: 1.7345, F1 Micro: 0.2500, F1 Macro: 0.2116, Accuracy: 0.2500\n","Epoch 6, Train Loss: 1.6561, Val Loss: 1.7638, F1 Micro: 0.1771, F1 Macro: 0.1131, Accuracy: 0.1771\n","Epoch 7, Train Loss: 1.6617, Val Loss: 1.7265, F1 Micro: 0.2604, F1 Macro: 0.1898, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6497, Val Loss: 1.7270, F1 Micro: 0.2604, F1 Macro: 0.2424, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.5995, Val Loss: 1.7609, F1 Micro: 0.1979, F1 Macro: 0.1411, Accuracy: 0.1979\n","Epoch 10, Train Loss: 1.6130, Val Loss: 1.7375, F1 Micro: 0.2917, F1 Macro: 0.2326, Accuracy: 0.2917\n","Epoch 11, Train Loss: 1.6242, Val Loss: 1.7316, F1 Micro: 0.2188, F1 Macro: 0.1702, Accuracy: 0.2188\n","Epoch 12, Train Loss: 1.5726, Val Loss: 1.7134, F1 Micro: 0.3542, F1 Macro: 0.3211, Accuracy: 0.3542\n","Epoch 13, Train Loss: 1.5836, Val Loss: 1.7486, F1 Micro: 0.2812, F1 Macro: 0.2461, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.5901, Val Loss: 1.7313, F1 Micro: 0.3021, F1 Macro: 0.2278, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.5565, Val Loss: 1.6554, F1 Micro: 0.3542, F1 Macro: 0.3614, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5409, Val Loss: 1.7035, F1 Micro: 0.3125, F1 Macro: 0.2909, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.5447, Val Loss: 1.6585, F1 Micro: 0.3750, F1 Macro: 0.3166, Accuracy: 0.3750\n","Epoch 18, Train Loss: 1.5223, Val Loss: 1.6870, F1 Micro: 0.3333, F1 Macro: 0.2828, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.5062, Val Loss: 1.6679, F1 Micro: 0.3750, F1 Macro: 0.3323, Accuracy: 0.3750\n","Epoch 20, Train Loss: 1.4958, Val Loss: 1.6593, F1 Micro: 0.3438, F1 Macro: 0.3026, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.4915, Val Loss: 1.6699, F1 Micro: 0.3542, F1 Macro: 0.3018, Accuracy: 0.3542\n","Epoch 22, Train Loss: 1.4834, Val Loss: 1.6498, F1 Micro: 0.3333, F1 Macro: 0.3062, Accuracy: 0.3333\n","Epoch 23, Train Loss: 1.4775, Val Loss: 1.7319, F1 Micro: 0.3542, F1 Macro: 0.2825, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.4580, Val Loss: 1.6286, F1 Micro: 0.3229, F1 Macro: 0.2964, Accuracy: 0.3229\n","Epoch 25, Train Loss: 1.5011, Val Loss: 1.7339, F1 Micro: 0.2812, F1 Macro: 0.2265, Accuracy: 0.2812\n","Epoch 26, Train Loss: 1.4238, Val Loss: 1.6291, F1 Micro: 0.3854, F1 Macro: 0.3412, Accuracy: 0.3854\n","Epoch 27, Train Loss: 1.4087, Val Loss: 1.7279, F1 Micro: 0.3542, F1 Macro: 0.3257, Accuracy: 0.3542\n","Epoch 28, Train Loss: 1.4379, Val Loss: 1.5952, F1 Micro: 0.3646, F1 Macro: 0.3535, Accuracy: 0.3646\n","Epoch 29, Train Loss: 1.4024, Val Loss: 1.6789, F1 Micro: 0.3958, F1 Macro: 0.3551, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.4235, Val Loss: 1.5838, F1 Micro: 0.3229, F1 Macro: 0.3127, Accuracy: 0.3229\n","Epoch 31, Train Loss: 1.3898, Val Loss: 1.6101, F1 Micro: 0.3542, F1 Macro: 0.3114, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.3875, Val Loss: 1.6254, F1 Micro: 0.3125, F1 Macro: 0.2839, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.4014, Val Loss: 1.6632, F1 Micro: 0.3854, F1 Macro: 0.3464, Accuracy: 0.3854\n","Epoch 34, Train Loss: 1.3722, Val Loss: 1.6871, F1 Micro: 0.3333, F1 Macro: 0.2791, Accuracy: 0.3333\n","Epoch 35, Train Loss: 1.3932, Val Loss: 1.5437, F1 Micro: 0.3542, F1 Macro: 0.3556, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.3671, Val Loss: 1.5888, F1 Micro: 0.4062, F1 Macro: 0.3792, Accuracy: 0.4062\n","Epoch 37, Train Loss: 1.3522, Val Loss: 1.5748, F1 Micro: 0.4062, F1 Macro: 0.3790, Accuracy: 0.4062\n","Epoch 38, Train Loss: 1.3594, Val Loss: 1.7751, F1 Micro: 0.2396, F1 Macro: 0.1849, Accuracy: 0.2396\n","Epoch 39, Train Loss: 1.3158, Val Loss: 1.6019, F1 Micro: 0.3333, F1 Macro: 0.2982, Accuracy: 0.3333\n","Epoch 40, Train Loss: 1.3520, Val Loss: 1.6715, F1 Micro: 0.4167, F1 Macro: 0.4098, Accuracy: 0.4167\n","Epoch 41, Train Loss: 1.3258, Val Loss: 1.6156, F1 Micro: 0.3646, F1 Macro: 0.3225, Accuracy: 0.3646\n","Epoch 42, Train Loss: 1.3150, Val Loss: 1.6122, F1 Micro: 0.3854, F1 Macro: 0.3462, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.2806, Val Loss: 1.5607, F1 Micro: 0.4062, F1 Macro: 0.4095, Accuracy: 0.4062\n","Epoch 44, Train Loss: 1.3076, Val Loss: 1.4852, F1 Micro: 0.4271, F1 Macro: 0.4239, Accuracy: 0.4271\n","Epoch 45, Train Loss: 1.3129, Val Loss: 1.5236, F1 Micro: 0.4583, F1 Macro: 0.4447, Accuracy: 0.4583\n","Epoch 46, Train Loss: 1.2740, Val Loss: 1.5318, F1 Micro: 0.3958, F1 Macro: 0.3932, Accuracy: 0.3958\n","Epoch 47, Train Loss: 1.2793, Val Loss: 1.5963, F1 Micro: 0.3958, F1 Macro: 0.3559, Accuracy: 0.3958\n","Epoch 48, Train Loss: 1.2521, Val Loss: 2.1992, F1 Micro: 0.3542, F1 Macro: 0.2684, Accuracy: 0.3542\n","Epoch 49, Train Loss: 1.3473, Val Loss: 1.5419, F1 Micro: 0.3646, F1 Macro: 0.3266, Accuracy: 0.3646\n","Epoch 50, Train Loss: 1.2575, Val Loss: 1.7101, F1 Micro: 0.3125, F1 Macro: 0.3013, Accuracy: 0.3125\n","Epoch 51, Train Loss: 1.2593, Val Loss: 1.5985, F1 Micro: 0.3958, F1 Macro: 0.3379, Accuracy: 0.3958\n","Epoch 52, Train Loss: 1.2414, Val Loss: 1.7470, F1 Micro: 0.4062, F1 Macro: 0.3667, Accuracy: 0.4062\n","Epoch 53, Train Loss: 1.2277, Val Loss: 1.5272, F1 Micro: 0.4167, F1 Macro: 0.4319, Accuracy: 0.4167\n","Epoch 54, Train Loss: 1.2303, Val Loss: 1.6248, F1 Micro: 0.4167, F1 Macro: 0.3384, Accuracy: 0.4167\n","Epoch 55, Train Loss: 1.2062, Val Loss: 1.6790, F1 Micro: 0.3542, F1 Macro: 0.3309, Accuracy: 0.3542\n","Epoch 56, Train Loss: 1.1921, Val Loss: 1.5391, F1 Micro: 0.4167, F1 Macro: 0.3880, Accuracy: 0.4167\n","Epoch 57, Train Loss: 1.2198, Val Loss: 1.7775, F1 Micro: 0.3021, F1 Macro: 0.2569, Accuracy: 0.3021\n","Epoch 58, Train Loss: 1.1868, Val Loss: 1.7059, F1 Micro: 0.3021, F1 Macro: 0.2590, Accuracy: 0.3021\n","Epoch 59, Train Loss: 1.2016, Val Loss: 1.5633, F1 Micro: 0.3854, F1 Macro: 0.3728, Accuracy: 0.3854\n","Epoch 60, Train Loss: 1.1909, Val Loss: 1.5793, F1 Micro: 0.4271, F1 Macro: 0.3894, Accuracy: 0.4271\n","Epoch 61, Train Loss: 1.2030, Val Loss: 1.5632, F1 Micro: 0.3854, F1 Macro: 0.3856, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.1961, Val Loss: 1.5287, F1 Micro: 0.4271, F1 Macro: 0.3775, Accuracy: 0.4271\n","Epoch 63, Train Loss: 1.1896, Val Loss: 1.5010, F1 Micro: 0.3854, F1 Macro: 0.3845, Accuracy: 0.3854\n","Epoch 64, Train Loss: 1.1771, Val Loss: 1.6402, F1 Micro: 0.3229, F1 Macro: 0.3349, Accuracy: 0.3229\n","Epoch 65, Train Loss: 1.1784, Val Loss: 1.5083, F1 Micro: 0.4271, F1 Macro: 0.4265, Accuracy: 0.4271\n","Epoch 66, Train Loss: 1.1415, Val Loss: 1.8242, F1 Micro: 0.3333, F1 Macro: 0.2662, Accuracy: 0.3333\n","Epoch 67, Train Loss: 1.2089, Val Loss: 1.9567, F1 Micro: 0.2604, F1 Macro: 0.2091, Accuracy: 0.2604\n","Epoch 68, Train Loss: 1.1913, Val Loss: 1.4828, F1 Micro: 0.4062, F1 Macro: 0.3832, Accuracy: 0.4062\n","Epoch 69, Train Loss: 1.1237, Val Loss: 1.8157, F1 Micro: 0.4167, F1 Macro: 0.3698, Accuracy: 0.4167\n","Epoch 70, Train Loss: 1.1473, Val Loss: 1.4509, F1 Micro: 0.4271, F1 Macro: 0.4417, Accuracy: 0.4271\n","Epoch 71, Train Loss: 1.1163, Val Loss: 1.5258, F1 Micro: 0.4062, F1 Macro: 0.4085, Accuracy: 0.4062\n","Epoch 72, Train Loss: 1.1267, Val Loss: 1.5154, F1 Micro: 0.3958, F1 Macro: 0.3648, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.1234, Val Loss: 1.6212, F1 Micro: 0.4375, F1 Macro: 0.4240, Accuracy: 0.4375\n","Epoch 74, Train Loss: 1.1386, Val Loss: 1.4310, F1 Micro: 0.4583, F1 Macro: 0.4271, Accuracy: 0.4583\n","Epoch 75, Train Loss: 1.0847, Val Loss: 1.4600, F1 Micro: 0.4167, F1 Macro: 0.4001, Accuracy: 0.4167\n","Epoch 76, Train Loss: 1.1083, Val Loss: 1.4741, F1 Micro: 0.4479, F1 Macro: 0.4433, Accuracy: 0.4479\n","Epoch 77, Train Loss: 1.0777, Val Loss: 1.5173, F1 Micro: 0.3854, F1 Macro: 0.3360, Accuracy: 0.3854\n","Epoch 78, Train Loss: 1.1199, Val Loss: 1.4462, F1 Micro: 0.4792, F1 Macro: 0.4634, Accuracy: 0.4792\n","Epoch 79, Train Loss: 1.1095, Val Loss: 1.5008, F1 Micro: 0.4479, F1 Macro: 0.4166, Accuracy: 0.4479\n","Epoch 80, Train Loss: 1.1129, Val Loss: 1.4646, F1 Micro: 0.4167, F1 Macro: 0.4073, Accuracy: 0.4167\n","Epoch 81, Train Loss: 1.0663, Val Loss: 1.6317, F1 Micro: 0.4583, F1 Macro: 0.4112, Accuracy: 0.4583\n","Epoch 82, Train Loss: 1.0997, Val Loss: 1.6096, F1 Micro: 0.3646, F1 Macro: 0.3234, Accuracy: 0.3646\n","Epoch 83, Train Loss: 1.0626, Val Loss: 1.5254, F1 Micro: 0.4792, F1 Macro: 0.4565, Accuracy: 0.4792\n","Epoch 84, Train Loss: 1.0958, Val Loss: 1.5600, F1 Micro: 0.3958, F1 Macro: 0.3878, Accuracy: 0.3958\n","Epoch 85, Train Loss: 1.0735, Val Loss: 1.9010, F1 Micro: 0.3750, F1 Macro: 0.3318, Accuracy: 0.3750\n","Epoch 86, Train Loss: 1.0605, Val Loss: 1.6333, F1 Micro: 0.4375, F1 Macro: 0.4069, Accuracy: 0.4375\n","Epoch 87, Train Loss: 1.0290, Val Loss: 1.4355, F1 Micro: 0.4896, F1 Macro: 0.4712, Accuracy: 0.4896\n","Epoch 88, Train Loss: 1.0309, Val Loss: 1.5367, F1 Micro: 0.3958, F1 Macro: 0.3798, Accuracy: 0.3958\n","Epoch 89, Train Loss: 1.0589, Val Loss: 1.5035, F1 Micro: 0.4062, F1 Macro: 0.3622, Accuracy: 0.4062\n","Epoch 90, Train Loss: 1.0615, Val Loss: 1.8340, F1 Micro: 0.3542, F1 Macro: 0.3343, Accuracy: 0.3542\n","Epoch 91, Train Loss: 1.0655, Val Loss: 1.7023, F1 Micro: 0.3542, F1 Macro: 0.3467, Accuracy: 0.3542\n","Epoch 92, Train Loss: 1.0340, Val Loss: 1.6892, F1 Micro: 0.4062, F1 Macro: 0.3861, Accuracy: 0.4062\n","Epoch 93, Train Loss: 1.0191, Val Loss: 1.3740, F1 Micro: 0.5208, F1 Macro: 0.5230, Accuracy: 0.5208\n","Epoch 94, Train Loss: 0.9932, Val Loss: 1.4565, F1 Micro: 0.5312, F1 Macro: 0.5011, Accuracy: 0.5312\n","Epoch 95, Train Loss: 1.0403, Val Loss: 1.6563, F1 Micro: 0.3958, F1 Macro: 0.3526, Accuracy: 0.3958\n","Epoch 96, Train Loss: 0.9995, Val Loss: 1.4593, F1 Micro: 0.5000, F1 Macro: 0.4474, Accuracy: 0.5000\n","Epoch 97, Train Loss: 1.0412, Val Loss: 1.6769, F1 Micro: 0.3333, F1 Macro: 0.3382, Accuracy: 0.3333\n","Epoch 98, Train Loss: 1.0485, Val Loss: 1.4671, F1 Micro: 0.4792, F1 Macro: 0.4370, Accuracy: 0.4792\n","Epoch 99, Train Loss: 1.0089, Val Loss: 1.5527, F1 Micro: 0.3854, F1 Macro: 0.3555, Accuracy: 0.3854\n","Epoch 100, Train Loss: 1.0488, Val Loss: 1.8217, F1 Micro: 0.3542, F1 Macro: 0.3393, Accuracy: 0.3542\n","Epoch 101, Train Loss: 1.0256, Val Loss: 1.4708, F1 Micro: 0.4375, F1 Macro: 0.4108, Accuracy: 0.4375\n","Epoch 102, Train Loss: 0.9854, Val Loss: 1.5375, F1 Micro: 0.4479, F1 Macro: 0.4121, Accuracy: 0.4479\n","Epoch 103, Train Loss: 0.9958, Val Loss: 1.3124, F1 Micro: 0.5312, F1 Macro: 0.5430, Accuracy: 0.5312\n","Epoch 104, Train Loss: 0.9810, Val Loss: 1.5298, F1 Micro: 0.4271, F1 Macro: 0.4162, Accuracy: 0.4271\n","Epoch 105, Train Loss: 1.0409, Val Loss: 1.4831, F1 Micro: 0.4583, F1 Macro: 0.4377, Accuracy: 0.4583\n","Epoch 106, Train Loss: 1.0113, Val Loss: 1.4190, F1 Micro: 0.4583, F1 Macro: 0.4282, Accuracy: 0.4583\n","Epoch 107, Train Loss: 0.9595, Val Loss: 1.5876, F1 Micro: 0.4167, F1 Macro: 0.4014, Accuracy: 0.4167\n","Epoch 108, Train Loss: 1.0036, Val Loss: 1.4632, F1 Micro: 0.4688, F1 Macro: 0.4624, Accuracy: 0.4688\n","Epoch 109, Train Loss: 0.9667, Val Loss: 1.5840, F1 Micro: 0.3854, F1 Macro: 0.3811, Accuracy: 0.3854\n","Epoch 110, Train Loss: 1.0087, Val Loss: 1.5464, F1 Micro: 0.3958, F1 Macro: 0.3751, Accuracy: 0.3958\n","Epoch 111, Train Loss: 0.9815, Val Loss: 1.5507, F1 Micro: 0.4062, F1 Macro: 0.3894, Accuracy: 0.4062\n","Epoch 112, Train Loss: 0.9835, Val Loss: 1.5255, F1 Micro: 0.4792, F1 Macro: 0.4488, Accuracy: 0.4792\n","Epoch 113, Train Loss: 0.9969, Val Loss: 1.8196, F1 Micro: 0.4375, F1 Macro: 0.3919, Accuracy: 0.4375\n","Epoch 114, Train Loss: 1.0084, Val Loss: 1.8634, F1 Micro: 0.3750, F1 Macro: 0.3461, Accuracy: 0.3750\n","Epoch 115, Train Loss: 0.9818, Val Loss: 1.8423, F1 Micro: 0.3542, F1 Macro: 0.3482, Accuracy: 0.3542\n","Epoch 116, Train Loss: 0.9261, Val Loss: 1.3739, F1 Micro: 0.4896, F1 Macro: 0.4651, Accuracy: 0.4896\n","Epoch 117, Train Loss: 0.9623, Val Loss: 1.3646, F1 Micro: 0.4896, F1 Macro: 0.4751, Accuracy: 0.4896\n","Epoch 118, Train Loss: 0.9439, Val Loss: 1.3296, F1 Micro: 0.5000, F1 Macro: 0.4947, Accuracy: 0.5000\n","Epoch 119, Train Loss: 0.9438, Val Loss: 1.3518, F1 Micro: 0.4896, F1 Macro: 0.4836, Accuracy: 0.4896\n","Epoch 120, Train Loss: 0.9349, Val Loss: 1.5459, F1 Micro: 0.3854, F1 Macro: 0.3551, Accuracy: 0.3854\n","Epoch 121, Train Loss: 0.8897, Val Loss: 1.3512, F1 Micro: 0.5417, F1 Macro: 0.5015, Accuracy: 0.5417\n","Epoch 122, Train Loss: 0.9457, Val Loss: 1.3261, F1 Micro: 0.4375, F1 Macro: 0.4388, Accuracy: 0.4375\n","Epoch 123, Train Loss: 0.9768, Val Loss: 1.6565, F1 Micro: 0.4375, F1 Macro: 0.4018, Accuracy: 0.4375\n","Epoch 124, Train Loss: 0.9278, Val Loss: 1.4793, F1 Micro: 0.4583, F1 Macro: 0.4522, Accuracy: 0.4583\n","Epoch 125, Train Loss: 0.9768, Val Loss: 1.5924, F1 Micro: 0.5000, F1 Macro: 0.4576, Accuracy: 0.5000\n","Epoch 126, Train Loss: 0.9577, Val Loss: 1.7558, F1 Micro: 0.3854, F1 Macro: 0.3842, Accuracy: 0.3854\n","Epoch 127, Train Loss: 0.9255, Val Loss: 1.4971, F1 Micro: 0.5000, F1 Macro: 0.4546, Accuracy: 0.5000\n","Epoch 128, Train Loss: 0.8997, Val Loss: 1.5811, F1 Micro: 0.4062, F1 Macro: 0.3809, Accuracy: 0.4062\n","Epoch 129, Train Loss: 0.9590, Val Loss: 1.5170, F1 Micro: 0.4688, F1 Macro: 0.4438, Accuracy: 0.4688\n","Epoch 130, Train Loss: 0.8684, Val Loss: 1.3893, F1 Micro: 0.5000, F1 Macro: 0.4928, Accuracy: 0.5000\n","Epoch 131, Train Loss: 0.9108, Val Loss: 1.5383, F1 Micro: 0.3854, F1 Macro: 0.3514, Accuracy: 0.3854\n","Epoch 132, Train Loss: 0.9475, Val Loss: 1.7183, F1 Micro: 0.4375, F1 Macro: 0.3996, Accuracy: 0.4375\n","Epoch 133, Train Loss: 0.9979, Val Loss: 2.0055, F1 Micro: 0.4479, F1 Macro: 0.4052, Accuracy: 0.4479\n","Epoch 134, Train Loss: 0.9045, Val Loss: 1.8342, F1 Micro: 0.3646, F1 Macro: 0.3149, Accuracy: 0.3646\n","Epoch 135, Train Loss: 0.8705, Val Loss: 1.4544, F1 Micro: 0.4583, F1 Macro: 0.4280, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.9063, Val Loss: 1.4074, F1 Micro: 0.5312, F1 Macro: 0.5085, Accuracy: 0.5312\n","Epoch 137, Train Loss: 0.9196, Val Loss: 1.4938, F1 Micro: 0.4375, F1 Macro: 0.4287, Accuracy: 0.4375\n","Epoch 138, Train Loss: 0.9380, Val Loss: 1.7586, F1 Micro: 0.4167, F1 Macro: 0.3771, Accuracy: 0.4167\n","Epoch 139, Train Loss: 0.9722, Val Loss: 1.5478, F1 Micro: 0.4479, F1 Macro: 0.4277, Accuracy: 0.4479\n","Epoch 140, Train Loss: 0.9146, Val Loss: 1.4148, F1 Micro: 0.4792, F1 Macro: 0.4652, Accuracy: 0.4792\n","Epoch 141, Train Loss: 0.8650, Val Loss: 1.6746, F1 Micro: 0.4896, F1 Macro: 0.4611, Accuracy: 0.4896\n","Epoch 142, Train Loss: 0.9297, Val Loss: 1.9007, F1 Micro: 0.3646, F1 Macro: 0.3340, Accuracy: 0.3646\n","Epoch 143, Train Loss: 0.8703, Val Loss: 1.4917, F1 Micro: 0.4479, F1 Macro: 0.4017, Accuracy: 0.4479\n","Epoch 144, Train Loss: 0.8765, Val Loss: 1.2935, F1 Micro: 0.5521, F1 Macro: 0.5453, Accuracy: 0.5521\n","Epoch 145, Train Loss: 0.8712, Val Loss: 1.2916, F1 Micro: 0.5208, F1 Macro: 0.5139, Accuracy: 0.5208\n","Epoch 146, Train Loss: 0.8724, Val Loss: 1.5644, F1 Micro: 0.4688, F1 Macro: 0.4388, Accuracy: 0.4688\n","Epoch 147, Train Loss: 0.8973, Val Loss: 1.7825, F1 Micro: 0.4271, F1 Macro: 0.4032, Accuracy: 0.4271\n","Epoch 148, Train Loss: 0.9459, Val Loss: 1.5368, F1 Micro: 0.3854, F1 Macro: 0.3879, Accuracy: 0.3854\n","Epoch 149, Train Loss: 0.9199, Val Loss: 2.2587, F1 Micro: 0.3438, F1 Macro: 0.3075, Accuracy: 0.3438\n","Epoch 150, Train Loss: 0.8800, Val Loss: 2.4917, F1 Micro: 0.2292, F1 Macro: 0.1684, Accuracy: 0.2292\n","Epoch 151, Train Loss: 0.8801, Val Loss: 1.7083, F1 Micro: 0.4479, F1 Macro: 0.4294, Accuracy: 0.4479\n","Epoch 152, Train Loss: 0.8375, Val Loss: 1.3639, F1 Micro: 0.5312, F1 Macro: 0.5178, Accuracy: 0.5312\n","Epoch 153, Train Loss: 0.8879, Val Loss: 1.4245, F1 Micro: 0.4896, F1 Macro: 0.4878, Accuracy: 0.4896\n","Epoch 154, Train Loss: 0.8993, Val Loss: 1.5966, F1 Micro: 0.4062, F1 Macro: 0.3690, Accuracy: 0.4062\n","Epoch 155, Train Loss: 0.8971, Val Loss: 1.4281, F1 Micro: 0.4583, F1 Macro: 0.4466, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.9175, Val Loss: 1.8859, F1 Micro: 0.4062, F1 Macro: 0.3721, Accuracy: 0.4062\n","Epoch 157, Train Loss: 0.8637, Val Loss: 1.5939, F1 Micro: 0.3958, F1 Macro: 0.4025, Accuracy: 0.3958\n","Epoch 158, Train Loss: 0.8902, Val Loss: 1.4244, F1 Micro: 0.5104, F1 Macro: 0.4962, Accuracy: 0.5104\n","Epoch 159, Train Loss: 0.8401, Val Loss: 1.4764, F1 Micro: 0.5000, F1 Macro: 0.4574, Accuracy: 0.5000\n","Epoch 160, Train Loss: 0.8359, Val Loss: 1.7395, F1 Micro: 0.4583, F1 Macro: 0.4421, Accuracy: 0.4583\n","Epoch 161, Train Loss: 0.8791, Val Loss: 1.7056, F1 Micro: 0.4271, F1 Macro: 0.3966, Accuracy: 0.4271\n","Epoch 162, Train Loss: 0.8239, Val Loss: 1.6101, F1 Micro: 0.4792, F1 Macro: 0.4600, Accuracy: 0.4792\n","Epoch 163, Train Loss: 0.8806, Val Loss: 1.3124, F1 Micro: 0.5833, F1 Macro: 0.5684, Accuracy: 0.5833\n","Epoch 164, Train Loss: 0.8626, Val Loss: 1.4633, F1 Micro: 0.4583, F1 Macro: 0.4628, Accuracy: 0.4583\n","Epoch 165, Train Loss: 0.8770, Val Loss: 1.5855, F1 Micro: 0.4583, F1 Macro: 0.4503, Accuracy: 0.4583\n","Epoch 166, Train Loss: 0.9183, Val Loss: 1.3532, F1 Micro: 0.5417, F1 Macro: 0.5192, Accuracy: 0.5417\n","Epoch 167, Train Loss: 0.8131, Val Loss: 1.7639, F1 Micro: 0.3542, F1 Macro: 0.3520, Accuracy: 0.3542\n","Epoch 168, Train Loss: 0.8368, Val Loss: 1.4216, F1 Micro: 0.4792, F1 Macro: 0.4668, Accuracy: 0.4792\n","Epoch 169, Train Loss: 0.8334, Val Loss: 1.5094, F1 Micro: 0.4583, F1 Macro: 0.4810, Accuracy: 0.4583\n","Epoch 170, Train Loss: 0.8110, Val Loss: 1.7767, F1 Micro: 0.4479, F1 Macro: 0.4003, Accuracy: 0.4479\n","Epoch 171, Train Loss: 0.8862, Val Loss: 1.6318, F1 Micro: 0.4375, F1 Macro: 0.4082, Accuracy: 0.4375\n","Epoch 172, Train Loss: 0.8202, Val Loss: 1.3232, F1 Micro: 0.4896, F1 Macro: 0.4886, Accuracy: 0.4896\n","Epoch 173, Train Loss: 0.8186, Val Loss: 1.3272, F1 Micro: 0.5312, F1 Macro: 0.4996, Accuracy: 0.5312\n","Epoch 174, Train Loss: 0.8455, Val Loss: 2.5949, F1 Micro: 0.3333, F1 Macro: 0.2820, Accuracy: 0.3333\n","Epoch 175, Train Loss: 0.8280, Val Loss: 1.6060, F1 Micro: 0.4271, F1 Macro: 0.4020, Accuracy: 0.4271\n","Epoch 176, Train Loss: 0.8068, Val Loss: 1.4223, F1 Micro: 0.5000, F1 Macro: 0.4965, Accuracy: 0.5000\n","Epoch 177, Train Loss: 0.8592, Val Loss: 1.8392, F1 Micro: 0.3750, F1 Macro: 0.3628, Accuracy: 0.3750\n","Epoch 178, Train Loss: 0.7934, Val Loss: 1.5657, F1 Micro: 0.4479, F1 Macro: 0.4464, Accuracy: 0.4479\n","Epoch 179, Train Loss: 0.8239, Val Loss: 1.4310, F1 Micro: 0.4688, F1 Macro: 0.4599, Accuracy: 0.4688\n","Epoch 180, Train Loss: 0.8358, Val Loss: 1.4865, F1 Micro: 0.4375, F1 Macro: 0.4133, Accuracy: 0.4375\n","Epoch 181, Train Loss: 0.8024, Val Loss: 1.7457, F1 Micro: 0.4062, F1 Macro: 0.3785, Accuracy: 0.4062\n","Epoch 182, Train Loss: 0.8660, Val Loss: 2.0433, F1 Micro: 0.4271, F1 Macro: 0.3624, Accuracy: 0.4271\n","Epoch 183, Train Loss: 0.8329, Val Loss: 1.9759, F1 Micro: 0.4271, F1 Macro: 0.3904, Accuracy: 0.4271\n","Epoch 184, Train Loss: 0.7970, Val Loss: 1.4872, F1 Micro: 0.4375, F1 Macro: 0.4136, Accuracy: 0.4375\n","Epoch 185, Train Loss: 0.7936, Val Loss: 1.4017, F1 Micro: 0.4167, F1 Macro: 0.4121, Accuracy: 0.4167\n","Epoch 186, Train Loss: 0.7919, Val Loss: 1.4863, F1 Micro: 0.5000, F1 Macro: 0.4834, Accuracy: 0.5000\n","Epoch 187, Train Loss: 0.7681, Val Loss: 1.5226, F1 Micro: 0.5000, F1 Macro: 0.5062, Accuracy: 0.5000\n","Epoch 188, Train Loss: 0.8254, Val Loss: 1.6905, F1 Micro: 0.4792, F1 Macro: 0.4672, Accuracy: 0.4792\n","Epoch 189, Train Loss: 0.7944, Val Loss: 1.5633, F1 Micro: 0.4688, F1 Macro: 0.4286, Accuracy: 0.4688\n","Epoch 190, Train Loss: 0.8260, Val Loss: 1.4561, F1 Micro: 0.5104, F1 Macro: 0.4988, Accuracy: 0.5104\n","Epoch 191, Train Loss: 0.7943, Val Loss: 1.5108, F1 Micro: 0.5104, F1 Macro: 0.4894, Accuracy: 0.5104\n","Epoch 192, Train Loss: 0.8301, Val Loss: 1.4040, F1 Micro: 0.5208, F1 Macro: 0.5075, Accuracy: 0.5208\n","Epoch 193, Train Loss: 0.7880, Val Loss: 1.4985, F1 Micro: 0.5104, F1 Macro: 0.4722, Accuracy: 0.5104\n","Epoch 194, Train Loss: 0.7867, Val Loss: 1.6405, F1 Micro: 0.4583, F1 Macro: 0.4395, Accuracy: 0.4583\n","Epoch 195, Train Loss: 0.7970, Val Loss: 1.6608, F1 Micro: 0.4792, F1 Macro: 0.4404, Accuracy: 0.4792\n","Epoch 196, Train Loss: 0.8156, Val Loss: 1.4313, F1 Micro: 0.5000, F1 Macro: 0.5058, Accuracy: 0.5000\n","Epoch 197, Train Loss: 0.8031, Val Loss: 1.6409, F1 Micro: 0.3854, F1 Macro: 0.3728, Accuracy: 0.3854\n","Epoch 198, Train Loss: 0.7684, Val Loss: 1.4660, F1 Micro: 0.4688, F1 Macro: 0.4405, Accuracy: 0.4688\n","Epoch 199, Train Loss: 0.7626, Val Loss: 1.3080, F1 Micro: 0.5000, F1 Macro: 0.4858, Accuracy: 0.5000\n","Epoch 200, Train Loss: 0.7894, Val Loss: 1.5488, F1 Micro: 0.4583, F1 Macro: 0.4324, Accuracy: 0.4583\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7932, Val Loss: 1.7573, F1 Micro: 0.1979, F1 Macro: 0.1181, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7428, Val Loss: 1.6988, F1 Micro: 0.2917, F1 Macro: 0.2212, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.7078, Val Loss: 1.6891, F1 Micro: 0.3229, F1 Macro: 0.3022, Accuracy: 0.3229\n","Epoch 4, Train Loss: 1.6678, Val Loss: 1.7003, F1 Micro: 0.3438, F1 Macro: 0.3050, Accuracy: 0.3438\n","Epoch 5, Train Loss: 1.6511, Val Loss: 1.7076, F1 Micro: 0.3021, F1 Macro: 0.2511, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.6351, Val Loss: 1.7117, F1 Micro: 0.3333, F1 Macro: 0.3269, Accuracy: 0.3333\n","Epoch 7, Train Loss: 1.6532, Val Loss: 1.7214, F1 Micro: 0.2812, F1 Macro: 0.2373, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6031, Val Loss: 1.6934, F1 Micro: 0.3229, F1 Macro: 0.3288, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.5939, Val Loss: 1.7125, F1 Micro: 0.3438, F1 Macro: 0.2804, Accuracy: 0.3438\n","Epoch 10, Train Loss: 1.5878, Val Loss: 1.6929, F1 Micro: 0.3333, F1 Macro: 0.3030, Accuracy: 0.3333\n","Epoch 11, Train Loss: 1.5558, Val Loss: 1.7021, F1 Micro: 0.3333, F1 Macro: 0.2980, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.5583, Val Loss: 1.7354, F1 Micro: 0.3750, F1 Macro: 0.3497, Accuracy: 0.3750\n","Epoch 13, Train Loss: 1.5674, Val Loss: 1.6857, F1 Micro: 0.3750, F1 Macro: 0.3419, Accuracy: 0.3750\n","Epoch 14, Train Loss: 1.5006, Val Loss: 1.7356, F1 Micro: 0.3021, F1 Macro: 0.2969, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.5021, Val Loss: 1.6953, F1 Micro: 0.3854, F1 Macro: 0.3519, Accuracy: 0.3854\n","Epoch 16, Train Loss: 1.4926, Val Loss: 1.7182, F1 Micro: 0.3854, F1 Macro: 0.3828, Accuracy: 0.3854\n","Epoch 17, Train Loss: 1.4569, Val Loss: 1.7715, F1 Micro: 0.2917, F1 Macro: 0.2720, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.4633, Val Loss: 1.6936, F1 Micro: 0.3958, F1 Macro: 0.3809, Accuracy: 0.3958\n","Epoch 19, Train Loss: 1.4369, Val Loss: 1.7036, F1 Micro: 0.3646, F1 Macro: 0.2990, Accuracy: 0.3646\n","Epoch 20, Train Loss: 1.4352, Val Loss: 1.7005, F1 Micro: 0.3646, F1 Macro: 0.3734, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.4498, Val Loss: 1.7708, F1 Micro: 0.3854, F1 Macro: 0.4061, Accuracy: 0.3854\n","Epoch 22, Train Loss: 1.4629, Val Loss: 1.6886, F1 Micro: 0.3958, F1 Macro: 0.3755, Accuracy: 0.3958\n","Epoch 23, Train Loss: 1.4386, Val Loss: 1.7485, F1 Micro: 0.3333, F1 Macro: 0.2974, Accuracy: 0.3333\n","Epoch 24, Train Loss: 1.4062, Val Loss: 1.6887, F1 Micro: 0.3646, F1 Macro: 0.3794, Accuracy: 0.3646\n","Epoch 25, Train Loss: 1.4172, Val Loss: 1.7007, F1 Micro: 0.3646, F1 Macro: 0.3341, Accuracy: 0.3646\n","Epoch 26, Train Loss: 1.3650, Val Loss: 1.6882, F1 Micro: 0.3125, F1 Macro: 0.2729, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.3904, Val Loss: 1.7245, F1 Micro: 0.4167, F1 Macro: 0.4083, Accuracy: 0.4167\n","Epoch 28, Train Loss: 1.3966, Val Loss: 1.6647, F1 Micro: 0.4271, F1 Macro: 0.4299, Accuracy: 0.4271\n","Epoch 29, Train Loss: 1.3721, Val Loss: 1.6810, F1 Micro: 0.3750, F1 Macro: 0.3804, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.3676, Val Loss: 1.7146, F1 Micro: 0.3854, F1 Macro: 0.3580, Accuracy: 0.3854\n","Epoch 31, Train Loss: 1.3553, Val Loss: 1.6517, F1 Micro: 0.3958, F1 Macro: 0.3614, Accuracy: 0.3958\n","Epoch 32, Train Loss: 1.3499, Val Loss: 1.7101, F1 Micro: 0.3542, F1 Macro: 0.3293, Accuracy: 0.3542\n","Epoch 33, Train Loss: 1.3193, Val Loss: 1.6592, F1 Micro: 0.4062, F1 Macro: 0.4088, Accuracy: 0.4062\n","Epoch 34, Train Loss: 1.3222, Val Loss: 1.8702, F1 Micro: 0.3021, F1 Macro: 0.2637, Accuracy: 0.3021\n","Epoch 35, Train Loss: 1.3316, Val Loss: 1.7897, F1 Micro: 0.3333, F1 Macro: 0.2655, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.3145, Val Loss: 1.6494, F1 Micro: 0.4271, F1 Macro: 0.4339, Accuracy: 0.4271\n","Epoch 37, Train Loss: 1.2798, Val Loss: 1.6873, F1 Micro: 0.4375, F1 Macro: 0.4183, Accuracy: 0.4375\n","Epoch 38, Train Loss: 1.2959, Val Loss: 1.6453, F1 Micro: 0.4479, F1 Macro: 0.4332, Accuracy: 0.4479\n","Epoch 39, Train Loss: 1.2713, Val Loss: 1.7024, F1 Micro: 0.3646, F1 Macro: 0.3270, Accuracy: 0.3646\n","Epoch 40, Train Loss: 1.2916, Val Loss: 1.6518, F1 Micro: 0.4062, F1 Macro: 0.4183, Accuracy: 0.4062\n","Epoch 41, Train Loss: 1.2523, Val Loss: 1.7875, F1 Micro: 0.3333, F1 Macro: 0.3170, Accuracy: 0.3333\n","Epoch 42, Train Loss: 1.2496, Val Loss: 1.6633, F1 Micro: 0.3854, F1 Macro: 0.3690, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.2620, Val Loss: 1.7079, F1 Micro: 0.4375, F1 Macro: 0.4126, Accuracy: 0.4375\n","Epoch 44, Train Loss: 1.2706, Val Loss: 1.6817, F1 Micro: 0.4167, F1 Macro: 0.3999, Accuracy: 0.4167\n","Epoch 45, Train Loss: 1.2430, Val Loss: 1.7193, F1 Micro: 0.4271, F1 Macro: 0.4219, Accuracy: 0.4271\n","Epoch 46, Train Loss: 1.2511, Val Loss: 1.8188, F1 Micro: 0.3646, F1 Macro: 0.3338, Accuracy: 0.3646\n","Epoch 47, Train Loss: 1.2094, Val Loss: 1.6002, F1 Micro: 0.4375, F1 Macro: 0.4341, Accuracy: 0.4375\n","Epoch 48, Train Loss: 1.2097, Val Loss: 1.7879, F1 Micro: 0.3333, F1 Macro: 0.3139, Accuracy: 0.3333\n","Epoch 49, Train Loss: 1.2115, Val Loss: 1.8110, F1 Micro: 0.3438, F1 Macro: 0.2862, Accuracy: 0.3438\n","Epoch 50, Train Loss: 1.2248, Val Loss: 1.7838, F1 Micro: 0.4062, F1 Macro: 0.3724, Accuracy: 0.4062\n","Epoch 51, Train Loss: 1.2376, Val Loss: 1.6841, F1 Micro: 0.4271, F1 Macro: 0.4151, Accuracy: 0.4271\n","Epoch 52, Train Loss: 1.2225, Val Loss: 1.6801, F1 Micro: 0.4479, F1 Macro: 0.4367, Accuracy: 0.4479\n","Epoch 53, Train Loss: 1.1958, Val Loss: 1.6959, F1 Micro: 0.4271, F1 Macro: 0.4231, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.1718, Val Loss: 1.7845, F1 Micro: 0.3958, F1 Macro: 0.3626, Accuracy: 0.3958\n","Epoch 55, Train Loss: 1.1905, Val Loss: 1.8191, F1 Micro: 0.3438, F1 Macro: 0.2831, Accuracy: 0.3438\n","Epoch 56, Train Loss: 1.1779, Val Loss: 1.7731, F1 Micro: 0.3438, F1 Macro: 0.3285, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.1746, Val Loss: 1.6723, F1 Micro: 0.4271, F1 Macro: 0.4084, Accuracy: 0.4271\n","Epoch 58, Train Loss: 1.1878, Val Loss: 2.0388, F1 Micro: 0.3229, F1 Macro: 0.2789, Accuracy: 0.3229\n","Epoch 59, Train Loss: 1.1279, Val Loss: 1.6694, F1 Micro: 0.4271, F1 Macro: 0.4372, Accuracy: 0.4271\n","Epoch 60, Train Loss: 1.1626, Val Loss: 1.6416, F1 Micro: 0.3750, F1 Macro: 0.3413, Accuracy: 0.3750\n","Epoch 61, Train Loss: 1.1325, Val Loss: 1.5664, F1 Micro: 0.4583, F1 Macro: 0.4721, Accuracy: 0.4583\n","Epoch 62, Train Loss: 1.1518, Val Loss: 1.6954, F1 Micro: 0.3958, F1 Macro: 0.4017, Accuracy: 0.3958\n","Epoch 63, Train Loss: 1.1601, Val Loss: 1.7787, F1 Micro: 0.3750, F1 Macro: 0.3822, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.1399, Val Loss: 1.7673, F1 Micro: 0.4375, F1 Macro: 0.4162, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.1444, Val Loss: 1.5784, F1 Micro: 0.4896, F1 Macro: 0.4898, Accuracy: 0.4896\n","Epoch 66, Train Loss: 1.1062, Val Loss: 1.6508, F1 Micro: 0.4271, F1 Macro: 0.4092, Accuracy: 0.4271\n","Epoch 67, Train Loss: 1.0947, Val Loss: 1.7746, F1 Micro: 0.4583, F1 Macro: 0.4532, Accuracy: 0.4583\n","Epoch 68, Train Loss: 1.0857, Val Loss: 1.8706, F1 Micro: 0.4167, F1 Macro: 0.4147, Accuracy: 0.4167\n","Epoch 69, Train Loss: 1.1346, Val Loss: 1.6489, F1 Micro: 0.4375, F1 Macro: 0.4383, Accuracy: 0.4375\n","Epoch 70, Train Loss: 1.1414, Val Loss: 1.5944, F1 Micro: 0.5104, F1 Macro: 0.4657, Accuracy: 0.5104\n","Epoch 71, Train Loss: 1.0931, Val Loss: 1.6537, F1 Micro: 0.3958, F1 Macro: 0.3463, Accuracy: 0.3958\n","Epoch 72, Train Loss: 1.1162, Val Loss: 1.5363, F1 Micro: 0.5000, F1 Macro: 0.4963, Accuracy: 0.5000\n","Epoch 73, Train Loss: 1.0518, Val Loss: 1.6664, F1 Micro: 0.4167, F1 Macro: 0.3908, Accuracy: 0.4167\n","Epoch 74, Train Loss: 1.0766, Val Loss: 1.6119, F1 Micro: 0.4583, F1 Macro: 0.4616, Accuracy: 0.4583\n","Epoch 75, Train Loss: 1.0727, Val Loss: 1.9574, F1 Micro: 0.3750, F1 Macro: 0.3633, Accuracy: 0.3750\n","Epoch 76, Train Loss: 1.1071, Val Loss: 1.7795, F1 Micro: 0.3854, F1 Macro: 0.3486, Accuracy: 0.3854\n","Epoch 77, Train Loss: 1.1009, Val Loss: 1.6793, F1 Micro: 0.4792, F1 Macro: 0.4737, Accuracy: 0.4792\n","Epoch 78, Train Loss: 1.0862, Val Loss: 1.6442, F1 Micro: 0.4792, F1 Macro: 0.4625, Accuracy: 0.4792\n","Epoch 79, Train Loss: 1.0382, Val Loss: 1.8632, F1 Micro: 0.3750, F1 Macro: 0.3477, Accuracy: 0.3750\n","Epoch 80, Train Loss: 1.1028, Val Loss: 1.6579, F1 Micro: 0.4583, F1 Macro: 0.3884, Accuracy: 0.4583\n","Epoch 81, Train Loss: 1.0546, Val Loss: 1.6945, F1 Micro: 0.4375, F1 Macro: 0.4374, Accuracy: 0.4375\n","Epoch 82, Train Loss: 1.0361, Val Loss: 1.6098, F1 Micro: 0.4375, F1 Macro: 0.4311, Accuracy: 0.4375\n","Epoch 83, Train Loss: 1.0609, Val Loss: 1.6988, F1 Micro: 0.4271, F1 Macro: 0.4049, Accuracy: 0.4271\n","Epoch 84, Train Loss: 0.9784, Val Loss: 1.6154, F1 Micro: 0.4896, F1 Macro: 0.4966, Accuracy: 0.4896\n","Epoch 85, Train Loss: 1.0075, Val Loss: 1.8635, F1 Micro: 0.4583, F1 Macro: 0.4002, Accuracy: 0.4583\n","Epoch 86, Train Loss: 1.0309, Val Loss: 1.6939, F1 Micro: 0.4792, F1 Macro: 0.4839, Accuracy: 0.4792\n","Epoch 87, Train Loss: 1.0859, Val Loss: 1.7923, F1 Micro: 0.4479, F1 Macro: 0.4562, Accuracy: 0.4479\n","Epoch 88, Train Loss: 1.0600, Val Loss: 1.6205, F1 Micro: 0.5000, F1 Macro: 0.5023, Accuracy: 0.5000\n","Epoch 89, Train Loss: 1.0367, Val Loss: 1.7549, F1 Micro: 0.4271, F1 Macro: 0.4324, Accuracy: 0.4271\n","Epoch 90, Train Loss: 0.9739, Val Loss: 1.5488, F1 Micro: 0.4688, F1 Macro: 0.4740, Accuracy: 0.4688\n","Epoch 91, Train Loss: 0.9789, Val Loss: 1.6117, F1 Micro: 0.5104, F1 Macro: 0.4930, Accuracy: 0.5104\n","Epoch 92, Train Loss: 1.0257, Val Loss: 1.7042, F1 Micro: 0.4896, F1 Macro: 0.4873, Accuracy: 0.4896\n","Epoch 93, Train Loss: 1.0063, Val Loss: 1.6816, F1 Micro: 0.4479, F1 Macro: 0.4251, Accuracy: 0.4479\n","Epoch 94, Train Loss: 1.0288, Val Loss: 1.6769, F1 Micro: 0.4271, F1 Macro: 0.3920, Accuracy: 0.4271\n","Epoch 95, Train Loss: 1.0075, Val Loss: 1.6983, F1 Micro: 0.4688, F1 Macro: 0.4403, Accuracy: 0.4688\n","Epoch 96, Train Loss: 1.0774, Val Loss: 1.5711, F1 Micro: 0.4583, F1 Macro: 0.4568, Accuracy: 0.4583\n","Epoch 97, Train Loss: 0.9934, Val Loss: 1.6905, F1 Micro: 0.4271, F1 Macro: 0.4374, Accuracy: 0.4271\n","Epoch 98, Train Loss: 1.0259, Val Loss: 1.6458, F1 Micro: 0.4479, F1 Macro: 0.4531, Accuracy: 0.4479\n","Epoch 99, Train Loss: 0.9969, Val Loss: 1.6072, F1 Micro: 0.4896, F1 Macro: 0.4850, Accuracy: 0.4896\n","Epoch 100, Train Loss: 0.9436, Val Loss: 1.8859, F1 Micro: 0.3958, F1 Macro: 0.3945, Accuracy: 0.3958\n","Epoch 101, Train Loss: 1.0136, Val Loss: 1.5755, F1 Micro: 0.4896, F1 Macro: 0.4866, Accuracy: 0.4896\n","Epoch 102, Train Loss: 0.9550, Val Loss: 1.7290, F1 Micro: 0.5208, F1 Macro: 0.4998, Accuracy: 0.5208\n","Epoch 103, Train Loss: 0.9555, Val Loss: 1.6237, F1 Micro: 0.4792, F1 Macro: 0.4748, Accuracy: 0.4792\n","Epoch 104, Train Loss: 0.9498, Val Loss: 1.5461, F1 Micro: 0.5000, F1 Macro: 0.5091, Accuracy: 0.5000\n","Epoch 105, Train Loss: 0.9457, Val Loss: 1.9677, F1 Micro: 0.4479, F1 Macro: 0.4245, Accuracy: 0.4479\n","Epoch 106, Train Loss: 0.9980, Val Loss: 1.8616, F1 Micro: 0.4271, F1 Macro: 0.3857, Accuracy: 0.4271\n","Epoch 107, Train Loss: 0.9506, Val Loss: 1.8243, F1 Micro: 0.4271, F1 Macro: 0.3667, Accuracy: 0.4271\n","Epoch 108, Train Loss: 0.9913, Val Loss: 1.9102, F1 Micro: 0.4271, F1 Macro: 0.3699, Accuracy: 0.4271\n","Epoch 109, Train Loss: 0.9518, Val Loss: 2.2482, F1 Micro: 0.3646, F1 Macro: 0.3427, Accuracy: 0.3646\n","Epoch 110, Train Loss: 0.9733, Val Loss: 1.5694, F1 Micro: 0.4896, F1 Macro: 0.4983, Accuracy: 0.4896\n","Epoch 111, Train Loss: 0.9526, Val Loss: 1.8973, F1 Micro: 0.3854, F1 Macro: 0.3732, Accuracy: 0.3854\n","Epoch 112, Train Loss: 0.9020, Val Loss: 1.7323, F1 Micro: 0.4479, F1 Macro: 0.4397, Accuracy: 0.4479\n","Epoch 113, Train Loss: 0.9303, Val Loss: 1.5555, F1 Micro: 0.5521, F1 Macro: 0.5397, Accuracy: 0.5521\n","Epoch 114, Train Loss: 0.9360, Val Loss: 1.7065, F1 Micro: 0.4792, F1 Macro: 0.4368, Accuracy: 0.4792\n","Epoch 115, Train Loss: 0.9454, Val Loss: 1.6283, F1 Micro: 0.5208, F1 Macro: 0.5287, Accuracy: 0.5208\n","Epoch 116, Train Loss: 0.9222, Val Loss: 1.5980, F1 Micro: 0.5000, F1 Macro: 0.4687, Accuracy: 0.5000\n","Epoch 117, Train Loss: 0.9660, Val Loss: 1.6511, F1 Micro: 0.4375, F1 Macro: 0.4087, Accuracy: 0.4375\n","Epoch 118, Train Loss: 0.9663, Val Loss: 1.5132, F1 Micro: 0.5312, F1 Macro: 0.5322, Accuracy: 0.5312\n","Epoch 119, Train Loss: 0.9259, Val Loss: 1.5328, F1 Micro: 0.5208, F1 Macro: 0.4915, Accuracy: 0.5208\n","Epoch 120, Train Loss: 0.9292, Val Loss: 1.7589, F1 Micro: 0.4583, F1 Macro: 0.4587, Accuracy: 0.4583\n","Epoch 121, Train Loss: 0.9545, Val Loss: 1.5975, F1 Micro: 0.5625, F1 Macro: 0.5637, Accuracy: 0.5625\n","Epoch 122, Train Loss: 0.8904, Val Loss: 1.5127, F1 Micro: 0.5625, F1 Macro: 0.5483, Accuracy: 0.5625\n","Epoch 123, Train Loss: 0.9089, Val Loss: 1.6202, F1 Micro: 0.5104, F1 Macro: 0.4985, Accuracy: 0.5104\n","Epoch 124, Train Loss: 0.8872, Val Loss: 2.0741, F1 Micro: 0.3750, F1 Macro: 0.3576, Accuracy: 0.3750\n","Epoch 125, Train Loss: 0.9441, Val Loss: 2.0104, F1 Micro: 0.4479, F1 Macro: 0.4390, Accuracy: 0.4479\n","Epoch 126, Train Loss: 0.9969, Val Loss: 1.5639, F1 Micro: 0.5417, F1 Macro: 0.5111, Accuracy: 0.5417\n","Epoch 127, Train Loss: 0.9321, Val Loss: 1.6837, F1 Micro: 0.5208, F1 Macro: 0.5262, Accuracy: 0.5208\n","Epoch 128, Train Loss: 0.9086, Val Loss: 1.7843, F1 Micro: 0.4688, F1 Macro: 0.4301, Accuracy: 0.4688\n","Epoch 129, Train Loss: 0.9426, Val Loss: 1.6326, F1 Micro: 0.4583, F1 Macro: 0.4487, Accuracy: 0.4583\n","Epoch 130, Train Loss: 0.9263, Val Loss: 1.5479, F1 Micro: 0.5521, F1 Macro: 0.5592, Accuracy: 0.5521\n","Epoch 131, Train Loss: 0.9460, Val Loss: 1.6444, F1 Micro: 0.4271, F1 Macro: 0.4155, Accuracy: 0.4271\n","Epoch 132, Train Loss: 0.9075, Val Loss: 1.8763, F1 Micro: 0.4479, F1 Macro: 0.4050, Accuracy: 0.4479\n","Epoch 133, Train Loss: 0.8990, Val Loss: 1.5853, F1 Micro: 0.5104, F1 Macro: 0.5065, Accuracy: 0.5104\n","Epoch 134, Train Loss: 0.9264, Val Loss: 1.5985, F1 Micro: 0.4688, F1 Macro: 0.4656, Accuracy: 0.4688\n","Epoch 135, Train Loss: 0.9018, Val Loss: 1.5547, F1 Micro: 0.5000, F1 Macro: 0.5056, Accuracy: 0.5000\n","Epoch 136, Train Loss: 0.8506, Val Loss: 1.5534, F1 Micro: 0.5312, F1 Macro: 0.5352, Accuracy: 0.5312\n","Epoch 137, Train Loss: 0.8808, Val Loss: 1.5318, F1 Micro: 0.5104, F1 Macro: 0.5191, Accuracy: 0.5104\n","Epoch 138, Train Loss: 0.8651, Val Loss: 1.5097, F1 Micro: 0.5312, F1 Macro: 0.5348, Accuracy: 0.5312\n","Epoch 139, Train Loss: 0.9063, Val Loss: 2.1290, F1 Micro: 0.4167, F1 Macro: 0.3860, Accuracy: 0.4167\n","Epoch 140, Train Loss: 0.9093, Val Loss: 1.8540, F1 Micro: 0.4375, F1 Macro: 0.4221, Accuracy: 0.4375\n","Epoch 141, Train Loss: 0.9005, Val Loss: 1.5597, F1 Micro: 0.5000, F1 Macro: 0.4936, Accuracy: 0.5000\n","Epoch 142, Train Loss: 0.8380, Val Loss: 1.5290, F1 Micro: 0.5417, F1 Macro: 0.5245, Accuracy: 0.5417\n","Epoch 143, Train Loss: 0.8380, Val Loss: 1.7312, F1 Micro: 0.5104, F1 Macro: 0.5285, Accuracy: 0.5104\n","Epoch 144, Train Loss: 0.8596, Val Loss: 1.6348, F1 Micro: 0.4896, F1 Macro: 0.4702, Accuracy: 0.4896\n","Epoch 145, Train Loss: 0.9043, Val Loss: 1.5482, F1 Micro: 0.5312, F1 Macro: 0.5354, Accuracy: 0.5312\n","Epoch 146, Train Loss: 0.8669, Val Loss: 2.0233, F1 Micro: 0.4583, F1 Macro: 0.4248, Accuracy: 0.4583\n","Epoch 147, Train Loss: 0.8756, Val Loss: 1.7145, F1 Micro: 0.4583, F1 Macro: 0.4465, Accuracy: 0.4583\n","Epoch 148, Train Loss: 0.8275, Val Loss: 1.7408, F1 Micro: 0.5208, F1 Macro: 0.4736, Accuracy: 0.5208\n","Epoch 149, Train Loss: 0.8939, Val Loss: 1.7743, F1 Micro: 0.4896, F1 Macro: 0.4633, Accuracy: 0.4896\n","Epoch 150, Train Loss: 0.8388, Val Loss: 1.4982, F1 Micro: 0.5729, F1 Macro: 0.5756, Accuracy: 0.5729\n","Epoch 151, Train Loss: 0.8411, Val Loss: 1.6903, F1 Micro: 0.5104, F1 Macro: 0.5084, Accuracy: 0.5104\n","Epoch 152, Train Loss: 0.8550, Val Loss: 1.7628, F1 Micro: 0.4479, F1 Macro: 0.4289, Accuracy: 0.4479\n","Epoch 153, Train Loss: 0.8772, Val Loss: 1.5078, F1 Micro: 0.5104, F1 Macro: 0.5068, Accuracy: 0.5104\n","Epoch 154, Train Loss: 0.8555, Val Loss: 1.7043, F1 Micro: 0.4479, F1 Macro: 0.4033, Accuracy: 0.4479\n","Epoch 155, Train Loss: 0.8454, Val Loss: 1.6337, F1 Micro: 0.5417, F1 Macro: 0.5453, Accuracy: 0.5417\n","Epoch 156, Train Loss: 0.8609, Val Loss: 1.7024, F1 Micro: 0.4896, F1 Macro: 0.4743, Accuracy: 0.4896\n","Epoch 157, Train Loss: 0.8548, Val Loss: 1.7880, F1 Micro: 0.5104, F1 Macro: 0.5106, Accuracy: 0.5104\n","Epoch 158, Train Loss: 0.8518, Val Loss: 1.6221, F1 Micro: 0.4375, F1 Macro: 0.3863, Accuracy: 0.4375\n","Epoch 159, Train Loss: 0.8383, Val Loss: 1.6006, F1 Micro: 0.5312, F1 Macro: 0.5460, Accuracy: 0.5312\n","Epoch 160, Train Loss: 0.7617, Val Loss: 1.7789, F1 Micro: 0.5000, F1 Macro: 0.4309, Accuracy: 0.5000\n","Epoch 161, Train Loss: 0.7975, Val Loss: 1.8082, F1 Micro: 0.4792, F1 Macro: 0.4764, Accuracy: 0.4792\n","Epoch 162, Train Loss: 0.7867, Val Loss: 1.5755, F1 Micro: 0.5312, F1 Macro: 0.5277, Accuracy: 0.5312\n","Epoch 163, Train Loss: 0.8165, Val Loss: 1.5931, F1 Micro: 0.5208, F1 Macro: 0.5278, Accuracy: 0.5208\n","Epoch 164, Train Loss: 0.8381, Val Loss: 1.8252, F1 Micro: 0.4167, F1 Macro: 0.3851, Accuracy: 0.4167\n","Epoch 165, Train Loss: 0.8287, Val Loss: 1.8983, F1 Micro: 0.4167, F1 Macro: 0.4155, Accuracy: 0.4167\n","Epoch 166, Train Loss: 0.8196, Val Loss: 1.5928, F1 Micro: 0.5104, F1 Macro: 0.5009, Accuracy: 0.5104\n","Epoch 167, Train Loss: 0.7760, Val Loss: 1.5900, F1 Micro: 0.5417, F1 Macro: 0.5439, Accuracy: 0.5417\n","Epoch 168, Train Loss: 0.7943, Val Loss: 1.5348, F1 Micro: 0.5312, F1 Macro: 0.5356, Accuracy: 0.5312\n","Epoch 169, Train Loss: 0.8116, Val Loss: 1.7032, F1 Micro: 0.4792, F1 Macro: 0.4840, Accuracy: 0.4792\n","Epoch 170, Train Loss: 0.7774, Val Loss: 1.8344, F1 Micro: 0.4688, F1 Macro: 0.4370, Accuracy: 0.4688\n","Epoch 171, Train Loss: 0.8168, Val Loss: 1.6401, F1 Micro: 0.5625, F1 Macro: 0.5285, Accuracy: 0.5625\n","Epoch 172, Train Loss: 0.8261, Val Loss: 2.2089, F1 Micro: 0.4375, F1 Macro: 0.3992, Accuracy: 0.4375\n","Epoch 173, Train Loss: 0.8177, Val Loss: 1.5792, F1 Micro: 0.4896, F1 Macro: 0.4766, Accuracy: 0.4896\n","Epoch 174, Train Loss: 0.8409, Val Loss: 1.7771, F1 Micro: 0.4583, F1 Macro: 0.4236, Accuracy: 0.4583\n","Epoch 175, Train Loss: 0.8501, Val Loss: 1.5200, F1 Micro: 0.5938, F1 Macro: 0.5957, Accuracy: 0.5938\n","Epoch 176, Train Loss: 0.8251, Val Loss: 2.2771, F1 Micro: 0.3958, F1 Macro: 0.3788, Accuracy: 0.3958\n","Epoch 177, Train Loss: 0.8100, Val Loss: 1.7958, F1 Micro: 0.4792, F1 Macro: 0.4644, Accuracy: 0.4792\n","Epoch 178, Train Loss: 0.8134, Val Loss: 1.7266, F1 Micro: 0.4896, F1 Macro: 0.4705, Accuracy: 0.4896\n","Epoch 179, Train Loss: 0.8141, Val Loss: 1.7570, F1 Micro: 0.4583, F1 Macro: 0.4117, Accuracy: 0.4583\n","Epoch 180, Train Loss: 0.7969, Val Loss: 1.5458, F1 Micro: 0.5521, F1 Macro: 0.5352, Accuracy: 0.5521\n","Epoch 181, Train Loss: 0.8174, Val Loss: 1.7434, F1 Micro: 0.4271, F1 Macro: 0.3874, Accuracy: 0.4271\n","Epoch 182, Train Loss: 0.7854, Val Loss: 1.7192, F1 Micro: 0.4688, F1 Macro: 0.4212, Accuracy: 0.4688\n","Epoch 183, Train Loss: 0.7923, Val Loss: 1.6377, F1 Micro: 0.5208, F1 Macro: 0.4966, Accuracy: 0.5208\n","Epoch 184, Train Loss: 0.7620, Val Loss: 1.5951, F1 Micro: 0.5417, F1 Macro: 0.5254, Accuracy: 0.5417\n","Epoch 185, Train Loss: 0.7708, Val Loss: 1.7173, F1 Micro: 0.4688, F1 Macro: 0.4874, Accuracy: 0.4688\n","Epoch 186, Train Loss: 0.7723, Val Loss: 1.6379, F1 Micro: 0.5417, F1 Macro: 0.5352, Accuracy: 0.5417\n","Epoch 187, Train Loss: 0.7554, Val Loss: 1.7411, F1 Micro: 0.4896, F1 Macro: 0.4630, Accuracy: 0.4896\n","Epoch 188, Train Loss: 0.7667, Val Loss: 1.7641, F1 Micro: 0.4583, F1 Macro: 0.4611, Accuracy: 0.4583\n","Epoch 189, Train Loss: 0.7043, Val Loss: 1.5934, F1 Micro: 0.5000, F1 Macro: 0.4963, Accuracy: 0.5000\n","Epoch 190, Train Loss: 0.8310, Val Loss: 1.9007, F1 Micro: 0.5000, F1 Macro: 0.4862, Accuracy: 0.5000\n","Epoch 191, Train Loss: 0.8475, Val Loss: 1.8705, F1 Micro: 0.4896, F1 Macro: 0.5019, Accuracy: 0.4896\n","Epoch 192, Train Loss: 0.7968, Val Loss: 1.9733, F1 Micro: 0.3958, F1 Macro: 0.3867, Accuracy: 0.3958\n","Epoch 193, Train Loss: 0.7927, Val Loss: 2.1225, F1 Micro: 0.3542, F1 Macro: 0.3214, Accuracy: 0.3542\n","Epoch 194, Train Loss: 0.7884, Val Loss: 1.9684, F1 Micro: 0.4479, F1 Macro: 0.4224, Accuracy: 0.4479\n","Epoch 195, Train Loss: 0.7904, Val Loss: 1.9997, F1 Micro: 0.4167, F1 Macro: 0.4084, Accuracy: 0.4167\n","Epoch 196, Train Loss: 0.8304, Val Loss: 2.2930, F1 Micro: 0.3646, F1 Macro: 0.3425, Accuracy: 0.3646\n","Epoch 197, Train Loss: 0.8220, Val Loss: 1.6528, F1 Micro: 0.5208, F1 Macro: 0.5021, Accuracy: 0.5208\n","Epoch 198, Train Loss: 0.7712, Val Loss: 1.5623, F1 Micro: 0.5729, F1 Macro: 0.5847, Accuracy: 0.5729\n","Epoch 199, Train Loss: 0.7320, Val Loss: 1.6854, F1 Micro: 0.4479, F1 Macro: 0.4341, Accuracy: 0.4479\n","Epoch 200, Train Loss: 0.7780, Val Loss: 2.0514, F1 Micro: 0.4688, F1 Macro: 0.4245, Accuracy: 0.4688\n","Average Score for hyperparameters (0.001, 16, 50): 0.5979166666666667\n","Best hyperparameters for Outer FOLD 4: (0.01, 16, 50) with score 0.6479166666666667\n","Epoch 1, Train Loss: 2.0146, Val Loss: 2.2119, F1 Micro: 0.2500, F1 Macro: 0.2050, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.8616, Val Loss: 1.9445, F1 Micro: 0.2833, F1 Macro: 0.2297, Accuracy: 0.2833\n","Epoch 3, Train Loss: 1.8002, Val Loss: 1.7871, F1 Micro: 0.2750, F1 Macro: 0.2052, Accuracy: 0.2750\n","Epoch 4, Train Loss: 1.6995, Val Loss: 1.8009, F1 Micro: 0.2583, F1 Macro: 0.1880, Accuracy: 0.2583\n","Epoch 5, Train Loss: 1.6475, Val Loss: 1.7703, F1 Micro: 0.3750, F1 Macro: 0.3109, Accuracy: 0.3750\n","Epoch 6, Train Loss: 1.6098, Val Loss: 1.7115, F1 Micro: 0.3333, F1 Macro: 0.2750, Accuracy: 0.3333\n","Epoch 7, Train Loss: 1.6725, Val Loss: 1.8394, F1 Micro: 0.3333, F1 Macro: 0.2622, Accuracy: 0.3333\n","Epoch 8, Train Loss: 1.5523, Val Loss: 1.8520, F1 Micro: 0.2750, F1 Macro: 0.2390, Accuracy: 0.2750\n","Epoch 9, Train Loss: 1.5897, Val Loss: 1.8090, F1 Micro: 0.3167, F1 Macro: 0.2471, Accuracy: 0.3167\n","Epoch 10, Train Loss: 1.6123, Val Loss: 1.7543, F1 Micro: 0.4083, F1 Macro: 0.3768, Accuracy: 0.4083\n","Epoch 11, Train Loss: 1.5253, Val Loss: 1.7610, F1 Micro: 0.3333, F1 Macro: 0.2926, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.4772, Val Loss: 1.6312, F1 Micro: 0.3333, F1 Macro: 0.2947, Accuracy: 0.3333\n","Epoch 13, Train Loss: 1.5282, Val Loss: 1.7745, F1 Micro: 0.3750, F1 Macro: 0.3425, Accuracy: 0.3750\n","Epoch 14, Train Loss: 1.4728, Val Loss: 1.7229, F1 Micro: 0.3417, F1 Macro: 0.3064, Accuracy: 0.3417\n","Epoch 15, Train Loss: 1.4668, Val Loss: 1.8049, F1 Micro: 0.3000, F1 Macro: 0.2178, Accuracy: 0.3000\n","Epoch 16, Train Loss: 1.4623, Val Loss: 1.7088, F1 Micro: 0.4083, F1 Macro: 0.3459, Accuracy: 0.4083\n","Epoch 17, Train Loss: 1.4082, Val Loss: 1.7503, F1 Micro: 0.3750, F1 Macro: 0.3071, Accuracy: 0.3750\n","Epoch 18, Train Loss: 1.3845, Val Loss: 1.8051, F1 Micro: 0.3167, F1 Macro: 0.2771, Accuracy: 0.3167\n","Epoch 19, Train Loss: 1.4079, Val Loss: 1.7356, F1 Micro: 0.3917, F1 Macro: 0.3578, Accuracy: 0.3917\n","Epoch 20, Train Loss: 1.3785, Val Loss: 1.6495, F1 Micro: 0.3167, F1 Macro: 0.2733, Accuracy: 0.3167\n","Epoch 21, Train Loss: 1.3726, Val Loss: 1.6011, F1 Micro: 0.4167, F1 Macro: 0.3968, Accuracy: 0.4167\n","Epoch 22, Train Loss: 1.3373, Val Loss: 1.5652, F1 Micro: 0.4583, F1 Macro: 0.3709, Accuracy: 0.4583\n","Epoch 23, Train Loss: 1.3432, Val Loss: 1.7114, F1 Micro: 0.3500, F1 Macro: 0.3382, Accuracy: 0.3500\n","Epoch 24, Train Loss: 1.3771, Val Loss: 1.5893, F1 Micro: 0.4167, F1 Macro: 0.3937, Accuracy: 0.4167\n","Epoch 25, Train Loss: 1.3601, Val Loss: 1.7318, F1 Micro: 0.2667, F1 Macro: 0.2450, Accuracy: 0.2667\n","Epoch 26, Train Loss: 1.3077, Val Loss: 1.6535, F1 Micro: 0.4000, F1 Macro: 0.3708, Accuracy: 0.4000\n","Epoch 27, Train Loss: 1.3060, Val Loss: 2.0964, F1 Micro: 0.3167, F1 Macro: 0.1979, Accuracy: 0.3167\n","Epoch 28, Train Loss: 1.2990, Val Loss: 1.4404, F1 Micro: 0.4500, F1 Macro: 0.4536, Accuracy: 0.4500\n","Epoch 29, Train Loss: 1.2781, Val Loss: 1.6171, F1 Micro: 0.4167, F1 Macro: 0.3454, Accuracy: 0.4167\n","Epoch 30, Train Loss: 1.2451, Val Loss: 2.3408, F1 Micro: 0.3833, F1 Macro: 0.3002, Accuracy: 0.3833\n","Epoch 31, Train Loss: 1.2731, Val Loss: 1.3648, F1 Micro: 0.5500, F1 Macro: 0.5124, Accuracy: 0.5500\n","Epoch 32, Train Loss: 1.2216, Val Loss: 1.6414, F1 Micro: 0.3917, F1 Macro: 0.3461, Accuracy: 0.3917\n","Epoch 33, Train Loss: 1.2377, Val Loss: 1.5566, F1 Micro: 0.4417, F1 Macro: 0.3960, Accuracy: 0.4417\n","Epoch 34, Train Loss: 1.2926, Val Loss: 1.9057, F1 Micro: 0.4250, F1 Macro: 0.4311, Accuracy: 0.4250\n","Epoch 35, Train Loss: 1.1920, Val Loss: 1.5267, F1 Micro: 0.4833, F1 Macro: 0.4548, Accuracy: 0.4833\n","Epoch 36, Train Loss: 1.1807, Val Loss: 1.8356, F1 Micro: 0.3667, F1 Macro: 0.3294, Accuracy: 0.3667\n","Epoch 37, Train Loss: 1.1367, Val Loss: 1.4818, F1 Micro: 0.4917, F1 Macro: 0.4737, Accuracy: 0.4917\n","Epoch 38, Train Loss: 1.1173, Val Loss: 1.7679, F1 Micro: 0.3417, F1 Macro: 0.3034, Accuracy: 0.3417\n","Epoch 39, Train Loss: 1.1621, Val Loss: 1.5834, F1 Micro: 0.4750, F1 Macro: 0.4609, Accuracy: 0.4750\n","Epoch 40, Train Loss: 1.1133, Val Loss: 1.8114, F1 Micro: 0.4250, F1 Macro: 0.3945, Accuracy: 0.4250\n","Epoch 41, Train Loss: 1.1239, Val Loss: 1.6659, F1 Micro: 0.4333, F1 Macro: 0.4075, Accuracy: 0.4333\n","Epoch 42, Train Loss: 1.1712, Val Loss: 3.1118, F1 Micro: 0.3167, F1 Macro: 0.2888, Accuracy: 0.3167\n","Epoch 43, Train Loss: 1.1060, Val Loss: 1.8108, F1 Micro: 0.4667, F1 Macro: 0.4155, Accuracy: 0.4667\n","Epoch 44, Train Loss: 1.0087, Val Loss: 1.5848, F1 Micro: 0.4167, F1 Macro: 0.4117, Accuracy: 0.4167\n","Epoch 45, Train Loss: 1.0483, Val Loss: 1.7420, F1 Micro: 0.4417, F1 Macro: 0.3955, Accuracy: 0.4417\n","Epoch 46, Train Loss: 1.0304, Val Loss: 1.7985, F1 Micro: 0.4167, F1 Macro: 0.3489, Accuracy: 0.4167\n","Epoch 47, Train Loss: 1.0916, Val Loss: 1.6127, F1 Micro: 0.3667, F1 Macro: 0.3652, Accuracy: 0.3667\n","Epoch 48, Train Loss: 1.0560, Val Loss: 2.0528, F1 Micro: 0.3833, F1 Macro: 0.3725, Accuracy: 0.3833\n","Epoch 49, Train Loss: 1.1550, Val Loss: 1.4946, F1 Micro: 0.5750, F1 Macro: 0.5719, Accuracy: 0.5750\n","Epoch 50, Train Loss: 0.9883, Val Loss: 1.8392, F1 Micro: 0.3917, F1 Macro: 0.3699, Accuracy: 0.3917\n","Epoch 51, Train Loss: 1.0460, Val Loss: 1.8065, F1 Micro: 0.4667, F1 Macro: 0.4330, Accuracy: 0.4667\n","Epoch 52, Train Loss: 1.0444, Val Loss: 2.3224, F1 Micro: 0.4500, F1 Macro: 0.4315, Accuracy: 0.4500\n","Epoch 53, Train Loss: 1.0955, Val Loss: 2.0754, F1 Micro: 0.3667, F1 Macro: 0.3282, Accuracy: 0.3667\n","Epoch 54, Train Loss: 1.0470, Val Loss: 1.8399, F1 Micro: 0.3500, F1 Macro: 0.3469, Accuracy: 0.3500\n","Epoch 55, Train Loss: 1.1271, Val Loss: 2.2752, F1 Micro: 0.3083, F1 Macro: 0.2456, Accuracy: 0.3083\n","Epoch 56, Train Loss: 1.1087, Val Loss: 1.7534, F1 Micro: 0.5000, F1 Macro: 0.4479, Accuracy: 0.5000\n","Epoch 57, Train Loss: 0.9735, Val Loss: 1.4286, F1 Micro: 0.4500, F1 Macro: 0.4289, Accuracy: 0.4500\n","Epoch 58, Train Loss: 0.9560, Val Loss: 1.4368, F1 Micro: 0.5583, F1 Macro: 0.5629, Accuracy: 0.5583\n","Epoch 59, Train Loss: 0.9411, Val Loss: 1.5539, F1 Micro: 0.5167, F1 Macro: 0.4961, Accuracy: 0.5167\n","Epoch 60, Train Loss: 0.9907, Val Loss: 2.3486, F1 Micro: 0.3250, F1 Macro: 0.2611, Accuracy: 0.3250\n","Epoch 61, Train Loss: 0.8998, Val Loss: 1.7141, F1 Micro: 0.3583, F1 Macro: 0.3396, Accuracy: 0.3583\n","Epoch 62, Train Loss: 0.9955, Val Loss: 1.6595, F1 Micro: 0.5000, F1 Macro: 0.4974, Accuracy: 0.5000\n","Epoch 63, Train Loss: 0.9184, Val Loss: 1.7144, F1 Micro: 0.4667, F1 Macro: 0.3984, Accuracy: 0.4667\n","Epoch 64, Train Loss: 0.9926, Val Loss: 2.4743, F1 Micro: 0.3667, F1 Macro: 0.3339, Accuracy: 0.3667\n","Epoch 65, Train Loss: 0.9788, Val Loss: 1.4916, F1 Micro: 0.4500, F1 Macro: 0.4254, Accuracy: 0.4500\n","Epoch 66, Train Loss: 1.0140, Val Loss: 1.6387, F1 Micro: 0.4000, F1 Macro: 0.3367, Accuracy: 0.4000\n","Epoch 67, Train Loss: 0.9369, Val Loss: 1.6941, F1 Micro: 0.4250, F1 Macro: 0.4104, Accuracy: 0.4250\n","Epoch 68, Train Loss: 0.8774, Val Loss: 1.7792, F1 Micro: 0.3917, F1 Macro: 0.3755, Accuracy: 0.3917\n","Epoch 69, Train Loss: 0.8861, Val Loss: 1.7551, F1 Micro: 0.4917, F1 Macro: 0.4690, Accuracy: 0.4917\n","Epoch 70, Train Loss: 0.8448, Val Loss: 1.7398, F1 Micro: 0.5083, F1 Macro: 0.4795, Accuracy: 0.5083\n","Epoch 71, Train Loss: 0.8932, Val Loss: 1.7309, F1 Micro: 0.4667, F1 Macro: 0.4333, Accuracy: 0.4667\n","Epoch 72, Train Loss: 0.9492, Val Loss: 1.9482, F1 Micro: 0.4167, F1 Macro: 0.4246, Accuracy: 0.4167\n","Epoch 73, Train Loss: 0.9063, Val Loss: 2.0567, F1 Micro: 0.4500, F1 Macro: 0.4206, Accuracy: 0.4500\n","Epoch 74, Train Loss: 0.9197, Val Loss: 1.4762, F1 Micro: 0.4917, F1 Macro: 0.4787, Accuracy: 0.4917\n","Epoch 75, Train Loss: 0.9144, Val Loss: 1.7253, F1 Micro: 0.4500, F1 Macro: 0.4483, Accuracy: 0.4500\n","Epoch 76, Train Loss: 0.8717, Val Loss: 2.6636, F1 Micro: 0.4250, F1 Macro: 0.3748, Accuracy: 0.4250\n","Epoch 77, Train Loss: 1.0167, Val Loss: 1.5739, F1 Micro: 0.4833, F1 Macro: 0.4343, Accuracy: 0.4833\n","Epoch 78, Train Loss: 0.8794, Val Loss: 1.5740, F1 Micro: 0.4417, F1 Macro: 0.4476, Accuracy: 0.4417\n","Epoch 79, Train Loss: 0.8549, Val Loss: 1.4047, F1 Micro: 0.6000, F1 Macro: 0.5922, Accuracy: 0.6000\n","Epoch 80, Train Loss: 0.7717, Val Loss: 1.9832, F1 Micro: 0.3917, F1 Macro: 0.3791, Accuracy: 0.3917\n","Epoch 81, Train Loss: 0.8358, Val Loss: 1.7102, F1 Micro: 0.5500, F1 Macro: 0.5195, Accuracy: 0.5500\n","Epoch 82, Train Loss: 0.8270, Val Loss: 1.8047, F1 Micro: 0.4750, F1 Macro: 0.4502, Accuracy: 0.4750\n","Epoch 83, Train Loss: 0.7477, Val Loss: 1.9097, F1 Micro: 0.4917, F1 Macro: 0.4533, Accuracy: 0.4917\n","Epoch 84, Train Loss: 0.8237, Val Loss: 1.7664, F1 Micro: 0.5250, F1 Macro: 0.5279, Accuracy: 0.5250\n","Epoch 85, Train Loss: 0.9522, Val Loss: 1.7117, F1 Micro: 0.4917, F1 Macro: 0.4937, Accuracy: 0.4917\n","Epoch 86, Train Loss: 0.8543, Val Loss: 1.5194, F1 Micro: 0.5083, F1 Macro: 0.4853, Accuracy: 0.5083\n","Epoch 87, Train Loss: 0.7843, Val Loss: 1.8713, F1 Micro: 0.4583, F1 Macro: 0.4322, Accuracy: 0.4583\n","Epoch 88, Train Loss: 0.7771, Val Loss: 1.5181, F1 Micro: 0.4917, F1 Macro: 0.5055, Accuracy: 0.4917\n","Epoch 89, Train Loss: 0.7871, Val Loss: 2.2811, F1 Micro: 0.4250, F1 Macro: 0.3442, Accuracy: 0.4250\n","Epoch 90, Train Loss: 0.7759, Val Loss: 2.0187, F1 Micro: 0.5417, F1 Macro: 0.5022, Accuracy: 0.5417\n","Epoch 91, Train Loss: 0.8232, Val Loss: 2.0627, F1 Micro: 0.5083, F1 Macro: 0.4753, Accuracy: 0.5083\n","Epoch 92, Train Loss: 0.7811, Val Loss: 2.0180, F1 Micro: 0.4250, F1 Macro: 0.4210, Accuracy: 0.4250\n","Epoch 93, Train Loss: 0.7406, Val Loss: 1.4015, F1 Micro: 0.5583, F1 Macro: 0.5320, Accuracy: 0.5583\n","Epoch 94, Train Loss: 0.7215, Val Loss: 1.6388, F1 Micro: 0.5667, F1 Macro: 0.5254, Accuracy: 0.5667\n","Epoch 95, Train Loss: 0.7446, Val Loss: 1.6838, F1 Micro: 0.4750, F1 Macro: 0.4562, Accuracy: 0.4750\n","Epoch 96, Train Loss: 0.7227, Val Loss: 1.8894, F1 Micro: 0.4500, F1 Macro: 0.4032, Accuracy: 0.4500\n","Epoch 97, Train Loss: 0.7800, Val Loss: 1.6660, F1 Micro: 0.5333, F1 Macro: 0.5122, Accuracy: 0.5333\n","Epoch 98, Train Loss: 0.7494, Val Loss: 1.5751, F1 Micro: 0.5167, F1 Macro: 0.5238, Accuracy: 0.5167\n","Epoch 99, Train Loss: 0.7084, Val Loss: 1.3993, F1 Micro: 0.6000, F1 Macro: 0.5979, Accuracy: 0.6000\n","Epoch 100, Train Loss: 0.7771, Val Loss: 1.8785, F1 Micro: 0.4417, F1 Macro: 0.4251, Accuracy: 0.4417\n","Epoch 101, Train Loss: 0.8160, Val Loss: 2.7987, F1 Micro: 0.3250, F1 Macro: 0.3210, Accuracy: 0.3250\n","Epoch 102, Train Loss: 0.8459, Val Loss: 1.8993, F1 Micro: 0.4833, F1 Macro: 0.4408, Accuracy: 0.4833\n","Epoch 103, Train Loss: 0.7727, Val Loss: 1.9141, F1 Micro: 0.5333, F1 Macro: 0.4779, Accuracy: 0.5333\n","Epoch 104, Train Loss: 0.7585, Val Loss: 3.0520, F1 Micro: 0.3083, F1 Macro: 0.2843, Accuracy: 0.3083\n","Epoch 105, Train Loss: 0.8210, Val Loss: 2.0401, F1 Micro: 0.4417, F1 Macro: 0.4199, Accuracy: 0.4417\n","Epoch 106, Train Loss: 0.7235, Val Loss: 1.4549, F1 Micro: 0.5917, F1 Macro: 0.5870, Accuracy: 0.5917\n","Epoch 107, Train Loss: 0.7474, Val Loss: 1.4916, F1 Micro: 0.5917, F1 Macro: 0.5841, Accuracy: 0.5917\n","Epoch 108, Train Loss: 0.8157, Val Loss: 2.4619, F1 Micro: 0.4833, F1 Macro: 0.4450, Accuracy: 0.4833\n","Epoch 109, Train Loss: 0.8649, Val Loss: 1.9276, F1 Micro: 0.4083, F1 Macro: 0.4151, Accuracy: 0.4083\n","Epoch 110, Train Loss: 0.7851, Val Loss: 2.4124, F1 Micro: 0.4583, F1 Macro: 0.4146, Accuracy: 0.4583\n","Epoch 111, Train Loss: 0.7909, Val Loss: 1.7105, F1 Micro: 0.5500, F1 Macro: 0.5262, Accuracy: 0.5500\n","Epoch 112, Train Loss: 0.7988, Val Loss: 2.1921, F1 Micro: 0.4833, F1 Macro: 0.4695, Accuracy: 0.4833\n","Epoch 113, Train Loss: 0.8105, Val Loss: 2.3450, F1 Micro: 0.3583, F1 Macro: 0.3370, Accuracy: 0.3583\n","Epoch 114, Train Loss: 0.7317, Val Loss: 2.0224, F1 Micro: 0.4333, F1 Macro: 0.4209, Accuracy: 0.4333\n","Epoch 115, Train Loss: 0.7538, Val Loss: 2.4034, F1 Micro: 0.3917, F1 Macro: 0.3580, Accuracy: 0.3917\n","Epoch 116, Train Loss: 0.7764, Val Loss: 2.5442, F1 Micro: 0.4417, F1 Macro: 0.4167, Accuracy: 0.4417\n","Epoch 117, Train Loss: 0.7549, Val Loss: 1.4006, F1 Micro: 0.5667, F1 Macro: 0.5498, Accuracy: 0.5667\n","Epoch 118, Train Loss: 0.6788, Val Loss: 1.7244, F1 Micro: 0.5583, F1 Macro: 0.5545, Accuracy: 0.5583\n","Epoch 119, Train Loss: 0.6001, Val Loss: 1.4663, F1 Micro: 0.6000, F1 Macro: 0.6108, Accuracy: 0.6000\n","Epoch 120, Train Loss: 0.5877, Val Loss: 1.5727, F1 Micro: 0.5500, F1 Macro: 0.5317, Accuracy: 0.5500\n","Epoch 121, Train Loss: 0.6695, Val Loss: 1.6094, F1 Micro: 0.6000, F1 Macro: 0.5645, Accuracy: 0.6000\n","Epoch 122, Train Loss: 0.7117, Val Loss: 1.6423, F1 Micro: 0.5750, F1 Macro: 0.5813, Accuracy: 0.5750\n","Epoch 123, Train Loss: 0.6349, Val Loss: 1.5744, F1 Micro: 0.5000, F1 Macro: 0.5088, Accuracy: 0.5000\n","Epoch 124, Train Loss: 0.6578, Val Loss: 1.4314, F1 Micro: 0.6417, F1 Macro: 0.6374, Accuracy: 0.6417\n","Epoch 125, Train Loss: 0.6274, Val Loss: 1.6180, F1 Micro: 0.5167, F1 Macro: 0.4852, Accuracy: 0.5167\n","Epoch 126, Train Loss: 0.5692, Val Loss: 1.7579, F1 Micro: 0.5250, F1 Macro: 0.5217, Accuracy: 0.5250\n","Epoch 127, Train Loss: 0.6181, Val Loss: 2.7084, F1 Micro: 0.5417, F1 Macro: 0.5033, Accuracy: 0.5417\n","Epoch 128, Train Loss: 0.7502, Val Loss: 1.3652, F1 Micro: 0.6167, F1 Macro: 0.6105, Accuracy: 0.6167\n","Epoch 129, Train Loss: 0.5937, Val Loss: 1.6722, F1 Micro: 0.4833, F1 Macro: 0.4628, Accuracy: 0.4833\n","Epoch 130, Train Loss: 0.7165, Val Loss: 1.6580, F1 Micro: 0.4917, F1 Macro: 0.4749, Accuracy: 0.4917\n","Epoch 131, Train Loss: 0.6276, Val Loss: 1.8457, F1 Micro: 0.4917, F1 Macro: 0.4319, Accuracy: 0.4917\n","Epoch 132, Train Loss: 0.5848, Val Loss: 1.4456, F1 Micro: 0.6417, F1 Macro: 0.6359, Accuracy: 0.6417\n","Epoch 133, Train Loss: 0.6205, Val Loss: 1.8817, F1 Micro: 0.4667, F1 Macro: 0.4640, Accuracy: 0.4667\n","Epoch 134, Train Loss: 0.6413, Val Loss: 1.8178, F1 Micro: 0.5250, F1 Macro: 0.5323, Accuracy: 0.5250\n","Epoch 135, Train Loss: 0.5817, Val Loss: 1.7741, F1 Micro: 0.4667, F1 Macro: 0.4178, Accuracy: 0.4667\n","Epoch 136, Train Loss: 0.6739, Val Loss: 1.4037, F1 Micro: 0.6583, F1 Macro: 0.6523, Accuracy: 0.6583\n","Epoch 137, Train Loss: 0.5071, Val Loss: 1.4311, F1 Micro: 0.6500, F1 Macro: 0.6503, Accuracy: 0.6500\n","Epoch 138, Train Loss: 0.5918, Val Loss: 2.1592, F1 Micro: 0.4250, F1 Macro: 0.4234, Accuracy: 0.4250\n","Epoch 139, Train Loss: 0.6728, Val Loss: 1.5556, F1 Micro: 0.6250, F1 Macro: 0.5971, Accuracy: 0.6250\n","Epoch 140, Train Loss: 0.6457, Val Loss: 2.5930, F1 Micro: 0.4167, F1 Macro: 0.3916, Accuracy: 0.4167\n","Epoch 141, Train Loss: 0.6386, Val Loss: 1.6015, F1 Micro: 0.6167, F1 Macro: 0.6213, Accuracy: 0.6167\n","Epoch 142, Train Loss: 0.5973, Val Loss: 1.9345, F1 Micro: 0.4667, F1 Macro: 0.4610, Accuracy: 0.4667\n","Epoch 143, Train Loss: 0.8188, Val Loss: 2.1127, F1 Micro: 0.4333, F1 Macro: 0.3870, Accuracy: 0.4333\n","Epoch 144, Train Loss: 0.6424, Val Loss: 2.3483, F1 Micro: 0.4167, F1 Macro: 0.3795, Accuracy: 0.4167\n","Epoch 145, Train Loss: 0.7496, Val Loss: 1.6271, F1 Micro: 0.6333, F1 Macro: 0.6346, Accuracy: 0.6333\n","Epoch 146, Train Loss: 0.5707, Val Loss: 1.6687, F1 Micro: 0.4500, F1 Macro: 0.4283, Accuracy: 0.4500\n","Epoch 147, Train Loss: 0.6092, Val Loss: 2.0234, F1 Micro: 0.4833, F1 Macro: 0.4499, Accuracy: 0.4833\n","Epoch 148, Train Loss: 0.5187, Val Loss: 1.8264, F1 Micro: 0.5417, F1 Macro: 0.5524, Accuracy: 0.5417\n","Epoch 149, Train Loss: 0.6552, Val Loss: 2.2666, F1 Micro: 0.5583, F1 Macro: 0.5329, Accuracy: 0.5583\n","Epoch 150, Train Loss: 0.6274, Val Loss: 2.1229, F1 Micro: 0.4500, F1 Macro: 0.4487, Accuracy: 0.4500\n","Epoch 151, Train Loss: 0.5287, Val Loss: 1.9591, F1 Micro: 0.5583, F1 Macro: 0.5448, Accuracy: 0.5583\n","Epoch 152, Train Loss: 0.5676, Val Loss: 1.5729, F1 Micro: 0.6333, F1 Macro: 0.6226, Accuracy: 0.6333\n","Epoch 153, Train Loss: 0.6123, Val Loss: 1.8478, F1 Micro: 0.5000, F1 Macro: 0.4963, Accuracy: 0.5000\n","Epoch 154, Train Loss: 0.6947, Val Loss: 2.2134, F1 Micro: 0.5417, F1 Macro: 0.4948, Accuracy: 0.5417\n","Epoch 155, Train Loss: 0.6263, Val Loss: 1.5681, F1 Micro: 0.5500, F1 Macro: 0.5477, Accuracy: 0.5500\n","Epoch 156, Train Loss: 0.5963, Val Loss: 2.6594, F1 Micro: 0.4333, F1 Macro: 0.4410, Accuracy: 0.4333\n","Epoch 157, Train Loss: 0.6198, Val Loss: 1.5420, F1 Micro: 0.6500, F1 Macro: 0.6432, Accuracy: 0.6500\n","Epoch 158, Train Loss: 0.5176, Val Loss: 1.7502, F1 Micro: 0.6167, F1 Macro: 0.5918, Accuracy: 0.6167\n","Epoch 159, Train Loss: 0.5223, Val Loss: 1.6794, F1 Micro: 0.5417, F1 Macro: 0.5462, Accuracy: 0.5417\n","Epoch 160, Train Loss: 0.5335, Val Loss: 1.7721, F1 Micro: 0.5667, F1 Macro: 0.5583, Accuracy: 0.5667\n","Epoch 161, Train Loss: 0.5519, Val Loss: 2.0395, F1 Micro: 0.5083, F1 Macro: 0.4956, Accuracy: 0.5083\n","Epoch 162, Train Loss: 0.5884, Val Loss: 1.5377, F1 Micro: 0.5250, F1 Macro: 0.5118, Accuracy: 0.5250\n","Epoch 163, Train Loss: 0.6182, Val Loss: 1.7375, F1 Micro: 0.6417, F1 Macro: 0.6379, Accuracy: 0.6417\n","Epoch 164, Train Loss: 0.4995, Val Loss: 1.4486, F1 Micro: 0.6333, F1 Macro: 0.6327, Accuracy: 0.6333\n","Epoch 165, Train Loss: 0.5177, Val Loss: 1.7109, F1 Micro: 0.6000, F1 Macro: 0.5777, Accuracy: 0.6000\n","Epoch 166, Train Loss: 0.5187, Val Loss: 2.0170, F1 Micro: 0.5333, F1 Macro: 0.5240, Accuracy: 0.5333\n","Epoch 167, Train Loss: 0.5322, Val Loss: 1.7459, F1 Micro: 0.5667, F1 Macro: 0.5387, Accuracy: 0.5667\n","Epoch 168, Train Loss: 0.4819, Val Loss: 1.5120, F1 Micro: 0.6333, F1 Macro: 0.6154, Accuracy: 0.6333\n","Epoch 169, Train Loss: 0.5298, Val Loss: 1.5433, F1 Micro: 0.6917, F1 Macro: 0.6905, Accuracy: 0.6917\n","Epoch 170, Train Loss: 0.4501, Val Loss: 1.6052, F1 Micro: 0.5833, F1 Macro: 0.5752, Accuracy: 0.5833\n","Epoch 171, Train Loss: 0.5722, Val Loss: 1.6632, F1 Micro: 0.5500, F1 Macro: 0.5571, Accuracy: 0.5500\n","Epoch 172, Train Loss: 0.4617, Val Loss: 1.7646, F1 Micro: 0.5750, F1 Macro: 0.5895, Accuracy: 0.5750\n","Epoch 173, Train Loss: 0.5741, Val Loss: 2.4042, F1 Micro: 0.4667, F1 Macro: 0.4284, Accuracy: 0.4667\n","Epoch 174, Train Loss: 0.6813, Val Loss: 5.1170, F1 Micro: 0.3583, F1 Macro: 0.3400, Accuracy: 0.3583\n","Epoch 175, Train Loss: 0.7644, Val Loss: 3.4390, F1 Micro: 0.5250, F1 Macro: 0.4949, Accuracy: 0.5250\n","Epoch 176, Train Loss: 0.5837, Val Loss: 1.5161, F1 Micro: 0.6167, F1 Macro: 0.6144, Accuracy: 0.6167\n","Epoch 177, Train Loss: 0.5290, Val Loss: 1.4319, F1 Micro: 0.6333, F1 Macro: 0.6432, Accuracy: 0.6333\n","Epoch 178, Train Loss: 0.5056, Val Loss: 1.5103, F1 Micro: 0.6417, F1 Macro: 0.6356, Accuracy: 0.6417\n","Epoch 179, Train Loss: 0.5154, Val Loss: 2.0081, F1 Micro: 0.5917, F1 Macro: 0.5927, Accuracy: 0.5917\n","Epoch 180, Train Loss: 0.6052, Val Loss: 2.5928, F1 Micro: 0.5417, F1 Macro: 0.4901, Accuracy: 0.5417\n","Epoch 181, Train Loss: 0.6142, Val Loss: 1.6223, F1 Micro: 0.5667, F1 Macro: 0.5461, Accuracy: 0.5667\n","Epoch 182, Train Loss: 0.5317, Val Loss: 1.6871, F1 Micro: 0.5083, F1 Macro: 0.4949, Accuracy: 0.5083\n","Epoch 183, Train Loss: 0.4661, Val Loss: 1.9782, F1 Micro: 0.4917, F1 Macro: 0.4852, Accuracy: 0.4917\n","Epoch 184, Train Loss: 0.4859, Val Loss: 1.9065, F1 Micro: 0.5000, F1 Macro: 0.4844, Accuracy: 0.5000\n","Epoch 185, Train Loss: 0.5176, Val Loss: 1.8327, F1 Micro: 0.5000, F1 Macro: 0.4929, Accuracy: 0.5000\n","Epoch 186, Train Loss: 0.5639, Val Loss: 1.5467, F1 Micro: 0.7000, F1 Macro: 0.7006, Accuracy: 0.7000\n","Epoch 187, Train Loss: 0.5172, Val Loss: 1.7428, F1 Micro: 0.6000, F1 Macro: 0.5964, Accuracy: 0.6000\n","Epoch 188, Train Loss: 0.4754, Val Loss: 2.0793, F1 Micro: 0.4917, F1 Macro: 0.4556, Accuracy: 0.4917\n","Epoch 189, Train Loss: 0.4976, Val Loss: 1.4505, F1 Micro: 0.6500, F1 Macro: 0.6390, Accuracy: 0.6500\n","Epoch 190, Train Loss: 0.4200, Val Loss: 2.3107, F1 Micro: 0.4167, F1 Macro: 0.4149, Accuracy: 0.4167\n","Epoch 191, Train Loss: 0.5477, Val Loss: 1.7367, F1 Micro: 0.5167, F1 Macro: 0.5103, Accuracy: 0.5167\n","Epoch 192, Train Loss: 0.5436, Val Loss: 2.3450, F1 Micro: 0.4750, F1 Macro: 0.4314, Accuracy: 0.4750\n","Epoch 193, Train Loss: 0.4981, Val Loss: 1.8313, F1 Micro: 0.6250, F1 Macro: 0.6204, Accuracy: 0.6250\n","Epoch 194, Train Loss: 0.5165, Val Loss: 1.6509, F1 Micro: 0.5667, F1 Macro: 0.5676, Accuracy: 0.5667\n","Epoch 195, Train Loss: 0.5780, Val Loss: 2.1284, F1 Micro: 0.5417, F1 Macro: 0.5517, Accuracy: 0.5417\n","Epoch 196, Train Loss: 0.6091, Val Loss: 1.8004, F1 Micro: 0.5250, F1 Macro: 0.4963, Accuracy: 0.5250\n","Epoch 197, Train Loss: 0.4964, Val Loss: 1.8379, F1 Micro: 0.5583, F1 Macro: 0.5576, Accuracy: 0.5583\n","Epoch 198, Train Loss: 0.5224, Val Loss: 1.8018, F1 Micro: 0.5250, F1 Macro: 0.5317, Accuracy: 0.5250\n","Epoch 199, Train Loss: 0.4587, Val Loss: 1.5488, F1 Micro: 0.6500, F1 Macro: 0.6494, Accuracy: 0.6500\n","Epoch 200, Train Loss: 0.5261, Val Loss: 1.5395, F1 Micro: 0.6250, F1 Macro: 0.6287, Accuracy: 0.6250\n","Test set evaluation - F1 Micro: 0.6250, F1 Macro: 0.6287, Accuracy: 0.6250\n"]}]},{"cell_type":"code","source":["models_evaluation_metrics['GraphSAGEModel']['f1_micro_test_list2']=0\n","models_evaluation_metrics['GraphSAGEModel']['f1_macro_test_list2']=0\n","models_evaluation_metrics['GraphSAGEModel']['accuracy_test_list2']=0\n","\n","update_model_metrics('GraphSAGEModel', f1_micro_test_list2, f1_macro_test_list2, accuracy_test_list2)\n","print(models_evaluation_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWBiTPW4XMBa","executionInfo":{"status":"ok","timestamp":1711312508151,"user_tz":-60,"elapsed":217,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"2cdb5465-a50a-4428-cc7f-f69236a0c9b4"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GraphSAGEModel': {'f1_micro': [[0.5416666666666666, 0.5916666666666667, 0.55, 0.625, 0.625]], 'f1_macro': [[0.5416629853341376, 0.5733081992486917, 0.5063247285356819, 0.6092964760197358, 0.6286759471141622]], 'accuracy': [[0.5416666666666666, 0.5916666666666667, 0.55, 0.625, 0.625]], 'f1_micro_test_list2': 0, 'f1_macro_test_list2': 0, 'accuracy_test_list2': 0}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NAjNsGT2q3wq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Try the model GIN"],"metadata":{"id":"EYaYkBZ-q_1B"}},{"cell_type":"code","source":["from torch_geometric.nn import GINConv, global_mean_pool, BatchNorm\n","\n","class GINModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout_rate=0.5):\n","        super(GINModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.convs = nn.ModuleList()\n","        self.bns = nn.ModuleList()\n","        self.dropout_rate = dropout_rate\n","\n","        # MLP for GINConv\n","        mlp = lambda input_dim, output_dim: nn.Sequential(\n","            nn.Linear(input_dim, output_dim),\n","            nn.ReLU(),\n","            nn.Linear(output_dim, output_dim)\n","        )\n","\n","        # Input layer\n","        self.convs.append(GINConv(mlp(input_dim, hidden_dim)))\n","        self.bns.append(BatchNorm(hidden_dim))\n","\n","        # Hidden layers\n","        for _ in range(num_layers - 2):\n","            self.convs.append(GINConv(mlp(hidden_dim, hidden_dim)))\n","            self.bns.append(BatchNorm(hidden_dim))\n","\n","        # Output layer\n","        self.convs.append(GINConv(mlp(hidden_dim, output_dim)))\n","        # Note: Batch normalization is not applied after the last GINConv layer before global pooling\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        # Go through the layers\n","        for i in range(self.num_layers - 1):\n","            x = self.convs[i](x, edge_index)\n","            x = self.bns[i](x)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n","\n","        # Output layer\n","        x = self.convs[-1](x, edge_index)\n","\n","        # Apply global mean pooling to get graph-level output\n","        x = global_mean_pool(x, data.batch)\n","\n","        return x\n"],"metadata":{"id":"ANfAJsKwrNyj","executionInfo":{"status":"ok","timestamp":1711383302050,"user_tz":-60,"elapsed":429,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list3 = []\n","f1_macro_test_list3 = []\n","accuracy_test_list3 = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_en)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_en[train_val_idx]\n","    test_dataset = dataset_en[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = GINModel(\n","                input_dim=dataset_en.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_en.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = GINModel(\n","                input_dim=dataset_en.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_en.num_classes,\n","                num_layers=2,\n","                dropout_rate=0.5\n","            ).to(device)\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list3.append(f1_micro_test)\n","    f1_macro_test_list3.append(f1_macro_test)\n","    accuracy_test_list3.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'GSAGE_fold_{fold}.pth')\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXiTsEGnrPAT","executionInfo":{"status":"ok","timestamp":1711224683278,"user_tz":-60,"elapsed":3299462,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"e4c7daae-8847-489d-d518-f72e8245e813"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 16, Train Loss: 1.6826, Val Loss: 1.8837, F1 Micro: 0.2292, F1 Macro: 0.1600, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.7126, Val Loss: 1.9081, F1 Micro: 0.1875, F1 Macro: 0.1276, Accuracy: 0.1875\n","Epoch 18, Train Loss: 1.6811, Val Loss: 1.7543, F1 Micro: 0.2396, F1 Macro: 0.1730, Accuracy: 0.2396\n","Epoch 19, Train Loss: 1.6941, Val Loss: 1.8801, F1 Micro: 0.2292, F1 Macro: 0.1606, Accuracy: 0.2292\n","Epoch 20, Train Loss: 1.6783, Val Loss: 1.7680, F1 Micro: 0.2292, F1 Macro: 0.1643, Accuracy: 0.2292\n","Epoch 21, Train Loss: 1.6840, Val Loss: 1.8256, F1 Micro: 0.2292, F1 Macro: 0.1582, Accuracy: 0.2292\n","Epoch 22, Train Loss: 1.6784, Val Loss: 1.8337, F1 Micro: 0.2812, F1 Macro: 0.2079, Accuracy: 0.2812\n","Epoch 23, Train Loss: 1.6827, Val Loss: 1.8336, F1 Micro: 0.2188, F1 Macro: 0.1459, Accuracy: 0.2188\n","Epoch 24, Train Loss: 1.6845, Val Loss: 1.8093, F1 Micro: 0.2292, F1 Macro: 0.1645, Accuracy: 0.2292\n","Epoch 25, Train Loss: 1.6653, Val Loss: 1.7904, F1 Micro: 0.2292, F1 Macro: 0.1721, Accuracy: 0.2292\n","Epoch 26, Train Loss: 1.6794, Val Loss: 2.0413, F1 Micro: 0.1250, F1 Macro: 0.0730, Accuracy: 0.1250\n","Epoch 27, Train Loss: 1.6831, Val Loss: 1.7558, F1 Micro: 0.2292, F1 Macro: 0.1697, Accuracy: 0.2292\n","Epoch 28, Train Loss: 1.6570, Val Loss: 1.7910, F1 Micro: 0.2292, F1 Macro: 0.1748, Accuracy: 0.2292\n","Epoch 29, Train Loss: 1.6570, Val Loss: 1.8525, F1 Micro: 0.2292, F1 Macro: 0.1634, Accuracy: 0.2292\n","Epoch 30, Train Loss: 1.6624, Val Loss: 1.8427, F1 Micro: 0.2917, F1 Macro: 0.2156, Accuracy: 0.2917\n","Epoch 31, Train Loss: 1.6434, Val Loss: 1.7866, F1 Micro: 0.2500, F1 Macro: 0.2059, Accuracy: 0.2500\n","Epoch 32, Train Loss: 1.6697, Val Loss: 1.8161, F1 Micro: 0.2708, F1 Macro: 0.1883, Accuracy: 0.2708\n","Epoch 33, Train Loss: 1.6519, Val Loss: 1.8716, F1 Micro: 0.2188, F1 Macro: 0.1522, Accuracy: 0.2188\n","Epoch 34, Train Loss: 1.6776, Val Loss: 2.0066, F1 Micro: 0.1771, F1 Macro: 0.1332, Accuracy: 0.1771\n","Epoch 35, Train Loss: 1.6474, Val Loss: 1.8498, F1 Micro: 0.2188, F1 Macro: 0.1652, Accuracy: 0.2188\n","Epoch 36, Train Loss: 1.6525, Val Loss: 1.7849, F1 Micro: 0.2604, F1 Macro: 0.1948, Accuracy: 0.2604\n","Epoch 37, Train Loss: 1.6356, Val Loss: 1.8143, F1 Micro: 0.2500, F1 Macro: 0.1969, Accuracy: 0.2500\n","Epoch 38, Train Loss: 1.6677, Val Loss: 1.8006, F1 Micro: 0.2500, F1 Macro: 0.1887, Accuracy: 0.2500\n","Epoch 39, Train Loss: 1.6405, Val Loss: 1.7936, F1 Micro: 0.2500, F1 Macro: 0.1861, Accuracy: 0.2500\n","Epoch 40, Train Loss: 1.6279, Val Loss: 1.8362, F1 Micro: 0.2083, F1 Macro: 0.1438, Accuracy: 0.2083\n","Epoch 41, Train Loss: 1.6129, Val Loss: 1.9087, F1 Micro: 0.1875, F1 Macro: 0.1410, Accuracy: 0.1875\n","Epoch 42, Train Loss: 1.6142, Val Loss: 1.8154, F1 Micro: 0.2604, F1 Macro: 0.2180, Accuracy: 0.2604\n","Epoch 43, Train Loss: 1.6048, Val Loss: 1.8295, F1 Micro: 0.2917, F1 Macro: 0.2098, Accuracy: 0.2917\n","Epoch 44, Train Loss: 1.6250, Val Loss: 1.9962, F1 Micro: 0.1875, F1 Macro: 0.1425, Accuracy: 0.1875\n","Epoch 45, Train Loss: 1.6214, Val Loss: 1.8695, F1 Micro: 0.3021, F1 Macro: 0.2099, Accuracy: 0.3021\n","Epoch 46, Train Loss: 1.6256, Val Loss: 1.7376, F1 Micro: 0.2708, F1 Macro: 0.2242, Accuracy: 0.2708\n","Epoch 47, Train Loss: 1.6445, Val Loss: 2.2556, F1 Micro: 0.1458, F1 Macro: 0.1025, Accuracy: 0.1458\n","Epoch 48, Train Loss: 1.6230, Val Loss: 1.8342, F1 Micro: 0.2292, F1 Macro: 0.2019, Accuracy: 0.2292\n","Epoch 49, Train Loss: 1.6190, Val Loss: 1.8722, F1 Micro: 0.2396, F1 Macro: 0.1953, Accuracy: 0.2396\n","Epoch 50, Train Loss: 1.5948, Val Loss: 1.7950, F1 Micro: 0.2812, F1 Macro: 0.2253, Accuracy: 0.2812\n","Epoch 51, Train Loss: 1.6000, Val Loss: 1.7838, F1 Micro: 0.2812, F1 Macro: 0.2110, Accuracy: 0.2812\n","Epoch 52, Train Loss: 1.5963, Val Loss: 1.8194, F1 Micro: 0.2812, F1 Macro: 0.2291, Accuracy: 0.2812\n","Epoch 53, Train Loss: 1.5862, Val Loss: 1.8086, F1 Micro: 0.2812, F1 Macro: 0.2377, Accuracy: 0.2812\n","Epoch 54, Train Loss: 1.5740, Val Loss: 1.9851, F1 Micro: 0.2292, F1 Macro: 0.1821, Accuracy: 0.2292\n","Epoch 55, Train Loss: 1.5854, Val Loss: 1.8325, F1 Micro: 0.2917, F1 Macro: 0.2028, Accuracy: 0.2917\n","Epoch 56, Train Loss: 1.5537, Val Loss: 1.8201, F1 Micro: 0.3333, F1 Macro: 0.2596, Accuracy: 0.3333\n","Epoch 57, Train Loss: 1.5605, Val Loss: 1.9062, F1 Micro: 0.1979, F1 Macro: 0.1578, Accuracy: 0.1979\n","Epoch 58, Train Loss: 1.5707, Val Loss: 1.8915, F1 Micro: 0.3021, F1 Macro: 0.2105, Accuracy: 0.3021\n","Epoch 59, Train Loss: 1.5405, Val Loss: 1.9533, F1 Micro: 0.1875, F1 Macro: 0.1423, Accuracy: 0.1875\n","Epoch 60, Train Loss: 1.5568, Val Loss: 1.8170, F1 Micro: 0.2708, F1 Macro: 0.2424, Accuracy: 0.2708\n","Epoch 61, Train Loss: 1.5565, Val Loss: 1.9071, F1 Micro: 0.1771, F1 Macro: 0.1292, Accuracy: 0.1771\n","Epoch 62, Train Loss: 1.5486, Val Loss: 2.0869, F1 Micro: 0.1771, F1 Macro: 0.1392, Accuracy: 0.1771\n","Epoch 63, Train Loss: 1.5534, Val Loss: 2.1888, F1 Micro: 0.1562, F1 Macro: 0.1232, Accuracy: 0.1562\n","Epoch 64, Train Loss: 1.5378, Val Loss: 1.9642, F1 Micro: 0.3542, F1 Macro: 0.2791, Accuracy: 0.3542\n","Epoch 65, Train Loss: 1.5625, Val Loss: 1.9632, F1 Micro: 0.1875, F1 Macro: 0.1542, Accuracy: 0.1875\n","Epoch 66, Train Loss: 1.5543, Val Loss: 1.8342, F1 Micro: 0.3333, F1 Macro: 0.2404, Accuracy: 0.3333\n","Epoch 67, Train Loss: 1.5106, Val Loss: 2.0756, F1 Micro: 0.2812, F1 Macro: 0.1610, Accuracy: 0.2812\n","Epoch 68, Train Loss: 1.5064, Val Loss: 1.9248, F1 Micro: 0.3229, F1 Macro: 0.2379, Accuracy: 0.3229\n","Epoch 69, Train Loss: 1.5027, Val Loss: 2.3477, F1 Micro: 0.1771, F1 Macro: 0.1278, Accuracy: 0.1771\n","Epoch 70, Train Loss: 1.5114, Val Loss: 1.8759, F1 Micro: 0.2812, F1 Macro: 0.2613, Accuracy: 0.2812\n","Epoch 71, Train Loss: 1.4898, Val Loss: 1.7369, F1 Micro: 0.3438, F1 Macro: 0.2816, Accuracy: 0.3438\n","Epoch 72, Train Loss: 1.4923, Val Loss: 1.9485, F1 Micro: 0.2083, F1 Macro: 0.1754, Accuracy: 0.2083\n","Epoch 73, Train Loss: 1.4757, Val Loss: 1.7594, F1 Micro: 0.2812, F1 Macro: 0.2281, Accuracy: 0.2812\n","Epoch 74, Train Loss: 1.4764, Val Loss: 1.7510, F1 Micro: 0.2708, F1 Macro: 0.2369, Accuracy: 0.2708\n","Epoch 75, Train Loss: 1.4535, Val Loss: 2.4978, F1 Micro: 0.2812, F1 Macro: 0.1562, Accuracy: 0.2812\n","Epoch 76, Train Loss: 1.4803, Val Loss: 1.8959, F1 Micro: 0.3021, F1 Macro: 0.2151, Accuracy: 0.3021\n","Epoch 77, Train Loss: 1.4478, Val Loss: 1.9633, F1 Micro: 0.3333, F1 Macro: 0.2525, Accuracy: 0.3333\n","Epoch 78, Train Loss: 1.4918, Val Loss: 2.2032, F1 Micro: 0.1771, F1 Macro: 0.1378, Accuracy: 0.1771\n","Epoch 79, Train Loss: 1.4983, Val Loss: 2.0184, F1 Micro: 0.2500, F1 Macro: 0.1925, Accuracy: 0.2500\n","Epoch 80, Train Loss: 1.4513, Val Loss: 1.8808, F1 Micro: 0.2396, F1 Macro: 0.1996, Accuracy: 0.2396\n","Epoch 81, Train Loss: 1.4568, Val Loss: 1.7007, F1 Micro: 0.3333, F1 Macro: 0.3170, Accuracy: 0.3333\n","Epoch 82, Train Loss: 1.4428, Val Loss: 1.9418, F1 Micro: 0.2708, F1 Macro: 0.2262, Accuracy: 0.2708\n","Epoch 83, Train Loss: 1.4038, Val Loss: 1.7778, F1 Micro: 0.3333, F1 Macro: 0.2601, Accuracy: 0.3333\n","Epoch 84, Train Loss: 1.4255, Val Loss: 1.7388, F1 Micro: 0.3542, F1 Macro: 0.3049, Accuracy: 0.3542\n","Epoch 85, Train Loss: 1.4042, Val Loss: 1.9964, F1 Micro: 0.2812, F1 Macro: 0.2559, Accuracy: 0.2812\n","Epoch 86, Train Loss: 1.4065, Val Loss: 1.8327, F1 Micro: 0.3125, F1 Macro: 0.2604, Accuracy: 0.3125\n","Epoch 87, Train Loss: 1.4394, Val Loss: 1.9395, F1 Micro: 0.3333, F1 Macro: 0.3162, Accuracy: 0.3333\n","Epoch 88, Train Loss: 1.4509, Val Loss: 2.1814, F1 Micro: 0.2188, F1 Macro: 0.1628, Accuracy: 0.2188\n","Epoch 89, Train Loss: 1.4582, Val Loss: 1.6916, F1 Micro: 0.3438, F1 Macro: 0.2915, Accuracy: 0.3438\n","Epoch 90, Train Loss: 1.4070, Val Loss: 1.6987, F1 Micro: 0.3750, F1 Macro: 0.3454, Accuracy: 0.3750\n","Epoch 91, Train Loss: 1.3962, Val Loss: 1.7375, F1 Micro: 0.3021, F1 Macro: 0.2653, Accuracy: 0.3021\n","Epoch 92, Train Loss: 1.3854, Val Loss: 2.0589, F1 Micro: 0.2812, F1 Macro: 0.2652, Accuracy: 0.2812\n","Epoch 93, Train Loss: 1.3777, Val Loss: 2.0250, F1 Micro: 0.3125, F1 Macro: 0.2771, Accuracy: 0.3125\n","Epoch 94, Train Loss: 1.3713, Val Loss: 1.8276, F1 Micro: 0.3333, F1 Macro: 0.2971, Accuracy: 0.3333\n","Epoch 95, Train Loss: 1.3550, Val Loss: 2.0224, F1 Micro: 0.3333, F1 Macro: 0.2676, Accuracy: 0.3333\n","Epoch 96, Train Loss: 1.3714, Val Loss: 1.7553, F1 Micro: 0.3229, F1 Macro: 0.3011, Accuracy: 0.3229\n","Epoch 97, Train Loss: 1.3990, Val Loss: 2.0310, F1 Micro: 0.3438, F1 Macro: 0.2771, Accuracy: 0.3438\n","Epoch 98, Train Loss: 1.3517, Val Loss: 1.7889, F1 Micro: 0.3958, F1 Macro: 0.3609, Accuracy: 0.3958\n","Epoch 99, Train Loss: 1.3598, Val Loss: 1.7264, F1 Micro: 0.3750, F1 Macro: 0.3357, Accuracy: 0.3750\n","Epoch 100, Train Loss: 1.3557, Val Loss: 1.9446, F1 Micro: 0.3646, F1 Macro: 0.3413, Accuracy: 0.3646\n","Epoch 101, Train Loss: 1.3253, Val Loss: 1.7461, F1 Micro: 0.4375, F1 Macro: 0.4268, Accuracy: 0.4375\n","Epoch 102, Train Loss: 1.3405, Val Loss: 2.4031, F1 Micro: 0.2708, F1 Macro: 0.2320, Accuracy: 0.2708\n","Epoch 103, Train Loss: 1.3649, Val Loss: 4.3258, F1 Micro: 0.1875, F1 Macro: 0.1879, Accuracy: 0.1875\n","Epoch 104, Train Loss: 1.3271, Val Loss: 1.9731, F1 Micro: 0.3542, F1 Macro: 0.3311, Accuracy: 0.3542\n","Epoch 105, Train Loss: 1.3581, Val Loss: 1.7054, F1 Micro: 0.3646, F1 Macro: 0.3249, Accuracy: 0.3646\n","Epoch 106, Train Loss: 1.2836, Val Loss: 1.7037, F1 Micro: 0.3542, F1 Macro: 0.3521, Accuracy: 0.3542\n","Epoch 107, Train Loss: 1.3137, Val Loss: 1.7979, F1 Micro: 0.3750, F1 Macro: 0.3615, Accuracy: 0.3750\n","Epoch 108, Train Loss: 1.3107, Val Loss: 1.7579, F1 Micro: 0.3854, F1 Macro: 0.3603, Accuracy: 0.3854\n","Epoch 109, Train Loss: 1.2917, Val Loss: 1.7178, F1 Micro: 0.3750, F1 Macro: 0.3583, Accuracy: 0.3750\n","Epoch 110, Train Loss: 1.2819, Val Loss: 1.7695, F1 Micro: 0.3750, F1 Macro: 0.3616, Accuracy: 0.3750\n","Epoch 111, Train Loss: 1.3125, Val Loss: 2.0436, F1 Micro: 0.3750, F1 Macro: 0.3498, Accuracy: 0.3750\n","Epoch 112, Train Loss: 1.2803, Val Loss: 1.6996, F1 Micro: 0.4583, F1 Macro: 0.4404, Accuracy: 0.4583\n","Epoch 113, Train Loss: 1.2700, Val Loss: 2.0166, F1 Micro: 0.3229, F1 Macro: 0.2987, Accuracy: 0.3229\n","Epoch 114, Train Loss: 1.2465, Val Loss: 1.9336, F1 Micro: 0.3229, F1 Macro: 0.3054, Accuracy: 0.3229\n","Epoch 115, Train Loss: 1.3032, Val Loss: 1.7724, F1 Micro: 0.4271, F1 Macro: 0.4138, Accuracy: 0.4271\n","Epoch 116, Train Loss: 1.2818, Val Loss: 1.6798, F1 Micro: 0.3229, F1 Macro: 0.3161, Accuracy: 0.3229\n","Epoch 117, Train Loss: 1.2459, Val Loss: 1.7193, F1 Micro: 0.3958, F1 Macro: 0.3489, Accuracy: 0.3958\n","Epoch 118, Train Loss: 1.2927, Val Loss: 1.9192, F1 Micro: 0.4375, F1 Macro: 0.4177, Accuracy: 0.4375\n","Epoch 119, Train Loss: 1.2659, Val Loss: 1.7793, F1 Micro: 0.3333, F1 Macro: 0.2921, Accuracy: 0.3333\n","Epoch 120, Train Loss: 1.2415, Val Loss: 2.0405, F1 Micro: 0.3750, F1 Macro: 0.3247, Accuracy: 0.3750\n","Epoch 121, Train Loss: 1.2614, Val Loss: 1.8913, F1 Micro: 0.3229, F1 Macro: 0.2914, Accuracy: 0.3229\n","Epoch 122, Train Loss: 1.2880, Val Loss: 4.3024, F1 Micro: 0.1667, F1 Macro: 0.1558, Accuracy: 0.1667\n","Epoch 123, Train Loss: 1.2898, Val Loss: 1.9655, F1 Micro: 0.4271, F1 Macro: 0.4204, Accuracy: 0.4271\n","Epoch 124, Train Loss: 1.2241, Val Loss: 1.6804, F1 Micro: 0.4062, F1 Macro: 0.3986, Accuracy: 0.4062\n","Epoch 125, Train Loss: 1.3091, Val Loss: 1.7507, F1 Micro: 0.3854, F1 Macro: 0.3563, Accuracy: 0.3854\n","Epoch 126, Train Loss: 1.2508, Val Loss: 1.8574, F1 Micro: 0.3750, F1 Macro: 0.3741, Accuracy: 0.3750\n","Epoch 127, Train Loss: 1.2773, Val Loss: 1.8254, F1 Micro: 0.3958, F1 Macro: 0.3547, Accuracy: 0.3958\n","Epoch 128, Train Loss: 1.2507, Val Loss: 1.6275, F1 Micro: 0.4479, F1 Macro: 0.4125, Accuracy: 0.4479\n","Epoch 129, Train Loss: 1.1789, Val Loss: 1.6164, F1 Micro: 0.4167, F1 Macro: 0.3949, Accuracy: 0.4167\n","Epoch 130, Train Loss: 1.2198, Val Loss: 1.7774, F1 Micro: 0.3854, F1 Macro: 0.3639, Accuracy: 0.3854\n","Epoch 131, Train Loss: 1.1981, Val Loss: 1.7242, F1 Micro: 0.4896, F1 Macro: 0.4708, Accuracy: 0.4896\n","Epoch 132, Train Loss: 1.2545, Val Loss: 1.7960, F1 Micro: 0.4167, F1 Macro: 0.3968, Accuracy: 0.4167\n","Epoch 133, Train Loss: 1.2730, Val Loss: 1.7048, F1 Micro: 0.4583, F1 Macro: 0.4411, Accuracy: 0.4583\n","Epoch 134, Train Loss: 1.1636, Val Loss: 2.1214, F1 Micro: 0.4375, F1 Macro: 0.4080, Accuracy: 0.4375\n","Epoch 135, Train Loss: 1.1912, Val Loss: 1.7667, F1 Micro: 0.3646, F1 Macro: 0.3340, Accuracy: 0.3646\n","Epoch 136, Train Loss: 1.2162, Val Loss: 2.1157, F1 Micro: 0.4062, F1 Macro: 0.3735, Accuracy: 0.4062\n","Epoch 137, Train Loss: 1.1659, Val Loss: 2.3048, F1 Micro: 0.4062, F1 Macro: 0.3859, Accuracy: 0.4062\n","Epoch 138, Train Loss: 1.1485, Val Loss: 1.7381, F1 Micro: 0.4583, F1 Macro: 0.4307, Accuracy: 0.4583\n","Epoch 139, Train Loss: 1.2122, Val Loss: 1.8397, F1 Micro: 0.4062, F1 Macro: 0.3981, Accuracy: 0.4062\n","Epoch 140, Train Loss: 1.1705, Val Loss: 1.9719, F1 Micro: 0.3229, F1 Macro: 0.3262, Accuracy: 0.3229\n","Epoch 141, Train Loss: 1.1536, Val Loss: 1.8243, F1 Micro: 0.3542, F1 Macro: 0.3175, Accuracy: 0.3542\n","Epoch 142, Train Loss: 1.1562, Val Loss: 2.6716, F1 Micro: 0.3438, F1 Macro: 0.3277, Accuracy: 0.3438\n","Epoch 143, Train Loss: 1.1726, Val Loss: 1.9875, F1 Micro: 0.4375, F1 Macro: 0.4228, Accuracy: 0.4375\n","Epoch 144, Train Loss: 1.2418, Val Loss: 1.6192, F1 Micro: 0.4688, F1 Macro: 0.4327, Accuracy: 0.4688\n","Epoch 145, Train Loss: 1.1946, Val Loss: 1.8095, F1 Micro: 0.3854, F1 Macro: 0.3711, Accuracy: 0.3854\n","Epoch 146, Train Loss: 1.1405, Val Loss: 2.1095, F1 Micro: 0.3438, F1 Macro: 0.2841, Accuracy: 0.3438\n","Epoch 147, Train Loss: 1.1439, Val Loss: 2.0533, F1 Micro: 0.3958, F1 Macro: 0.3575, Accuracy: 0.3958\n","Epoch 148, Train Loss: 1.1542, Val Loss: 2.1248, F1 Micro: 0.3854, F1 Macro: 0.3697, Accuracy: 0.3854\n","Epoch 149, Train Loss: 1.1150, Val Loss: 2.0376, F1 Micro: 0.3854, F1 Macro: 0.3650, Accuracy: 0.3854\n","Epoch 150, Train Loss: 1.1279, Val Loss: 2.2039, F1 Micro: 0.3750, F1 Macro: 0.3667, Accuracy: 0.3750\n","Epoch 151, Train Loss: 1.1229, Val Loss: 1.7433, F1 Micro: 0.4896, F1 Macro: 0.4758, Accuracy: 0.4896\n","Epoch 152, Train Loss: 1.1494, Val Loss: 1.8231, F1 Micro: 0.4688, F1 Macro: 0.4533, Accuracy: 0.4688\n","Epoch 153, Train Loss: 1.1235, Val Loss: 2.1092, F1 Micro: 0.3542, F1 Macro: 0.3177, Accuracy: 0.3542\n","Epoch 154, Train Loss: 1.1322, Val Loss: 3.3283, F1 Micro: 0.2917, F1 Macro: 0.2617, Accuracy: 0.2917\n","Epoch 155, Train Loss: 1.0830, Val Loss: 1.9069, F1 Micro: 0.3958, F1 Macro: 0.3764, Accuracy: 0.3958\n","Epoch 156, Train Loss: 1.0655, Val Loss: 2.0831, F1 Micro: 0.3750, F1 Macro: 0.3545, Accuracy: 0.3750\n","Epoch 157, Train Loss: 1.1178, Val Loss: 3.0691, F1 Micro: 0.3125, F1 Macro: 0.2825, Accuracy: 0.3125\n","Epoch 158, Train Loss: 1.1035, Val Loss: 2.7201, F1 Micro: 0.3125, F1 Macro: 0.2908, Accuracy: 0.3125\n","Epoch 159, Train Loss: 1.1104, Val Loss: 2.1373, F1 Micro: 0.3750, F1 Macro: 0.3475, Accuracy: 0.3750\n","Epoch 160, Train Loss: 1.1089, Val Loss: 1.9987, F1 Micro: 0.4167, F1 Macro: 0.3985, Accuracy: 0.4167\n","Epoch 161, Train Loss: 1.0655, Val Loss: 1.9508, F1 Micro: 0.4271, F1 Macro: 0.4116, Accuracy: 0.4271\n","Epoch 162, Train Loss: 1.0871, Val Loss: 2.3583, F1 Micro: 0.3750, F1 Macro: 0.3370, Accuracy: 0.3750\n","Epoch 163, Train Loss: 1.1450, Val Loss: 1.8963, F1 Micro: 0.5208, F1 Macro: 0.5133, Accuracy: 0.5208\n","Epoch 164, Train Loss: 1.0649, Val Loss: 1.9882, F1 Micro: 0.4375, F1 Macro: 0.4358, Accuracy: 0.4375\n","Epoch 165, Train Loss: 1.0627, Val Loss: 2.1600, F1 Micro: 0.3958, F1 Macro: 0.3877, Accuracy: 0.3958\n","Epoch 166, Train Loss: 1.0627, Val Loss: 1.9489, F1 Micro: 0.4479, F1 Macro: 0.4539, Accuracy: 0.4479\n","Epoch 167, Train Loss: 1.0536, Val Loss: 1.9474, F1 Micro: 0.3958, F1 Macro: 0.3788, Accuracy: 0.3958\n","Epoch 168, Train Loss: 1.0063, Val Loss: 2.0635, F1 Micro: 0.4688, F1 Macro: 0.4648, Accuracy: 0.4688\n","Epoch 169, Train Loss: 1.0914, Val Loss: 1.7533, F1 Micro: 0.4792, F1 Macro: 0.4758, Accuracy: 0.4792\n","Epoch 170, Train Loss: 1.0525, Val Loss: 1.9156, F1 Micro: 0.5104, F1 Macro: 0.5048, Accuracy: 0.5104\n","Epoch 171, Train Loss: 1.1295, Val Loss: 2.1867, F1 Micro: 0.3750, F1 Macro: 0.3804, Accuracy: 0.3750\n","Epoch 172, Train Loss: 1.1114, Val Loss: 2.2328, F1 Micro: 0.3854, F1 Macro: 0.3583, Accuracy: 0.3854\n","Epoch 173, Train Loss: 1.0848, Val Loss: 1.8909, F1 Micro: 0.4688, F1 Macro: 0.4715, Accuracy: 0.4688\n","Epoch 174, Train Loss: 1.0741, Val Loss: 2.1036, F1 Micro: 0.4062, F1 Macro: 0.3718, Accuracy: 0.4062\n","Epoch 175, Train Loss: 1.0557, Val Loss: 2.2153, F1 Micro: 0.4583, F1 Macro: 0.4566, Accuracy: 0.4583\n","Epoch 176, Train Loss: 1.0667, Val Loss: 1.6945, F1 Micro: 0.5312, F1 Macro: 0.5281, Accuracy: 0.5312\n","Epoch 177, Train Loss: 1.0011, Val Loss: 1.7529, F1 Micro: 0.5000, F1 Macro: 0.4812, Accuracy: 0.5000\n","Epoch 178, Train Loss: 1.0867, Val Loss: 1.9628, F1 Micro: 0.4792, F1 Macro: 0.4719, Accuracy: 0.4792\n","Epoch 179, Train Loss: 1.0489, Val Loss: 1.8159, F1 Micro: 0.5208, F1 Macro: 0.5371, Accuracy: 0.5208\n","Epoch 180, Train Loss: 1.0465, Val Loss: 1.7496, F1 Micro: 0.5000, F1 Macro: 0.4848, Accuracy: 0.5000\n","Epoch 181, Train Loss: 1.0612, Val Loss: 1.8549, F1 Micro: 0.4375, F1 Macro: 0.4445, Accuracy: 0.4375\n","Epoch 182, Train Loss: 1.0047, Val Loss: 1.7482, F1 Micro: 0.4271, F1 Macro: 0.4167, Accuracy: 0.4271\n","Epoch 183, Train Loss: 1.0121, Val Loss: 1.8951, F1 Micro: 0.4479, F1 Macro: 0.4308, Accuracy: 0.4479\n","Epoch 184, Train Loss: 1.0141, Val Loss: 2.3967, F1 Micro: 0.4062, F1 Macro: 0.3693, Accuracy: 0.4062\n","Epoch 185, Train Loss: 1.0894, Val Loss: 1.6068, F1 Micro: 0.4479, F1 Macro: 0.4611, Accuracy: 0.4479\n","Epoch 186, Train Loss: 1.0964, Val Loss: 1.8667, F1 Micro: 0.4271, F1 Macro: 0.4301, Accuracy: 0.4271\n","Epoch 187, Train Loss: 1.0048, Val Loss: 1.9759, F1 Micro: 0.4167, F1 Macro: 0.4233, Accuracy: 0.4167\n","Epoch 188, Train Loss: 1.0239, Val Loss: 1.6789, F1 Micro: 0.4479, F1 Macro: 0.4550, Accuracy: 0.4479\n","Epoch 189, Train Loss: 1.0334, Val Loss: 1.7128, F1 Micro: 0.4792, F1 Macro: 0.4826, Accuracy: 0.4792\n","Epoch 190, Train Loss: 1.0130, Val Loss: 1.8193, F1 Micro: 0.5729, F1 Macro: 0.5715, Accuracy: 0.5729\n","Epoch 191, Train Loss: 0.9604, Val Loss: 2.5021, F1 Micro: 0.4062, F1 Macro: 0.3931, Accuracy: 0.4062\n","Epoch 192, Train Loss: 0.9700, Val Loss: 3.0006, F1 Micro: 0.3229, F1 Macro: 0.2939, Accuracy: 0.3229\n","Epoch 193, Train Loss: 1.0174, Val Loss: 2.0283, F1 Micro: 0.4375, F1 Macro: 0.4159, Accuracy: 0.4375\n","Epoch 194, Train Loss: 1.0070, Val Loss: 2.3289, F1 Micro: 0.4271, F1 Macro: 0.4124, Accuracy: 0.4271\n","Epoch 195, Train Loss: 1.0018, Val Loss: 2.0576, F1 Micro: 0.4583, F1 Macro: 0.4459, Accuracy: 0.4583\n","Epoch 196, Train Loss: 1.0213, Val Loss: 2.2636, F1 Micro: 0.4167, F1 Macro: 0.4085, Accuracy: 0.4167\n","Epoch 197, Train Loss: 0.9719, Val Loss: 1.8038, F1 Micro: 0.5312, F1 Macro: 0.5330, Accuracy: 0.5312\n","Epoch 198, Train Loss: 1.0603, Val Loss: 2.3338, F1 Micro: 0.4062, F1 Macro: 0.3747, Accuracy: 0.4062\n","Epoch 199, Train Loss: 0.9349, Val Loss: 2.3961, F1 Micro: 0.4062, F1 Macro: 0.4023, Accuracy: 0.4062\n","Epoch 200, Train Loss: 0.9916, Val Loss: 2.9913, F1 Micro: 0.4375, F1 Macro: 0.4300, Accuracy: 0.4375\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.7978, Val Loss: 1.8438, F1 Micro: 0.2083, F1 Macro: 0.1344, Accuracy: 0.2083\n","Epoch 2, Train Loss: 1.7432, Val Loss: 1.8698, F1 Micro: 0.1875, F1 Macro: 0.1353, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.7311, Val Loss: 1.7162, F1 Micro: 0.2500, F1 Macro: 0.1699, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.7188, Val Loss: 1.8050, F1 Micro: 0.2292, F1 Macro: 0.1790, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.6751, Val Loss: 1.8107, F1 Micro: 0.2083, F1 Macro: 0.1547, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.6841, Val Loss: 1.7322, F1 Micro: 0.2604, F1 Macro: 0.2329, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.6025, Val Loss: 1.7101, F1 Micro: 0.3125, F1 Macro: 0.2627, Accuracy: 0.3125\n","Epoch 8, Train Loss: 1.6090, Val Loss: 1.7969, F1 Micro: 0.2812, F1 Macro: 0.2439, Accuracy: 0.2812\n","Epoch 9, Train Loss: 1.6012, Val Loss: 1.9009, F1 Micro: 0.2917, F1 Macro: 0.1797, Accuracy: 0.2917\n","Epoch 10, Train Loss: 1.5989, Val Loss: 1.8205, F1 Micro: 0.2708, F1 Macro: 0.2032, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.5615, Val Loss: 1.6251, F1 Micro: 0.3333, F1 Macro: 0.2956, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.5671, Val Loss: 1.6314, F1 Micro: 0.3646, F1 Macro: 0.3081, Accuracy: 0.3646\n","Epoch 13, Train Loss: 1.5498, Val Loss: 1.8004, F1 Micro: 0.2917, F1 Macro: 0.2380, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.5693, Val Loss: 2.0008, F1 Micro: 0.3021, F1 Macro: 0.2397, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.5424, Val Loss: 1.6235, F1 Micro: 0.3542, F1 Macro: 0.3227, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.4980, Val Loss: 1.9475, F1 Micro: 0.3542, F1 Macro: 0.2930, Accuracy: 0.3542\n","Epoch 17, Train Loss: 1.4769, Val Loss: 1.8959, F1 Micro: 0.3229, F1 Macro: 0.2777, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.5072, Val Loss: 2.0579, F1 Micro: 0.2917, F1 Macro: 0.2011, Accuracy: 0.2917\n","Epoch 19, Train Loss: 1.4571, Val Loss: 2.1968, F1 Micro: 0.2604, F1 Macro: 0.2053, Accuracy: 0.2604\n","Epoch 20, Train Loss: 1.4945, Val Loss: 1.8442, F1 Micro: 0.3542, F1 Macro: 0.3048, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.4573, Val Loss: 1.6632, F1 Micro: 0.3750, F1 Macro: 0.3640, Accuracy: 0.3750\n","Epoch 22, Train Loss: 1.4347, Val Loss: 1.7794, F1 Micro: 0.3542, F1 Macro: 0.3030, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.4106, Val Loss: 1.7326, F1 Micro: 0.2917, F1 Macro: 0.2521, Accuracy: 0.2917\n","Epoch 24, Train Loss: 1.4313, Val Loss: 1.6983, F1 Micro: 0.3125, F1 Macro: 0.2688, Accuracy: 0.3125\n","Epoch 25, Train Loss: 1.3824, Val Loss: 1.7967, F1 Micro: 0.3542, F1 Macro: 0.3380, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.3994, Val Loss: 1.9803, F1 Micro: 0.3438, F1 Macro: 0.2846, Accuracy: 0.3438\n","Epoch 27, Train Loss: 1.3699, Val Loss: 2.2895, F1 Micro: 0.2604, F1 Macro: 0.2126, Accuracy: 0.2604\n","Epoch 28, Train Loss: 1.3594, Val Loss: 1.8266, F1 Micro: 0.3333, F1 Macro: 0.3020, Accuracy: 0.3333\n","Epoch 29, Train Loss: 1.3566, Val Loss: 1.9768, F1 Micro: 0.3854, F1 Macro: 0.3528, Accuracy: 0.3854\n","Epoch 30, Train Loss: 1.3406, Val Loss: 2.1070, F1 Micro: 0.3438, F1 Macro: 0.3021, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.3479, Val Loss: 1.8544, F1 Micro: 0.3229, F1 Macro: 0.2780, Accuracy: 0.3229\n","Epoch 32, Train Loss: 1.3642, Val Loss: 1.8765, F1 Micro: 0.4062, F1 Macro: 0.3758, Accuracy: 0.4062\n","Epoch 33, Train Loss: 1.3356, Val Loss: 2.2680, F1 Micro: 0.2188, F1 Macro: 0.1856, Accuracy: 0.2188\n","Epoch 34, Train Loss: 1.2761, Val Loss: 1.6514, F1 Micro: 0.3750, F1 Macro: 0.3703, Accuracy: 0.3750\n","Epoch 35, Train Loss: 1.2958, Val Loss: 1.8739, F1 Micro: 0.2708, F1 Macro: 0.2541, Accuracy: 0.2708\n","Epoch 36, Train Loss: 1.2582, Val Loss: 2.7955, F1 Micro: 0.2917, F1 Macro: 0.2077, Accuracy: 0.2917\n","Epoch 37, Train Loss: 1.3053, Val Loss: 1.6407, F1 Micro: 0.4479, F1 Macro: 0.4395, Accuracy: 0.4479\n","Epoch 38, Train Loss: 1.2613, Val Loss: 1.7514, F1 Micro: 0.3646, F1 Macro: 0.2961, Accuracy: 0.3646\n","Epoch 39, Train Loss: 1.2434, Val Loss: 3.0964, F1 Micro: 0.2812, F1 Macro: 0.1789, Accuracy: 0.2812\n","Epoch 40, Train Loss: 1.2820, Val Loss: 1.7763, F1 Micro: 0.3646, F1 Macro: 0.3100, Accuracy: 0.3646\n","Epoch 41, Train Loss: 1.2201, Val Loss: 1.7361, F1 Micro: 0.3542, F1 Macro: 0.3382, Accuracy: 0.3542\n","Epoch 42, Train Loss: 1.1954, Val Loss: 2.4058, F1 Micro: 0.3125, F1 Macro: 0.2612, Accuracy: 0.3125\n","Epoch 43, Train Loss: 1.2458, Val Loss: 1.7244, F1 Micro: 0.4167, F1 Macro: 0.3917, Accuracy: 0.4167\n","Epoch 44, Train Loss: 1.2089, Val Loss: 1.7105, F1 Micro: 0.3438, F1 Macro: 0.3070, Accuracy: 0.3438\n","Epoch 45, Train Loss: 1.1697, Val Loss: 1.6948, F1 Micro: 0.4479, F1 Macro: 0.4088, Accuracy: 0.4479\n","Epoch 46, Train Loss: 1.1671, Val Loss: 1.8031, F1 Micro: 0.4167, F1 Macro: 0.4058, Accuracy: 0.4167\n","Epoch 47, Train Loss: 1.1979, Val Loss: 2.1294, F1 Micro: 0.2812, F1 Macro: 0.2493, Accuracy: 0.2812\n","Epoch 48, Train Loss: 1.1719, Val Loss: 2.5878, F1 Micro: 0.3542, F1 Macro: 0.2855, Accuracy: 0.3542\n","Epoch 49, Train Loss: 1.1486, Val Loss: 1.7176, F1 Micro: 0.4896, F1 Macro: 0.4426, Accuracy: 0.4896\n","Epoch 50, Train Loss: 1.0954, Val Loss: 1.8197, F1 Micro: 0.4792, F1 Macro: 0.4450, Accuracy: 0.4792\n","Epoch 51, Train Loss: 1.1057, Val Loss: 1.9964, F1 Micro: 0.3438, F1 Macro: 0.2936, Accuracy: 0.3438\n","Epoch 52, Train Loss: 1.1358, Val Loss: 1.7353, F1 Micro: 0.5104, F1 Macro: 0.4914, Accuracy: 0.5104\n","Epoch 53, Train Loss: 1.1409, Val Loss: 1.8275, F1 Micro: 0.4062, F1 Macro: 0.3528, Accuracy: 0.4062\n","Epoch 54, Train Loss: 1.1045, Val Loss: 1.7432, F1 Micro: 0.4583, F1 Macro: 0.3993, Accuracy: 0.4583\n","Epoch 55, Train Loss: 1.1149, Val Loss: 2.4997, F1 Micro: 0.3438, F1 Macro: 0.2546, Accuracy: 0.3438\n","Epoch 56, Train Loss: 1.1211, Val Loss: 2.4313, F1 Micro: 0.3438, F1 Macro: 0.2607, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.1511, Val Loss: 2.4078, F1 Micro: 0.3438, F1 Macro: 0.3464, Accuracy: 0.3438\n","Epoch 58, Train Loss: 1.1570, Val Loss: 1.6759, F1 Micro: 0.4271, F1 Macro: 0.4052, Accuracy: 0.4271\n","Epoch 59, Train Loss: 1.1149, Val Loss: 1.9366, F1 Micro: 0.3542, F1 Macro: 0.3170, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.0536, Val Loss: 1.9264, F1 Micro: 0.4688, F1 Macro: 0.4351, Accuracy: 0.4688\n","Epoch 61, Train Loss: 1.0303, Val Loss: 1.8046, F1 Micro: 0.4271, F1 Macro: 0.3821, Accuracy: 0.4271\n","Epoch 62, Train Loss: 1.0513, Val Loss: 1.8624, F1 Micro: 0.4375, F1 Macro: 0.3811, Accuracy: 0.4375\n","Epoch 63, Train Loss: 0.9916, Val Loss: 2.1765, F1 Micro: 0.4375, F1 Macro: 0.4162, Accuracy: 0.4375\n","Epoch 64, Train Loss: 1.0943, Val Loss: 1.8213, F1 Micro: 0.3750, F1 Macro: 0.3446, Accuracy: 0.3750\n","Epoch 65, Train Loss: 1.0146, Val Loss: 1.8505, F1 Micro: 0.4271, F1 Macro: 0.4241, Accuracy: 0.4271\n","Epoch 66, Train Loss: 1.0275, Val Loss: 2.0013, F1 Micro: 0.4375, F1 Macro: 0.4274, Accuracy: 0.4375\n","Epoch 67, Train Loss: 1.0350, Val Loss: 2.4499, F1 Micro: 0.3958, F1 Macro: 0.3739, Accuracy: 0.3958\n","Epoch 68, Train Loss: 1.0169, Val Loss: 1.8469, F1 Micro: 0.4688, F1 Macro: 0.4337, Accuracy: 0.4688\n","Epoch 69, Train Loss: 1.0362, Val Loss: 1.9359, F1 Micro: 0.4479, F1 Macro: 0.4269, Accuracy: 0.4479\n","Epoch 70, Train Loss: 0.9779, Val Loss: 2.2359, F1 Micro: 0.5208, F1 Macro: 0.4997, Accuracy: 0.5208\n","Epoch 71, Train Loss: 1.0153, Val Loss: 2.0847, F1 Micro: 0.4167, F1 Macro: 0.3685, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.0090, Val Loss: 1.8094, F1 Micro: 0.4271, F1 Macro: 0.4178, Accuracy: 0.4271\n","Epoch 73, Train Loss: 0.9663, Val Loss: 1.8580, F1 Micro: 0.4375, F1 Macro: 0.4064, Accuracy: 0.4375\n","Epoch 74, Train Loss: 0.9714, Val Loss: 1.9778, F1 Micro: 0.4375, F1 Macro: 0.3700, Accuracy: 0.4375\n","Epoch 75, Train Loss: 0.9552, Val Loss: 2.1160, F1 Micro: 0.4167, F1 Macro: 0.3374, Accuracy: 0.4167\n","Epoch 76, Train Loss: 0.9626, Val Loss: 2.0311, F1 Micro: 0.4167, F1 Macro: 0.3899, Accuracy: 0.4167\n","Epoch 77, Train Loss: 1.0129, Val Loss: 1.8534, F1 Micro: 0.4792, F1 Macro: 0.4499, Accuracy: 0.4792\n","Epoch 78, Train Loss: 0.9386, Val Loss: 1.7466, F1 Micro: 0.4271, F1 Macro: 0.3802, Accuracy: 0.4271\n","Epoch 79, Train Loss: 0.8995, Val Loss: 2.1080, F1 Micro: 0.4479, F1 Macro: 0.4309, Accuracy: 0.4479\n","Epoch 80, Train Loss: 1.0050, Val Loss: 1.9454, F1 Micro: 0.4688, F1 Macro: 0.4526, Accuracy: 0.4688\n","Epoch 81, Train Loss: 0.9638, Val Loss: 2.1201, F1 Micro: 0.4167, F1 Macro: 0.3598, Accuracy: 0.4167\n","Epoch 82, Train Loss: 0.9208, Val Loss: 2.0746, F1 Micro: 0.5000, F1 Macro: 0.4697, Accuracy: 0.5000\n","Epoch 83, Train Loss: 0.9706, Val Loss: 2.0425, F1 Micro: 0.3958, F1 Macro: 0.3633, Accuracy: 0.3958\n","Epoch 84, Train Loss: 0.9001, Val Loss: 1.9378, F1 Micro: 0.4792, F1 Macro: 0.4648, Accuracy: 0.4792\n","Epoch 85, Train Loss: 0.9113, Val Loss: 2.1986, F1 Micro: 0.4688, F1 Macro: 0.4374, Accuracy: 0.4688\n","Epoch 86, Train Loss: 0.9260, Val Loss: 2.0118, F1 Micro: 0.4583, F1 Macro: 0.4007, Accuracy: 0.4583\n","Epoch 87, Train Loss: 0.9220, Val Loss: 2.2124, F1 Micro: 0.3958, F1 Macro: 0.3253, Accuracy: 0.3958\n","Epoch 88, Train Loss: 0.8958, Val Loss: 1.9394, F1 Micro: 0.4375, F1 Macro: 0.3760, Accuracy: 0.4375\n","Epoch 89, Train Loss: 0.8520, Val Loss: 2.3678, F1 Micro: 0.3958, F1 Macro: 0.3927, Accuracy: 0.3958\n","Epoch 90, Train Loss: 0.9343, Val Loss: 2.3757, F1 Micro: 0.4375, F1 Macro: 0.4276, Accuracy: 0.4375\n","Epoch 91, Train Loss: 0.9234, Val Loss: 2.1180, F1 Micro: 0.4583, F1 Macro: 0.3810, Accuracy: 0.4583\n","Epoch 92, Train Loss: 0.8865, Val Loss: 1.9752, F1 Micro: 0.4688, F1 Macro: 0.4371, Accuracy: 0.4688\n","Epoch 93, Train Loss: 0.9036, Val Loss: 1.9641, F1 Micro: 0.4375, F1 Macro: 0.4000, Accuracy: 0.4375\n","Epoch 94, Train Loss: 0.9075, Val Loss: 1.8092, F1 Micro: 0.4583, F1 Macro: 0.4512, Accuracy: 0.4583\n","Epoch 95, Train Loss: 0.8917, Val Loss: 2.2297, F1 Micro: 0.3854, F1 Macro: 0.3784, Accuracy: 0.3854\n","Epoch 96, Train Loss: 0.9051, Val Loss: 2.7058, F1 Micro: 0.2917, F1 Macro: 0.2598, Accuracy: 0.2917\n","Epoch 97, Train Loss: 0.8959, Val Loss: 2.1949, F1 Micro: 0.4792, F1 Macro: 0.4673, Accuracy: 0.4792\n","Epoch 98, Train Loss: 0.8316, Val Loss: 2.0640, F1 Micro: 0.4479, F1 Macro: 0.3764, Accuracy: 0.4479\n","Epoch 99, Train Loss: 0.8601, Val Loss: 2.5677, F1 Micro: 0.3333, F1 Macro: 0.2914, Accuracy: 0.3333\n","Epoch 100, Train Loss: 0.8741, Val Loss: 1.9786, F1 Micro: 0.4271, F1 Macro: 0.3581, Accuracy: 0.4271\n","Epoch 101, Train Loss: 0.8183, Val Loss: 1.9212, F1 Micro: 0.5000, F1 Macro: 0.4726, Accuracy: 0.5000\n","Epoch 102, Train Loss: 0.8013, Val Loss: 1.9014, F1 Micro: 0.4375, F1 Macro: 0.4207, Accuracy: 0.4375\n","Epoch 103, Train Loss: 0.8354, Val Loss: 1.8721, F1 Micro: 0.4792, F1 Macro: 0.4581, Accuracy: 0.4792\n","Epoch 104, Train Loss: 0.8061, Val Loss: 1.9126, F1 Micro: 0.5104, F1 Macro: 0.4904, Accuracy: 0.5104\n","Epoch 105, Train Loss: 0.7341, Val Loss: 2.0277, F1 Micro: 0.4792, F1 Macro: 0.4630, Accuracy: 0.4792\n","Epoch 106, Train Loss: 0.8073, Val Loss: 1.8355, F1 Micro: 0.4688, F1 Macro: 0.4442, Accuracy: 0.4688\n","Epoch 107, Train Loss: 0.7819, Val Loss: 1.8339, F1 Micro: 0.4375, F1 Macro: 0.4050, Accuracy: 0.4375\n","Epoch 108, Train Loss: 0.8656, Val Loss: 2.6875, F1 Micro: 0.4271, F1 Macro: 0.3853, Accuracy: 0.4271\n","Epoch 109, Train Loss: 0.8390, Val Loss: 2.1116, F1 Micro: 0.4792, F1 Macro: 0.4181, Accuracy: 0.4792\n","Epoch 110, Train Loss: 0.8234, Val Loss: 1.9260, F1 Micro: 0.4479, F1 Macro: 0.4190, Accuracy: 0.4479\n","Epoch 111, Train Loss: 0.8098, Val Loss: 2.2317, F1 Micro: 0.5000, F1 Macro: 0.4687, Accuracy: 0.5000\n","Epoch 112, Train Loss: 0.7417, Val Loss: 2.1525, F1 Micro: 0.4792, F1 Macro: 0.4458, Accuracy: 0.4792\n","Epoch 113, Train Loss: 0.6883, Val Loss: 1.9390, F1 Micro: 0.4167, F1 Macro: 0.3758, Accuracy: 0.4167\n","Epoch 114, Train Loss: 0.8150, Val Loss: 1.9567, F1 Micro: 0.4688, F1 Macro: 0.4553, Accuracy: 0.4688\n","Epoch 115, Train Loss: 0.8109, Val Loss: 1.8504, F1 Micro: 0.4375, F1 Macro: 0.4219, Accuracy: 0.4375\n","Epoch 116, Train Loss: 0.8736, Val Loss: 1.9686, F1 Micro: 0.4479, F1 Macro: 0.4415, Accuracy: 0.4479\n","Epoch 117, Train Loss: 0.7347, Val Loss: 1.9113, F1 Micro: 0.4375, F1 Macro: 0.4251, Accuracy: 0.4375\n","Epoch 118, Train Loss: 0.7406, Val Loss: 2.0723, F1 Micro: 0.5000, F1 Macro: 0.4845, Accuracy: 0.5000\n","Epoch 119, Train Loss: 0.7536, Val Loss: 1.8914, F1 Micro: 0.4271, F1 Macro: 0.3917, Accuracy: 0.4271\n","Epoch 120, Train Loss: 0.7234, Val Loss: 2.5315, F1 Micro: 0.4688, F1 Macro: 0.4180, Accuracy: 0.4688\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.7806, Val Loss: 1.7908, F1 Micro: 0.1979, F1 Macro: 0.1204, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7261, Val Loss: 1.7816, F1 Micro: 0.2083, F1 Macro: 0.1374, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.7448, Val Loss: 1.8262, F1 Micro: 0.2500, F1 Macro: 0.1235, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.7284, Val Loss: 1.8016, F1 Micro: 0.2083, F1 Macro: 0.1244, Accuracy: 0.2083\n","Epoch 5, Train Loss: 1.7076, Val Loss: 1.7634, F1 Micro: 0.3021, F1 Macro: 0.2106, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.6950, Val Loss: 1.8000, F1 Micro: 0.2396, F1 Macro: 0.1483, Accuracy: 0.2396\n","Epoch 7, Train Loss: 1.6672, Val Loss: 1.8483, F1 Micro: 0.2708, F1 Macro: 0.1860, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.6421, Val Loss: 1.7881, F1 Micro: 0.1979, F1 Macro: 0.1471, Accuracy: 0.1979\n","Epoch 9, Train Loss: 1.6009, Val Loss: 1.7341, F1 Micro: 0.2292, F1 Macro: 0.1909, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.5913, Val Loss: 1.7283, F1 Micro: 0.2604, F1 Macro: 0.2289, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.5881, Val Loss: 1.8787, F1 Micro: 0.2708, F1 Macro: 0.2154, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.5925, Val Loss: 2.1245, F1 Micro: 0.2083, F1 Macro: 0.1246, Accuracy: 0.2083\n","Epoch 13, Train Loss: 1.5985, Val Loss: 1.7587, F1 Micro: 0.1771, F1 Macro: 0.1372, Accuracy: 0.1771\n","Epoch 14, Train Loss: 1.5467, Val Loss: 1.8092, F1 Micro: 0.2604, F1 Macro: 0.2357, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.5473, Val Loss: 1.7209, F1 Micro: 0.3333, F1 Macro: 0.3086, Accuracy: 0.3333\n","Epoch 16, Train Loss: 1.5725, Val Loss: 1.7167, F1 Micro: 0.2604, F1 Macro: 0.2406, Accuracy: 0.2604\n","Epoch 17, Train Loss: 1.5647, Val Loss: 2.0076, F1 Micro: 0.2396, F1 Macro: 0.1795, Accuracy: 0.2396\n","Epoch 18, Train Loss: 1.5362, Val Loss: 1.6949, F1 Micro: 0.2604, F1 Macro: 0.2148, Accuracy: 0.2604\n","Epoch 19, Train Loss: 1.5175, Val Loss: 1.7591, F1 Micro: 0.2500, F1 Macro: 0.2112, Accuracy: 0.2500\n","Epoch 20, Train Loss: 1.5013, Val Loss: 2.0859, F1 Micro: 0.2083, F1 Macro: 0.1611, Accuracy: 0.2083\n","Epoch 21, Train Loss: 1.5147, Val Loss: 1.6852, F1 Micro: 0.3021, F1 Macro: 0.2725, Accuracy: 0.3021\n","Epoch 22, Train Loss: 1.5037, Val Loss: 1.8299, F1 Micro: 0.2604, F1 Macro: 0.2322, Accuracy: 0.2604\n","Epoch 23, Train Loss: 1.4941, Val Loss: 1.8094, F1 Micro: 0.3021, F1 Macro: 0.2517, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.4901, Val Loss: 1.9869, F1 Micro: 0.2396, F1 Macro: 0.2093, Accuracy: 0.2396\n","Epoch 25, Train Loss: 1.4903, Val Loss: 1.8043, F1 Micro: 0.2917, F1 Macro: 0.2545, Accuracy: 0.2917\n","Epoch 26, Train Loss: 1.4426, Val Loss: 2.0229, F1 Micro: 0.2292, F1 Macro: 0.2027, Accuracy: 0.2292\n","Epoch 27, Train Loss: 1.4853, Val Loss: 1.8181, F1 Micro: 0.2812, F1 Macro: 0.2694, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.4741, Val Loss: 2.0712, F1 Micro: 0.2604, F1 Macro: 0.2235, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.4482, Val Loss: 1.8074, F1 Micro: 0.2917, F1 Macro: 0.2627, Accuracy: 0.2917\n","Epoch 30, Train Loss: 1.4331, Val Loss: 1.8591, F1 Micro: 0.3333, F1 Macro: 0.2663, Accuracy: 0.3333\n","Epoch 31, Train Loss: 1.4474, Val Loss: 2.0251, F1 Micro: 0.2604, F1 Macro: 0.2245, Accuracy: 0.2604\n","Epoch 32, Train Loss: 1.4170, Val Loss: 2.3262, F1 Micro: 0.2604, F1 Macro: 0.2206, Accuracy: 0.2604\n","Epoch 33, Train Loss: 1.4617, Val Loss: 1.8210, F1 Micro: 0.2812, F1 Macro: 0.2619, Accuracy: 0.2812\n","Epoch 34, Train Loss: 1.4358, Val Loss: 1.8960, F1 Micro: 0.3229, F1 Macro: 0.2991, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.3923, Val Loss: 1.9072, F1 Micro: 0.3333, F1 Macro: 0.3043, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.3837, Val Loss: 2.2631, F1 Micro: 0.2708, F1 Macro: 0.2329, Accuracy: 0.2708\n","Epoch 37, Train Loss: 1.3985, Val Loss: 1.8418, F1 Micro: 0.3438, F1 Macro: 0.3042, Accuracy: 0.3438\n","Epoch 38, Train Loss: 1.3966, Val Loss: 2.0564, F1 Micro: 0.3229, F1 Macro: 0.2983, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.3631, Val Loss: 1.8188, F1 Micro: 0.3333, F1 Macro: 0.2872, Accuracy: 0.3333\n","Epoch 40, Train Loss: 1.4001, Val Loss: 1.7793, F1 Micro: 0.3854, F1 Macro: 0.3481, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.3645, Val Loss: 1.9275, F1 Micro: 0.3438, F1 Macro: 0.3335, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.3308, Val Loss: 2.0263, F1 Micro: 0.3229, F1 Macro: 0.2980, Accuracy: 0.3229\n","Epoch 43, Train Loss: 1.3728, Val Loss: 2.1722, F1 Micro: 0.3021, F1 Macro: 0.2756, Accuracy: 0.3021\n","Epoch 44, Train Loss: 1.2932, Val Loss: 1.9245, F1 Micro: 0.3646, F1 Macro: 0.3121, Accuracy: 0.3646\n","Epoch 45, Train Loss: 1.3404, Val Loss: 2.5000, F1 Micro: 0.2188, F1 Macro: 0.1851, Accuracy: 0.2188\n","Epoch 46, Train Loss: 1.3885, Val Loss: 1.9691, F1 Micro: 0.3021, F1 Macro: 0.2733, Accuracy: 0.3021\n","Epoch 47, Train Loss: 1.2999, Val Loss: 2.2027, F1 Micro: 0.3021, F1 Macro: 0.2573, Accuracy: 0.3021\n","Epoch 48, Train Loss: 1.3012, Val Loss: 2.0033, F1 Micro: 0.3021, F1 Macro: 0.2791, Accuracy: 0.3021\n","Epoch 49, Train Loss: 1.2884, Val Loss: 2.6327, F1 Micro: 0.2396, F1 Macro: 0.2118, Accuracy: 0.2396\n","Epoch 50, Train Loss: 1.3574, Val Loss: 1.9609, F1 Micro: 0.3333, F1 Macro: 0.3017, Accuracy: 0.3333\n","Epoch 51, Train Loss: 1.2632, Val Loss: 2.1590, F1 Micro: 0.3125, F1 Macro: 0.2931, Accuracy: 0.3125\n","Epoch 52, Train Loss: 1.2920, Val Loss: 2.6970, F1 Micro: 0.2917, F1 Macro: 0.2334, Accuracy: 0.2917\n","Epoch 53, Train Loss: 1.3371, Val Loss: 2.4321, F1 Micro: 0.2812, F1 Macro: 0.2384, Accuracy: 0.2812\n","Epoch 54, Train Loss: 1.2589, Val Loss: 2.1722, F1 Micro: 0.2708, F1 Macro: 0.2603, Accuracy: 0.2708\n","Epoch 55, Train Loss: 1.2623, Val Loss: 2.0634, F1 Micro: 0.2812, F1 Macro: 0.2483, Accuracy: 0.2812\n","Epoch 56, Train Loss: 1.2328, Val Loss: 2.1873, F1 Micro: 0.3333, F1 Macro: 0.3201, Accuracy: 0.3333\n","Epoch 57, Train Loss: 1.2614, Val Loss: 2.5580, F1 Micro: 0.2604, F1 Macro: 0.2092, Accuracy: 0.2604\n","Epoch 58, Train Loss: 1.2982, Val Loss: 2.0757, F1 Micro: 0.3229, F1 Macro: 0.2940, Accuracy: 0.3229\n","Epoch 59, Train Loss: 1.2613, Val Loss: 2.1605, F1 Micro: 0.3125, F1 Macro: 0.2946, Accuracy: 0.3125\n","Epoch 60, Train Loss: 1.2480, Val Loss: 3.4597, F1 Micro: 0.2500, F1 Macro: 0.1897, Accuracy: 0.2500\n","Epoch 61, Train Loss: 1.2065, Val Loss: 2.2704, F1 Micro: 0.3854, F1 Macro: 0.3644, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.2099, Val Loss: 2.1843, F1 Micro: 0.3333, F1 Macro: 0.3043, Accuracy: 0.3333\n","Epoch 63, Train Loss: 1.1663, Val Loss: 2.3619, F1 Micro: 0.2812, F1 Macro: 0.2458, Accuracy: 0.2812\n","Epoch 64, Train Loss: 1.1546, Val Loss: 2.4685, F1 Micro: 0.2917, F1 Macro: 0.2384, Accuracy: 0.2917\n","Epoch 65, Train Loss: 1.2206, Val Loss: 2.2151, F1 Micro: 0.2917, F1 Macro: 0.2701, Accuracy: 0.2917\n","Epoch 66, Train Loss: 1.1925, Val Loss: 2.1095, F1 Micro: 0.3229, F1 Macro: 0.2698, Accuracy: 0.3229\n","Epoch 67, Train Loss: 1.1394, Val Loss: 2.2174, F1 Micro: 0.4062, F1 Macro: 0.3888, Accuracy: 0.4062\n","Epoch 68, Train Loss: 1.1616, Val Loss: 3.3450, F1 Micro: 0.2500, F1 Macro: 0.1837, Accuracy: 0.2500\n","Epoch 69, Train Loss: 1.2494, Val Loss: 2.1462, F1 Micro: 0.3958, F1 Macro: 0.3791, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.1441, Val Loss: 2.7214, F1 Micro: 0.2604, F1 Macro: 0.2320, Accuracy: 0.2604\n","Epoch 71, Train Loss: 1.1818, Val Loss: 2.2847, F1 Micro: 0.3854, F1 Macro: 0.3755, Accuracy: 0.3854\n","Epoch 72, Train Loss: 1.1726, Val Loss: 2.0329, F1 Micro: 0.3333, F1 Macro: 0.3293, Accuracy: 0.3333\n","Epoch 73, Train Loss: 1.1368, Val Loss: 2.3954, F1 Micro: 0.3125, F1 Macro: 0.2898, Accuracy: 0.3125\n","Epoch 74, Train Loss: 1.1430, Val Loss: 2.2151, F1 Micro: 0.3333, F1 Macro: 0.3264, Accuracy: 0.3333\n","Epoch 75, Train Loss: 1.1257, Val Loss: 2.1230, F1 Micro: 0.3438, F1 Macro: 0.3334, Accuracy: 0.3438\n","Epoch 76, Train Loss: 1.1157, Val Loss: 2.2211, F1 Micro: 0.4167, F1 Macro: 0.3868, Accuracy: 0.4167\n","Epoch 77, Train Loss: 1.0885, Val Loss: 2.6140, F1 Micro: 0.3438, F1 Macro: 0.3277, Accuracy: 0.3438\n","Epoch 78, Train Loss: 1.1287, Val Loss: 2.1352, F1 Micro: 0.4062, F1 Macro: 0.3968, Accuracy: 0.4062\n","Epoch 79, Train Loss: 1.1171, Val Loss: 2.6553, F1 Micro: 0.3229, F1 Macro: 0.2803, Accuracy: 0.3229\n","Epoch 80, Train Loss: 1.1526, Val Loss: 2.3947, F1 Micro: 0.3958, F1 Macro: 0.3692, Accuracy: 0.3958\n","Epoch 81, Train Loss: 1.1071, Val Loss: 2.3580, F1 Micro: 0.3750, F1 Macro: 0.3606, Accuracy: 0.3750\n","Epoch 82, Train Loss: 1.1048, Val Loss: 2.3763, F1 Micro: 0.3958, F1 Macro: 0.3670, Accuracy: 0.3958\n","Epoch 83, Train Loss: 1.0264, Val Loss: 2.6894, F1 Micro: 0.4167, F1 Macro: 0.3671, Accuracy: 0.4167\n","Epoch 84, Train Loss: 1.1182, Val Loss: 2.2675, F1 Micro: 0.3750, F1 Macro: 0.3465, Accuracy: 0.3750\n","Epoch 85, Train Loss: 1.1168, Val Loss: 2.1639, F1 Micro: 0.3854, F1 Macro: 0.3628, Accuracy: 0.3854\n","Epoch 86, Train Loss: 1.0809, Val Loss: 3.0467, F1 Micro: 0.2812, F1 Macro: 0.2367, Accuracy: 0.2812\n","Epoch 87, Train Loss: 1.0442, Val Loss: 2.6545, F1 Micro: 0.3229, F1 Macro: 0.2935, Accuracy: 0.3229\n","Epoch 88, Train Loss: 1.0621, Val Loss: 2.5354, F1 Micro: 0.4062, F1 Macro: 0.4026, Accuracy: 0.4062\n","Epoch 89, Train Loss: 1.0598, Val Loss: 2.0819, F1 Micro: 0.4271, F1 Macro: 0.4142, Accuracy: 0.4271\n","Epoch 90, Train Loss: 1.0687, Val Loss: 2.5228, F1 Micro: 0.3438, F1 Macro: 0.3033, Accuracy: 0.3438\n","Epoch 91, Train Loss: 1.0835, Val Loss: 2.3327, F1 Micro: 0.4167, F1 Macro: 0.4024, Accuracy: 0.4167\n","Epoch 92, Train Loss: 1.0870, Val Loss: 3.1067, F1 Micro: 0.2396, F1 Macro: 0.2184, Accuracy: 0.2396\n","Epoch 93, Train Loss: 1.0144, Val Loss: 2.3334, F1 Micro: 0.4271, F1 Macro: 0.4163, Accuracy: 0.4271\n","Epoch 94, Train Loss: 1.0220, Val Loss: 2.5813, F1 Micro: 0.3542, F1 Macro: 0.3117, Accuracy: 0.3542\n","Epoch 95, Train Loss: 1.0170, Val Loss: 2.6239, F1 Micro: 0.3854, F1 Macro: 0.3649, Accuracy: 0.3854\n","Epoch 96, Train Loss: 1.0430, Val Loss: 2.5296, F1 Micro: 0.4062, F1 Macro: 0.3812, Accuracy: 0.4062\n","Epoch 97, Train Loss: 0.9980, Val Loss: 2.3713, F1 Micro: 0.4479, F1 Macro: 0.4333, Accuracy: 0.4479\n","Epoch 98, Train Loss: 0.9716, Val Loss: 2.4331, F1 Micro: 0.4167, F1 Macro: 0.3909, Accuracy: 0.4167\n","Epoch 99, Train Loss: 1.0074, Val Loss: 2.3879, F1 Micro: 0.3646, F1 Macro: 0.3500, Accuracy: 0.3646\n","Epoch 100, Train Loss: 1.0462, Val Loss: 2.7108, F1 Micro: 0.3646, F1 Macro: 0.3572, Accuracy: 0.3646\n","Epoch 101, Train Loss: 0.9895, Val Loss: 2.4331, F1 Micro: 0.4583, F1 Macro: 0.4308, Accuracy: 0.4583\n","Epoch 102, Train Loss: 0.9964, Val Loss: 2.6744, F1 Micro: 0.4062, F1 Macro: 0.4051, Accuracy: 0.4062\n","Epoch 103, Train Loss: 0.9884, Val Loss: 2.9024, F1 Micro: 0.3333, F1 Macro: 0.3236, Accuracy: 0.3333\n","Epoch 104, Train Loss: 1.0216, Val Loss: 2.6833, F1 Micro: 0.3854, F1 Macro: 0.3641, Accuracy: 0.3854\n","Epoch 105, Train Loss: 1.0723, Val Loss: 2.5930, F1 Micro: 0.3958, F1 Macro: 0.3882, Accuracy: 0.3958\n","Epoch 106, Train Loss: 0.9759, Val Loss: 2.5780, F1 Micro: 0.4062, F1 Macro: 0.3671, Accuracy: 0.4062\n","Epoch 107, Train Loss: 1.0079, Val Loss: 2.2710, F1 Micro: 0.4271, F1 Macro: 0.4146, Accuracy: 0.4271\n","Epoch 108, Train Loss: 0.9547, Val Loss: 2.4810, F1 Micro: 0.3750, F1 Macro: 0.3404, Accuracy: 0.3750\n","Epoch 109, Train Loss: 0.9737, Val Loss: 2.8200, F1 Micro: 0.4062, F1 Macro: 0.3808, Accuracy: 0.4062\n","Epoch 110, Train Loss: 0.9598, Val Loss: 2.2828, F1 Micro: 0.4583, F1 Macro: 0.4518, Accuracy: 0.4583\n","Epoch 111, Train Loss: 0.9655, Val Loss: 2.6712, F1 Micro: 0.3854, F1 Macro: 0.3717, Accuracy: 0.3854\n","Epoch 112, Train Loss: 0.8819, Val Loss: 2.9079, F1 Micro: 0.4062, F1 Macro: 0.3988, Accuracy: 0.4062\n","Epoch 113, Train Loss: 1.0634, Val Loss: 2.6774, F1 Micro: 0.4167, F1 Macro: 0.4024, Accuracy: 0.4167\n","Epoch 114, Train Loss: 0.9450, Val Loss: 2.6433, F1 Micro: 0.4167, F1 Macro: 0.4029, Accuracy: 0.4167\n","Epoch 115, Train Loss: 0.8968, Val Loss: 2.5161, F1 Micro: 0.3854, F1 Macro: 0.3651, Accuracy: 0.3854\n","Epoch 116, Train Loss: 0.9214, Val Loss: 3.1075, F1 Micro: 0.3750, F1 Macro: 0.3520, Accuracy: 0.3750\n","Epoch 117, Train Loss: 0.9273, Val Loss: 2.6822, F1 Micro: 0.4479, F1 Macro: 0.4302, Accuracy: 0.4479\n","Epoch 118, Train Loss: 0.9139, Val Loss: 2.7676, F1 Micro: 0.4375, F1 Macro: 0.4243, Accuracy: 0.4375\n","Epoch 119, Train Loss: 0.9207, Val Loss: 3.2263, F1 Micro: 0.4271, F1 Macro: 0.3894, Accuracy: 0.4271\n","Epoch 120, Train Loss: 0.9586, Val Loss: 2.7584, F1 Micro: 0.3750, F1 Macro: 0.3687, Accuracy: 0.3750\n","Epoch 121, Train Loss: 0.9296, Val Loss: 2.6459, F1 Micro: 0.3750, F1 Macro: 0.3516, Accuracy: 0.3750\n","Epoch 122, Train Loss: 0.8984, Val Loss: 3.1479, F1 Micro: 0.4167, F1 Macro: 0.3950, Accuracy: 0.4167\n","Epoch 123, Train Loss: 0.9453, Val Loss: 3.1877, F1 Micro: 0.4271, F1 Macro: 0.4088, Accuracy: 0.4271\n","Epoch 124, Train Loss: 0.9570, Val Loss: 2.6240, F1 Micro: 0.4688, F1 Macro: 0.4663, Accuracy: 0.4688\n","Epoch 125, Train Loss: 0.8839, Val Loss: 2.6614, F1 Micro: 0.4583, F1 Macro: 0.4561, Accuracy: 0.4583\n","Epoch 126, Train Loss: 0.8948, Val Loss: 2.7563, F1 Micro: 0.4375, F1 Macro: 0.4229, Accuracy: 0.4375\n","Epoch 127, Train Loss: 0.8583, Val Loss: 2.8787, F1 Micro: 0.3021, F1 Macro: 0.3048, Accuracy: 0.3021\n","Epoch 128, Train Loss: 0.8879, Val Loss: 2.7712, F1 Micro: 0.4583, F1 Macro: 0.4445, Accuracy: 0.4583\n","Epoch 129, Train Loss: 0.8777, Val Loss: 2.7495, F1 Micro: 0.4688, F1 Macro: 0.4575, Accuracy: 0.4688\n","Epoch 130, Train Loss: 0.8704, Val Loss: 2.7652, F1 Micro: 0.4792, F1 Macro: 0.4729, Accuracy: 0.4792\n","Epoch 131, Train Loss: 0.8915, Val Loss: 2.9083, F1 Micro: 0.4479, F1 Macro: 0.4390, Accuracy: 0.4479\n","Epoch 132, Train Loss: 0.8847, Val Loss: 3.0772, F1 Micro: 0.4688, F1 Macro: 0.4573, Accuracy: 0.4688\n","Epoch 133, Train Loss: 0.8478, Val Loss: 2.7446, F1 Micro: 0.4792, F1 Macro: 0.4811, Accuracy: 0.4792\n","Epoch 134, Train Loss: 0.8475, Val Loss: 2.6497, F1 Micro: 0.4688, F1 Macro: 0.4560, Accuracy: 0.4688\n","Epoch 135, Train Loss: 0.8620, Val Loss: 3.1884, F1 Micro: 0.4271, F1 Macro: 0.4231, Accuracy: 0.4271\n","Epoch 136, Train Loss: 0.8076, Val Loss: 3.1818, F1 Micro: 0.4479, F1 Macro: 0.4303, Accuracy: 0.4479\n","Epoch 137, Train Loss: 0.8192, Val Loss: 2.9507, F1 Micro: 0.4688, F1 Macro: 0.4622, Accuracy: 0.4688\n","Epoch 138, Train Loss: 0.8227, Val Loss: 3.1099, F1 Micro: 0.3854, F1 Macro: 0.3705, Accuracy: 0.3854\n","Epoch 139, Train Loss: 0.9255, Val Loss: 3.2038, F1 Micro: 0.3646, F1 Macro: 0.3506, Accuracy: 0.3646\n","Epoch 140, Train Loss: 0.8438, Val Loss: 3.2240, F1 Micro: 0.4062, F1 Macro: 0.3996, Accuracy: 0.4062\n","Epoch 141, Train Loss: 0.9310, Val Loss: 3.2123, F1 Micro: 0.3438, F1 Macro: 0.3342, Accuracy: 0.3438\n","Epoch 142, Train Loss: 0.8243, Val Loss: 2.8435, F1 Micro: 0.4479, F1 Macro: 0.4376, Accuracy: 0.4479\n","Epoch 143, Train Loss: 0.8016, Val Loss: 2.9578, F1 Micro: 0.4167, F1 Macro: 0.4122, Accuracy: 0.4167\n","Epoch 144, Train Loss: 0.8504, Val Loss: 3.2848, F1 Micro: 0.4167, F1 Macro: 0.3948, Accuracy: 0.4167\n","Epoch 145, Train Loss: 0.8616, Val Loss: 2.8682, F1 Micro: 0.4688, F1 Macro: 0.4427, Accuracy: 0.4688\n","Epoch 146, Train Loss: 0.7980, Val Loss: 3.4179, F1 Micro: 0.4271, F1 Macro: 0.4203, Accuracy: 0.4271\n","Epoch 147, Train Loss: 0.7512, Val Loss: 3.1141, F1 Micro: 0.4479, F1 Macro: 0.4513, Accuracy: 0.4479\n","Epoch 148, Train Loss: 0.8010, Val Loss: 3.4763, F1 Micro: 0.3958, F1 Macro: 0.3615, Accuracy: 0.3958\n","Epoch 149, Train Loss: 0.8083, Val Loss: 2.9605, F1 Micro: 0.4688, F1 Macro: 0.4460, Accuracy: 0.4688\n","Epoch 150, Train Loss: 0.8083, Val Loss: 3.0700, F1 Micro: 0.4167, F1 Macro: 0.4088, Accuracy: 0.4167\n","Epoch 151, Train Loss: 0.8862, Val Loss: 2.5940, F1 Micro: 0.4792, F1 Macro: 0.4750, Accuracy: 0.4792\n","Epoch 152, Train Loss: 0.7510, Val Loss: 2.9297, F1 Micro: 0.4271, F1 Macro: 0.4132, Accuracy: 0.4271\n","Epoch 153, Train Loss: 0.7940, Val Loss: 3.0422, F1 Micro: 0.4792, F1 Macro: 0.4596, Accuracy: 0.4792\n","Epoch 154, Train Loss: 0.8099, Val Loss: 3.3889, F1 Micro: 0.4792, F1 Macro: 0.4763, Accuracy: 0.4792\n","Epoch 155, Train Loss: 0.7602, Val Loss: 2.9836, F1 Micro: 0.3958, F1 Macro: 0.3868, Accuracy: 0.3958\n","Epoch 156, Train Loss: 0.7693, Val Loss: 2.9084, F1 Micro: 0.4271, F1 Macro: 0.4061, Accuracy: 0.4271\n","Epoch 157, Train Loss: 0.7883, Val Loss: 3.1282, F1 Micro: 0.4792, F1 Macro: 0.4714, Accuracy: 0.4792\n","Epoch 158, Train Loss: 0.7892, Val Loss: 3.1773, F1 Micro: 0.4792, F1 Macro: 0.4668, Accuracy: 0.4792\n","Epoch 159, Train Loss: 0.7568, Val Loss: 3.5202, F1 Micro: 0.4062, F1 Macro: 0.3986, Accuracy: 0.4062\n","Epoch 160, Train Loss: 0.6918, Val Loss: 3.0263, F1 Micro: 0.4583, F1 Macro: 0.4574, Accuracy: 0.4583\n","Epoch 161, Train Loss: 0.7156, Val Loss: 3.5135, F1 Micro: 0.3750, F1 Macro: 0.3361, Accuracy: 0.3750\n","Epoch 162, Train Loss: 0.7529, Val Loss: 2.9665, F1 Micro: 0.4688, F1 Macro: 0.4216, Accuracy: 0.4688\n","Epoch 163, Train Loss: 0.7088, Val Loss: 3.0565, F1 Micro: 0.4896, F1 Macro: 0.4736, Accuracy: 0.4896\n","Epoch 164, Train Loss: 0.7808, Val Loss: 3.5659, F1 Micro: 0.4271, F1 Macro: 0.4210, Accuracy: 0.4271\n","Epoch 165, Train Loss: 0.7359, Val Loss: 3.2322, F1 Micro: 0.3854, F1 Macro: 0.3707, Accuracy: 0.3854\n","Epoch 166, Train Loss: 0.7581, Val Loss: 3.2112, F1 Micro: 0.4688, F1 Macro: 0.4567, Accuracy: 0.4688\n","Epoch 167, Train Loss: 0.7217, Val Loss: 3.1274, F1 Micro: 0.4271, F1 Macro: 0.4041, Accuracy: 0.4271\n","Epoch 168, Train Loss: 0.7085, Val Loss: 3.3205, F1 Micro: 0.4271, F1 Macro: 0.4104, Accuracy: 0.4271\n","Epoch 169, Train Loss: 0.7237, Val Loss: 4.0350, F1 Micro: 0.4062, F1 Macro: 0.3515, Accuracy: 0.4062\n","Epoch 170, Train Loss: 0.8163, Val Loss: 3.4469, F1 Micro: 0.3854, F1 Macro: 0.3572, Accuracy: 0.3854\n","Epoch 171, Train Loss: 0.7645, Val Loss: 3.4354, F1 Micro: 0.4792, F1 Macro: 0.4691, Accuracy: 0.4792\n","Epoch 172, Train Loss: 0.6909, Val Loss: 3.2109, F1 Micro: 0.4479, F1 Macro: 0.4415, Accuracy: 0.4479\n","Epoch 173, Train Loss: 0.7103, Val Loss: 3.2646, F1 Micro: 0.4792, F1 Macro: 0.4819, Accuracy: 0.4792\n","Epoch 174, Train Loss: 0.6753, Val Loss: 4.0354, F1 Micro: 0.4167, F1 Macro: 0.3922, Accuracy: 0.4167\n","Epoch 175, Train Loss: 0.6930, Val Loss: 2.7937, F1 Micro: 0.4792, F1 Macro: 0.4536, Accuracy: 0.4792\n","Epoch 176, Train Loss: 0.7648, Val Loss: 3.3021, F1 Micro: 0.4896, F1 Macro: 0.4839, Accuracy: 0.4896\n","Epoch 177, Train Loss: 0.7331, Val Loss: 3.2506, F1 Micro: 0.5000, F1 Macro: 0.4934, Accuracy: 0.5000\n","Epoch 178, Train Loss: 0.7446, Val Loss: 3.3599, F1 Micro: 0.5104, F1 Macro: 0.5143, Accuracy: 0.5104\n","Epoch 179, Train Loss: 0.6323, Val Loss: 3.2233, F1 Micro: 0.4062, F1 Macro: 0.3968, Accuracy: 0.4062\n","Epoch 180, Train Loss: 0.6408, Val Loss: 3.5198, F1 Micro: 0.4375, F1 Macro: 0.4368, Accuracy: 0.4375\n","Epoch 181, Train Loss: 0.7305, Val Loss: 3.2950, F1 Micro: 0.4062, F1 Macro: 0.3901, Accuracy: 0.4062\n","Epoch 182, Train Loss: 0.7180, Val Loss: 2.9013, F1 Micro: 0.4271, F1 Macro: 0.4182, Accuracy: 0.4271\n","Epoch 183, Train Loss: 0.7155, Val Loss: 3.1473, F1 Micro: 0.4375, F1 Macro: 0.4073, Accuracy: 0.4375\n","Epoch 184, Train Loss: 0.7673, Val Loss: 3.1558, F1 Micro: 0.4479, F1 Macro: 0.4391, Accuracy: 0.4479\n","Epoch 185, Train Loss: 0.6386, Val Loss: 3.0699, F1 Micro: 0.4896, F1 Macro: 0.4844, Accuracy: 0.4896\n","Epoch 186, Train Loss: 0.6545, Val Loss: 3.5879, F1 Micro: 0.4583, F1 Macro: 0.4319, Accuracy: 0.4583\n","Epoch 187, Train Loss: 0.6808, Val Loss: 3.0499, F1 Micro: 0.4688, F1 Macro: 0.4629, Accuracy: 0.4688\n","Epoch 188, Train Loss: 0.6661, Val Loss: 3.9978, F1 Micro: 0.4167, F1 Macro: 0.4185, Accuracy: 0.4167\n","Epoch 189, Train Loss: 0.7437, Val Loss: 3.5429, F1 Micro: 0.4062, F1 Macro: 0.3793, Accuracy: 0.4062\n","Epoch 190, Train Loss: 0.6739, Val Loss: 3.6590, F1 Micro: 0.4167, F1 Macro: 0.3890, Accuracy: 0.4167\n","Epoch 191, Train Loss: 0.6909, Val Loss: 3.2552, F1 Micro: 0.4896, F1 Macro: 0.4861, Accuracy: 0.4896\n","Epoch 192, Train Loss: 0.6555, Val Loss: 3.4196, F1 Micro: 0.4688, F1 Macro: 0.4550, Accuracy: 0.4688\n","Epoch 193, Train Loss: 0.6872, Val Loss: 3.0719, F1 Micro: 0.4688, F1 Macro: 0.4661, Accuracy: 0.4688\n","Epoch 194, Train Loss: 0.6731, Val Loss: 3.2526, F1 Micro: 0.4792, F1 Macro: 0.4646, Accuracy: 0.4792\n","Epoch 195, Train Loss: 0.6324, Val Loss: 3.7714, F1 Micro: 0.3958, F1 Macro: 0.3710, Accuracy: 0.3958\n","Epoch 196, Train Loss: 0.6038, Val Loss: 3.3973, F1 Micro: 0.4167, F1 Macro: 0.3955, Accuracy: 0.4167\n","Epoch 197, Train Loss: 0.6134, Val Loss: 3.6507, F1 Micro: 0.4479, F1 Macro: 0.4197, Accuracy: 0.4479\n","Epoch 198, Train Loss: 0.7864, Val Loss: 3.5602, F1 Micro: 0.4792, F1 Macro: 0.4583, Accuracy: 0.4792\n","Epoch 199, Train Loss: 0.7039, Val Loss: 3.4354, F1 Micro: 0.4167, F1 Macro: 0.3788, Accuracy: 0.4167\n","Epoch 200, Train Loss: 0.7010, Val Loss: 2.7401, F1 Micro: 0.4792, F1 Macro: 0.4663, Accuracy: 0.4792\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.7955, Val Loss: 1.6945, F1 Micro: 0.2604, F1 Macro: 0.1910, Accuracy: 0.2604\n","Epoch 2, Train Loss: 1.7797, Val Loss: 1.7172, F1 Micro: 0.2083, F1 Macro: 0.1179, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.7502, Val Loss: 1.9570, F1 Micro: 0.2708, F1 Macro: 0.1587, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.7633, Val Loss: 1.6583, F1 Micro: 0.3021, F1 Macro: 0.2533, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.7364, Val Loss: 1.6277, F1 Micro: 0.2812, F1 Macro: 0.2175, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.7447, Val Loss: 1.6696, F1 Micro: 0.3542, F1 Macro: 0.2688, Accuracy: 0.3542\n","Epoch 7, Train Loss: 1.7614, Val Loss: 1.6500, F1 Micro: 0.3125, F1 Macro: 0.2294, Accuracy: 0.3125\n","Epoch 8, Train Loss: 1.7087, Val Loss: 1.6115, F1 Micro: 0.3333, F1 Macro: 0.2859, Accuracy: 0.3333\n","Epoch 9, Train Loss: 1.7039, Val Loss: 1.6585, F1 Micro: 0.2708, F1 Macro: 0.2064, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.7147, Val Loss: 1.6451, F1 Micro: 0.2917, F1 Macro: 0.2172, Accuracy: 0.2917\n","Epoch 11, Train Loss: 1.7228, Val Loss: 1.6274, F1 Micro: 0.3542, F1 Macro: 0.2977, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.7136, Val Loss: 1.6586, F1 Micro: 0.2812, F1 Macro: 0.2234, Accuracy: 0.2812\n","Epoch 13, Train Loss: 1.6970, Val Loss: 1.6151, F1 Micro: 0.3229, F1 Macro: 0.2246, Accuracy: 0.3229\n","Epoch 14, Train Loss: 1.6971, Val Loss: 1.7394, F1 Micro: 0.3229, F1 Macro: 0.2281, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.6987, Val Loss: 1.6293, F1 Micro: 0.2917, F1 Macro: 0.2070, Accuracy: 0.2917\n","Epoch 16, Train Loss: 1.6865, Val Loss: 1.6183, F1 Micro: 0.3646, F1 Macro: 0.2962, Accuracy: 0.3646\n","Epoch 17, Train Loss: 1.6770, Val Loss: 1.6524, F1 Micro: 0.3125, F1 Macro: 0.2781, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.6714, Val Loss: 1.6039, F1 Micro: 0.3438, F1 Macro: 0.2601, Accuracy: 0.3438\n","Epoch 19, Train Loss: 1.6912, Val Loss: 1.5910, F1 Micro: 0.3542, F1 Macro: 0.2574, Accuracy: 0.3542\n","Epoch 20, Train Loss: 1.6797, Val Loss: 1.6228, F1 Micro: 0.3229, F1 Macro: 0.2795, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.6655, Val Loss: 1.9479, F1 Micro: 0.2812, F1 Macro: 0.2114, Accuracy: 0.2812\n","Epoch 22, Train Loss: 1.6839, Val Loss: 1.7290, F1 Micro: 0.3542, F1 Macro: 0.2746, Accuracy: 0.3542\n","Epoch 23, Train Loss: 1.6580, Val Loss: 1.6053, F1 Micro: 0.3542, F1 Macro: 0.3059, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.6942, Val Loss: 1.6381, F1 Micro: 0.3438, F1 Macro: 0.2668, Accuracy: 0.3438\n","Epoch 25, Train Loss: 1.6806, Val Loss: 1.6292, F1 Micro: 0.3125, F1 Macro: 0.2860, Accuracy: 0.3125\n","Epoch 26, Train Loss: 1.6663, Val Loss: 1.8799, F1 Micro: 0.3125, F1 Macro: 0.2128, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.6756, Val Loss: 1.5747, F1 Micro: 0.3958, F1 Macro: 0.3371, Accuracy: 0.3958\n","Epoch 28, Train Loss: 1.6693, Val Loss: 1.5656, F1 Micro: 0.3750, F1 Macro: 0.3111, Accuracy: 0.3750\n","Epoch 29, Train Loss: 1.6532, Val Loss: 1.5983, F1 Micro: 0.3958, F1 Macro: 0.3279, Accuracy: 0.3958\n","Epoch 30, Train Loss: 1.6572, Val Loss: 1.5819, F1 Micro: 0.4062, F1 Macro: 0.3511, Accuracy: 0.4062\n","Epoch 31, Train Loss: 1.6251, Val Loss: 1.6247, F1 Micro: 0.3229, F1 Macro: 0.2777, Accuracy: 0.3229\n","Epoch 32, Train Loss: 1.6448, Val Loss: 1.6204, F1 Micro: 0.3333, F1 Macro: 0.2751, Accuracy: 0.3333\n","Epoch 33, Train Loss: 1.6493, Val Loss: 1.6181, F1 Micro: 0.3750, F1 Macro: 0.3620, Accuracy: 0.3750\n","Epoch 34, Train Loss: 1.6776, Val Loss: 1.5875, F1 Micro: 0.3542, F1 Macro: 0.2880, Accuracy: 0.3542\n","Epoch 35, Train Loss: 1.6509, Val Loss: 1.5881, F1 Micro: 0.3542, F1 Macro: 0.2694, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.6154, Val Loss: 1.6296, F1 Micro: 0.3125, F1 Macro: 0.2706, Accuracy: 0.3125\n","Epoch 37, Train Loss: 1.6357, Val Loss: 1.6354, F1 Micro: 0.3125, F1 Macro: 0.2501, Accuracy: 0.3125\n","Epoch 38, Train Loss: 1.6311, Val Loss: 1.6792, F1 Micro: 0.2708, F1 Macro: 0.2087, Accuracy: 0.2708\n","Epoch 39, Train Loss: 1.6269, Val Loss: 1.5943, F1 Micro: 0.3229, F1 Macro: 0.2461, Accuracy: 0.3229\n","Epoch 40, Train Loss: 1.6143, Val Loss: 1.6209, F1 Micro: 0.3333, F1 Macro: 0.2517, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.6168, Val Loss: 1.5841, F1 Micro: 0.3542, F1 Macro: 0.3107, Accuracy: 0.3542\n","Epoch 42, Train Loss: 1.5866, Val Loss: 1.6257, F1 Micro: 0.2917, F1 Macro: 0.2516, Accuracy: 0.2917\n","Epoch 43, Train Loss: 1.6197, Val Loss: 1.5816, F1 Micro: 0.3750, F1 Macro: 0.3419, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.5979, Val Loss: 1.6446, F1 Micro: 0.3125, F1 Macro: 0.2698, Accuracy: 0.3125\n","Epoch 45, Train Loss: 1.6002, Val Loss: 1.6030, F1 Micro: 0.3125, F1 Macro: 0.2697, Accuracy: 0.3125\n","Epoch 46, Train Loss: 1.6032, Val Loss: 1.6806, F1 Micro: 0.3021, F1 Macro: 0.2423, Accuracy: 0.3021\n","Epoch 47, Train Loss: 1.5945, Val Loss: 1.5701, F1 Micro: 0.3333, F1 Macro: 0.2978, Accuracy: 0.3333\n","Epoch 48, Train Loss: 1.5596, Val Loss: 1.7658, F1 Micro: 0.3542, F1 Macro: 0.2561, Accuracy: 0.3542\n","Epoch 49, Train Loss: 1.5912, Val Loss: 1.6389, F1 Micro: 0.3854, F1 Macro: 0.3265, Accuracy: 0.3854\n","Epoch 50, Train Loss: 1.5784, Val Loss: 1.5687, F1 Micro: 0.3438, F1 Macro: 0.2964, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.5832, Val Loss: 1.6154, F1 Micro: 0.3125, F1 Macro: 0.2683, Accuracy: 0.3125\n","Epoch 52, Train Loss: 1.5738, Val Loss: 1.9355, F1 Micro: 0.3438, F1 Macro: 0.2288, Accuracy: 0.3438\n","Epoch 53, Train Loss: 1.5581, Val Loss: 1.5332, F1 Micro: 0.3750, F1 Macro: 0.2997, Accuracy: 0.3750\n","Epoch 54, Train Loss: 1.5351, Val Loss: 1.5625, F1 Micro: 0.4167, F1 Macro: 0.3484, Accuracy: 0.4167\n","Epoch 55, Train Loss: 1.5281, Val Loss: 1.8472, F1 Micro: 0.2917, F1 Macro: 0.2113, Accuracy: 0.2917\n","Epoch 56, Train Loss: 1.5232, Val Loss: 1.7365, F1 Micro: 0.3750, F1 Macro: 0.3014, Accuracy: 0.3750\n","Epoch 57, Train Loss: 1.5317, Val Loss: 1.5980, F1 Micro: 0.4062, F1 Macro: 0.3182, Accuracy: 0.4062\n","Epoch 58, Train Loss: 1.4907, Val Loss: 1.5430, F1 Micro: 0.4375, F1 Macro: 0.3903, Accuracy: 0.4375\n","Epoch 59, Train Loss: 1.4913, Val Loss: 1.5130, F1 Micro: 0.3958, F1 Macro: 0.3330, Accuracy: 0.3958\n","Epoch 60, Train Loss: 1.5123, Val Loss: 1.4242, F1 Micro: 0.4688, F1 Macro: 0.4207, Accuracy: 0.4688\n","Epoch 61, Train Loss: 1.4669, Val Loss: 1.6227, F1 Micro: 0.3958, F1 Macro: 0.3247, Accuracy: 0.3958\n","Epoch 62, Train Loss: 1.4982, Val Loss: 1.4564, F1 Micro: 0.4479, F1 Macro: 0.4064, Accuracy: 0.4479\n","Epoch 63, Train Loss: 1.4614, Val Loss: 1.8805, F1 Micro: 0.3646, F1 Macro: 0.2754, Accuracy: 0.3646\n","Epoch 64, Train Loss: 1.4495, Val Loss: 1.5227, F1 Micro: 0.4375, F1 Macro: 0.3860, Accuracy: 0.4375\n","Epoch 65, Train Loss: 1.4377, Val Loss: 1.5621, F1 Micro: 0.3750, F1 Macro: 0.3736, Accuracy: 0.3750\n","Epoch 66, Train Loss: 1.4379, Val Loss: 1.5469, F1 Micro: 0.4062, F1 Macro: 0.3750, Accuracy: 0.4062\n","Epoch 67, Train Loss: 1.4251, Val Loss: 1.3749, F1 Micro: 0.5104, F1 Macro: 0.5008, Accuracy: 0.5104\n","Epoch 68, Train Loss: 1.3928, Val Loss: 1.5184, F1 Micro: 0.4896, F1 Macro: 0.4863, Accuracy: 0.4896\n","Epoch 69, Train Loss: 1.3995, Val Loss: 1.6363, F1 Micro: 0.3958, F1 Macro: 0.3928, Accuracy: 0.3958\n","Epoch 70, Train Loss: 1.3977, Val Loss: 1.6891, F1 Micro: 0.4062, F1 Macro: 0.3367, Accuracy: 0.4062\n","Epoch 71, Train Loss: 1.3753, Val Loss: 1.6849, F1 Micro: 0.3958, F1 Macro: 0.3180, Accuracy: 0.3958\n","Epoch 72, Train Loss: 1.3488, Val Loss: 1.9108, F1 Micro: 0.3958, F1 Macro: 0.3521, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.3429, Val Loss: 1.5179, F1 Micro: 0.5000, F1 Macro: 0.4850, Accuracy: 0.5000\n","Epoch 74, Train Loss: 1.3558, Val Loss: 2.1278, F1 Micro: 0.3542, F1 Macro: 0.2623, Accuracy: 0.3542\n","Epoch 75, Train Loss: 1.3563, Val Loss: 1.9670, F1 Micro: 0.3333, F1 Macro: 0.3033, Accuracy: 0.3333\n","Epoch 76, Train Loss: 1.3092, Val Loss: 1.6300, F1 Micro: 0.4375, F1 Macro: 0.4247, Accuracy: 0.4375\n","Epoch 77, Train Loss: 1.3516, Val Loss: 1.5939, F1 Micro: 0.4896, F1 Macro: 0.4789, Accuracy: 0.4896\n","Epoch 78, Train Loss: 1.2989, Val Loss: 1.6616, F1 Micro: 0.4062, F1 Macro: 0.3713, Accuracy: 0.4062\n","Epoch 79, Train Loss: 1.2492, Val Loss: 1.7778, F1 Micro: 0.3958, F1 Macro: 0.3608, Accuracy: 0.3958\n","Epoch 80, Train Loss: 1.2537, Val Loss: 1.6345, F1 Micro: 0.4167, F1 Macro: 0.3626, Accuracy: 0.4167\n","Epoch 81, Train Loss: 1.3293, Val Loss: 1.8518, F1 Micro: 0.3542, F1 Macro: 0.3375, Accuracy: 0.3542\n","Epoch 82, Train Loss: 1.2738, Val Loss: 1.7839, F1 Micro: 0.4271, F1 Macro: 0.3873, Accuracy: 0.4271\n","Epoch 83, Train Loss: 1.2394, Val Loss: 1.7105, F1 Micro: 0.5625, F1 Macro: 0.5389, Accuracy: 0.5625\n","Epoch 84, Train Loss: 1.3235, Val Loss: 1.5564, F1 Micro: 0.5208, F1 Macro: 0.5112, Accuracy: 0.5208\n","Epoch 85, Train Loss: 1.2281, Val Loss: 1.6957, F1 Micro: 0.4479, F1 Macro: 0.3962, Accuracy: 0.4479\n","Epoch 86, Train Loss: 1.2203, Val Loss: 1.6813, F1 Micro: 0.4375, F1 Macro: 0.4007, Accuracy: 0.4375\n","Epoch 87, Train Loss: 1.2224, Val Loss: 1.8344, F1 Micro: 0.4271, F1 Macro: 0.4291, Accuracy: 0.4271\n","Epoch 88, Train Loss: 1.2219, Val Loss: 1.5543, F1 Micro: 0.5312, F1 Macro: 0.5244, Accuracy: 0.5312\n","Epoch 89, Train Loss: 1.1967, Val Loss: 2.0042, F1 Micro: 0.4271, F1 Macro: 0.3625, Accuracy: 0.4271\n","Epoch 90, Train Loss: 1.1841, Val Loss: 3.1298, F1 Micro: 0.2500, F1 Macro: 0.1901, Accuracy: 0.2500\n","Epoch 91, Train Loss: 1.1752, Val Loss: 1.6135, F1 Micro: 0.4688, F1 Macro: 0.4701, Accuracy: 0.4688\n","Epoch 92, Train Loss: 1.1991, Val Loss: 1.5574, F1 Micro: 0.4896, F1 Macro: 0.4950, Accuracy: 0.4896\n","Epoch 93, Train Loss: 1.1800, Val Loss: 1.7955, F1 Micro: 0.3958, F1 Macro: 0.3706, Accuracy: 0.3958\n","Epoch 94, Train Loss: 1.2089, Val Loss: 2.0640, F1 Micro: 0.3958, F1 Macro: 0.3362, Accuracy: 0.3958\n","Epoch 95, Train Loss: 1.2246, Val Loss: 1.7756, F1 Micro: 0.4688, F1 Macro: 0.4632, Accuracy: 0.4688\n","Epoch 96, Train Loss: 1.1702, Val Loss: 2.1946, F1 Micro: 0.3646, F1 Macro: 0.3389, Accuracy: 0.3646\n","Epoch 97, Train Loss: 1.1551, Val Loss: 1.6084, F1 Micro: 0.4896, F1 Macro: 0.5027, Accuracy: 0.4896\n","Epoch 98, Train Loss: 1.1913, Val Loss: 1.5380, F1 Micro: 0.5312, F1 Macro: 0.5030, Accuracy: 0.5312\n","Epoch 99, Train Loss: 1.1095, Val Loss: 1.5778, F1 Micro: 0.4792, F1 Macro: 0.4762, Accuracy: 0.4792\n","Epoch 100, Train Loss: 1.1125, Val Loss: 1.7252, F1 Micro: 0.4167, F1 Macro: 0.3832, Accuracy: 0.4167\n","Epoch 101, Train Loss: 1.1460, Val Loss: 2.0420, F1 Micro: 0.3646, F1 Macro: 0.3554, Accuracy: 0.3646\n","Epoch 102, Train Loss: 1.1358, Val Loss: 1.7253, F1 Micro: 0.5000, F1 Macro: 0.4928, Accuracy: 0.5000\n","Epoch 103, Train Loss: 1.1217, Val Loss: 2.1644, F1 Micro: 0.4062, F1 Macro: 0.3777, Accuracy: 0.4062\n","Epoch 104, Train Loss: 1.1244, Val Loss: 1.6250, F1 Micro: 0.5000, F1 Macro: 0.4906, Accuracy: 0.5000\n","Epoch 105, Train Loss: 1.1159, Val Loss: 1.7659, F1 Micro: 0.4792, F1 Macro: 0.4552, Accuracy: 0.4792\n","Epoch 106, Train Loss: 1.1465, Val Loss: 4.1091, F1 Micro: 0.2188, F1 Macro: 0.1573, Accuracy: 0.2188\n","Epoch 107, Train Loss: 1.1043, Val Loss: 1.6932, F1 Micro: 0.4792, F1 Macro: 0.4858, Accuracy: 0.4792\n","Epoch 108, Train Loss: 1.0940, Val Loss: 1.7885, F1 Micro: 0.5417, F1 Macro: 0.5349, Accuracy: 0.5417\n","Epoch 109, Train Loss: 1.0743, Val Loss: 1.6087, F1 Micro: 0.5417, F1 Macro: 0.5387, Accuracy: 0.5417\n","Epoch 110, Train Loss: 1.0490, Val Loss: 1.7057, F1 Micro: 0.4896, F1 Macro: 0.4753, Accuracy: 0.4896\n","Epoch 111, Train Loss: 1.0749, Val Loss: 1.7509, F1 Micro: 0.4583, F1 Macro: 0.4563, Accuracy: 0.4583\n","Epoch 112, Train Loss: 1.0470, Val Loss: 1.7805, F1 Micro: 0.4583, F1 Macro: 0.4256, Accuracy: 0.4583\n","Epoch 113, Train Loss: 1.0704, Val Loss: 2.0045, F1 Micro: 0.4583, F1 Macro: 0.4246, Accuracy: 0.4583\n","Epoch 114, Train Loss: 1.1131, Val Loss: 1.6871, F1 Micro: 0.4688, F1 Macro: 0.4700, Accuracy: 0.4688\n","Epoch 115, Train Loss: 1.1419, Val Loss: 1.7685, F1 Micro: 0.4479, F1 Macro: 0.4306, Accuracy: 0.4479\n","Epoch 116, Train Loss: 1.0566, Val Loss: 1.7985, F1 Micro: 0.3854, F1 Macro: 0.3676, Accuracy: 0.3854\n","Epoch 117, Train Loss: 1.0456, Val Loss: 1.9655, F1 Micro: 0.4375, F1 Macro: 0.4114, Accuracy: 0.4375\n","Epoch 118, Train Loss: 1.0291, Val Loss: 1.7209, F1 Micro: 0.5104, F1 Macro: 0.5087, Accuracy: 0.5104\n","Epoch 119, Train Loss: 1.0400, Val Loss: 2.1160, F1 Micro: 0.4062, F1 Macro: 0.3704, Accuracy: 0.4062\n","Epoch 120, Train Loss: 1.0752, Val Loss: 2.3477, F1 Micro: 0.3333, F1 Macro: 0.2852, Accuracy: 0.3333\n","Epoch 121, Train Loss: 1.1202, Val Loss: 2.1731, F1 Micro: 0.4271, F1 Macro: 0.4258, Accuracy: 0.4271\n","Epoch 122, Train Loss: 1.0580, Val Loss: 2.0052, F1 Micro: 0.4792, F1 Macro: 0.4749, Accuracy: 0.4792\n","Epoch 123, Train Loss: 1.0244, Val Loss: 1.8423, F1 Micro: 0.5000, F1 Macro: 0.4724, Accuracy: 0.5000\n","Epoch 124, Train Loss: 1.0314, Val Loss: 2.1521, F1 Micro: 0.4479, F1 Macro: 0.4238, Accuracy: 0.4479\n","Epoch 125, Train Loss: 0.9868, Val Loss: 3.0926, F1 Micro: 0.3229, F1 Macro: 0.2887, Accuracy: 0.3229\n","Epoch 126, Train Loss: 1.0995, Val Loss: 2.6406, F1 Micro: 0.3542, F1 Macro: 0.3223, Accuracy: 0.3542\n","Epoch 127, Train Loss: 1.0001, Val Loss: 1.7573, F1 Micro: 0.5208, F1 Macro: 0.5165, Accuracy: 0.5208\n","Epoch 128, Train Loss: 0.9579, Val Loss: 1.6767, F1 Micro: 0.4792, F1 Macro: 0.4880, Accuracy: 0.4792\n","Epoch 129, Train Loss: 0.9639, Val Loss: 2.0932, F1 Micro: 0.4688, F1 Macro: 0.4558, Accuracy: 0.4688\n","Epoch 130, Train Loss: 0.9643, Val Loss: 1.8023, F1 Micro: 0.4896, F1 Macro: 0.4750, Accuracy: 0.4896\n","Epoch 131, Train Loss: 0.9627, Val Loss: 2.2176, F1 Micro: 0.4167, F1 Macro: 0.3783, Accuracy: 0.4167\n","Epoch 132, Train Loss: 0.9534, Val Loss: 2.2620, F1 Micro: 0.3958, F1 Macro: 0.3711, Accuracy: 0.3958\n","Epoch 133, Train Loss: 1.0031, Val Loss: 2.1056, F1 Micro: 0.4375, F1 Macro: 0.4313, Accuracy: 0.4375\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.5479166666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8497, Val Loss: 1.7747, F1 Micro: 0.1979, F1 Macro: 0.1294, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7926, Val Loss: 1.7870, F1 Micro: 0.1771, F1 Macro: 0.1154, Accuracy: 0.1771\n","Epoch 3, Train Loss: 1.7720, Val Loss: 1.7995, F1 Micro: 0.1667, F1 Macro: 0.1386, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.7431, Val Loss: 1.7707, F1 Micro: 0.2188, F1 Macro: 0.2037, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.7322, Val Loss: 1.7420, F1 Micro: 0.2604, F1 Macro: 0.1964, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.7329, Val Loss: 1.7446, F1 Micro: 0.2708, F1 Macro: 0.2276, Accuracy: 0.2708\n","Epoch 7, Train Loss: 1.6922, Val Loss: 1.7834, F1 Micro: 0.2292, F1 Macro: 0.2079, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.6908, Val Loss: 1.7723, F1 Micro: 0.2188, F1 Macro: 0.1970, Accuracy: 0.2188\n","Epoch 9, Train Loss: 1.6567, Val Loss: 1.7208, F1 Micro: 0.3125, F1 Macro: 0.2829, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.6445, Val Loss: 1.9308, F1 Micro: 0.2500, F1 Macro: 0.1999, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.6426, Val Loss: 1.6918, F1 Micro: 0.3021, F1 Macro: 0.2775, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.6234, Val Loss: 1.7154, F1 Micro: 0.3021, F1 Macro: 0.2795, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.6063, Val Loss: 1.6625, F1 Micro: 0.3229, F1 Macro: 0.3017, Accuracy: 0.3229\n","Epoch 14, Train Loss: 1.5993, Val Loss: 1.7429, F1 Micro: 0.3229, F1 Macro: 0.3140, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.5974, Val Loss: 1.7503, F1 Micro: 0.3229, F1 Macro: 0.3024, Accuracy: 0.3229\n","Epoch 16, Train Loss: 1.5718, Val Loss: 1.7484, F1 Micro: 0.3229, F1 Macro: 0.2796, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.5760, Val Loss: 1.7061, F1 Micro: 0.3125, F1 Macro: 0.3176, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.5524, Val Loss: 1.8503, F1 Micro: 0.2708, F1 Macro: 0.2311, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.5302, Val Loss: 1.6769, F1 Micro: 0.3333, F1 Macro: 0.3231, Accuracy: 0.3333\n","Epoch 20, Train Loss: 1.5399, Val Loss: 1.8200, F1 Micro: 0.2812, F1 Macro: 0.2620, Accuracy: 0.2812\n","Epoch 21, Train Loss: 1.4848, Val Loss: 1.8910, F1 Micro: 0.2917, F1 Macro: 0.2311, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.5202, Val Loss: 2.5418, F1 Micro: 0.2292, F1 Macro: 0.1938, Accuracy: 0.2292\n","Epoch 23, Train Loss: 1.5041, Val Loss: 1.7262, F1 Micro: 0.3229, F1 Macro: 0.2999, Accuracy: 0.3229\n","Epoch 24, Train Loss: 1.4896, Val Loss: 1.6905, F1 Micro: 0.3125, F1 Macro: 0.2813, Accuracy: 0.3125\n","Epoch 25, Train Loss: 1.4928, Val Loss: 1.6806, F1 Micro: 0.3438, F1 Macro: 0.3049, Accuracy: 0.3438\n","Epoch 26, Train Loss: 1.4626, Val Loss: 1.7440, F1 Micro: 0.3646, F1 Macro: 0.3323, Accuracy: 0.3646\n","Epoch 27, Train Loss: 1.4700, Val Loss: 1.7966, F1 Micro: 0.3021, F1 Macro: 0.2963, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.4455, Val Loss: 1.6912, F1 Micro: 0.3542, F1 Macro: 0.3447, Accuracy: 0.3542\n","Epoch 29, Train Loss: 1.4548, Val Loss: 1.6779, F1 Micro: 0.3229, F1 Macro: 0.2491, Accuracy: 0.3229\n","Epoch 30, Train Loss: 1.4307, Val Loss: 1.8331, F1 Micro: 0.3750, F1 Macro: 0.3483, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.4339, Val Loss: 1.6762, F1 Micro: 0.2917, F1 Macro: 0.3054, Accuracy: 0.2917\n","Epoch 32, Train Loss: 1.4236, Val Loss: 2.1877, F1 Micro: 0.2396, F1 Macro: 0.1904, Accuracy: 0.2396\n","Epoch 33, Train Loss: 1.3913, Val Loss: 1.9480, F1 Micro: 0.3125, F1 Macro: 0.3079, Accuracy: 0.3125\n","Epoch 34, Train Loss: 1.4042, Val Loss: 1.8877, F1 Micro: 0.2917, F1 Macro: 0.2489, Accuracy: 0.2917\n","Epoch 35, Train Loss: 1.3771, Val Loss: 1.6490, F1 Micro: 0.3542, F1 Macro: 0.3287, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.3862, Val Loss: 1.7807, F1 Micro: 0.3229, F1 Macro: 0.3173, Accuracy: 0.3229\n","Epoch 37, Train Loss: 1.3720, Val Loss: 1.7647, F1 Micro: 0.3333, F1 Macro: 0.3192, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.3786, Val Loss: 2.2113, F1 Micro: 0.2917, F1 Macro: 0.2827, Accuracy: 0.2917\n","Epoch 39, Train Loss: 1.3625, Val Loss: 1.9741, F1 Micro: 0.3229, F1 Macro: 0.3275, Accuracy: 0.3229\n","Epoch 40, Train Loss: 1.3608, Val Loss: 1.6684, F1 Micro: 0.3750, F1 Macro: 0.3705, Accuracy: 0.3750\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.7365, Val Loss: 1.9981, F1 Micro: 0.1979, F1 Macro: 0.1658, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7093, Val Loss: 1.7409, F1 Micro: 0.2188, F1 Macro: 0.1466, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7030, Val Loss: 1.8348, F1 Micro: 0.2188, F1 Macro: 0.1521, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.7058, Val Loss: 1.8079, F1 Micro: 0.2396, F1 Macro: 0.1724, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.6479, Val Loss: 1.7550, F1 Micro: 0.2500, F1 Macro: 0.1665, Accuracy: 0.2500\n","Epoch 6, Train Loss: 1.6252, Val Loss: 1.6518, F1 Micro: 0.2917, F1 Macro: 0.2279, Accuracy: 0.2917\n","Epoch 7, Train Loss: 1.6575, Val Loss: 1.7768, F1 Micro: 0.2604, F1 Macro: 0.1901, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6237, Val Loss: 1.7410, F1 Micro: 0.1979, F1 Macro: 0.1674, Accuracy: 0.1979\n","Epoch 9, Train Loss: 1.5988, Val Loss: 1.6576, F1 Micro: 0.3333, F1 Macro: 0.2697, Accuracy: 0.3333\n","Epoch 10, Train Loss: 1.6013, Val Loss: 1.6707, F1 Micro: 0.3229, F1 Macro: 0.2588, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.5925, Val Loss: 1.7821, F1 Micro: 0.2604, F1 Macro: 0.1915, Accuracy: 0.2604\n","Epoch 12, Train Loss: 1.5628, Val Loss: 1.7207, F1 Micro: 0.2917, F1 Macro: 0.2251, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.5442, Val Loss: 1.6266, F1 Micro: 0.3438, F1 Macro: 0.3101, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.5354, Val Loss: 1.6069, F1 Micro: 0.3646, F1 Macro: 0.3121, Accuracy: 0.3646\n","Epoch 15, Train Loss: 1.5710, Val Loss: 1.6497, F1 Micro: 0.3438, F1 Macro: 0.3171, Accuracy: 0.3438\n","Epoch 16, Train Loss: 1.4890, Val Loss: 1.6768, F1 Micro: 0.3021, F1 Macro: 0.2790, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.5176, Val Loss: 1.7242, F1 Micro: 0.3438, F1 Macro: 0.3082, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5456, Val Loss: 1.6404, F1 Micro: 0.2708, F1 Macro: 0.2479, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.5094, Val Loss: 1.5088, F1 Micro: 0.3750, F1 Macro: 0.3595, Accuracy: 0.3750\n","Epoch 20, Train Loss: 1.5076, Val Loss: 1.6737, F1 Micro: 0.3229, F1 Macro: 0.3047, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.4713, Val Loss: 1.4827, F1 Micro: 0.3542, F1 Macro: 0.3269, Accuracy: 0.3542\n","Epoch 22, Train Loss: 1.4839, Val Loss: 1.4395, F1 Micro: 0.4062, F1 Macro: 0.3305, Accuracy: 0.4062\n","Epoch 23, Train Loss: 1.5075, Val Loss: 1.6321, F1 Micro: 0.3125, F1 Macro: 0.2686, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.4951, Val Loss: 1.5217, F1 Micro: 0.3646, F1 Macro: 0.3195, Accuracy: 0.3646\n","Epoch 25, Train Loss: 1.4583, Val Loss: 1.6580, F1 Micro: 0.2812, F1 Macro: 0.2819, Accuracy: 0.2812\n","Epoch 26, Train Loss: 1.4204, Val Loss: 1.5228, F1 Micro: 0.3854, F1 Macro: 0.3647, Accuracy: 0.3854\n","Epoch 27, Train Loss: 1.4761, Val Loss: 1.6469, F1 Micro: 0.2812, F1 Macro: 0.2706, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.4724, Val Loss: 1.6135, F1 Micro: 0.3958, F1 Macro: 0.4052, Accuracy: 0.3958\n","Epoch 29, Train Loss: 1.4091, Val Loss: 1.4151, F1 Micro: 0.4271, F1 Macro: 0.3654, Accuracy: 0.4271\n","Epoch 30, Train Loss: 1.4333, Val Loss: 1.5269, F1 Micro: 0.4062, F1 Macro: 0.3801, Accuracy: 0.4062\n","Epoch 31, Train Loss: 1.3895, Val Loss: 1.4596, F1 Micro: 0.3646, F1 Macro: 0.3490, Accuracy: 0.3646\n","Epoch 32, Train Loss: 1.3875, Val Loss: 1.9846, F1 Micro: 0.2812, F1 Macro: 0.2408, Accuracy: 0.2812\n","Epoch 33, Train Loss: 1.3702, Val Loss: 1.4253, F1 Micro: 0.4375, F1 Macro: 0.4074, Accuracy: 0.4375\n","Epoch 34, Train Loss: 1.4179, Val Loss: 1.6724, F1 Micro: 0.3646, F1 Macro: 0.3546, Accuracy: 0.3646\n","Epoch 35, Train Loss: 1.3668, Val Loss: 1.3819, F1 Micro: 0.4167, F1 Macro: 0.3349, Accuracy: 0.4167\n","Epoch 36, Train Loss: 1.3883, Val Loss: 1.5768, F1 Micro: 0.4062, F1 Macro: 0.4068, Accuracy: 0.4062\n","Epoch 37, Train Loss: 1.3203, Val Loss: 1.4670, F1 Micro: 0.3958, F1 Macro: 0.3756, Accuracy: 0.3958\n","Epoch 38, Train Loss: 1.3161, Val Loss: 1.5212, F1 Micro: 0.4375, F1 Macro: 0.4338, Accuracy: 0.4375\n","Epoch 39, Train Loss: 1.2997, Val Loss: 1.5755, F1 Micro: 0.3542, F1 Macro: 0.3468, Accuracy: 0.3542\n","Epoch 40, Train Loss: 1.3213, Val Loss: 2.0238, F1 Micro: 0.3750, F1 Macro: 0.3061, Accuracy: 0.3750\n","Epoch 41, Train Loss: 1.3493, Val Loss: 1.5230, F1 Micro: 0.4375, F1 Macro: 0.4231, Accuracy: 0.4375\n","Epoch 42, Train Loss: 1.2820, Val Loss: 2.6724, F1 Micro: 0.2708, F1 Macro: 0.2110, Accuracy: 0.2708\n","Epoch 43, Train Loss: 1.3165, Val Loss: 1.4539, F1 Micro: 0.4688, F1 Macro: 0.4175, Accuracy: 0.4688\n","Epoch 44, Train Loss: 1.3396, Val Loss: 1.4937, F1 Micro: 0.4583, F1 Macro: 0.4656, Accuracy: 0.4583\n","Epoch 45, Train Loss: 1.2865, Val Loss: 1.3852, F1 Micro: 0.4271, F1 Macro: 0.3790, Accuracy: 0.4271\n","Epoch 46, Train Loss: 1.2755, Val Loss: 1.9438, F1 Micro: 0.3542, F1 Macro: 0.3459, Accuracy: 0.3542\n","Epoch 47, Train Loss: 1.3071, Val Loss: 1.4958, F1 Micro: 0.3854, F1 Macro: 0.3249, Accuracy: 0.3854\n","Epoch 48, Train Loss: 1.2311, Val Loss: 1.6282, F1 Micro: 0.3854, F1 Macro: 0.3689, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.2532, Val Loss: 1.8121, F1 Micro: 0.4167, F1 Macro: 0.4046, Accuracy: 0.4167\n","Epoch 50, Train Loss: 1.2732, Val Loss: 2.2341, F1 Micro: 0.3438, F1 Macro: 0.3271, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.2634, Val Loss: 2.4799, F1 Micro: 0.2812, F1 Macro: 0.2619, Accuracy: 0.2812\n","Epoch 52, Train Loss: 1.2064, Val Loss: 1.5104, F1 Micro: 0.4375, F1 Macro: 0.4170, Accuracy: 0.4375\n","Epoch 53, Train Loss: 1.2342, Val Loss: 2.3684, F1 Micro: 0.3438, F1 Macro: 0.3147, Accuracy: 0.3438\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8491, Val Loss: 1.8212, F1 Micro: 0.1458, F1 Macro: 0.0440, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.7499, Val Loss: 1.7671, F1 Micro: 0.2292, F1 Macro: 0.1563, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.7231, Val Loss: 1.7673, F1 Micro: 0.2604, F1 Macro: 0.1664, Accuracy: 0.2604\n","Epoch 4, Train Loss: 1.6954, Val Loss: 1.7246, F1 Micro: 0.3021, F1 Macro: 0.2265, Accuracy: 0.3021\n","Epoch 5, Train Loss: 1.6866, Val Loss: 1.6932, F1 Micro: 0.2708, F1 Macro: 0.1801, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.6624, Val Loss: 1.7013, F1 Micro: 0.2812, F1 Macro: 0.2621, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.6635, Val Loss: 1.6726, F1 Micro: 0.2604, F1 Macro: 0.2216, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6511, Val Loss: 1.6781, F1 Micro: 0.3021, F1 Macro: 0.2398, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.6068, Val Loss: 1.7689, F1 Micro: 0.3125, F1 Macro: 0.2784, Accuracy: 0.3125\n","Epoch 10, Train Loss: 1.6113, Val Loss: 1.6910, F1 Micro: 0.2396, F1 Macro: 0.2196, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.5923, Val Loss: 1.6196, F1 Micro: 0.3125, F1 Macro: 0.2609, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.5857, Val Loss: 1.7378, F1 Micro: 0.3438, F1 Macro: 0.3115, Accuracy: 0.3438\n","Epoch 13, Train Loss: 1.5630, Val Loss: 1.6295, F1 Micro: 0.2708, F1 Macro: 0.2315, Accuracy: 0.2708\n","Epoch 14, Train Loss: 1.5705, Val Loss: 1.6322, F1 Micro: 0.3333, F1 Macro: 0.2978, Accuracy: 0.3333\n","Epoch 15, Train Loss: 1.5421, Val Loss: 1.6648, F1 Micro: 0.2812, F1 Macro: 0.2241, Accuracy: 0.2812\n","Epoch 16, Train Loss: 1.5480, Val Loss: 1.6091, F1 Micro: 0.3125, F1 Macro: 0.2738, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.5381, Val Loss: 1.6011, F1 Micro: 0.3021, F1 Macro: 0.2605, Accuracy: 0.3021\n","Epoch 18, Train Loss: 1.5441, Val Loss: 2.0861, F1 Micro: 0.1771, F1 Macro: 0.1469, Accuracy: 0.1771\n","Epoch 19, Train Loss: 1.5563, Val Loss: 1.5888, F1 Micro: 0.4062, F1 Macro: 0.4042, Accuracy: 0.4062\n","Epoch 20, Train Loss: 1.5363, Val Loss: 1.6523, F1 Micro: 0.3438, F1 Macro: 0.3120, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.5321, Val Loss: 1.6302, F1 Micro: 0.3021, F1 Macro: 0.2652, Accuracy: 0.3021\n","Epoch 22, Train Loss: 1.5146, Val Loss: 1.7358, F1 Micro: 0.2812, F1 Macro: 0.2275, Accuracy: 0.2812\n","Epoch 23, Train Loss: 1.4847, Val Loss: 1.7083, F1 Micro: 0.3125, F1 Macro: 0.2881, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.5074, Val Loss: 1.6330, F1 Micro: 0.3125, F1 Macro: 0.2601, Accuracy: 0.3125\n","Epoch 25, Train Loss: 1.4742, Val Loss: 1.9254, F1 Micro: 0.3333, F1 Macro: 0.2871, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.4801, Val Loss: 1.6854, F1 Micro: 0.3333, F1 Macro: 0.2797, Accuracy: 0.3333\n","Epoch 27, Train Loss: 1.4647, Val Loss: 1.8248, F1 Micro: 0.3229, F1 Macro: 0.2694, Accuracy: 0.3229\n","Epoch 28, Train Loss: 1.4652, Val Loss: 1.5907, F1 Micro: 0.3125, F1 Macro: 0.2998, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.4827, Val Loss: 2.0219, F1 Micro: 0.3125, F1 Macro: 0.2573, Accuracy: 0.3125\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.7936, Val Loss: 1.8225, F1 Micro: 0.1979, F1 Macro: 0.1286, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7623, Val Loss: 1.8078, F1 Micro: 0.1875, F1 Macro: 0.1277, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.7560, Val Loss: 1.7934, F1 Micro: 0.1875, F1 Macro: 0.1327, Accuracy: 0.1875\n","Epoch 4, Train Loss: 1.7257, Val Loss: 2.1253, F1 Micro: 0.1771, F1 Macro: 0.0942, Accuracy: 0.1771\n","Epoch 5, Train Loss: 1.7201, Val Loss: 1.8414, F1 Micro: 0.2188, F1 Macro: 0.1355, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.7208, Val Loss: 1.7882, F1 Micro: 0.1562, F1 Macro: 0.1206, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7012, Val Loss: 2.2628, F1 Micro: 0.1979, F1 Macro: 0.1020, Accuracy: 0.1979\n","Epoch 8, Train Loss: 1.7123, Val Loss: 1.7710, F1 Micro: 0.2083, F1 Macro: 0.1948, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.6964, Val Loss: 1.8354, F1 Micro: 0.2292, F1 Macro: 0.1517, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.6764, Val Loss: 1.8892, F1 Micro: 0.1771, F1 Macro: 0.1176, Accuracy: 0.1771\n","Epoch 11, Train Loss: 1.6783, Val Loss: 2.0476, F1 Micro: 0.1875, F1 Macro: 0.1359, Accuracy: 0.1875\n","Epoch 12, Train Loss: 1.6743, Val Loss: 1.8770, F1 Micro: 0.1979, F1 Macro: 0.1245, Accuracy: 0.1979\n","Epoch 13, Train Loss: 1.6976, Val Loss: 1.7954, F1 Micro: 0.1875, F1 Macro: 0.1421, Accuracy: 0.1875\n","Epoch 14, Train Loss: 1.6511, Val Loss: 1.7530, F1 Micro: 0.2604, F1 Macro: 0.2425, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.6731, Val Loss: 1.8123, F1 Micro: 0.1979, F1 Macro: 0.1619, Accuracy: 0.1979\n","Epoch 16, Train Loss: 1.6439, Val Loss: 1.8225, F1 Micro: 0.2500, F1 Macro: 0.2184, Accuracy: 0.2500\n","Epoch 17, Train Loss: 1.6525, Val Loss: 2.3492, F1 Micro: 0.1771, F1 Macro: 0.0938, Accuracy: 0.1771\n","Epoch 18, Train Loss: 1.6575, Val Loss: 1.9617, F1 Micro: 0.2500, F1 Macro: 0.1846, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.6125, Val Loss: 1.7979, F1 Micro: 0.2708, F1 Macro: 0.2130, Accuracy: 0.2708\n","Epoch 20, Train Loss: 1.6464, Val Loss: 1.8554, F1 Micro: 0.1979, F1 Macro: 0.1571, Accuracy: 0.1979\n","Epoch 21, Train Loss: 1.6279, Val Loss: 1.8228, F1 Micro: 0.2812, F1 Macro: 0.2821, Accuracy: 0.2812\n","Epoch 22, Train Loss: 1.5908, Val Loss: 1.9222, F1 Micro: 0.1771, F1 Macro: 0.1251, Accuracy: 0.1771\n","Epoch 23, Train Loss: 1.6295, Val Loss: 1.8734, F1 Micro: 0.2500, F1 Macro: 0.2001, Accuracy: 0.2500\n","Epoch 24, Train Loss: 1.6074, Val Loss: 1.8022, F1 Micro: 0.2708, F1 Macro: 0.2432, Accuracy: 0.2708\n","Epoch 25, Train Loss: 1.6094, Val Loss: 1.8506, F1 Micro: 0.2917, F1 Macro: 0.2395, Accuracy: 0.2917\n","Epoch 26, Train Loss: 1.5882, Val Loss: 2.1980, F1 Micro: 0.2500, F1 Macro: 0.1641, Accuracy: 0.2500\n","Epoch 27, Train Loss: 1.6050, Val Loss: 1.9144, F1 Micro: 0.3021, F1 Macro: 0.2280, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.6016, Val Loss: 1.8188, F1 Micro: 0.2917, F1 Macro: 0.2483, Accuracy: 0.2917\n","Epoch 29, Train Loss: 1.5730, Val Loss: 1.9039, F1 Micro: 0.2708, F1 Macro: 0.2056, Accuracy: 0.2708\n","Epoch 30, Train Loss: 1.5860, Val Loss: 1.8968, F1 Micro: 0.2500, F1 Macro: 0.2005, Accuracy: 0.2500\n","Epoch 31, Train Loss: 1.5695, Val Loss: 2.1267, F1 Micro: 0.2396, F1 Macro: 0.1588, Accuracy: 0.2396\n","Epoch 32, Train Loss: 1.5444, Val Loss: 1.8370, F1 Micro: 0.2917, F1 Macro: 0.2868, Accuracy: 0.2917\n","Epoch 33, Train Loss: 1.5380, Val Loss: 1.9402, F1 Micro: 0.2812, F1 Macro: 0.1982, Accuracy: 0.2812\n","Epoch 34, Train Loss: 1.5444, Val Loss: 1.9075, F1 Micro: 0.2917, F1 Macro: 0.2437, Accuracy: 0.2917\n","Epoch 35, Train Loss: 1.5735, Val Loss: 2.2354, F1 Micro: 0.2188, F1 Macro: 0.1593, Accuracy: 0.2188\n","Epoch 36, Train Loss: 1.5286, Val Loss: 1.8587, F1 Micro: 0.3125, F1 Macro: 0.2908, Accuracy: 0.3125\n","Epoch 37, Train Loss: 1.5095, Val Loss: 1.9151, F1 Micro: 0.3229, F1 Macro: 0.2513, Accuracy: 0.3229\n","Epoch 38, Train Loss: 1.5303, Val Loss: 2.4455, F1 Micro: 0.1979, F1 Macro: 0.1067, Accuracy: 0.1979\n","Epoch 39, Train Loss: 1.5180, Val Loss: 1.8850, F1 Micro: 0.3021, F1 Macro: 0.2742, Accuracy: 0.3021\n","Epoch 40, Train Loss: 1.5373, Val Loss: 1.8430, F1 Micro: 0.3333, F1 Macro: 0.3080, Accuracy: 0.3333\n","Epoch 41, Train Loss: 1.4896, Val Loss: 2.0134, F1 Micro: 0.2708, F1 Macro: 0.2230, Accuracy: 0.2708\n","Epoch 42, Train Loss: 1.5136, Val Loss: 3.2602, F1 Micro: 0.1979, F1 Macro: 0.1025, Accuracy: 0.1979\n","Epoch 43, Train Loss: 1.4861, Val Loss: 1.8860, F1 Micro: 0.2604, F1 Macro: 0.1736, Accuracy: 0.2604\n","Epoch 44, Train Loss: 1.4979, Val Loss: 2.0659, F1 Micro: 0.2812, F1 Macro: 0.2257, Accuracy: 0.2812\n","Epoch 45, Train Loss: 1.4643, Val Loss: 1.9922, F1 Micro: 0.3021, F1 Macro: 0.2465, Accuracy: 0.3021\n","Epoch 46, Train Loss: 1.4899, Val Loss: 2.0303, F1 Micro: 0.3333, F1 Macro: 0.2913, Accuracy: 0.3333\n","Epoch 47, Train Loss: 1.4734, Val Loss: 1.9823, F1 Micro: 0.2500, F1 Macro: 0.2103, Accuracy: 0.2500\n","Epoch 48, Train Loss: 1.4657, Val Loss: 1.9766, F1 Micro: 0.3229, F1 Macro: 0.2781, Accuracy: 0.3229\n","Epoch 49, Train Loss: 1.4365, Val Loss: 1.9414, F1 Micro: 0.3125, F1 Macro: 0.2860, Accuracy: 0.3125\n","Epoch 50, Train Loss: 1.4327, Val Loss: 2.3225, F1 Micro: 0.2708, F1 Macro: 0.1945, Accuracy: 0.2708\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8288, Val Loss: 1.7057, F1 Micro: 0.2396, F1 Macro: 0.1595, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7558, Val Loss: 1.7175, F1 Micro: 0.2500, F1 Macro: 0.1921, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.7395, Val Loss: 1.7189, F1 Micro: 0.3021, F1 Macro: 0.2360, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.7256, Val Loss: 1.7215, F1 Micro: 0.2604, F1 Macro: 0.1949, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.7194, Val Loss: 1.7386, F1 Micro: 0.2917, F1 Macro: 0.2744, Accuracy: 0.2917\n","Epoch 6, Train Loss: 1.7428, Val Loss: 1.7312, F1 Micro: 0.2604, F1 Macro: 0.2341, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.7151, Val Loss: 1.8489, F1 Micro: 0.2396, F1 Macro: 0.1891, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6780, Val Loss: 1.6735, F1 Micro: 0.2917, F1 Macro: 0.2252, Accuracy: 0.2917\n","Epoch 9, Train Loss: 1.6823, Val Loss: 1.9646, F1 Micro: 0.2396, F1 Macro: 0.1933, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.6854, Val Loss: 1.6815, F1 Micro: 0.2604, F1 Macro: 0.1928, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.6717, Val Loss: 1.7119, F1 Micro: 0.3229, F1 Macro: 0.2781, Accuracy: 0.3229\n","Epoch 12, Train Loss: 1.6406, Val Loss: 1.6870, F1 Micro: 0.2188, F1 Macro: 0.2178, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.6459, Val Loss: 1.6395, F1 Micro: 0.3229, F1 Macro: 0.2468, Accuracy: 0.3229\n","Epoch 14, Train Loss: 1.6441, Val Loss: 1.6352, F1 Micro: 0.2812, F1 Macro: 0.2434, Accuracy: 0.2812\n","Epoch 15, Train Loss: 1.6460, Val Loss: 1.6181, F1 Micro: 0.3229, F1 Macro: 0.2889, Accuracy: 0.3229\n","Epoch 16, Train Loss: 1.6446, Val Loss: 1.7303, F1 Micro: 0.2292, F1 Macro: 0.1799, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.6388, Val Loss: 1.5706, F1 Micro: 0.3333, F1 Macro: 0.3000, Accuracy: 0.3333\n","Epoch 18, Train Loss: 1.5913, Val Loss: 1.6533, F1 Micro: 0.2708, F1 Macro: 0.1923, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.5814, Val Loss: 1.5749, F1 Micro: 0.3125, F1 Macro: 0.3176, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.5620, Val Loss: 1.5589, F1 Micro: 0.3229, F1 Macro: 0.3124, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.5722, Val Loss: 1.7051, F1 Micro: 0.2604, F1 Macro: 0.1711, Accuracy: 0.2604\n","Epoch 22, Train Loss: 1.5528, Val Loss: 1.5758, F1 Micro: 0.3021, F1 Macro: 0.2621, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.5376, Val Loss: 1.6117, F1 Micro: 0.2708, F1 Macro: 0.1978, Accuracy: 0.2708\n","Epoch 24, Train Loss: 1.5335, Val Loss: 1.8815, F1 Micro: 0.2500, F1 Macro: 0.2424, Accuracy: 0.2500\n","Epoch 25, Train Loss: 1.5755, Val Loss: 1.8060, F1 Micro: 0.3229, F1 Macro: 0.2141, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.5487, Val Loss: 1.7667, F1 Micro: 0.2917, F1 Macro: 0.2829, Accuracy: 0.2917\n","Epoch 27, Train Loss: 1.5594, Val Loss: 1.5786, F1 Micro: 0.3333, F1 Macro: 0.3164, Accuracy: 0.3333\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.3833333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8069, Val Loss: 1.7069, F1 Micro: 0.3438, F1 Macro: 0.2212, Accuracy: 0.3438\n","Epoch 2, Train Loss: 1.7400, Val Loss: 1.7147, F1 Micro: 0.2396, F1 Macro: 0.1657, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7435, Val Loss: 1.7377, F1 Micro: 0.2292, F1 Macro: 0.1805, Accuracy: 0.2292\n","Epoch 4, Train Loss: 1.7141, Val Loss: 1.7049, F1 Micro: 0.2396, F1 Macro: 0.1432, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.7260, Val Loss: 1.8877, F1 Micro: 0.2604, F1 Macro: 0.1957, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.7068, Val Loss: 1.7555, F1 Micro: 0.2917, F1 Macro: 0.1821, Accuracy: 0.2917\n","Epoch 7, Train Loss: 1.7060, Val Loss: 1.7498, F1 Micro: 0.2604, F1 Macro: 0.2358, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6961, Val Loss: 1.6760, F1 Micro: 0.2708, F1 Macro: 0.2364, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.6821, Val Loss: 1.8176, F1 Micro: 0.2500, F1 Macro: 0.1843, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.6672, Val Loss: 1.7487, F1 Micro: 0.2500, F1 Macro: 0.1808, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.6801, Val Loss: 1.7065, F1 Micro: 0.3021, F1 Macro: 0.2860, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.6691, Val Loss: 1.6805, F1 Micro: 0.3333, F1 Macro: 0.2510, Accuracy: 0.3333\n","Epoch 13, Train Loss: 1.6599, Val Loss: 1.6830, F1 Micro: 0.2604, F1 Macro: 0.2117, Accuracy: 0.2604\n","Epoch 14, Train Loss: 1.6616, Val Loss: 1.7010, F1 Micro: 0.2917, F1 Macro: 0.2563, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.6334, Val Loss: 1.7000, F1 Micro: 0.2917, F1 Macro: 0.2479, Accuracy: 0.2917\n","Epoch 16, Train Loss: 1.6372, Val Loss: 1.7581, F1 Micro: 0.2812, F1 Macro: 0.2549, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.6076, Val Loss: 1.8953, F1 Micro: 0.2500, F1 Macro: 0.2236, Accuracy: 0.2500\n","Epoch 18, Train Loss: 1.5920, Val Loss: 1.9471, F1 Micro: 0.1771, F1 Macro: 0.0618, Accuracy: 0.1771\n","Epoch 19, Train Loss: 1.5870, Val Loss: 2.3186, F1 Micro: 0.2292, F1 Macro: 0.1832, Accuracy: 0.2292\n","Epoch 20, Train Loss: 1.5850, Val Loss: 1.7011, F1 Micro: 0.2396, F1 Macro: 0.1790, Accuracy: 0.2396\n","Epoch 21, Train Loss: 1.5731, Val Loss: 1.6736, F1 Micro: 0.3229, F1 Macro: 0.2338, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.5565, Val Loss: 1.7135, F1 Micro: 0.2500, F1 Macro: 0.2245, Accuracy: 0.2500\n","Epoch 23, Train Loss: 1.5370, Val Loss: 1.7012, F1 Micro: 0.2917, F1 Macro: 0.2678, Accuracy: 0.2917\n","Epoch 24, Train Loss: 1.5119, Val Loss: 1.7141, F1 Micro: 0.2604, F1 Macro: 0.2247, Accuracy: 0.2604\n","Epoch 25, Train Loss: 1.5135, Val Loss: 1.6468, F1 Micro: 0.3229, F1 Macro: 0.3112, Accuracy: 0.3229\n","Epoch 26, Train Loss: 1.5233, Val Loss: 2.3117, F1 Micro: 0.2292, F1 Macro: 0.1918, Accuracy: 0.2292\n","Epoch 27, Train Loss: 1.5128, Val Loss: 1.7215, F1 Micro: 0.2812, F1 Macro: 0.1752, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.4719, Val Loss: 1.6384, F1 Micro: 0.3333, F1 Macro: 0.2855, Accuracy: 0.3333\n","Epoch 29, Train Loss: 1.4933, Val Loss: 1.8843, F1 Micro: 0.2604, F1 Macro: 0.2432, Accuracy: 0.2604\n","Epoch 30, Train Loss: 1.4561, Val Loss: 1.6413, F1 Micro: 0.3542, F1 Macro: 0.3323, Accuracy: 0.3542\n","Epoch 31, Train Loss: 1.4498, Val Loss: 1.7179, F1 Micro: 0.3229, F1 Macro: 0.2932, Accuracy: 0.3229\n","Epoch 32, Train Loss: 1.4269, Val Loss: 1.6907, F1 Micro: 0.3438, F1 Macro: 0.3253, Accuracy: 0.3438\n","Epoch 33, Train Loss: 1.4376, Val Loss: 1.6637, F1 Micro: 0.3333, F1 Macro: 0.2615, Accuracy: 0.3333\n","Epoch 34, Train Loss: 1.4060, Val Loss: 1.9954, F1 Micro: 0.3229, F1 Macro: 0.2869, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.4540, Val Loss: 1.8581, F1 Micro: 0.3125, F1 Macro: 0.2607, Accuracy: 0.3125\n","Epoch 36, Train Loss: 1.4317, Val Loss: 1.6557, F1 Micro: 0.3542, F1 Macro: 0.2733, Accuracy: 0.3542\n","Epoch 37, Train Loss: 1.4097, Val Loss: 1.6842, F1 Micro: 0.3438, F1 Macro: 0.3315, Accuracy: 0.3438\n","Epoch 38, Train Loss: 1.3702, Val Loss: 1.6576, F1 Micro: 0.3333, F1 Macro: 0.2616, Accuracy: 0.3333\n","Epoch 39, Train Loss: 1.3784, Val Loss: 1.7630, F1 Micro: 0.3229, F1 Macro: 0.2523, Accuracy: 0.3229\n","Epoch 40, Train Loss: 1.3924, Val Loss: 1.6521, F1 Micro: 0.3854, F1 Macro: 0.3430, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.3760, Val Loss: 1.9499, F1 Micro: 0.3438, F1 Macro: 0.3209, Accuracy: 0.3438\n","Epoch 42, Train Loss: 1.3649, Val Loss: 1.6349, F1 Micro: 0.3854, F1 Macro: 0.3464, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.3328, Val Loss: 1.7247, F1 Micro: 0.3438, F1 Macro: 0.2672, Accuracy: 0.3438\n","Epoch 44, Train Loss: 1.3568, Val Loss: 1.6703, F1 Micro: 0.3125, F1 Macro: 0.2980, Accuracy: 0.3125\n","Epoch 45, Train Loss: 1.3734, Val Loss: 1.6375, F1 Micro: 0.3438, F1 Macro: 0.3047, Accuracy: 0.3438\n","Epoch 46, Train Loss: 1.3235, Val Loss: 1.7330, F1 Micro: 0.3229, F1 Macro: 0.2773, Accuracy: 0.3229\n","Epoch 47, Train Loss: 1.3470, Val Loss: 1.6218, F1 Micro: 0.4479, F1 Macro: 0.4118, Accuracy: 0.4479\n","Epoch 48, Train Loss: 1.3387, Val Loss: 1.7645, F1 Micro: 0.3646, F1 Macro: 0.3427, Accuracy: 0.3646\n","Epoch 49, Train Loss: 1.3311, Val Loss: 1.9806, F1 Micro: 0.2917, F1 Macro: 0.2491, Accuracy: 0.2917\n","Epoch 50, Train Loss: 1.2906, Val Loss: 1.6478, F1 Micro: 0.4271, F1 Macro: 0.4093, Accuracy: 0.4271\n","Epoch 51, Train Loss: 1.2841, Val Loss: 1.6505, F1 Micro: 0.4479, F1 Macro: 0.4283, Accuracy: 0.4479\n","Epoch 52, Train Loss: 1.2986, Val Loss: 1.7015, F1 Micro: 0.3646, F1 Macro: 0.2873, Accuracy: 0.3646\n","Epoch 53, Train Loss: 1.3097, Val Loss: 2.3443, F1 Micro: 0.2396, F1 Macro: 0.1869, Accuracy: 0.2396\n","Epoch 54, Train Loss: 1.2940, Val Loss: 1.7543, F1 Micro: 0.3854, F1 Macro: 0.3548, Accuracy: 0.3854\n","Epoch 55, Train Loss: 1.3123, Val Loss: 1.9393, F1 Micro: 0.2917, F1 Macro: 0.2545, Accuracy: 0.2917\n","Epoch 56, Train Loss: 1.2876, Val Loss: 1.6146, F1 Micro: 0.4062, F1 Macro: 0.3869, Accuracy: 0.4062\n","Epoch 57, Train Loss: 1.2869, Val Loss: 1.6618, F1 Micro: 0.3958, F1 Macro: 0.3891, Accuracy: 0.3958\n","Epoch 58, Train Loss: 1.2409, Val Loss: 1.8324, F1 Micro: 0.3438, F1 Macro: 0.3168, Accuracy: 0.3438\n","Epoch 59, Train Loss: 1.2348, Val Loss: 1.6956, F1 Micro: 0.4167, F1 Macro: 0.4247, Accuracy: 0.4167\n","Epoch 60, Train Loss: 1.2634, Val Loss: 1.8037, F1 Micro: 0.3854, F1 Macro: 0.3716, Accuracy: 0.3854\n","Epoch 61, Train Loss: 1.2440, Val Loss: 1.6558, F1 Micro: 0.3854, F1 Macro: 0.3680, Accuracy: 0.3854\n","Epoch 62, Train Loss: 1.2163, Val Loss: 1.7403, F1 Micro: 0.4062, F1 Macro: 0.4077, Accuracy: 0.4062\n","Epoch 63, Train Loss: 1.2484, Val Loss: 2.1293, F1 Micro: 0.2917, F1 Macro: 0.2944, Accuracy: 0.2917\n","Epoch 64, Train Loss: 1.2431, Val Loss: 1.9693, F1 Micro: 0.3750, F1 Macro: 0.3142, Accuracy: 0.3750\n","Epoch 65, Train Loss: 1.2656, Val Loss: 1.6681, F1 Micro: 0.3854, F1 Macro: 0.3771, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.2171, Val Loss: 1.7752, F1 Micro: 0.3958, F1 Macro: 0.3816, Accuracy: 0.3958\n","Epoch 67, Train Loss: 1.2246, Val Loss: 1.5450, F1 Micro: 0.4688, F1 Macro: 0.4641, Accuracy: 0.4688\n","Epoch 68, Train Loss: 1.2122, Val Loss: 1.6184, F1 Micro: 0.4479, F1 Macro: 0.4456, Accuracy: 0.4479\n","Epoch 69, Train Loss: 1.1749, Val Loss: 1.5789, F1 Micro: 0.4583, F1 Macro: 0.4560, Accuracy: 0.4583\n","Epoch 70, Train Loss: 1.1959, Val Loss: 2.1247, F1 Micro: 0.3854, F1 Macro: 0.3863, Accuracy: 0.3854\n","Epoch 71, Train Loss: 1.1808, Val Loss: 1.6553, F1 Micro: 0.4167, F1 Macro: 0.4122, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.1646, Val Loss: 1.5946, F1 Micro: 0.4375, F1 Macro: 0.3935, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.1791, Val Loss: 1.7284, F1 Micro: 0.5000, F1 Macro: 0.4954, Accuracy: 0.5000\n","Epoch 74, Train Loss: 1.1838, Val Loss: 1.6883, F1 Micro: 0.3750, F1 Macro: 0.3560, Accuracy: 0.3750\n","Epoch 75, Train Loss: 1.1818, Val Loss: 1.5377, F1 Micro: 0.4062, F1 Macro: 0.3692, Accuracy: 0.4062\n","Epoch 76, Train Loss: 1.1342, Val Loss: 1.6419, F1 Micro: 0.4271, F1 Macro: 0.3713, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.1527, Val Loss: 3.4370, F1 Micro: 0.2917, F1 Macro: 0.2789, Accuracy: 0.2917\n","Epoch 78, Train Loss: 1.1591, Val Loss: 1.7932, F1 Micro: 0.3542, F1 Macro: 0.3356, Accuracy: 0.3542\n","Epoch 79, Train Loss: 1.1486, Val Loss: 1.6798, F1 Micro: 0.3958, F1 Macro: 0.3898, Accuracy: 0.3958\n","Epoch 80, Train Loss: 1.1430, Val Loss: 2.3799, F1 Micro: 0.3333, F1 Macro: 0.3364, Accuracy: 0.3333\n","Epoch 81, Train Loss: 1.1484, Val Loss: 1.7532, F1 Micro: 0.3854, F1 Macro: 0.3749, Accuracy: 0.3854\n","Epoch 82, Train Loss: 1.1372, Val Loss: 1.7858, F1 Micro: 0.4375, F1 Macro: 0.4173, Accuracy: 0.4375\n","Epoch 83, Train Loss: 1.1225, Val Loss: 1.7212, F1 Micro: 0.4583, F1 Macro: 0.4502, Accuracy: 0.4583\n","Epoch 84, Train Loss: 1.1189, Val Loss: 1.6628, F1 Micro: 0.4271, F1 Macro: 0.3903, Accuracy: 0.4271\n","Epoch 85, Train Loss: 1.1144, Val Loss: 1.8190, F1 Micro: 0.3750, F1 Macro: 0.3776, Accuracy: 0.3750\n","Epoch 86, Train Loss: 1.1415, Val Loss: 2.1173, F1 Micro: 0.3125, F1 Macro: 0.2580, Accuracy: 0.3125\n","Epoch 87, Train Loss: 1.0939, Val Loss: 1.7484, F1 Micro: 0.4271, F1 Macro: 0.4268, Accuracy: 0.4271\n","Epoch 88, Train Loss: 1.1478, Val Loss: 1.8894, F1 Micro: 0.3542, F1 Macro: 0.3313, Accuracy: 0.3542\n","Epoch 89, Train Loss: 1.1007, Val Loss: 1.6621, F1 Micro: 0.3750, F1 Macro: 0.3783, Accuracy: 0.3750\n","Epoch 90, Train Loss: 1.1353, Val Loss: 1.6063, F1 Micro: 0.4167, F1 Macro: 0.4035, Accuracy: 0.4167\n","Epoch 91, Train Loss: 1.0672, Val Loss: 1.8565, F1 Micro: 0.4062, F1 Macro: 0.4161, Accuracy: 0.4062\n","Epoch 92, Train Loss: 1.1107, Val Loss: 1.8765, F1 Micro: 0.3958, F1 Macro: 0.3788, Accuracy: 0.3958\n","Epoch 93, Train Loss: 1.0734, Val Loss: 1.6820, F1 Micro: 0.4479, F1 Macro: 0.4319, Accuracy: 0.4479\n","Epoch 94, Train Loss: 1.1177, Val Loss: 1.6108, F1 Micro: 0.4062, F1 Macro: 0.3776, Accuracy: 0.4062\n","Epoch 95, Train Loss: 1.1414, Val Loss: 1.9270, F1 Micro: 0.4375, F1 Macro: 0.4261, Accuracy: 0.4375\n","Epoch 96, Train Loss: 1.0910, Val Loss: 1.9681, F1 Micro: 0.4167, F1 Macro: 0.4032, Accuracy: 0.4167\n","Epoch 97, Train Loss: 1.1066, Val Loss: 1.9688, F1 Micro: 0.4167, F1 Macro: 0.3848, Accuracy: 0.4167\n","Epoch 98, Train Loss: 1.1156, Val Loss: 1.8382, F1 Micro: 0.4688, F1 Macro: 0.4746, Accuracy: 0.4688\n","Epoch 99, Train Loss: 1.0853, Val Loss: 1.7535, F1 Micro: 0.4271, F1 Macro: 0.4291, Accuracy: 0.4271\n","Epoch 100, Train Loss: 1.0408, Val Loss: 1.5367, F1 Micro: 0.5000, F1 Macro: 0.4539, Accuracy: 0.5000\n","Epoch 101, Train Loss: 0.9850, Val Loss: 1.7881, F1 Micro: 0.4792, F1 Macro: 0.4637, Accuracy: 0.4792\n","Epoch 102, Train Loss: 1.0100, Val Loss: 2.0419, F1 Micro: 0.3854, F1 Macro: 0.3875, Accuracy: 0.3854\n","Epoch 103, Train Loss: 1.0159, Val Loss: 1.6707, F1 Micro: 0.4583, F1 Macro: 0.4249, Accuracy: 0.4583\n","Epoch 104, Train Loss: 0.9976, Val Loss: 1.5580, F1 Micro: 0.4792, F1 Macro: 0.4344, Accuracy: 0.4792\n","Epoch 105, Train Loss: 1.0367, Val Loss: 2.0509, F1 Micro: 0.4375, F1 Macro: 0.4010, Accuracy: 0.4375\n","Epoch 106, Train Loss: 1.0423, Val Loss: 1.5187, F1 Micro: 0.4792, F1 Macro: 0.4255, Accuracy: 0.4792\n","Epoch 107, Train Loss: 1.0546, Val Loss: 2.2350, F1 Micro: 0.3542, F1 Macro: 0.3092, Accuracy: 0.3542\n","Epoch 108, Train Loss: 0.9969, Val Loss: 1.9736, F1 Micro: 0.4583, F1 Macro: 0.4347, Accuracy: 0.4583\n","Epoch 109, Train Loss: 1.0309, Val Loss: 2.3007, F1 Micro: 0.3854, F1 Macro: 0.3793, Accuracy: 0.3854\n","Epoch 110, Train Loss: 1.0291, Val Loss: 1.6314, F1 Micro: 0.4688, F1 Macro: 0.4043, Accuracy: 0.4688\n","Epoch 111, Train Loss: 0.9655, Val Loss: 1.5548, F1 Micro: 0.4792, F1 Macro: 0.4354, Accuracy: 0.4792\n","Epoch 112, Train Loss: 0.9583, Val Loss: 1.5099, F1 Micro: 0.5521, F1 Macro: 0.5189, Accuracy: 0.5521\n","Epoch 113, Train Loss: 0.9053, Val Loss: 2.1531, F1 Micro: 0.3958, F1 Macro: 0.3843, Accuracy: 0.3958\n","Epoch 114, Train Loss: 0.8897, Val Loss: 1.8857, F1 Micro: 0.4062, F1 Macro: 0.3941, Accuracy: 0.4062\n","Epoch 115, Train Loss: 0.8947, Val Loss: 1.5658, F1 Micro: 0.5312, F1 Macro: 0.4783, Accuracy: 0.5312\n","Epoch 116, Train Loss: 0.9501, Val Loss: 2.5501, F1 Micro: 0.3333, F1 Macro: 0.3025, Accuracy: 0.3333\n","Epoch 117, Train Loss: 0.9120, Val Loss: 2.7912, F1 Micro: 0.3438, F1 Macro: 0.2913, Accuracy: 0.3438\n","Epoch 118, Train Loss: 0.8813, Val Loss: 2.1620, F1 Micro: 0.4062, F1 Macro: 0.4079, Accuracy: 0.4062\n","Epoch 119, Train Loss: 0.8952, Val Loss: 1.5633, F1 Micro: 0.5208, F1 Macro: 0.4811, Accuracy: 0.5208\n","Epoch 120, Train Loss: 0.9287, Val Loss: 2.2920, F1 Micro: 0.4271, F1 Macro: 0.4295, Accuracy: 0.4271\n","Epoch 121, Train Loss: 0.8895, Val Loss: 1.6066, F1 Micro: 0.5625, F1 Macro: 0.5295, Accuracy: 0.5625\n","Epoch 122, Train Loss: 0.8621, Val Loss: 1.6861, F1 Micro: 0.5208, F1 Macro: 0.5161, Accuracy: 0.5208\n","Epoch 123, Train Loss: 0.8602, Val Loss: 2.3319, F1 Micro: 0.3229, F1 Macro: 0.2519, Accuracy: 0.3229\n","Epoch 124, Train Loss: 0.9037, Val Loss: 2.2260, F1 Micro: 0.4167, F1 Macro: 0.4157, Accuracy: 0.4167\n","Epoch 125, Train Loss: 0.8630, Val Loss: 1.6815, F1 Micro: 0.5417, F1 Macro: 0.5237, Accuracy: 0.5417\n","Epoch 126, Train Loss: 0.9060, Val Loss: 2.7065, F1 Micro: 0.3646, F1 Macro: 0.3414, Accuracy: 0.3646\n","Epoch 127, Train Loss: 0.8345, Val Loss: 1.9055, F1 Micro: 0.4479, F1 Macro: 0.3711, Accuracy: 0.4479\n","Epoch 128, Train Loss: 0.8951, Val Loss: 2.2259, F1 Micro: 0.3958, F1 Macro: 0.3239, Accuracy: 0.3958\n","Epoch 129, Train Loss: 0.8614, Val Loss: 1.8584, F1 Micro: 0.4271, F1 Macro: 0.4335, Accuracy: 0.4271\n","Epoch 130, Train Loss: 0.8231, Val Loss: 1.8432, F1 Micro: 0.4583, F1 Macro: 0.4644, Accuracy: 0.4583\n","Epoch 131, Train Loss: 0.8047, Val Loss: 1.7156, F1 Micro: 0.5000, F1 Macro: 0.4580, Accuracy: 0.5000\n","Epoch 132, Train Loss: 0.8592, Val Loss: 1.9152, F1 Micro: 0.5000, F1 Macro: 0.4818, Accuracy: 0.5000\n","Epoch 133, Train Loss: 0.8773, Val Loss: 2.1076, F1 Micro: 0.4375, F1 Macro: 0.4541, Accuracy: 0.4375\n","Epoch 134, Train Loss: 0.8747, Val Loss: 1.4544, F1 Micro: 0.5417, F1 Macro: 0.5035, Accuracy: 0.5417\n","Epoch 135, Train Loss: 0.8075, Val Loss: 2.0196, F1 Micro: 0.3958, F1 Macro: 0.3544, Accuracy: 0.3958\n","Epoch 136, Train Loss: 0.7707, Val Loss: 1.8086, F1 Micro: 0.4792, F1 Macro: 0.4790, Accuracy: 0.4792\n","Epoch 137, Train Loss: 0.7897, Val Loss: 1.7066, F1 Micro: 0.5625, F1 Macro: 0.5369, Accuracy: 0.5625\n","Epoch 138, Train Loss: 0.7954, Val Loss: 1.5521, F1 Micro: 0.5417, F1 Macro: 0.5276, Accuracy: 0.5417\n","Epoch 139, Train Loss: 0.7841, Val Loss: 2.3630, F1 Micro: 0.3750, F1 Macro: 0.3371, Accuracy: 0.3750\n","Epoch 140, Train Loss: 0.8082, Val Loss: 1.5820, F1 Micro: 0.5729, F1 Macro: 0.5635, Accuracy: 0.5729\n","Epoch 141, Train Loss: 0.7353, Val Loss: 1.8841, F1 Micro: 0.5208, F1 Macro: 0.5133, Accuracy: 0.5208\n","Epoch 142, Train Loss: 0.7205, Val Loss: 1.9393, F1 Micro: 0.4792, F1 Macro: 0.4829, Accuracy: 0.4792\n","Epoch 143, Train Loss: 0.7303, Val Loss: 1.6178, F1 Micro: 0.5729, F1 Macro: 0.5426, Accuracy: 0.5729\n","Epoch 144, Train Loss: 0.7341, Val Loss: 1.7148, F1 Micro: 0.4792, F1 Macro: 0.4729, Accuracy: 0.4792\n","Epoch 145, Train Loss: 0.6964, Val Loss: 1.8204, F1 Micro: 0.5104, F1 Macro: 0.5008, Accuracy: 0.5104\n","Epoch 146, Train Loss: 0.6815, Val Loss: 1.9279, F1 Micro: 0.4271, F1 Macro: 0.3998, Accuracy: 0.4271\n","Epoch 147, Train Loss: 0.7238, Val Loss: 1.9470, F1 Micro: 0.5104, F1 Macro: 0.5091, Accuracy: 0.5104\n","Epoch 148, Train Loss: 0.7801, Val Loss: 1.7208, F1 Micro: 0.5208, F1 Macro: 0.4657, Accuracy: 0.5208\n","Epoch 149, Train Loss: 0.7632, Val Loss: 1.5725, F1 Micro: 0.5729, F1 Macro: 0.5557, Accuracy: 0.5729\n","Epoch 150, Train Loss: 0.6994, Val Loss: 2.0395, F1 Micro: 0.4479, F1 Macro: 0.4163, Accuracy: 0.4479\n","Epoch 151, Train Loss: 0.7439, Val Loss: 2.8534, F1 Micro: 0.3854, F1 Macro: 0.3874, Accuracy: 0.3854\n","Epoch 152, Train Loss: 0.7677, Val Loss: 1.7605, F1 Micro: 0.4896, F1 Macro: 0.4966, Accuracy: 0.4896\n","Epoch 153, Train Loss: 0.7126, Val Loss: 2.0127, F1 Micro: 0.4896, F1 Macro: 0.4958, Accuracy: 0.4896\n","Epoch 154, Train Loss: 0.7077, Val Loss: 2.9252, F1 Micro: 0.3333, F1 Macro: 0.2806, Accuracy: 0.3333\n","Epoch 155, Train Loss: 0.7427, Val Loss: 2.2821, F1 Micro: 0.4688, F1 Macro: 0.4732, Accuracy: 0.4688\n","Epoch 156, Train Loss: 0.7433, Val Loss: 1.5892, F1 Micro: 0.5104, F1 Macro: 0.5024, Accuracy: 0.5104\n","Epoch 157, Train Loss: 0.6568, Val Loss: 1.9951, F1 Micro: 0.4583, F1 Macro: 0.4177, Accuracy: 0.4583\n","Epoch 158, Train Loss: 0.6852, Val Loss: 2.7481, F1 Micro: 0.4167, F1 Macro: 0.4276, Accuracy: 0.4167\n","Epoch 159, Train Loss: 0.7030, Val Loss: 1.5140, F1 Micro: 0.6250, F1 Macro: 0.6043, Accuracy: 0.6250\n","Epoch 160, Train Loss: 0.6794, Val Loss: 1.8776, F1 Micro: 0.4688, F1 Macro: 0.4667, Accuracy: 0.4688\n","Epoch 161, Train Loss: 0.7237, Val Loss: 3.0511, F1 Micro: 0.3646, F1 Macro: 0.3713, Accuracy: 0.3646\n","Epoch 162, Train Loss: 0.6675, Val Loss: 3.0983, F1 Micro: 0.3333, F1 Macro: 0.2930, Accuracy: 0.3333\n","Epoch 163, Train Loss: 0.6885, Val Loss: 1.6644, F1 Micro: 0.5208, F1 Macro: 0.5128, Accuracy: 0.5208\n","Epoch 164, Train Loss: 0.6419, Val Loss: 1.8674, F1 Micro: 0.5104, F1 Macro: 0.5091, Accuracy: 0.5104\n","Epoch 165, Train Loss: 0.6658, Val Loss: 1.7074, F1 Micro: 0.5625, F1 Macro: 0.5258, Accuracy: 0.5625\n","Epoch 166, Train Loss: 0.7254, Val Loss: 1.5975, F1 Micro: 0.5625, F1 Macro: 0.5567, Accuracy: 0.5625\n","Epoch 167, Train Loss: 0.6124, Val Loss: 2.0247, F1 Micro: 0.5000, F1 Macro: 0.5124, Accuracy: 0.5000\n","Epoch 168, Train Loss: 0.6842, Val Loss: 1.5916, F1 Micro: 0.5104, F1 Macro: 0.5000, Accuracy: 0.5104\n","Epoch 169, Train Loss: 0.5987, Val Loss: 1.6986, F1 Micro: 0.5729, F1 Macro: 0.5608, Accuracy: 0.5729\n","Epoch 170, Train Loss: 0.6310, Val Loss: 2.5434, F1 Micro: 0.4167, F1 Macro: 0.3816, Accuracy: 0.4167\n","Epoch 171, Train Loss: 0.6560, Val Loss: 1.9185, F1 Micro: 0.5000, F1 Macro: 0.4871, Accuracy: 0.5000\n","Epoch 172, Train Loss: 0.5997, Val Loss: 2.1743, F1 Micro: 0.4062, F1 Macro: 0.3802, Accuracy: 0.4062\n","Epoch 173, Train Loss: 0.6770, Val Loss: 2.1969, F1 Micro: 0.4688, F1 Macro: 0.4692, Accuracy: 0.4688\n","Epoch 174, Train Loss: 0.6216, Val Loss: 1.7969, F1 Micro: 0.5000, F1 Macro: 0.4799, Accuracy: 0.5000\n","Epoch 175, Train Loss: 0.6167, Val Loss: 1.6048, F1 Micro: 0.5625, F1 Macro: 0.5581, Accuracy: 0.5625\n","Epoch 176, Train Loss: 0.6508, Val Loss: 2.9052, F1 Micro: 0.4167, F1 Macro: 0.4188, Accuracy: 0.4167\n","Epoch 177, Train Loss: 0.7189, Val Loss: 1.5910, F1 Micro: 0.5938, F1 Macro: 0.5795, Accuracy: 0.5938\n","Epoch 178, Train Loss: 0.6078, Val Loss: 2.2977, F1 Micro: 0.4583, F1 Macro: 0.4593, Accuracy: 0.4583\n","Epoch 179, Train Loss: 0.7003, Val Loss: 1.6588, F1 Micro: 0.5521, F1 Macro: 0.5255, Accuracy: 0.5521\n","Epoch 180, Train Loss: 0.5657, Val Loss: 2.3624, F1 Micro: 0.4583, F1 Macro: 0.4549, Accuracy: 0.4583\n","Epoch 181, Train Loss: 0.5689, Val Loss: 2.1459, F1 Micro: 0.4688, F1 Macro: 0.4681, Accuracy: 0.4688\n","Epoch 182, Train Loss: 0.6025, Val Loss: 2.4973, F1 Micro: 0.4792, F1 Macro: 0.4326, Accuracy: 0.4792\n","Epoch 183, Train Loss: 0.7130, Val Loss: 1.6896, F1 Micro: 0.5625, F1 Macro: 0.5432, Accuracy: 0.5625\n","Epoch 184, Train Loss: 0.5911, Val Loss: 1.6472, F1 Micro: 0.5625, F1 Macro: 0.5272, Accuracy: 0.5625\n","Epoch 185, Train Loss: 0.5605, Val Loss: 2.1272, F1 Micro: 0.4375, F1 Macro: 0.4267, Accuracy: 0.4375\n","Epoch 186, Train Loss: 0.5876, Val Loss: 1.5431, F1 Micro: 0.6042, F1 Macro: 0.5854, Accuracy: 0.6042\n","Epoch 187, Train Loss: 0.5496, Val Loss: 1.7085, F1 Micro: 0.5521, F1 Macro: 0.5386, Accuracy: 0.5521\n","Epoch 188, Train Loss: 0.5731, Val Loss: 1.8255, F1 Micro: 0.4896, F1 Macro: 0.4454, Accuracy: 0.4896\n","Epoch 189, Train Loss: 0.5467, Val Loss: 1.7690, F1 Micro: 0.5729, F1 Macro: 0.5586, Accuracy: 0.5729\n","Epoch 190, Train Loss: 0.5981, Val Loss: 1.8635, F1 Micro: 0.5104, F1 Macro: 0.4933, Accuracy: 0.5104\n","Epoch 191, Train Loss: 0.5609, Val Loss: 1.6871, F1 Micro: 0.5938, F1 Macro: 0.5848, Accuracy: 0.5938\n","Epoch 192, Train Loss: 0.5828, Val Loss: 1.9226, F1 Micro: 0.5312, F1 Macro: 0.5309, Accuracy: 0.5312\n","Epoch 193, Train Loss: 0.5654, Val Loss: 1.7056, F1 Micro: 0.5625, F1 Macro: 0.5403, Accuracy: 0.5625\n","Epoch 194, Train Loss: 0.5466, Val Loss: 2.1617, F1 Micro: 0.5000, F1 Macro: 0.4774, Accuracy: 0.5000\n","Epoch 195, Train Loss: 0.5163, Val Loss: 2.0947, F1 Micro: 0.4896, F1 Macro: 0.4877, Accuracy: 0.4896\n","Epoch 196, Train Loss: 0.5131, Val Loss: 2.2635, F1 Micro: 0.4688, F1 Macro: 0.4636, Accuracy: 0.4688\n","Epoch 197, Train Loss: 0.4963, Val Loss: 3.0287, F1 Micro: 0.3958, F1 Macro: 0.3519, Accuracy: 0.3958\n","Epoch 198, Train Loss: 0.5219, Val Loss: 1.9459, F1 Micro: 0.5833, F1 Macro: 0.5642, Accuracy: 0.5833\n","Epoch 199, Train Loss: 0.4726, Val Loss: 1.8352, F1 Micro: 0.5938, F1 Macro: 0.5901, Accuracy: 0.5938\n","Epoch 200, Train Loss: 0.4412, Val Loss: 1.9645, F1 Micro: 0.5104, F1 Macro: 0.5100, Accuracy: 0.5104\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7877, Val Loss: 1.8790, F1 Micro: 0.2500, F1 Macro: 0.1829, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.7519, Val Loss: 1.8421, F1 Micro: 0.2292, F1 Macro: 0.1700, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.7540, Val Loss: 1.8383, F1 Micro: 0.3021, F1 Macro: 0.2667, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.7278, Val Loss: 1.7794, F1 Micro: 0.2708, F1 Macro: 0.2353, Accuracy: 0.2708\n","Epoch 5, Train Loss: 1.7140, Val Loss: 1.7498, F1 Micro: 0.2604, F1 Macro: 0.2062, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.6924, Val Loss: 1.7405, F1 Micro: 0.2500, F1 Macro: 0.1799, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.6879, Val Loss: 1.8926, F1 Micro: 0.2604, F1 Macro: 0.2303, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6866, Val Loss: 1.7340, F1 Micro: 0.2708, F1 Macro: 0.1929, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.6706, Val Loss: 1.7263, F1 Micro: 0.3021, F1 Macro: 0.2368, Accuracy: 0.3021\n","Epoch 10, Train Loss: 1.6564, Val Loss: 1.7192, F1 Micro: 0.2708, F1 Macro: 0.2125, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.6496, Val Loss: 1.8032, F1 Micro: 0.2292, F1 Macro: 0.1592, Accuracy: 0.2292\n","Epoch 12, Train Loss: 1.6339, Val Loss: 1.7802, F1 Micro: 0.3021, F1 Macro: 0.2709, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.6352, Val Loss: 2.0518, F1 Micro: 0.2396, F1 Macro: 0.1840, Accuracy: 0.2396\n","Epoch 14, Train Loss: 1.6525, Val Loss: 1.7713, F1 Micro: 0.3229, F1 Macro: 0.2671, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.6514, Val Loss: 1.7464, F1 Micro: 0.3333, F1 Macro: 0.2674, Accuracy: 0.3333\n","Epoch 16, Train Loss: 1.6272, Val Loss: 1.6362, F1 Micro: 0.3125, F1 Macro: 0.2726, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.5995, Val Loss: 2.0736, F1 Micro: 0.1979, F1 Macro: 0.1734, Accuracy: 0.1979\n","Epoch 18, Train Loss: 1.6096, Val Loss: 1.8602, F1 Micro: 0.2708, F1 Macro: 0.2554, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.5895, Val Loss: 2.1733, F1 Micro: 0.2292, F1 Macro: 0.1783, Accuracy: 0.2292\n","Epoch 20, Train Loss: 1.5948, Val Loss: 1.7879, F1 Micro: 0.2604, F1 Macro: 0.1910, Accuracy: 0.2604\n","Epoch 21, Train Loss: 1.5586, Val Loss: 1.6902, F1 Micro: 0.3125, F1 Macro: 0.2634, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.5554, Val Loss: 1.6703, F1 Micro: 0.3125, F1 Macro: 0.2668, Accuracy: 0.3125\n","Epoch 23, Train Loss: 1.5681, Val Loss: 1.8090, F1 Micro: 0.3229, F1 Macro: 0.2975, Accuracy: 0.3229\n","Epoch 24, Train Loss: 1.5842, Val Loss: 1.7890, F1 Micro: 0.3125, F1 Macro: 0.2710, Accuracy: 0.3125\n","Epoch 25, Train Loss: 1.5521, Val Loss: 1.8171, F1 Micro: 0.2500, F1 Macro: 0.2039, Accuracy: 0.2500\n","Epoch 26, Train Loss: 1.5556, Val Loss: 1.7756, F1 Micro: 0.2708, F1 Macro: 0.2344, Accuracy: 0.2708\n","Epoch 27, Train Loss: 1.5323, Val Loss: 1.7053, F1 Micro: 0.3333, F1 Macro: 0.2956, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.5269, Val Loss: 1.9026, F1 Micro: 0.2604, F1 Macro: 0.2432, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.5549, Val Loss: 1.8483, F1 Micro: 0.3021, F1 Macro: 0.2976, Accuracy: 0.3021\n","Epoch 30, Train Loss: 1.5239, Val Loss: 2.1523, F1 Micro: 0.2604, F1 Macro: 0.2021, Accuracy: 0.2604\n","Epoch 31, Train Loss: 1.5140, Val Loss: 1.6578, F1 Micro: 0.3542, F1 Macro: 0.3248, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.5178, Val Loss: 1.7469, F1 Micro: 0.3333, F1 Macro: 0.2921, Accuracy: 0.3333\n","Epoch 33, Train Loss: 1.5232, Val Loss: 1.7226, F1 Micro: 0.3438, F1 Macro: 0.3566, Accuracy: 0.3438\n","Epoch 34, Train Loss: 1.5502, Val Loss: 1.7095, F1 Micro: 0.2917, F1 Macro: 0.2811, Accuracy: 0.2917\n","Epoch 35, Train Loss: 1.4941, Val Loss: 1.6204, F1 Micro: 0.3750, F1 Macro: 0.3619, Accuracy: 0.3750\n","Epoch 36, Train Loss: 1.4938, Val Loss: 1.7435, F1 Micro: 0.3333, F1 Macro: 0.2670, Accuracy: 0.3333\n","Epoch 37, Train Loss: 1.4977, Val Loss: 2.0049, F1 Micro: 0.2396, F1 Macro: 0.2154, Accuracy: 0.2396\n","Epoch 38, Train Loss: 1.5001, Val Loss: 1.8177, F1 Micro: 0.3021, F1 Macro: 0.2531, Accuracy: 0.3021\n","Epoch 39, Train Loss: 1.5056, Val Loss: 1.6095, F1 Micro: 0.3333, F1 Macro: 0.3266, Accuracy: 0.3333\n","Epoch 40, Train Loss: 1.5036, Val Loss: 2.1366, F1 Micro: 0.3021, F1 Macro: 0.2669, Accuracy: 0.3021\n","Epoch 41, Train Loss: 1.4771, Val Loss: 1.9132, F1 Micro: 0.2604, F1 Macro: 0.2406, Accuracy: 0.2604\n","Epoch 42, Train Loss: 1.4647, Val Loss: 1.9145, F1 Micro: 0.2500, F1 Macro: 0.2438, Accuracy: 0.2500\n","Epoch 43, Train Loss: 1.4629, Val Loss: 1.8984, F1 Micro: 0.3021, F1 Macro: 0.2626, Accuracy: 0.3021\n","Epoch 44, Train Loss: 1.4719, Val Loss: 1.6232, F1 Micro: 0.3542, F1 Macro: 0.3232, Accuracy: 0.3542\n","Epoch 45, Train Loss: 1.4599, Val Loss: 2.4190, F1 Micro: 0.2708, F1 Macro: 0.2296, Accuracy: 0.2708\n","Epoch 46, Train Loss: 1.4446, Val Loss: 1.6769, F1 Micro: 0.3229, F1 Macro: 0.3339, Accuracy: 0.3229\n","Epoch 47, Train Loss: 1.4330, Val Loss: 1.7603, F1 Micro: 0.3229, F1 Macro: 0.2834, Accuracy: 0.3229\n","Epoch 48, Train Loss: 1.4965, Val Loss: 1.8619, F1 Micro: 0.3021, F1 Macro: 0.2602, Accuracy: 0.3021\n","Epoch 49, Train Loss: 1.4513, Val Loss: 1.8751, F1 Micro: 0.2708, F1 Macro: 0.2207, Accuracy: 0.2708\n","Epoch 50, Train Loss: 1.4547, Val Loss: 1.8177, F1 Micro: 0.3021, F1 Macro: 0.2641, Accuracy: 0.3021\n","Epoch 51, Train Loss: 1.4474, Val Loss: 1.7631, F1 Micro: 0.3333, F1 Macro: 0.3066, Accuracy: 0.3333\n","Epoch 52, Train Loss: 1.4297, Val Loss: 1.7043, F1 Micro: 0.3750, F1 Macro: 0.3582, Accuracy: 0.3750\n","Epoch 53, Train Loss: 1.4015, Val Loss: 1.7032, F1 Micro: 0.3854, F1 Macro: 0.3601, Accuracy: 0.3854\n","Epoch 54, Train Loss: 1.4018, Val Loss: 1.6309, F1 Micro: 0.4062, F1 Macro: 0.4093, Accuracy: 0.4062\n","Epoch 55, Train Loss: 1.3937, Val Loss: 1.7360, F1 Micro: 0.3646, F1 Macro: 0.3535, Accuracy: 0.3646\n","Epoch 56, Train Loss: 1.4105, Val Loss: 1.6169, F1 Micro: 0.3229, F1 Macro: 0.2635, Accuracy: 0.3229\n","Epoch 57, Train Loss: 1.4062, Val Loss: 1.6452, F1 Micro: 0.4375, F1 Macro: 0.4286, Accuracy: 0.4375\n","Epoch 58, Train Loss: 1.3963, Val Loss: 1.6297, F1 Micro: 0.3958, F1 Macro: 0.3840, Accuracy: 0.3958\n","Epoch 59, Train Loss: 1.3822, Val Loss: 1.5901, F1 Micro: 0.3854, F1 Macro: 0.3496, Accuracy: 0.3854\n","Epoch 60, Train Loss: 1.4011, Val Loss: 1.5748, F1 Micro: 0.4479, F1 Macro: 0.4350, Accuracy: 0.4479\n","Epoch 61, Train Loss: 1.3433, Val Loss: 1.6448, F1 Micro: 0.4167, F1 Macro: 0.4017, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.3588, Val Loss: 1.6810, F1 Micro: 0.3854, F1 Macro: 0.3671, Accuracy: 0.3854\n","Epoch 63, Train Loss: 1.3545, Val Loss: 1.7856, F1 Micro: 0.2917, F1 Macro: 0.2629, Accuracy: 0.2917\n","Epoch 64, Train Loss: 1.3833, Val Loss: 2.4302, F1 Micro: 0.2500, F1 Macro: 0.2010, Accuracy: 0.2500\n","Epoch 65, Train Loss: 1.3454, Val Loss: 1.6897, F1 Micro: 0.3542, F1 Macro: 0.3181, Accuracy: 0.3542\n","Epoch 66, Train Loss: 1.3445, Val Loss: 1.5576, F1 Micro: 0.3854, F1 Macro: 0.3373, Accuracy: 0.3854\n","Epoch 67, Train Loss: 1.3353, Val Loss: 2.0865, F1 Micro: 0.2708, F1 Macro: 0.2640, Accuracy: 0.2708\n","Epoch 68, Train Loss: 1.3322, Val Loss: 1.8181, F1 Micro: 0.3125, F1 Macro: 0.2767, Accuracy: 0.3125\n","Epoch 69, Train Loss: 1.3194, Val Loss: 1.7337, F1 Micro: 0.3333, F1 Macro: 0.3167, Accuracy: 0.3333\n","Epoch 70, Train Loss: 1.3097, Val Loss: 1.6859, F1 Micro: 0.4479, F1 Macro: 0.4266, Accuracy: 0.4479\n","Epoch 71, Train Loss: 1.3155, Val Loss: 1.8278, F1 Micro: 0.3333, F1 Macro: 0.2737, Accuracy: 0.3333\n","Epoch 72, Train Loss: 1.3327, Val Loss: 1.5040, F1 Micro: 0.4792, F1 Macro: 0.4553, Accuracy: 0.4792\n","Epoch 73, Train Loss: 1.2723, Val Loss: 1.6448, F1 Micro: 0.3333, F1 Macro: 0.3346, Accuracy: 0.3333\n","Epoch 74, Train Loss: 1.3060, Val Loss: 1.7516, F1 Micro: 0.3542, F1 Macro: 0.3327, Accuracy: 0.3542\n","Epoch 75, Train Loss: 1.2801, Val Loss: 2.2172, F1 Micro: 0.2292, F1 Macro: 0.2082, Accuracy: 0.2292\n","Epoch 76, Train Loss: 1.2876, Val Loss: 2.1325, F1 Micro: 0.3229, F1 Macro: 0.2905, Accuracy: 0.3229\n","Epoch 77, Train Loss: 1.2462, Val Loss: 1.4559, F1 Micro: 0.4792, F1 Macro: 0.4695, Accuracy: 0.4792\n","Epoch 78, Train Loss: 1.2435, Val Loss: 1.8574, F1 Micro: 0.3646, F1 Macro: 0.3231, Accuracy: 0.3646\n","Epoch 79, Train Loss: 1.2712, Val Loss: 1.7182, F1 Micro: 0.3542, F1 Macro: 0.3064, Accuracy: 0.3542\n","Epoch 80, Train Loss: 1.2847, Val Loss: 1.4813, F1 Micro: 0.5000, F1 Macro: 0.4943, Accuracy: 0.5000\n","Epoch 81, Train Loss: 1.2368, Val Loss: 1.5467, F1 Micro: 0.4479, F1 Macro: 0.4161, Accuracy: 0.4479\n","Epoch 82, Train Loss: 1.2504, Val Loss: 1.6261, F1 Micro: 0.4479, F1 Macro: 0.4326, Accuracy: 0.4479\n","Epoch 83, Train Loss: 1.2381, Val Loss: 1.5153, F1 Micro: 0.4375, F1 Macro: 0.4291, Accuracy: 0.4375\n","Epoch 84, Train Loss: 1.2247, Val Loss: 1.6467, F1 Micro: 0.4062, F1 Macro: 0.3875, Accuracy: 0.4062\n","Epoch 85, Train Loss: 1.2114, Val Loss: 1.5784, F1 Micro: 0.4271, F1 Macro: 0.4021, Accuracy: 0.4271\n","Epoch 86, Train Loss: 1.2503, Val Loss: 2.1283, F1 Micro: 0.2604, F1 Macro: 0.2368, Accuracy: 0.2604\n","Epoch 87, Train Loss: 1.2544, Val Loss: 1.4936, F1 Micro: 0.4583, F1 Macro: 0.4314, Accuracy: 0.4583\n","Epoch 88, Train Loss: 1.2118, Val Loss: 1.6977, F1 Micro: 0.3333, F1 Macro: 0.3424, Accuracy: 0.3333\n","Epoch 89, Train Loss: 1.2417, Val Loss: 1.8570, F1 Micro: 0.4062, F1 Macro: 0.3763, Accuracy: 0.4062\n","Epoch 90, Train Loss: 1.2428, Val Loss: 1.7210, F1 Micro: 0.3958, F1 Macro: 0.3849, Accuracy: 0.3958\n","Epoch 91, Train Loss: 1.2538, Val Loss: 2.4301, F1 Micro: 0.3750, F1 Macro: 0.3329, Accuracy: 0.3750\n","Epoch 92, Train Loss: 1.2878, Val Loss: 1.6323, F1 Micro: 0.3333, F1 Macro: 0.3128, Accuracy: 0.3333\n","Epoch 93, Train Loss: 1.1925, Val Loss: 1.5919, F1 Micro: 0.4375, F1 Macro: 0.4313, Accuracy: 0.4375\n","Epoch 94, Train Loss: 1.1758, Val Loss: 1.5234, F1 Micro: 0.4688, F1 Macro: 0.4467, Accuracy: 0.4688\n","Epoch 95, Train Loss: 1.2346, Val Loss: 1.5107, F1 Micro: 0.4583, F1 Macro: 0.4499, Accuracy: 0.4583\n","Epoch 96, Train Loss: 1.1975, Val Loss: 1.7821, F1 Micro: 0.3542, F1 Macro: 0.3303, Accuracy: 0.3542\n","Epoch 97, Train Loss: 1.2092, Val Loss: 1.4524, F1 Micro: 0.4583, F1 Macro: 0.4290, Accuracy: 0.4583\n","Epoch 98, Train Loss: 1.1680, Val Loss: 1.6738, F1 Micro: 0.3750, F1 Macro: 0.3786, Accuracy: 0.3750\n","Epoch 99, Train Loss: 1.1953, Val Loss: 2.0409, F1 Micro: 0.3542, F1 Macro: 0.3102, Accuracy: 0.3542\n","Epoch 100, Train Loss: 1.1782, Val Loss: 1.6476, F1 Micro: 0.3958, F1 Macro: 0.3426, Accuracy: 0.3958\n","Epoch 101, Train Loss: 1.2162, Val Loss: 1.8334, F1 Micro: 0.3854, F1 Macro: 0.3659, Accuracy: 0.3854\n","Epoch 102, Train Loss: 1.1141, Val Loss: 1.6439, F1 Micro: 0.4271, F1 Macro: 0.4247, Accuracy: 0.4271\n","Epoch 103, Train Loss: 1.1370, Val Loss: 1.4331, F1 Micro: 0.4792, F1 Macro: 0.4811, Accuracy: 0.4792\n","Epoch 104, Train Loss: 1.1651, Val Loss: 1.7432, F1 Micro: 0.3958, F1 Macro: 0.3428, Accuracy: 0.3958\n","Epoch 105, Train Loss: 1.2056, Val Loss: 1.6139, F1 Micro: 0.3958, F1 Macro: 0.3787, Accuracy: 0.3958\n","Epoch 106, Train Loss: 1.2003, Val Loss: 2.2549, F1 Micro: 0.2708, F1 Macro: 0.2212, Accuracy: 0.2708\n","Epoch 107, Train Loss: 1.1700, Val Loss: 1.9247, F1 Micro: 0.3750, F1 Macro: 0.3406, Accuracy: 0.3750\n","Epoch 108, Train Loss: 1.1425, Val Loss: 1.4593, F1 Micro: 0.4479, F1 Macro: 0.4334, Accuracy: 0.4479\n","Epoch 109, Train Loss: 1.1396, Val Loss: 1.5894, F1 Micro: 0.4583, F1 Macro: 0.4605, Accuracy: 0.4583\n","Epoch 110, Train Loss: 1.1291, Val Loss: 1.7955, F1 Micro: 0.3958, F1 Macro: 0.3699, Accuracy: 0.3958\n","Epoch 111, Train Loss: 1.1126, Val Loss: 1.5942, F1 Micro: 0.4271, F1 Macro: 0.3839, Accuracy: 0.4271\n","Epoch 112, Train Loss: 1.1262, Val Loss: 1.7233, F1 Micro: 0.3750, F1 Macro: 0.3699, Accuracy: 0.3750\n","Epoch 113, Train Loss: 1.1599, Val Loss: 1.5631, F1 Micro: 0.4167, F1 Macro: 0.3466, Accuracy: 0.4167\n","Epoch 114, Train Loss: 1.1159, Val Loss: 1.7127, F1 Micro: 0.4375, F1 Macro: 0.4142, Accuracy: 0.4375\n","Epoch 115, Train Loss: 1.1137, Val Loss: 1.8524, F1 Micro: 0.3646, F1 Macro: 0.3354, Accuracy: 0.3646\n","Epoch 116, Train Loss: 1.1001, Val Loss: 1.5038, F1 Micro: 0.4375, F1 Macro: 0.4070, Accuracy: 0.4375\n","Epoch 117, Train Loss: 1.1371, Val Loss: 1.5664, F1 Micro: 0.4271, F1 Macro: 0.4442, Accuracy: 0.4271\n","Epoch 118, Train Loss: 1.0887, Val Loss: 1.6532, F1 Micro: 0.4062, F1 Macro: 0.4063, Accuracy: 0.4062\n","Epoch 119, Train Loss: 1.1025, Val Loss: 1.8477, F1 Micro: 0.4271, F1 Macro: 0.4209, Accuracy: 0.4271\n","Epoch 120, Train Loss: 1.0688, Val Loss: 1.6506, F1 Micro: 0.3854, F1 Macro: 0.3737, Accuracy: 0.3854\n","Epoch 121, Train Loss: 1.0998, Val Loss: 3.0077, F1 Micro: 0.2396, F1 Macro: 0.1860, Accuracy: 0.2396\n","Epoch 122, Train Loss: 1.1729, Val Loss: 1.7698, F1 Micro: 0.4479, F1 Macro: 0.4232, Accuracy: 0.4479\n","Epoch 123, Train Loss: 1.0771, Val Loss: 1.4631, F1 Micro: 0.4688, F1 Macro: 0.4620, Accuracy: 0.4688\n","Epoch 124, Train Loss: 1.0676, Val Loss: 2.4658, F1 Micro: 0.3229, F1 Macro: 0.2813, Accuracy: 0.3229\n","Epoch 125, Train Loss: 1.1058, Val Loss: 1.7688, F1 Micro: 0.4167, F1 Macro: 0.4093, Accuracy: 0.4167\n","Epoch 126, Train Loss: 1.1047, Val Loss: 1.5236, F1 Micro: 0.4271, F1 Macro: 0.3935, Accuracy: 0.4271\n","Epoch 127, Train Loss: 1.0620, Val Loss: 2.0269, F1 Micro: 0.3854, F1 Macro: 0.3659, Accuracy: 0.3854\n","Epoch 128, Train Loss: 1.0700, Val Loss: 1.6335, F1 Micro: 0.4062, F1 Macro: 0.3993, Accuracy: 0.4062\n","Epoch 129, Train Loss: 1.0672, Val Loss: 2.0120, F1 Micro: 0.3021, F1 Macro: 0.2736, Accuracy: 0.3021\n","Epoch 130, Train Loss: 1.0703, Val Loss: 1.6056, F1 Micro: 0.4167, F1 Macro: 0.3895, Accuracy: 0.4167\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8118, Val Loss: 1.7848, F1 Micro: 0.2500, F1 Macro: 0.1599, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.7483, Val Loss: 1.7963, F1 Micro: 0.1562, F1 Macro: 0.0996, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7301, Val Loss: 1.8372, F1 Micro: 0.1562, F1 Macro: 0.1124, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7066, Val Loss: 1.7900, F1 Micro: 0.1979, F1 Macro: 0.1499, Accuracy: 0.1979\n","Epoch 5, Train Loss: 1.6943, Val Loss: 1.7527, F1 Micro: 0.1667, F1 Macro: 0.1245, Accuracy: 0.1667\n","Epoch 6, Train Loss: 1.6799, Val Loss: 1.7479, F1 Micro: 0.2083, F1 Macro: 0.1514, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.6660, Val Loss: 1.7737, F1 Micro: 0.2708, F1 Macro: 0.2129, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.6496, Val Loss: 1.8101, F1 Micro: 0.3021, F1 Macro: 0.2381, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.6314, Val Loss: 1.6972, F1 Micro: 0.3021, F1 Macro: 0.2743, Accuracy: 0.3021\n","Epoch 10, Train Loss: 1.6259, Val Loss: 1.7220, F1 Micro: 0.3021, F1 Macro: 0.2366, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.6012, Val Loss: 1.7633, F1 Micro: 0.2708, F1 Macro: 0.2136, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.6013, Val Loss: 1.6938, F1 Micro: 0.3333, F1 Macro: 0.2796, Accuracy: 0.3333\n","Epoch 13, Train Loss: 1.5975, Val Loss: 1.7952, F1 Micro: 0.2188, F1 Macro: 0.1951, Accuracy: 0.2188\n","Epoch 14, Train Loss: 1.5813, Val Loss: 1.9000, F1 Micro: 0.2917, F1 Macro: 0.1878, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.5927, Val Loss: 1.7416, F1 Micro: 0.2188, F1 Macro: 0.2129, Accuracy: 0.2188\n","Epoch 16, Train Loss: 1.5709, Val Loss: 1.6838, F1 Micro: 0.2604, F1 Macro: 0.2364, Accuracy: 0.2604\n","Epoch 17, Train Loss: 1.5451, Val Loss: 1.6998, F1 Micro: 0.3542, F1 Macro: 0.3159, Accuracy: 0.3542\n","Epoch 18, Train Loss: 1.5389, Val Loss: 1.6847, F1 Micro: 0.2812, F1 Macro: 0.2325, Accuracy: 0.2812\n","Epoch 19, Train Loss: 1.5505, Val Loss: 1.7365, F1 Micro: 0.3125, F1 Macro: 0.2577, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.5268, Val Loss: 1.7061, F1 Micro: 0.3125, F1 Macro: 0.2912, Accuracy: 0.3125\n","Epoch 21, Train Loss: 1.5110, Val Loss: 1.7158, F1 Micro: 0.2708, F1 Macro: 0.2549, Accuracy: 0.2708\n","Epoch 22, Train Loss: 1.5237, Val Loss: 1.9916, F1 Micro: 0.1146, F1 Macro: 0.0884, Accuracy: 0.1146\n","Epoch 23, Train Loss: 1.5091, Val Loss: 1.6528, F1 Micro: 0.3542, F1 Macro: 0.3324, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.4860, Val Loss: 1.7963, F1 Micro: 0.3021, F1 Macro: 0.2705, Accuracy: 0.3021\n","Epoch 25, Train Loss: 1.4964, Val Loss: 1.7497, F1 Micro: 0.3542, F1 Macro: 0.2952, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.4676, Val Loss: 1.7241, F1 Micro: 0.2812, F1 Macro: 0.2501, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.4662, Val Loss: 1.8450, F1 Micro: 0.1979, F1 Macro: 0.1533, Accuracy: 0.1979\n","Epoch 28, Train Loss: 1.4602, Val Loss: 1.8534, F1 Micro: 0.2708, F1 Macro: 0.2489, Accuracy: 0.2708\n","Epoch 29, Train Loss: 1.4576, Val Loss: 1.7141, F1 Micro: 0.3125, F1 Macro: 0.2786, Accuracy: 0.3125\n","Epoch 30, Train Loss: 1.4241, Val Loss: 2.1866, F1 Micro: 0.2812, F1 Macro: 0.2650, Accuracy: 0.2812\n","Epoch 31, Train Loss: 1.4239, Val Loss: 1.7958, F1 Micro: 0.2917, F1 Macro: 0.2729, Accuracy: 0.2917\n","Epoch 32, Train Loss: 1.4222, Val Loss: 2.2770, F1 Micro: 0.3125, F1 Macro: 0.2582, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.4060, Val Loss: 1.7710, F1 Micro: 0.2396, F1 Macro: 0.2164, Accuracy: 0.2396\n","Epoch 34, Train Loss: 1.4181, Val Loss: 1.9731, F1 Micro: 0.3542, F1 Macro: 0.3104, Accuracy: 0.3542\n","Epoch 35, Train Loss: 1.4067, Val Loss: 1.8019, F1 Micro: 0.3542, F1 Macro: 0.3241, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.3746, Val Loss: 2.3051, F1 Micro: 0.2188, F1 Macro: 0.1685, Accuracy: 0.2188\n","Epoch 37, Train Loss: 1.3776, Val Loss: 1.7711, F1 Micro: 0.2917, F1 Macro: 0.2651, Accuracy: 0.2917\n","Epoch 38, Train Loss: 1.3926, Val Loss: 1.9102, F1 Micro: 0.2708, F1 Macro: 0.2256, Accuracy: 0.2708\n","Epoch 39, Train Loss: 1.3585, Val Loss: 1.8192, F1 Micro: 0.2500, F1 Macro: 0.2262, Accuracy: 0.2500\n","Epoch 40, Train Loss: 1.3630, Val Loss: 1.8976, F1 Micro: 0.3021, F1 Macro: 0.2625, Accuracy: 0.3021\n","Epoch 41, Train Loss: 1.3669, Val Loss: 1.9365, F1 Micro: 0.2708, F1 Macro: 0.2602, Accuracy: 0.2708\n","Epoch 42, Train Loss: 1.3145, Val Loss: 2.0759, F1 Micro: 0.2812, F1 Macro: 0.2163, Accuracy: 0.2812\n","Epoch 43, Train Loss: 1.2926, Val Loss: 2.6221, F1 Micro: 0.2812, F1 Macro: 0.1786, Accuracy: 0.2812\n","Epoch 44, Train Loss: 1.3166, Val Loss: 1.6691, F1 Micro: 0.3333, F1 Macro: 0.2924, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.3155, Val Loss: 1.8929, F1 Micro: 0.3542, F1 Macro: 0.3261, Accuracy: 0.3542\n","Epoch 46, Train Loss: 1.2986, Val Loss: 1.8758, F1 Micro: 0.3438, F1 Macro: 0.3084, Accuracy: 0.3438\n","Epoch 47, Train Loss: 1.2916, Val Loss: 1.9313, F1 Micro: 0.3542, F1 Macro: 0.3235, Accuracy: 0.3542\n","Epoch 48, Train Loss: 1.2839, Val Loss: 2.1946, F1 Micro: 0.2917, F1 Macro: 0.2467, Accuracy: 0.2917\n","Epoch 49, Train Loss: 1.2312, Val Loss: 1.8781, F1 Micro: 0.3021, F1 Macro: 0.2675, Accuracy: 0.3021\n","Epoch 50, Train Loss: 1.2976, Val Loss: 1.8698, F1 Micro: 0.3542, F1 Macro: 0.3224, Accuracy: 0.3542\n","Epoch 51, Train Loss: 1.2324, Val Loss: 2.1435, F1 Micro: 0.3333, F1 Macro: 0.2857, Accuracy: 0.3333\n","Epoch 52, Train Loss: 1.2666, Val Loss: 1.7670, F1 Micro: 0.3229, F1 Macro: 0.2907, Accuracy: 0.3229\n","Epoch 53, Train Loss: 1.2509, Val Loss: 1.6798, F1 Micro: 0.4062, F1 Macro: 0.3660, Accuracy: 0.4062\n","Epoch 54, Train Loss: 1.2241, Val Loss: 2.4883, F1 Micro: 0.3333, F1 Macro: 0.3055, Accuracy: 0.3333\n","Epoch 55, Train Loss: 1.2195, Val Loss: 2.0539, F1 Micro: 0.3854, F1 Macro: 0.3417, Accuracy: 0.3854\n","Epoch 56, Train Loss: 1.2255, Val Loss: 1.8152, F1 Micro: 0.3646, F1 Macro: 0.3407, Accuracy: 0.3646\n","Epoch 57, Train Loss: 1.2386, Val Loss: 1.7410, F1 Micro: 0.3854, F1 Macro: 0.3382, Accuracy: 0.3854\n","Epoch 58, Train Loss: 1.2059, Val Loss: 1.7651, F1 Micro: 0.3542, F1 Macro: 0.3271, Accuracy: 0.3542\n","Epoch 59, Train Loss: 1.2180, Val Loss: 2.0674, F1 Micro: 0.3125, F1 Macro: 0.2601, Accuracy: 0.3125\n","Epoch 60, Train Loss: 1.1978, Val Loss: 2.5129, F1 Micro: 0.3125, F1 Macro: 0.2912, Accuracy: 0.3125\n","Epoch 61, Train Loss: 1.2763, Val Loss: 1.7690, F1 Micro: 0.3333, F1 Macro: 0.3105, Accuracy: 0.3333\n","Epoch 62, Train Loss: 1.1677, Val Loss: 1.9692, F1 Micro: 0.3333, F1 Macro: 0.3247, Accuracy: 0.3333\n","Epoch 63, Train Loss: 1.1744, Val Loss: 1.6835, F1 Micro: 0.4062, F1 Macro: 0.3885, Accuracy: 0.4062\n","Epoch 64, Train Loss: 1.1910, Val Loss: 2.0415, F1 Micro: 0.3229, F1 Macro: 0.2636, Accuracy: 0.3229\n","Epoch 65, Train Loss: 1.1681, Val Loss: 2.0418, F1 Micro: 0.3854, F1 Macro: 0.3756, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.1643, Val Loss: 2.3478, F1 Micro: 0.3646, F1 Macro: 0.3313, Accuracy: 0.3646\n","Epoch 67, Train Loss: 1.1158, Val Loss: 2.8623, F1 Micro: 0.2812, F1 Macro: 0.2309, Accuracy: 0.2812\n","Epoch 68, Train Loss: 1.1277, Val Loss: 2.2748, F1 Micro: 0.3646, F1 Macro: 0.3579, Accuracy: 0.3646\n","Epoch 69, Train Loss: 1.1143, Val Loss: 2.1484, F1 Micro: 0.3021, F1 Macro: 0.2519, Accuracy: 0.3021\n","Epoch 70, Train Loss: 1.1032, Val Loss: 1.7962, F1 Micro: 0.3542, F1 Macro: 0.3097, Accuracy: 0.3542\n","Epoch 71, Train Loss: 1.1185, Val Loss: 1.8436, F1 Micro: 0.4271, F1 Macro: 0.4188, Accuracy: 0.4271\n","Epoch 72, Train Loss: 1.0822, Val Loss: 1.8414, F1 Micro: 0.3958, F1 Macro: 0.3731, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.1128, Val Loss: 1.7847, F1 Micro: 0.3958, F1 Macro: 0.3783, Accuracy: 0.3958\n","Epoch 74, Train Loss: 1.1280, Val Loss: 1.7849, F1 Micro: 0.4479, F1 Macro: 0.4169, Accuracy: 0.4479\n","Epoch 75, Train Loss: 1.1005, Val Loss: 1.9615, F1 Micro: 0.3333, F1 Macro: 0.2850, Accuracy: 0.3333\n","Epoch 76, Train Loss: 1.0811, Val Loss: 1.6180, F1 Micro: 0.4062, F1 Macro: 0.3762, Accuracy: 0.4062\n","Epoch 77, Train Loss: 1.0553, Val Loss: 2.3087, F1 Micro: 0.3438, F1 Macro: 0.3176, Accuracy: 0.3438\n","Epoch 78, Train Loss: 1.0578, Val Loss: 2.8287, F1 Micro: 0.2812, F1 Macro: 0.2485, Accuracy: 0.2812\n","Epoch 79, Train Loss: 1.0848, Val Loss: 2.2916, F1 Micro: 0.3229, F1 Macro: 0.2928, Accuracy: 0.3229\n","Epoch 80, Train Loss: 1.1080, Val Loss: 1.8132, F1 Micro: 0.3125, F1 Macro: 0.2684, Accuracy: 0.3125\n","Epoch 81, Train Loss: 1.1033, Val Loss: 1.7708, F1 Micro: 0.3958, F1 Macro: 0.3691, Accuracy: 0.3958\n","Epoch 82, Train Loss: 1.0491, Val Loss: 1.7253, F1 Micro: 0.4062, F1 Macro: 0.3670, Accuracy: 0.4062\n","Epoch 83, Train Loss: 1.0393, Val Loss: 1.8133, F1 Micro: 0.4167, F1 Macro: 0.4098, Accuracy: 0.4167\n","Epoch 84, Train Loss: 1.0608, Val Loss: 1.8181, F1 Micro: 0.4062, F1 Macro: 0.3910, Accuracy: 0.4062\n","Epoch 85, Train Loss: 1.0614, Val Loss: 2.1053, F1 Micro: 0.3542, F1 Macro: 0.3168, Accuracy: 0.3542\n","Epoch 86, Train Loss: 1.0371, Val Loss: 2.1297, F1 Micro: 0.3542, F1 Macro: 0.3122, Accuracy: 0.3542\n","Epoch 87, Train Loss: 1.0346, Val Loss: 1.6602, F1 Micro: 0.4688, F1 Macro: 0.4428, Accuracy: 0.4688\n","Epoch 88, Train Loss: 1.0076, Val Loss: 1.7380, F1 Micro: 0.3958, F1 Macro: 0.3742, Accuracy: 0.3958\n","Epoch 89, Train Loss: 1.0198, Val Loss: 1.7986, F1 Micro: 0.3854, F1 Macro: 0.3586, Accuracy: 0.3854\n","Epoch 90, Train Loss: 0.9992, Val Loss: 1.7297, F1 Micro: 0.4167, F1 Macro: 0.3723, Accuracy: 0.4167\n","Epoch 91, Train Loss: 0.9159, Val Loss: 1.9311, F1 Micro: 0.4896, F1 Macro: 0.4657, Accuracy: 0.4896\n","Epoch 92, Train Loss: 1.0048, Val Loss: 1.6814, F1 Micro: 0.4479, F1 Macro: 0.4441, Accuracy: 0.4479\n","Epoch 93, Train Loss: 0.9867, Val Loss: 2.5242, F1 Micro: 0.3229, F1 Macro: 0.3194, Accuracy: 0.3229\n","Epoch 94, Train Loss: 0.9834, Val Loss: 1.8174, F1 Micro: 0.3958, F1 Macro: 0.3614, Accuracy: 0.3958\n","Epoch 95, Train Loss: 0.9661, Val Loss: 1.6994, F1 Micro: 0.4271, F1 Macro: 0.4082, Accuracy: 0.4271\n","Epoch 96, Train Loss: 0.9671, Val Loss: 1.7430, F1 Micro: 0.4062, F1 Macro: 0.3514, Accuracy: 0.4062\n","Epoch 97, Train Loss: 0.9207, Val Loss: 2.0083, F1 Micro: 0.3750, F1 Macro: 0.3776, Accuracy: 0.3750\n","Epoch 98, Train Loss: 0.9127, Val Loss: 1.7197, F1 Micro: 0.4062, F1 Macro: 0.3647, Accuracy: 0.4062\n","Epoch 99, Train Loss: 0.9325, Val Loss: 1.6144, F1 Micro: 0.4479, F1 Macro: 0.4123, Accuracy: 0.4479\n","Epoch 100, Train Loss: 0.8979, Val Loss: 1.7024, F1 Micro: 0.4688, F1 Macro: 0.4394, Accuracy: 0.4688\n","Epoch 101, Train Loss: 0.9959, Val Loss: 1.5641, F1 Micro: 0.4271, F1 Macro: 0.4078, Accuracy: 0.4271\n","Epoch 102, Train Loss: 0.9708, Val Loss: 1.7288, F1 Micro: 0.4271, F1 Macro: 0.4167, Accuracy: 0.4271\n","Epoch 103, Train Loss: 0.9060, Val Loss: 1.6056, F1 Micro: 0.4792, F1 Macro: 0.4457, Accuracy: 0.4792\n","Epoch 104, Train Loss: 0.8991, Val Loss: 1.6892, F1 Micro: 0.4792, F1 Macro: 0.4466, Accuracy: 0.4792\n","Epoch 105, Train Loss: 0.9137, Val Loss: 2.2221, F1 Micro: 0.4583, F1 Macro: 0.4258, Accuracy: 0.4583\n","Epoch 106, Train Loss: 0.9426, Val Loss: 2.1125, F1 Micro: 0.4167, F1 Macro: 0.3820, Accuracy: 0.4167\n","Epoch 107, Train Loss: 0.8648, Val Loss: 3.1429, F1 Micro: 0.3438, F1 Macro: 0.2895, Accuracy: 0.3438\n","Epoch 108, Train Loss: 0.9532, Val Loss: 1.7732, F1 Micro: 0.4583, F1 Macro: 0.3940, Accuracy: 0.4583\n","Epoch 109, Train Loss: 0.8761, Val Loss: 2.5472, F1 Micro: 0.4271, F1 Macro: 0.3261, Accuracy: 0.4271\n","Epoch 110, Train Loss: 0.8439, Val Loss: 1.6496, F1 Micro: 0.4896, F1 Macro: 0.4634, Accuracy: 0.4896\n","Epoch 111, Train Loss: 0.7988, Val Loss: 1.5616, F1 Micro: 0.5312, F1 Macro: 0.4962, Accuracy: 0.5312\n","Epoch 112, Train Loss: 0.8175, Val Loss: 1.7711, F1 Micro: 0.4271, F1 Macro: 0.3767, Accuracy: 0.4271\n","Epoch 113, Train Loss: 0.8679, Val Loss: 1.5968, F1 Micro: 0.5000, F1 Macro: 0.4540, Accuracy: 0.5000\n","Epoch 114, Train Loss: 0.8588, Val Loss: 2.2737, F1 Micro: 0.3542, F1 Macro: 0.2673, Accuracy: 0.3542\n","Epoch 115, Train Loss: 0.8374, Val Loss: 1.5947, F1 Micro: 0.4792, F1 Macro: 0.4482, Accuracy: 0.4792\n","Epoch 116, Train Loss: 0.8096, Val Loss: 1.6790, F1 Micro: 0.5000, F1 Macro: 0.4824, Accuracy: 0.5000\n","Epoch 117, Train Loss: 0.7969, Val Loss: 3.1259, F1 Micro: 0.3021, F1 Macro: 0.2663, Accuracy: 0.3021\n","Epoch 118, Train Loss: 0.8024, Val Loss: 1.7451, F1 Micro: 0.3646, F1 Macro: 0.2804, Accuracy: 0.3646\n","Epoch 119, Train Loss: 0.7985, Val Loss: 1.7366, F1 Micro: 0.4896, F1 Macro: 0.4395, Accuracy: 0.4896\n","Epoch 120, Train Loss: 0.8144, Val Loss: 1.5673, F1 Micro: 0.4479, F1 Macro: 0.4370, Accuracy: 0.4479\n","Epoch 121, Train Loss: 0.7903, Val Loss: 1.9852, F1 Micro: 0.4583, F1 Macro: 0.4477, Accuracy: 0.4583\n","Epoch 122, Train Loss: 0.7949, Val Loss: 2.0685, F1 Micro: 0.5104, F1 Macro: 0.4895, Accuracy: 0.5104\n","Epoch 123, Train Loss: 0.7575, Val Loss: 2.0655, F1 Micro: 0.4479, F1 Macro: 0.4326, Accuracy: 0.4479\n","Epoch 124, Train Loss: 0.7742, Val Loss: 1.7454, F1 Micro: 0.4792, F1 Macro: 0.4473, Accuracy: 0.4792\n","Epoch 125, Train Loss: 0.7207, Val Loss: 2.3355, F1 Micro: 0.3854, F1 Macro: 0.3670, Accuracy: 0.3854\n","Epoch 126, Train Loss: 0.8122, Val Loss: 1.9719, F1 Micro: 0.4688, F1 Macro: 0.4265, Accuracy: 0.4688\n","Epoch 127, Train Loss: 0.7877, Val Loss: 1.8282, F1 Micro: 0.5104, F1 Macro: 0.4710, Accuracy: 0.5104\n","Epoch 128, Train Loss: 0.7571, Val Loss: 1.8776, F1 Micro: 0.4896, F1 Macro: 0.4812, Accuracy: 0.4896\n","Epoch 129, Train Loss: 0.7053, Val Loss: 1.9818, F1 Micro: 0.4375, F1 Macro: 0.3922, Accuracy: 0.4375\n","Epoch 130, Train Loss: 0.7932, Val Loss: 1.9946, F1 Micro: 0.4271, F1 Macro: 0.3670, Accuracy: 0.4271\n","Epoch 131, Train Loss: 0.7216, Val Loss: 2.0481, F1 Micro: 0.3854, F1 Macro: 0.3529, Accuracy: 0.3854\n","Epoch 132, Train Loss: 0.7156, Val Loss: 1.8955, F1 Micro: 0.4896, F1 Macro: 0.4626, Accuracy: 0.4896\n","Epoch 133, Train Loss: 0.7217, Val Loss: 2.0989, F1 Micro: 0.3958, F1 Macro: 0.3809, Accuracy: 0.3958\n","Epoch 134, Train Loss: 0.7524, Val Loss: 2.9821, F1 Micro: 0.3229, F1 Macro: 0.2224, Accuracy: 0.3229\n","Epoch 135, Train Loss: 0.7148, Val Loss: 1.8886, F1 Micro: 0.4583, F1 Macro: 0.4321, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.6944, Val Loss: 2.2783, F1 Micro: 0.3229, F1 Macro: 0.2947, Accuracy: 0.3229\n","Epoch 137, Train Loss: 0.7164, Val Loss: 1.7295, F1 Micro: 0.5312, F1 Macro: 0.4891, Accuracy: 0.5312\n","Epoch 138, Train Loss: 0.6708, Val Loss: 1.9183, F1 Micro: 0.4583, F1 Macro: 0.4251, Accuracy: 0.4583\n","Epoch 139, Train Loss: 0.6724, Val Loss: 1.9010, F1 Micro: 0.4792, F1 Macro: 0.4859, Accuracy: 0.4792\n","Epoch 140, Train Loss: 0.6746, Val Loss: 1.6998, F1 Micro: 0.5104, F1 Macro: 0.5060, Accuracy: 0.5104\n","Epoch 141, Train Loss: 0.6589, Val Loss: 1.8128, F1 Micro: 0.5000, F1 Macro: 0.4906, Accuracy: 0.5000\n","Epoch 142, Train Loss: 0.6959, Val Loss: 2.2268, F1 Micro: 0.3958, F1 Macro: 0.3591, Accuracy: 0.3958\n","Epoch 143, Train Loss: 0.6999, Val Loss: 1.8631, F1 Micro: 0.4792, F1 Macro: 0.4651, Accuracy: 0.4792\n","Epoch 144, Train Loss: 0.7035, Val Loss: 1.5722, F1 Micro: 0.5000, F1 Macro: 0.4774, Accuracy: 0.5000\n","Epoch 145, Train Loss: 0.6528, Val Loss: 1.6378, F1 Micro: 0.5521, F1 Macro: 0.5359, Accuracy: 0.5521\n","Epoch 146, Train Loss: 0.6598, Val Loss: 2.3757, F1 Micro: 0.4375, F1 Macro: 0.3938, Accuracy: 0.4375\n","Epoch 147, Train Loss: 0.6331, Val Loss: 1.8773, F1 Micro: 0.4688, F1 Macro: 0.4479, Accuracy: 0.4688\n","Epoch 148, Train Loss: 0.6555, Val Loss: 1.7034, F1 Micro: 0.5208, F1 Macro: 0.4959, Accuracy: 0.5208\n","Epoch 149, Train Loss: 0.5967, Val Loss: 2.4483, F1 Micro: 0.4792, F1 Macro: 0.4592, Accuracy: 0.4792\n","Epoch 150, Train Loss: 0.6787, Val Loss: 1.7118, F1 Micro: 0.5000, F1 Macro: 0.4961, Accuracy: 0.5000\n","Epoch 151, Train Loss: 0.5819, Val Loss: 1.7388, F1 Micro: 0.4583, F1 Macro: 0.4463, Accuracy: 0.4583\n","Epoch 152, Train Loss: 0.5711, Val Loss: 2.1807, F1 Micro: 0.3854, F1 Macro: 0.3040, Accuracy: 0.3854\n","Epoch 153, Train Loss: 0.6172, Val Loss: 1.6404, F1 Micro: 0.5312, F1 Macro: 0.5170, Accuracy: 0.5312\n","Epoch 154, Train Loss: 0.6115, Val Loss: 1.6277, F1 Micro: 0.5417, F1 Macro: 0.5257, Accuracy: 0.5417\n","Epoch 155, Train Loss: 0.5869, Val Loss: 2.3965, F1 Micro: 0.3854, F1 Macro: 0.3136, Accuracy: 0.3854\n","Epoch 156, Train Loss: 0.6610, Val Loss: 2.3463, F1 Micro: 0.4792, F1 Macro: 0.4503, Accuracy: 0.4792\n","Epoch 157, Train Loss: 0.6225, Val Loss: 1.7148, F1 Micro: 0.5417, F1 Macro: 0.5242, Accuracy: 0.5417\n","Epoch 158, Train Loss: 0.5819, Val Loss: 1.9987, F1 Micro: 0.4167, F1 Macro: 0.3791, Accuracy: 0.4167\n","Epoch 159, Train Loss: 0.5713, Val Loss: 1.8496, F1 Micro: 0.4896, F1 Macro: 0.4284, Accuracy: 0.4896\n","Epoch 160, Train Loss: 0.5525, Val Loss: 2.0562, F1 Micro: 0.4375, F1 Macro: 0.4152, Accuracy: 0.4375\n","Epoch 161, Train Loss: 0.5297, Val Loss: 1.5457, F1 Micro: 0.5729, F1 Macro: 0.5456, Accuracy: 0.5729\n","Epoch 162, Train Loss: 0.5539, Val Loss: 1.9607, F1 Micro: 0.4688, F1 Macro: 0.4435, Accuracy: 0.4688\n","Epoch 163, Train Loss: 0.5185, Val Loss: 1.7463, F1 Micro: 0.5417, F1 Macro: 0.5449, Accuracy: 0.5417\n","Epoch 164, Train Loss: 0.5670, Val Loss: 1.7376, F1 Micro: 0.5104, F1 Macro: 0.5173, Accuracy: 0.5104\n","Epoch 165, Train Loss: 0.5328, Val Loss: 1.8817, F1 Micro: 0.5208, F1 Macro: 0.4962, Accuracy: 0.5208\n","Epoch 166, Train Loss: 0.5964, Val Loss: 2.3566, F1 Micro: 0.4583, F1 Macro: 0.4114, Accuracy: 0.4583\n","Epoch 167, Train Loss: 0.5518, Val Loss: 1.8242, F1 Micro: 0.5104, F1 Macro: 0.4847, Accuracy: 0.5104\n","Epoch 168, Train Loss: 0.5283, Val Loss: 1.9657, F1 Micro: 0.4896, F1 Macro: 0.4580, Accuracy: 0.4896\n","Epoch 169, Train Loss: 0.4933, Val Loss: 1.7660, F1 Micro: 0.4792, F1 Macro: 0.4566, Accuracy: 0.4792\n","Epoch 170, Train Loss: 0.5407, Val Loss: 2.1770, F1 Micro: 0.4583, F1 Macro: 0.4016, Accuracy: 0.4583\n","Epoch 171, Train Loss: 0.5193, Val Loss: 1.7636, F1 Micro: 0.4896, F1 Macro: 0.4486, Accuracy: 0.4896\n","Epoch 172, Train Loss: 0.5751, Val Loss: 2.2534, F1 Micro: 0.3542, F1 Macro: 0.3326, Accuracy: 0.3542\n","Epoch 173, Train Loss: 0.5614, Val Loss: 1.7651, F1 Micro: 0.5521, F1 Macro: 0.5324, Accuracy: 0.5521\n","Epoch 174, Train Loss: 0.5462, Val Loss: 1.6747, F1 Micro: 0.5417, F1 Macro: 0.5047, Accuracy: 0.5417\n","Epoch 175, Train Loss: 0.5092, Val Loss: 1.9317, F1 Micro: 0.4688, F1 Macro: 0.4134, Accuracy: 0.4688\n","Epoch 176, Train Loss: 0.5241, Val Loss: 2.1004, F1 Micro: 0.4792, F1 Macro: 0.4614, Accuracy: 0.4792\n","Epoch 177, Train Loss: 0.5500, Val Loss: 2.1774, F1 Micro: 0.4479, F1 Macro: 0.4213, Accuracy: 0.4479\n","Epoch 178, Train Loss: 0.5466, Val Loss: 2.2375, F1 Micro: 0.4688, F1 Macro: 0.4402, Accuracy: 0.4688\n","Epoch 179, Train Loss: 0.5442, Val Loss: 1.9069, F1 Micro: 0.4792, F1 Macro: 0.4762, Accuracy: 0.4792\n","Epoch 180, Train Loss: 0.5159, Val Loss: 1.8268, F1 Micro: 0.5625, F1 Macro: 0.5241, Accuracy: 0.5625\n","Epoch 181, Train Loss: 0.4979, Val Loss: 2.1127, F1 Micro: 0.5000, F1 Macro: 0.4813, Accuracy: 0.5000\n","Epoch 182, Train Loss: 0.4814, Val Loss: 2.7712, F1 Micro: 0.3750, F1 Macro: 0.3564, Accuracy: 0.3750\n","Epoch 183, Train Loss: 0.5188, Val Loss: 2.1576, F1 Micro: 0.5104, F1 Macro: 0.4864, Accuracy: 0.5104\n","Epoch 184, Train Loss: 0.4714, Val Loss: 1.9819, F1 Micro: 0.5208, F1 Macro: 0.5096, Accuracy: 0.5208\n","Epoch 185, Train Loss: 0.4852, Val Loss: 2.4793, F1 Micro: 0.4792, F1 Macro: 0.4482, Accuracy: 0.4792\n","Epoch 186, Train Loss: 0.4238, Val Loss: 1.6630, F1 Micro: 0.5312, F1 Macro: 0.5220, Accuracy: 0.5312\n","Epoch 187, Train Loss: 0.4408, Val Loss: 1.7938, F1 Micro: 0.5729, F1 Macro: 0.5498, Accuracy: 0.5729\n","Epoch 188, Train Loss: 0.5107, Val Loss: 2.0768, F1 Micro: 0.4479, F1 Macro: 0.4290, Accuracy: 0.4479\n","Epoch 189, Train Loss: 0.5328, Val Loss: 3.2494, F1 Micro: 0.3542, F1 Macro: 0.3276, Accuracy: 0.3542\n","Epoch 190, Train Loss: 0.6027, Val Loss: 2.2525, F1 Micro: 0.4167, F1 Macro: 0.3964, Accuracy: 0.4167\n","Epoch 191, Train Loss: 0.5468, Val Loss: 1.9438, F1 Micro: 0.4583, F1 Macro: 0.4609, Accuracy: 0.4583\n","Epoch 192, Train Loss: 0.4780, Val Loss: 2.1167, F1 Micro: 0.5000, F1 Macro: 0.4738, Accuracy: 0.5000\n","Epoch 193, Train Loss: 0.4471, Val Loss: 2.0999, F1 Micro: 0.5000, F1 Macro: 0.4925, Accuracy: 0.5000\n","Epoch 194, Train Loss: 0.4557, Val Loss: 2.4363, F1 Micro: 0.4375, F1 Macro: 0.3698, Accuracy: 0.4375\n","Epoch 195, Train Loss: 0.4465, Val Loss: 1.8154, F1 Micro: 0.4896, F1 Macro: 0.4774, Accuracy: 0.4896\n","Epoch 196, Train Loss: 0.4312, Val Loss: 1.8630, F1 Micro: 0.5208, F1 Macro: 0.5024, Accuracy: 0.5208\n","Epoch 197, Train Loss: 0.4483, Val Loss: 2.0189, F1 Micro: 0.4792, F1 Macro: 0.4651, Accuracy: 0.4792\n","Epoch 198, Train Loss: 0.4348, Val Loss: 2.5159, F1 Micro: 0.4688, F1 Macro: 0.4327, Accuracy: 0.4688\n","Epoch 199, Train Loss: 0.4725, Val Loss: 2.6191, F1 Micro: 0.5000, F1 Macro: 0.4813, Accuracy: 0.5000\n","Epoch 200, Train Loss: 0.5109, Val Loss: 2.0327, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8023, Val Loss: 1.8004, F1 Micro: 0.1458, F1 Macro: 0.0646, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.7898, Val Loss: 1.8103, F1 Micro: 0.1250, F1 Macro: 0.0400, Accuracy: 0.1250\n","Epoch 3, Train Loss: 1.7854, Val Loss: 1.7826, F1 Micro: 0.1875, F1 Macro: 0.0864, Accuracy: 0.1875\n","Epoch 4, Train Loss: 1.7638, Val Loss: 1.7706, F1 Micro: 0.2396, F1 Macro: 0.1455, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.7466, Val Loss: 1.7973, F1 Micro: 0.2188, F1 Macro: 0.1672, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.7293, Val Loss: 1.7572, F1 Micro: 0.2188, F1 Macro: 0.1521, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.7264, Val Loss: 1.7623, F1 Micro: 0.2292, F1 Macro: 0.1355, Accuracy: 0.2292\n","Epoch 8, Train Loss: 1.7022, Val Loss: 1.6946, F1 Micro: 0.3021, F1 Macro: 0.2636, Accuracy: 0.3021\n","Epoch 9, Train Loss: 1.6942, Val Loss: 1.7640, F1 Micro: 0.2292, F1 Macro: 0.1725, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.6793, Val Loss: 1.9247, F1 Micro: 0.2292, F1 Macro: 0.1569, Accuracy: 0.2292\n","Epoch 11, Train Loss: 1.6389, Val Loss: 2.0999, F1 Micro: 0.2083, F1 Macro: 0.1350, Accuracy: 0.2083\n","Epoch 12, Train Loss: 1.6506, Val Loss: 1.7865, F1 Micro: 0.2188, F1 Macro: 0.1623, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.6259, Val Loss: 1.7082, F1 Micro: 0.2396, F1 Macro: 0.2196, Accuracy: 0.2396\n","Epoch 14, Train Loss: 1.6135, Val Loss: 1.6335, F1 Micro: 0.3333, F1 Macro: 0.3295, Accuracy: 0.3333\n","Epoch 15, Train Loss: 1.6200, Val Loss: 1.6910, F1 Micro: 0.2604, F1 Macro: 0.2340, Accuracy: 0.2604\n","Epoch 16, Train Loss: 1.5949, Val Loss: 1.8187, F1 Micro: 0.3021, F1 Macro: 0.2733, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.5941, Val Loss: 1.6925, F1 Micro: 0.2812, F1 Macro: 0.2267, Accuracy: 0.2812\n","Epoch 18, Train Loss: 1.5726, Val Loss: 1.6805, F1 Micro: 0.2708, F1 Macro: 0.2392, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.5807, Val Loss: 1.6690, F1 Micro: 0.2708, F1 Macro: 0.1916, Accuracy: 0.2708\n","Epoch 20, Train Loss: 1.5563, Val Loss: 1.7001, F1 Micro: 0.2812, F1 Macro: 0.2618, Accuracy: 0.2812\n","Epoch 21, Train Loss: 1.5195, Val Loss: 1.6458, F1 Micro: 0.2604, F1 Macro: 0.2515, Accuracy: 0.2604\n","Epoch 22, Train Loss: 1.5211, Val Loss: 1.8868, F1 Micro: 0.1771, F1 Macro: 0.1115, Accuracy: 0.1771\n","Epoch 23, Train Loss: 1.5099, Val Loss: 1.7295, F1 Micro: 0.2188, F1 Macro: 0.2142, Accuracy: 0.2188\n","Epoch 24, Train Loss: 1.5008, Val Loss: 1.7991, F1 Micro: 0.3333, F1 Macro: 0.3112, Accuracy: 0.3333\n","Epoch 25, Train Loss: 1.4824, Val Loss: 1.9541, F1 Micro: 0.2604, F1 Macro: 0.2412, Accuracy: 0.2604\n","Epoch 26, Train Loss: 1.4799, Val Loss: 1.6766, F1 Micro: 0.3125, F1 Macro: 0.2946, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.4632, Val Loss: 1.6700, F1 Micro: 0.2917, F1 Macro: 0.2551, Accuracy: 0.2917\n","Epoch 28, Train Loss: 1.4532, Val Loss: 1.7034, F1 Micro: 0.2604, F1 Macro: 0.2206, Accuracy: 0.2604\n","Epoch 29, Train Loss: 1.4469, Val Loss: 1.7371, F1 Micro: 0.2917, F1 Macro: 0.2547, Accuracy: 0.2917\n","Epoch 30, Train Loss: 1.4472, Val Loss: 1.8286, F1 Micro: 0.3438, F1 Macro: 0.3214, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.4360, Val Loss: 1.7664, F1 Micro: 0.3021, F1 Macro: 0.2808, Accuracy: 0.3021\n","Epoch 32, Train Loss: 1.4452, Val Loss: 1.9386, F1 Micro: 0.2604, F1 Macro: 0.2018, Accuracy: 0.2604\n","Epoch 33, Train Loss: 1.4126, Val Loss: 1.8869, F1 Micro: 0.2500, F1 Macro: 0.1962, Accuracy: 0.2500\n","Epoch 34, Train Loss: 1.4097, Val Loss: 1.7018, F1 Micro: 0.2812, F1 Macro: 0.2701, Accuracy: 0.2812\n","Epoch 35, Train Loss: 1.3639, Val Loss: 1.9637, F1 Micro: 0.2708, F1 Macro: 0.2629, Accuracy: 0.2708\n","Epoch 36, Train Loss: 1.3806, Val Loss: 1.7777, F1 Micro: 0.2604, F1 Macro: 0.2305, Accuracy: 0.2604\n","Epoch 37, Train Loss: 1.3844, Val Loss: 1.7418, F1 Micro: 0.3333, F1 Macro: 0.3042, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.3928, Val Loss: 1.8172, F1 Micro: 0.3229, F1 Macro: 0.3088, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.3812, Val Loss: 3.2009, F1 Micro: 0.1562, F1 Macro: 0.0911, Accuracy: 0.1562\n","Epoch 40, Train Loss: 1.3592, Val Loss: 1.7435, F1 Micro: 0.3021, F1 Macro: 0.2674, Accuracy: 0.3021\n","Epoch 41, Train Loss: 1.3264, Val Loss: 1.6800, F1 Micro: 0.3333, F1 Macro: 0.3111, Accuracy: 0.3333\n","Epoch 42, Train Loss: 1.3054, Val Loss: 2.0797, F1 Micro: 0.2917, F1 Macro: 0.2742, Accuracy: 0.2917\n","Epoch 43, Train Loss: 1.3531, Val Loss: 2.0166, F1 Micro: 0.2500, F1 Macro: 0.2182, Accuracy: 0.2500\n","Epoch 44, Train Loss: 1.3272, Val Loss: 1.7453, F1 Micro: 0.3438, F1 Macro: 0.3133, Accuracy: 0.3438\n","Epoch 45, Train Loss: 1.3107, Val Loss: 3.4956, F1 Micro: 0.2604, F1 Macro: 0.1975, Accuracy: 0.2604\n","Epoch 46, Train Loss: 1.2783, Val Loss: 1.6919, F1 Micro: 0.3542, F1 Macro: 0.3194, Accuracy: 0.3542\n","Epoch 47, Train Loss: 1.2737, Val Loss: 1.5849, F1 Micro: 0.3750, F1 Macro: 0.3564, Accuracy: 0.3750\n","Epoch 48, Train Loss: 1.2513, Val Loss: 1.9534, F1 Micro: 0.3021, F1 Macro: 0.2634, Accuracy: 0.3021\n","Epoch 49, Train Loss: 1.2294, Val Loss: 1.6891, F1 Micro: 0.4375, F1 Macro: 0.4078, Accuracy: 0.4375\n","Epoch 50, Train Loss: 1.2136, Val Loss: 1.9201, F1 Micro: 0.3229, F1 Macro: 0.2862, Accuracy: 0.3229\n","Epoch 51, Train Loss: 1.2870, Val Loss: 1.7584, F1 Micro: 0.4062, F1 Macro: 0.3707, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.2222, Val Loss: 1.6648, F1 Micro: 0.4479, F1 Macro: 0.4496, Accuracy: 0.4479\n","Epoch 53, Train Loss: 1.2396, Val Loss: 2.1716, F1 Micro: 0.3125, F1 Macro: 0.2840, Accuracy: 0.3125\n","Epoch 54, Train Loss: 1.2141, Val Loss: 2.1702, F1 Micro: 0.3542, F1 Macro: 0.3208, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.1752, Val Loss: 2.1061, F1 Micro: 0.3125, F1 Macro: 0.2852, Accuracy: 0.3125\n","Epoch 56, Train Loss: 1.2068, Val Loss: 2.3656, F1 Micro: 0.3229, F1 Macro: 0.2912, Accuracy: 0.3229\n","Epoch 57, Train Loss: 1.2293, Val Loss: 1.9345, F1 Micro: 0.3854, F1 Macro: 0.3681, Accuracy: 0.3854\n","Epoch 58, Train Loss: 1.1964, Val Loss: 1.7459, F1 Micro: 0.4479, F1 Macro: 0.4329, Accuracy: 0.4479\n","Epoch 59, Train Loss: 1.1848, Val Loss: 2.4478, F1 Micro: 0.3438, F1 Macro: 0.3330, Accuracy: 0.3438\n","Epoch 60, Train Loss: 1.2242, Val Loss: 1.6705, F1 Micro: 0.4688, F1 Macro: 0.4533, Accuracy: 0.4688\n","Epoch 61, Train Loss: 1.1769, Val Loss: 1.8805, F1 Micro: 0.4062, F1 Macro: 0.3796, Accuracy: 0.4062\n","Epoch 62, Train Loss: 1.1335, Val Loss: 1.8676, F1 Micro: 0.4062, F1 Macro: 0.3909, Accuracy: 0.4062\n","Epoch 63, Train Loss: 1.1815, Val Loss: 1.8574, F1 Micro: 0.4479, F1 Macro: 0.4435, Accuracy: 0.4479\n","Epoch 64, Train Loss: 1.1383, Val Loss: 3.1228, F1 Micro: 0.3333, F1 Macro: 0.2577, Accuracy: 0.3333\n","Epoch 65, Train Loss: 1.1528, Val Loss: 1.7249, F1 Micro: 0.4271, F1 Macro: 0.3949, Accuracy: 0.4271\n","Epoch 66, Train Loss: 1.1388, Val Loss: 1.7984, F1 Micro: 0.4583, F1 Macro: 0.4494, Accuracy: 0.4583\n","Epoch 67, Train Loss: 1.1289, Val Loss: 2.3387, F1 Micro: 0.3229, F1 Macro: 0.2735, Accuracy: 0.3229\n","Epoch 68, Train Loss: 1.1172, Val Loss: 2.8423, F1 Micro: 0.2708, F1 Macro: 0.2511, Accuracy: 0.2708\n","Epoch 69, Train Loss: 1.0870, Val Loss: 2.7404, F1 Micro: 0.2604, F1 Macro: 0.2322, Accuracy: 0.2604\n","Epoch 70, Train Loss: 1.1372, Val Loss: 2.1901, F1 Micro: 0.3750, F1 Macro: 0.3641, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.1283, Val Loss: 2.2989, F1 Micro: 0.2812, F1 Macro: 0.1928, Accuracy: 0.2812\n","Epoch 72, Train Loss: 1.0643, Val Loss: 2.4603, F1 Micro: 0.4062, F1 Macro: 0.3892, Accuracy: 0.4062\n","Epoch 73, Train Loss: 1.0654, Val Loss: 2.1422, F1 Micro: 0.3854, F1 Macro: 0.3592, Accuracy: 0.3854\n","Epoch 74, Train Loss: 1.0113, Val Loss: 1.8891, F1 Micro: 0.4896, F1 Macro: 0.4892, Accuracy: 0.4896\n","Epoch 75, Train Loss: 1.0143, Val Loss: 2.0725, F1 Micro: 0.4688, F1 Macro: 0.4767, Accuracy: 0.4688\n","Epoch 76, Train Loss: 1.0074, Val Loss: 1.7974, F1 Micro: 0.4479, F1 Macro: 0.4441, Accuracy: 0.4479\n","Epoch 77, Train Loss: 0.9703, Val Loss: 2.3595, F1 Micro: 0.3854, F1 Macro: 0.3200, Accuracy: 0.3854\n","Epoch 78, Train Loss: 1.0268, Val Loss: 2.0363, F1 Micro: 0.4688, F1 Macro: 0.4279, Accuracy: 0.4688\n","Epoch 79, Train Loss: 0.9583, Val Loss: 2.1326, F1 Micro: 0.4583, F1 Macro: 0.4394, Accuracy: 0.4583\n","Epoch 80, Train Loss: 0.9712, Val Loss: 2.1362, F1 Micro: 0.4479, F1 Macro: 0.4304, Accuracy: 0.4479\n","Epoch 81, Train Loss: 0.9576, Val Loss: 1.9425, F1 Micro: 0.4583, F1 Macro: 0.4509, Accuracy: 0.4583\n","Epoch 82, Train Loss: 0.9372, Val Loss: 3.0086, F1 Micro: 0.3854, F1 Macro: 0.3306, Accuracy: 0.3854\n","Epoch 83, Train Loss: 1.0066, Val Loss: 2.0982, F1 Micro: 0.4375, F1 Macro: 0.4330, Accuracy: 0.4375\n","Epoch 84, Train Loss: 0.9613, Val Loss: 1.9970, F1 Micro: 0.4375, F1 Macro: 0.3992, Accuracy: 0.4375\n","Epoch 85, Train Loss: 0.9857, Val Loss: 1.9770, F1 Micro: 0.5208, F1 Macro: 0.5260, Accuracy: 0.5208\n","Epoch 86, Train Loss: 0.9881, Val Loss: 2.2735, F1 Micro: 0.4062, F1 Macro: 0.3908, Accuracy: 0.4062\n","Epoch 87, Train Loss: 0.9941, Val Loss: 2.2383, F1 Micro: 0.3958, F1 Macro: 0.3474, Accuracy: 0.3958\n","Epoch 88, Train Loss: 0.9623, Val Loss: 1.9211, F1 Micro: 0.4167, F1 Macro: 0.4027, Accuracy: 0.4167\n","Epoch 89, Train Loss: 0.9725, Val Loss: 2.3114, F1 Micro: 0.4271, F1 Macro: 0.4025, Accuracy: 0.4271\n","Epoch 90, Train Loss: 0.9118, Val Loss: 2.2828, F1 Micro: 0.3750, F1 Macro: 0.3211, Accuracy: 0.3750\n","Epoch 91, Train Loss: 0.8468, Val Loss: 2.5290, F1 Micro: 0.4167, F1 Macro: 0.3774, Accuracy: 0.4167\n","Epoch 92, Train Loss: 0.8827, Val Loss: 2.1247, F1 Micro: 0.4375, F1 Macro: 0.4105, Accuracy: 0.4375\n","Epoch 93, Train Loss: 0.9049, Val Loss: 2.3768, F1 Micro: 0.4271, F1 Macro: 0.4072, Accuracy: 0.4271\n","Epoch 94, Train Loss: 0.9221, Val Loss: 2.4485, F1 Micro: 0.4271, F1 Macro: 0.4054, Accuracy: 0.4271\n","Epoch 95, Train Loss: 0.8451, Val Loss: 2.0483, F1 Micro: 0.4271, F1 Macro: 0.4112, Accuracy: 0.4271\n","Epoch 96, Train Loss: 0.8596, Val Loss: 2.6714, F1 Micro: 0.3438, F1 Macro: 0.3103, Accuracy: 0.3438\n","Epoch 97, Train Loss: 0.8799, Val Loss: 2.5140, F1 Micro: 0.4375, F1 Macro: 0.4141, Accuracy: 0.4375\n","Epoch 98, Train Loss: 0.9159, Val Loss: 1.9965, F1 Micro: 0.4583, F1 Macro: 0.4492, Accuracy: 0.4583\n","Epoch 99, Train Loss: 0.8249, Val Loss: 2.2931, F1 Micro: 0.3958, F1 Macro: 0.3359, Accuracy: 0.3958\n","Epoch 100, Train Loss: 0.8262, Val Loss: 2.0034, F1 Micro: 0.5000, F1 Macro: 0.4902, Accuracy: 0.5000\n","Epoch 101, Train Loss: 0.8338, Val Loss: 2.1819, F1 Micro: 0.4479, F1 Macro: 0.4168, Accuracy: 0.4479\n","Epoch 102, Train Loss: 0.8421, Val Loss: 2.1268, F1 Micro: 0.4583, F1 Macro: 0.4334, Accuracy: 0.4583\n","Epoch 103, Train Loss: 0.7912, Val Loss: 2.3289, F1 Micro: 0.4896, F1 Macro: 0.4488, Accuracy: 0.4896\n","Epoch 104, Train Loss: 0.7696, Val Loss: 2.7123, F1 Micro: 0.3958, F1 Macro: 0.3845, Accuracy: 0.3958\n","Epoch 105, Train Loss: 0.8154, Val Loss: 2.3633, F1 Micro: 0.4479, F1 Macro: 0.4166, Accuracy: 0.4479\n","Epoch 106, Train Loss: 0.7698, Val Loss: 2.2463, F1 Micro: 0.5208, F1 Macro: 0.5087, Accuracy: 0.5208\n","Epoch 107, Train Loss: 0.8258, Val Loss: 1.9935, F1 Micro: 0.4688, F1 Macro: 0.4681, Accuracy: 0.4688\n","Epoch 108, Train Loss: 0.7520, Val Loss: 2.6273, F1 Micro: 0.4688, F1 Macro: 0.4384, Accuracy: 0.4688\n","Epoch 109, Train Loss: 0.7810, Val Loss: 2.6843, F1 Micro: 0.4062, F1 Macro: 0.3851, Accuracy: 0.4062\n","Epoch 110, Train Loss: 0.8050, Val Loss: 2.3220, F1 Micro: 0.4167, F1 Macro: 0.3797, Accuracy: 0.4167\n","Epoch 111, Train Loss: 0.7302, Val Loss: 2.5912, F1 Micro: 0.3750, F1 Macro: 0.3674, Accuracy: 0.3750\n","Epoch 112, Train Loss: 0.8027, Val Loss: 2.2632, F1 Micro: 0.5312, F1 Macro: 0.5221, Accuracy: 0.5312\n","Epoch 113, Train Loss: 0.7001, Val Loss: 2.7035, F1 Micro: 0.3750, F1 Macro: 0.3482, Accuracy: 0.3750\n","Epoch 114, Train Loss: 0.7656, Val Loss: 2.3703, F1 Micro: 0.3854, F1 Macro: 0.3727, Accuracy: 0.3854\n","Epoch 115, Train Loss: 0.7387, Val Loss: 2.7036, F1 Micro: 0.3542, F1 Macro: 0.3068, Accuracy: 0.3542\n","Epoch 116, Train Loss: 0.7719, Val Loss: 2.8052, F1 Micro: 0.4062, F1 Macro: 0.3893, Accuracy: 0.4062\n","Epoch 117, Train Loss: 0.7260, Val Loss: 2.0079, F1 Micro: 0.5625, F1 Macro: 0.5561, Accuracy: 0.5625\n","Epoch 118, Train Loss: 0.7594, Val Loss: 2.4022, F1 Micro: 0.4583, F1 Macro: 0.4533, Accuracy: 0.4583\n","Epoch 119, Train Loss: 0.7938, Val Loss: 2.5465, F1 Micro: 0.4375, F1 Macro: 0.4350, Accuracy: 0.4375\n","Epoch 120, Train Loss: 0.7443, Val Loss: 2.1625, F1 Micro: 0.5000, F1 Macro: 0.4910, Accuracy: 0.5000\n","Epoch 121, Train Loss: 0.7068, Val Loss: 2.2126, F1 Micro: 0.5208, F1 Macro: 0.5062, Accuracy: 0.5208\n","Epoch 122, Train Loss: 0.6934, Val Loss: 2.1357, F1 Micro: 0.5417, F1 Macro: 0.5535, Accuracy: 0.5417\n","Epoch 123, Train Loss: 0.7482, Val Loss: 3.2051, F1 Micro: 0.3958, F1 Macro: 0.3658, Accuracy: 0.3958\n","Epoch 124, Train Loss: 0.7020, Val Loss: 2.5622, F1 Micro: 0.5104, F1 Macro: 0.4748, Accuracy: 0.5104\n","Epoch 125, Train Loss: 0.6599, Val Loss: 2.4150, F1 Micro: 0.3646, F1 Macro: 0.3125, Accuracy: 0.3646\n","Epoch 126, Train Loss: 0.7371, Val Loss: 2.4237, F1 Micro: 0.4271, F1 Macro: 0.3900, Accuracy: 0.4271\n","Epoch 127, Train Loss: 0.6752, Val Loss: 2.3869, F1 Micro: 0.5208, F1 Macro: 0.5098, Accuracy: 0.5208\n","Epoch 128, Train Loss: 0.6446, Val Loss: 2.4277, F1 Micro: 0.4583, F1 Macro: 0.4290, Accuracy: 0.4583\n","Epoch 129, Train Loss: 0.6446, Val Loss: 2.3881, F1 Micro: 0.5000, F1 Macro: 0.4826, Accuracy: 0.5000\n","Epoch 130, Train Loss: 0.7016, Val Loss: 2.7483, F1 Micro: 0.4375, F1 Macro: 0.4205, Accuracy: 0.4375\n","Epoch 131, Train Loss: 0.6967, Val Loss: 3.1547, F1 Micro: 0.4688, F1 Macro: 0.4221, Accuracy: 0.4688\n","Epoch 132, Train Loss: 0.6862, Val Loss: 2.6965, F1 Micro: 0.3958, F1 Macro: 0.4002, Accuracy: 0.3958\n","Epoch 133, Train Loss: 0.6667, Val Loss: 2.7455, F1 Micro: 0.3646, F1 Macro: 0.3703, Accuracy: 0.3646\n","Epoch 134, Train Loss: 0.6445, Val Loss: 3.1651, F1 Micro: 0.4896, F1 Macro: 0.4472, Accuracy: 0.4896\n","Epoch 135, Train Loss: 0.5961, Val Loss: 2.6308, F1 Micro: 0.4896, F1 Macro: 0.4821, Accuracy: 0.4896\n","Epoch 136, Train Loss: 0.6383, Val Loss: 2.9743, F1 Micro: 0.4375, F1 Macro: 0.4023, Accuracy: 0.4375\n","Epoch 137, Train Loss: 0.6186, Val Loss: 2.5563, F1 Micro: 0.5000, F1 Macro: 0.4724, Accuracy: 0.5000\n","Epoch 138, Train Loss: 0.6155, Val Loss: 2.4132, F1 Micro: 0.4271, F1 Macro: 0.4335, Accuracy: 0.4271\n","Epoch 139, Train Loss: 0.5457, Val Loss: 2.4824, F1 Micro: 0.5417, F1 Macro: 0.5174, Accuracy: 0.5417\n","Epoch 140, Train Loss: 0.6554, Val Loss: 2.8235, F1 Micro: 0.4688, F1 Macro: 0.4392, Accuracy: 0.4688\n","Epoch 141, Train Loss: 0.6016, Val Loss: 2.5787, F1 Micro: 0.5104, F1 Macro: 0.4910, Accuracy: 0.5104\n","Epoch 142, Train Loss: 0.5490, Val Loss: 3.0310, F1 Micro: 0.4062, F1 Macro: 0.3486, Accuracy: 0.4062\n","Epoch 143, Train Loss: 0.6300, Val Loss: 2.8563, F1 Micro: 0.4375, F1 Macro: 0.4468, Accuracy: 0.4375\n","Epoch 144, Train Loss: 0.5871, Val Loss: 3.1421, F1 Micro: 0.4375, F1 Macro: 0.4354, Accuracy: 0.4375\n","Epoch 145, Train Loss: 0.6109, Val Loss: 3.0407, F1 Micro: 0.4479, F1 Macro: 0.4416, Accuracy: 0.4479\n","Epoch 146, Train Loss: 0.6016, Val Loss: 2.4534, F1 Micro: 0.5104, F1 Macro: 0.5041, Accuracy: 0.5104\n","Epoch 147, Train Loss: 0.5967, Val Loss: 3.3008, F1 Micro: 0.4792, F1 Macro: 0.4410, Accuracy: 0.4792\n","Epoch 148, Train Loss: 0.5932, Val Loss: 3.0109, F1 Micro: 0.4583, F1 Macro: 0.4247, Accuracy: 0.4583\n","Epoch 149, Train Loss: 0.6059, Val Loss: 2.2545, F1 Micro: 0.5729, F1 Macro: 0.5763, Accuracy: 0.5729\n","Epoch 150, Train Loss: 0.5379, Val Loss: 2.3495, F1 Micro: 0.5417, F1 Macro: 0.5616, Accuracy: 0.5417\n","Epoch 151, Train Loss: 0.5667, Val Loss: 2.7145, F1 Micro: 0.5000, F1 Macro: 0.4751, Accuracy: 0.5000\n","Epoch 152, Train Loss: 0.5525, Val Loss: 2.8520, F1 Micro: 0.4167, F1 Macro: 0.4296, Accuracy: 0.4167\n","Epoch 153, Train Loss: 0.5577, Val Loss: 2.6635, F1 Micro: 0.4167, F1 Macro: 0.4423, Accuracy: 0.4167\n","Epoch 154, Train Loss: 0.6259, Val Loss: 2.6120, F1 Micro: 0.5625, F1 Macro: 0.5434, Accuracy: 0.5625\n","Epoch 155, Train Loss: 0.5757, Val Loss: 3.0137, F1 Micro: 0.4792, F1 Macro: 0.4438, Accuracy: 0.4792\n","Epoch 156, Train Loss: 0.5769, Val Loss: 2.5618, F1 Micro: 0.5521, F1 Macro: 0.5105, Accuracy: 0.5521\n","Epoch 157, Train Loss: 0.5826, Val Loss: 2.8502, F1 Micro: 0.5417, F1 Macro: 0.5116, Accuracy: 0.5417\n","Epoch 158, Train Loss: 0.5482, Val Loss: 2.8916, F1 Micro: 0.4375, F1 Macro: 0.4356, Accuracy: 0.4375\n","Epoch 159, Train Loss: 0.5114, Val Loss: 2.3920, F1 Micro: 0.5208, F1 Macro: 0.5370, Accuracy: 0.5208\n","Epoch 160, Train Loss: 0.5681, Val Loss: 2.5678, F1 Micro: 0.4688, F1 Macro: 0.4451, Accuracy: 0.4688\n","Epoch 161, Train Loss: 0.6589, Val Loss: 3.3326, F1 Micro: 0.3958, F1 Macro: 0.3739, Accuracy: 0.3958\n","Epoch 162, Train Loss: 0.6093, Val Loss: 2.5293, F1 Micro: 0.5417, F1 Macro: 0.5368, Accuracy: 0.5417\n","Epoch 163, Train Loss: 0.5338, Val Loss: 2.7910, F1 Micro: 0.4896, F1 Macro: 0.4565, Accuracy: 0.4896\n","Epoch 164, Train Loss: 0.4629, Val Loss: 3.2144, F1 Micro: 0.4792, F1 Macro: 0.4331, Accuracy: 0.4792\n","Epoch 165, Train Loss: 0.4911, Val Loss: 2.9806, F1 Micro: 0.4896, F1 Macro: 0.4758, Accuracy: 0.4896\n","Epoch 166, Train Loss: 0.4873, Val Loss: 2.4575, F1 Micro: 0.5521, F1 Macro: 0.5470, Accuracy: 0.5521\n","Epoch 167, Train Loss: 0.4951, Val Loss: 2.6495, F1 Micro: 0.5208, F1 Macro: 0.5189, Accuracy: 0.5208\n","Epoch 168, Train Loss: 0.4741, Val Loss: 2.6392, F1 Micro: 0.5312, F1 Macro: 0.5388, Accuracy: 0.5312\n","Epoch 169, Train Loss: 0.4987, Val Loss: 3.2307, F1 Micro: 0.4688, F1 Macro: 0.4653, Accuracy: 0.4688\n","Epoch 170, Train Loss: 0.5004, Val Loss: 3.1074, F1 Micro: 0.4688, F1 Macro: 0.4489, Accuracy: 0.4688\n","Epoch 171, Train Loss: 0.5196, Val Loss: 3.3072, F1 Micro: 0.4271, F1 Macro: 0.4186, Accuracy: 0.4271\n","Epoch 172, Train Loss: 0.4659, Val Loss: 2.8985, F1 Micro: 0.5000, F1 Macro: 0.5104, Accuracy: 0.5000\n","Epoch 173, Train Loss: 0.5407, Val Loss: 2.9168, F1 Micro: 0.4896, F1 Macro: 0.4828, Accuracy: 0.4896\n","Epoch 174, Train Loss: 0.6233, Val Loss: 3.0480, F1 Micro: 0.4375, F1 Macro: 0.4555, Accuracy: 0.4375\n","Epoch 175, Train Loss: 0.5649, Val Loss: 3.2825, F1 Micro: 0.4583, F1 Macro: 0.4268, Accuracy: 0.4583\n","Epoch 176, Train Loss: 0.4767, Val Loss: 2.7040, F1 Micro: 0.5208, F1 Macro: 0.5292, Accuracy: 0.5208\n","Epoch 177, Train Loss: 0.5272, Val Loss: 2.8643, F1 Micro: 0.4583, F1 Macro: 0.4565, Accuracy: 0.4583\n","Epoch 178, Train Loss: 0.4989, Val Loss: 2.6523, F1 Micro: 0.5208, F1 Macro: 0.5057, Accuracy: 0.5208\n","Epoch 179, Train Loss: 0.4845, Val Loss: 3.5439, F1 Micro: 0.5000, F1 Macro: 0.4673, Accuracy: 0.5000\n","Epoch 180, Train Loss: 0.4506, Val Loss: 3.6352, F1 Micro: 0.3854, F1 Macro: 0.3369, Accuracy: 0.3854\n","Epoch 181, Train Loss: 0.4651, Val Loss: 3.4925, F1 Micro: 0.3542, F1 Macro: 0.3293, Accuracy: 0.3542\n","Epoch 182, Train Loss: 0.4615, Val Loss: 2.5983, F1 Micro: 0.5312, F1 Macro: 0.5215, Accuracy: 0.5312\n","Epoch 183, Train Loss: 0.3851, Val Loss: 3.0863, F1 Micro: 0.4792, F1 Macro: 0.4762, Accuracy: 0.4792\n","Epoch 184, Train Loss: 0.4525, Val Loss: 3.1016, F1 Micro: 0.4688, F1 Macro: 0.4864, Accuracy: 0.4688\n","Epoch 185, Train Loss: 0.4983, Val Loss: 3.7214, F1 Micro: 0.4583, F1 Macro: 0.4261, Accuracy: 0.4583\n","Epoch 186, Train Loss: 0.4587, Val Loss: 2.8824, F1 Micro: 0.5208, F1 Macro: 0.5069, Accuracy: 0.5208\n","Epoch 187, Train Loss: 0.4094, Val Loss: 3.1283, F1 Micro: 0.4792, F1 Macro: 0.4596, Accuracy: 0.4792\n","Epoch 188, Train Loss: 0.4754, Val Loss: 3.1017, F1 Micro: 0.3854, F1 Macro: 0.3564, Accuracy: 0.3854\n","Epoch 189, Train Loss: 0.4289, Val Loss: 3.3706, F1 Micro: 0.5000, F1 Macro: 0.5078, Accuracy: 0.5000\n","Epoch 190, Train Loss: 0.4988, Val Loss: 3.1103, F1 Micro: 0.5000, F1 Macro: 0.4941, Accuracy: 0.5000\n","Epoch 191, Train Loss: 0.4085, Val Loss: 3.5097, F1 Micro: 0.5208, F1 Macro: 0.5199, Accuracy: 0.5208\n","Epoch 192, Train Loss: 0.4673, Val Loss: 3.2266, F1 Micro: 0.4479, F1 Macro: 0.4385, Accuracy: 0.4479\n","Epoch 193, Train Loss: 0.4903, Val Loss: 2.7326, F1 Micro: 0.4896, F1 Macro: 0.4781, Accuracy: 0.4896\n","Epoch 194, Train Loss: 0.4321, Val Loss: 3.2803, F1 Micro: 0.4479, F1 Macro: 0.4784, Accuracy: 0.4479\n","Epoch 195, Train Loss: 0.4214, Val Loss: 3.6967, F1 Micro: 0.4479, F1 Macro: 0.4676, Accuracy: 0.4479\n","Epoch 196, Train Loss: 0.4533, Val Loss: 3.2241, F1 Micro: 0.4896, F1 Macro: 0.4838, Accuracy: 0.4896\n","Epoch 197, Train Loss: 0.4032, Val Loss: 3.4351, F1 Micro: 0.5208, F1 Macro: 0.4944, Accuracy: 0.5208\n","Epoch 198, Train Loss: 0.4677, Val Loss: 3.3587, F1 Micro: 0.5208, F1 Macro: 0.5125, Accuracy: 0.5208\n","Epoch 199, Train Loss: 0.3800, Val Loss: 3.0443, F1 Micro: 0.5417, F1 Macro: 0.5458, Accuracy: 0.5417\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8130, Val Loss: 1.7005, F1 Micro: 0.2500, F1 Macro: 0.1814, Accuracy: 0.2500\n","Epoch 2, Train Loss: 1.7527, Val Loss: 1.7005, F1 Micro: 0.2812, F1 Macro: 0.2597, Accuracy: 0.2812\n","Epoch 3, Train Loss: 1.7543, Val Loss: 1.6901, F1 Micro: 0.2812, F1 Macro: 0.2365, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.7346, Val Loss: 1.6511, F1 Micro: 0.3333, F1 Macro: 0.2946, Accuracy: 0.3333\n","Epoch 5, Train Loss: 1.7201, Val Loss: 1.6599, F1 Micro: 0.3125, F1 Macro: 0.2759, Accuracy: 0.3125\n","Epoch 6, Train Loss: 1.7271, Val Loss: 1.6614, F1 Micro: 0.3438, F1 Macro: 0.2538, Accuracy: 0.3438\n","Epoch 7, Train Loss: 1.7178, Val Loss: 1.6921, F1 Micro: 0.3229, F1 Macro: 0.2295, Accuracy: 0.3229\n","Epoch 8, Train Loss: 1.7065, Val Loss: 1.6772, F1 Micro: 0.3333, F1 Macro: 0.2700, Accuracy: 0.3333\n","Epoch 9, Train Loss: 1.7289, Val Loss: 1.6515, F1 Micro: 0.3333, F1 Macro: 0.2418, Accuracy: 0.3333\n","Epoch 10, Train Loss: 1.7100, Val Loss: 1.7312, F1 Micro: 0.2396, F1 Macro: 0.1484, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.7102, Val Loss: 1.7950, F1 Micro: 0.2917, F1 Macro: 0.1965, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.6978, Val Loss: 1.6532, F1 Micro: 0.2917, F1 Macro: 0.2119, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.6797, Val Loss: 1.8245, F1 Micro: 0.2604, F1 Macro: 0.1364, Accuracy: 0.2604\n","Epoch 14, Train Loss: 1.6814, Val Loss: 1.6388, F1 Micro: 0.3021, F1 Macro: 0.2203, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.6550, Val Loss: 1.6394, F1 Micro: 0.3125, F1 Macro: 0.2113, Accuracy: 0.3125\n","Epoch 16, Train Loss: 1.6453, Val Loss: 1.6303, F1 Micro: 0.3125, F1 Macro: 0.2441, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.6494, Val Loss: 1.7435, F1 Micro: 0.2083, F1 Macro: 0.1634, Accuracy: 0.2083\n","Epoch 18, Train Loss: 1.6519, Val Loss: 1.6792, F1 Micro: 0.3021, F1 Macro: 0.2015, Accuracy: 0.3021\n","Epoch 19, Train Loss: 1.6369, Val Loss: 1.6599, F1 Micro: 0.3229, F1 Macro: 0.2864, Accuracy: 0.3229\n","Epoch 20, Train Loss: 1.6523, Val Loss: 1.6069, F1 Micro: 0.3542, F1 Macro: 0.2918, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.6022, Val Loss: 1.5886, F1 Micro: 0.3333, F1 Macro: 0.2677, Accuracy: 0.3333\n","Epoch 22, Train Loss: 1.6131, Val Loss: 1.6689, F1 Micro: 0.3021, F1 Macro: 0.2476, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.6112, Val Loss: 1.8622, F1 Micro: 0.2604, F1 Macro: 0.1841, Accuracy: 0.2604\n","Epoch 24, Train Loss: 1.6234, Val Loss: 1.6066, F1 Micro: 0.3750, F1 Macro: 0.3287, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.6030, Val Loss: 1.5500, F1 Micro: 0.3438, F1 Macro: 0.3161, Accuracy: 0.3438\n","Epoch 26, Train Loss: 1.6056, Val Loss: 1.6022, F1 Micro: 0.3542, F1 Macro: 0.3314, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.5893, Val Loss: 1.6687, F1 Micro: 0.3229, F1 Macro: 0.2063, Accuracy: 0.3229\n","Epoch 28, Train Loss: 1.6195, Val Loss: 2.0738, F1 Micro: 0.2917, F1 Macro: 0.2524, Accuracy: 0.2917\n","Epoch 29, Train Loss: 1.5774, Val Loss: 1.5652, F1 Micro: 0.4062, F1 Macro: 0.3616, Accuracy: 0.4062\n","Epoch 30, Train Loss: 1.5369, Val Loss: 1.5327, F1 Micro: 0.3438, F1 Macro: 0.2888, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.5289, Val Loss: 1.6159, F1 Micro: 0.3750, F1 Macro: 0.3118, Accuracy: 0.3750\n","Epoch 32, Train Loss: 1.5548, Val Loss: 2.0712, F1 Micro: 0.2708, F1 Macro: 0.1816, Accuracy: 0.2708\n","Epoch 33, Train Loss: 1.5183, Val Loss: 1.6287, F1 Micro: 0.3542, F1 Macro: 0.2886, Accuracy: 0.3542\n","Epoch 34, Train Loss: 1.5018, Val Loss: 1.5606, F1 Micro: 0.3438, F1 Macro: 0.3111, Accuracy: 0.3438\n","Epoch 35, Train Loss: 1.5166, Val Loss: 1.5480, F1 Micro: 0.3750, F1 Macro: 0.3414, Accuracy: 0.3750\n","Epoch 36, Train Loss: 1.5186, Val Loss: 1.4801, F1 Micro: 0.4375, F1 Macro: 0.4135, Accuracy: 0.4375\n","Epoch 37, Train Loss: 1.4992, Val Loss: 1.5858, F1 Micro: 0.3333, F1 Macro: 0.2719, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.5323, Val Loss: 1.4947, F1 Micro: 0.4792, F1 Macro: 0.4307, Accuracy: 0.4792\n","Epoch 39, Train Loss: 1.4576, Val Loss: 1.5521, F1 Micro: 0.4583, F1 Macro: 0.4234, Accuracy: 0.4583\n","Epoch 40, Train Loss: 1.4766, Val Loss: 1.5038, F1 Micro: 0.4583, F1 Macro: 0.4383, Accuracy: 0.4583\n","Epoch 41, Train Loss: 1.4303, Val Loss: 1.5424, F1 Micro: 0.3854, F1 Macro: 0.3554, Accuracy: 0.3854\n","Epoch 42, Train Loss: 1.3943, Val Loss: 1.5800, F1 Micro: 0.3750, F1 Macro: 0.3593, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.3946, Val Loss: 2.3755, F1 Micro: 0.3021, F1 Macro: 0.2149, Accuracy: 0.3021\n","Epoch 44, Train Loss: 1.4017, Val Loss: 2.3142, F1 Micro: 0.2812, F1 Macro: 0.2105, Accuracy: 0.2812\n","Epoch 45, Train Loss: 1.3897, Val Loss: 1.6259, F1 Micro: 0.3958, F1 Macro: 0.3480, Accuracy: 0.3958\n","Epoch 46, Train Loss: 1.3661, Val Loss: 1.7679, F1 Micro: 0.3854, F1 Macro: 0.3227, Accuracy: 0.3854\n","Epoch 47, Train Loss: 1.3127, Val Loss: 1.5230, F1 Micro: 0.4479, F1 Macro: 0.3958, Accuracy: 0.4479\n","Epoch 48, Train Loss: 1.3279, Val Loss: 2.0314, F1 Micro: 0.4062, F1 Macro: 0.3550, Accuracy: 0.4062\n","Epoch 49, Train Loss: 1.3502, Val Loss: 1.7183, F1 Micro: 0.3750, F1 Macro: 0.3408, Accuracy: 0.3750\n","Epoch 50, Train Loss: 1.2885, Val Loss: 1.5853, F1 Micro: 0.4479, F1 Macro: 0.4259, Accuracy: 0.4479\n","Epoch 51, Train Loss: 1.2640, Val Loss: 1.5040, F1 Micro: 0.4375, F1 Macro: 0.3891, Accuracy: 0.4375\n","Epoch 52, Train Loss: 1.2773, Val Loss: 1.6169, F1 Micro: 0.4167, F1 Macro: 0.3594, Accuracy: 0.4167\n","Epoch 53, Train Loss: 1.2411, Val Loss: 1.5910, F1 Micro: 0.3958, F1 Macro: 0.3893, Accuracy: 0.3958\n","Epoch 54, Train Loss: 1.2441, Val Loss: 1.6879, F1 Micro: 0.4167, F1 Macro: 0.3912, Accuracy: 0.4167\n","Epoch 55, Train Loss: 1.2596, Val Loss: 1.6632, F1 Micro: 0.3646, F1 Macro: 0.3385, Accuracy: 0.3646\n","Epoch 56, Train Loss: 1.2019, Val Loss: 2.0526, F1 Micro: 0.3438, F1 Macro: 0.2821, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.2547, Val Loss: 1.9169, F1 Micro: 0.3542, F1 Macro: 0.3109, Accuracy: 0.3542\n","Epoch 58, Train Loss: 1.2618, Val Loss: 2.2346, F1 Micro: 0.3021, F1 Macro: 0.2402, Accuracy: 0.3021\n","Epoch 59, Train Loss: 1.2225, Val Loss: 1.6379, F1 Micro: 0.4479, F1 Macro: 0.3915, Accuracy: 0.4479\n","Epoch 60, Train Loss: 1.2082, Val Loss: 1.6027, F1 Micro: 0.4271, F1 Macro: 0.3657, Accuracy: 0.4271\n","Epoch 61, Train Loss: 1.1694, Val Loss: 1.9313, F1 Micro: 0.4062, F1 Macro: 0.4170, Accuracy: 0.4062\n","Epoch 62, Train Loss: 1.1503, Val Loss: 1.9407, F1 Micro: 0.3125, F1 Macro: 0.2755, Accuracy: 0.3125\n","Epoch 63, Train Loss: 1.2390, Val Loss: 1.8490, F1 Micro: 0.3542, F1 Macro: 0.3263, Accuracy: 0.3542\n","Epoch 64, Train Loss: 1.1871, Val Loss: 1.6165, F1 Micro: 0.4167, F1 Macro: 0.3844, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.1151, Val Loss: 1.8109, F1 Micro: 0.4583, F1 Macro: 0.4021, Accuracy: 0.4583\n","Epoch 66, Train Loss: 1.1236, Val Loss: 1.5013, F1 Micro: 0.4896, F1 Macro: 0.4802, Accuracy: 0.4896\n","Epoch 67, Train Loss: 1.1119, Val Loss: 1.4016, F1 Micro: 0.5417, F1 Macro: 0.5423, Accuracy: 0.5417\n","Epoch 68, Train Loss: 1.0829, Val Loss: 1.4767, F1 Micro: 0.4896, F1 Macro: 0.4832, Accuracy: 0.4896\n","Epoch 69, Train Loss: 1.0802, Val Loss: 1.8376, F1 Micro: 0.4167, F1 Macro: 0.3919, Accuracy: 0.4167\n","Epoch 70, Train Loss: 1.1107, Val Loss: 2.0835, F1 Micro: 0.3646, F1 Macro: 0.3510, Accuracy: 0.3646\n","Epoch 71, Train Loss: 1.1099, Val Loss: 1.5841, F1 Micro: 0.4479, F1 Macro: 0.4458, Accuracy: 0.4479\n","Epoch 72, Train Loss: 1.1146, Val Loss: 2.1529, F1 Micro: 0.3958, F1 Macro: 0.3940, Accuracy: 0.3958\n","Epoch 73, Train Loss: 1.0868, Val Loss: 1.3535, F1 Micro: 0.5729, F1 Macro: 0.5620, Accuracy: 0.5729\n","Epoch 74, Train Loss: 1.0498, Val Loss: 1.8700, F1 Micro: 0.4375, F1 Macro: 0.3987, Accuracy: 0.4375\n","Epoch 75, Train Loss: 1.0592, Val Loss: 1.6307, F1 Micro: 0.4271, F1 Macro: 0.4051, Accuracy: 0.4271\n","Epoch 76, Train Loss: 1.0710, Val Loss: 1.4860, F1 Micro: 0.5208, F1 Macro: 0.4979, Accuracy: 0.5208\n","Epoch 77, Train Loss: 1.0991, Val Loss: 1.6978, F1 Micro: 0.4896, F1 Macro: 0.4670, Accuracy: 0.4896\n","Epoch 78, Train Loss: 1.0509, Val Loss: 1.4067, F1 Micro: 0.5104, F1 Macro: 0.5110, Accuracy: 0.5104\n","Epoch 79, Train Loss: 1.0959, Val Loss: 1.8307, F1 Micro: 0.3750, F1 Macro: 0.3547, Accuracy: 0.3750\n","Epoch 80, Train Loss: 1.0588, Val Loss: 2.3330, F1 Micro: 0.3542, F1 Macro: 0.3287, Accuracy: 0.3542\n","Epoch 81, Train Loss: 1.0965, Val Loss: 1.9996, F1 Micro: 0.3854, F1 Macro: 0.3501, Accuracy: 0.3854\n","Epoch 82, Train Loss: 1.0489, Val Loss: 1.3929, F1 Micro: 0.5417, F1 Macro: 0.5095, Accuracy: 0.5417\n","Epoch 83, Train Loss: 1.0443, Val Loss: 2.4510, F1 Micro: 0.3229, F1 Macro: 0.2700, Accuracy: 0.3229\n","Epoch 84, Train Loss: 1.0420, Val Loss: 1.5584, F1 Micro: 0.5104, F1 Macro: 0.4895, Accuracy: 0.5104\n","Epoch 85, Train Loss: 1.0392, Val Loss: 1.4811, F1 Micro: 0.5000, F1 Macro: 0.4933, Accuracy: 0.5000\n","Epoch 86, Train Loss: 1.0193, Val Loss: 2.1223, F1 Micro: 0.3646, F1 Macro: 0.3245, Accuracy: 0.3646\n","Epoch 87, Train Loss: 0.9661, Val Loss: 1.8206, F1 Micro: 0.4688, F1 Macro: 0.4495, Accuracy: 0.4688\n","Epoch 88, Train Loss: 0.9714, Val Loss: 1.6286, F1 Micro: 0.4375, F1 Macro: 0.4316, Accuracy: 0.4375\n","Epoch 89, Train Loss: 0.9489, Val Loss: 1.7331, F1 Micro: 0.4688, F1 Macro: 0.4600, Accuracy: 0.4688\n","Epoch 90, Train Loss: 1.0082, Val Loss: 1.5515, F1 Micro: 0.4792, F1 Macro: 0.4684, Accuracy: 0.4792\n","Epoch 91, Train Loss: 0.9632, Val Loss: 1.6621, F1 Micro: 0.4688, F1 Macro: 0.4676, Accuracy: 0.4688\n","Epoch 92, Train Loss: 0.9271, Val Loss: 1.7916, F1 Micro: 0.5208, F1 Macro: 0.5000, Accuracy: 0.5208\n","Epoch 93, Train Loss: 0.9363, Val Loss: 1.5482, F1 Micro: 0.5208, F1 Macro: 0.5024, Accuracy: 0.5208\n","Epoch 94, Train Loss: 0.9485, Val Loss: 1.9358, F1 Micro: 0.3958, F1 Macro: 0.3626, Accuracy: 0.3958\n","Epoch 95, Train Loss: 0.9675, Val Loss: 2.0153, F1 Micro: 0.4167, F1 Macro: 0.4203, Accuracy: 0.4167\n","Epoch 96, Train Loss: 0.9407, Val Loss: 1.6953, F1 Micro: 0.4688, F1 Macro: 0.4719, Accuracy: 0.4688\n","Epoch 97, Train Loss: 0.9227, Val Loss: 1.6513, F1 Micro: 0.5417, F1 Macro: 0.5207, Accuracy: 0.5417\n","Epoch 98, Train Loss: 0.9132, Val Loss: 1.6696, F1 Micro: 0.4792, F1 Macro: 0.4656, Accuracy: 0.4792\n","Epoch 99, Train Loss: 0.8957, Val Loss: 1.7348, F1 Micro: 0.4792, F1 Macro: 0.4653, Accuracy: 0.4792\n","Epoch 100, Train Loss: 0.9453, Val Loss: 1.5874, F1 Micro: 0.4896, F1 Macro: 0.4667, Accuracy: 0.4896\n","Epoch 101, Train Loss: 0.9503, Val Loss: 1.5739, F1 Micro: 0.5312, F1 Macro: 0.5303, Accuracy: 0.5312\n","Epoch 102, Train Loss: 0.8416, Val Loss: 1.6536, F1 Micro: 0.5000, F1 Macro: 0.4846, Accuracy: 0.5000\n","Epoch 103, Train Loss: 0.8944, Val Loss: 1.6277, F1 Micro: 0.5104, F1 Macro: 0.4971, Accuracy: 0.5104\n","Epoch 104, Train Loss: 0.8875, Val Loss: 1.7290, F1 Micro: 0.4792, F1 Macro: 0.4695, Accuracy: 0.4792\n","Epoch 105, Train Loss: 0.9147, Val Loss: 2.0271, F1 Micro: 0.4271, F1 Macro: 0.3969, Accuracy: 0.4271\n","Epoch 106, Train Loss: 0.8782, Val Loss: 1.6875, F1 Micro: 0.5208, F1 Macro: 0.5111, Accuracy: 0.5208\n","Epoch 107, Train Loss: 0.8750, Val Loss: 1.6171, F1 Micro: 0.4896, F1 Macro: 0.4695, Accuracy: 0.4896\n","Epoch 108, Train Loss: 0.8144, Val Loss: 1.6766, F1 Micro: 0.4688, F1 Macro: 0.4463, Accuracy: 0.4688\n","Epoch 109, Train Loss: 0.8159, Val Loss: 1.9393, F1 Micro: 0.5000, F1 Macro: 0.4861, Accuracy: 0.5000\n","Epoch 110, Train Loss: 0.8032, Val Loss: 1.5462, F1 Micro: 0.4792, F1 Macro: 0.4758, Accuracy: 0.4792\n","Epoch 111, Train Loss: 0.8638, Val Loss: 1.7453, F1 Micro: 0.4375, F1 Macro: 0.4207, Accuracy: 0.4375\n","Epoch 112, Train Loss: 0.9063, Val Loss: 1.5631, F1 Micro: 0.5000, F1 Macro: 0.4909, Accuracy: 0.5000\n","Epoch 113, Train Loss: 0.8174, Val Loss: 2.1160, F1 Micro: 0.3750, F1 Macro: 0.3508, Accuracy: 0.3750\n","Epoch 114, Train Loss: 0.8276, Val Loss: 1.8461, F1 Micro: 0.4583, F1 Macro: 0.4169, Accuracy: 0.4583\n","Epoch 115, Train Loss: 0.8116, Val Loss: 1.8064, F1 Micro: 0.4896, F1 Macro: 0.4846, Accuracy: 0.4896\n","Epoch 116, Train Loss: 0.8008, Val Loss: 2.1480, F1 Micro: 0.4479, F1 Macro: 0.4424, Accuracy: 0.4479\n","Epoch 117, Train Loss: 0.7690, Val Loss: 2.1596, F1 Micro: 0.4479, F1 Macro: 0.4552, Accuracy: 0.4479\n","Epoch 118, Train Loss: 0.7907, Val Loss: 1.6762, F1 Micro: 0.5208, F1 Macro: 0.5151, Accuracy: 0.5208\n","Epoch 119, Train Loss: 0.7726, Val Loss: 1.9803, F1 Micro: 0.4583, F1 Macro: 0.4188, Accuracy: 0.4583\n","Epoch 120, Train Loss: 0.7936, Val Loss: 1.6471, F1 Micro: 0.5521, F1 Macro: 0.5542, Accuracy: 0.5521\n","Epoch 121, Train Loss: 0.8207, Val Loss: 2.5692, F1 Micro: 0.4688, F1 Macro: 0.4419, Accuracy: 0.4688\n","Epoch 122, Train Loss: 0.7653, Val Loss: 1.6520, F1 Micro: 0.5000, F1 Macro: 0.4812, Accuracy: 0.5000\n","Epoch 123, Train Loss: 0.7276, Val Loss: 2.3581, F1 Micro: 0.3750, F1 Macro: 0.3550, Accuracy: 0.3750\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.5687499999999999\n","Best hyperparameters for Outer FOLD 3: (0.001, 16, 50) with score 0.5687499999999999\n","Epoch 1, Train Loss: 1.8220, Val Loss: 1.7970, F1 Micro: 0.1583, F1 Macro: 0.0456, Accuracy: 0.1583\n","Epoch 2, Train Loss: 1.7891, Val Loss: 1.7691, F1 Micro: 0.1917, F1 Macro: 0.1133, Accuracy: 0.1917\n","Epoch 3, Train Loss: 1.7728, Val Loss: 1.7846, F1 Micro: 0.1667, F1 Macro: 0.0953, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.7575, Val Loss: 1.7450, F1 Micro: 0.2250, F1 Macro: 0.1677, Accuracy: 0.2250\n","Epoch 5, Train Loss: 1.7447, Val Loss: 1.7187, F1 Micro: 0.2250, F1 Macro: 0.2004, Accuracy: 0.2250\n","Epoch 6, Train Loss: 1.7253, Val Loss: 1.9236, F1 Micro: 0.2500, F1 Macro: 0.1481, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.7268, Val Loss: 1.6913, F1 Micro: 0.2500, F1 Macro: 0.1894, Accuracy: 0.2500\n","Epoch 8, Train Loss: 1.6806, Val Loss: 1.6994, F1 Micro: 0.2167, F1 Macro: 0.2174, Accuracy: 0.2167\n","Epoch 9, Train Loss: 1.6730, Val Loss: 1.6851, F1 Micro: 0.2750, F1 Macro: 0.2424, Accuracy: 0.2750\n","Epoch 10, Train Loss: 1.6379, Val Loss: 1.6801, F1 Micro: 0.2583, F1 Macro: 0.2553, Accuracy: 0.2583\n","Epoch 11, Train Loss: 1.6335, Val Loss: 1.6970, F1 Micro: 0.2333, F1 Macro: 0.2426, Accuracy: 0.2333\n","Epoch 12, Train Loss: 1.6179, Val Loss: 1.7324, F1 Micro: 0.2750, F1 Macro: 0.2206, Accuracy: 0.2750\n","Epoch 13, Train Loss: 1.6022, Val Loss: 1.6840, F1 Micro: 0.2583, F1 Macro: 0.2249, Accuracy: 0.2583\n","Epoch 14, Train Loss: 1.5956, Val Loss: 1.7043, F1 Micro: 0.2500, F1 Macro: 0.1560, Accuracy: 0.2500\n","Epoch 15, Train Loss: 1.5830, Val Loss: 1.6512, F1 Micro: 0.3417, F1 Macro: 0.3088, Accuracy: 0.3417\n","Epoch 16, Train Loss: 1.5841, Val Loss: 1.7151, F1 Micro: 0.2583, F1 Macro: 0.1784, Accuracy: 0.2583\n","Epoch 17, Train Loss: 1.5644, Val Loss: 1.6545, F1 Micro: 0.2917, F1 Macro: 0.2418, Accuracy: 0.2917\n","Epoch 18, Train Loss: 1.5614, Val Loss: 1.7738, F1 Micro: 0.2833, F1 Macro: 0.2445, Accuracy: 0.2833\n","Epoch 19, Train Loss: 1.5678, Val Loss: 1.8862, F1 Micro: 0.2583, F1 Macro: 0.2378, Accuracy: 0.2583\n","Epoch 20, Train Loss: 1.5395, Val Loss: 2.0637, F1 Micro: 0.2417, F1 Macro: 0.1764, Accuracy: 0.2417\n","Epoch 21, Train Loss: 1.5297, Val Loss: 1.9047, F1 Micro: 0.2417, F1 Macro: 0.1616, Accuracy: 0.2417\n","Epoch 22, Train Loss: 1.5657, Val Loss: 1.6374, F1 Micro: 0.3250, F1 Macro: 0.3101, Accuracy: 0.3250\n","Epoch 23, Train Loss: 1.5123, Val Loss: 1.5878, F1 Micro: 0.3917, F1 Macro: 0.3811, Accuracy: 0.3917\n","Epoch 24, Train Loss: 1.4919, Val Loss: 1.6325, F1 Micro: 0.3917, F1 Macro: 0.3532, Accuracy: 0.3917\n","Epoch 25, Train Loss: 1.5067, Val Loss: 1.7829, F1 Micro: 0.3000, F1 Macro: 0.2127, Accuracy: 0.3000\n","Epoch 26, Train Loss: 1.4888, Val Loss: 1.6582, F1 Micro: 0.3083, F1 Macro: 0.2468, Accuracy: 0.3083\n","Epoch 27, Train Loss: 1.4758, Val Loss: 1.6244, F1 Micro: 0.3167, F1 Macro: 0.3052, Accuracy: 0.3167\n","Epoch 28, Train Loss: 1.4964, Val Loss: 1.6002, F1 Micro: 0.3667, F1 Macro: 0.3233, Accuracy: 0.3667\n","Epoch 29, Train Loss: 1.4445, Val Loss: 1.8158, F1 Micro: 0.3000, F1 Macro: 0.2127, Accuracy: 0.3000\n","Epoch 30, Train Loss: 1.4772, Val Loss: 1.6338, F1 Micro: 0.3750, F1 Macro: 0.3499, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.4230, Val Loss: 1.6313, F1 Micro: 0.3917, F1 Macro: 0.3412, Accuracy: 0.3917\n","Epoch 32, Train Loss: 1.4422, Val Loss: 2.2334, F1 Micro: 0.2667, F1 Macro: 0.1763, Accuracy: 0.2667\n","Epoch 33, Train Loss: 1.4103, Val Loss: 1.7085, F1 Micro: 0.3833, F1 Macro: 0.3655, Accuracy: 0.3833\n","Epoch 34, Train Loss: 1.4213, Val Loss: 1.6734, F1 Micro: 0.3833, F1 Macro: 0.3682, Accuracy: 0.3833\n","Epoch 35, Train Loss: 1.4050, Val Loss: 1.5578, F1 Micro: 0.3917, F1 Macro: 0.3768, Accuracy: 0.3917\n","Epoch 36, Train Loss: 1.3890, Val Loss: 1.6578, F1 Micro: 0.4250, F1 Macro: 0.4066, Accuracy: 0.4250\n","Epoch 37, Train Loss: 1.4011, Val Loss: 2.4544, F1 Micro: 0.2667, F1 Macro: 0.1551, Accuracy: 0.2667\n","Epoch 38, Train Loss: 1.3581, Val Loss: 1.7786, F1 Micro: 0.3417, F1 Macro: 0.3061, Accuracy: 0.3417\n","Epoch 39, Train Loss: 1.3539, Val Loss: 1.5429, F1 Micro: 0.4333, F1 Macro: 0.4236, Accuracy: 0.4333\n","Epoch 40, Train Loss: 1.3178, Val Loss: 1.9052, F1 Micro: 0.3167, F1 Macro: 0.2428, Accuracy: 0.3167\n","Epoch 41, Train Loss: 1.3299, Val Loss: 1.5771, F1 Micro: 0.3833, F1 Macro: 0.3381, Accuracy: 0.3833\n","Epoch 42, Train Loss: 1.3047, Val Loss: 1.5441, F1 Micro: 0.4417, F1 Macro: 0.4172, Accuracy: 0.4417\n","Epoch 43, Train Loss: 1.2859, Val Loss: 1.6267, F1 Micro: 0.3833, F1 Macro: 0.3500, Accuracy: 0.3833\n","Epoch 44, Train Loss: 1.2903, Val Loss: 1.5956, F1 Micro: 0.4333, F1 Macro: 0.4124, Accuracy: 0.4333\n","Epoch 45, Train Loss: 1.3083, Val Loss: 1.5116, F1 Micro: 0.4500, F1 Macro: 0.4298, Accuracy: 0.4500\n","Epoch 46, Train Loss: 1.2562, Val Loss: 2.1150, F1 Micro: 0.3250, F1 Macro: 0.2812, Accuracy: 0.3250\n","Epoch 47, Train Loss: 1.2600, Val Loss: 2.0628, F1 Micro: 0.3167, F1 Macro: 0.2633, Accuracy: 0.3167\n","Epoch 48, Train Loss: 1.2959, Val Loss: 1.7767, F1 Micro: 0.3583, F1 Macro: 0.3585, Accuracy: 0.3583\n","Epoch 49, Train Loss: 1.2681, Val Loss: 1.7481, F1 Micro: 0.3833, F1 Macro: 0.3574, Accuracy: 0.3833\n","Epoch 50, Train Loss: 1.2863, Val Loss: 1.9355, F1 Micro: 0.3417, F1 Macro: 0.3166, Accuracy: 0.3417\n","Epoch 51, Train Loss: 1.2508, Val Loss: 2.3020, F1 Micro: 0.3000, F1 Macro: 0.2012, Accuracy: 0.3000\n","Epoch 52, Train Loss: 1.2265, Val Loss: 1.4719, F1 Micro: 0.4000, F1 Macro: 0.3587, Accuracy: 0.4000\n","Epoch 53, Train Loss: 1.2299, Val Loss: 1.4798, F1 Micro: 0.4083, F1 Macro: 0.3780, Accuracy: 0.4083\n","Epoch 54, Train Loss: 1.1998, Val Loss: 1.6183, F1 Micro: 0.3917, F1 Macro: 0.3483, Accuracy: 0.3917\n","Epoch 55, Train Loss: 1.1618, Val Loss: 1.9881, F1 Micro: 0.3667, F1 Macro: 0.3429, Accuracy: 0.3667\n","Epoch 56, Train Loss: 1.1747, Val Loss: 2.2370, F1 Micro: 0.2833, F1 Macro: 0.2310, Accuracy: 0.2833\n","Epoch 57, Train Loss: 1.2100, Val Loss: 1.9397, F1 Micro: 0.4667, F1 Macro: 0.4471, Accuracy: 0.4667\n","Epoch 58, Train Loss: 1.1699, Val Loss: 2.2051, F1 Micro: 0.2750, F1 Macro: 0.2253, Accuracy: 0.2750\n","Epoch 59, Train Loss: 1.1902, Val Loss: 2.1656, F1 Micro: 0.3917, F1 Macro: 0.3607, Accuracy: 0.3917\n","Epoch 60, Train Loss: 1.1893, Val Loss: 1.9580, F1 Micro: 0.3917, F1 Macro: 0.3406, Accuracy: 0.3917\n","Epoch 61, Train Loss: 1.1852, Val Loss: 1.4802, F1 Micro: 0.4333, F1 Macro: 0.4144, Accuracy: 0.4333\n","Epoch 62, Train Loss: 1.1933, Val Loss: 1.5791, F1 Micro: 0.4083, F1 Macro: 0.3799, Accuracy: 0.4083\n","Epoch 63, Train Loss: 1.1652, Val Loss: 1.6829, F1 Micro: 0.4417, F1 Macro: 0.4124, Accuracy: 0.4417\n","Epoch 64, Train Loss: 1.1553, Val Loss: 1.6597, F1 Micro: 0.4083, F1 Macro: 0.3622, Accuracy: 0.4083\n","Epoch 65, Train Loss: 1.1529, Val Loss: 1.4702, F1 Micro: 0.4583, F1 Macro: 0.4336, Accuracy: 0.4583\n","Epoch 66, Train Loss: 1.1140, Val Loss: 1.7443, F1 Micro: 0.4083, F1 Macro: 0.3851, Accuracy: 0.4083\n","Epoch 67, Train Loss: 1.1434, Val Loss: 1.5076, F1 Micro: 0.4500, F1 Macro: 0.4141, Accuracy: 0.4500\n","Epoch 68, Train Loss: 1.1044, Val Loss: 1.6233, F1 Micro: 0.4167, F1 Macro: 0.3611, Accuracy: 0.4167\n","Epoch 69, Train Loss: 1.1784, Val Loss: 1.7374, F1 Micro: 0.3250, F1 Macro: 0.2684, Accuracy: 0.3250\n","Epoch 70, Train Loss: 1.1517, Val Loss: 1.9027, F1 Micro: 0.3750, F1 Macro: 0.3207, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.1087, Val Loss: 1.5100, F1 Micro: 0.4917, F1 Macro: 0.4850, Accuracy: 0.4917\n","Epoch 72, Train Loss: 1.0943, Val Loss: 1.5122, F1 Micro: 0.4417, F1 Macro: 0.4335, Accuracy: 0.4417\n","Epoch 73, Train Loss: 1.1301, Val Loss: 1.5647, F1 Micro: 0.3917, F1 Macro: 0.3566, Accuracy: 0.3917\n","Epoch 74, Train Loss: 1.0764, Val Loss: 1.5012, F1 Micro: 0.4417, F1 Macro: 0.4319, Accuracy: 0.4417\n","Epoch 75, Train Loss: 1.1254, Val Loss: 2.0465, F1 Micro: 0.4000, F1 Macro: 0.3914, Accuracy: 0.4000\n","Epoch 76, Train Loss: 1.1256, Val Loss: 2.2564, F1 Micro: 0.3250, F1 Macro: 0.2925, Accuracy: 0.3250\n","Epoch 77, Train Loss: 1.0748, Val Loss: 1.6152, F1 Micro: 0.4500, F1 Macro: 0.4117, Accuracy: 0.4500\n","Epoch 78, Train Loss: 1.1211, Val Loss: 1.8505, F1 Micro: 0.3833, F1 Macro: 0.3701, Accuracy: 0.3833\n","Epoch 79, Train Loss: 1.0355, Val Loss: 1.8871, F1 Micro: 0.4417, F1 Macro: 0.4090, Accuracy: 0.4417\n","Epoch 80, Train Loss: 1.0743, Val Loss: 1.6548, F1 Micro: 0.4417, F1 Macro: 0.4213, Accuracy: 0.4417\n","Epoch 81, Train Loss: 1.0611, Val Loss: 1.6831, F1 Micro: 0.4833, F1 Macro: 0.4672, Accuracy: 0.4833\n","Epoch 82, Train Loss: 1.0373, Val Loss: 1.7035, F1 Micro: 0.4417, F1 Macro: 0.4134, Accuracy: 0.4417\n","Epoch 83, Train Loss: 1.0547, Val Loss: 1.8061, F1 Micro: 0.4167, F1 Macro: 0.3982, Accuracy: 0.4167\n","Epoch 84, Train Loss: 1.0106, Val Loss: 1.4734, F1 Micro: 0.4583, F1 Macro: 0.4405, Accuracy: 0.4583\n","Epoch 85, Train Loss: 1.0215, Val Loss: 1.7757, F1 Micro: 0.4083, F1 Macro: 0.3679, Accuracy: 0.4083\n","Epoch 86, Train Loss: 1.0498, Val Loss: 1.7937, F1 Micro: 0.3833, F1 Macro: 0.3386, Accuracy: 0.3833\n","Epoch 87, Train Loss: 1.0631, Val Loss: 2.0362, F1 Micro: 0.3667, F1 Macro: 0.3161, Accuracy: 0.3667\n","Epoch 88, Train Loss: 1.0414, Val Loss: 1.5053, F1 Micro: 0.4833, F1 Macro: 0.4505, Accuracy: 0.4833\n","Epoch 89, Train Loss: 1.0026, Val Loss: 1.5811, F1 Micro: 0.4667, F1 Macro: 0.4599, Accuracy: 0.4667\n","Epoch 90, Train Loss: 0.9578, Val Loss: 1.7170, F1 Micro: 0.4083, F1 Macro: 0.3970, Accuracy: 0.4083\n","Epoch 91, Train Loss: 1.0124, Val Loss: 1.6412, F1 Micro: 0.4583, F1 Macro: 0.4428, Accuracy: 0.4583\n","Epoch 92, Train Loss: 0.9948, Val Loss: 2.6980, F1 Micro: 0.3417, F1 Macro: 0.2911, Accuracy: 0.3417\n","Epoch 93, Train Loss: 1.0057, Val Loss: 1.5866, F1 Micro: 0.4083, F1 Macro: 0.3869, Accuracy: 0.4083\n","Epoch 94, Train Loss: 0.9716, Val Loss: 1.8242, F1 Micro: 0.3917, F1 Macro: 0.3641, Accuracy: 0.3917\n","Epoch 95, Train Loss: 0.9745, Val Loss: 1.4546, F1 Micro: 0.5000, F1 Macro: 0.4782, Accuracy: 0.5000\n","Epoch 96, Train Loss: 0.9682, Val Loss: 1.4849, F1 Micro: 0.4583, F1 Macro: 0.4483, Accuracy: 0.4583\n","Epoch 97, Train Loss: 1.0058, Val Loss: 1.4242, F1 Micro: 0.5167, F1 Macro: 0.4968, Accuracy: 0.5167\n","Epoch 98, Train Loss: 1.0022, Val Loss: 1.9458, F1 Micro: 0.4333, F1 Macro: 0.4095, Accuracy: 0.4333\n","Epoch 99, Train Loss: 0.9956, Val Loss: 1.7399, F1 Micro: 0.4750, F1 Macro: 0.4529, Accuracy: 0.4750\n","Epoch 100, Train Loss: 0.9237, Val Loss: 1.6588, F1 Micro: 0.4917, F1 Macro: 0.4382, Accuracy: 0.4917\n","Epoch 101, Train Loss: 1.0005, Val Loss: 1.7552, F1 Micro: 0.4417, F1 Macro: 0.4325, Accuracy: 0.4417\n","Epoch 102, Train Loss: 0.9728, Val Loss: 1.5681, F1 Micro: 0.4500, F1 Macro: 0.4206, Accuracy: 0.4500\n","Epoch 103, Train Loss: 0.9347, Val Loss: 1.6367, F1 Micro: 0.4583, F1 Macro: 0.4314, Accuracy: 0.4583\n","Epoch 104, Train Loss: 0.9656, Val Loss: 2.0158, F1 Micro: 0.3417, F1 Macro: 0.2830, Accuracy: 0.3417\n","Epoch 105, Train Loss: 0.9700, Val Loss: 1.4694, F1 Micro: 0.5000, F1 Macro: 0.5010, Accuracy: 0.5000\n","Epoch 106, Train Loss: 0.9402, Val Loss: 1.9446, F1 Micro: 0.4417, F1 Macro: 0.4010, Accuracy: 0.4417\n","Epoch 107, Train Loss: 0.9545, Val Loss: 1.9531, F1 Micro: 0.4333, F1 Macro: 0.4040, Accuracy: 0.4333\n","Epoch 108, Train Loss: 0.9196, Val Loss: 1.9353, F1 Micro: 0.4417, F1 Macro: 0.4336, Accuracy: 0.4417\n","Epoch 109, Train Loss: 0.9571, Val Loss: 1.5945, F1 Micro: 0.5000, F1 Macro: 0.4862, Accuracy: 0.5000\n","Epoch 110, Train Loss: 0.9143, Val Loss: 1.5116, F1 Micro: 0.4667, F1 Macro: 0.4514, Accuracy: 0.4667\n","Epoch 111, Train Loss: 0.8682, Val Loss: 1.7810, F1 Micro: 0.4833, F1 Macro: 0.4968, Accuracy: 0.4833\n","Epoch 112, Train Loss: 0.9099, Val Loss: 1.6929, F1 Micro: 0.5000, F1 Macro: 0.4901, Accuracy: 0.5000\n","Epoch 113, Train Loss: 0.8996, Val Loss: 1.5271, F1 Micro: 0.5000, F1 Macro: 0.4572, Accuracy: 0.5000\n","Epoch 114, Train Loss: 0.8832, Val Loss: 1.4885, F1 Micro: 0.4750, F1 Macro: 0.4519, Accuracy: 0.4750\n","Epoch 115, Train Loss: 0.8831, Val Loss: 1.7756, F1 Micro: 0.4667, F1 Macro: 0.4455, Accuracy: 0.4667\n","Epoch 116, Train Loss: 0.8985, Val Loss: 1.6640, F1 Micro: 0.4167, F1 Macro: 0.3870, Accuracy: 0.4167\n","Epoch 117, Train Loss: 0.8905, Val Loss: 1.5073, F1 Micro: 0.4833, F1 Macro: 0.4887, Accuracy: 0.4833\n","Epoch 118, Train Loss: 0.8526, Val Loss: 2.0116, F1 Micro: 0.4333, F1 Macro: 0.4133, Accuracy: 0.4333\n","Epoch 119, Train Loss: 0.9357, Val Loss: 2.7861, F1 Micro: 0.3833, F1 Macro: 0.3722, Accuracy: 0.3833\n","Epoch 120, Train Loss: 0.8477, Val Loss: 1.6984, F1 Micro: 0.4917, F1 Macro: 0.4771, Accuracy: 0.4917\n","Epoch 121, Train Loss: 0.8424, Val Loss: 2.7502, F1 Micro: 0.4000, F1 Macro: 0.3614, Accuracy: 0.4000\n","Epoch 122, Train Loss: 0.9082, Val Loss: 1.5908, F1 Micro: 0.4833, F1 Macro: 0.4605, Accuracy: 0.4833\n","Epoch 123, Train Loss: 0.8476, Val Loss: 1.5104, F1 Micro: 0.5000, F1 Macro: 0.4708, Accuracy: 0.5000\n","Epoch 124, Train Loss: 0.7907, Val Loss: 1.4936, F1 Micro: 0.5000, F1 Macro: 0.4910, Accuracy: 0.5000\n","Epoch 125, Train Loss: 0.9092, Val Loss: 2.5945, F1 Micro: 0.3167, F1 Macro: 0.2943, Accuracy: 0.3167\n","Epoch 126, Train Loss: 0.8579, Val Loss: 1.5132, F1 Micro: 0.4750, F1 Macro: 0.4590, Accuracy: 0.4750\n","Epoch 127, Train Loss: 0.9051, Val Loss: 1.5273, F1 Micro: 0.4833, F1 Macro: 0.4607, Accuracy: 0.4833\n","Epoch 128, Train Loss: 0.8533, Val Loss: 1.6171, F1 Micro: 0.4917, F1 Macro: 0.4790, Accuracy: 0.4917\n","Epoch 129, Train Loss: 0.7972, Val Loss: 1.9484, F1 Micro: 0.5000, F1 Macro: 0.4923, Accuracy: 0.5000\n","Epoch 130, Train Loss: 0.8045, Val Loss: 1.5402, F1 Micro: 0.4917, F1 Macro: 0.4680, Accuracy: 0.4917\n","Epoch 131, Train Loss: 0.8122, Val Loss: 1.7789, F1 Micro: 0.4167, F1 Macro: 0.3919, Accuracy: 0.4167\n","Epoch 132, Train Loss: 0.8970, Val Loss: 1.8313, F1 Micro: 0.5083, F1 Macro: 0.4833, Accuracy: 0.5083\n","Epoch 133, Train Loss: 0.8261, Val Loss: 2.0185, F1 Micro: 0.3833, F1 Macro: 0.3567, Accuracy: 0.3833\n","Epoch 134, Train Loss: 0.8468, Val Loss: 2.4539, F1 Micro: 0.3583, F1 Macro: 0.3266, Accuracy: 0.3583\n","Epoch 135, Train Loss: 0.8320, Val Loss: 2.0153, F1 Micro: 0.4500, F1 Macro: 0.4312, Accuracy: 0.4500\n","Epoch 136, Train Loss: 0.8363, Val Loss: 1.5138, F1 Micro: 0.5083, F1 Macro: 0.4933, Accuracy: 0.5083\n","Epoch 137, Train Loss: 0.7961, Val Loss: 1.4410, F1 Micro: 0.5333, F1 Macro: 0.5269, Accuracy: 0.5333\n","Epoch 138, Train Loss: 0.7607, Val Loss: 1.7956, F1 Micro: 0.4833, F1 Macro: 0.4710, Accuracy: 0.4833\n","Epoch 139, Train Loss: 0.8290, Val Loss: 1.7179, F1 Micro: 0.4750, F1 Macro: 0.4618, Accuracy: 0.4750\n","Epoch 140, Train Loss: 0.7414, Val Loss: 1.4015, F1 Micro: 0.4917, F1 Macro: 0.4787, Accuracy: 0.4917\n","Epoch 141, Train Loss: 0.7722, Val Loss: 1.6067, F1 Micro: 0.5417, F1 Macro: 0.5518, Accuracy: 0.5417\n","Epoch 142, Train Loss: 0.7883, Val Loss: 2.0163, F1 Micro: 0.4667, F1 Macro: 0.4445, Accuracy: 0.4667\n","Epoch 143, Train Loss: 0.7578, Val Loss: 2.3273, F1 Micro: 0.4333, F1 Macro: 0.4144, Accuracy: 0.4333\n","Epoch 144, Train Loss: 0.7281, Val Loss: 1.4517, F1 Micro: 0.5250, F1 Macro: 0.5102, Accuracy: 0.5250\n","Epoch 145, Train Loss: 0.7468, Val Loss: 2.3268, F1 Micro: 0.4667, F1 Macro: 0.4153, Accuracy: 0.4667\n","Epoch 146, Train Loss: 0.7197, Val Loss: 1.5883, F1 Micro: 0.5083, F1 Macro: 0.4901, Accuracy: 0.5083\n","Epoch 147, Train Loss: 0.7482, Val Loss: 1.7981, F1 Micro: 0.4750, F1 Macro: 0.4546, Accuracy: 0.4750\n","Epoch 148, Train Loss: 0.7885, Val Loss: 1.7536, F1 Micro: 0.4500, F1 Macro: 0.4455, Accuracy: 0.4500\n","Epoch 149, Train Loss: 0.7460, Val Loss: 1.8591, F1 Micro: 0.5167, F1 Macro: 0.5048, Accuracy: 0.5167\n","Epoch 150, Train Loss: 0.7628, Val Loss: 2.6732, F1 Micro: 0.4250, F1 Macro: 0.3576, Accuracy: 0.4250\n","Epoch 151, Train Loss: 0.7466, Val Loss: 2.1537, F1 Micro: 0.5167, F1 Macro: 0.5202, Accuracy: 0.5167\n","Epoch 152, Train Loss: 0.7438, Val Loss: 1.4671, F1 Micro: 0.5667, F1 Macro: 0.5674, Accuracy: 0.5667\n","Epoch 153, Train Loss: 0.7289, Val Loss: 1.9192, F1 Micro: 0.4500, F1 Macro: 0.4310, Accuracy: 0.4500\n","Epoch 154, Train Loss: 0.7417, Val Loss: 1.9145, F1 Micro: 0.5167, F1 Macro: 0.5106, Accuracy: 0.5167\n","Epoch 155, Train Loss: 0.7544, Val Loss: 2.2901, F1 Micro: 0.3750, F1 Macro: 0.3307, Accuracy: 0.3750\n","Epoch 156, Train Loss: 0.7677, Val Loss: 1.6888, F1 Micro: 0.4750, F1 Macro: 0.4584, Accuracy: 0.4750\n","Epoch 157, Train Loss: 0.7304, Val Loss: 1.7225, F1 Micro: 0.5083, F1 Macro: 0.4958, Accuracy: 0.5083\n","Epoch 158, Train Loss: 0.7802, Val Loss: 1.4033, F1 Micro: 0.5417, F1 Macro: 0.5376, Accuracy: 0.5417\n","Epoch 159, Train Loss: 0.7761, Val Loss: 1.7261, F1 Micro: 0.4833, F1 Macro: 0.4607, Accuracy: 0.4833\n","Epoch 160, Train Loss: 0.7208, Val Loss: 1.8894, F1 Micro: 0.5000, F1 Macro: 0.5159, Accuracy: 0.5000\n","Epoch 161, Train Loss: 0.6805, Val Loss: 1.5656, F1 Micro: 0.5500, F1 Macro: 0.5541, Accuracy: 0.5500\n","Epoch 162, Train Loss: 0.7013, Val Loss: 1.7615, F1 Micro: 0.4917, F1 Macro: 0.4709, Accuracy: 0.4917\n","Epoch 163, Train Loss: 0.7075, Val Loss: 1.8266, F1 Micro: 0.5083, F1 Macro: 0.4915, Accuracy: 0.5083\n","Epoch 164, Train Loss: 0.6852, Val Loss: 1.9020, F1 Micro: 0.5250, F1 Macro: 0.5094, Accuracy: 0.5250\n","Epoch 165, Train Loss: 0.6810, Val Loss: 1.6383, F1 Micro: 0.5417, F1 Macro: 0.5410, Accuracy: 0.5417\n","Epoch 166, Train Loss: 0.6815, Val Loss: 1.4350, F1 Micro: 0.5250, F1 Macro: 0.5286, Accuracy: 0.5250\n","Epoch 167, Train Loss: 0.6804, Val Loss: 1.7027, F1 Micro: 0.5083, F1 Macro: 0.5143, Accuracy: 0.5083\n","Epoch 168, Train Loss: 0.6346, Val Loss: 2.3671, F1 Micro: 0.4083, F1 Macro: 0.3880, Accuracy: 0.4083\n","Epoch 169, Train Loss: 0.6992, Val Loss: 1.8423, F1 Micro: 0.5583, F1 Macro: 0.5601, Accuracy: 0.5583\n","Epoch 170, Train Loss: 0.6719, Val Loss: 1.8166, F1 Micro: 0.5333, F1 Macro: 0.5273, Accuracy: 0.5333\n","Epoch 171, Train Loss: 0.6687, Val Loss: 1.9746, F1 Micro: 0.4833, F1 Macro: 0.4703, Accuracy: 0.4833\n","Epoch 172, Train Loss: 0.7087, Val Loss: 1.9803, F1 Micro: 0.4833, F1 Macro: 0.4761, Accuracy: 0.4833\n","Epoch 173, Train Loss: 0.6582, Val Loss: 1.8999, F1 Micro: 0.5333, F1 Macro: 0.5261, Accuracy: 0.5333\n","Epoch 174, Train Loss: 0.6089, Val Loss: 1.9977, F1 Micro: 0.4750, F1 Macro: 0.4726, Accuracy: 0.4750\n","Epoch 175, Train Loss: 0.6919, Val Loss: 2.6110, F1 Micro: 0.4250, F1 Macro: 0.4063, Accuracy: 0.4250\n","Epoch 176, Train Loss: 0.6247, Val Loss: 1.7926, F1 Micro: 0.5667, F1 Macro: 0.5736, Accuracy: 0.5667\n","Epoch 177, Train Loss: 0.6811, Val Loss: 1.6795, F1 Micro: 0.5583, F1 Macro: 0.5650, Accuracy: 0.5583\n","Epoch 178, Train Loss: 0.6488, Val Loss: 2.2131, F1 Micro: 0.4917, F1 Macro: 0.4851, Accuracy: 0.4917\n","Epoch 179, Train Loss: 0.6987, Val Loss: 1.7886, F1 Micro: 0.5500, F1 Macro: 0.5459, Accuracy: 0.5500\n","Epoch 180, Train Loss: 0.6662, Val Loss: 1.6428, F1 Micro: 0.5583, F1 Macro: 0.5603, Accuracy: 0.5583\n","Epoch 181, Train Loss: 0.5812, Val Loss: 1.7143, F1 Micro: 0.5667, F1 Macro: 0.5592, Accuracy: 0.5667\n","Epoch 182, Train Loss: 0.6223, Val Loss: 1.6377, F1 Micro: 0.5500, F1 Macro: 0.5504, Accuracy: 0.5500\n","Epoch 183, Train Loss: 0.5433, Val Loss: 2.3077, F1 Micro: 0.5083, F1 Macro: 0.5083, Accuracy: 0.5083\n","Epoch 184, Train Loss: 0.5910, Val Loss: 1.6601, F1 Micro: 0.5833, F1 Macro: 0.5791, Accuracy: 0.5833\n","Epoch 185, Train Loss: 0.5561, Val Loss: 1.5828, F1 Micro: 0.6167, F1 Macro: 0.6224, Accuracy: 0.6167\n","Epoch 186, Train Loss: 0.6083, Val Loss: 1.6766, F1 Micro: 0.6000, F1 Macro: 0.6010, Accuracy: 0.6000\n","Epoch 187, Train Loss: 0.6340, Val Loss: 2.0531, F1 Micro: 0.5417, F1 Macro: 0.5381, Accuracy: 0.5417\n","Epoch 188, Train Loss: 0.6339, Val Loss: 1.7266, F1 Micro: 0.5417, F1 Macro: 0.5258, Accuracy: 0.5417\n","Epoch 189, Train Loss: 0.6000, Val Loss: 1.7544, F1 Micro: 0.5500, F1 Macro: 0.5338, Accuracy: 0.5500\n","Epoch 190, Train Loss: 0.6357, Val Loss: 1.6531, F1 Micro: 0.5500, F1 Macro: 0.5425, Accuracy: 0.5500\n","Epoch 191, Train Loss: 0.6214, Val Loss: 1.7265, F1 Micro: 0.5583, F1 Macro: 0.5524, Accuracy: 0.5583\n","Epoch 192, Train Loss: 0.5921, Val Loss: 1.5314, F1 Micro: 0.6000, F1 Macro: 0.5931, Accuracy: 0.6000\n","Epoch 193, Train Loss: 0.6035, Val Loss: 1.7153, F1 Micro: 0.5667, F1 Macro: 0.5677, Accuracy: 0.5667\n","Epoch 194, Train Loss: 0.6496, Val Loss: 1.6845, F1 Micro: 0.5417, F1 Macro: 0.5340, Accuracy: 0.5417\n","Epoch 195, Train Loss: 0.5858, Val Loss: 2.1309, F1 Micro: 0.4667, F1 Macro: 0.4688, Accuracy: 0.4667\n","Epoch 196, Train Loss: 0.6536, Val Loss: 1.9033, F1 Micro: 0.5333, F1 Macro: 0.5296, Accuracy: 0.5333\n","Epoch 197, Train Loss: 0.5723, Val Loss: 1.7218, F1 Micro: 0.5250, F1 Macro: 0.5123, Accuracy: 0.5250\n","Epoch 198, Train Loss: 0.5718, Val Loss: 1.5645, F1 Micro: 0.5250, F1 Macro: 0.5149, Accuracy: 0.5250\n","Epoch 199, Train Loss: 0.5239, Val Loss: 1.6881, F1 Micro: 0.5833, F1 Macro: 0.5708, Accuracy: 0.5833\n","Epoch 200, Train Loss: 0.5403, Val Loss: 1.9159, F1 Micro: 0.5500, F1 Macro: 0.5469, Accuracy: 0.5500\n","Test set evaluation - F1 Micro: 0.5500, F1 Macro: 0.5469, Accuracy: 0.5500\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8794, Val Loss: 1.8096, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 2, Train Loss: 1.7976, Val Loss: 1.8038, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 3, Train Loss: 1.7939, Val Loss: 1.8008, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 4, Train Loss: 1.7937, Val Loss: 1.8006, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 5, Train Loss: 1.7926, Val Loss: 1.8040, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 6, Train Loss: 1.7922, Val Loss: 1.8030, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 7, Train Loss: 1.7920, Val Loss: 1.8018, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 8, Train Loss: 1.7931, Val Loss: 1.7998, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 9, Train Loss: 1.7923, Val Loss: 1.8018, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 10, Train Loss: 1.7918, Val Loss: 1.8005, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 11, Train Loss: 1.7933, Val Loss: 1.8005, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8272, Val Loss: 1.7890, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 2, Train Loss: 1.8002, Val Loss: 1.7943, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 3, Train Loss: 1.7939, Val Loss: 1.7986, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 4, Train Loss: 1.7922, Val Loss: 1.8012, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 5, Train Loss: 1.7924, Val Loss: 1.8019, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 6, Train Loss: 1.7935, Val Loss: 1.8009, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 7, Train Loss: 1.7915, Val Loss: 1.8034, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 8, Train Loss: 1.7931, Val Loss: 1.8025, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 9, Train Loss: 1.7924, Val Loss: 1.8080, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 10, Train Loss: 1.7922, Val Loss: 1.8045, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 11, Train Loss: 1.7929, Val Loss: 1.8041, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8281, Val Loss: 1.8184, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 2, Train Loss: 1.7977, Val Loss: 1.8153, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 3, Train Loss: 1.7931, Val Loss: 1.8157, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 4, Train Loss: 1.7916, Val Loss: 1.8144, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 5, Train Loss: 1.7908, Val Loss: 1.8128, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 6, Train Loss: 1.7912, Val Loss: 1.8158, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 7, Train Loss: 1.7919, Val Loss: 1.8156, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 8, Train Loss: 1.7904, Val Loss: 1.8153, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 9, Train Loss: 1.7906, Val Loss: 1.8124, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 10, Train Loss: 1.7909, Val Loss: 1.8134, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 11, Train Loss: 1.7916, Val Loss: 1.8122, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8379, Val Loss: 1.8051, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 2, Train Loss: 1.7991, Val Loss: 1.7966, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.7949, Val Loss: 1.7957, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.7943, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7934, Val Loss: 1.7937, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 6, Train Loss: 1.7925, Val Loss: 1.7959, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7937, Val Loss: 1.7955, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 8, Train Loss: 1.7942, Val Loss: 1.7960, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 9, Train Loss: 1.7935, Val Loss: 1.7946, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 10, Train Loss: 1.7923, Val Loss: 1.7957, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.7943, Val Loss: 1.7949, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8571, Val Loss: 1.7951, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.7936, Val Loss: 1.7970, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7931, Val Loss: 1.7956, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7930, Val Loss: 1.7970, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7929, Val Loss: 1.7946, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 6, Train Loss: 1.7925, Val Loss: 1.7956, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7928, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 1.7828, Val Loss: 1.7827, F1 Micro: 0.2396, F1 Macro: 0.1534, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.7951, Val Loss: 1.7977, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 10, Train Loss: 1.7925, Val Loss: 1.7967, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 11, Train Loss: 1.7925, Val Loss: 1.7956, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 12, Train Loss: 1.7943, Val Loss: 1.7977, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 13, Train Loss: 1.7934, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 14, Train Loss: 1.7931, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 15, Train Loss: 1.7932, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 16, Train Loss: 1.7938, Val Loss: 1.7959, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 17, Train Loss: 1.7924, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 18, Train Loss: 1.7927, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.16458333333333336\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8411, Val Loss: 1.7950, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 2, Train Loss: 1.7988, Val Loss: 1.7973, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7928, Val Loss: 1.7975, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7941, Val Loss: 1.8000, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 5, Train Loss: 1.7932, Val Loss: 1.7997, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 6, Train Loss: 1.7927, Val Loss: 1.8029, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 7, Train Loss: 1.7923, Val Loss: 1.8026, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 8, Train Loss: 1.7923, Val Loss: 1.8025, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 9, Train Loss: 1.7918, Val Loss: 1.8033, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 10, Train Loss: 1.7929, Val Loss: 1.8009, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 11, Train Loss: 1.7920, Val Loss: 1.8045, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 12, Train Loss: 1.7928, Val Loss: 1.8021, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 13, Train Loss: 1.7923, Val Loss: 1.8021, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 14, Train Loss: 1.7928, Val Loss: 1.8016, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 15, Train Loss: 1.7931, Val Loss: 1.8020, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 16, Train Loss: 1.7939, Val Loss: 1.8030, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 17, Train Loss: 1.7920, Val Loss: 1.8032, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 18, Train Loss: 1.7927, Val Loss: 1.8036, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 19, Train Loss: 1.7917, Val Loss: 1.8030, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 20, Train Loss: 1.7939, Val Loss: 1.8029, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 21, Train Loss: 1.7926, Val Loss: 1.8028, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 22, Train Loss: 1.7931, Val Loss: 1.8014, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 23, Train Loss: 1.7915, Val Loss: 1.8036, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 24, Train Loss: 1.7921, Val Loss: 1.8012, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 25, Train Loss: 1.7930, Val Loss: 1.8018, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 26, Train Loss: 1.7938, Val Loss: 1.8043, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 27, Train Loss: 1.7917, Val Loss: 1.8015, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 28, Train Loss: 1.7920, Val Loss: 1.8009, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 29, Train Loss: 1.7930, Val Loss: 1.8007, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 30, Train Loss: 1.7937, Val Loss: 1.7996, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 31, Train Loss: 1.7934, Val Loss: 1.8055, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 32, Train Loss: 1.7931, Val Loss: 1.8022, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 33, Train Loss: 1.7942, Val Loss: 1.8027, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 34, Train Loss: 1.7920, Val Loss: 1.8015, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 35, Train Loss: 1.7920, Val Loss: 1.7999, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 36, Train Loss: 1.7918, Val Loss: 1.8019, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 37, Train Loss: 1.7926, Val Loss: 1.8008, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 38, Train Loss: 1.7916, Val Loss: 1.8012, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 39, Train Loss: 1.7925, Val Loss: 1.8033, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 40, Train Loss: 1.7919, Val Loss: 1.8009, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 41, Train Loss: 1.7920, Val Loss: 1.8001, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 42, Train Loss: 1.7920, Val Loss: 1.8046, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 43, Train Loss: 1.7922, Val Loss: 1.8034, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 44, Train Loss: 1.7928, Val Loss: 1.8007, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 45, Train Loss: 1.7936, Val Loss: 1.8045, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 46, Train Loss: 1.7935, Val Loss: 1.7994, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 47, Train Loss: 1.7921, Val Loss: 1.8019, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 48, Train Loss: 1.7929, Val Loss: 1.8026, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 49, Train Loss: 1.7934, Val Loss: 1.8014, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 50, Train Loss: 1.7938, Val Loss: 1.8021, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 51, Train Loss: 1.7923, Val Loss: 1.8034, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.9389, Val Loss: 1.8075, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 2, Train Loss: 1.7953, Val Loss: 1.8054, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 3, Train Loss: 1.7944, Val Loss: 1.8035, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 4, Train Loss: 1.7921, Val Loss: 1.8011, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 5, Train Loss: 1.7934, Val Loss: 1.8042, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 6, Train Loss: 1.7925, Val Loss: 1.8024, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 7, Train Loss: 1.7936, Val Loss: 1.8023, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 8, Train Loss: 1.7928, Val Loss: 1.8020, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 9, Train Loss: 1.7947, Val Loss: 1.8065, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 10, Train Loss: 1.7924, Val Loss: 1.8007, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 11, Train Loss: 1.7920, Val Loss: 1.8033, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 12, Train Loss: 1.7920, Val Loss: 1.8026, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 13, Train Loss: 1.7917, Val Loss: 1.8060, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 14, Train Loss: 1.7921, Val Loss: 1.8063, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 15, Train Loss: 1.7920, Val Loss: 1.8019, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 16, Train Loss: 1.7913, Val Loss: 1.8030, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 17, Train Loss: 1.7925, Val Loss: 1.8042, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 18, Train Loss: 1.7936, Val Loss: 1.8000, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 19, Train Loss: 1.7924, Val Loss: 1.8067, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 20, Train Loss: 1.7919, Val Loss: 1.8057, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 21, Train Loss: 1.7922, Val Loss: 1.8075, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 22, Train Loss: 1.7934, Val Loss: 1.8005, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 23, Train Loss: 1.7924, Val Loss: 1.8060, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 24, Train Loss: 1.7924, Val Loss: 1.8081, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 25, Train Loss: 1.7925, Val Loss: 1.8027, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 26, Train Loss: 1.7931, Val Loss: 1.8070, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 27, Train Loss: 1.7924, Val Loss: 1.8061, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 28, Train Loss: 1.7917, Val Loss: 1.8028, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 29, Train Loss: 1.7927, Val Loss: 1.8031, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 30, Train Loss: 1.7931, Val Loss: 1.8044, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 31, Train Loss: 1.7919, Val Loss: 1.8039, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 32, Train Loss: 1.7914, Val Loss: 1.8055, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 33, Train Loss: 1.7926, Val Loss: 1.8063, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 34, Train Loss: 1.7931, Val Loss: 1.7993, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 35, Train Loss: 1.7924, Val Loss: 1.8045, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 36, Train Loss: 1.7922, Val Loss: 1.8039, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 37, Train Loss: 1.7919, Val Loss: 1.8034, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 38, Train Loss: 1.7924, Val Loss: 1.8046, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 39, Train Loss: 1.7922, Val Loss: 1.8015, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 40, Train Loss: 1.7927, Val Loss: 1.8060, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 41, Train Loss: 1.7935, Val Loss: 1.8036, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 42, Train Loss: 1.7921, Val Loss: 1.8016, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 43, Train Loss: 1.7934, Val Loss: 1.8029, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 44, Train Loss: 1.7924, Val Loss: 1.8062, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 45, Train Loss: 1.7937, Val Loss: 1.8041, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 46, Train Loss: 1.7932, Val Loss: 1.8024, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 47, Train Loss: 1.7919, Val Loss: 1.8026, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 48, Train Loss: 1.7926, Val Loss: 1.8041, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 49, Train Loss: 1.7921, Val Loss: 1.8042, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 50, Train Loss: 1.7918, Val Loss: 1.8035, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 51, Train Loss: 1.7925, Val Loss: 1.8010, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8250, Val Loss: 1.7819, F1 Micro: 0.1979, F1 Macro: 0.0551, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7969, Val Loss: 1.7969, F1 Micro: 0.1979, F1 Macro: 0.0551, Accuracy: 0.1979\n","Epoch 3, Train Loss: 1.7916, Val Loss: 1.8040, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 4, Train Loss: 1.7904, Val Loss: 1.8093, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 5, Train Loss: 1.7905, Val Loss: 1.8137, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 6, Train Loss: 1.7924, Val Loss: 1.8122, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 7, Train Loss: 1.7906, Val Loss: 1.8149, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 8, Train Loss: 1.7923, Val Loss: 1.8207, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 9, Train Loss: 1.7904, Val Loss: 1.8158, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 10, Train Loss: 1.7907, Val Loss: 1.8164, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 11, Train Loss: 1.7909, Val Loss: 1.8101, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 12, Train Loss: 1.7913, Val Loss: 1.8125, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 13, Train Loss: 1.7908, Val Loss: 1.8134, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 14, Train Loss: 1.7940, Val Loss: 1.8192, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 15, Train Loss: 1.7920, Val Loss: 1.8120, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 16, Train Loss: 1.7907, Val Loss: 1.8205, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 17, Train Loss: 1.7906, Val Loss: 1.8191, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 18, Train Loss: 1.7904, Val Loss: 1.8148, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 19, Train Loss: 1.7901, Val Loss: 1.8177, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 20, Train Loss: 1.7909, Val Loss: 1.8180, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 21, Train Loss: 1.7921, Val Loss: 1.8129, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 22, Train Loss: 1.7909, Val Loss: 1.8169, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 23, Train Loss: 1.7918, Val Loss: 1.8133, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 24, Train Loss: 1.7895, Val Loss: 1.8177, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 25, Train Loss: 1.7919, Val Loss: 1.8102, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 26, Train Loss: 1.7924, Val Loss: 1.8226, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 27, Train Loss: 1.7902, Val Loss: 1.8144, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 28, Train Loss: 1.7909, Val Loss: 1.8171, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 29, Train Loss: 1.7912, Val Loss: 1.8171, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 30, Train Loss: 1.7903, Val Loss: 1.8159, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 31, Train Loss: 1.7927, Val Loss: 1.8151, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 32, Train Loss: 1.7910, Val Loss: 1.8182, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 33, Train Loss: 1.7906, Val Loss: 1.8135, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 34, Train Loss: 1.7907, Val Loss: 1.8150, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 35, Train Loss: 1.7917, Val Loss: 1.8156, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 36, Train Loss: 1.7898, Val Loss: 1.8148, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 37, Train Loss: 1.7906, Val Loss: 1.8160, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 38, Train Loss: 1.7915, Val Loss: 1.8122, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 39, Train Loss: 1.7914, Val Loss: 1.8080, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 40, Train Loss: 1.7912, Val Loss: 1.8135, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 41, Train Loss: 1.7908, Val Loss: 1.8135, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 42, Train Loss: 1.7913, Val Loss: 1.8193, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 43, Train Loss: 1.7906, Val Loss: 1.8121, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 44, Train Loss: 1.7909, Val Loss: 1.8171, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 45, Train Loss: 1.7907, Val Loss: 1.8165, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 46, Train Loss: 1.7902, Val Loss: 1.8155, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 47, Train Loss: 1.7909, Val Loss: 1.8152, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 48, Train Loss: 1.7904, Val Loss: 1.8164, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 49, Train Loss: 1.7911, Val Loss: 1.8152, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 50, Train Loss: 1.7922, Val Loss: 1.8183, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 51, Train Loss: 1.7907, Val Loss: 1.8125, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8408, Val Loss: 1.7969, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 2, Train Loss: 1.7970, Val Loss: 1.7932, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7933, Val Loss: 1.7936, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7939, Val Loss: 1.7941, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7939, Val Loss: 1.7948, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 6, Train Loss: 1.7930, Val Loss: 1.7950, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 7, Train Loss: 1.7939, Val Loss: 1.7941, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 8, Train Loss: 1.7926, Val Loss: 1.7966, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 9, Train Loss: 1.7929, Val Loss: 1.7953, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 10, Train Loss: 1.7939, Val Loss: 1.7942, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.7920, Val Loss: 1.7957, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 12, Train Loss: 1.7932, Val Loss: 1.7950, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 13, Train Loss: 1.7925, Val Loss: 1.7953, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 14, Train Loss: 1.7920, Val Loss: 1.7948, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 15, Train Loss: 1.7935, Val Loss: 1.7940, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 16, Train Loss: 1.7925, Val Loss: 1.7949, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 17, Train Loss: 1.7927, Val Loss: 1.7969, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 18, Train Loss: 1.7932, Val Loss: 1.7950, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 19, Train Loss: 1.7931, Val Loss: 1.7943, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 20, Train Loss: 1.7953, Val Loss: 1.7949, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 21, Train Loss: 1.7937, Val Loss: 1.7939, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 22, Train Loss: 1.7951, Val Loss: 1.7958, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 23, Train Loss: 1.7938, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 24, Train Loss: 1.7923, Val Loss: 1.7942, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 25, Train Loss: 1.7927, Val Loss: 1.7952, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 26, Train Loss: 1.7928, Val Loss: 1.7939, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 27, Train Loss: 1.7929, Val Loss: 1.7954, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 28, Train Loss: 1.7929, Val Loss: 1.7944, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 29, Train Loss: 1.7938, Val Loss: 1.7952, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 30, Train Loss: 1.7942, Val Loss: 1.7951, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 31, Train Loss: 1.7935, Val Loss: 1.7948, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 32, Train Loss: 1.7927, Val Loss: 1.7937, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 33, Train Loss: 1.7932, Val Loss: 1.7959, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 34, Train Loss: 1.7927, Val Loss: 1.7941, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 35, Train Loss: 1.7935, Val Loss: 1.7936, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 36, Train Loss: 1.7921, Val Loss: 1.7951, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 37, Train Loss: 1.7936, Val Loss: 1.7960, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 38, Train Loss: 1.7930, Val Loss: 1.7945, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 39, Train Loss: 1.7935, Val Loss: 1.7942, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 40, Train Loss: 1.7939, Val Loss: 1.7941, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 41, Train Loss: 1.7920, Val Loss: 1.7948, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 42, Train Loss: 1.7924, Val Loss: 1.7949, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 43, Train Loss: 1.7937, Val Loss: 1.7939, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 44, Train Loss: 1.7937, Val Loss: 1.7953, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 45, Train Loss: 1.7930, Val Loss: 1.7953, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 46, Train Loss: 1.7936, Val Loss: 1.7945, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 47, Train Loss: 1.7949, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 48, Train Loss: 1.7920, Val Loss: 1.7941, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 49, Train Loss: 1.7938, Val Loss: 1.7954, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 50, Train Loss: 1.7933, Val Loss: 1.7943, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 51, Train Loss: 1.7928, Val Loss: 1.7955, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 52, Train Loss: 1.7927, Val Loss: 1.7959, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 53, Train Loss: 1.7931, Val Loss: 1.7947, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 54, Train Loss: 1.7942, Val Loss: 1.7954, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 55, Train Loss: 1.7929, Val Loss: 1.7951, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 56, Train Loss: 1.7927, Val Loss: 1.7939, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8583, Val Loss: 1.7996, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.8004, Val Loss: 1.7958, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 3, Train Loss: 1.7951, Val Loss: 1.7936, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 4, Train Loss: 1.7941, Val Loss: 1.7955, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7931, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 6, Train Loss: 1.7934, Val Loss: 1.7963, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7924, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 1.7931, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 9, Train Loss: 1.7924, Val Loss: 1.7975, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 10, Train Loss: 1.7939, Val Loss: 1.7970, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 11, Train Loss: 1.7929, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 12, Train Loss: 1.7930, Val Loss: 1.7949, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 13, Train Loss: 1.7934, Val Loss: 1.7984, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 14, Train Loss: 1.7929, Val Loss: 1.7943, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 15, Train Loss: 1.7927, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 16, Train Loss: 1.7932, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 17, Train Loss: 1.7923, Val Loss: 1.7966, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 18, Train Loss: 1.7935, Val Loss: 1.7974, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 19, Train Loss: 1.7929, Val Loss: 1.7982, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 20, Train Loss: 1.7936, Val Loss: 1.7953, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 21, Train Loss: 1.7928, Val Loss: 1.7950, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 22, Train Loss: 1.7922, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 23, Train Loss: 1.7931, Val Loss: 1.7987, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 24, Train Loss: 1.7921, Val Loss: 1.7952, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 25, Train Loss: 1.7932, Val Loss: 1.7946, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 26, Train Loss: 1.7940, Val Loss: 1.7955, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 27, Train Loss: 1.7922, Val Loss: 1.7975, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 28, Train Loss: 1.7943, Val Loss: 1.7982, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 29, Train Loss: 1.7930, Val Loss: 1.7961, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 30, Train Loss: 1.7933, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 31, Train Loss: 1.7922, Val Loss: 1.7961, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 32, Train Loss: 1.7933, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 33, Train Loss: 1.7925, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 34, Train Loss: 1.7926, Val Loss: 1.7953, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 35, Train Loss: 1.7939, Val Loss: 1.7979, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 36, Train Loss: 1.7926, Val Loss: 1.7955, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 37, Train Loss: 1.7941, Val Loss: 1.7978, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 38, Train Loss: 1.7938, Val Loss: 1.7979, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 39, Train Loss: 1.7929, Val Loss: 1.7969, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 40, Train Loss: 1.7924, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 41, Train Loss: 1.7927, Val Loss: 1.7960, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 42, Train Loss: 1.7926, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 43, Train Loss: 1.7927, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 44, Train Loss: 1.7928, Val Loss: 1.7991, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 45, Train Loss: 1.7928, Val Loss: 1.7992, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 46, Train Loss: 1.7932, Val Loss: 1.7969, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 47, Train Loss: 1.7928, Val Loss: 1.7972, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 48, Train Loss: 1.7934, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 49, Train Loss: 1.7926, Val Loss: 1.7956, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 50, Train Loss: 1.7926, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 51, Train Loss: 1.7944, Val Loss: 1.7979, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 52, Train Loss: 1.7935, Val Loss: 1.7974, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 53, Train Loss: 1.7922, Val Loss: 1.7961, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 54, Train Loss: 1.7930, Val Loss: 1.7958, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.15625\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8844, Val Loss: 1.7890, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 2, Train Loss: 1.7952, Val Loss: 1.7900, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7929, Val Loss: 1.7922, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7925, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7919, Val Loss: 1.7970, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 6, Train Loss: 1.7917, Val Loss: 1.7996, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 7, Train Loss: 1.7913, Val Loss: 1.8008, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 8, Train Loss: 1.7916, Val Loss: 1.7991, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 9, Train Loss: 1.7909, Val Loss: 1.8003, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 10, Train Loss: 1.7911, Val Loss: 1.7999, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 11, Train Loss: 1.7912, Val Loss: 1.8022, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8160, Val Loss: 1.8155, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 2, Train Loss: 1.7939, Val Loss: 1.8077, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 3, Train Loss: 1.7915, Val Loss: 1.8082, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 4, Train Loss: 1.7914, Val Loss: 1.8065, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 5, Train Loss: 1.7906, Val Loss: 1.8066, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 6, Train Loss: 1.7905, Val Loss: 1.8047, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 7, Train Loss: 1.7905, Val Loss: 1.8060, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 8, Train Loss: 1.7908, Val Loss: 1.8029, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 9, Train Loss: 1.7915, Val Loss: 1.8022, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 10, Train Loss: 1.7915, Val Loss: 1.8057, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 11, Train Loss: 1.7906, Val Loss: 1.8045, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.9025, Val Loss: 1.8249, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 2, Train Loss: 1.8022, Val Loss: 1.8146, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 3, Train Loss: 1.7951, Val Loss: 1.8127, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 4, Train Loss: 1.7920, Val Loss: 1.8158, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 5, Train Loss: 1.7907, Val Loss: 1.8134, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 6, Train Loss: 1.7919, Val Loss: 1.8189, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 7, Train Loss: 1.7896, Val Loss: 1.8127, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 8, Train Loss: 1.7901, Val Loss: 1.8108, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 9, Train Loss: 1.7904, Val Loss: 1.8170, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 10, Train Loss: 1.7895, Val Loss: 1.8139, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 11, Train Loss: 1.7900, Val Loss: 1.8166, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8986, Val Loss: 1.8002, F1 Micro: 0.1771, F1 Macro: 0.0501, Accuracy: 0.1771\n","Epoch 2, Train Loss: 1.7962, Val Loss: 1.7962, F1 Micro: 0.1771, F1 Macro: 0.0501, Accuracy: 0.1771\n","Epoch 3, Train Loss: 1.7935, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7923, Val Loss: 1.7936, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 5, Train Loss: 1.7932, Val Loss: 1.7959, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 6, Train Loss: 1.7919, Val Loss: 1.7953, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7919, Val Loss: 1.7954, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 8, Train Loss: 1.7925, Val Loss: 1.7945, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 9, Train Loss: 1.7914, Val Loss: 1.7945, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 10, Train Loss: 1.7919, Val Loss: 1.7953, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.7922, Val Loss: 1.7952, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8392, Val Loss: 1.7991, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.8013, Val Loss: 1.7952, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7953, Val Loss: 1.7930, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7937, Val Loss: 1.7930, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7925, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 6, Train Loss: 1.7921, Val Loss: 1.7959, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7916, Val Loss: 1.7967, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 1.7921, Val Loss: 1.7974, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 9, Train Loss: 1.7918, Val Loss: 1.7956, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 10, Train Loss: 1.7916, Val Loss: 1.7958, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 11, Train Loss: 1.7918, Val Loss: 1.7954, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 12, Train Loss: 1.7917, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.16041666666666668\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8225, Val Loss: 1.8373, F1 Micro: 0.1250, F1 Macro: 0.0598, Accuracy: 0.1250\n","Epoch 2, Train Loss: 1.7800, Val Loss: 1.8401, F1 Micro: 0.1771, F1 Macro: 0.1177, Accuracy: 0.1771\n","Epoch 3, Train Loss: 1.7947, Val Loss: 1.8149, F1 Micro: 0.1458, F1 Macro: 0.0748, Accuracy: 0.1458\n","Epoch 4, Train Loss: 1.7769, Val Loss: 1.7431, F1 Micro: 0.2188, F1 Macro: 0.1000, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.7709, Val Loss: 1.8204, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 6, Train Loss: 1.7929, Val Loss: 1.8157, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 7, Train Loss: 1.7899, Val Loss: 1.8099, F1 Micro: 0.1354, F1 Macro: 0.0401, Accuracy: 0.1354\n","Epoch 8, Train Loss: 1.7784, Val Loss: 1.8035, F1 Micro: 0.1458, F1 Macro: 0.0732, Accuracy: 0.1458\n","Epoch 9, Train Loss: 1.7748, Val Loss: 1.8055, F1 Micro: 0.1250, F1 Macro: 0.0559, Accuracy: 0.1250\n","Epoch 10, Train Loss: 1.7655, Val Loss: 1.8122, F1 Micro: 0.1458, F1 Macro: 0.0732, Accuracy: 0.1458\n","Epoch 11, Train Loss: 1.7804, Val Loss: 1.7946, F1 Micro: 0.1458, F1 Macro: 0.0751, Accuracy: 0.1458\n","Epoch 12, Train Loss: 1.7646, Val Loss: 1.8054, F1 Micro: 0.1458, F1 Macro: 0.0819, Accuracy: 0.1458\n","Epoch 13, Train Loss: 1.7686, Val Loss: 1.8086, F1 Micro: 0.1354, F1 Macro: 0.0670, Accuracy: 0.1354\n","Epoch 14, Train Loss: 1.7710, Val Loss: 1.7980, F1 Micro: 0.1458, F1 Macro: 0.0760, Accuracy: 0.1458\n","Epoch 15, Train Loss: 1.7669, Val Loss: 1.8096, F1 Micro: 0.1250, F1 Macro: 0.0577, Accuracy: 0.1250\n","Epoch 16, Train Loss: 1.7511, Val Loss: 1.8519, F1 Micro: 0.1771, F1 Macro: 0.0909, Accuracy: 0.1771\n","Epoch 17, Train Loss: 1.7626, Val Loss: 1.8143, F1 Micro: 0.2604, F1 Macro: 0.2073, Accuracy: 0.2604\n","Epoch 18, Train Loss: 1.7620, Val Loss: 1.8154, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 19, Train Loss: 1.7579, Val Loss: 1.8178, F1 Micro: 0.1354, F1 Macro: 0.0673, Accuracy: 0.1354\n","Epoch 20, Train Loss: 1.7545, Val Loss: 1.8304, F1 Micro: 0.1562, F1 Macro: 0.0964, Accuracy: 0.1562\n","Epoch 21, Train Loss: 1.7593, Val Loss: 1.8324, F1 Micro: 0.1562, F1 Macro: 0.0800, Accuracy: 0.1562\n","Epoch 22, Train Loss: 1.7577, Val Loss: 1.8251, F1 Micro: 0.1667, F1 Macro: 0.1030, Accuracy: 0.1667\n","Epoch 23, Train Loss: 1.7556, Val Loss: 1.8654, F1 Micro: 0.2188, F1 Macro: 0.1483, Accuracy: 0.2188\n","Epoch 24, Train Loss: 1.7517, Val Loss: 1.8870, F1 Micro: 0.2396, F1 Macro: 0.1791, Accuracy: 0.2396\n","Epoch 25, Train Loss: 1.7872, Val Loss: 1.8228, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 26, Train Loss: 1.7757, Val Loss: 1.8362, F1 Micro: 0.1562, F1 Macro: 0.0919, Accuracy: 0.1562\n","Epoch 27, Train Loss: 1.7738, Val Loss: 1.8322, F1 Micro: 0.2188, F1 Macro: 0.1347, Accuracy: 0.2188\n","Epoch 28, Train Loss: 1.7598, Val Loss: 1.8796, F1 Micro: 0.2083, F1 Macro: 0.1296, Accuracy: 0.2083\n","Epoch 29, Train Loss: 1.7496, Val Loss: 1.9075, F1 Micro: 0.2500, F1 Macro: 0.1830, Accuracy: 0.2500\n","Epoch 30, Train Loss: 1.7399, Val Loss: 1.8816, F1 Micro: 0.2500, F1 Macro: 0.1857, Accuracy: 0.2500\n","Epoch 31, Train Loss: 1.7324, Val Loss: 1.8640, F1 Micro: 0.1979, F1 Macro: 0.1264, Accuracy: 0.1979\n","Epoch 32, Train Loss: 1.7488, Val Loss: 1.8340, F1 Micro: 0.1979, F1 Macro: 0.1151, Accuracy: 0.1979\n","Epoch 33, Train Loss: 1.7370, Val Loss: 1.9082, F1 Micro: 0.2083, F1 Macro: 0.1339, Accuracy: 0.2083\n","Epoch 34, Train Loss: 1.7265, Val Loss: 1.8526, F1 Micro: 0.2083, F1 Macro: 0.1379, Accuracy: 0.2083\n","Epoch 35, Train Loss: 1.7336, Val Loss: 1.8056, F1 Micro: 0.1979, F1 Macro: 0.1365, Accuracy: 0.1979\n","Epoch 36, Train Loss: 1.7407, Val Loss: 1.8084, F1 Micro: 0.1771, F1 Macro: 0.1127, Accuracy: 0.1771\n","Epoch 37, Train Loss: 1.7386, Val Loss: 1.7980, F1 Micro: 0.1875, F1 Macro: 0.1498, Accuracy: 0.1875\n","Epoch 38, Train Loss: 1.7322, Val Loss: 1.8447, F1 Micro: 0.1458, F1 Macro: 0.0471, Accuracy: 0.1458\n","Epoch 39, Train Loss: 1.7414, Val Loss: 1.8041, F1 Micro: 0.2188, F1 Macro: 0.1570, Accuracy: 0.2188\n","Epoch 40, Train Loss: 1.7283, Val Loss: 1.8455, F1 Micro: 0.2396, F1 Macro: 0.1973, Accuracy: 0.2396\n","Epoch 41, Train Loss: 1.7116, Val Loss: 1.7531, F1 Micro: 0.2188, F1 Macro: 0.1621, Accuracy: 0.2188\n","Epoch 42, Train Loss: 1.7188, Val Loss: 1.8568, F1 Micro: 0.1667, F1 Macro: 0.0866, Accuracy: 0.1667\n","Epoch 43, Train Loss: 1.7117, Val Loss: 1.7738, F1 Micro: 0.1875, F1 Macro: 0.1087, Accuracy: 0.1875\n","Epoch 44, Train Loss: 1.7235, Val Loss: 1.9060, F1 Micro: 0.2083, F1 Macro: 0.1475, Accuracy: 0.2083\n","Epoch 45, Train Loss: 1.7159, Val Loss: 1.7273, F1 Micro: 0.2396, F1 Macro: 0.1953, Accuracy: 0.2396\n","Epoch 46, Train Loss: 1.7009, Val Loss: 1.8482, F1 Micro: 0.1458, F1 Macro: 0.0462, Accuracy: 0.1458\n","Epoch 47, Train Loss: 1.6987, Val Loss: 2.0097, F1 Micro: 0.1979, F1 Macro: 0.1271, Accuracy: 0.1979\n","Epoch 48, Train Loss: 1.6773, Val Loss: 1.8078, F1 Micro: 0.1875, F1 Macro: 0.1180, Accuracy: 0.1875\n","Epoch 49, Train Loss: 1.6691, Val Loss: 1.7473, F1 Micro: 0.2188, F1 Macro: 0.1521, Accuracy: 0.2188\n","Epoch 50, Train Loss: 1.6662, Val Loss: 2.9418, F1 Micro: 0.1771, F1 Macro: 0.1277, Accuracy: 0.1771\n","Epoch 51, Train Loss: 1.7109, Val Loss: 3.6191, F1 Micro: 0.2083, F1 Macro: 0.1310, Accuracy: 0.2083\n","Epoch 52, Train Loss: 1.6866, Val Loss: 1.7321, F1 Micro: 0.1979, F1 Macro: 0.1563, Accuracy: 0.1979\n","Epoch 53, Train Loss: 1.6542, Val Loss: 1.8273, F1 Micro: 0.1458, F1 Macro: 0.0471, Accuracy: 0.1458\n","Epoch 54, Train Loss: 1.6578, Val Loss: 1.8571, F1 Micro: 0.1562, F1 Macro: 0.0455, Accuracy: 0.1562\n","Epoch 55, Train Loss: 1.6825, Val Loss: 5.1614, F1 Micro: 0.2188, F1 Macro: 0.1570, Accuracy: 0.2188\n","Epoch 56, Train Loss: 1.7242, Val Loss: 1.8471, F1 Micro: 0.1562, F1 Macro: 0.0459, Accuracy: 0.1562\n","Epoch 57, Train Loss: 1.6280, Val Loss: 1.6952, F1 Micro: 0.2292, F1 Macro: 0.2014, Accuracy: 0.2292\n","Epoch 58, Train Loss: 1.6642, Val Loss: 1.7599, F1 Micro: 0.1979, F1 Macro: 0.1433, Accuracy: 0.1979\n","Epoch 59, Train Loss: 1.6811, Val Loss: 1.8398, F1 Micro: 0.2396, F1 Macro: 0.2005, Accuracy: 0.2396\n","Epoch 60, Train Loss: 1.6429, Val Loss: 1.8268, F1 Micro: 0.1667, F1 Macro: 0.0690, Accuracy: 0.1667\n","Epoch 61, Train Loss: 1.6152, Val Loss: 2.6828, F1 Micro: 0.2188, F1 Macro: 0.1727, Accuracy: 0.2188\n","Epoch 62, Train Loss: 1.6289, Val Loss: 1.7121, F1 Micro: 0.2396, F1 Macro: 0.2145, Accuracy: 0.2396\n","Epoch 63, Train Loss: 1.6560, Val Loss: 1.8488, F1 Micro: 0.1667, F1 Macro: 0.0668, Accuracy: 0.1667\n","Epoch 64, Train Loss: 1.6714, Val Loss: 1.8521, F1 Micro: 0.1562, F1 Macro: 0.0459, Accuracy: 0.1562\n","Epoch 65, Train Loss: 1.6747, Val Loss: 1.6966, F1 Micro: 0.2396, F1 Macro: 0.1935, Accuracy: 0.2396\n","Epoch 66, Train Loss: 1.6022, Val Loss: 1.7725, F1 Micro: 0.2396, F1 Macro: 0.1851, Accuracy: 0.2396\n","Epoch 67, Train Loss: 1.6066, Val Loss: 1.8002, F1 Micro: 0.1667, F1 Macro: 0.0883, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8915, Val Loss: 1.7851, F1 Micro: 0.2396, F1 Macro: 0.1176, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7483, Val Loss: 1.7931, F1 Micro: 0.2396, F1 Macro: 0.1215, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7419, Val Loss: 1.7587, F1 Micro: 0.2396, F1 Macro: 0.1352, Accuracy: 0.2396\n","Epoch 4, Train Loss: 1.7638, Val Loss: 1.7525, F1 Micro: 0.2292, F1 Macro: 0.1212, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.7492, Val Loss: 1.9001, F1 Micro: 0.0833, F1 Macro: 0.0470, Accuracy: 0.0833\n","Epoch 6, Train Loss: 1.7516, Val Loss: 1.8485, F1 Micro: 0.1979, F1 Macro: 0.1331, Accuracy: 0.1979\n","Epoch 7, Train Loss: 1.7327, Val Loss: 1.7602, F1 Micro: 0.2188, F1 Macro: 0.1167, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.7431, Val Loss: 1.8602, F1 Micro: 0.2292, F1 Macro: 0.1363, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.7497, Val Loss: 1.7644, F1 Micro: 0.2188, F1 Macro: 0.1162, Accuracy: 0.2188\n","Epoch 10, Train Loss: 1.7440, Val Loss: 1.8024, F1 Micro: 0.2188, F1 Macro: 0.1162, Accuracy: 0.2188\n","Epoch 11, Train Loss: 1.7412, Val Loss: 1.8220, F1 Micro: 0.1771, F1 Macro: 0.0881, Accuracy: 0.1771\n","Epoch 12, Train Loss: 1.7313, Val Loss: 1.7928, F1 Micro: 0.2396, F1 Macro: 0.1215, Accuracy: 0.2396\n","Epoch 13, Train Loss: 1.7323, Val Loss: 1.8113, F1 Micro: 0.2188, F1 Macro: 0.1396, Accuracy: 0.2188\n","Epoch 14, Train Loss: 1.7295, Val Loss: 1.8566, F1 Micro: 0.0625, F1 Macro: 0.0238, Accuracy: 0.0625\n","Epoch 15, Train Loss: 1.7387, Val Loss: 1.7726, F1 Micro: 0.2188, F1 Macro: 0.1421, Accuracy: 0.2188\n","Epoch 16, Train Loss: 1.7358, Val Loss: 1.7782, F1 Micro: 0.2083, F1 Macro: 0.1072, Accuracy: 0.2083\n","Epoch 17, Train Loss: 1.7359, Val Loss: 2.2535, F1 Micro: 0.1042, F1 Macro: 0.0330, Accuracy: 0.1042\n","Epoch 18, Train Loss: 1.7149, Val Loss: 1.7840, F1 Micro: 0.2188, F1 Macro: 0.1162, Accuracy: 0.2188\n","Epoch 19, Train Loss: 1.7266, Val Loss: 1.8357, F1 Micro: 0.1250, F1 Macro: 0.0788, Accuracy: 0.1250\n","Epoch 20, Train Loss: 1.7230, Val Loss: 1.7722, F1 Micro: 0.2396, F1 Macro: 0.1215, Accuracy: 0.2396\n","Epoch 21, Train Loss: 1.7401, Val Loss: 1.8704, F1 Micro: 0.1354, F1 Macro: 0.0971, Accuracy: 0.1354\n","Epoch 22, Train Loss: 1.7318, Val Loss: 1.8681, F1 Micro: 0.1250, F1 Macro: 0.0736, Accuracy: 0.1250\n","Epoch 23, Train Loss: 1.7051, Val Loss: 1.9592, F1 Micro: 0.1146, F1 Macro: 0.0686, Accuracy: 0.1146\n","Epoch 24, Train Loss: 1.7189, Val Loss: 1.7615, F1 Micro: 0.2500, F1 Macro: 0.1415, Accuracy: 0.2500\n","Epoch 25, Train Loss: 1.7306, Val Loss: 2.4097, F1 Micro: 0.1667, F1 Macro: 0.1339, Accuracy: 0.1667\n","Epoch 26, Train Loss: 1.7283, Val Loss: 1.7473, F1 Micro: 0.2812, F1 Macro: 0.1781, Accuracy: 0.2812\n","Epoch 27, Train Loss: 1.7126, Val Loss: 1.7530, F1 Micro: 0.2604, F1 Macro: 0.1584, Accuracy: 0.2604\n","Epoch 28, Train Loss: 1.7034, Val Loss: 1.8184, F1 Micro: 0.1667, F1 Macro: 0.1312, Accuracy: 0.1667\n","Epoch 29, Train Loss: 1.7009, Val Loss: 1.7331, F1 Micro: 0.2292, F1 Macro: 0.1344, Accuracy: 0.2292\n","Epoch 30, Train Loss: 1.6959, Val Loss: 1.7361, F1 Micro: 0.1979, F1 Macro: 0.1429, Accuracy: 0.1979\n","Epoch 31, Train Loss: 1.6864, Val Loss: 1.7019, F1 Micro: 0.1979, F1 Macro: 0.1578, Accuracy: 0.1979\n","Epoch 32, Train Loss: 1.6880, Val Loss: 1.7358, F1 Micro: 0.1875, F1 Macro: 0.1355, Accuracy: 0.1875\n","Epoch 33, Train Loss: 1.6614, Val Loss: 1.9585, F1 Micro: 0.1875, F1 Macro: 0.1220, Accuracy: 0.1875\n","Epoch 34, Train Loss: 1.6840, Val Loss: 1.7225, F1 Micro: 0.1979, F1 Macro: 0.1598, Accuracy: 0.1979\n","Epoch 35, Train Loss: 1.6933, Val Loss: 1.8307, F1 Micro: 0.1458, F1 Macro: 0.0886, Accuracy: 0.1458\n","Epoch 36, Train Loss: 1.6782, Val Loss: 1.7169, F1 Micro: 0.1771, F1 Macro: 0.1201, Accuracy: 0.1771\n","Epoch 37, Train Loss: 1.6589, Val Loss: 2.8101, F1 Micro: 0.1562, F1 Macro: 0.1192, Accuracy: 0.1562\n","Epoch 38, Train Loss: 1.6654, Val Loss: 1.7148, F1 Micro: 0.1771, F1 Macro: 0.1201, Accuracy: 0.1771\n","Epoch 39, Train Loss: 1.6608, Val Loss: 1.7709, F1 Micro: 0.2188, F1 Macro: 0.1675, Accuracy: 0.2188\n","Epoch 40, Train Loss: 1.6854, Val Loss: 1.7176, F1 Micro: 0.1771, F1 Macro: 0.1208, Accuracy: 0.1771\n","Epoch 41, Train Loss: 1.6514, Val Loss: 1.7997, F1 Micro: 0.2396, F1 Macro: 0.1771, Accuracy: 0.2396\n","Epoch 42, Train Loss: 1.6465, Val Loss: 1.9387, F1 Micro: 0.1771, F1 Macro: 0.1456, Accuracy: 0.1771\n","Epoch 43, Train Loss: 1.6838, Val Loss: 1.8406, F1 Micro: 0.1979, F1 Macro: 0.1361, Accuracy: 0.1979\n","Epoch 44, Train Loss: 1.6348, Val Loss: 2.0024, F1 Micro: 0.1771, F1 Macro: 0.1355, Accuracy: 0.1771\n","Epoch 45, Train Loss: 1.6567, Val Loss: 2.0322, F1 Micro: 0.2292, F1 Macro: 0.1808, Accuracy: 0.2292\n","Epoch 46, Train Loss: 1.6734, Val Loss: 14.0154, F1 Micro: 0.1042, F1 Macro: 0.0324, Accuracy: 0.1042\n","Epoch 47, Train Loss: 1.6685, Val Loss: 1.7859, F1 Micro: 0.2083, F1 Macro: 0.1507, Accuracy: 0.2083\n","Epoch 48, Train Loss: 1.6389, Val Loss: 1.7431, F1 Micro: 0.1771, F1 Macro: 0.1161, Accuracy: 0.1771\n","Epoch 49, Train Loss: 1.6365, Val Loss: 1.7772, F1 Micro: 0.1875, F1 Macro: 0.1271, Accuracy: 0.1875\n","Epoch 50, Train Loss: 1.6419, Val Loss: 1.8554, F1 Micro: 0.2604, F1 Macro: 0.2162, Accuracy: 0.2604\n","Epoch 51, Train Loss: 1.6693, Val Loss: 1.7586, F1 Micro: 0.1979, F1 Macro: 0.1496, Accuracy: 0.1979\n","Epoch 52, Train Loss: 1.6438, Val Loss: 2.5778, F1 Micro: 0.1771, F1 Macro: 0.1461, Accuracy: 0.1771\n","Epoch 53, Train Loss: 1.6354, Val Loss: 1.8073, F1 Micro: 0.2083, F1 Macro: 0.1481, Accuracy: 0.2083\n","Epoch 54, Train Loss: 1.6398, Val Loss: 1.9228, F1 Micro: 0.2292, F1 Macro: 0.1636, Accuracy: 0.2292\n","Epoch 55, Train Loss: 1.7096, Val Loss: 1.7696, F1 Micro: 0.1562, F1 Macro: 0.0861, Accuracy: 0.1562\n","Epoch 56, Train Loss: 1.6359, Val Loss: 1.7630, F1 Micro: 0.1979, F1 Macro: 0.1529, Accuracy: 0.1979\n","Epoch 57, Train Loss: 1.6438, Val Loss: 1.9165, F1 Micro: 0.1875, F1 Macro: 0.1308, Accuracy: 0.1875\n","Epoch 58, Train Loss: 1.6422, Val Loss: 5.2700, F1 Micro: 0.1667, F1 Macro: 0.1295, Accuracy: 0.1667\n","Epoch 59, Train Loss: 1.6232, Val Loss: 2.2022, F1 Micro: 0.1771, F1 Macro: 0.1242, Accuracy: 0.1771\n","Epoch 60, Train Loss: 1.6310, Val Loss: 2.0550, F1 Micro: 0.1667, F1 Macro: 0.1345, Accuracy: 0.1667\n","Epoch 61, Train Loss: 1.6277, Val Loss: 1.8965, F1 Micro: 0.2083, F1 Macro: 0.1642, Accuracy: 0.2083\n","Epoch 62, Train Loss: 1.6218, Val Loss: 3.0866, F1 Micro: 0.1562, F1 Macro: 0.1132, Accuracy: 0.1562\n","Epoch 63, Train Loss: 1.6349, Val Loss: 1.9270, F1 Micro: 0.1875, F1 Macro: 0.1289, Accuracy: 0.1875\n","Epoch 64, Train Loss: 1.6713, Val Loss: 2.2908, F1 Micro: 0.1771, F1 Macro: 0.1610, Accuracy: 0.1771\n","Epoch 65, Train Loss: 1.6334, Val Loss: 1.7958, F1 Micro: 0.1771, F1 Macro: 0.1255, Accuracy: 0.1771\n","Epoch 66, Train Loss: 1.6139, Val Loss: 2.2880, F1 Micro: 0.1979, F1 Macro: 0.1455, Accuracy: 0.1979\n","Epoch 67, Train Loss: 1.6646, Val Loss: 1.9348, F1 Micro: 0.1562, F1 Macro: 0.1000, Accuracy: 0.1562\n","Epoch 68, Train Loss: 1.6159, Val Loss: 2.2380, F1 Micro: 0.1875, F1 Macro: 0.1557, Accuracy: 0.1875\n","Epoch 69, Train Loss: 1.6407, Val Loss: 1.8601, F1 Micro: 0.1771, F1 Macro: 0.1262, Accuracy: 0.1771\n","Epoch 70, Train Loss: 1.6114, Val Loss: 1.8652, F1 Micro: 0.1875, F1 Macro: 0.1262, Accuracy: 0.1875\n","Epoch 71, Train Loss: 1.6340, Val Loss: 1.8761, F1 Micro: 0.2083, F1 Macro: 0.1690, Accuracy: 0.2083\n","Epoch 72, Train Loss: 1.6461, Val Loss: 8.4982, F1 Micro: 0.1250, F1 Macro: 0.0729, Accuracy: 0.1250\n","Epoch 73, Train Loss: 1.6721, Val Loss: 1.9235, F1 Micro: 0.1979, F1 Macro: 0.1461, Accuracy: 0.1979\n","Epoch 74, Train Loss: 1.5873, Val Loss: 1.8194, F1 Micro: 0.1979, F1 Macro: 0.1516, Accuracy: 0.1979\n","Epoch 75, Train Loss: 1.6110, Val Loss: 1.8339, F1 Micro: 0.1875, F1 Macro: 0.1299, Accuracy: 0.1875\n","Epoch 76, Train Loss: 1.5715, Val Loss: 2.1605, F1 Micro: 0.1667, F1 Macro: 0.1290, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8606, Val Loss: 1.8407, F1 Micro: 0.0938, F1 Macro: 0.0521, Accuracy: 0.0938\n","Epoch 2, Train Loss: 1.8032, Val Loss: 1.8400, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 3, Train Loss: 1.7950, Val Loss: 1.8288, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 4, Train Loss: 1.7911, Val Loss: 1.8224, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 5, Train Loss: 1.7905, Val Loss: 1.8164, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 6, Train Loss: 1.7902, Val Loss: 1.8151, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 7, Train Loss: 1.7899, Val Loss: 1.8139, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 8, Train Loss: 1.7895, Val Loss: 1.8143, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 9, Train Loss: 1.7898, Val Loss: 1.8161, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 10, Train Loss: 1.7906, Val Loss: 1.8171, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 11, Train Loss: 1.7897, Val Loss: 1.8164, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 12, Train Loss: 1.7891, Val Loss: 1.8170, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 13, Train Loss: 1.7894, Val Loss: 1.8171, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 14, Train Loss: 1.7896, Val Loss: 1.8193, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 15, Train Loss: 1.7905, Val Loss: 1.8124, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 16, Train Loss: 1.7894, Val Loss: 1.8139, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 17, Train Loss: 1.7897, Val Loss: 1.8162, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 18, Train Loss: 1.7893, Val Loss: 1.8148, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 19, Train Loss: 1.7904, Val Loss: 1.8114, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 20, Train Loss: 1.7897, Val Loss: 1.8156, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 21, Train Loss: 1.7895, Val Loss: 1.8155, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 22, Train Loss: 1.7894, Val Loss: 1.8161, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 23, Train Loss: 1.7899, Val Loss: 1.8150, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 24, Train Loss: 1.7896, Val Loss: 1.8191, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 25, Train Loss: 1.7902, Val Loss: 1.8122, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 26, Train Loss: 1.7901, Val Loss: 1.8158, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 27, Train Loss: 1.7898, Val Loss: 1.8179, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 28, Train Loss: 1.7895, Val Loss: 1.8147, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 29, Train Loss: 1.7895, Val Loss: 1.8174, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 30, Train Loss: 1.7900, Val Loss: 1.8130, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 31, Train Loss: 1.7901, Val Loss: 1.8147, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 32, Train Loss: 1.7903, Val Loss: 1.8151, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 33, Train Loss: 1.7894, Val Loss: 1.8152, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 34, Train Loss: 1.7897, Val Loss: 1.8164, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 35, Train Loss: 1.7902, Val Loss: 1.8192, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 36, Train Loss: 1.7907, Val Loss: 1.8172, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 37, Train Loss: 1.7901, Val Loss: 1.8163, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 38, Train Loss: 1.7897, Val Loss: 1.8146, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 39, Train Loss: 1.7905, Val Loss: 1.8120, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 40, Train Loss: 1.7907, Val Loss: 1.8171, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 41, Train Loss: 1.7896, Val Loss: 1.8144, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 42, Train Loss: 1.7898, Val Loss: 1.8144, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 43, Train Loss: 1.7894, Val Loss: 1.8132, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 44, Train Loss: 1.7899, Val Loss: 1.8181, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 45, Train Loss: 1.7902, Val Loss: 1.8168, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 46, Train Loss: 1.7893, Val Loss: 1.8146, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 47, Train Loss: 1.7902, Val Loss: 1.8166, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 48, Train Loss: 1.7900, Val Loss: 1.8154, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 49, Train Loss: 1.7907, Val Loss: 1.8144, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 50, Train Loss: 1.7901, Val Loss: 1.8166, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 51, Train Loss: 1.7896, Val Loss: 1.8130, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 52, Train Loss: 1.7905, Val Loss: 1.8178, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 53, Train Loss: 1.7904, Val Loss: 1.8146, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 54, Train Loss: 1.7903, Val Loss: 1.8180, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 55, Train Loss: 1.7896, Val Loss: 1.8140, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 56, Train Loss: 1.7891, Val Loss: 1.8158, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 57, Train Loss: 1.7896, Val Loss: 1.8141, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 58, Train Loss: 1.7898, Val Loss: 1.8131, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 59, Train Loss: 1.7904, Val Loss: 1.8139, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 60, Train Loss: 1.7895, Val Loss: 1.8191, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 61, Train Loss: 1.7896, Val Loss: 1.8164, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 62, Train Loss: 1.7897, Val Loss: 1.8146, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 63, Train Loss: 1.7891, Val Loss: 1.8149, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 64, Train Loss: 1.7907, Val Loss: 1.8133, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 65, Train Loss: 1.7896, Val Loss: 1.8163, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 66, Train Loss: 1.7894, Val Loss: 1.8161, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 67, Train Loss: 1.7898, Val Loss: 1.8193, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 68, Train Loss: 1.7895, Val Loss: 1.8195, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 69, Train Loss: 1.7899, Val Loss: 1.8139, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 70, Train Loss: 1.7899, Val Loss: 1.8131, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 71, Train Loss: 1.7895, Val Loss: 1.8143, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 72, Train Loss: 1.7892, Val Loss: 1.8153, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 73, Train Loss: 1.7894, Val Loss: 1.8149, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 74, Train Loss: 1.7908, Val Loss: 1.8161, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 75, Train Loss: 1.7893, Val Loss: 1.8159, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 76, Train Loss: 1.7894, Val Loss: 1.8166, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 77, Train Loss: 1.7894, Val Loss: 1.8160, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 78, Train Loss: 1.7902, Val Loss: 1.8127, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 79, Train Loss: 1.7903, Val Loss: 1.8191, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 80, Train Loss: 1.7898, Val Loss: 1.8132, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 81, Train Loss: 1.7903, Val Loss: 1.8146, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 82, Train Loss: 1.7897, Val Loss: 1.8160, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 83, Train Loss: 1.7906, Val Loss: 1.8212, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 84, Train Loss: 1.7892, Val Loss: 1.8157, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 85, Train Loss: 1.7897, Val Loss: 1.8132, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 86, Train Loss: 1.7895, Val Loss: 1.8162, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 87, Train Loss: 1.7897, Val Loss: 1.8161, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 88, Train Loss: 1.7896, Val Loss: 1.8136, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Epoch 89, Train Loss: 1.7896, Val Loss: 1.8156, F1 Micro: 0.0729, F1 Macro: 0.0227, Accuracy: 0.0729\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8413, Val Loss: 1.7968, F1 Micro: 0.1875, F1 Macro: 0.0531, Accuracy: 0.1875\n","Epoch 2, Train Loss: 1.8085, Val Loss: 1.7910, F1 Micro: 0.1667, F1 Macro: 0.0494, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.7951, Val Loss: 1.7811, F1 Micro: 0.1771, F1 Macro: 0.0652, Accuracy: 0.1771\n","Epoch 4, Train Loss: 1.7921, Val Loss: 1.8247, F1 Micro: 0.1771, F1 Macro: 0.0520, Accuracy: 0.1771\n","Epoch 5, Train Loss: 1.7800, Val Loss: 1.7961, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 6, Train Loss: 1.7701, Val Loss: 1.7615, F1 Micro: 0.1979, F1 Macro: 0.1060, Accuracy: 0.1979\n","Epoch 7, Train Loss: 1.7639, Val Loss: 1.7799, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 8, Train Loss: 1.7850, Val Loss: 1.7911, F1 Micro: 0.1771, F1 Macro: 0.0681, Accuracy: 0.1771\n","Epoch 9, Train Loss: 1.7848, Val Loss: 1.7854, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 10, Train Loss: 1.7633, Val Loss: 1.7926, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.7852, Val Loss: 1.7931, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 12, Train Loss: 1.7804, Val Loss: 1.7932, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 13, Train Loss: 1.7812, Val Loss: 1.7929, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 14, Train Loss: 1.7795, Val Loss: 1.7938, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 15, Train Loss: 1.7821, Val Loss: 1.7948, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 16, Train Loss: 1.7967, Val Loss: 1.7872, F1 Micro: 0.1562, F1 Macro: 0.0624, Accuracy: 0.1562\n","Epoch 17, Train Loss: 1.7893, Val Loss: 1.7928, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 18, Train Loss: 1.7818, Val Loss: 1.7930, F1 Micro: 0.1667, F1 Macro: 0.0651, Accuracy: 0.1667\n","Epoch 19, Train Loss: 1.7626, Val Loss: 1.7770, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 20, Train Loss: 1.7519, Val Loss: 1.7809, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 21, Train Loss: 1.7351, Val Loss: 1.7900, F1 Micro: 0.1771, F1 Macro: 0.1039, Accuracy: 0.1771\n","Epoch 22, Train Loss: 1.7289, Val Loss: 1.7827, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 23, Train Loss: 1.7381, Val Loss: 1.7903, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 24, Train Loss: 1.7351, Val Loss: 1.7819, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 25, Train Loss: 1.7176, Val Loss: 1.7857, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 26, Train Loss: 1.7294, Val Loss: 1.7944, F1 Micro: 0.1562, F1 Macro: 0.0476, Accuracy: 0.1562\n","Epoch 27, Train Loss: 1.7322, Val Loss: 1.7910, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 28, Train Loss: 1.7329, Val Loss: 1.7885, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 29, Train Loss: 1.7314, Val Loss: 1.7883, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 30, Train Loss: 1.7199, Val Loss: 1.7934, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 31, Train Loss: 1.7245, Val Loss: 1.7881, F1 Micro: 0.1875, F1 Macro: 0.0952, Accuracy: 0.1875\n","Epoch 32, Train Loss: 1.7306, Val Loss: 1.7928, F1 Micro: 0.1875, F1 Macro: 0.0952, Accuracy: 0.1875\n","Epoch 33, Train Loss: 1.7208, Val Loss: 1.7925, F1 Micro: 0.1771, F1 Macro: 0.0899, Accuracy: 0.1771\n","Epoch 34, Train Loss: 1.7075, Val Loss: 1.7902, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 35, Train Loss: 1.7311, Val Loss: 1.7941, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 36, Train Loss: 1.7436, Val Loss: 1.7889, F1 Micro: 0.1979, F1 Macro: 0.1148, Accuracy: 0.1979\n","Epoch 37, Train Loss: 1.7157, Val Loss: 1.8006, F1 Micro: 0.1979, F1 Macro: 0.1242, Accuracy: 0.1979\n","Epoch 38, Train Loss: 1.7215, Val Loss: 1.7906, F1 Micro: 0.1979, F1 Macro: 0.1148, Accuracy: 0.1979\n","Epoch 39, Train Loss: 1.7201, Val Loss: 1.7876, F1 Micro: 0.1667, F1 Macro: 0.1043, Accuracy: 0.1667\n","Epoch 40, Train Loss: 1.7302, Val Loss: 1.7878, F1 Micro: 0.1979, F1 Macro: 0.1148, Accuracy: 0.1979\n","Epoch 41, Train Loss: 1.7138, Val Loss: 1.7799, F1 Micro: 0.2188, F1 Macro: 0.1884, Accuracy: 0.2188\n","Epoch 42, Train Loss: 1.7058, Val Loss: 1.7962, F1 Micro: 0.1979, F1 Macro: 0.1481, Accuracy: 0.1979\n","Epoch 43, Train Loss: 1.7143, Val Loss: 1.7956, F1 Micro: 0.1979, F1 Macro: 0.1128, Accuracy: 0.1979\n","Epoch 44, Train Loss: 1.7056, Val Loss: 1.7892, F1 Micro: 0.2083, F1 Macro: 0.1587, Accuracy: 0.2083\n","Epoch 45, Train Loss: 1.7320, Val Loss: 1.7893, F1 Micro: 0.2083, F1 Macro: 0.1249, Accuracy: 0.2083\n","Epoch 46, Train Loss: 1.7223, Val Loss: 1.8013, F1 Micro: 0.1771, F1 Macro: 0.0943, Accuracy: 0.1771\n","Epoch 47, Train Loss: 1.7132, Val Loss: 1.7865, F1 Micro: 0.1875, F1 Macro: 0.0940, Accuracy: 0.1875\n","Epoch 48, Train Loss: 1.7081, Val Loss: 1.8006, F1 Micro: 0.1875, F1 Macro: 0.1046, Accuracy: 0.1875\n","Epoch 49, Train Loss: 1.7118, Val Loss: 1.7993, F1 Micro: 0.1771, F1 Macro: 0.0921, Accuracy: 0.1771\n","Epoch 50, Train Loss: 1.7109, Val Loss: 1.8078, F1 Micro: 0.1875, F1 Macro: 0.0948, Accuracy: 0.1875\n","Epoch 51, Train Loss: 1.7036, Val Loss: 1.7967, F1 Micro: 0.1979, F1 Macro: 0.1222, Accuracy: 0.1979\n","Epoch 52, Train Loss: 1.7112, Val Loss: 1.7942, F1 Micro: 0.1875, F1 Macro: 0.0976, Accuracy: 0.1875\n","Epoch 53, Train Loss: 1.7024, Val Loss: 1.7879, F1 Micro: 0.1979, F1 Macro: 0.1128, Accuracy: 0.1979\n","Epoch 54, Train Loss: 1.7017, Val Loss: 1.7941, F1 Micro: 0.1875, F1 Macro: 0.1403, Accuracy: 0.1875\n","Epoch 55, Train Loss: 1.6981, Val Loss: 1.8112, F1 Micro: 0.2292, F1 Macro: 0.1685, Accuracy: 0.2292\n","Epoch 56, Train Loss: 1.6875, Val Loss: 1.7741, F1 Micro: 0.1979, F1 Macro: 0.1204, Accuracy: 0.1979\n","Epoch 57, Train Loss: 1.7205, Val Loss: 1.7727, F1 Micro: 0.1875, F1 Macro: 0.1529, Accuracy: 0.1875\n","Epoch 58, Train Loss: 1.7007, Val Loss: 1.7659, F1 Micro: 0.1875, F1 Macro: 0.1331, Accuracy: 0.1875\n","Epoch 59, Train Loss: 1.6738, Val Loss: 1.7669, F1 Micro: 0.1667, F1 Macro: 0.1244, Accuracy: 0.1667\n","Epoch 60, Train Loss: 1.7087, Val Loss: 1.8033, F1 Micro: 0.1979, F1 Macro: 0.1290, Accuracy: 0.1979\n","Epoch 61, Train Loss: 1.6982, Val Loss: 1.7876, F1 Micro: 0.2083, F1 Macro: 0.1338, Accuracy: 0.2083\n","Epoch 62, Train Loss: 1.6855, Val Loss: 1.7976, F1 Micro: 0.2083, F1 Macro: 0.1472, Accuracy: 0.2083\n","Epoch 63, Train Loss: 1.6993, Val Loss: 1.8010, F1 Micro: 0.2083, F1 Macro: 0.1771, Accuracy: 0.2083\n","Epoch 64, Train Loss: 1.6690, Val Loss: 1.7851, F1 Micro: 0.1667, F1 Macro: 0.1149, Accuracy: 0.1667\n","Epoch 65, Train Loss: 1.6719, Val Loss: 1.7862, F1 Micro: 0.1875, F1 Macro: 0.1403, Accuracy: 0.1875\n","Epoch 66, Train Loss: 1.6831, Val Loss: 1.7870, F1 Micro: 0.1667, F1 Macro: 0.1238, Accuracy: 0.1667\n","Epoch 67, Train Loss: 1.7036, Val Loss: 1.8114, F1 Micro: 0.1771, F1 Macro: 0.0713, Accuracy: 0.1771\n","Epoch 68, Train Loss: 1.7084, Val Loss: 1.8223, F1 Micro: 0.1771, F1 Macro: 0.0938, Accuracy: 0.1771\n","Epoch 69, Train Loss: 1.6908, Val Loss: 1.7918, F1 Micro: 0.1771, F1 Macro: 0.1260, Accuracy: 0.1771\n","Epoch 70, Train Loss: 1.6827, Val Loss: 2.0227, F1 Micro: 0.2188, F1 Macro: 0.1673, Accuracy: 0.2188\n","Epoch 71, Train Loss: 1.6696, Val Loss: 2.2038, F1 Micro: 0.2292, F1 Macro: 0.1519, Accuracy: 0.2292\n","Epoch 72, Train Loss: 1.6676, Val Loss: 1.8147, F1 Micro: 0.1771, F1 Macro: 0.1097, Accuracy: 0.1771\n","Epoch 73, Train Loss: 1.6798, Val Loss: 1.8390, F1 Micro: 0.1771, F1 Macro: 0.0874, Accuracy: 0.1771\n","Epoch 74, Train Loss: 1.6803, Val Loss: 1.8419, F1 Micro: 0.1771, F1 Macro: 0.1079, Accuracy: 0.1771\n","Epoch 75, Train Loss: 1.6977, Val Loss: 1.8211, F1 Micro: 0.2188, F1 Macro: 0.1692, Accuracy: 0.2188\n","Epoch 76, Train Loss: 1.6684, Val Loss: 2.3945, F1 Micro: 0.1979, F1 Macro: 0.1131, Accuracy: 0.1979\n","Epoch 77, Train Loss: 1.6426, Val Loss: 1.8237, F1 Micro: 0.2188, F1 Macro: 0.1487, Accuracy: 0.2188\n","Epoch 78, Train Loss: 1.7184, Val Loss: 1.7957, F1 Micro: 0.1979, F1 Macro: 0.0999, Accuracy: 0.1979\n","Epoch 79, Train Loss: 1.6678, Val Loss: 2.0374, F1 Micro: 0.2188, F1 Macro: 0.2019, Accuracy: 0.2188\n","Epoch 80, Train Loss: 1.6390, Val Loss: 1.7930, F1 Micro: 0.2292, F1 Macro: 0.1703, Accuracy: 0.2292\n","Epoch 81, Train Loss: 1.6559, Val Loss: 1.8329, F1 Micro: 0.2292, F1 Macro: 0.1924, Accuracy: 0.2292\n","Epoch 82, Train Loss: 1.6429, Val Loss: 1.7774, F1 Micro: 0.2188, F1 Macro: 0.1629, Accuracy: 0.2188\n","Epoch 83, Train Loss: 1.6268, Val Loss: 1.8417, F1 Micro: 0.2083, F1 Macro: 0.1344, Accuracy: 0.2083\n","Epoch 84, Train Loss: 1.6466, Val Loss: 2.0700, F1 Micro: 0.2604, F1 Macro: 0.2279, Accuracy: 0.2604\n","Epoch 85, Train Loss: 1.6284, Val Loss: 1.8338, F1 Micro: 0.1875, F1 Macro: 0.0891, Accuracy: 0.1875\n","Epoch 86, Train Loss: 1.6053, Val Loss: 4.8195, F1 Micro: 0.1875, F1 Macro: 0.1236, Accuracy: 0.1875\n","Epoch 87, Train Loss: 1.6180, Val Loss: 1.8024, F1 Micro: 0.2188, F1 Macro: 0.1420, Accuracy: 0.2188\n","Epoch 88, Train Loss: 1.6661, Val Loss: 1.8481, F1 Micro: 0.1875, F1 Macro: 0.0870, Accuracy: 0.1875\n","Epoch 89, Train Loss: 1.6728, Val Loss: 2.0336, F1 Micro: 0.2188, F1 Macro: 0.2008, Accuracy: 0.2188\n","Epoch 90, Train Loss: 1.6212, Val Loss: 1.7956, F1 Micro: 0.2292, F1 Macro: 0.1604, Accuracy: 0.2292\n","Epoch 91, Train Loss: 1.6165, Val Loss: 1.8429, F1 Micro: 0.2188, F1 Macro: 0.1675, Accuracy: 0.2188\n","Epoch 92, Train Loss: 1.6259, Val Loss: 1.8399, F1 Micro: 0.1875, F1 Macro: 0.0903, Accuracy: 0.1875\n","Epoch 93, Train Loss: 1.6391, Val Loss: 1.9464, F1 Micro: 0.2083, F1 Macro: 0.1574, Accuracy: 0.2083\n","Epoch 94, Train Loss: 1.6261, Val Loss: 1.8975, F1 Micro: 0.2188, F1 Macro: 0.1640, Accuracy: 0.2188\n","Epoch 95, Train Loss: 1.6110, Val Loss: 1.9056, F1 Micro: 0.2083, F1 Macro: 0.1838, Accuracy: 0.2083\n","Epoch 96, Train Loss: 1.6432, Val Loss: 2.0038, F1 Micro: 0.1979, F1 Macro: 0.1814, Accuracy: 0.1979\n","Epoch 97, Train Loss: 1.7708, Val Loss: 1.8892, F1 Micro: 0.2188, F1 Macro: 0.1782, Accuracy: 0.2188\n","Epoch 98, Train Loss: 1.7404, Val Loss: 1.7901, F1 Micro: 0.1875, F1 Macro: 0.0683, Accuracy: 0.1875\n","Epoch 99, Train Loss: 1.7610, Val Loss: 2.2585, F1 Micro: 0.1875, F1 Macro: 0.1393, Accuracy: 0.1875\n","Epoch 100, Train Loss: 1.7568, Val Loss: 1.7947, F1 Micro: 0.1771, F1 Macro: 0.0511, Accuracy: 0.1771\n","Epoch 101, Train Loss: 1.7464, Val Loss: 1.7487, F1 Micro: 0.2083, F1 Macro: 0.1463, Accuracy: 0.2083\n","Epoch 102, Train Loss: 1.7269, Val Loss: 1.7881, F1 Micro: 0.2292, F1 Macro: 0.1879, Accuracy: 0.2292\n","Epoch 103, Train Loss: 1.7188, Val Loss: 1.7596, F1 Micro: 0.1875, F1 Macro: 0.1491, Accuracy: 0.1875\n","Epoch 104, Train Loss: 1.7159, Val Loss: 1.7392, F1 Micro: 0.2604, F1 Macro: 0.2090, Accuracy: 0.2604\n","Epoch 105, Train Loss: 1.7088, Val Loss: 1.7718, F1 Micro: 0.2292, F1 Macro: 0.1799, Accuracy: 0.2292\n","Epoch 106, Train Loss: 1.7067, Val Loss: 1.8058, F1 Micro: 0.1562, F1 Macro: 0.0467, Accuracy: 0.1562\n","Epoch 107, Train Loss: 1.6751, Val Loss: 1.8053, F1 Micro: 0.2396, F1 Macro: 0.1917, Accuracy: 0.2396\n","Epoch 108, Train Loss: 1.6281, Val Loss: 1.7845, F1 Micro: 0.2188, F1 Macro: 0.1615, Accuracy: 0.2188\n","Epoch 109, Train Loss: 1.6114, Val Loss: 1.8256, F1 Micro: 0.1979, F1 Macro: 0.1223, Accuracy: 0.1979\n","Epoch 110, Train Loss: 1.6130, Val Loss: 1.8482, F1 Micro: 0.2188, F1 Macro: 0.1833, Accuracy: 0.2188\n","Epoch 111, Train Loss: 1.6185, Val Loss: 1.7728, F1 Micro: 0.2604, F1 Macro: 0.2146, Accuracy: 0.2604\n","Epoch 112, Train Loss: 1.6281, Val Loss: 1.8960, F1 Micro: 0.1875, F1 Macro: 0.1043, Accuracy: 0.1875\n","Epoch 113, Train Loss: 1.6193, Val Loss: 1.8324, F1 Micro: 0.2292, F1 Macro: 0.1754, Accuracy: 0.2292\n","Epoch 114, Train Loss: 1.6285, Val Loss: 1.8101, F1 Micro: 0.2292, F1 Macro: 0.1727, Accuracy: 0.2292\n","Epoch 115, Train Loss: 1.6098, Val Loss: 1.8228, F1 Micro: 0.1979, F1 Macro: 0.1072, Accuracy: 0.1979\n","Epoch 116, Train Loss: 1.5992, Val Loss: 1.8764, F1 Micro: 0.2500, F1 Macro: 0.2093, Accuracy: 0.2500\n","Epoch 117, Train Loss: 1.5947, Val Loss: 1.8365, F1 Micro: 0.2292, F1 Macro: 0.1819, Accuracy: 0.2292\n","Epoch 118, Train Loss: 1.6072, Val Loss: 1.8236, F1 Micro: 0.1875, F1 Macro: 0.0897, Accuracy: 0.1875\n","Epoch 119, Train Loss: 1.6138, Val Loss: 2.0905, F1 Micro: 0.1771, F1 Macro: 0.1478, Accuracy: 0.1771\n","Epoch 120, Train Loss: 1.5848, Val Loss: 1.7886, F1 Micro: 0.2188, F1 Macro: 0.1850, Accuracy: 0.2188\n","Epoch 121, Train Loss: 1.5735, Val Loss: 1.8579, F1 Micro: 0.1875, F1 Macro: 0.0872, Accuracy: 0.1875\n","Epoch 122, Train Loss: 1.5857, Val Loss: 1.8190, F1 Micro: 0.2188, F1 Macro: 0.1748, Accuracy: 0.2188\n","Epoch 123, Train Loss: 1.5818, Val Loss: 3.9405, F1 Micro: 0.1979, F1 Macro: 0.1533, Accuracy: 0.1979\n","Epoch 124, Train Loss: 1.6728, Val Loss: 1.9361, F1 Micro: 0.1875, F1 Macro: 0.1045, Accuracy: 0.1875\n","Epoch 125, Train Loss: 1.5980, Val Loss: 1.8980, F1 Micro: 0.1667, F1 Macro: 0.0984, Accuracy: 0.1667\n","Epoch 126, Train Loss: 1.6007, Val Loss: 1.8487, F1 Micro: 0.1979, F1 Macro: 0.1270, Accuracy: 0.1979\n","Epoch 127, Train Loss: 1.5886, Val Loss: 1.8400, F1 Micro: 0.2500, F1 Macro: 0.1874, Accuracy: 0.2500\n","Epoch 128, Train Loss: 1.5601, Val Loss: 1.8954, F1 Micro: 0.2188, F1 Macro: 0.1492, Accuracy: 0.2188\n","Epoch 129, Train Loss: 1.5751, Val Loss: 1.8603, F1 Micro: 0.2188, F1 Macro: 0.1614, Accuracy: 0.2188\n","Epoch 130, Train Loss: 1.5731, Val Loss: 1.7764, F1 Micro: 0.2292, F1 Macro: 0.1662, Accuracy: 0.2292\n","Epoch 131, Train Loss: 1.5954, Val Loss: 2.0283, F1 Micro: 0.2083, F1 Macro: 0.1613, Accuracy: 0.2083\n","Epoch 132, Train Loss: 1.6128, Val Loss: 1.7545, F1 Micro: 0.2292, F1 Macro: 0.1525, Accuracy: 0.2292\n","Epoch 133, Train Loss: 1.5516, Val Loss: 1.7867, F1 Micro: 0.2292, F1 Macro: 0.1583, Accuracy: 0.2292\n","Epoch 134, Train Loss: 1.5716, Val Loss: 1.8453, F1 Micro: 0.2188, F1 Macro: 0.1549, Accuracy: 0.2188\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8104, Val Loss: 1.8179, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 2, Train Loss: 1.7966, Val Loss: 1.8092, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7947, Val Loss: 1.8047, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 4, Train Loss: 1.7927, Val Loss: 1.8024, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 5, Train Loss: 1.7925, Val Loss: 1.7985, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 6, Train Loss: 1.7915, Val Loss: 1.7990, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 1.7919, Val Loss: 1.7980, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 1.7912, Val Loss: 1.7975, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 9, Train Loss: 1.7898, Val Loss: 1.7997, F1 Micro: 0.1562, F1 Macro: 0.0455, Accuracy: 0.1562\n","Epoch 10, Train Loss: 1.7919, Val Loss: 1.7995, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 11, Train Loss: 1.7915, Val Loss: 1.7984, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 12, Train Loss: 1.7915, Val Loss: 1.7972, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 13, Train Loss: 1.7913, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 14, Train Loss: 1.7914, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 15, Train Loss: 1.7916, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 16, Train Loss: 1.7902, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 17, Train Loss: 1.7907, Val Loss: 1.7974, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 18, Train Loss: 1.7898, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 19, Train Loss: 1.7903, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 20, Train Loss: 1.7876, Val Loss: 1.7967, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 21, Train Loss: 1.7877, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 22, Train Loss: 1.7947, Val Loss: 1.7968, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 23, Train Loss: 1.7898, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 24, Train Loss: 1.7886, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 25, Train Loss: 1.7884, Val Loss: 1.7963, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 26, Train Loss: 1.7889, Val Loss: 1.7969, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 27, Train Loss: 1.7882, Val Loss: 1.7950, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 28, Train Loss: 1.7878, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 29, Train Loss: 1.7880, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 30, Train Loss: 1.7869, Val Loss: 1.7977, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 31, Train Loss: 1.7873, Val Loss: 1.7973, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 32, Train Loss: 1.7872, Val Loss: 1.7959, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 33, Train Loss: 1.7874, Val Loss: 1.7957, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 34, Train Loss: 1.7869, Val Loss: 1.7956, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 35, Train Loss: 1.7883, Val Loss: 1.7974, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 36, Train Loss: 1.7872, Val Loss: 1.7974, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 37, Train Loss: 1.7878, Val Loss: 1.7965, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 38, Train Loss: 1.7870, Val Loss: 1.7962, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 39, Train Loss: 1.7870, Val Loss: 1.7951, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 40, Train Loss: 1.7873, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 41, Train Loss: 1.7875, Val Loss: 1.7952, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 42, Train Loss: 1.7872, Val Loss: 1.7954, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 43, Train Loss: 1.7870, Val Loss: 1.7967, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 44, Train Loss: 1.7869, Val Loss: 1.7970, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 45, Train Loss: 1.7872, Val Loss: 1.7961, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 46, Train Loss: 1.7872, Val Loss: 1.7964, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 47, Train Loss: 1.7889, Val Loss: 1.7971, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 48, Train Loss: 1.7873, Val Loss: 1.7949, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 49, Train Loss: 1.7871, Val Loss: 1.7952, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 50, Train Loss: 1.7872, Val Loss: 1.7954, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 51, Train Loss: 1.7876, Val Loss: 1.7983, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.22083333333333335\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.7942, Val Loss: 1.7192, F1 Micro: 0.2812, F1 Macro: 0.1764, Accuracy: 0.2812\n","Epoch 2, Train Loss: 1.7683, Val Loss: 1.7781, F1 Micro: 0.2500, F1 Macro: 0.2030, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.7455, Val Loss: 1.7430, F1 Micro: 0.2083, F1 Macro: 0.1595, Accuracy: 0.2083\n","Epoch 4, Train Loss: 1.7547, Val Loss: 1.7628, F1 Micro: 0.2188, F1 Macro: 0.1626, Accuracy: 0.2188\n","Epoch 5, Train Loss: 1.7438, Val Loss: 1.7553, F1 Micro: 0.2292, F1 Macro: 0.1692, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.7456, Val Loss: 1.7564, F1 Micro: 0.2188, F1 Macro: 0.1615, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.7280, Val Loss: 1.7597, F1 Micro: 0.2396, F1 Macro: 0.1799, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.7349, Val Loss: 1.7757, F1 Micro: 0.2292, F1 Macro: 0.1687, Accuracy: 0.2292\n","Epoch 9, Train Loss: 1.7325, Val Loss: 1.7555, F1 Micro: 0.2188, F1 Macro: 0.1621, Accuracy: 0.2188\n","Epoch 10, Train Loss: 1.7235, Val Loss: 1.7575, F1 Micro: 0.2396, F1 Macro: 0.1774, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.7237, Val Loss: 1.7547, F1 Micro: 0.2396, F1 Macro: 0.1746, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8111, Val Loss: 1.8261, F1 Micro: 0.1771, F1 Macro: 0.0550, Accuracy: 0.1771\n","Epoch 2, Train Loss: 1.7702, Val Loss: 1.8637, F1 Micro: 0.2500, F1 Macro: 0.1726, Accuracy: 0.2500\n","Epoch 3, Train Loss: 1.7866, Val Loss: 1.8214, F1 Micro: 0.2396, F1 Macro: 0.1465, Accuracy: 0.2396\n","Epoch 4, Train Loss: 1.7707, Val Loss: 1.8365, F1 Micro: 0.2500, F1 Macro: 0.1573, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.7517, Val Loss: 1.9667, F1 Micro: 0.2604, F1 Macro: 0.1908, Accuracy: 0.2604\n","Epoch 6, Train Loss: 1.7150, Val Loss: 1.8612, F1 Micro: 0.2604, F1 Macro: 0.1851, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.7000, Val Loss: 2.0674, F1 Micro: 0.2083, F1 Macro: 0.1743, Accuracy: 0.2083\n","Epoch 8, Train Loss: 1.6910, Val Loss: 1.8064, F1 Micro: 0.3229, F1 Macro: 0.2750, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.7071, Val Loss: 1.7527, F1 Micro: 0.2812, F1 Macro: 0.2307, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.6809, Val Loss: 1.7214, F1 Micro: 0.3229, F1 Macro: 0.2832, Accuracy: 0.3229\n","Epoch 11, Train Loss: 1.6784, Val Loss: 1.7781, F1 Micro: 0.3854, F1 Macro: 0.3221, Accuracy: 0.3854\n","Epoch 12, Train Loss: 1.6891, Val Loss: 1.7783, F1 Micro: 0.2812, F1 Macro: 0.2275, Accuracy: 0.2812\n","Epoch 13, Train Loss: 1.6727, Val Loss: 1.7629, F1 Micro: 0.3750, F1 Macro: 0.3402, Accuracy: 0.3750\n","Epoch 14, Train Loss: 1.6518, Val Loss: 1.7180, F1 Micro: 0.2812, F1 Macro: 0.2300, Accuracy: 0.2812\n","Epoch 15, Train Loss: 1.6431, Val Loss: 1.7547, F1 Micro: 0.3333, F1 Macro: 0.2917, Accuracy: 0.3333\n","Epoch 16, Train Loss: 1.6280, Val Loss: 1.7625, F1 Micro: 0.3542, F1 Macro: 0.3140, Accuracy: 0.3542\n","Epoch 17, Train Loss: 1.6194, Val Loss: 1.6793, F1 Micro: 0.3438, F1 Macro: 0.3121, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.6225, Val Loss: 1.6859, F1 Micro: 0.2812, F1 Macro: 0.2486, Accuracy: 0.2812\n","Epoch 19, Train Loss: 1.6436, Val Loss: 1.8269, F1 Micro: 0.2188, F1 Macro: 0.1808, Accuracy: 0.2188\n","Epoch 20, Train Loss: 1.6004, Val Loss: 1.7707, F1 Micro: 0.3229, F1 Macro: 0.2927, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.6005, Val Loss: 1.7207, F1 Micro: 0.3542, F1 Macro: 0.3260, Accuracy: 0.3542\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8161, Val Loss: 1.7808, F1 Micro: 0.1979, F1 Macro: 0.0970, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7715, Val Loss: 1.7758, F1 Micro: 0.2188, F1 Macro: 0.1432, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7499, Val Loss: 1.7712, F1 Micro: 0.2812, F1 Macro: 0.1882, Accuracy: 0.2812\n","Epoch 4, Train Loss: 1.7369, Val Loss: 1.8279, F1 Micro: 0.1667, F1 Macro: 0.1330, Accuracy: 0.1667\n","Epoch 5, Train Loss: 1.7525, Val Loss: 1.7813, F1 Micro: 0.2292, F1 Macro: 0.1610, Accuracy: 0.2292\n","Epoch 6, Train Loss: 1.7182, Val Loss: 1.7657, F1 Micro: 0.2292, F1 Macro: 0.1294, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.7067, Val Loss: 1.7242, F1 Micro: 0.2708, F1 Macro: 0.1843, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.7044, Val Loss: 1.7531, F1 Micro: 0.2708, F1 Macro: 0.2019, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.6975, Val Loss: 2.0099, F1 Micro: 0.2292, F1 Macro: 0.1130, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.6692, Val Loss: 1.7687, F1 Micro: 0.2292, F1 Macro: 0.1863, Accuracy: 0.2292\n","Epoch 11, Train Loss: 1.6794, Val Loss: 1.8743, F1 Micro: 0.2604, F1 Macro: 0.2045, Accuracy: 0.2604\n","Epoch 12, Train Loss: 1.6713, Val Loss: 1.7382, F1 Micro: 0.3125, F1 Macro: 0.2171, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.6384, Val Loss: 1.7342, F1 Micro: 0.2812, F1 Macro: 0.2489, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.6349, Val Loss: 1.8003, F1 Micro: 0.2188, F1 Macro: 0.1857, Accuracy: 0.2188\n","Epoch 15, Train Loss: 1.6365, Val Loss: 1.8480, F1 Micro: 0.2292, F1 Macro: 0.1901, Accuracy: 0.2292\n","Epoch 16, Train Loss: 1.6090, Val Loss: 1.7006, F1 Micro: 0.3125, F1 Macro: 0.2916, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.5857, Val Loss: 1.6808, F1 Micro: 0.3438, F1 Macro: 0.3336, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5893, Val Loss: 1.6257, F1 Micro: 0.3542, F1 Macro: 0.3242, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.5584, Val Loss: 1.7342, F1 Micro: 0.3021, F1 Macro: 0.2783, Accuracy: 0.3021\n","Epoch 20, Train Loss: 1.5751, Val Loss: 1.6803, F1 Micro: 0.3333, F1 Macro: 0.2917, Accuracy: 0.3333\n","Epoch 21, Train Loss: 1.5562, Val Loss: 1.6801, F1 Micro: 0.3229, F1 Macro: 0.2712, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.5493, Val Loss: 1.7425, F1 Micro: 0.2708, F1 Macro: 0.2436, Accuracy: 0.2708\n","Epoch 23, Train Loss: 1.5353, Val Loss: 1.8156, F1 Micro: 0.3021, F1 Macro: 0.2412, Accuracy: 0.3021\n","Epoch 24, Train Loss: 1.5312, Val Loss: 1.6589, F1 Micro: 0.3750, F1 Macro: 0.3212, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.5271, Val Loss: 1.6411, F1 Micro: 0.3750, F1 Macro: 0.3035, Accuracy: 0.3750\n","Epoch 26, Train Loss: 1.4998, Val Loss: 1.8122, F1 Micro: 0.3333, F1 Macro: 0.3139, Accuracy: 0.3333\n","Epoch 27, Train Loss: 1.5050, Val Loss: 1.6466, F1 Micro: 0.4167, F1 Macro: 0.3776, Accuracy: 0.4167\n","Epoch 28, Train Loss: 1.5012, Val Loss: 1.7987, F1 Micro: 0.3125, F1 Macro: 0.2599, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.4836, Val Loss: 1.7785, F1 Micro: 0.3646, F1 Macro: 0.3062, Accuracy: 0.3646\n","Epoch 30, Train Loss: 1.4842, Val Loss: 1.6749, F1 Micro: 0.3646, F1 Macro: 0.3196, Accuracy: 0.3646\n","Epoch 31, Train Loss: 1.4744, Val Loss: 1.7156, F1 Micro: 0.3021, F1 Macro: 0.2641, Accuracy: 0.3021\n","Epoch 32, Train Loss: 1.4805, Val Loss: 1.6209, F1 Micro: 0.3750, F1 Macro: 0.3375, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.4356, Val Loss: 1.6256, F1 Micro: 0.3542, F1 Macro: 0.3042, Accuracy: 0.3542\n","Epoch 34, Train Loss: 1.4543, Val Loss: 1.8582, F1 Micro: 0.3229, F1 Macro: 0.2670, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.4392, Val Loss: 1.6704, F1 Micro: 0.3542, F1 Macro: 0.3235, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.4355, Val Loss: 1.6372, F1 Micro: 0.4271, F1 Macro: 0.3626, Accuracy: 0.4271\n","Epoch 37, Train Loss: 1.4375, Val Loss: 1.6409, F1 Micro: 0.4271, F1 Macro: 0.3487, Accuracy: 0.4271\n","Epoch 38, Train Loss: 1.4254, Val Loss: 1.8607, F1 Micro: 0.3646, F1 Macro: 0.3299, Accuracy: 0.3646\n","Epoch 39, Train Loss: 1.4380, Val Loss: 1.8737, F1 Micro: 0.2604, F1 Macro: 0.2446, Accuracy: 0.2604\n","Epoch 40, Train Loss: 1.3923, Val Loss: 1.6426, F1 Micro: 0.4167, F1 Macro: 0.3584, Accuracy: 0.4167\n","Epoch 41, Train Loss: 1.4049, Val Loss: 1.6442, F1 Micro: 0.4271, F1 Macro: 0.3738, Accuracy: 0.4271\n","Epoch 42, Train Loss: 1.4004, Val Loss: 1.6399, F1 Micro: 0.3854, F1 Macro: 0.3319, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.3892, Val Loss: 1.6684, F1 Micro: 0.3646, F1 Macro: 0.3075, Accuracy: 0.3646\n","Epoch 44, Train Loss: 1.3659, Val Loss: 1.6460, F1 Micro: 0.4167, F1 Macro: 0.3361, Accuracy: 0.4167\n","Epoch 45, Train Loss: 1.4049, Val Loss: 1.6126, F1 Micro: 0.4375, F1 Macro: 0.3710, Accuracy: 0.4375\n","Epoch 46, Train Loss: 1.3538, Val Loss: 1.7622, F1 Micro: 0.3854, F1 Macro: 0.3306, Accuracy: 0.3854\n","Epoch 47, Train Loss: 1.3509, Val Loss: 1.7441, F1 Micro: 0.3542, F1 Macro: 0.3291, Accuracy: 0.3542\n","Epoch 48, Train Loss: 1.3805, Val Loss: 2.5630, F1 Micro: 0.3021, F1 Macro: 0.2300, Accuracy: 0.3021\n","Epoch 49, Train Loss: 1.3745, Val Loss: 1.5818, F1 Micro: 0.4375, F1 Macro: 0.3658, Accuracy: 0.4375\n","Epoch 50, Train Loss: 1.3409, Val Loss: 1.6243, F1 Micro: 0.4375, F1 Macro: 0.3949, Accuracy: 0.4375\n","Epoch 51, Train Loss: 1.3484, Val Loss: 1.5780, F1 Micro: 0.4583, F1 Macro: 0.4280, Accuracy: 0.4583\n","Epoch 52, Train Loss: 1.3281, Val Loss: 1.6963, F1 Micro: 0.4062, F1 Macro: 0.3632, Accuracy: 0.4062\n","Epoch 53, Train Loss: 1.3496, Val Loss: 1.6288, F1 Micro: 0.3958, F1 Macro: 0.3385, Accuracy: 0.3958\n","Epoch 54, Train Loss: 1.2900, Val Loss: 1.7720, F1 Micro: 0.3958, F1 Macro: 0.3497, Accuracy: 0.3958\n","Epoch 55, Train Loss: 1.3376, Val Loss: 2.2033, F1 Micro: 0.2500, F1 Macro: 0.2257, Accuracy: 0.2500\n","Epoch 56, Train Loss: 1.3513, Val Loss: 1.7060, F1 Micro: 0.2917, F1 Macro: 0.2657, Accuracy: 0.2917\n","Epoch 57, Train Loss: 1.3001, Val Loss: 1.6955, F1 Micro: 0.3750, F1 Macro: 0.3567, Accuracy: 0.3750\n","Epoch 58, Train Loss: 1.3289, Val Loss: 1.7106, F1 Micro: 0.4062, F1 Macro: 0.3563, Accuracy: 0.4062\n","Epoch 59, Train Loss: 1.3015, Val Loss: 1.7196, F1 Micro: 0.3750, F1 Macro: 0.3318, Accuracy: 0.3750\n","Epoch 60, Train Loss: 1.3390, Val Loss: 1.6821, F1 Micro: 0.3854, F1 Macro: 0.3333, Accuracy: 0.3854\n","Epoch 61, Train Loss: 1.2593, Val Loss: 1.7333, F1 Micro: 0.4375, F1 Macro: 0.3738, Accuracy: 0.4375\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8257, Val Loss: 1.7878, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 2, Train Loss: 1.7814, Val Loss: 1.7569, F1 Micro: 0.2083, F1 Macro: 0.1454, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.7635, Val Loss: 1.7530, F1 Micro: 0.1875, F1 Macro: 0.1788, Accuracy: 0.1875\n","Epoch 4, Train Loss: 1.7621, Val Loss: 1.7437, F1 Micro: 0.2396, F1 Macro: 0.1818, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.7361, Val Loss: 1.7412, F1 Micro: 0.2396, F1 Macro: 0.1768, Accuracy: 0.2396\n","Epoch 6, Train Loss: 1.7485, Val Loss: 1.7367, F1 Micro: 0.2292, F1 Macro: 0.2064, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.7247, Val Loss: 1.7227, F1 Micro: 0.2500, F1 Macro: 0.2195, Accuracy: 0.2500\n","Epoch 8, Train Loss: 1.7191, Val Loss: 1.7260, F1 Micro: 0.2188, F1 Macro: 0.1704, Accuracy: 0.2188\n","Epoch 9, Train Loss: 1.6905, Val Loss: 1.7090, F1 Micro: 0.2500, F1 Macro: 0.2296, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.6852, Val Loss: 1.7407, F1 Micro: 0.2396, F1 Macro: 0.1761, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.6706, Val Loss: 1.7234, F1 Micro: 0.2917, F1 Macro: 0.2599, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.6561, Val Loss: 1.7170, F1 Micro: 0.2396, F1 Macro: 0.1878, Accuracy: 0.2396\n","Epoch 13, Train Loss: 1.6560, Val Loss: 1.6730, F1 Micro: 0.2812, F1 Macro: 0.2548, Accuracy: 0.2812\n","Epoch 14, Train Loss: 1.6387, Val Loss: 1.6878, F1 Micro: 0.2812, F1 Macro: 0.2378, Accuracy: 0.2812\n","Epoch 15, Train Loss: 1.6406, Val Loss: 1.6640, F1 Micro: 0.3229, F1 Macro: 0.2781, Accuracy: 0.3229\n","Epoch 16, Train Loss: 1.6322, Val Loss: 1.6834, F1 Micro: 0.2812, F1 Macro: 0.2265, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.6280, Val Loss: 1.6791, F1 Micro: 0.2292, F1 Macro: 0.1981, Accuracy: 0.2292\n","Epoch 18, Train Loss: 1.6359, Val Loss: 1.6799, F1 Micro: 0.3229, F1 Macro: 0.2698, Accuracy: 0.3229\n","Epoch 19, Train Loss: 1.6024, Val Loss: 1.6719, F1 Micro: 0.3125, F1 Macro: 0.2581, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.6141, Val Loss: 1.6920, F1 Micro: 0.2708, F1 Macro: 0.2572, Accuracy: 0.2708\n","Epoch 21, Train Loss: 1.6008, Val Loss: 1.7166, F1 Micro: 0.2396, F1 Macro: 0.2083, Accuracy: 0.2396\n","Epoch 22, Train Loss: 1.6192, Val Loss: 1.6625, F1 Micro: 0.3229, F1 Macro: 0.2689, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.5689, Val Loss: 1.6531, F1 Micro: 0.3333, F1 Macro: 0.2908, Accuracy: 0.3333\n","Epoch 24, Train Loss: 1.5877, Val Loss: 1.7124, F1 Micro: 0.3021, F1 Macro: 0.2740, Accuracy: 0.3021\n","Epoch 25, Train Loss: 1.5860, Val Loss: 1.6200, F1 Micro: 0.3542, F1 Macro: 0.3133, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.5526, Val Loss: 1.6163, F1 Micro: 0.3125, F1 Macro: 0.2578, Accuracy: 0.3125\n","Epoch 27, Train Loss: 1.5916, Val Loss: 1.6774, F1 Micro: 0.3333, F1 Macro: 0.2847, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.5533, Val Loss: 1.7110, F1 Micro: 0.3125, F1 Macro: 0.2785, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.5566, Val Loss: 1.6431, F1 Micro: 0.3750, F1 Macro: 0.3238, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.5223, Val Loss: 1.6262, F1 Micro: 0.3438, F1 Macro: 0.3080, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.5431, Val Loss: 1.6606, F1 Micro: 0.3438, F1 Macro: 0.3059, Accuracy: 0.3438\n","Epoch 32, Train Loss: 1.5092, Val Loss: 1.7083, F1 Micro: 0.3438, F1 Macro: 0.2873, Accuracy: 0.3438\n","Epoch 33, Train Loss: 1.5114, Val Loss: 1.7900, F1 Micro: 0.2292, F1 Macro: 0.2133, Accuracy: 0.2292\n","Epoch 34, Train Loss: 1.5296, Val Loss: 1.6449, F1 Micro: 0.3750, F1 Macro: 0.3289, Accuracy: 0.3750\n","Epoch 35, Train Loss: 1.5179, Val Loss: 1.6856, F1 Micro: 0.3542, F1 Macro: 0.3258, Accuracy: 0.3542\n","Epoch 36, Train Loss: 1.4736, Val Loss: 1.5912, F1 Micro: 0.3438, F1 Macro: 0.3050, Accuracy: 0.3438\n","Epoch 37, Train Loss: 1.4664, Val Loss: 1.5986, F1 Micro: 0.2917, F1 Macro: 0.2720, Accuracy: 0.2917\n","Epoch 38, Train Loss: 1.4786, Val Loss: 2.2426, F1 Micro: 0.3542, F1 Macro: 0.3056, Accuracy: 0.3542\n","Epoch 39, Train Loss: 1.4929, Val Loss: 1.7643, F1 Micro: 0.3438, F1 Macro: 0.2894, Accuracy: 0.3438\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8216, Val Loss: 1.7929, F1 Micro: 0.1562, F1 Macro: 0.0763, Accuracy: 0.1562\n","Epoch 2, Train Loss: 1.7518, Val Loss: 1.7929, F1 Micro: 0.1562, F1 Macro: 0.0602, Accuracy: 0.1562\n","Epoch 3, Train Loss: 1.7452, Val Loss: 2.2242, F1 Micro: 0.1667, F1 Macro: 0.0800, Accuracy: 0.1667\n","Epoch 4, Train Loss: 1.7326, Val Loss: 1.7789, F1 Micro: 0.2083, F1 Macro: 0.1668, Accuracy: 0.2083\n","Epoch 5, Train Loss: 1.7324, Val Loss: 1.8031, F1 Micro: 0.1458, F1 Macro: 0.0898, Accuracy: 0.1458\n","Epoch 6, Train Loss: 1.7267, Val Loss: 2.0149, F1 Micro: 0.1979, F1 Macro: 0.1126, Accuracy: 0.1979\n","Epoch 7, Train Loss: 1.7127, Val Loss: 1.7989, F1 Micro: 0.1771, F1 Macro: 0.0957, Accuracy: 0.1771\n","Epoch 8, Train Loss: 1.7376, Val Loss: 2.0129, F1 Micro: 0.2083, F1 Macro: 0.1227, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.7012, Val Loss: 1.7768, F1 Micro: 0.1771, F1 Macro: 0.1114, Accuracy: 0.1771\n","Epoch 10, Train Loss: 1.6803, Val Loss: 1.8868, F1 Micro: 0.1458, F1 Macro: 0.0817, Accuracy: 0.1458\n","Epoch 11, Train Loss: 1.6617, Val Loss: 1.8172, F1 Micro: 0.2500, F1 Macro: 0.2041, Accuracy: 0.2500\n","Epoch 12, Train Loss: 1.6181, Val Loss: 1.9863, F1 Micro: 0.1458, F1 Macro: 0.0476, Accuracy: 0.1458\n","Epoch 13, Train Loss: 1.6222, Val Loss: 2.0298, F1 Micro: 0.1875, F1 Macro: 0.1282, Accuracy: 0.1875\n","Epoch 14, Train Loss: 1.5937, Val Loss: 1.8353, F1 Micro: 0.2917, F1 Macro: 0.2563, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.5647, Val Loss: 1.7135, F1 Micro: 0.2604, F1 Macro: 0.2394, Accuracy: 0.2604\n","Epoch 16, Train Loss: 1.5743, Val Loss: 2.6844, F1 Micro: 0.1875, F1 Macro: 0.0945, Accuracy: 0.1875\n","Epoch 17, Train Loss: 1.5822, Val Loss: 1.6857, F1 Micro: 0.3125, F1 Macro: 0.2825, Accuracy: 0.3125\n","Epoch 18, Train Loss: 1.5476, Val Loss: 1.8971, F1 Micro: 0.2604, F1 Macro: 0.2400, Accuracy: 0.2604\n","Epoch 19, Train Loss: 1.5331, Val Loss: 2.0026, F1 Micro: 0.2083, F1 Macro: 0.1248, Accuracy: 0.2083\n","Epoch 20, Train Loss: 1.5265, Val Loss: 2.0820, F1 Micro: 0.2917, F1 Macro: 0.2610, Accuracy: 0.2917\n","Epoch 21, Train Loss: 1.5080, Val Loss: 1.7109, F1 Micro: 0.3125, F1 Macro: 0.2824, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.5085, Val Loss: 2.3591, F1 Micro: 0.2188, F1 Macro: 0.1604, Accuracy: 0.2188\n","Epoch 23, Train Loss: 1.4550, Val Loss: 1.7089, F1 Micro: 0.3750, F1 Macro: 0.3803, Accuracy: 0.3750\n","Epoch 24, Train Loss: 1.4367, Val Loss: 3.1348, F1 Micro: 0.2292, F1 Macro: 0.1748, Accuracy: 0.2292\n","Epoch 25, Train Loss: 1.4677, Val Loss: 1.9197, F1 Micro: 0.3333, F1 Macro: 0.3128, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.4880, Val Loss: 1.6691, F1 Micro: 0.3854, F1 Macro: 0.3923, Accuracy: 0.3854\n","Epoch 27, Train Loss: 1.4480, Val Loss: 1.7900, F1 Micro: 0.3542, F1 Macro: 0.3450, Accuracy: 0.3542\n","Epoch 28, Train Loss: 1.4530, Val Loss: 1.6904, F1 Micro: 0.3542, F1 Macro: 0.3515, Accuracy: 0.3542\n","Epoch 29, Train Loss: 1.4139, Val Loss: 1.6984, F1 Micro: 0.3646, F1 Macro: 0.3425, Accuracy: 0.3646\n","Epoch 30, Train Loss: 1.4639, Val Loss: 2.4742, F1 Micro: 0.2396, F1 Macro: 0.1931, Accuracy: 0.2396\n","Epoch 31, Train Loss: 1.4044, Val Loss: 1.7659, F1 Micro: 0.3333, F1 Macro: 0.3064, Accuracy: 0.3333\n","Epoch 32, Train Loss: 1.3969, Val Loss: 1.8987, F1 Micro: 0.3021, F1 Macro: 0.2684, Accuracy: 0.3021\n","Epoch 33, Train Loss: 1.3783, Val Loss: 1.8559, F1 Micro: 0.3333, F1 Macro: 0.3148, Accuracy: 0.3333\n","Epoch 34, Train Loss: 1.3749, Val Loss: 1.7604, F1 Micro: 0.3229, F1 Macro: 0.2934, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.3850, Val Loss: 1.7759, F1 Micro: 0.3750, F1 Macro: 0.3579, Accuracy: 0.3750\n","Epoch 36, Train Loss: 1.4406, Val Loss: 1.6494, F1 Micro: 0.3646, F1 Macro: 0.3572, Accuracy: 0.3646\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.3770833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8161, Val Loss: 1.7668, F1 Micro: 0.1875, F1 Macro: 0.1094, Accuracy: 0.1875\n","Epoch 2, Train Loss: 1.7418, Val Loss: 1.7669, F1 Micro: 0.2083, F1 Macro: 0.1244, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.7580, Val Loss: 1.7299, F1 Micro: 0.2396, F1 Macro: 0.1479, Accuracy: 0.2396\n","Epoch 4, Train Loss: 1.7526, Val Loss: 1.7485, F1 Micro: 0.2292, F1 Macro: 0.2063, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.7456, Val Loss: 1.7452, F1 Micro: 0.2083, F1 Macro: 0.1537, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.7262, Val Loss: 1.7203, F1 Micro: 0.2708, F1 Macro: 0.2156, Accuracy: 0.2708\n","Epoch 7, Train Loss: 1.7117, Val Loss: 1.7323, F1 Micro: 0.2812, F1 Macro: 0.2223, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6861, Val Loss: 1.7273, F1 Micro: 0.2604, F1 Macro: 0.2291, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.6817, Val Loss: 1.7330, F1 Micro: 0.2396, F1 Macro: 0.1601, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.6607, Val Loss: 1.6733, F1 Micro: 0.2500, F1 Macro: 0.2037, Accuracy: 0.2500\n","Epoch 11, Train Loss: 1.6623, Val Loss: 2.4284, F1 Micro: 0.2083, F1 Macro: 0.1446, Accuracy: 0.2083\n","Epoch 12, Train Loss: 1.6560, Val Loss: 1.7724, F1 Micro: 0.3021, F1 Macro: 0.2149, Accuracy: 0.3021\n","Epoch 13, Train Loss: 1.6255, Val Loss: 1.6724, F1 Micro: 0.2917, F1 Macro: 0.2468, Accuracy: 0.2917\n","Epoch 14, Train Loss: 1.6303, Val Loss: 2.0643, F1 Micro: 0.2292, F1 Macro: 0.1641, Accuracy: 0.2292\n","Epoch 15, Train Loss: 1.6007, Val Loss: 1.6737, F1 Micro: 0.2812, F1 Macro: 0.2282, Accuracy: 0.2812\n","Epoch 16, Train Loss: 1.5780, Val Loss: 1.8500, F1 Micro: 0.2812, F1 Macro: 0.2139, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.5744, Val Loss: 1.6631, F1 Micro: 0.3750, F1 Macro: 0.3227, Accuracy: 0.3750\n","Epoch 18, Train Loss: 1.5786, Val Loss: 1.6348, F1 Micro: 0.3333, F1 Macro: 0.2953, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.5767, Val Loss: 1.6775, F1 Micro: 0.3021, F1 Macro: 0.2587, Accuracy: 0.3021\n","Epoch 20, Train Loss: 1.5210, Val Loss: 1.7090, F1 Micro: 0.3021, F1 Macro: 0.3024, Accuracy: 0.3021\n","Epoch 21, Train Loss: 1.5378, Val Loss: 1.6871, F1 Micro: 0.3750, F1 Macro: 0.3314, Accuracy: 0.3750\n","Epoch 22, Train Loss: 1.5266, Val Loss: 1.7365, F1 Micro: 0.2396, F1 Macro: 0.1911, Accuracy: 0.2396\n","Epoch 23, Train Loss: 1.5296, Val Loss: 1.8215, F1 Micro: 0.2917, F1 Macro: 0.2710, Accuracy: 0.2917\n","Epoch 24, Train Loss: 1.5494, Val Loss: 1.6985, F1 Micro: 0.3229, F1 Macro: 0.2799, Accuracy: 0.3229\n","Epoch 25, Train Loss: 1.4847, Val Loss: 1.7297, F1 Micro: 0.3333, F1 Macro: 0.2944, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.4618, Val Loss: 1.7010, F1 Micro: 0.3646, F1 Macro: 0.3340, Accuracy: 0.3646\n","Epoch 27, Train Loss: 1.4980, Val Loss: 1.9135, F1 Micro: 0.3229, F1 Macro: 0.2568, Accuracy: 0.3229\n","Epoch 28, Train Loss: 1.4729, Val Loss: 1.8917, F1 Micro: 0.3125, F1 Macro: 0.3078, Accuracy: 0.3125\n","Epoch 29, Train Loss: 1.4651, Val Loss: 1.6338, F1 Micro: 0.3333, F1 Macro: 0.3241, Accuracy: 0.3333\n","Epoch 30, Train Loss: 1.4172, Val Loss: 1.6969, F1 Micro: 0.3021, F1 Macro: 0.2625, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.4388, Val Loss: 1.8301, F1 Micro: 0.3125, F1 Macro: 0.2978, Accuracy: 0.3125\n","Epoch 32, Train Loss: 1.4345, Val Loss: 1.5884, F1 Micro: 0.3750, F1 Macro: 0.3237, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.4150, Val Loss: 1.7195, F1 Micro: 0.3854, F1 Macro: 0.3311, Accuracy: 0.3854\n","Epoch 34, Train Loss: 1.4204, Val Loss: 1.9505, F1 Micro: 0.3333, F1 Macro: 0.2539, Accuracy: 0.3333\n","Epoch 35, Train Loss: 1.3854, Val Loss: 1.7348, F1 Micro: 0.3333, F1 Macro: 0.2908, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.3620, Val Loss: 1.9224, F1 Micro: 0.2396, F1 Macro: 0.2195, Accuracy: 0.2396\n","Epoch 37, Train Loss: 1.3866, Val Loss: 1.8629, F1 Micro: 0.2396, F1 Macro: 0.2181, Accuracy: 0.2396\n","Epoch 38, Train Loss: 1.3741, Val Loss: 1.7899, F1 Micro: 0.3438, F1 Macro: 0.2590, Accuracy: 0.3438\n","Epoch 39, Train Loss: 1.3180, Val Loss: 1.6914, F1 Micro: 0.3021, F1 Macro: 0.2679, Accuracy: 0.3021\n","Epoch 40, Train Loss: 1.3170, Val Loss: 1.6959, F1 Micro: 0.3958, F1 Macro: 0.3886, Accuracy: 0.3958\n","Epoch 41, Train Loss: 1.2912, Val Loss: 1.5764, F1 Micro: 0.3958, F1 Macro: 0.3707, Accuracy: 0.3958\n","Epoch 42, Train Loss: 1.3330, Val Loss: 1.6684, F1 Micro: 0.3854, F1 Macro: 0.3507, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.3142, Val Loss: 1.6712, F1 Micro: 0.3229, F1 Macro: 0.3043, Accuracy: 0.3229\n","Epoch 44, Train Loss: 1.2978, Val Loss: 1.6834, F1 Micro: 0.3750, F1 Macro: 0.3184, Accuracy: 0.3750\n","Epoch 45, Train Loss: 1.2808, Val Loss: 1.7437, F1 Micro: 0.3958, F1 Macro: 0.3414, Accuracy: 0.3958\n","Epoch 46, Train Loss: 1.3421, Val Loss: 1.8075, F1 Micro: 0.3438, F1 Macro: 0.3169, Accuracy: 0.3438\n","Epoch 47, Train Loss: 1.2220, Val Loss: 1.8982, F1 Micro: 0.3854, F1 Macro: 0.3477, Accuracy: 0.3854\n","Epoch 48, Train Loss: 1.2550, Val Loss: 1.7889, F1 Micro: 0.4271, F1 Macro: 0.3843, Accuracy: 0.4271\n","Epoch 49, Train Loss: 1.2873, Val Loss: 1.5492, F1 Micro: 0.4896, F1 Macro: 0.4376, Accuracy: 0.4896\n","Epoch 50, Train Loss: 1.2207, Val Loss: 1.5749, F1 Micro: 0.3854, F1 Macro: 0.3526, Accuracy: 0.3854\n","Epoch 51, Train Loss: 1.2090, Val Loss: 1.9315, F1 Micro: 0.3854, F1 Macro: 0.3167, Accuracy: 0.3854\n","Epoch 52, Train Loss: 1.2333, Val Loss: 1.8019, F1 Micro: 0.3854, F1 Macro: 0.3660, Accuracy: 0.3854\n","Epoch 53, Train Loss: 1.2076, Val Loss: 1.7811, F1 Micro: 0.3646, F1 Macro: 0.3264, Accuracy: 0.3646\n","Epoch 54, Train Loss: 1.1999, Val Loss: 2.5116, F1 Micro: 0.3229, F1 Macro: 0.3037, Accuracy: 0.3229\n","Epoch 55, Train Loss: 1.2089, Val Loss: 2.5348, F1 Micro: 0.2917, F1 Macro: 0.2819, Accuracy: 0.2917\n","Epoch 56, Train Loss: 1.2237, Val Loss: 1.8903, F1 Micro: 0.3125, F1 Macro: 0.2946, Accuracy: 0.3125\n","Epoch 57, Train Loss: 1.1879, Val Loss: 1.5303, F1 Micro: 0.4167, F1 Macro: 0.3927, Accuracy: 0.4167\n","Epoch 58, Train Loss: 1.1671, Val Loss: 1.5593, F1 Micro: 0.4271, F1 Macro: 0.3821, Accuracy: 0.4271\n","Epoch 59, Train Loss: 1.1575, Val Loss: 2.1180, F1 Micro: 0.3750, F1 Macro: 0.3137, Accuracy: 0.3750\n","Epoch 60, Train Loss: 1.1586, Val Loss: 1.8635, F1 Micro: 0.3542, F1 Macro: 0.3065, Accuracy: 0.3542\n","Epoch 61, Train Loss: 1.1474, Val Loss: 1.6107, F1 Micro: 0.4271, F1 Macro: 0.3891, Accuracy: 0.4271\n","Epoch 62, Train Loss: 1.1704, Val Loss: 2.0810, F1 Micro: 0.3438, F1 Macro: 0.3294, Accuracy: 0.3438\n","Epoch 63, Train Loss: 1.1778, Val Loss: 1.7524, F1 Micro: 0.3854, F1 Macro: 0.3499, Accuracy: 0.3854\n","Epoch 64, Train Loss: 1.1239, Val Loss: 1.5634, F1 Micro: 0.3333, F1 Macro: 0.3147, Accuracy: 0.3333\n","Epoch 65, Train Loss: 1.1440, Val Loss: 2.4611, F1 Micro: 0.3125, F1 Macro: 0.2979, Accuracy: 0.3125\n","Epoch 66, Train Loss: 1.1387, Val Loss: 1.5134, F1 Micro: 0.4583, F1 Macro: 0.4309, Accuracy: 0.4583\n","Epoch 67, Train Loss: 1.1539, Val Loss: 1.6285, F1 Micro: 0.4792, F1 Macro: 0.4563, Accuracy: 0.4792\n","Epoch 68, Train Loss: 1.0747, Val Loss: 1.6668, F1 Micro: 0.3958, F1 Macro: 0.3935, Accuracy: 0.3958\n","Epoch 69, Train Loss: 1.1153, Val Loss: 1.5685, F1 Micro: 0.3125, F1 Macro: 0.3054, Accuracy: 0.3125\n","Epoch 70, Train Loss: 1.1135, Val Loss: 1.7735, F1 Micro: 0.3229, F1 Macro: 0.3132, Accuracy: 0.3229\n","Epoch 71, Train Loss: 1.1177, Val Loss: 1.5723, F1 Micro: 0.4375, F1 Macro: 0.4117, Accuracy: 0.4375\n","Epoch 72, Train Loss: 1.0805, Val Loss: 1.5590, F1 Micro: 0.4271, F1 Macro: 0.3844, Accuracy: 0.4271\n","Epoch 73, Train Loss: 1.0981, Val Loss: 1.7920, F1 Micro: 0.4062, F1 Macro: 0.3682, Accuracy: 0.4062\n","Epoch 74, Train Loss: 1.1006, Val Loss: 1.6127, F1 Micro: 0.3646, F1 Macro: 0.3466, Accuracy: 0.3646\n","Epoch 75, Train Loss: 1.0747, Val Loss: 1.9206, F1 Micro: 0.3333, F1 Macro: 0.3214, Accuracy: 0.3333\n","Epoch 76, Train Loss: 1.1014, Val Loss: 1.5942, F1 Micro: 0.4375, F1 Macro: 0.4098, Accuracy: 0.4375\n","Epoch 77, Train Loss: 1.0032, Val Loss: 2.2014, F1 Micro: 0.4271, F1 Macro: 0.3339, Accuracy: 0.4271\n","Epoch 78, Train Loss: 1.0808, Val Loss: 1.6509, F1 Micro: 0.4792, F1 Macro: 0.4422, Accuracy: 0.4792\n","Epoch 79, Train Loss: 1.0888, Val Loss: 1.7211, F1 Micro: 0.4167, F1 Macro: 0.3635, Accuracy: 0.4167\n","Epoch 80, Train Loss: 1.0556, Val Loss: 1.8629, F1 Micro: 0.3854, F1 Macro: 0.3838, Accuracy: 0.3854\n","Epoch 81, Train Loss: 1.0085, Val Loss: 1.5325, F1 Micro: 0.3958, F1 Macro: 0.3959, Accuracy: 0.3958\n","Epoch 82, Train Loss: 1.0386, Val Loss: 1.6183, F1 Micro: 0.4271, F1 Macro: 0.4113, Accuracy: 0.4271\n","Epoch 83, Train Loss: 1.0385, Val Loss: 1.6881, F1 Micro: 0.4167, F1 Macro: 0.4025, Accuracy: 0.4167\n","Epoch 84, Train Loss: 1.0199, Val Loss: 1.7946, F1 Micro: 0.3542, F1 Macro: 0.3294, Accuracy: 0.3542\n","Epoch 85, Train Loss: 1.0142, Val Loss: 1.6216, F1 Micro: 0.4167, F1 Macro: 0.3834, Accuracy: 0.4167\n","Epoch 86, Train Loss: 0.9936, Val Loss: 1.6681, F1 Micro: 0.4271, F1 Macro: 0.4119, Accuracy: 0.4271\n","Epoch 87, Train Loss: 1.0067, Val Loss: 2.6090, F1 Micro: 0.3542, F1 Macro: 0.3141, Accuracy: 0.3542\n","Epoch 88, Train Loss: 1.0187, Val Loss: 2.2012, F1 Micro: 0.4479, F1 Macro: 0.3947, Accuracy: 0.4479\n","Epoch 89, Train Loss: 1.0035, Val Loss: 1.6836, F1 Micro: 0.4271, F1 Macro: 0.4118, Accuracy: 0.4271\n","Epoch 90, Train Loss: 1.0064, Val Loss: 1.9245, F1 Micro: 0.3646, F1 Macro: 0.3250, Accuracy: 0.3646\n","Epoch 91, Train Loss: 1.0380, Val Loss: 2.0531, F1 Micro: 0.3333, F1 Macro: 0.3173, Accuracy: 0.3333\n","Epoch 92, Train Loss: 1.0076, Val Loss: 1.6234, F1 Micro: 0.4271, F1 Macro: 0.3850, Accuracy: 0.4271\n","Epoch 93, Train Loss: 1.0018, Val Loss: 1.7826, F1 Micro: 0.4271, F1 Macro: 0.4068, Accuracy: 0.4271\n","Epoch 94, Train Loss: 0.9687, Val Loss: 1.8745, F1 Micro: 0.4479, F1 Macro: 0.3979, Accuracy: 0.4479\n","Epoch 95, Train Loss: 1.0301, Val Loss: 1.7944, F1 Micro: 0.4479, F1 Macro: 0.4172, Accuracy: 0.4479\n","Epoch 96, Train Loss: 0.9904, Val Loss: 1.6438, F1 Micro: 0.5208, F1 Macro: 0.5050, Accuracy: 0.5208\n","Epoch 97, Train Loss: 0.9652, Val Loss: 1.7435, F1 Micro: 0.3854, F1 Macro: 0.3769, Accuracy: 0.3854\n","Epoch 98, Train Loss: 0.9573, Val Loss: 3.5971, F1 Micro: 0.3125, F1 Macro: 0.2877, Accuracy: 0.3125\n","Epoch 99, Train Loss: 1.0472, Val Loss: 1.9016, F1 Micro: 0.4062, F1 Macro: 0.3950, Accuracy: 0.4062\n","Epoch 100, Train Loss: 0.9600, Val Loss: 2.1198, F1 Micro: 0.3958, F1 Macro: 0.3735, Accuracy: 0.3958\n","Epoch 101, Train Loss: 0.8769, Val Loss: 1.7414, F1 Micro: 0.3958, F1 Macro: 0.3802, Accuracy: 0.3958\n","Epoch 102, Train Loss: 0.9835, Val Loss: 2.2331, F1 Micro: 0.3438, F1 Macro: 0.3247, Accuracy: 0.3438\n","Epoch 103, Train Loss: 0.9880, Val Loss: 1.7244, F1 Micro: 0.4479, F1 Macro: 0.4112, Accuracy: 0.4479\n","Epoch 104, Train Loss: 0.9593, Val Loss: 2.5986, F1 Micro: 0.3958, F1 Macro: 0.3601, Accuracy: 0.3958\n","Epoch 105, Train Loss: 0.9574, Val Loss: 1.8238, F1 Micro: 0.4479, F1 Macro: 0.4371, Accuracy: 0.4479\n","Epoch 106, Train Loss: 0.9848, Val Loss: 1.7650, F1 Micro: 0.3750, F1 Macro: 0.3602, Accuracy: 0.3750\n","Epoch 107, Train Loss: 0.9249, Val Loss: 1.8510, F1 Micro: 0.4688, F1 Macro: 0.4232, Accuracy: 0.4688\n","Epoch 108, Train Loss: 0.9126, Val Loss: 2.2031, F1 Micro: 0.4375, F1 Macro: 0.3971, Accuracy: 0.4375\n","Epoch 109, Train Loss: 0.8753, Val Loss: 1.7744, F1 Micro: 0.4375, F1 Macro: 0.4131, Accuracy: 0.4375\n","Epoch 110, Train Loss: 0.9213, Val Loss: 1.9004, F1 Micro: 0.4167, F1 Macro: 0.3799, Accuracy: 0.4167\n","Epoch 111, Train Loss: 0.8634, Val Loss: 2.1720, F1 Micro: 0.3646, F1 Macro: 0.3594, Accuracy: 0.3646\n","Epoch 112, Train Loss: 0.8586, Val Loss: 2.2937, F1 Micro: 0.3229, F1 Macro: 0.3059, Accuracy: 0.3229\n","Epoch 113, Train Loss: 0.9715, Val Loss: 1.8522, F1 Micro: 0.4167, F1 Macro: 0.3741, Accuracy: 0.4167\n","Epoch 114, Train Loss: 0.9396, Val Loss: 1.8444, F1 Micro: 0.4688, F1 Macro: 0.4403, Accuracy: 0.4688\n","Epoch 115, Train Loss: 0.8657, Val Loss: 1.8573, F1 Micro: 0.4271, F1 Macro: 0.4037, Accuracy: 0.4271\n","Epoch 116, Train Loss: 0.8418, Val Loss: 1.9131, F1 Micro: 0.4375, F1 Macro: 0.4216, Accuracy: 0.4375\n","Epoch 117, Train Loss: 0.9593, Val Loss: 1.7101, F1 Micro: 0.4792, F1 Macro: 0.4537, Accuracy: 0.4792\n","Epoch 118, Train Loss: 0.9296, Val Loss: 2.0492, F1 Micro: 0.3750, F1 Macro: 0.3332, Accuracy: 0.3750\n","Epoch 119, Train Loss: 0.8277, Val Loss: 2.2707, F1 Micro: 0.4896, F1 Macro: 0.4535, Accuracy: 0.4896\n","Epoch 120, Train Loss: 0.8617, Val Loss: 2.0290, F1 Micro: 0.4479, F1 Macro: 0.4216, Accuracy: 0.4479\n","Epoch 121, Train Loss: 0.8994, Val Loss: 1.9134, F1 Micro: 0.4167, F1 Macro: 0.3997, Accuracy: 0.4167\n","Epoch 122, Train Loss: 0.9136, Val Loss: 2.1078, F1 Micro: 0.3958, F1 Macro: 0.3568, Accuracy: 0.3958\n","Epoch 123, Train Loss: 0.8732, Val Loss: 1.8147, F1 Micro: 0.4583, F1 Macro: 0.4297, Accuracy: 0.4583\n","Epoch 124, Train Loss: 0.8286, Val Loss: 1.8139, F1 Micro: 0.4688, F1 Macro: 0.4470, Accuracy: 0.4688\n","Epoch 125, Train Loss: 0.8390, Val Loss: 2.0495, F1 Micro: 0.3958, F1 Macro: 0.3951, Accuracy: 0.3958\n","Epoch 126, Train Loss: 0.8164, Val Loss: 1.9050, F1 Micro: 0.4479, F1 Macro: 0.4172, Accuracy: 0.4479\n","Epoch 127, Train Loss: 0.8354, Val Loss: 2.2182, F1 Micro: 0.3958, F1 Macro: 0.3867, Accuracy: 0.3958\n","Epoch 128, Train Loss: 0.8952, Val Loss: 1.8163, F1 Micro: 0.4271, F1 Macro: 0.3926, Accuracy: 0.4271\n","Epoch 129, Train Loss: 0.7887, Val Loss: 2.0400, F1 Micro: 0.4167, F1 Macro: 0.3885, Accuracy: 0.4167\n","Epoch 130, Train Loss: 0.8877, Val Loss: 2.0310, F1 Micro: 0.3646, F1 Macro: 0.3552, Accuracy: 0.3646\n","Epoch 131, Train Loss: 0.8961, Val Loss: 2.7527, F1 Micro: 0.3125, F1 Macro: 0.3057, Accuracy: 0.3125\n","Epoch 132, Train Loss: 0.8396, Val Loss: 1.9709, F1 Micro: 0.4688, F1 Macro: 0.4172, Accuracy: 0.4688\n","Epoch 133, Train Loss: 0.8183, Val Loss: 1.6973, F1 Micro: 0.4792, F1 Macro: 0.4767, Accuracy: 0.4792\n","Epoch 134, Train Loss: 0.8426, Val Loss: 2.0862, F1 Micro: 0.4062, F1 Macro: 0.3473, Accuracy: 0.4062\n","Epoch 135, Train Loss: 0.8522, Val Loss: 1.7635, F1 Micro: 0.4583, F1 Macro: 0.4446, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.8068, Val Loss: 2.0209, F1 Micro: 0.4375, F1 Macro: 0.4329, Accuracy: 0.4375\n","Epoch 137, Train Loss: 0.8244, Val Loss: 1.7287, F1 Micro: 0.5104, F1 Macro: 0.5078, Accuracy: 0.5104\n","Epoch 138, Train Loss: 0.8463, Val Loss: 2.0833, F1 Micro: 0.5000, F1 Macro: 0.4694, Accuracy: 0.5000\n","Epoch 139, Train Loss: 0.7907, Val Loss: 1.8885, F1 Micro: 0.5000, F1 Macro: 0.4826, Accuracy: 0.5000\n","Epoch 140, Train Loss: 0.7895, Val Loss: 2.0810, F1 Micro: 0.4583, F1 Macro: 0.4208, Accuracy: 0.4583\n","Epoch 141, Train Loss: 0.7794, Val Loss: 2.2463, F1 Micro: 0.4792, F1 Macro: 0.4450, Accuracy: 0.4792\n","Epoch 142, Train Loss: 0.7300, Val Loss: 1.8373, F1 Micro: 0.4375, F1 Macro: 0.4246, Accuracy: 0.4375\n","Epoch 143, Train Loss: 0.8020, Val Loss: 1.6306, F1 Micro: 0.4688, F1 Macro: 0.4587, Accuracy: 0.4688\n","Epoch 144, Train Loss: 0.8215, Val Loss: 1.9013, F1 Micro: 0.5104, F1 Macro: 0.5034, Accuracy: 0.5104\n","Epoch 145, Train Loss: 0.7977, Val Loss: 2.1877, F1 Micro: 0.4479, F1 Macro: 0.4126, Accuracy: 0.4479\n","Epoch 146, Train Loss: 0.7681, Val Loss: 2.1136, F1 Micro: 0.4271, F1 Macro: 0.4159, Accuracy: 0.4271\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8235, Val Loss: 1.9735, F1 Micro: 0.2396, F1 Macro: 0.1967, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7530, Val Loss: 1.8720, F1 Micro: 0.2396, F1 Macro: 0.1727, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7572, Val Loss: 1.8286, F1 Micro: 0.2083, F1 Macro: 0.1974, Accuracy: 0.2083\n","Epoch 4, Train Loss: 1.7378, Val Loss: 1.8593, F1 Micro: 0.2500, F1 Macro: 0.1952, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.7214, Val Loss: 1.9453, F1 Micro: 0.1771, F1 Macro: 0.1562, Accuracy: 0.1771\n","Epoch 6, Train Loss: 1.7259, Val Loss: 1.8887, F1 Micro: 0.2188, F1 Macro: 0.1367, Accuracy: 0.2188\n","Epoch 7, Train Loss: 1.7237, Val Loss: 1.9513, F1 Micro: 0.2500, F1 Macro: 0.1843, Accuracy: 0.2500\n","Epoch 8, Train Loss: 1.7182, Val Loss: 1.9829, F1 Micro: 0.2188, F1 Macro: 0.1897, Accuracy: 0.2188\n","Epoch 9, Train Loss: 1.7151, Val Loss: 1.9477, F1 Micro: 0.2292, F1 Macro: 0.1812, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.7159, Val Loss: 1.9210, F1 Micro: 0.2396, F1 Macro: 0.1893, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.6988, Val Loss: 1.9154, F1 Micro: 0.2917, F1 Macro: 0.2312, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.7128, Val Loss: 1.8695, F1 Micro: 0.2812, F1 Macro: 0.2174, Accuracy: 0.2812\n","Epoch 13, Train Loss: 1.6962, Val Loss: 1.8632, F1 Micro: 0.2396, F1 Macro: 0.1532, Accuracy: 0.2396\n","Epoch 14, Train Loss: 1.7001, Val Loss: 1.7539, F1 Micro: 0.3229, F1 Macro: 0.2691, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.6830, Val Loss: 1.9879, F1 Micro: 0.2396, F1 Macro: 0.2067, Accuracy: 0.2396\n","Epoch 16, Train Loss: 1.6820, Val Loss: 1.8500, F1 Micro: 0.3750, F1 Macro: 0.3266, Accuracy: 0.3750\n","Epoch 17, Train Loss: 1.6897, Val Loss: 1.8496, F1 Micro: 0.3229, F1 Macro: 0.2717, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.6672, Val Loss: 1.9510, F1 Micro: 0.2708, F1 Macro: 0.1957, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.6575, Val Loss: 1.7814, F1 Micro: 0.3854, F1 Macro: 0.3295, Accuracy: 0.3854\n","Epoch 20, Train Loss: 1.6770, Val Loss: 1.8769, F1 Micro: 0.3542, F1 Macro: 0.3041, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.6620, Val Loss: 1.9012, F1 Micro: 0.3229, F1 Macro: 0.2913, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.6496, Val Loss: 1.8525, F1 Micro: 0.3021, F1 Macro: 0.2705, Accuracy: 0.3021\n","Epoch 23, Train Loss: 1.6374, Val Loss: 1.7849, F1 Micro: 0.3125, F1 Macro: 0.2771, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.6305, Val Loss: 2.1463, F1 Micro: 0.2917, F1 Macro: 0.2463, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.6249, Val Loss: 1.7848, F1 Micro: 0.3750, F1 Macro: 0.3246, Accuracy: 0.3750\n","Epoch 26, Train Loss: 1.6227, Val Loss: 1.8215, F1 Micro: 0.2083, F1 Macro: 0.1806, Accuracy: 0.2083\n","Epoch 27, Train Loss: 1.6310, Val Loss: 1.7358, F1 Micro: 0.3542, F1 Macro: 0.3037, Accuracy: 0.3542\n","Epoch 28, Train Loss: 1.6217, Val Loss: 1.8932, F1 Micro: 0.2396, F1 Macro: 0.1456, Accuracy: 0.2396\n","Epoch 29, Train Loss: 1.6099, Val Loss: 1.7713, F1 Micro: 0.3125, F1 Macro: 0.2482, Accuracy: 0.3125\n","Epoch 30, Train Loss: 1.5895, Val Loss: 1.9940, F1 Micro: 0.3125, F1 Macro: 0.2376, Accuracy: 0.3125\n","Epoch 31, Train Loss: 1.5692, Val Loss: 1.7891, F1 Micro: 0.3125, F1 Macro: 0.2425, Accuracy: 0.3125\n","Epoch 32, Train Loss: 1.6024, Val Loss: 1.7900, F1 Micro: 0.3125, F1 Macro: 0.2857, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.5841, Val Loss: 1.9739, F1 Micro: 0.2917, F1 Macro: 0.2091, Accuracy: 0.2917\n","Epoch 34, Train Loss: 1.5314, Val Loss: 1.9812, F1 Micro: 0.2396, F1 Macro: 0.1959, Accuracy: 0.2396\n","Epoch 35, Train Loss: 1.5559, Val Loss: 2.3316, F1 Micro: 0.2500, F1 Macro: 0.1685, Accuracy: 0.2500\n","Epoch 36, Train Loss: 1.5289, Val Loss: 1.7603, F1 Micro: 0.3333, F1 Macro: 0.2559, Accuracy: 0.3333\n","Epoch 37, Train Loss: 1.5197, Val Loss: 1.7295, F1 Micro: 0.3646, F1 Macro: 0.2971, Accuracy: 0.3646\n","Epoch 38, Train Loss: 1.4871, Val Loss: 1.9471, F1 Micro: 0.3542, F1 Macro: 0.3012, Accuracy: 0.3542\n","Epoch 39, Train Loss: 1.5002, Val Loss: 1.8081, F1 Micro: 0.3542, F1 Macro: 0.3117, Accuracy: 0.3542\n","Epoch 40, Train Loss: 1.4817, Val Loss: 1.7661, F1 Micro: 0.3646, F1 Macro: 0.2948, Accuracy: 0.3646\n","Epoch 41, Train Loss: 1.4424, Val Loss: 2.1801, F1 Micro: 0.2708, F1 Macro: 0.2109, Accuracy: 0.2708\n","Epoch 42, Train Loss: 1.4879, Val Loss: 1.8825, F1 Micro: 0.3750, F1 Macro: 0.3188, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.4465, Val Loss: 1.6831, F1 Micro: 0.3750, F1 Macro: 0.3195, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.4608, Val Loss: 1.6609, F1 Micro: 0.3333, F1 Macro: 0.2658, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.4133, Val Loss: 1.7507, F1 Micro: 0.4062, F1 Macro: 0.3687, Accuracy: 0.4062\n","Epoch 46, Train Loss: 1.3777, Val Loss: 2.1021, F1 Micro: 0.2917, F1 Macro: 0.2079, Accuracy: 0.2917\n","Epoch 47, Train Loss: 1.3904, Val Loss: 1.8446, F1 Micro: 0.3646, F1 Macro: 0.3000, Accuracy: 0.3646\n","Epoch 48, Train Loss: 1.4332, Val Loss: 1.6729, F1 Micro: 0.3438, F1 Macro: 0.3257, Accuracy: 0.3438\n","Epoch 49, Train Loss: 1.4008, Val Loss: 1.9181, F1 Micro: 0.3854, F1 Macro: 0.3299, Accuracy: 0.3854\n","Epoch 50, Train Loss: 1.4162, Val Loss: 1.8843, F1 Micro: 0.3750, F1 Macro: 0.3342, Accuracy: 0.3750\n","Epoch 51, Train Loss: 1.3564, Val Loss: 2.1538, F1 Micro: 0.3333, F1 Macro: 0.2742, Accuracy: 0.3333\n","Epoch 52, Train Loss: 1.3527, Val Loss: 1.6896, F1 Micro: 0.3750, F1 Macro: 0.3213, Accuracy: 0.3750\n","Epoch 53, Train Loss: 1.3773, Val Loss: 1.7518, F1 Micro: 0.3854, F1 Macro: 0.3506, Accuracy: 0.3854\n","Epoch 54, Train Loss: 1.3277, Val Loss: 1.9090, F1 Micro: 0.3229, F1 Macro: 0.2651, Accuracy: 0.3229\n","Epoch 55, Train Loss: 1.4013, Val Loss: 1.7640, F1 Micro: 0.3438, F1 Macro: 0.2830, Accuracy: 0.3438\n","Epoch 56, Train Loss: 1.3410, Val Loss: 1.7712, F1 Micro: 0.4062, F1 Macro: 0.3801, Accuracy: 0.4062\n","Epoch 57, Train Loss: 1.2902, Val Loss: 1.7350, F1 Micro: 0.3646, F1 Macro: 0.3385, Accuracy: 0.3646\n","Epoch 58, Train Loss: 1.3087, Val Loss: 1.9344, F1 Micro: 0.3542, F1 Macro: 0.3103, Accuracy: 0.3542\n","Epoch 59, Train Loss: 1.2993, Val Loss: 1.5494, F1 Micro: 0.4479, F1 Macro: 0.4139, Accuracy: 0.4479\n","Epoch 60, Train Loss: 1.3015, Val Loss: 1.6089, F1 Micro: 0.4688, F1 Macro: 0.4221, Accuracy: 0.4688\n","Epoch 61, Train Loss: 1.2954, Val Loss: 1.6823, F1 Micro: 0.4167, F1 Macro: 0.3807, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.2525, Val Loss: 1.9805, F1 Micro: 0.3438, F1 Macro: 0.2767, Accuracy: 0.3438\n","Epoch 63, Train Loss: 1.3292, Val Loss: 1.6545, F1 Micro: 0.4375, F1 Macro: 0.4024, Accuracy: 0.4375\n","Epoch 64, Train Loss: 1.2604, Val Loss: 1.7983, F1 Micro: 0.4792, F1 Macro: 0.4361, Accuracy: 0.4792\n","Epoch 65, Train Loss: 1.3021, Val Loss: 2.3804, F1 Micro: 0.2917, F1 Macro: 0.2768, Accuracy: 0.2917\n","Epoch 66, Train Loss: 1.3033, Val Loss: 1.6503, F1 Micro: 0.4688, F1 Macro: 0.4360, Accuracy: 0.4688\n","Epoch 67, Train Loss: 1.2657, Val Loss: 1.7555, F1 Micro: 0.3854, F1 Macro: 0.3442, Accuracy: 0.3854\n","Epoch 68, Train Loss: 1.3045, Val Loss: 2.0020, F1 Micro: 0.3542, F1 Macro: 0.3090, Accuracy: 0.3542\n","Epoch 69, Train Loss: 1.2294, Val Loss: 1.8594, F1 Micro: 0.3542, F1 Macro: 0.2851, Accuracy: 0.3542\n","Epoch 70, Train Loss: 1.2276, Val Loss: 1.9891, F1 Micro: 0.2917, F1 Macro: 0.2304, Accuracy: 0.2917\n","Epoch 71, Train Loss: 1.2520, Val Loss: 1.7402, F1 Micro: 0.4167, F1 Macro: 0.3559, Accuracy: 0.4167\n","Epoch 72, Train Loss: 1.2002, Val Loss: 1.7510, F1 Micro: 0.3854, F1 Macro: 0.3240, Accuracy: 0.3854\n","Epoch 73, Train Loss: 1.2235, Val Loss: 1.8754, F1 Micro: 0.3958, F1 Macro: 0.3639, Accuracy: 0.3958\n","Epoch 74, Train Loss: 1.2200, Val Loss: 1.7370, F1 Micro: 0.4271, F1 Macro: 0.4129, Accuracy: 0.4271\n","Epoch 75, Train Loss: 1.2211, Val Loss: 1.7259, F1 Micro: 0.4271, F1 Macro: 0.3842, Accuracy: 0.4271\n","Epoch 76, Train Loss: 1.2053, Val Loss: 2.1493, F1 Micro: 0.3542, F1 Macro: 0.3200, Accuracy: 0.3542\n","Epoch 77, Train Loss: 1.2090, Val Loss: 1.6685, F1 Micro: 0.3854, F1 Macro: 0.3300, Accuracy: 0.3854\n","Epoch 78, Train Loss: 1.1692, Val Loss: 1.6243, F1 Micro: 0.4583, F1 Macro: 0.4393, Accuracy: 0.4583\n","Epoch 79, Train Loss: 1.1802, Val Loss: 1.6012, F1 Micro: 0.4479, F1 Macro: 0.4120, Accuracy: 0.4479\n","Epoch 80, Train Loss: 1.2004, Val Loss: 2.0264, F1 Micro: 0.3854, F1 Macro: 0.3694, Accuracy: 0.3854\n","Epoch 81, Train Loss: 1.2170, Val Loss: 1.6832, F1 Micro: 0.4583, F1 Macro: 0.4332, Accuracy: 0.4583\n","Epoch 82, Train Loss: 1.1850, Val Loss: 1.9199, F1 Micro: 0.3646, F1 Macro: 0.3344, Accuracy: 0.3646\n","Epoch 83, Train Loss: 1.2022, Val Loss: 1.5993, F1 Micro: 0.4792, F1 Macro: 0.4372, Accuracy: 0.4792\n","Epoch 84, Train Loss: 1.1556, Val Loss: 1.7419, F1 Micro: 0.3854, F1 Macro: 0.3216, Accuracy: 0.3854\n","Epoch 85, Train Loss: 1.1749, Val Loss: 1.5986, F1 Micro: 0.4479, F1 Macro: 0.4249, Accuracy: 0.4479\n","Epoch 86, Train Loss: 1.1822, Val Loss: 1.8102, F1 Micro: 0.3750, F1 Macro: 0.3351, Accuracy: 0.3750\n","Epoch 87, Train Loss: 1.1664, Val Loss: 1.8312, F1 Micro: 0.4271, F1 Macro: 0.3761, Accuracy: 0.4271\n","Epoch 88, Train Loss: 1.1150, Val Loss: 1.8392, F1 Micro: 0.4271, F1 Macro: 0.4089, Accuracy: 0.4271\n","Epoch 89, Train Loss: 1.1488, Val Loss: 1.5890, F1 Micro: 0.5000, F1 Macro: 0.4344, Accuracy: 0.5000\n","Epoch 90, Train Loss: 1.1482, Val Loss: 1.8043, F1 Micro: 0.4271, F1 Macro: 0.3938, Accuracy: 0.4271\n","Epoch 91, Train Loss: 1.1447, Val Loss: 2.1508, F1 Micro: 0.3438, F1 Macro: 0.2829, Accuracy: 0.3438\n","Epoch 92, Train Loss: 1.1429, Val Loss: 1.8015, F1 Micro: 0.4792, F1 Macro: 0.4323, Accuracy: 0.4792\n","Epoch 93, Train Loss: 1.1509, Val Loss: 1.5684, F1 Micro: 0.4167, F1 Macro: 0.3694, Accuracy: 0.4167\n","Epoch 94, Train Loss: 1.1049, Val Loss: 1.5524, F1 Micro: 0.4688, F1 Macro: 0.4516, Accuracy: 0.4688\n","Epoch 95, Train Loss: 1.1209, Val Loss: 2.0572, F1 Micro: 0.3229, F1 Macro: 0.2562, Accuracy: 0.3229\n","Epoch 96, Train Loss: 1.0909, Val Loss: 1.5674, F1 Micro: 0.4688, F1 Macro: 0.4252, Accuracy: 0.4688\n","Epoch 97, Train Loss: 1.1232, Val Loss: 1.7852, F1 Micro: 0.5000, F1 Macro: 0.4782, Accuracy: 0.5000\n","Epoch 98, Train Loss: 1.0699, Val Loss: 1.7129, F1 Micro: 0.4792, F1 Macro: 0.4495, Accuracy: 0.4792\n","Epoch 99, Train Loss: 1.0742, Val Loss: 2.4251, F1 Micro: 0.3958, F1 Macro: 0.2862, Accuracy: 0.3958\n","Epoch 100, Train Loss: 1.0992, Val Loss: 1.5573, F1 Micro: 0.5208, F1 Macro: 0.4916, Accuracy: 0.5208\n","Epoch 101, Train Loss: 1.0425, Val Loss: 1.6648, F1 Micro: 0.4271, F1 Macro: 0.4065, Accuracy: 0.4271\n","Epoch 102, Train Loss: 1.0581, Val Loss: 2.0360, F1 Micro: 0.4062, F1 Macro: 0.3520, Accuracy: 0.4062\n","Epoch 103, Train Loss: 1.0425, Val Loss: 1.7379, F1 Micro: 0.4583, F1 Macro: 0.3982, Accuracy: 0.4583\n","Epoch 104, Train Loss: 1.0776, Val Loss: 2.1512, F1 Micro: 0.3958, F1 Macro: 0.3729, Accuracy: 0.3958\n","Epoch 105, Train Loss: 1.1166, Val Loss: 1.9103, F1 Micro: 0.3854, F1 Macro: 0.3301, Accuracy: 0.3854\n","Epoch 106, Train Loss: 1.1031, Val Loss: 1.7590, F1 Micro: 0.4792, F1 Macro: 0.4399, Accuracy: 0.4792\n","Epoch 107, Train Loss: 1.0481, Val Loss: 1.7746, F1 Micro: 0.3958, F1 Macro: 0.3314, Accuracy: 0.3958\n","Epoch 108, Train Loss: 1.0336, Val Loss: 1.9326, F1 Micro: 0.3750, F1 Macro: 0.3158, Accuracy: 0.3750\n","Epoch 109, Train Loss: 1.0997, Val Loss: 1.8454, F1 Micro: 0.4375, F1 Macro: 0.4076, Accuracy: 0.4375\n","Epoch 110, Train Loss: 1.0197, Val Loss: 1.6694, F1 Micro: 0.4271, F1 Macro: 0.3821, Accuracy: 0.4271\n","Epoch 111, Train Loss: 1.0439, Val Loss: 1.6463, F1 Micro: 0.5208, F1 Macro: 0.4980, Accuracy: 0.5208\n","Epoch 112, Train Loss: 1.0383, Val Loss: 1.6606, F1 Micro: 0.4688, F1 Macro: 0.4403, Accuracy: 0.4688\n","Epoch 113, Train Loss: 0.9899, Val Loss: 1.5397, F1 Micro: 0.4896, F1 Macro: 0.4569, Accuracy: 0.4896\n","Epoch 114, Train Loss: 0.9801, Val Loss: 1.7263, F1 Micro: 0.4271, F1 Macro: 0.3780, Accuracy: 0.4271\n","Epoch 115, Train Loss: 1.0074, Val Loss: 1.5156, F1 Micro: 0.4688, F1 Macro: 0.4278, Accuracy: 0.4688\n","Epoch 116, Train Loss: 0.9707, Val Loss: 1.7189, F1 Micro: 0.5104, F1 Macro: 0.4890, Accuracy: 0.5104\n","Epoch 117, Train Loss: 1.0074, Val Loss: 1.8087, F1 Micro: 0.4375, F1 Macro: 0.3956, Accuracy: 0.4375\n","Epoch 118, Train Loss: 0.9858, Val Loss: 1.7231, F1 Micro: 0.3854, F1 Macro: 0.3469, Accuracy: 0.3854\n","Epoch 119, Train Loss: 0.9301, Val Loss: 1.6632, F1 Micro: 0.4792, F1 Macro: 0.4333, Accuracy: 0.4792\n","Epoch 120, Train Loss: 0.9611, Val Loss: 2.1974, F1 Micro: 0.3750, F1 Macro: 0.3230, Accuracy: 0.3750\n","Epoch 121, Train Loss: 1.0567, Val Loss: 1.8109, F1 Micro: 0.4167, F1 Macro: 0.3711, Accuracy: 0.4167\n","Epoch 122, Train Loss: 0.9954, Val Loss: 2.2708, F1 Micro: 0.4167, F1 Macro: 0.3776, Accuracy: 0.4167\n","Epoch 123, Train Loss: 1.0147, Val Loss: 1.6809, F1 Micro: 0.4583, F1 Macro: 0.4247, Accuracy: 0.4583\n","Epoch 124, Train Loss: 0.9539, Val Loss: 1.7503, F1 Micro: 0.4688, F1 Macro: 0.4423, Accuracy: 0.4688\n","Epoch 125, Train Loss: 1.0020, Val Loss: 1.9923, F1 Micro: 0.4375, F1 Macro: 0.4174, Accuracy: 0.4375\n","Epoch 126, Train Loss: 0.9152, Val Loss: 2.0227, F1 Micro: 0.4583, F1 Macro: 0.4186, Accuracy: 0.4583\n","Epoch 127, Train Loss: 0.9869, Val Loss: 1.7516, F1 Micro: 0.4792, F1 Macro: 0.4613, Accuracy: 0.4792\n","Epoch 128, Train Loss: 0.8910, Val Loss: 1.9417, F1 Micro: 0.4062, F1 Macro: 0.3676, Accuracy: 0.4062\n","Epoch 129, Train Loss: 0.9363, Val Loss: 1.6898, F1 Micro: 0.4896, F1 Macro: 0.4828, Accuracy: 0.4896\n","Epoch 130, Train Loss: 0.8765, Val Loss: 1.9779, F1 Micro: 0.4479, F1 Macro: 0.4066, Accuracy: 0.4479\n","Epoch 131, Train Loss: 0.9358, Val Loss: 2.5099, F1 Micro: 0.4167, F1 Macro: 0.3918, Accuracy: 0.4167\n","Epoch 132, Train Loss: 0.9666, Val Loss: 1.8361, F1 Micro: 0.4792, F1 Macro: 0.4398, Accuracy: 0.4792\n","Epoch 133, Train Loss: 0.9623, Val Loss: 2.4699, F1 Micro: 0.3750, F1 Macro: 0.3442, Accuracy: 0.3750\n","Epoch 134, Train Loss: 0.9504, Val Loss: 1.7286, F1 Micro: 0.5312, F1 Macro: 0.5204, Accuracy: 0.5312\n","Epoch 135, Train Loss: 0.8850, Val Loss: 1.7783, F1 Micro: 0.4479, F1 Macro: 0.4315, Accuracy: 0.4479\n","Epoch 136, Train Loss: 0.9117, Val Loss: 1.8024, F1 Micro: 0.4583, F1 Macro: 0.4258, Accuracy: 0.4583\n","Epoch 137, Train Loss: 0.9092, Val Loss: 1.5888, F1 Micro: 0.5208, F1 Macro: 0.4959, Accuracy: 0.5208\n","Epoch 138, Train Loss: 0.8898, Val Loss: 1.9637, F1 Micro: 0.4583, F1 Macro: 0.4303, Accuracy: 0.4583\n","Epoch 139, Train Loss: 0.8675, Val Loss: 1.8102, F1 Micro: 0.4479, F1 Macro: 0.4212, Accuracy: 0.4479\n","Epoch 140, Train Loss: 0.8884, Val Loss: 1.7906, F1 Micro: 0.5104, F1 Macro: 0.4906, Accuracy: 0.5104\n","Epoch 141, Train Loss: 0.8873, Val Loss: 1.8572, F1 Micro: 0.4583, F1 Macro: 0.4290, Accuracy: 0.4583\n","Epoch 142, Train Loss: 0.8677, Val Loss: 1.7585, F1 Micro: 0.5000, F1 Macro: 0.4532, Accuracy: 0.5000\n","Epoch 143, Train Loss: 0.8743, Val Loss: 1.8783, F1 Micro: 0.4792, F1 Macro: 0.4292, Accuracy: 0.4792\n","Epoch 144, Train Loss: 0.8970, Val Loss: 1.7835, F1 Micro: 0.4271, F1 Macro: 0.4050, Accuracy: 0.4271\n","Epoch 145, Train Loss: 0.8696, Val Loss: 2.0551, F1 Micro: 0.4167, F1 Macro: 0.4082, Accuracy: 0.4167\n","Epoch 146, Train Loss: 0.8495, Val Loss: 1.9552, F1 Micro: 0.4792, F1 Macro: 0.4311, Accuracy: 0.4792\n","Epoch 147, Train Loss: 0.9112, Val Loss: 1.9038, F1 Micro: 0.4896, F1 Macro: 0.4510, Accuracy: 0.4896\n","Epoch 148, Train Loss: 0.8746, Val Loss: 1.7720, F1 Micro: 0.4583, F1 Macro: 0.4178, Accuracy: 0.4583\n","Epoch 149, Train Loss: 0.8927, Val Loss: 1.9861, F1 Micro: 0.5000, F1 Macro: 0.4549, Accuracy: 0.5000\n","Epoch 150, Train Loss: 0.8438, Val Loss: 1.8379, F1 Micro: 0.4688, F1 Macro: 0.4237, Accuracy: 0.4688\n","Epoch 151, Train Loss: 0.8495, Val Loss: 1.5142, F1 Micro: 0.5104, F1 Macro: 0.4944, Accuracy: 0.5104\n","Epoch 152, Train Loss: 0.8486, Val Loss: 2.2866, F1 Micro: 0.4688, F1 Macro: 0.4504, Accuracy: 0.4688\n","Epoch 153, Train Loss: 0.8231, Val Loss: 1.9765, F1 Micro: 0.4896, F1 Macro: 0.4601, Accuracy: 0.4896\n","Epoch 154, Train Loss: 0.8421, Val Loss: 2.2323, F1 Micro: 0.4375, F1 Macro: 0.3950, Accuracy: 0.4375\n","Epoch 155, Train Loss: 0.8161, Val Loss: 1.7769, F1 Micro: 0.5208, F1 Macro: 0.4940, Accuracy: 0.5208\n","Epoch 156, Train Loss: 0.8541, Val Loss: 1.9305, F1 Micro: 0.4479, F1 Macro: 0.4435, Accuracy: 0.4479\n","Epoch 157, Train Loss: 0.8468, Val Loss: 1.6147, F1 Micro: 0.5208, F1 Macro: 0.4944, Accuracy: 0.5208\n","Epoch 158, Train Loss: 0.8227, Val Loss: 2.0912, F1 Micro: 0.4375, F1 Macro: 0.3539, Accuracy: 0.4375\n","Epoch 159, Train Loss: 0.8386, Val Loss: 2.5237, F1 Micro: 0.4167, F1 Macro: 0.3691, Accuracy: 0.4167\n","Epoch 160, Train Loss: 0.9155, Val Loss: 1.7403, F1 Micro: 0.5417, F1 Macro: 0.4853, Accuracy: 0.5417\n","Epoch 161, Train Loss: 0.8017, Val Loss: 1.7256, F1 Micro: 0.4583, F1 Macro: 0.4182, Accuracy: 0.4583\n","Epoch 162, Train Loss: 0.8601, Val Loss: 2.2931, F1 Micro: 0.3958, F1 Macro: 0.3468, Accuracy: 0.3958\n","Epoch 163, Train Loss: 0.9191, Val Loss: 1.5504, F1 Micro: 0.4792, F1 Macro: 0.4445, Accuracy: 0.4792\n","Epoch 164, Train Loss: 0.8490, Val Loss: 1.8826, F1 Micro: 0.4375, F1 Macro: 0.4166, Accuracy: 0.4375\n","Epoch 165, Train Loss: 0.8031, Val Loss: 1.6428, F1 Micro: 0.5521, F1 Macro: 0.5245, Accuracy: 0.5521\n","Epoch 166, Train Loss: 0.7739, Val Loss: 1.9429, F1 Micro: 0.5312, F1 Macro: 0.5192, Accuracy: 0.5312\n","Epoch 167, Train Loss: 0.7741, Val Loss: 1.6666, F1 Micro: 0.5000, F1 Macro: 0.4803, Accuracy: 0.5000\n","Epoch 168, Train Loss: 0.8024, Val Loss: 1.9581, F1 Micro: 0.5417, F1 Macro: 0.5117, Accuracy: 0.5417\n","Epoch 169, Train Loss: 0.7667, Val Loss: 2.0979, F1 Micro: 0.4688, F1 Macro: 0.4088, Accuracy: 0.4688\n","Epoch 170, Train Loss: 0.7632, Val Loss: 1.7341, F1 Micro: 0.5000, F1 Macro: 0.4689, Accuracy: 0.5000\n","Epoch 171, Train Loss: 0.8183, Val Loss: 2.0354, F1 Micro: 0.5104, F1 Macro: 0.4979, Accuracy: 0.5104\n","Epoch 172, Train Loss: 0.7293, Val Loss: 1.8466, F1 Micro: 0.5208, F1 Macro: 0.5010, Accuracy: 0.5208\n","Epoch 173, Train Loss: 0.7247, Val Loss: 1.9209, F1 Micro: 0.5000, F1 Macro: 0.4819, Accuracy: 0.5000\n","Epoch 174, Train Loss: 0.8006, Val Loss: 1.9270, F1 Micro: 0.5000, F1 Macro: 0.4597, Accuracy: 0.5000\n","Epoch 175, Train Loss: 0.7463, Val Loss: 1.8759, F1 Micro: 0.4583, F1 Macro: 0.4311, Accuracy: 0.4583\n","Epoch 176, Train Loss: 0.7741, Val Loss: 1.9556, F1 Micro: 0.4479, F1 Macro: 0.4262, Accuracy: 0.4479\n","Epoch 177, Train Loss: 0.7309, Val Loss: 1.9381, F1 Micro: 0.5312, F1 Macro: 0.5156, Accuracy: 0.5312\n","Epoch 178, Train Loss: 0.7918, Val Loss: 1.8810, F1 Micro: 0.4688, F1 Macro: 0.4297, Accuracy: 0.4688\n","Epoch 179, Train Loss: 0.7726, Val Loss: 2.5204, F1 Micro: 0.3333, F1 Macro: 0.2871, Accuracy: 0.3333\n","Epoch 180, Train Loss: 0.7280, Val Loss: 1.7667, F1 Micro: 0.5729, F1 Macro: 0.5394, Accuracy: 0.5729\n","Epoch 181, Train Loss: 0.7740, Val Loss: 1.8083, F1 Micro: 0.4896, F1 Macro: 0.4492, Accuracy: 0.4896\n","Epoch 182, Train Loss: 0.7611, Val Loss: 1.6907, F1 Micro: 0.5312, F1 Macro: 0.4858, Accuracy: 0.5312\n","Epoch 183, Train Loss: 0.7447, Val Loss: 1.6656, F1 Micro: 0.5625, F1 Macro: 0.5378, Accuracy: 0.5625\n","Epoch 184, Train Loss: 0.7245, Val Loss: 1.8665, F1 Micro: 0.4271, F1 Macro: 0.4199, Accuracy: 0.4271\n","Epoch 185, Train Loss: 0.6795, Val Loss: 1.9430, F1 Micro: 0.4896, F1 Macro: 0.4679, Accuracy: 0.4896\n","Epoch 186, Train Loss: 0.6986, Val Loss: 2.0098, F1 Micro: 0.4688, F1 Macro: 0.4629, Accuracy: 0.4688\n","Epoch 187, Train Loss: 0.7481, Val Loss: 1.8351, F1 Micro: 0.5312, F1 Macro: 0.4907, Accuracy: 0.5312\n","Epoch 188, Train Loss: 0.7285, Val Loss: 1.8886, F1 Micro: 0.5417, F1 Macro: 0.5046, Accuracy: 0.5417\n","Epoch 189, Train Loss: 0.7476, Val Loss: 2.3839, F1 Micro: 0.4896, F1 Macro: 0.4690, Accuracy: 0.4896\n","Epoch 190, Train Loss: 0.7397, Val Loss: 1.7920, F1 Micro: 0.5000, F1 Macro: 0.4739, Accuracy: 0.5000\n","Epoch 191, Train Loss: 0.6466, Val Loss: 2.2741, F1 Micro: 0.4479, F1 Macro: 0.4366, Accuracy: 0.4479\n","Epoch 192, Train Loss: 0.6126, Val Loss: 1.8578, F1 Micro: 0.4896, F1 Macro: 0.4430, Accuracy: 0.4896\n","Epoch 193, Train Loss: 0.7155, Val Loss: 2.0175, F1 Micro: 0.4792, F1 Macro: 0.4855, Accuracy: 0.4792\n","Epoch 194, Train Loss: 0.7541, Val Loss: 1.6315, F1 Micro: 0.5312, F1 Macro: 0.5029, Accuracy: 0.5312\n","Epoch 195, Train Loss: 0.6423, Val Loss: 1.9229, F1 Micro: 0.5521, F1 Macro: 0.5336, Accuracy: 0.5521\n","Epoch 196, Train Loss: 0.6522, Val Loss: 2.0176, F1 Micro: 0.5000, F1 Macro: 0.4905, Accuracy: 0.5000\n","Epoch 197, Train Loss: 0.6951, Val Loss: 1.9445, F1 Micro: 0.4792, F1 Macro: 0.4363, Accuracy: 0.4792\n","Epoch 198, Train Loss: 0.7287, Val Loss: 1.7380, F1 Micro: 0.4271, F1 Macro: 0.3798, Accuracy: 0.4271\n","Epoch 199, Train Loss: 0.7421, Val Loss: 1.8554, F1 Micro: 0.5417, F1 Macro: 0.5111, Accuracy: 0.5417\n","Epoch 200, Train Loss: 0.6481, Val Loss: 2.1424, F1 Micro: 0.5208, F1 Macro: 0.5072, Accuracy: 0.5208\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.7863, Val Loss: 2.0600, F1 Micro: 0.1354, F1 Macro: 0.1002, Accuracy: 0.1354\n","Epoch 2, Train Loss: 1.7409, Val Loss: 1.7473, F1 Micro: 0.2396, F1 Macro: 0.1075, Accuracy: 0.2396\n","Epoch 3, Train Loss: 1.7185, Val Loss: 1.7479, F1 Micro: 0.3021, F1 Macro: 0.2208, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.7175, Val Loss: 1.7549, F1 Micro: 0.2396, F1 Macro: 0.1067, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.7167, Val Loss: 1.6838, F1 Micro: 0.3333, F1 Macro: 0.2106, Accuracy: 0.3333\n","Epoch 6, Train Loss: 1.6926, Val Loss: 1.6921, F1 Micro: 0.2812, F1 Macro: 0.1948, Accuracy: 0.2812\n","Epoch 7, Train Loss: 1.6657, Val Loss: 1.6987, F1 Micro: 0.3333, F1 Macro: 0.2400, Accuracy: 0.3333\n","Epoch 8, Train Loss: 1.6547, Val Loss: 1.6673, F1 Micro: 0.3438, F1 Macro: 0.2993, Accuracy: 0.3438\n","Epoch 9, Train Loss: 1.6460, Val Loss: 1.9606, F1 Micro: 0.2500, F1 Macro: 0.1873, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.6541, Val Loss: 1.6354, F1 Micro: 0.3958, F1 Macro: 0.3338, Accuracy: 0.3958\n","Epoch 11, Train Loss: 1.6359, Val Loss: 1.6609, F1 Micro: 0.2917, F1 Macro: 0.2312, Accuracy: 0.2917\n","Epoch 12, Train Loss: 1.6257, Val Loss: 1.9040, F1 Micro: 0.2396, F1 Macro: 0.1343, Accuracy: 0.2396\n","Epoch 13, Train Loss: 1.6142, Val Loss: 1.8354, F1 Micro: 0.2292, F1 Macro: 0.1856, Accuracy: 0.2292\n","Epoch 14, Train Loss: 1.6052, Val Loss: 1.7130, F1 Micro: 0.3229, F1 Macro: 0.2673, Accuracy: 0.3229\n","Epoch 15, Train Loss: 1.6112, Val Loss: 1.6302, F1 Micro: 0.3542, F1 Macro: 0.3051, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.6371, Val Loss: 1.7595, F1 Micro: 0.3021, F1 Macro: 0.2969, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.6106, Val Loss: 1.7053, F1 Micro: 0.3229, F1 Macro: 0.2903, Accuracy: 0.3229\n","Epoch 18, Train Loss: 1.5496, Val Loss: 1.8174, F1 Micro: 0.2708, F1 Macro: 0.2310, Accuracy: 0.2708\n","Epoch 19, Train Loss: 1.5626, Val Loss: 1.8190, F1 Micro: 0.3229, F1 Macro: 0.2342, Accuracy: 0.3229\n","Epoch 20, Train Loss: 1.5579, Val Loss: 1.6601, F1 Micro: 0.3750, F1 Macro: 0.2965, Accuracy: 0.3750\n","Epoch 21, Train Loss: 1.5340, Val Loss: 1.9550, F1 Micro: 0.2917, F1 Macro: 0.2357, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.5297, Val Loss: 1.6805, F1 Micro: 0.3229, F1 Macro: 0.2615, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.5624, Val Loss: 1.8558, F1 Micro: 0.3542, F1 Macro: 0.2359, Accuracy: 0.3542\n","Epoch 24, Train Loss: 1.5183, Val Loss: 1.6654, F1 Micro: 0.3542, F1 Macro: 0.3061, Accuracy: 0.3542\n","Epoch 25, Train Loss: 1.4961, Val Loss: 1.6274, F1 Micro: 0.3333, F1 Macro: 0.2831, Accuracy: 0.3333\n","Epoch 26, Train Loss: 1.5052, Val Loss: 1.9983, F1 Micro: 0.3229, F1 Macro: 0.2347, Accuracy: 0.3229\n","Epoch 27, Train Loss: 1.4623, Val Loss: 1.7789, F1 Micro: 0.3333, F1 Macro: 0.2689, Accuracy: 0.3333\n","Epoch 28, Train Loss: 1.4743, Val Loss: 1.8516, F1 Micro: 0.3542, F1 Macro: 0.2826, Accuracy: 0.3542\n","Epoch 29, Train Loss: 1.4788, Val Loss: 2.1002, F1 Micro: 0.2604, F1 Macro: 0.2637, Accuracy: 0.2604\n","Epoch 30, Train Loss: 1.4427, Val Loss: 1.7296, F1 Micro: 0.3750, F1 Macro: 0.3044, Accuracy: 0.3750\n","Epoch 31, Train Loss: 1.4329, Val Loss: 1.6118, F1 Micro: 0.4062, F1 Macro: 0.3447, Accuracy: 0.4062\n","Epoch 32, Train Loss: 1.4322, Val Loss: 1.9003, F1 Micro: 0.3854, F1 Macro: 0.3283, Accuracy: 0.3854\n","Epoch 33, Train Loss: 1.4513, Val Loss: 1.8229, F1 Micro: 0.3542, F1 Macro: 0.2828, Accuracy: 0.3542\n","Epoch 34, Train Loss: 1.4197, Val Loss: 2.0472, F1 Micro: 0.3438, F1 Macro: 0.2555, Accuracy: 0.3438\n","Epoch 35, Train Loss: 1.4005, Val Loss: 1.7332, F1 Micro: 0.3854, F1 Macro: 0.3164, Accuracy: 0.3854\n","Epoch 36, Train Loss: 1.3633, Val Loss: 1.8549, F1 Micro: 0.3750, F1 Macro: 0.3016, Accuracy: 0.3750\n","Epoch 37, Train Loss: 1.3990, Val Loss: 1.9500, F1 Micro: 0.2708, F1 Macro: 0.2582, Accuracy: 0.2708\n","Epoch 38, Train Loss: 1.3840, Val Loss: 1.7072, F1 Micro: 0.3438, F1 Macro: 0.2926, Accuracy: 0.3438\n","Epoch 39, Train Loss: 1.4170, Val Loss: 1.8384, F1 Micro: 0.2917, F1 Macro: 0.2633, Accuracy: 0.2917\n","Epoch 40, Train Loss: 1.3819, Val Loss: 1.7267, F1 Micro: 0.3854, F1 Macro: 0.3260, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.3298, Val Loss: 1.6534, F1 Micro: 0.3750, F1 Macro: 0.3008, Accuracy: 0.3750\n","Epoch 42, Train Loss: 1.3478, Val Loss: 1.5778, F1 Micro: 0.3750, F1 Macro: 0.3361, Accuracy: 0.3750\n","Epoch 43, Train Loss: 1.3704, Val Loss: 1.8008, F1 Micro: 0.3750, F1 Macro: 0.3111, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.3262, Val Loss: 1.8836, F1 Micro: 0.3333, F1 Macro: 0.2822, Accuracy: 0.3333\n","Epoch 45, Train Loss: 1.3784, Val Loss: 1.8238, F1 Micro: 0.3750, F1 Macro: 0.2975, Accuracy: 0.3750\n","Epoch 46, Train Loss: 1.3692, Val Loss: 1.7094, F1 Micro: 0.4167, F1 Macro: 0.3496, Accuracy: 0.4167\n","Epoch 47, Train Loss: 1.3095, Val Loss: 1.8395, F1 Micro: 0.3854, F1 Macro: 0.3189, Accuracy: 0.3854\n","Epoch 48, Train Loss: 1.3029, Val Loss: 2.2476, F1 Micro: 0.3854, F1 Macro: 0.2905, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.2821, Val Loss: 1.6154, F1 Micro: 0.4375, F1 Macro: 0.3648, Accuracy: 0.4375\n","Epoch 50, Train Loss: 1.3033, Val Loss: 1.8116, F1 Micro: 0.3958, F1 Macro: 0.3388, Accuracy: 0.3958\n","Epoch 51, Train Loss: 1.2924, Val Loss: 1.9163, F1 Micro: 0.4062, F1 Macro: 0.3602, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.2621, Val Loss: 1.6194, F1 Micro: 0.4479, F1 Macro: 0.3752, Accuracy: 0.4479\n","Epoch 53, Train Loss: 1.2627, Val Loss: 1.7269, F1 Micro: 0.4271, F1 Macro: 0.3725, Accuracy: 0.4271\n","Epoch 54, Train Loss: 1.2102, Val Loss: 1.6965, F1 Micro: 0.3854, F1 Macro: 0.3146, Accuracy: 0.3854\n","Epoch 55, Train Loss: 1.2293, Val Loss: 1.7006, F1 Micro: 0.3958, F1 Macro: 0.3340, Accuracy: 0.3958\n","Epoch 56, Train Loss: 1.2453, Val Loss: 1.8190, F1 Micro: 0.3438, F1 Macro: 0.3021, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.2082, Val Loss: 1.5312, F1 Micro: 0.4688, F1 Macro: 0.4201, Accuracy: 0.4688\n","Epoch 58, Train Loss: 1.1908, Val Loss: 1.9253, F1 Micro: 0.3438, F1 Macro: 0.3077, Accuracy: 0.3438\n","Epoch 59, Train Loss: 1.2184, Val Loss: 2.8775, F1 Micro: 0.3646, F1 Macro: 0.2864, Accuracy: 0.3646\n","Epoch 60, Train Loss: 1.2900, Val Loss: 1.5126, F1 Micro: 0.4375, F1 Macro: 0.3719, Accuracy: 0.4375\n","Epoch 61, Train Loss: 1.1779, Val Loss: 1.6363, F1 Micro: 0.4896, F1 Macro: 0.4238, Accuracy: 0.4896\n","Epoch 62, Train Loss: 1.2101, Val Loss: 1.5224, F1 Micro: 0.4583, F1 Macro: 0.4092, Accuracy: 0.4583\n","Epoch 63, Train Loss: 1.1473, Val Loss: 1.5801, F1 Micro: 0.4479, F1 Macro: 0.3745, Accuracy: 0.4479\n","Epoch 64, Train Loss: 1.1683, Val Loss: 1.7902, F1 Micro: 0.4271, F1 Macro: 0.3315, Accuracy: 0.4271\n","Epoch 65, Train Loss: 1.1512, Val Loss: 1.8820, F1 Micro: 0.3854, F1 Macro: 0.3607, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.1991, Val Loss: 1.5435, F1 Micro: 0.4896, F1 Macro: 0.4522, Accuracy: 0.4896\n","Epoch 67, Train Loss: 1.1602, Val Loss: 1.7572, F1 Micro: 0.3750, F1 Macro: 0.3327, Accuracy: 0.3750\n","Epoch 68, Train Loss: 1.1838, Val Loss: 1.5847, F1 Micro: 0.4479, F1 Macro: 0.4042, Accuracy: 0.4479\n","Epoch 69, Train Loss: 1.1500, Val Loss: 2.1521, F1 Micro: 0.3125, F1 Macro: 0.2890, Accuracy: 0.3125\n","Epoch 70, Train Loss: 1.1374, Val Loss: 1.9730, F1 Micro: 0.4167, F1 Macro: 0.3415, Accuracy: 0.4167\n","Epoch 71, Train Loss: 1.1459, Val Loss: 1.5085, F1 Micro: 0.4896, F1 Macro: 0.4543, Accuracy: 0.4896\n","Epoch 72, Train Loss: 1.1729, Val Loss: 1.6562, F1 Micro: 0.4583, F1 Macro: 0.3827, Accuracy: 0.4583\n","Epoch 73, Train Loss: 1.1175, Val Loss: 2.7990, F1 Micro: 0.2292, F1 Macro: 0.1754, Accuracy: 0.2292\n","Epoch 74, Train Loss: 1.1650, Val Loss: 1.7845, F1 Micro: 0.4062, F1 Macro: 0.3634, Accuracy: 0.4062\n","Epoch 75, Train Loss: 1.1503, Val Loss: 1.8079, F1 Micro: 0.4271, F1 Macro: 0.4029, Accuracy: 0.4271\n","Epoch 76, Train Loss: 1.1175, Val Loss: 1.6497, F1 Micro: 0.4896, F1 Macro: 0.4621, Accuracy: 0.4896\n","Epoch 77, Train Loss: 1.0732, Val Loss: 1.8090, F1 Micro: 0.4688, F1 Macro: 0.4085, Accuracy: 0.4688\n","Epoch 78, Train Loss: 1.1255, Val Loss: 2.2790, F1 Micro: 0.4167, F1 Macro: 0.3578, Accuracy: 0.4167\n","Epoch 79, Train Loss: 1.1074, Val Loss: 1.7253, F1 Micro: 0.4792, F1 Macro: 0.4147, Accuracy: 0.4792\n","Epoch 80, Train Loss: 1.0350, Val Loss: 1.6771, F1 Micro: 0.5104, F1 Macro: 0.4736, Accuracy: 0.5104\n","Epoch 81, Train Loss: 1.1073, Val Loss: 1.5835, F1 Micro: 0.5000, F1 Macro: 0.4837, Accuracy: 0.5000\n","Epoch 82, Train Loss: 1.0606, Val Loss: 2.3367, F1 Micro: 0.3438, F1 Macro: 0.3067, Accuracy: 0.3438\n","Epoch 83, Train Loss: 1.0850, Val Loss: 1.6782, F1 Micro: 0.4688, F1 Macro: 0.4380, Accuracy: 0.4688\n","Epoch 84, Train Loss: 1.1505, Val Loss: 1.7917, F1 Micro: 0.4688, F1 Macro: 0.4094, Accuracy: 0.4688\n","Epoch 85, Train Loss: 1.0622, Val Loss: 1.8724, F1 Micro: 0.4583, F1 Macro: 0.4008, Accuracy: 0.4583\n","Epoch 86, Train Loss: 1.0789, Val Loss: 1.5516, F1 Micro: 0.5417, F1 Macro: 0.4991, Accuracy: 0.5417\n","Epoch 87, Train Loss: 1.0672, Val Loss: 1.7828, F1 Micro: 0.4167, F1 Macro: 0.3567, Accuracy: 0.4167\n","Epoch 88, Train Loss: 1.0576, Val Loss: 1.6176, F1 Micro: 0.4688, F1 Macro: 0.4494, Accuracy: 0.4688\n","Epoch 89, Train Loss: 1.0580, Val Loss: 1.6783, F1 Micro: 0.4688, F1 Macro: 0.4256, Accuracy: 0.4688\n","Epoch 90, Train Loss: 1.0377, Val Loss: 2.1033, F1 Micro: 0.4271, F1 Macro: 0.3580, Accuracy: 0.4271\n","Epoch 91, Train Loss: 1.0218, Val Loss: 1.8471, F1 Micro: 0.4479, F1 Macro: 0.4054, Accuracy: 0.4479\n","Epoch 92, Train Loss: 1.0158, Val Loss: 2.3254, F1 Micro: 0.4271, F1 Macro: 0.3754, Accuracy: 0.4271\n","Epoch 93, Train Loss: 1.0711, Val Loss: 1.5824, F1 Micro: 0.5208, F1 Macro: 0.4708, Accuracy: 0.5208\n","Epoch 94, Train Loss: 1.0115, Val Loss: 1.5324, F1 Micro: 0.4896, F1 Macro: 0.4560, Accuracy: 0.4896\n","Epoch 95, Train Loss: 0.9648, Val Loss: 1.9355, F1 Micro: 0.4583, F1 Macro: 0.4084, Accuracy: 0.4583\n","Epoch 96, Train Loss: 1.0740, Val Loss: 1.9573, F1 Micro: 0.4688, F1 Macro: 0.4096, Accuracy: 0.4688\n","Epoch 97, Train Loss: 0.9906, Val Loss: 1.5932, F1 Micro: 0.5000, F1 Macro: 0.4409, Accuracy: 0.5000\n","Epoch 98, Train Loss: 0.9805, Val Loss: 2.1919, F1 Micro: 0.3438, F1 Macro: 0.3255, Accuracy: 0.3438\n","Epoch 99, Train Loss: 0.9787, Val Loss: 1.5919, F1 Micro: 0.4792, F1 Macro: 0.4631, Accuracy: 0.4792\n","Epoch 100, Train Loss: 0.9150, Val Loss: 1.8169, F1 Micro: 0.4792, F1 Macro: 0.4527, Accuracy: 0.4792\n","Epoch 101, Train Loss: 1.0502, Val Loss: 2.1796, F1 Micro: 0.4062, F1 Macro: 0.3655, Accuracy: 0.4062\n","Epoch 102, Train Loss: 0.9540, Val Loss: 1.9925, F1 Micro: 0.4167, F1 Macro: 0.3936, Accuracy: 0.4167\n","Epoch 103, Train Loss: 0.9904, Val Loss: 1.7455, F1 Micro: 0.4896, F1 Macro: 0.4618, Accuracy: 0.4896\n","Epoch 104, Train Loss: 1.0607, Val Loss: 2.4874, F1 Micro: 0.3854, F1 Macro: 0.3673, Accuracy: 0.3854\n","Epoch 105, Train Loss: 0.9440, Val Loss: 1.7354, F1 Micro: 0.4896, F1 Macro: 0.4755, Accuracy: 0.4896\n","Epoch 106, Train Loss: 0.9795, Val Loss: 2.0542, F1 Micro: 0.3646, F1 Macro: 0.3330, Accuracy: 0.3646\n","Epoch 107, Train Loss: 0.9966, Val Loss: 1.6994, F1 Micro: 0.4688, F1 Macro: 0.4836, Accuracy: 0.4688\n","Epoch 108, Train Loss: 0.9734, Val Loss: 1.9988, F1 Micro: 0.4062, F1 Macro: 0.3618, Accuracy: 0.4062\n","Epoch 109, Train Loss: 0.9222, Val Loss: 1.7603, F1 Micro: 0.4896, F1 Macro: 0.4265, Accuracy: 0.4896\n","Epoch 110, Train Loss: 0.8886, Val Loss: 1.8634, F1 Micro: 0.4271, F1 Macro: 0.4106, Accuracy: 0.4271\n","Epoch 111, Train Loss: 0.9282, Val Loss: 1.8936, F1 Micro: 0.4896, F1 Macro: 0.4464, Accuracy: 0.4896\n","Epoch 112, Train Loss: 0.9426, Val Loss: 1.5388, F1 Micro: 0.4688, F1 Macro: 0.4345, Accuracy: 0.4688\n","Epoch 113, Train Loss: 0.9722, Val Loss: 1.6201, F1 Micro: 0.5417, F1 Macro: 0.5011, Accuracy: 0.5417\n","Epoch 114, Train Loss: 0.9552, Val Loss: 1.8530, F1 Micro: 0.4167, F1 Macro: 0.4143, Accuracy: 0.4167\n","Epoch 115, Train Loss: 0.8961, Val Loss: 2.0464, F1 Micro: 0.4167, F1 Macro: 0.3957, Accuracy: 0.4167\n","Epoch 116, Train Loss: 0.9425, Val Loss: 1.8319, F1 Micro: 0.4688, F1 Macro: 0.4377, Accuracy: 0.4688\n","Epoch 117, Train Loss: 0.9123, Val Loss: 1.5896, F1 Micro: 0.5417, F1 Macro: 0.5139, Accuracy: 0.5417\n","Epoch 118, Train Loss: 0.9080, Val Loss: 1.7938, F1 Micro: 0.4792, F1 Macro: 0.4268, Accuracy: 0.4792\n","Epoch 119, Train Loss: 0.8878, Val Loss: 1.8855, F1 Micro: 0.4375, F1 Macro: 0.3740, Accuracy: 0.4375\n","Epoch 120, Train Loss: 0.8867, Val Loss: 1.7097, F1 Micro: 0.4896, F1 Macro: 0.4364, Accuracy: 0.4896\n","Epoch 121, Train Loss: 0.8422, Val Loss: 2.0710, F1 Micro: 0.4479, F1 Macro: 0.3893, Accuracy: 0.4479\n","Epoch 122, Train Loss: 0.9147, Val Loss: 1.8478, F1 Micro: 0.5000, F1 Macro: 0.4482, Accuracy: 0.5000\n","Epoch 123, Train Loss: 0.9122, Val Loss: 2.2856, F1 Micro: 0.4062, F1 Macro: 0.3623, Accuracy: 0.4062\n","Epoch 124, Train Loss: 0.8855, Val Loss: 1.7807, F1 Micro: 0.5312, F1 Macro: 0.4995, Accuracy: 0.5312\n","Epoch 125, Train Loss: 0.8540, Val Loss: 1.9093, F1 Micro: 0.4688, F1 Macro: 0.4488, Accuracy: 0.4688\n","Epoch 126, Train Loss: 0.8640, Val Loss: 1.6818, F1 Micro: 0.4896, F1 Macro: 0.4594, Accuracy: 0.4896\n","Epoch 127, Train Loss: 0.8878, Val Loss: 1.6563, F1 Micro: 0.5000, F1 Macro: 0.4757, Accuracy: 0.5000\n","Epoch 128, Train Loss: 0.8254, Val Loss: 1.7857, F1 Micro: 0.5000, F1 Macro: 0.4829, Accuracy: 0.5000\n","Epoch 129, Train Loss: 0.8982, Val Loss: 1.6900, F1 Micro: 0.5417, F1 Macro: 0.4926, Accuracy: 0.5417\n","Epoch 130, Train Loss: 0.8630, Val Loss: 2.2804, F1 Micro: 0.4583, F1 Macro: 0.4400, Accuracy: 0.4583\n","Epoch 131, Train Loss: 0.9115, Val Loss: 1.7733, F1 Micro: 0.5104, F1 Macro: 0.4834, Accuracy: 0.5104\n","Epoch 132, Train Loss: 0.8587, Val Loss: 1.7154, F1 Micro: 0.4792, F1 Macro: 0.4355, Accuracy: 0.4792\n","Epoch 133, Train Loss: 0.8405, Val Loss: 2.2432, F1 Micro: 0.3750, F1 Macro: 0.3441, Accuracy: 0.3750\n","Epoch 134, Train Loss: 0.8594, Val Loss: 1.6744, F1 Micro: 0.5417, F1 Macro: 0.5036, Accuracy: 0.5417\n","Epoch 135, Train Loss: 0.8097, Val Loss: 1.8211, F1 Micro: 0.4583, F1 Macro: 0.4281, Accuracy: 0.4583\n","Epoch 136, Train Loss: 0.8536, Val Loss: 2.0187, F1 Micro: 0.4479, F1 Macro: 0.4018, Accuracy: 0.4479\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8080, Val Loss: 1.7840, F1 Micro: 0.2396, F1 Macro: 0.1773, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7145, Val Loss: 2.1440, F1 Micro: 0.1771, F1 Macro: 0.1191, Accuracy: 0.1771\n","Epoch 3, Train Loss: 1.7510, Val Loss: 1.8218, F1 Micro: 0.1771, F1 Macro: 0.1303, Accuracy: 0.1771\n","Epoch 4, Train Loss: 1.7034, Val Loss: 1.9132, F1 Micro: 0.1875, F1 Macro: 0.1426, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.6879, Val Loss: 1.7348, F1 Micro: 0.2812, F1 Macro: 0.2451, Accuracy: 0.2812\n","Epoch 6, Train Loss: 1.6805, Val Loss: 1.8018, F1 Micro: 0.2292, F1 Macro: 0.1623, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.6602, Val Loss: 1.8131, F1 Micro: 0.2708, F1 Macro: 0.2070, Accuracy: 0.2708\n","Epoch 8, Train Loss: 1.6466, Val Loss: 1.7316, F1 Micro: 0.2812, F1 Macro: 0.2104, Accuracy: 0.2812\n","Epoch 9, Train Loss: 1.6347, Val Loss: 1.8047, F1 Micro: 0.2500, F1 Macro: 0.2114, Accuracy: 0.2500\n","Epoch 10, Train Loss: 1.6462, Val Loss: 1.7578, F1 Micro: 0.3333, F1 Macro: 0.2773, Accuracy: 0.3333\n","Epoch 11, Train Loss: 1.6562, Val Loss: 1.7213, F1 Micro: 0.3542, F1 Macro: 0.3167, Accuracy: 0.3542\n","Epoch 12, Train Loss: 1.6380, Val Loss: 1.7502, F1 Micro: 0.2917, F1 Macro: 0.2538, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.6034, Val Loss: 1.6982, F1 Micro: 0.3021, F1 Macro: 0.2654, Accuracy: 0.3021\n","Epoch 14, Train Loss: 1.6259, Val Loss: 1.7250, F1 Micro: 0.3021, F1 Macro: 0.2633, Accuracy: 0.3021\n","Epoch 15, Train Loss: 1.6354, Val Loss: 1.7349, F1 Micro: 0.3542, F1 Macro: 0.2908, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.6100, Val Loss: 1.7552, F1 Micro: 0.3021, F1 Macro: 0.2330, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.5940, Val Loss: 1.6713, F1 Micro: 0.3854, F1 Macro: 0.3457, Accuracy: 0.3854\n","Epoch 18, Train Loss: 1.5842, Val Loss: 1.7247, F1 Micro: 0.3542, F1 Macro: 0.3087, Accuracy: 0.3542\n","Epoch 19, Train Loss: 1.5982, Val Loss: 1.8155, F1 Micro: 0.3229, F1 Macro: 0.2736, Accuracy: 0.3229\n","Epoch 20, Train Loss: 1.5695, Val Loss: 1.6665, F1 Micro: 0.3750, F1 Macro: 0.3232, Accuracy: 0.3750\n","Epoch 21, Train Loss: 1.5725, Val Loss: 1.6897, F1 Micro: 0.3229, F1 Macro: 0.2789, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.5623, Val Loss: 1.7881, F1 Micro: 0.2917, F1 Macro: 0.2550, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.5506, Val Loss: 1.6672, F1 Micro: 0.3438, F1 Macro: 0.3147, Accuracy: 0.3438\n","Epoch 24, Train Loss: 1.5679, Val Loss: 1.6031, F1 Micro: 0.3958, F1 Macro: 0.3501, Accuracy: 0.3958\n","Epoch 25, Train Loss: 1.5482, Val Loss: 1.7337, F1 Micro: 0.3646, F1 Macro: 0.3300, Accuracy: 0.3646\n","Epoch 26, Train Loss: 1.5071, Val Loss: 1.6810, F1 Micro: 0.3854, F1 Macro: 0.3578, Accuracy: 0.3854\n","Epoch 27, Train Loss: 1.5396, Val Loss: 1.7082, F1 Micro: 0.3229, F1 Macro: 0.2753, Accuracy: 0.3229\n","Epoch 28, Train Loss: 1.5113, Val Loss: 2.0050, F1 Micro: 0.2812, F1 Macro: 0.2343, Accuracy: 0.2812\n","Epoch 29, Train Loss: 1.5121, Val Loss: 1.7425, F1 Micro: 0.3333, F1 Macro: 0.2847, Accuracy: 0.3333\n","Epoch 30, Train Loss: 1.5023, Val Loss: 1.7743, F1 Micro: 0.3438, F1 Macro: 0.3213, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.5081, Val Loss: 1.8314, F1 Micro: 0.3125, F1 Macro: 0.2945, Accuracy: 0.3125\n","Epoch 32, Train Loss: 1.5040, Val Loss: 1.6247, F1 Micro: 0.4271, F1 Macro: 0.3699, Accuracy: 0.4271\n","Epoch 33, Train Loss: 1.4874, Val Loss: 1.7466, F1 Micro: 0.3229, F1 Macro: 0.2690, Accuracy: 0.3229\n","Epoch 34, Train Loss: 1.4649, Val Loss: 1.7394, F1 Micro: 0.3750, F1 Macro: 0.3286, Accuracy: 0.3750\n","Epoch 35, Train Loss: 1.4577, Val Loss: 1.7719, F1 Micro: 0.3646, F1 Macro: 0.3303, Accuracy: 0.3646\n","Epoch 36, Train Loss: 1.4265, Val Loss: 1.7036, F1 Micro: 0.3646, F1 Macro: 0.3291, Accuracy: 0.3646\n","Epoch 37, Train Loss: 1.4583, Val Loss: 2.2220, F1 Micro: 0.2917, F1 Macro: 0.2602, Accuracy: 0.2917\n","Epoch 38, Train Loss: 1.4408, Val Loss: 2.1422, F1 Micro: 0.2917, F1 Macro: 0.2581, Accuracy: 0.2917\n","Epoch 39, Train Loss: 1.4478, Val Loss: 1.6308, F1 Micro: 0.3854, F1 Macro: 0.3221, Accuracy: 0.3854\n","Epoch 40, Train Loss: 1.4497, Val Loss: 1.6169, F1 Micro: 0.3854, F1 Macro: 0.3340, Accuracy: 0.3854\n","Epoch 41, Train Loss: 1.4459, Val Loss: 1.8032, F1 Micro: 0.3854, F1 Macro: 0.3493, Accuracy: 0.3854\n","Epoch 42, Train Loss: 1.4482, Val Loss: 1.6727, F1 Micro: 0.3854, F1 Macro: 0.3432, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.4272, Val Loss: 1.8784, F1 Micro: 0.3333, F1 Macro: 0.2928, Accuracy: 0.3333\n","Epoch 44, Train Loss: 1.4559, Val Loss: 1.9224, F1 Micro: 0.3854, F1 Macro: 0.3193, Accuracy: 0.3854\n","Epoch 45, Train Loss: 1.4003, Val Loss: 1.8240, F1 Micro: 0.3021, F1 Macro: 0.2567, Accuracy: 0.3021\n","Epoch 46, Train Loss: 1.4152, Val Loss: 1.6560, F1 Micro: 0.4167, F1 Macro: 0.3518, Accuracy: 0.4167\n","Epoch 47, Train Loss: 1.3988, Val Loss: 1.8225, F1 Micro: 0.3854, F1 Macro: 0.3797, Accuracy: 0.3854\n","Epoch 48, Train Loss: 1.3780, Val Loss: 1.7741, F1 Micro: 0.3438, F1 Macro: 0.3072, Accuracy: 0.3438\n","Epoch 49, Train Loss: 1.4280, Val Loss: 1.7375, F1 Micro: 0.3646, F1 Macro: 0.3338, Accuracy: 0.3646\n","Epoch 50, Train Loss: 1.3769, Val Loss: 1.8282, F1 Micro: 0.2917, F1 Macro: 0.2260, Accuracy: 0.2917\n","Epoch 51, Train Loss: 1.3819, Val Loss: 1.8488, F1 Micro: 0.3854, F1 Macro: 0.3802, Accuracy: 0.3854\n","Epoch 52, Train Loss: 1.4072, Val Loss: 1.5824, F1 Micro: 0.4375, F1 Macro: 0.3807, Accuracy: 0.4375\n","Epoch 53, Train Loss: 1.3604, Val Loss: 1.8767, F1 Micro: 0.4062, F1 Macro: 0.3532, Accuracy: 0.4062\n","Epoch 54, Train Loss: 1.3672, Val Loss: 1.6082, F1 Micro: 0.3854, F1 Macro: 0.3301, Accuracy: 0.3854\n","Epoch 55, Train Loss: 1.3583, Val Loss: 2.0176, F1 Micro: 0.4062, F1 Macro: 0.3683, Accuracy: 0.4062\n","Epoch 56, Train Loss: 1.3871, Val Loss: 1.8703, F1 Micro: 0.2604, F1 Macro: 0.2051, Accuracy: 0.2604\n","Epoch 57, Train Loss: 1.3430, Val Loss: 1.5699, F1 Micro: 0.4271, F1 Macro: 0.3824, Accuracy: 0.4271\n","Epoch 58, Train Loss: 1.3672, Val Loss: 1.7149, F1 Micro: 0.3750, F1 Macro: 0.3202, Accuracy: 0.3750\n","Epoch 59, Train Loss: 1.2986, Val Loss: 1.8550, F1 Micro: 0.4271, F1 Macro: 0.3731, Accuracy: 0.4271\n","Epoch 60, Train Loss: 1.3247, Val Loss: 2.1367, F1 Micro: 0.3229, F1 Macro: 0.2973, Accuracy: 0.3229\n","Epoch 61, Train Loss: 1.3118, Val Loss: 1.6353, F1 Micro: 0.3750, F1 Macro: 0.3322, Accuracy: 0.3750\n","Epoch 62, Train Loss: 1.3008, Val Loss: 1.8366, F1 Micro: 0.4167, F1 Macro: 0.3673, Accuracy: 0.4167\n","Epoch 63, Train Loss: 1.3356, Val Loss: 1.5616, F1 Micro: 0.4062, F1 Macro: 0.3556, Accuracy: 0.4062\n","Epoch 64, Train Loss: 1.3185, Val Loss: 1.5623, F1 Micro: 0.4479, F1 Macro: 0.4128, Accuracy: 0.4479\n","Epoch 65, Train Loss: 1.3415, Val Loss: 1.6782, F1 Micro: 0.4479, F1 Macro: 0.4327, Accuracy: 0.4479\n","Epoch 66, Train Loss: 1.2968, Val Loss: 1.5719, F1 Micro: 0.3646, F1 Macro: 0.3314, Accuracy: 0.3646\n","Epoch 67, Train Loss: 1.2731, Val Loss: 1.6929, F1 Micro: 0.3438, F1 Macro: 0.3213, Accuracy: 0.3438\n","Epoch 68, Train Loss: 1.3127, Val Loss: 3.0984, F1 Micro: 0.2083, F1 Macro: 0.1235, Accuracy: 0.2083\n","Epoch 69, Train Loss: 1.3330, Val Loss: 2.6605, F1 Micro: 0.2604, F1 Macro: 0.2165, Accuracy: 0.2604\n","Epoch 70, Train Loss: 1.2777, Val Loss: 1.9357, F1 Micro: 0.3542, F1 Macro: 0.3387, Accuracy: 0.3542\n","Epoch 71, Train Loss: 1.2785, Val Loss: 1.6101, F1 Micro: 0.3958, F1 Macro: 0.3570, Accuracy: 0.3958\n","Epoch 72, Train Loss: 1.2622, Val Loss: 2.0649, F1 Micro: 0.3021, F1 Macro: 0.2135, Accuracy: 0.3021\n","Epoch 73, Train Loss: 1.2559, Val Loss: 2.2731, F1 Micro: 0.3958, F1 Macro: 0.3172, Accuracy: 0.3958\n","Epoch 74, Train Loss: 1.2849, Val Loss: 1.8282, F1 Micro: 0.3646, F1 Macro: 0.3086, Accuracy: 0.3646\n","Epoch 75, Train Loss: 1.2454, Val Loss: 1.7511, F1 Micro: 0.3958, F1 Macro: 0.3906, Accuracy: 0.3958\n","Epoch 76, Train Loss: 1.2304, Val Loss: 1.6364, F1 Micro: 0.4062, F1 Macro: 0.3617, Accuracy: 0.4062\n","Epoch 77, Train Loss: 1.2985, Val Loss: 2.2191, F1 Micro: 0.2812, F1 Macro: 0.2479, Accuracy: 0.2812\n","Epoch 78, Train Loss: 1.2159, Val Loss: 1.5703, F1 Micro: 0.3958, F1 Macro: 0.3799, Accuracy: 0.3958\n","Epoch 79, Train Loss: 1.2564, Val Loss: 1.7184, F1 Micro: 0.3854, F1 Macro: 0.3552, Accuracy: 0.3854\n","Epoch 80, Train Loss: 1.2152, Val Loss: 1.8051, F1 Micro: 0.3958, F1 Macro: 0.3692, Accuracy: 0.3958\n","Epoch 81, Train Loss: 1.1985, Val Loss: 2.8121, F1 Micro: 0.2292, F1 Macro: 0.1987, Accuracy: 0.2292\n","Epoch 82, Train Loss: 1.2113, Val Loss: 1.7899, F1 Micro: 0.3438, F1 Macro: 0.2842, Accuracy: 0.3438\n","Epoch 83, Train Loss: 1.2004, Val Loss: 1.6173, F1 Micro: 0.3854, F1 Macro: 0.3581, Accuracy: 0.3854\n","Epoch 84, Train Loss: 1.1762, Val Loss: 2.0268, F1 Micro: 0.4167, F1 Macro: 0.3773, Accuracy: 0.4167\n","Epoch 85, Train Loss: 1.1848, Val Loss: 1.8684, F1 Micro: 0.3854, F1 Macro: 0.3581, Accuracy: 0.3854\n","Epoch 86, Train Loss: 1.1875, Val Loss: 1.9049, F1 Micro: 0.3333, F1 Macro: 0.3213, Accuracy: 0.3333\n","Epoch 87, Train Loss: 1.1984, Val Loss: 2.2764, F1 Micro: 0.2917, F1 Macro: 0.2670, Accuracy: 0.2917\n","Epoch 88, Train Loss: 1.1919, Val Loss: 1.9173, F1 Micro: 0.3750, F1 Macro: 0.3297, Accuracy: 0.3750\n","Epoch 89, Train Loss: 1.1751, Val Loss: 1.6863, F1 Micro: 0.4375, F1 Macro: 0.4164, Accuracy: 0.4375\n","Epoch 90, Train Loss: 1.1295, Val Loss: 1.8003, F1 Micro: 0.3854, F1 Macro: 0.3793, Accuracy: 0.3854\n","Epoch 91, Train Loss: 1.1535, Val Loss: 1.9553, F1 Micro: 0.3229, F1 Macro: 0.2956, Accuracy: 0.3229\n","Epoch 92, Train Loss: 1.1351, Val Loss: 2.7810, F1 Micro: 0.3021, F1 Macro: 0.2564, Accuracy: 0.3021\n","Epoch 93, Train Loss: 1.1637, Val Loss: 2.2688, F1 Micro: 0.4062, F1 Macro: 0.3793, Accuracy: 0.4062\n","Epoch 94, Train Loss: 1.1620, Val Loss: 1.7447, F1 Micro: 0.3958, F1 Macro: 0.3802, Accuracy: 0.3958\n","Epoch 95, Train Loss: 1.1195, Val Loss: 1.8023, F1 Micro: 0.4062, F1 Macro: 0.3963, Accuracy: 0.4062\n","Epoch 96, Train Loss: 1.1640, Val Loss: 2.8996, F1 Micro: 0.2917, F1 Macro: 0.2290, Accuracy: 0.2917\n","Epoch 97, Train Loss: 1.1311, Val Loss: 1.6507, F1 Micro: 0.4375, F1 Macro: 0.4172, Accuracy: 0.4375\n","Epoch 98, Train Loss: 1.1227, Val Loss: 1.5900, F1 Micro: 0.4479, F1 Macro: 0.4218, Accuracy: 0.4479\n","Epoch 99, Train Loss: 1.1427, Val Loss: 1.5587, F1 Micro: 0.3750, F1 Macro: 0.3525, Accuracy: 0.3750\n","Epoch 100, Train Loss: 1.0782, Val Loss: 1.9203, F1 Micro: 0.3646, F1 Macro: 0.3753, Accuracy: 0.3646\n","Epoch 101, Train Loss: 1.1057, Val Loss: 1.6823, F1 Micro: 0.4583, F1 Macro: 0.4457, Accuracy: 0.4583\n","Epoch 102, Train Loss: 1.0724, Val Loss: 1.8125, F1 Micro: 0.4583, F1 Macro: 0.4359, Accuracy: 0.4583\n","Epoch 103, Train Loss: 1.0982, Val Loss: 1.6360, F1 Micro: 0.4375, F1 Macro: 0.4305, Accuracy: 0.4375\n","Epoch 104, Train Loss: 1.0770, Val Loss: 1.6606, F1 Micro: 0.4375, F1 Macro: 0.4265, Accuracy: 0.4375\n","Epoch 105, Train Loss: 1.0751, Val Loss: 2.2320, F1 Micro: 0.3021, F1 Macro: 0.2251, Accuracy: 0.3021\n","Epoch 106, Train Loss: 1.0824, Val Loss: 2.6145, F1 Micro: 0.3333, F1 Macro: 0.3249, Accuracy: 0.3333\n","Epoch 107, Train Loss: 1.0873, Val Loss: 1.8361, F1 Micro: 0.3229, F1 Macro: 0.2635, Accuracy: 0.3229\n","Epoch 108, Train Loss: 1.1078, Val Loss: 1.7905, F1 Micro: 0.4583, F1 Macro: 0.4196, Accuracy: 0.4583\n","Epoch 109, Train Loss: 1.0780, Val Loss: 2.1146, F1 Micro: 0.3750, F1 Macro: 0.3655, Accuracy: 0.3750\n","Epoch 110, Train Loss: 1.0194, Val Loss: 1.6863, F1 Micro: 0.4062, F1 Macro: 0.3886, Accuracy: 0.4062\n","Epoch 111, Train Loss: 1.0645, Val Loss: 1.7119, F1 Micro: 0.3750, F1 Macro: 0.3409, Accuracy: 0.3750\n","Epoch 112, Train Loss: 1.1010, Val Loss: 1.9213, F1 Micro: 0.3438, F1 Macro: 0.3236, Accuracy: 0.3438\n","Epoch 113, Train Loss: 1.1045, Val Loss: 1.9369, F1 Micro: 0.3021, F1 Macro: 0.2871, Accuracy: 0.3021\n","Epoch 114, Train Loss: 1.1288, Val Loss: 1.8293, F1 Micro: 0.3646, F1 Macro: 0.2980, Accuracy: 0.3646\n","Epoch 115, Train Loss: 1.0675, Val Loss: 1.7554, F1 Micro: 0.3958, F1 Macro: 0.3851, Accuracy: 0.3958\n","Epoch 116, Train Loss: 0.9770, Val Loss: 1.6916, F1 Micro: 0.4688, F1 Macro: 0.4536, Accuracy: 0.4688\n","Epoch 117, Train Loss: 0.9437, Val Loss: 1.9524, F1 Micro: 0.4479, F1 Macro: 0.4108, Accuracy: 0.4479\n","Epoch 118, Train Loss: 0.9756, Val Loss: 1.8460, F1 Micro: 0.3854, F1 Macro: 0.3595, Accuracy: 0.3854\n","Epoch 119, Train Loss: 0.9811, Val Loss: 1.7414, F1 Micro: 0.3854, F1 Macro: 0.3481, Accuracy: 0.3854\n","Epoch 120, Train Loss: 1.0019, Val Loss: 1.8512, F1 Micro: 0.5104, F1 Macro: 0.4906, Accuracy: 0.5104\n","Epoch 121, Train Loss: 0.9793, Val Loss: 2.3786, F1 Micro: 0.3333, F1 Macro: 0.2601, Accuracy: 0.3333\n","Epoch 122, Train Loss: 1.0100, Val Loss: 1.6955, F1 Micro: 0.4271, F1 Macro: 0.4092, Accuracy: 0.4271\n","Epoch 123, Train Loss: 0.9598, Val Loss: 1.8386, F1 Micro: 0.3958, F1 Macro: 0.3830, Accuracy: 0.3958\n","Epoch 124, Train Loss: 0.9538, Val Loss: 1.5299, F1 Micro: 0.4792, F1 Macro: 0.4627, Accuracy: 0.4792\n","Epoch 125, Train Loss: 1.0210, Val Loss: 1.7166, F1 Micro: 0.4062, F1 Macro: 0.3951, Accuracy: 0.4062\n","Epoch 126, Train Loss: 0.9469, Val Loss: 2.1154, F1 Micro: 0.3646, F1 Macro: 0.3780, Accuracy: 0.3646\n","Epoch 127, Train Loss: 0.9856, Val Loss: 4.3739, F1 Micro: 0.2188, F1 Macro: 0.1558, Accuracy: 0.2188\n","Epoch 128, Train Loss: 0.9983, Val Loss: 1.7714, F1 Micro: 0.4062, F1 Macro: 0.3763, Accuracy: 0.4062\n","Epoch 129, Train Loss: 0.9339, Val Loss: 1.7437, F1 Micro: 0.4583, F1 Macro: 0.4392, Accuracy: 0.4583\n","Epoch 130, Train Loss: 0.9515, Val Loss: 1.7979, F1 Micro: 0.4688, F1 Macro: 0.4571, Accuracy: 0.4688\n","Epoch 131, Train Loss: 0.9240, Val Loss: 3.0585, F1 Micro: 0.2812, F1 Macro: 0.2190, Accuracy: 0.2812\n","Epoch 132, Train Loss: 1.0161, Val Loss: 1.6917, F1 Micro: 0.3958, F1 Macro: 0.3930, Accuracy: 0.3958\n","Epoch 133, Train Loss: 0.9172, Val Loss: 1.9583, F1 Micro: 0.4375, F1 Macro: 0.4148, Accuracy: 0.4375\n","Epoch 134, Train Loss: 0.8948, Val Loss: 1.8110, F1 Micro: 0.4479, F1 Macro: 0.4331, Accuracy: 0.4479\n","Epoch 135, Train Loss: 0.8360, Val Loss: 1.7599, F1 Micro: 0.4688, F1 Macro: 0.4669, Accuracy: 0.4688\n","Epoch 136, Train Loss: 0.9334, Val Loss: 2.0450, F1 Micro: 0.4375, F1 Macro: 0.4124, Accuracy: 0.4375\n","Epoch 137, Train Loss: 0.8639, Val Loss: 1.8360, F1 Micro: 0.4271, F1 Macro: 0.4040, Accuracy: 0.4271\n","Epoch 138, Train Loss: 0.8398, Val Loss: 2.0105, F1 Micro: 0.4583, F1 Macro: 0.4496, Accuracy: 0.4583\n","Epoch 139, Train Loss: 0.9172, Val Loss: 2.2443, F1 Micro: 0.4792, F1 Macro: 0.4561, Accuracy: 0.4792\n","Epoch 140, Train Loss: 0.8911, Val Loss: 1.8153, F1 Micro: 0.4167, F1 Macro: 0.3955, Accuracy: 0.4167\n","Epoch 141, Train Loss: 0.9314, Val Loss: 1.7627, F1 Micro: 0.4688, F1 Macro: 0.4613, Accuracy: 0.4688\n","Epoch 142, Train Loss: 0.8812, Val Loss: 1.9911, F1 Micro: 0.4167, F1 Macro: 0.4005, Accuracy: 0.4167\n","Epoch 143, Train Loss: 0.8904, Val Loss: 2.6794, F1 Micro: 0.3021, F1 Macro: 0.2698, Accuracy: 0.3021\n","Epoch 144, Train Loss: 0.8796, Val Loss: 2.0504, F1 Micro: 0.3750, F1 Macro: 0.3548, Accuracy: 0.3750\n","Epoch 145, Train Loss: 0.8194, Val Loss: 1.6583, F1 Micro: 0.4479, F1 Macro: 0.4306, Accuracy: 0.4479\n","Epoch 146, Train Loss: 0.9439, Val Loss: 1.7683, F1 Micro: 0.4583, F1 Macro: 0.4421, Accuracy: 0.4583\n","Epoch 147, Train Loss: 0.8936, Val Loss: 2.4877, F1 Micro: 0.3333, F1 Macro: 0.3033, Accuracy: 0.3333\n","Epoch 148, Train Loss: 0.9011, Val Loss: 1.6597, F1 Micro: 0.4583, F1 Macro: 0.4424, Accuracy: 0.4583\n","Epoch 149, Train Loss: 0.8689, Val Loss: 1.9066, F1 Micro: 0.4271, F1 Macro: 0.4183, Accuracy: 0.4271\n","Epoch 150, Train Loss: 0.8766, Val Loss: 2.0687, F1 Micro: 0.4062, F1 Macro: 0.3881, Accuracy: 0.4062\n","Epoch 151, Train Loss: 0.9529, Val Loss: 1.7627, F1 Micro: 0.4375, F1 Macro: 0.4270, Accuracy: 0.4375\n","Epoch 152, Train Loss: 0.9174, Val Loss: 1.8974, F1 Micro: 0.3854, F1 Macro: 0.3509, Accuracy: 0.3854\n","Epoch 153, Train Loss: 0.8350, Val Loss: 1.7418, F1 Micro: 0.4375, F1 Macro: 0.4235, Accuracy: 0.4375\n","Epoch 154, Train Loss: 0.8309, Val Loss: 1.9677, F1 Micro: 0.3750, F1 Macro: 0.3611, Accuracy: 0.3750\n","Epoch 155, Train Loss: 0.8778, Val Loss: 1.6513, F1 Micro: 0.4479, F1 Macro: 0.4277, Accuracy: 0.4479\n","Epoch 156, Train Loss: 0.8117, Val Loss: 2.0880, F1 Micro: 0.3854, F1 Macro: 0.3589, Accuracy: 0.3854\n","Epoch 157, Train Loss: 0.8535, Val Loss: 2.2700, F1 Micro: 0.3750, F1 Macro: 0.3395, Accuracy: 0.3750\n","Epoch 158, Train Loss: 0.7701, Val Loss: 1.6689, F1 Micro: 0.4167, F1 Macro: 0.3791, Accuracy: 0.4167\n","Epoch 159, Train Loss: 0.8226, Val Loss: 1.7491, F1 Micro: 0.4479, F1 Macro: 0.4431, Accuracy: 0.4479\n","Epoch 160, Train Loss: 0.7814, Val Loss: 1.9882, F1 Micro: 0.4792, F1 Macro: 0.4796, Accuracy: 0.4792\n","Epoch 161, Train Loss: 0.7707, Val Loss: 1.9251, F1 Micro: 0.4479, F1 Macro: 0.4325, Accuracy: 0.4479\n","Epoch 162, Train Loss: 0.8115, Val Loss: 2.0239, F1 Micro: 0.3854, F1 Macro: 0.3604, Accuracy: 0.3854\n","Epoch 163, Train Loss: 0.9129, Val Loss: 1.8247, F1 Micro: 0.4062, F1 Macro: 0.3987, Accuracy: 0.4062\n","Epoch 164, Train Loss: 0.7709, Val Loss: 1.8763, F1 Micro: 0.5000, F1 Macro: 0.5001, Accuracy: 0.5000\n","Epoch 165, Train Loss: 0.7643, Val Loss: 1.9648, F1 Micro: 0.3750, F1 Macro: 0.3685, Accuracy: 0.3750\n","Epoch 166, Train Loss: 0.7984, Val Loss: 1.9875, F1 Micro: 0.4271, F1 Macro: 0.4141, Accuracy: 0.4271\n","Epoch 167, Train Loss: 0.8048, Val Loss: 1.9654, F1 Micro: 0.4583, F1 Macro: 0.4514, Accuracy: 0.4583\n","Epoch 168, Train Loss: 0.7824, Val Loss: 1.7752, F1 Micro: 0.5000, F1 Macro: 0.4763, Accuracy: 0.5000\n","Epoch 169, Train Loss: 0.8053, Val Loss: 1.9742, F1 Micro: 0.4375, F1 Macro: 0.4386, Accuracy: 0.4375\n","Epoch 170, Train Loss: 0.8060, Val Loss: 1.9695, F1 Micro: 0.5312, F1 Macro: 0.5289, Accuracy: 0.5312\n","Epoch 171, Train Loss: 0.7451, Val Loss: 2.0783, F1 Micro: 0.4062, F1 Macro: 0.3527, Accuracy: 0.4062\n","Epoch 172, Train Loss: 0.7852, Val Loss: 2.1365, F1 Micro: 0.5104, F1 Macro: 0.4998, Accuracy: 0.5104\n","Epoch 173, Train Loss: 0.7729, Val Loss: 1.9025, F1 Micro: 0.4583, F1 Macro: 0.4578, Accuracy: 0.4583\n","Epoch 174, Train Loss: 0.7530, Val Loss: 1.9477, F1 Micro: 0.4896, F1 Macro: 0.4801, Accuracy: 0.4896\n","Epoch 175, Train Loss: 0.8180, Val Loss: 2.3407, F1 Micro: 0.4375, F1 Macro: 0.4326, Accuracy: 0.4375\n","Epoch 176, Train Loss: 0.7780, Val Loss: 1.8823, F1 Micro: 0.4688, F1 Macro: 0.4510, Accuracy: 0.4688\n","Epoch 177, Train Loss: 0.7492, Val Loss: 1.9657, F1 Micro: 0.4479, F1 Macro: 0.4413, Accuracy: 0.4479\n","Epoch 178, Train Loss: 0.7227, Val Loss: 1.9366, F1 Micro: 0.3958, F1 Macro: 0.3654, Accuracy: 0.3958\n","Epoch 179, Train Loss: 0.7349, Val Loss: 1.9478, F1 Micro: 0.4062, F1 Macro: 0.3835, Accuracy: 0.4062\n","Epoch 180, Train Loss: 0.7379, Val Loss: 2.1606, F1 Micro: 0.3958, F1 Macro: 0.3861, Accuracy: 0.3958\n","Epoch 181, Train Loss: 0.8175, Val Loss: 1.9681, F1 Micro: 0.4792, F1 Macro: 0.4661, Accuracy: 0.4792\n","Epoch 182, Train Loss: 0.6884, Val Loss: 2.6591, F1 Micro: 0.3542, F1 Macro: 0.3440, Accuracy: 0.3542\n","Epoch 183, Train Loss: 0.7519, Val Loss: 2.0344, F1 Micro: 0.3854, F1 Macro: 0.3671, Accuracy: 0.3854\n","Epoch 184, Train Loss: 0.7041, Val Loss: 1.8751, F1 Micro: 0.4792, F1 Macro: 0.4723, Accuracy: 0.4792\n","Epoch 185, Train Loss: 0.7337, Val Loss: 2.1400, F1 Micro: 0.4792, F1 Macro: 0.4688, Accuracy: 0.4792\n","Epoch 186, Train Loss: 0.7197, Val Loss: 2.3800, F1 Micro: 0.3646, F1 Macro: 0.3386, Accuracy: 0.3646\n","Epoch 187, Train Loss: 0.7459, Val Loss: 1.6865, F1 Micro: 0.5417, F1 Macro: 0.5172, Accuracy: 0.5417\n","Epoch 188, Train Loss: 0.6361, Val Loss: 1.9667, F1 Micro: 0.4896, F1 Macro: 0.4789, Accuracy: 0.4896\n","Epoch 189, Train Loss: 0.6683, Val Loss: 2.1401, F1 Micro: 0.3958, F1 Macro: 0.3830, Accuracy: 0.3958\n","Epoch 190, Train Loss: 0.7063, Val Loss: 1.8345, F1 Micro: 0.4167, F1 Macro: 0.3960, Accuracy: 0.4167\n","Epoch 191, Train Loss: 0.7754, Val Loss: 1.8765, F1 Micro: 0.4583, F1 Macro: 0.4455, Accuracy: 0.4583\n","Epoch 192, Train Loss: 0.6990, Val Loss: 1.9623, F1 Micro: 0.4896, F1 Macro: 0.4721, Accuracy: 0.4896\n","Epoch 193, Train Loss: 0.6956, Val Loss: 2.0303, F1 Micro: 0.4688, F1 Macro: 0.4421, Accuracy: 0.4688\n","Epoch 194, Train Loss: 0.6971, Val Loss: 1.9778, F1 Micro: 0.4271, F1 Macro: 0.4298, Accuracy: 0.4271\n","Epoch 195, Train Loss: 0.7312, Val Loss: 2.0079, F1 Micro: 0.4167, F1 Macro: 0.4056, Accuracy: 0.4167\n","Epoch 196, Train Loss: 0.6819, Val Loss: 2.0445, F1 Micro: 0.5104, F1 Macro: 0.4919, Accuracy: 0.5104\n","Epoch 197, Train Loss: 0.7413, Val Loss: 2.9470, F1 Micro: 0.3854, F1 Macro: 0.3542, Accuracy: 0.3854\n","Epoch 198, Train Loss: 0.6808, Val Loss: 2.2695, F1 Micro: 0.4062, F1 Macro: 0.3813, Accuracy: 0.4062\n","Epoch 199, Train Loss: 0.7111, Val Loss: 2.2953, F1 Micro: 0.5208, F1 Macro: 0.5188, Accuracy: 0.5208\n","Epoch 200, Train Loss: 0.6481, Val Loss: 1.7679, F1 Micro: 0.5208, F1 Macro: 0.5044, Accuracy: 0.5208\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8252, Val Loss: 1.7817, F1 Micro: 0.1354, F1 Macro: 0.0442, Accuracy: 0.1354\n","Epoch 2, Train Loss: 1.7826, Val Loss: 1.7893, F1 Micro: 0.1667, F1 Macro: 0.0655, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.7155, Val Loss: 1.9336, F1 Micro: 0.1875, F1 Macro: 0.1298, Accuracy: 0.1875\n","Epoch 4, Train Loss: 1.7208, Val Loss: 1.8179, F1 Micro: 0.2292, F1 Macro: 0.1822, Accuracy: 0.2292\n","Epoch 5, Train Loss: 1.6947, Val Loss: 1.7784, F1 Micro: 0.1875, F1 Macro: 0.1559, Accuracy: 0.1875\n","Epoch 6, Train Loss: 1.6557, Val Loss: 1.7504, F1 Micro: 0.2500, F1 Macro: 0.2100, Accuracy: 0.2500\n","Epoch 7, Train Loss: 1.6696, Val Loss: 1.7462, F1 Micro: 0.2500, F1 Macro: 0.1974, Accuracy: 0.2500\n","Epoch 8, Train Loss: 1.6220, Val Loss: 1.8313, F1 Micro: 0.2396, F1 Macro: 0.1883, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.6237, Val Loss: 1.8146, F1 Micro: 0.2396, F1 Macro: 0.1750, Accuracy: 0.2396\n","Epoch 10, Train Loss: 1.6137, Val Loss: 1.7991, F1 Micro: 0.2396, F1 Macro: 0.1882, Accuracy: 0.2396\n","Epoch 11, Train Loss: 1.6122, Val Loss: 1.8594, F1 Micro: 0.2708, F1 Macro: 0.1965, Accuracy: 0.2708\n","Epoch 12, Train Loss: 1.5815, Val Loss: 1.9023, F1 Micro: 0.2708, F1 Macro: 0.1973, Accuracy: 0.2708\n","Epoch 13, Train Loss: 1.5681, Val Loss: 2.0436, F1 Micro: 0.2500, F1 Macro: 0.1818, Accuracy: 0.2500\n","Epoch 14, Train Loss: 1.5670, Val Loss: 1.6937, F1 Micro: 0.3125, F1 Macro: 0.2351, Accuracy: 0.3125\n","Epoch 15, Train Loss: 1.5897, Val Loss: 1.7323, F1 Micro: 0.2708, F1 Macro: 0.2123, Accuracy: 0.2708\n","Epoch 16, Train Loss: 1.5744, Val Loss: 2.1551, F1 Micro: 0.2292, F1 Macro: 0.1428, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.5336, Val Loss: 2.1247, F1 Micro: 0.2188, F1 Macro: 0.1468, Accuracy: 0.2188\n","Epoch 18, Train Loss: 1.5725, Val Loss: 1.6629, F1 Micro: 0.2917, F1 Macro: 0.2315, Accuracy: 0.2917\n","Epoch 19, Train Loss: 1.5055, Val Loss: 1.7348, F1 Micro: 0.3229, F1 Macro: 0.2658, Accuracy: 0.3229\n","Epoch 20, Train Loss: 1.5178, Val Loss: 1.7189, F1 Micro: 0.2708, F1 Macro: 0.2232, Accuracy: 0.2708\n","Epoch 21, Train Loss: 1.5063, Val Loss: 1.7217, F1 Micro: 0.3125, F1 Macro: 0.2605, Accuracy: 0.3125\n","Epoch 22, Train Loss: 1.5096, Val Loss: 1.8640, F1 Micro: 0.2917, F1 Macro: 0.2219, Accuracy: 0.2917\n","Epoch 23, Train Loss: 1.4992, Val Loss: 1.8359, F1 Micro: 0.3125, F1 Macro: 0.2613, Accuracy: 0.3125\n","Epoch 24, Train Loss: 1.4860, Val Loss: 2.0081, F1 Micro: 0.2917, F1 Macro: 0.2263, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.4735, Val Loss: 1.7020, F1 Micro: 0.2812, F1 Macro: 0.2250, Accuracy: 0.2812\n","Epoch 26, Train Loss: 1.4710, Val Loss: 2.1173, F1 Micro: 0.2396, F1 Macro: 0.1566, Accuracy: 0.2396\n","Epoch 27, Train Loss: 1.4675, Val Loss: 1.8719, F1 Micro: 0.2396, F1 Macro: 0.1442, Accuracy: 0.2396\n","Epoch 28, Train Loss: 1.4793, Val Loss: 1.9245, F1 Micro: 0.2812, F1 Macro: 0.2429, Accuracy: 0.2812\n","Epoch 29, Train Loss: 1.4733, Val Loss: 1.6948, F1 Micro: 0.3542, F1 Macro: 0.2934, Accuracy: 0.3542\n","Epoch 30, Train Loss: 1.4652, Val Loss: 1.9062, F1 Micro: 0.2812, F1 Macro: 0.1836, Accuracy: 0.2812\n","Epoch 31, Train Loss: 1.4811, Val Loss: 1.9651, F1 Micro: 0.2812, F1 Macro: 0.2103, Accuracy: 0.2812\n","Epoch 32, Train Loss: 1.4402, Val Loss: 1.9429, F1 Micro: 0.3021, F1 Macro: 0.2520, Accuracy: 0.3021\n","Epoch 33, Train Loss: 1.4543, Val Loss: 2.3807, F1 Micro: 0.3021, F1 Macro: 0.2466, Accuracy: 0.3021\n","Epoch 34, Train Loss: 1.4307, Val Loss: 1.7444, F1 Micro: 0.3125, F1 Macro: 0.2667, Accuracy: 0.3125\n","Epoch 35, Train Loss: 1.4722, Val Loss: 1.9012, F1 Micro: 0.3021, F1 Macro: 0.2460, Accuracy: 0.3021\n","Epoch 36, Train Loss: 1.4746, Val Loss: 1.9605, F1 Micro: 0.2812, F1 Macro: 0.1930, Accuracy: 0.2812\n","Epoch 37, Train Loss: 1.4437, Val Loss: 1.7096, F1 Micro: 0.3333, F1 Macro: 0.2774, Accuracy: 0.3333\n","Epoch 38, Train Loss: 1.4293, Val Loss: 1.7552, F1 Micro: 0.3021, F1 Macro: 0.2644, Accuracy: 0.3021\n","Epoch 39, Train Loss: 1.4365, Val Loss: 1.6813, F1 Micro: 0.3125, F1 Macro: 0.2740, Accuracy: 0.3125\n","Epoch 40, Train Loss: 1.3854, Val Loss: 1.7573, F1 Micro: 0.3021, F1 Macro: 0.2534, Accuracy: 0.3021\n","Epoch 41, Train Loss: 1.4100, Val Loss: 1.9182, F1 Micro: 0.2917, F1 Macro: 0.2296, Accuracy: 0.2917\n","Epoch 42, Train Loss: 1.4220, Val Loss: 2.0505, F1 Micro: 0.3229, F1 Macro: 0.2625, Accuracy: 0.3229\n","Epoch 43, Train Loss: 1.3865, Val Loss: 1.9681, F1 Micro: 0.2708, F1 Macro: 0.2017, Accuracy: 0.2708\n","Epoch 44, Train Loss: 1.4405, Val Loss: 1.6708, F1 Micro: 0.3229, F1 Macro: 0.2791, Accuracy: 0.3229\n","Epoch 45, Train Loss: 1.4095, Val Loss: 1.6944, F1 Micro: 0.3125, F1 Macro: 0.2949, Accuracy: 0.3125\n","Epoch 46, Train Loss: 1.4061, Val Loss: 1.7798, F1 Micro: 0.3125, F1 Macro: 0.2499, Accuracy: 0.3125\n","Epoch 47, Train Loss: 1.3700, Val Loss: 1.7250, F1 Micro: 0.3542, F1 Macro: 0.3193, Accuracy: 0.3542\n","Epoch 48, Train Loss: 1.3792, Val Loss: 1.8210, F1 Micro: 0.2917, F1 Macro: 0.2595, Accuracy: 0.2917\n","Epoch 49, Train Loss: 1.3594, Val Loss: 1.6082, F1 Micro: 0.3854, F1 Macro: 0.3779, Accuracy: 0.3854\n","Epoch 50, Train Loss: 1.3639, Val Loss: 1.7541, F1 Micro: 0.3021, F1 Macro: 0.2783, Accuracy: 0.3021\n","Epoch 51, Train Loss: 1.3404, Val Loss: 1.7472, F1 Micro: 0.3021, F1 Macro: 0.2530, Accuracy: 0.3021\n","Epoch 52, Train Loss: 1.3754, Val Loss: 1.8253, F1 Micro: 0.4062, F1 Macro: 0.3703, Accuracy: 0.4062\n","Epoch 53, Train Loss: 1.3969, Val Loss: 1.6271, F1 Micro: 0.3438, F1 Macro: 0.3272, Accuracy: 0.3438\n","Epoch 54, Train Loss: 1.3591, Val Loss: 1.9111, F1 Micro: 0.2917, F1 Macro: 0.2528, Accuracy: 0.2917\n","Epoch 55, Train Loss: 1.3739, Val Loss: 1.7031, F1 Micro: 0.3750, F1 Macro: 0.3558, Accuracy: 0.3750\n","Epoch 56, Train Loss: 1.3433, Val Loss: 1.7963, F1 Micro: 0.2917, F1 Macro: 0.2389, Accuracy: 0.2917\n","Epoch 57, Train Loss: 1.3279, Val Loss: 2.0527, F1 Micro: 0.3333, F1 Macro: 0.2836, Accuracy: 0.3333\n","Epoch 58, Train Loss: 1.3271, Val Loss: 1.7125, F1 Micro: 0.3750, F1 Macro: 0.3477, Accuracy: 0.3750\n","Epoch 59, Train Loss: 1.3165, Val Loss: 1.6530, F1 Micro: 0.3542, F1 Macro: 0.3363, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.2564, Val Loss: 1.7317, F1 Micro: 0.3646, F1 Macro: 0.3496, Accuracy: 0.3646\n","Epoch 61, Train Loss: 1.3317, Val Loss: 2.4297, F1 Micro: 0.3229, F1 Macro: 0.2624, Accuracy: 0.3229\n","Epoch 62, Train Loss: 1.3612, Val Loss: 1.9874, F1 Micro: 0.3021, F1 Macro: 0.2177, Accuracy: 0.3021\n","Epoch 63, Train Loss: 1.3160, Val Loss: 1.7517, F1 Micro: 0.3750, F1 Macro: 0.3649, Accuracy: 0.3750\n","Epoch 64, Train Loss: 1.3043, Val Loss: 1.6362, F1 Micro: 0.3646, F1 Macro: 0.3566, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.3002, Val Loss: 1.9075, F1 Micro: 0.3958, F1 Macro: 0.3663, Accuracy: 0.3958\n","Epoch 66, Train Loss: 1.2649, Val Loss: 2.0616, F1 Micro: 0.2917, F1 Macro: 0.2095, Accuracy: 0.2917\n","Epoch 67, Train Loss: 1.3067, Val Loss: 1.7093, F1 Micro: 0.3854, F1 Macro: 0.3729, Accuracy: 0.3854\n","Epoch 68, Train Loss: 1.2676, Val Loss: 1.7890, F1 Micro: 0.3438, F1 Macro: 0.3242, Accuracy: 0.3438\n","Epoch 69, Train Loss: 1.3078, Val Loss: 1.6767, F1 Micro: 0.3854, F1 Macro: 0.3747, Accuracy: 0.3854\n","Epoch 70, Train Loss: 1.2454, Val Loss: 1.6617, F1 Micro: 0.3438, F1 Macro: 0.3386, Accuracy: 0.3438\n","Epoch 71, Train Loss: 1.2772, Val Loss: 1.6425, F1 Micro: 0.3854, F1 Macro: 0.3879, Accuracy: 0.3854\n","Epoch 72, Train Loss: 1.2577, Val Loss: 1.7301, F1 Micro: 0.3646, F1 Macro: 0.3416, Accuracy: 0.3646\n","Epoch 73, Train Loss: 1.2862, Val Loss: 1.8066, F1 Micro: 0.3854, F1 Macro: 0.3682, Accuracy: 0.3854\n","Epoch 74, Train Loss: 1.2778, Val Loss: 1.6280, F1 Micro: 0.3229, F1 Macro: 0.3206, Accuracy: 0.3229\n","Epoch 75, Train Loss: 1.3015, Val Loss: 1.7243, F1 Micro: 0.3125, F1 Macro: 0.3010, Accuracy: 0.3125\n","Epoch 76, Train Loss: 1.2855, Val Loss: 1.6934, F1 Micro: 0.3854, F1 Macro: 0.3760, Accuracy: 0.3854\n","Epoch 77, Train Loss: 1.2431, Val Loss: 1.6705, F1 Micro: 0.3438, F1 Macro: 0.3319, Accuracy: 0.3438\n","Epoch 78, Train Loss: 1.2464, Val Loss: 1.6994, F1 Micro: 0.3958, F1 Macro: 0.3876, Accuracy: 0.3958\n","Epoch 79, Train Loss: 1.2463, Val Loss: 2.0087, F1 Micro: 0.3021, F1 Macro: 0.2631, Accuracy: 0.3021\n","Epoch 80, Train Loss: 1.2565, Val Loss: 2.0021, F1 Micro: 0.3438, F1 Macro: 0.3034, Accuracy: 0.3438\n","Epoch 81, Train Loss: 1.2095, Val Loss: 1.9578, F1 Micro: 0.3854, F1 Macro: 0.3426, Accuracy: 0.3854\n","Epoch 82, Train Loss: 1.2395, Val Loss: 1.7586, F1 Micro: 0.4062, F1 Macro: 0.3886, Accuracy: 0.4062\n","Epoch 83, Train Loss: 1.2309, Val Loss: 1.8707, F1 Micro: 0.3125, F1 Macro: 0.3084, Accuracy: 0.3125\n","Epoch 84, Train Loss: 1.2336, Val Loss: 1.8464, F1 Micro: 0.3958, F1 Macro: 0.3892, Accuracy: 0.3958\n","Epoch 85, Train Loss: 1.2253, Val Loss: 1.6836, F1 Micro: 0.4062, F1 Macro: 0.3892, Accuracy: 0.4062\n","Epoch 86, Train Loss: 1.2172, Val Loss: 1.9458, F1 Micro: 0.3750, F1 Macro: 0.3412, Accuracy: 0.3750\n","Epoch 87, Train Loss: 1.1985, Val Loss: 2.1043, F1 Micro: 0.2917, F1 Macro: 0.2652, Accuracy: 0.2917\n","Epoch 88, Train Loss: 1.1826, Val Loss: 1.8965, F1 Micro: 0.3125, F1 Macro: 0.2845, Accuracy: 0.3125\n","Epoch 89, Train Loss: 1.1785, Val Loss: 1.8133, F1 Micro: 0.3333, F1 Macro: 0.3278, Accuracy: 0.3333\n","Epoch 90, Train Loss: 1.1578, Val Loss: 1.8827, F1 Micro: 0.4271, F1 Macro: 0.4170, Accuracy: 0.4271\n","Epoch 91, Train Loss: 1.1924, Val Loss: 2.4325, F1 Micro: 0.3646, F1 Macro: 0.3420, Accuracy: 0.3646\n","Epoch 92, Train Loss: 1.2533, Val Loss: 1.7703, F1 Micro: 0.3646, F1 Macro: 0.3491, Accuracy: 0.3646\n","Epoch 93, Train Loss: 1.1317, Val Loss: 1.7809, F1 Micro: 0.4271, F1 Macro: 0.4266, Accuracy: 0.4271\n","Epoch 94, Train Loss: 1.1801, Val Loss: 1.7907, F1 Micro: 0.3958, F1 Macro: 0.3747, Accuracy: 0.3958\n","Epoch 95, Train Loss: 1.1804, Val Loss: 1.9419, F1 Micro: 0.3542, F1 Macro: 0.3391, Accuracy: 0.3542\n","Epoch 96, Train Loss: 1.1604, Val Loss: 1.6586, F1 Micro: 0.4479, F1 Macro: 0.4459, Accuracy: 0.4479\n","Epoch 97, Train Loss: 1.1422, Val Loss: 1.7577, F1 Micro: 0.4375, F1 Macro: 0.4271, Accuracy: 0.4375\n","Epoch 98, Train Loss: 1.1757, Val Loss: 1.7930, F1 Micro: 0.3958, F1 Macro: 0.3848, Accuracy: 0.3958\n","Epoch 99, Train Loss: 1.1962, Val Loss: 1.6644, F1 Micro: 0.3958, F1 Macro: 0.3907, Accuracy: 0.3958\n","Epoch 100, Train Loss: 1.1505, Val Loss: 2.0557, F1 Micro: 0.4271, F1 Macro: 0.4170, Accuracy: 0.4271\n","Epoch 101, Train Loss: 1.1653, Val Loss: 2.3810, F1 Micro: 0.3021, F1 Macro: 0.2670, Accuracy: 0.3021\n","Epoch 102, Train Loss: 1.1714, Val Loss: 2.0426, F1 Micro: 0.3958, F1 Macro: 0.3806, Accuracy: 0.3958\n","Epoch 103, Train Loss: 1.1122, Val Loss: 2.2956, F1 Micro: 0.4271, F1 Macro: 0.4162, Accuracy: 0.4271\n","Epoch 104, Train Loss: 1.1925, Val Loss: 1.7488, F1 Micro: 0.4167, F1 Macro: 0.4215, Accuracy: 0.4167\n","Epoch 105, Train Loss: 1.1500, Val Loss: 1.7599, F1 Micro: 0.3750, F1 Macro: 0.3722, Accuracy: 0.3750\n","Epoch 106, Train Loss: 1.1837, Val Loss: 1.7766, F1 Micro: 0.4479, F1 Macro: 0.4503, Accuracy: 0.4479\n","Epoch 107, Train Loss: 1.1547, Val Loss: 1.8318, F1 Micro: 0.4167, F1 Macro: 0.4229, Accuracy: 0.4167\n","Epoch 108, Train Loss: 1.1424, Val Loss: 1.9630, F1 Micro: 0.3958, F1 Macro: 0.3778, Accuracy: 0.3958\n","Epoch 109, Train Loss: 1.1643, Val Loss: 1.7990, F1 Micro: 0.4167, F1 Macro: 0.4027, Accuracy: 0.4167\n","Epoch 110, Train Loss: 1.1612, Val Loss: 1.9398, F1 Micro: 0.4062, F1 Macro: 0.3916, Accuracy: 0.4062\n","Epoch 111, Train Loss: 1.1186, Val Loss: 1.9973, F1 Micro: 0.3438, F1 Macro: 0.3294, Accuracy: 0.3438\n","Epoch 112, Train Loss: 1.1529, Val Loss: 1.9681, F1 Micro: 0.3750, F1 Macro: 0.3548, Accuracy: 0.3750\n","Epoch 113, Train Loss: 1.1523, Val Loss: 1.8307, F1 Micro: 0.3542, F1 Macro: 0.3383, Accuracy: 0.3542\n","Epoch 114, Train Loss: 1.1841, Val Loss: 1.8549, F1 Micro: 0.4583, F1 Macro: 0.4473, Accuracy: 0.4583\n","Epoch 115, Train Loss: 1.1337, Val Loss: 1.6791, F1 Micro: 0.4375, F1 Macro: 0.4320, Accuracy: 0.4375\n","Epoch 116, Train Loss: 1.1352, Val Loss: 1.9126, F1 Micro: 0.3854, F1 Macro: 0.3685, Accuracy: 0.3854\n","Epoch 117, Train Loss: 1.1667, Val Loss: 1.8547, F1 Micro: 0.4479, F1 Macro: 0.4374, Accuracy: 0.4479\n","Epoch 118, Train Loss: 1.1037, Val Loss: 1.8085, F1 Micro: 0.3854, F1 Macro: 0.3755, Accuracy: 0.3854\n","Epoch 119, Train Loss: 1.1147, Val Loss: 1.8190, F1 Micro: 0.4271, F1 Macro: 0.4274, Accuracy: 0.4271\n","Epoch 120, Train Loss: 1.0964, Val Loss: 1.9237, F1 Micro: 0.4167, F1 Macro: 0.4050, Accuracy: 0.4167\n","Epoch 121, Train Loss: 1.0978, Val Loss: 2.0168, F1 Micro: 0.3542, F1 Macro: 0.3525, Accuracy: 0.3542\n","Epoch 122, Train Loss: 1.1564, Val Loss: 1.8660, F1 Micro: 0.3646, F1 Macro: 0.3477, Accuracy: 0.3646\n","Epoch 123, Train Loss: 1.1100, Val Loss: 2.1959, F1 Micro: 0.3438, F1 Macro: 0.3283, Accuracy: 0.3438\n","Epoch 124, Train Loss: 1.1261, Val Loss: 2.0046, F1 Micro: 0.3958, F1 Macro: 0.3824, Accuracy: 0.3958\n","Epoch 125, Train Loss: 1.1041, Val Loss: 2.1816, F1 Micro: 0.3438, F1 Macro: 0.3277, Accuracy: 0.3438\n","Epoch 126, Train Loss: 1.1230, Val Loss: 1.8791, F1 Micro: 0.4375, F1 Macro: 0.4319, Accuracy: 0.4375\n","Epoch 127, Train Loss: 1.0861, Val Loss: 1.9415, F1 Micro: 0.3958, F1 Macro: 0.3833, Accuracy: 0.3958\n","Epoch 128, Train Loss: 1.1336, Val Loss: 1.7374, F1 Micro: 0.4583, F1 Macro: 0.4547, Accuracy: 0.4583\n","Epoch 129, Train Loss: 1.1053, Val Loss: 2.0039, F1 Micro: 0.3750, F1 Macro: 0.3508, Accuracy: 0.3750\n","Epoch 130, Train Loss: 1.0511, Val Loss: 1.8610, F1 Micro: 0.4167, F1 Macro: 0.4181, Accuracy: 0.4167\n","Epoch 131, Train Loss: 1.0657, Val Loss: 1.7824, F1 Micro: 0.4062, F1 Macro: 0.3983, Accuracy: 0.4062\n","Epoch 132, Train Loss: 1.0417, Val Loss: 1.7892, F1 Micro: 0.5000, F1 Macro: 0.4968, Accuracy: 0.5000\n","Epoch 133, Train Loss: 1.1322, Val Loss: 1.7192, F1 Micro: 0.4167, F1 Macro: 0.4150, Accuracy: 0.4167\n","Epoch 134, Train Loss: 1.0888, Val Loss: 1.9838, F1 Micro: 0.3750, F1 Macro: 0.3578, Accuracy: 0.3750\n","Epoch 135, Train Loss: 1.0955, Val Loss: 1.8094, F1 Micro: 0.4062, F1 Macro: 0.3934, Accuracy: 0.4062\n","Epoch 136, Train Loss: 1.0845, Val Loss: 1.8229, F1 Micro: 0.4479, F1 Macro: 0.4311, Accuracy: 0.4479\n","Epoch 137, Train Loss: 1.0436, Val Loss: 2.2574, F1 Micro: 0.3854, F1 Macro: 0.3690, Accuracy: 0.3854\n","Epoch 138, Train Loss: 1.0256, Val Loss: 2.1386, F1 Micro: 0.3958, F1 Macro: 0.3957, Accuracy: 0.3958\n","Epoch 139, Train Loss: 1.0567, Val Loss: 1.9461, F1 Micro: 0.4583, F1 Macro: 0.4567, Accuracy: 0.4583\n","Epoch 140, Train Loss: 1.1157, Val Loss: 1.7564, F1 Micro: 0.3750, F1 Macro: 0.3609, Accuracy: 0.3750\n","Epoch 141, Train Loss: 1.0772, Val Loss: 2.0035, F1 Micro: 0.4167, F1 Macro: 0.3999, Accuracy: 0.4167\n","Epoch 142, Train Loss: 1.0533, Val Loss: 2.3022, F1 Micro: 0.3646, F1 Macro: 0.3579, Accuracy: 0.3646\n","Epoch 143, Train Loss: 1.0617, Val Loss: 2.1189, F1 Micro: 0.4271, F1 Macro: 0.4275, Accuracy: 0.4271\n","Epoch 144, Train Loss: 1.1008, Val Loss: 2.2466, F1 Micro: 0.3854, F1 Macro: 0.3559, Accuracy: 0.3854\n","Epoch 145, Train Loss: 1.0630, Val Loss: 1.9605, F1 Micro: 0.4479, F1 Macro: 0.4450, Accuracy: 0.4479\n","Epoch 146, Train Loss: 1.0357, Val Loss: 1.9511, F1 Micro: 0.3854, F1 Macro: 0.3743, Accuracy: 0.3854\n","Epoch 147, Train Loss: 1.0627, Val Loss: 1.7493, F1 Micro: 0.4062, F1 Macro: 0.4148, Accuracy: 0.4062\n","Epoch 148, Train Loss: 1.0426, Val Loss: 1.8271, F1 Micro: 0.4583, F1 Macro: 0.4612, Accuracy: 0.4583\n","Epoch 149, Train Loss: 1.0359, Val Loss: 2.1367, F1 Micro: 0.4479, F1 Macro: 0.4322, Accuracy: 0.4479\n","Epoch 150, Train Loss: 1.0239, Val Loss: 2.2802, F1 Micro: 0.3958, F1 Macro: 0.3904, Accuracy: 0.3958\n","Epoch 151, Train Loss: 0.9930, Val Loss: 1.8894, F1 Micro: 0.4062, F1 Macro: 0.3950, Accuracy: 0.4062\n","Epoch 152, Train Loss: 1.0331, Val Loss: 2.1367, F1 Micro: 0.4792, F1 Macro: 0.4671, Accuracy: 0.4792\n","Epoch 153, Train Loss: 1.0383, Val Loss: 2.1445, F1 Micro: 0.4062, F1 Macro: 0.4061, Accuracy: 0.4062\n","Epoch 154, Train Loss: 1.0477, Val Loss: 2.0077, F1 Micro: 0.4688, F1 Macro: 0.4679, Accuracy: 0.4688\n","Epoch 155, Train Loss: 1.0384, Val Loss: 3.7077, F1 Micro: 0.3125, F1 Macro: 0.2850, Accuracy: 0.3125\n","Epoch 156, Train Loss: 1.0341, Val Loss: 1.8884, F1 Micro: 0.4375, F1 Macro: 0.4287, Accuracy: 0.4375\n","Epoch 157, Train Loss: 1.0135, Val Loss: 2.0776, F1 Micro: 0.4479, F1 Macro: 0.4485, Accuracy: 0.4479\n","Epoch 158, Train Loss: 1.0320, Val Loss: 1.6790, F1 Micro: 0.4375, F1 Macro: 0.4268, Accuracy: 0.4375\n","Epoch 159, Train Loss: 0.9933, Val Loss: 1.8288, F1 Micro: 0.4479, F1 Macro: 0.4404, Accuracy: 0.4479\n","Epoch 160, Train Loss: 1.0129, Val Loss: 1.8563, F1 Micro: 0.5000, F1 Macro: 0.4949, Accuracy: 0.5000\n","Epoch 161, Train Loss: 1.0333, Val Loss: 2.2764, F1 Micro: 0.3750, F1 Macro: 0.3607, Accuracy: 0.3750\n","Epoch 162, Train Loss: 0.9862, Val Loss: 1.8022, F1 Micro: 0.4688, F1 Macro: 0.4606, Accuracy: 0.4688\n","Epoch 163, Train Loss: 0.9768, Val Loss: 2.2944, F1 Micro: 0.4583, F1 Macro: 0.4457, Accuracy: 0.4583\n","Epoch 164, Train Loss: 0.9658, Val Loss: 2.3509, F1 Micro: 0.3021, F1 Macro: 0.2634, Accuracy: 0.3021\n","Epoch 165, Train Loss: 0.9951, Val Loss: 2.2665, F1 Micro: 0.4062, F1 Macro: 0.3892, Accuracy: 0.4062\n","Epoch 166, Train Loss: 0.9963, Val Loss: 2.0099, F1 Micro: 0.4375, F1 Macro: 0.4363, Accuracy: 0.4375\n","Epoch 167, Train Loss: 0.9857, Val Loss: 1.8222, F1 Micro: 0.4792, F1 Macro: 0.4792, Accuracy: 0.4792\n","Epoch 168, Train Loss: 0.9730, Val Loss: 1.9994, F1 Micro: 0.4479, F1 Macro: 0.4465, Accuracy: 0.4479\n","Epoch 169, Train Loss: 1.0063, Val Loss: 2.0841, F1 Micro: 0.4479, F1 Macro: 0.4388, Accuracy: 0.4479\n","Epoch 170, Train Loss: 1.0188, Val Loss: 1.7730, F1 Micro: 0.4271, F1 Macro: 0.4173, Accuracy: 0.4271\n","Epoch 171, Train Loss: 0.9857, Val Loss: 1.8970, F1 Micro: 0.3854, F1 Macro: 0.3535, Accuracy: 0.3854\n","Epoch 172, Train Loss: 1.0027, Val Loss: 2.1857, F1 Micro: 0.4479, F1 Macro: 0.4473, Accuracy: 0.4479\n","Epoch 173, Train Loss: 0.9827, Val Loss: 2.2430, F1 Micro: 0.4062, F1 Macro: 0.4027, Accuracy: 0.4062\n","Epoch 174, Train Loss: 0.9482, Val Loss: 2.1184, F1 Micro: 0.3646, F1 Macro: 0.3507, Accuracy: 0.3646\n","Epoch 175, Train Loss: 0.9863, Val Loss: 1.8556, F1 Micro: 0.4688, F1 Macro: 0.4593, Accuracy: 0.4688\n","Epoch 176, Train Loss: 0.9562, Val Loss: 3.2458, F1 Micro: 0.3854, F1 Macro: 0.3674, Accuracy: 0.3854\n","Epoch 177, Train Loss: 1.0562, Val Loss: 2.0112, F1 Micro: 0.4271, F1 Macro: 0.4248, Accuracy: 0.4271\n","Epoch 178, Train Loss: 0.9483, Val Loss: 2.2582, F1 Micro: 0.4479, F1 Macro: 0.4529, Accuracy: 0.4479\n","Epoch 179, Train Loss: 1.0273, Val Loss: 1.9381, F1 Micro: 0.4583, F1 Macro: 0.4573, Accuracy: 0.4583\n","Epoch 180, Train Loss: 0.9737, Val Loss: 2.2350, F1 Micro: 0.3958, F1 Macro: 0.3879, Accuracy: 0.3958\n","Epoch 181, Train Loss: 0.9178, Val Loss: 1.9778, F1 Micro: 0.4688, F1 Macro: 0.4756, Accuracy: 0.4688\n","Epoch 182, Train Loss: 0.9388, Val Loss: 2.1061, F1 Micro: 0.4375, F1 Macro: 0.4374, Accuracy: 0.4375\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.5354166666666667\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.7768, Val Loss: 1.7210, F1 Micro: 0.2396, F1 Macro: 0.1506, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7388, Val Loss: 1.7377, F1 Micro: 0.2812, F1 Macro: 0.2267, Accuracy: 0.2812\n","Epoch 3, Train Loss: 1.7148, Val Loss: 1.7047, F1 Micro: 0.3021, F1 Macro: 0.2613, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.6880, Val Loss: 1.7787, F1 Micro: 0.1875, F1 Macro: 0.1760, Accuracy: 0.1875\n","Epoch 5, Train Loss: 1.6927, Val Loss: 1.7485, F1 Micro: 0.2083, F1 Macro: 0.1599, Accuracy: 0.2083\n","Epoch 6, Train Loss: 1.6806, Val Loss: 1.6899, F1 Micro: 0.2604, F1 Macro: 0.2238, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.6751, Val Loss: 1.7640, F1 Micro: 0.2604, F1 Macro: 0.2362, Accuracy: 0.2604\n","Epoch 8, Train Loss: 1.6837, Val Loss: 1.6936, F1 Micro: 0.2604, F1 Macro: 0.2324, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.6612, Val Loss: 1.7098, F1 Micro: 0.2812, F1 Macro: 0.2520, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.6497, Val Loss: 1.7225, F1 Micro: 0.2708, F1 Macro: 0.2463, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.6475, Val Loss: 1.7187, F1 Micro: 0.2500, F1 Macro: 0.1746, Accuracy: 0.2500\n","Epoch 12, Train Loss: 1.6221, Val Loss: 2.0177, F1 Micro: 0.2083, F1 Macro: 0.1494, Accuracy: 0.2083\n","Epoch 13, Train Loss: 1.6472, Val Loss: 1.8163, F1 Micro: 0.2188, F1 Macro: 0.1741, Accuracy: 0.2188\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8393, Val Loss: 1.8393, F1 Micro: 0.1458, F1 Macro: 0.0872, Accuracy: 0.1458\n","Epoch 2, Train Loss: 1.7452, Val Loss: 1.8813, F1 Micro: 0.1667, F1 Macro: 0.1206, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.7349, Val Loss: 1.8963, F1 Micro: 0.2396, F1 Macro: 0.1417, Accuracy: 0.2396\n","Epoch 4, Train Loss: 1.7484, Val Loss: 1.8993, F1 Micro: 0.2604, F1 Macro: 0.1589, Accuracy: 0.2604\n","Epoch 5, Train Loss: 1.7218, Val Loss: 1.8028, F1 Micro: 0.3021, F1 Macro: 0.2384, Accuracy: 0.3021\n","Epoch 6, Train Loss: 1.7318, Val Loss: 1.8163, F1 Micro: 0.2083, F1 Macro: 0.1511, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.7186, Val Loss: 1.7899, F1 Micro: 0.1875, F1 Macro: 0.1314, Accuracy: 0.1875\n","Epoch 8, Train Loss: 1.6803, Val Loss: 1.8325, F1 Micro: 0.2604, F1 Macro: 0.2534, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.6897, Val Loss: 1.8409, F1 Micro: 0.1771, F1 Macro: 0.1254, Accuracy: 0.1771\n","Epoch 10, Train Loss: 1.6685, Val Loss: 1.8736, F1 Micro: 0.1979, F1 Macro: 0.1543, Accuracy: 0.1979\n","Epoch 11, Train Loss: 1.6687, Val Loss: 1.7899, F1 Micro: 0.3021, F1 Macro: 0.2742, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.6478, Val Loss: 1.8288, F1 Micro: 0.2917, F1 Macro: 0.2554, Accuracy: 0.2917\n","Epoch 13, Train Loss: 1.6735, Val Loss: 1.7753, F1 Micro: 0.3542, F1 Macro: 0.3325, Accuracy: 0.3542\n","Epoch 14, Train Loss: 1.6685, Val Loss: 2.1484, F1 Micro: 0.2083, F1 Macro: 0.1789, Accuracy: 0.2083\n","Epoch 15, Train Loss: 1.6460, Val Loss: 1.7695, F1 Micro: 0.2396, F1 Macro: 0.1556, Accuracy: 0.2396\n","Epoch 16, Train Loss: 1.6258, Val Loss: 1.7319, F1 Micro: 0.2812, F1 Macro: 0.2796, Accuracy: 0.2812\n","Epoch 17, Train Loss: 1.6246, Val Loss: 1.6859, F1 Micro: 0.3438, F1 Macro: 0.3207, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.6076, Val Loss: 1.8589, F1 Micro: 0.2500, F1 Macro: 0.2060, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.6044, Val Loss: 1.6914, F1 Micro: 0.4167, F1 Macro: 0.3781, Accuracy: 0.4167\n","Epoch 20, Train Loss: 1.5672, Val Loss: 1.7221, F1 Micro: 0.3542, F1 Macro: 0.2974, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.5750, Val Loss: 1.7545, F1 Micro: 0.3229, F1 Macro: 0.2676, Accuracy: 0.3229\n","Epoch 22, Train Loss: 1.5506, Val Loss: 1.7680, F1 Micro: 0.3854, F1 Macro: 0.3426, Accuracy: 0.3854\n","Epoch 23, Train Loss: 1.5381, Val Loss: 1.8692, F1 Micro: 0.2917, F1 Macro: 0.2092, Accuracy: 0.2917\n","Epoch 24, Train Loss: 1.5551, Val Loss: 1.6325, F1 Micro: 0.3854, F1 Macro: 0.3474, Accuracy: 0.3854\n","Epoch 25, Train Loss: 1.5297, Val Loss: 1.6599, F1 Micro: 0.3542, F1 Macro: 0.2856, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.4963, Val Loss: 1.6437, F1 Micro: 0.4271, F1 Macro: 0.3665, Accuracy: 0.4271\n","Epoch 27, Train Loss: 1.5070, Val Loss: 1.6252, F1 Micro: 0.3958, F1 Macro: 0.3571, Accuracy: 0.3958\n","Epoch 28, Train Loss: 1.5038, Val Loss: 1.6645, F1 Micro: 0.3750, F1 Macro: 0.3427, Accuracy: 0.3750\n","Epoch 29, Train Loss: 1.4755, Val Loss: 1.9551, F1 Micro: 0.2708, F1 Macro: 0.2260, Accuracy: 0.2708\n","Epoch 30, Train Loss: 1.4613, Val Loss: 1.7003, F1 Micro: 0.3438, F1 Macro: 0.2320, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.4641, Val Loss: 2.2225, F1 Micro: 0.2083, F1 Macro: 0.1414, Accuracy: 0.2083\n","Epoch 32, Train Loss: 1.5036, Val Loss: 1.6957, F1 Micro: 0.3854, F1 Macro: 0.3285, Accuracy: 0.3854\n","Epoch 33, Train Loss: 1.4744, Val Loss: 1.5462, F1 Micro: 0.3646, F1 Macro: 0.3350, Accuracy: 0.3646\n","Epoch 34, Train Loss: 1.4780, Val Loss: 1.7109, F1 Micro: 0.3854, F1 Macro: 0.3213, Accuracy: 0.3854\n","Epoch 35, Train Loss: 1.4664, Val Loss: 2.2997, F1 Micro: 0.2292, F1 Macro: 0.1364, Accuracy: 0.2292\n","Epoch 36, Train Loss: 1.4385, Val Loss: 1.5411, F1 Micro: 0.3958, F1 Macro: 0.3574, Accuracy: 0.3958\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.7682, Val Loss: 2.0150, F1 Micro: 0.2396, F1 Macro: 0.1257, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7093, Val Loss: 1.7642, F1 Micro: 0.1875, F1 Macro: 0.1535, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.6992, Val Loss: 1.9802, F1 Micro: 0.2083, F1 Macro: 0.1617, Accuracy: 0.2083\n","Epoch 4, Train Loss: 1.6826, Val Loss: 1.7833, F1 Micro: 0.2812, F1 Macro: 0.2475, Accuracy: 0.2812\n","Epoch 5, Train Loss: 1.6610, Val Loss: 1.7976, F1 Micro: 0.2188, F1 Macro: 0.1315, Accuracy: 0.2188\n","Epoch 6, Train Loss: 1.6472, Val Loss: 2.0014, F1 Micro: 0.2604, F1 Macro: 0.1820, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.6159, Val Loss: 1.8404, F1 Micro: 0.2396, F1 Macro: 0.1523, Accuracy: 0.2396\n","Epoch 8, Train Loss: 1.6493, Val Loss: 1.8244, F1 Micro: 0.2708, F1 Macro: 0.2395, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.6525, Val Loss: 1.7768, F1 Micro: 0.2708, F1 Macro: 0.2007, Accuracy: 0.2708\n","Epoch 10, Train Loss: 1.5959, Val Loss: 2.1293, F1 Micro: 0.2188, F1 Macro: 0.1005, Accuracy: 0.2188\n","Epoch 11, Train Loss: 1.6143, Val Loss: 1.7094, F1 Micro: 0.3333, F1 Macro: 0.2892, Accuracy: 0.3333\n","Epoch 12, Train Loss: 1.5881, Val Loss: 2.0959, F1 Micro: 0.1979, F1 Macro: 0.1100, Accuracy: 0.1979\n","Epoch 13, Train Loss: 1.5876, Val Loss: 1.7244, F1 Micro: 0.3542, F1 Macro: 0.2966, Accuracy: 0.3542\n","Epoch 14, Train Loss: 1.5664, Val Loss: 1.8679, F1 Micro: 0.2708, F1 Macro: 0.2079, Accuracy: 0.2708\n","Epoch 15, Train Loss: 1.5569, Val Loss: 1.8117, F1 Micro: 0.3229, F1 Macro: 0.2423, Accuracy: 0.3229\n","Epoch 16, Train Loss: 1.5313, Val Loss: 1.7559, F1 Micro: 0.3229, F1 Macro: 0.2800, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.5041, Val Loss: 1.7737, F1 Micro: 0.3438, F1 Macro: 0.2797, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5337, Val Loss: 1.8450, F1 Micro: 0.3125, F1 Macro: 0.2337, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.5057, Val Loss: 1.8307, F1 Micro: 0.2917, F1 Macro: 0.1997, Accuracy: 0.2917\n","Epoch 20, Train Loss: 1.4848, Val Loss: 1.6267, F1 Micro: 0.3542, F1 Macro: 0.3358, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.4684, Val Loss: 1.5820, F1 Micro: 0.3438, F1 Macro: 0.2698, Accuracy: 0.3438\n","Epoch 22, Train Loss: 1.4783, Val Loss: 1.8103, F1 Micro: 0.3229, F1 Macro: 0.2963, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.4386, Val Loss: 1.5825, F1 Micro: 0.3958, F1 Macro: 0.3068, Accuracy: 0.3958\n","Epoch 24, Train Loss: 1.4224, Val Loss: 2.0323, F1 Micro: 0.2708, F1 Macro: 0.2091, Accuracy: 0.2708\n","Epoch 25, Train Loss: 1.4068, Val Loss: 1.6954, F1 Micro: 0.3021, F1 Macro: 0.2891, Accuracy: 0.3021\n","Epoch 26, Train Loss: 1.3716, Val Loss: 1.5643, F1 Micro: 0.3958, F1 Macro: 0.3985, Accuracy: 0.3958\n","Epoch 27, Train Loss: 1.4079, Val Loss: 1.5833, F1 Micro: 0.3542, F1 Macro: 0.3354, Accuracy: 0.3542\n","Epoch 28, Train Loss: 1.3869, Val Loss: 2.3252, F1 Micro: 0.2292, F1 Macro: 0.2034, Accuracy: 0.2292\n","Epoch 29, Train Loss: 1.3748, Val Loss: 1.5990, F1 Micro: 0.4375, F1 Macro: 0.3766, Accuracy: 0.4375\n","Epoch 30, Train Loss: 1.3672, Val Loss: 1.6445, F1 Micro: 0.3854, F1 Macro: 0.3604, Accuracy: 0.3854\n","Epoch 31, Train Loss: 1.3625, Val Loss: 1.6200, F1 Micro: 0.3333, F1 Macro: 0.2869, Accuracy: 0.3333\n","Epoch 32, Train Loss: 1.3199, Val Loss: 1.5332, F1 Micro: 0.3958, F1 Macro: 0.3555, Accuracy: 0.3958\n","Epoch 33, Train Loss: 1.3228, Val Loss: 2.0974, F1 Micro: 0.2292, F1 Macro: 0.1977, Accuracy: 0.2292\n","Epoch 34, Train Loss: 1.3498, Val Loss: 1.7470, F1 Micro: 0.3229, F1 Macro: 0.2305, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.3334, Val Loss: 1.8955, F1 Micro: 0.2812, F1 Macro: 0.2913, Accuracy: 0.2812\n","Epoch 36, Train Loss: 1.2826, Val Loss: 1.7462, F1 Micro: 0.2708, F1 Macro: 0.2120, Accuracy: 0.2708\n","Epoch 37, Train Loss: 1.2817, Val Loss: 2.7044, F1 Micro: 0.2812, F1 Macro: 0.1923, Accuracy: 0.2812\n","Epoch 38, Train Loss: 1.2592, Val Loss: 1.6158, F1 Micro: 0.4062, F1 Macro: 0.3817, Accuracy: 0.4062\n","Epoch 39, Train Loss: 1.2680, Val Loss: 1.6712, F1 Micro: 0.3333, F1 Macro: 0.3047, Accuracy: 0.3333\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.8177, Val Loss: 1.8040, F1 Micro: 0.1875, F1 Macro: 0.1205, Accuracy: 0.1875\n","Epoch 2, Train Loss: 1.7702, Val Loss: 1.7780, F1 Micro: 0.1875, F1 Macro: 0.0956, Accuracy: 0.1875\n","Epoch 3, Train Loss: 1.7455, Val Loss: 1.7564, F1 Micro: 0.2083, F1 Macro: 0.1717, Accuracy: 0.2083\n","Epoch 4, Train Loss: 1.7183, Val Loss: 1.8458, F1 Micro: 0.1979, F1 Macro: 0.1422, Accuracy: 0.1979\n","Epoch 5, Train Loss: 1.7170, Val Loss: 1.8073, F1 Micro: 0.2396, F1 Macro: 0.2239, Accuracy: 0.2396\n","Epoch 6, Train Loss: 1.6923, Val Loss: 1.9768, F1 Micro: 0.2083, F1 Macro: 0.1542, Accuracy: 0.2083\n","Epoch 7, Train Loss: 1.6938, Val Loss: 1.9229, F1 Micro: 0.2083, F1 Macro: 0.1574, Accuracy: 0.2083\n","Epoch 8, Train Loss: 1.6636, Val Loss: 1.8509, F1 Micro: 0.2396, F1 Macro: 0.1817, Accuracy: 0.2396\n","Epoch 9, Train Loss: 1.6455, Val Loss: 1.8473, F1 Micro: 0.2083, F1 Macro: 0.1506, Accuracy: 0.2083\n","Epoch 10, Train Loss: 1.6271, Val Loss: 2.0165, F1 Micro: 0.2812, F1 Macro: 0.2227, Accuracy: 0.2812\n","Epoch 11, Train Loss: 1.6224, Val Loss: 1.7380, F1 Micro: 0.2812, F1 Macro: 0.2449, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.6066, Val Loss: 1.9433, F1 Micro: 0.2188, F1 Macro: 0.1783, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.6151, Val Loss: 1.7630, F1 Micro: 0.2083, F1 Macro: 0.1566, Accuracy: 0.2083\n","Epoch 14, Train Loss: 1.5605, Val Loss: 1.7637, F1 Micro: 0.2604, F1 Macro: 0.2187, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.5691, Val Loss: 2.0843, F1 Micro: 0.2604, F1 Macro: 0.1828, Accuracy: 0.2604\n","Epoch 16, Train Loss: 1.5466, Val Loss: 1.6907, F1 Micro: 0.3021, F1 Macro: 0.2960, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.5346, Val Loss: 2.0437, F1 Micro: 0.2500, F1 Macro: 0.2029, Accuracy: 0.2500\n","Epoch 18, Train Loss: 1.5195, Val Loss: 1.7934, F1 Micro: 0.2917, F1 Macro: 0.2552, Accuracy: 0.2917\n","Epoch 19, Train Loss: 1.5353, Val Loss: 1.7854, F1 Micro: 0.2708, F1 Macro: 0.2483, Accuracy: 0.2708\n","Epoch 20, Train Loss: 1.5122, Val Loss: 1.7207, F1 Micro: 0.3229, F1 Macro: 0.2958, Accuracy: 0.3229\n","Epoch 21, Train Loss: 1.4842, Val Loss: 1.7255, F1 Micro: 0.3021, F1 Macro: 0.2593, Accuracy: 0.3021\n","Epoch 22, Train Loss: 1.4376, Val Loss: 1.7236, F1 Micro: 0.3229, F1 Macro: 0.3372, Accuracy: 0.3229\n","Epoch 23, Train Loss: 1.4423, Val Loss: 1.6567, F1 Micro: 0.3333, F1 Macro: 0.3248, Accuracy: 0.3333\n","Epoch 24, Train Loss: 1.4540, Val Loss: 1.7257, F1 Micro: 0.2604, F1 Macro: 0.2592, Accuracy: 0.2604\n","Epoch 25, Train Loss: 1.4251, Val Loss: 1.9720, F1 Micro: 0.2812, F1 Macro: 0.2561, Accuracy: 0.2812\n","Epoch 26, Train Loss: 1.4477, Val Loss: 1.7569, F1 Micro: 0.2917, F1 Macro: 0.2552, Accuracy: 0.2917\n","Epoch 27, Train Loss: 1.3959, Val Loss: 1.9764, F1 Micro: 0.2812, F1 Macro: 0.2345, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.3724, Val Loss: 2.0256, F1 Micro: 0.2708, F1 Macro: 0.2294, Accuracy: 0.2708\n","Epoch 29, Train Loss: 1.4144, Val Loss: 1.7541, F1 Micro: 0.3229, F1 Macro: 0.2858, Accuracy: 0.3229\n","Epoch 30, Train Loss: 1.3694, Val Loss: 1.6968, F1 Micro: 0.3125, F1 Macro: 0.2960, Accuracy: 0.3125\n","Epoch 31, Train Loss: 1.3573, Val Loss: 1.9263, F1 Micro: 0.3333, F1 Macro: 0.2919, Accuracy: 0.3333\n","Epoch 32, Train Loss: 1.3634, Val Loss: 2.0615, F1 Micro: 0.3125, F1 Macro: 0.2631, Accuracy: 0.3125\n","Epoch 33, Train Loss: 1.3352, Val Loss: 1.7899, F1 Micro: 0.2812, F1 Macro: 0.2753, Accuracy: 0.2812\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.7925, Val Loss: 1.8234, F1 Micro: 0.2396, F1 Macro: 0.1229, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7060, Val Loss: 1.8350, F1 Micro: 0.2292, F1 Macro: 0.1842, Accuracy: 0.2292\n","Epoch 3, Train Loss: 1.7049, Val Loss: 1.7143, F1 Micro: 0.2708, F1 Macro: 0.2157, Accuracy: 0.2708\n","Epoch 4, Train Loss: 1.6792, Val Loss: 1.7266, F1 Micro: 0.2917, F1 Macro: 0.2202, Accuracy: 0.2917\n","Epoch 5, Train Loss: 1.6768, Val Loss: 1.6843, F1 Micro: 0.2708, F1 Macro: 0.1847, Accuracy: 0.2708\n","Epoch 6, Train Loss: 1.6670, Val Loss: 2.1853, F1 Micro: 0.2396, F1 Macro: 0.1522, Accuracy: 0.2396\n","Epoch 7, Train Loss: 1.6745, Val Loss: 1.7933, F1 Micro: 0.2917, F1 Macro: 0.2490, Accuracy: 0.2917\n","Epoch 8, Train Loss: 1.6408, Val Loss: 1.7307, F1 Micro: 0.2604, F1 Macro: 0.2163, Accuracy: 0.2604\n","Epoch 9, Train Loss: 1.6173, Val Loss: 1.6976, F1 Micro: 0.2812, F1 Macro: 0.2219, Accuracy: 0.2812\n","Epoch 10, Train Loss: 1.5955, Val Loss: 1.7201, F1 Micro: 0.3021, F1 Macro: 0.2471, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.6020, Val Loss: 1.6880, F1 Micro: 0.3125, F1 Macro: 0.2416, Accuracy: 0.3125\n","Epoch 12, Train Loss: 1.5726, Val Loss: 1.7877, F1 Micro: 0.2396, F1 Macro: 0.1839, Accuracy: 0.2396\n","Epoch 13, Train Loss: 1.5302, Val Loss: 1.6790, F1 Micro: 0.3229, F1 Macro: 0.2991, Accuracy: 0.3229\n","Epoch 14, Train Loss: 1.5506, Val Loss: 1.6905, F1 Micro: 0.2604, F1 Macro: 0.2219, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.5398, Val Loss: 1.7476, F1 Micro: 0.3021, F1 Macro: 0.2903, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.5240, Val Loss: 1.9577, F1 Micro: 0.3021, F1 Macro: 0.2653, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.5261, Val Loss: 1.6892, F1 Micro: 0.2708, F1 Macro: 0.2679, Accuracy: 0.2708\n","Epoch 18, Train Loss: 1.5144, Val Loss: 1.6630, F1 Micro: 0.3333, F1 Macro: 0.3000, Accuracy: 0.3333\n","Epoch 19, Train Loss: 1.5304, Val Loss: 1.7113, F1 Micro: 0.3125, F1 Macro: 0.2779, Accuracy: 0.3125\n","Epoch 20, Train Loss: 1.5239, Val Loss: 1.7283, F1 Micro: 0.2292, F1 Macro: 0.2019, Accuracy: 0.2292\n","Epoch 21, Train Loss: 1.4704, Val Loss: 1.6987, F1 Micro: 0.3021, F1 Macro: 0.2715, Accuracy: 0.3021\n","Epoch 22, Train Loss: 1.4653, Val Loss: 1.6090, F1 Micro: 0.2812, F1 Macro: 0.2494, Accuracy: 0.2812\n","Epoch 23, Train Loss: 1.4289, Val Loss: 2.2769, F1 Micro: 0.2917, F1 Macro: 0.2511, Accuracy: 0.2917\n","Epoch 24, Train Loss: 1.4589, Val Loss: 1.7187, F1 Micro: 0.2917, F1 Macro: 0.2667, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.4302, Val Loss: 1.8651, F1 Micro: 0.2812, F1 Macro: 0.2791, Accuracy: 0.2812\n","Epoch 26, Train Loss: 1.4473, Val Loss: 1.6981, F1 Micro: 0.3021, F1 Macro: 0.2890, Accuracy: 0.3021\n","Epoch 27, Train Loss: 1.4382, Val Loss: 2.0388, F1 Micro: 0.2708, F1 Macro: 0.2252, Accuracy: 0.2708\n","Epoch 28, Train Loss: 1.3947, Val Loss: 1.7645, F1 Micro: 0.2812, F1 Macro: 0.2423, Accuracy: 0.2812\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.3666666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7845, Val Loss: 1.6991, F1 Micro: 0.2708, F1 Macro: 0.2691, Accuracy: 0.2708\n","Epoch 2, Train Loss: 1.7210, Val Loss: 1.7931, F1 Micro: 0.2083, F1 Macro: 0.1728, Accuracy: 0.2083\n","Epoch 3, Train Loss: 1.6791, Val Loss: 1.8462, F1 Micro: 0.3125, F1 Macro: 0.2433, Accuracy: 0.3125\n","Epoch 4, Train Loss: 1.6487, Val Loss: 1.8500, F1 Micro: 0.2500, F1 Macro: 0.1906, Accuracy: 0.2500\n","Epoch 5, Train Loss: 1.6407, Val Loss: 1.7949, F1 Micro: 0.2917, F1 Macro: 0.2722, Accuracy: 0.2917\n","Epoch 6, Train Loss: 1.6459, Val Loss: 1.6974, F1 Micro: 0.3333, F1 Macro: 0.3165, Accuracy: 0.3333\n","Epoch 7, Train Loss: 1.6606, Val Loss: 2.2115, F1 Micro: 0.1771, F1 Macro: 0.1306, Accuracy: 0.1771\n","Epoch 8, Train Loss: 1.6258, Val Loss: 1.8477, F1 Micro: 0.3229, F1 Macro: 0.3259, Accuracy: 0.3229\n","Epoch 9, Train Loss: 1.5864, Val Loss: 2.0372, F1 Micro: 0.3229, F1 Macro: 0.2527, Accuracy: 0.3229\n","Epoch 10, Train Loss: 1.5803, Val Loss: 1.9779, F1 Micro: 0.2708, F1 Macro: 0.2302, Accuracy: 0.2708\n","Epoch 11, Train Loss: 1.5792, Val Loss: 1.6972, F1 Micro: 0.2812, F1 Macro: 0.2542, Accuracy: 0.2812\n","Epoch 12, Train Loss: 1.5951, Val Loss: 2.1771, F1 Micro: 0.2188, F1 Macro: 0.1594, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.5905, Val Loss: 1.7175, F1 Micro: 0.3438, F1 Macro: 0.3551, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.5376, Val Loss: 1.9271, F1 Micro: 0.2917, F1 Macro: 0.2347, Accuracy: 0.2917\n","Epoch 15, Train Loss: 1.5396, Val Loss: 1.7770, F1 Micro: 0.3021, F1 Macro: 0.2859, Accuracy: 0.3021\n","Epoch 16, Train Loss: 1.5257, Val Loss: 2.6386, F1 Micro: 0.2292, F1 Macro: 0.1771, Accuracy: 0.2292\n","Epoch 17, Train Loss: 1.4908, Val Loss: 1.6532, F1 Micro: 0.3646, F1 Macro: 0.3615, Accuracy: 0.3646\n","Epoch 18, Train Loss: 1.4975, Val Loss: 1.7782, F1 Micro: 0.2500, F1 Macro: 0.2141, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.4876, Val Loss: 1.6388, F1 Micro: 0.3958, F1 Macro: 0.3462, Accuracy: 0.3958\n","Epoch 20, Train Loss: 1.4733, Val Loss: 1.7783, F1 Micro: 0.3438, F1 Macro: 0.3529, Accuracy: 0.3438\n","Epoch 21, Train Loss: 1.4310, Val Loss: 1.9198, F1 Micro: 0.3333, F1 Macro: 0.3290, Accuracy: 0.3333\n","Epoch 22, Train Loss: 1.4778, Val Loss: 1.7275, F1 Micro: 0.3125, F1 Macro: 0.2772, Accuracy: 0.3125\n","Epoch 23, Train Loss: 1.4118, Val Loss: 2.0455, F1 Micro: 0.2500, F1 Macro: 0.2164, Accuracy: 0.2500\n","Epoch 24, Train Loss: 1.3951, Val Loss: 2.0457, F1 Micro: 0.2917, F1 Macro: 0.2597, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.4019, Val Loss: 1.7619, F1 Micro: 0.3125, F1 Macro: 0.2848, Accuracy: 0.3125\n","Epoch 26, Train Loss: 1.4043, Val Loss: 1.7860, F1 Micro: 0.3958, F1 Macro: 0.3273, Accuracy: 0.3958\n","Epoch 27, Train Loss: 1.3995, Val Loss: 2.3111, F1 Micro: 0.2812, F1 Macro: 0.2510, Accuracy: 0.2812\n","Epoch 28, Train Loss: 1.3504, Val Loss: 1.9052, F1 Micro: 0.3229, F1 Macro: 0.2538, Accuracy: 0.3229\n","Epoch 29, Train Loss: 1.3316, Val Loss: 1.7459, F1 Micro: 0.3021, F1 Macro: 0.2577, Accuracy: 0.3021\n","Epoch 30, Train Loss: 1.3318, Val Loss: 2.0515, F1 Micro: 0.3021, F1 Macro: 0.2771, Accuracy: 0.3021\n","Epoch 31, Train Loss: 1.2808, Val Loss: 2.0026, F1 Micro: 0.2500, F1 Macro: 0.2212, Accuracy: 0.2500\n","Epoch 32, Train Loss: 1.3018, Val Loss: 2.0377, F1 Micro: 0.3854, F1 Macro: 0.3614, Accuracy: 0.3854\n","Epoch 33, Train Loss: 1.2429, Val Loss: 2.2169, F1 Micro: 0.3125, F1 Macro: 0.2918, Accuracy: 0.3125\n","Epoch 34, Train Loss: 1.3523, Val Loss: 2.1671, F1 Micro: 0.3438, F1 Macro: 0.3523, Accuracy: 0.3438\n","Epoch 35, Train Loss: 1.2998, Val Loss: 1.6241, F1 Micro: 0.4896, F1 Macro: 0.4607, Accuracy: 0.4896\n","Epoch 36, Train Loss: 1.2726, Val Loss: 1.9059, F1 Micro: 0.4167, F1 Macro: 0.3569, Accuracy: 0.4167\n","Epoch 37, Train Loss: 1.2893, Val Loss: 1.6011, F1 Micro: 0.4896, F1 Macro: 0.4629, Accuracy: 0.4896\n","Epoch 38, Train Loss: 1.2260, Val Loss: 1.9974, F1 Micro: 0.3542, F1 Macro: 0.3726, Accuracy: 0.3542\n","Epoch 39, Train Loss: 1.2302, Val Loss: 2.2093, F1 Micro: 0.2708, F1 Macro: 0.2337, Accuracy: 0.2708\n","Epoch 40, Train Loss: 1.2387, Val Loss: 1.7252, F1 Micro: 0.4167, F1 Macro: 0.3848, Accuracy: 0.4167\n","Epoch 41, Train Loss: 1.1953, Val Loss: 1.6980, F1 Micro: 0.3854, F1 Macro: 0.3493, Accuracy: 0.3854\n","Epoch 42, Train Loss: 1.1815, Val Loss: 2.1179, F1 Micro: 0.3229, F1 Macro: 0.2694, Accuracy: 0.3229\n","Epoch 43, Train Loss: 1.2553, Val Loss: 2.1217, F1 Micro: 0.3750, F1 Macro: 0.3071, Accuracy: 0.3750\n","Epoch 44, Train Loss: 1.2628, Val Loss: 1.7689, F1 Micro: 0.4271, F1 Macro: 0.3711, Accuracy: 0.4271\n","Epoch 45, Train Loss: 1.2608, Val Loss: 2.3035, F1 Micro: 0.2917, F1 Macro: 0.1991, Accuracy: 0.2917\n","Epoch 46, Train Loss: 1.1778, Val Loss: 1.8356, F1 Micro: 0.3646, F1 Macro: 0.3791, Accuracy: 0.3646\n","Epoch 47, Train Loss: 1.1719, Val Loss: 1.8362, F1 Micro: 0.3229, F1 Macro: 0.2979, Accuracy: 0.3229\n","Epoch 48, Train Loss: 1.1724, Val Loss: 1.9177, F1 Micro: 0.3854, F1 Macro: 0.3666, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.1753, Val Loss: 3.1993, F1 Micro: 0.3646, F1 Macro: 0.2790, Accuracy: 0.3646\n","Epoch 50, Train Loss: 1.2052, Val Loss: 2.2786, F1 Micro: 0.3542, F1 Macro: 0.2609, Accuracy: 0.3542\n","Epoch 51, Train Loss: 1.1514, Val Loss: 1.8079, F1 Micro: 0.3646, F1 Macro: 0.3827, Accuracy: 0.3646\n","Epoch 52, Train Loss: 1.1804, Val Loss: 1.9850, F1 Micro: 0.3125, F1 Macro: 0.2783, Accuracy: 0.3125\n","Epoch 53, Train Loss: 1.1529, Val Loss: 2.6668, F1 Micro: 0.2708, F1 Macro: 0.2264, Accuracy: 0.2708\n","Epoch 54, Train Loss: 1.1081, Val Loss: 2.2277, F1 Micro: 0.3542, F1 Macro: 0.2930, Accuracy: 0.3542\n","Epoch 55, Train Loss: 1.1210, Val Loss: 1.9592, F1 Micro: 0.3542, F1 Macro: 0.3172, Accuracy: 0.3542\n","Epoch 56, Train Loss: 1.1081, Val Loss: 1.6597, F1 Micro: 0.3542, F1 Macro: 0.3407, Accuracy: 0.3542\n","Epoch 57, Train Loss: 1.0666, Val Loss: 3.7418, F1 Micro: 0.2604, F1 Macro: 0.2159, Accuracy: 0.2604\n","Epoch 58, Train Loss: 1.0647, Val Loss: 1.5661, F1 Micro: 0.4583, F1 Macro: 0.4494, Accuracy: 0.4583\n","Epoch 59, Train Loss: 1.0577, Val Loss: 1.7501, F1 Micro: 0.3958, F1 Macro: 0.3741, Accuracy: 0.3958\n","Epoch 60, Train Loss: 1.0721, Val Loss: 2.3388, F1 Micro: 0.2812, F1 Macro: 0.2708, Accuracy: 0.2812\n","Epoch 61, Train Loss: 1.0933, Val Loss: 1.9942, F1 Micro: 0.3646, F1 Macro: 0.3470, Accuracy: 0.3646\n","Epoch 62, Train Loss: 1.0664, Val Loss: 1.6476, F1 Micro: 0.4167, F1 Macro: 0.4346, Accuracy: 0.4167\n","Epoch 63, Train Loss: 1.0110, Val Loss: 2.1164, F1 Micro: 0.3229, F1 Macro: 0.3295, Accuracy: 0.3229\n","Epoch 64, Train Loss: 1.0295, Val Loss: 2.1478, F1 Micro: 0.3646, F1 Macro: 0.3165, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.0379, Val Loss: 2.4021, F1 Micro: 0.3542, F1 Macro: 0.2936, Accuracy: 0.3542\n","Epoch 66, Train Loss: 1.0009, Val Loss: 1.7022, F1 Micro: 0.4271, F1 Macro: 0.3804, Accuracy: 0.4271\n","Epoch 67, Train Loss: 1.0495, Val Loss: 2.3865, F1 Micro: 0.3750, F1 Macro: 0.3502, Accuracy: 0.3750\n","Epoch 68, Train Loss: 1.0378, Val Loss: 2.5532, F1 Micro: 0.3958, F1 Macro: 0.3136, Accuracy: 0.3958\n","Epoch 69, Train Loss: 1.0238, Val Loss: 2.0679, F1 Micro: 0.4375, F1 Macro: 0.3602, Accuracy: 0.4375\n","Epoch 70, Train Loss: 0.9976, Val Loss: 2.4821, F1 Micro: 0.3333, F1 Macro: 0.2906, Accuracy: 0.3333\n","Epoch 71, Train Loss: 1.0298, Val Loss: 1.8631, F1 Micro: 0.4167, F1 Macro: 0.3547, Accuracy: 0.4167\n","Epoch 72, Train Loss: 0.9927, Val Loss: 1.8397, F1 Micro: 0.4375, F1 Macro: 0.4166, Accuracy: 0.4375\n","Epoch 73, Train Loss: 1.0306, Val Loss: 1.7140, F1 Micro: 0.3542, F1 Macro: 0.3483, Accuracy: 0.3542\n","Epoch 74, Train Loss: 1.0095, Val Loss: 1.5910, F1 Micro: 0.4375, F1 Macro: 0.4463, Accuracy: 0.4375\n","Epoch 75, Train Loss: 0.9587, Val Loss: 1.9804, F1 Micro: 0.4583, F1 Macro: 0.4462, Accuracy: 0.4583\n","Epoch 76, Train Loss: 1.0229, Val Loss: 3.5500, F1 Micro: 0.2917, F1 Macro: 0.2597, Accuracy: 0.2917\n","Epoch 77, Train Loss: 0.9741, Val Loss: 2.3303, F1 Micro: 0.2917, F1 Macro: 0.2459, Accuracy: 0.2917\n","Epoch 78, Train Loss: 0.9484, Val Loss: 1.8726, F1 Micro: 0.3854, F1 Macro: 0.3532, Accuracy: 0.3854\n","Epoch 79, Train Loss: 0.9647, Val Loss: 2.2542, F1 Micro: 0.2917, F1 Macro: 0.2646, Accuracy: 0.2917\n","Epoch 80, Train Loss: 0.9879, Val Loss: 2.2131, F1 Micro: 0.3542, F1 Macro: 0.3154, Accuracy: 0.3542\n","Epoch 81, Train Loss: 0.9344, Val Loss: 1.9319, F1 Micro: 0.4271, F1 Macro: 0.4165, Accuracy: 0.4271\n","Epoch 82, Train Loss: 0.9580, Val Loss: 2.1678, F1 Micro: 0.3854, F1 Macro: 0.3324, Accuracy: 0.3854\n","Epoch 83, Train Loss: 0.9047, Val Loss: 1.6543, F1 Micro: 0.4271, F1 Macro: 0.4405, Accuracy: 0.4271\n","Epoch 84, Train Loss: 0.8616, Val Loss: 1.7758, F1 Micro: 0.4583, F1 Macro: 0.4077, Accuracy: 0.4583\n","Epoch 85, Train Loss: 0.9025, Val Loss: 2.2212, F1 Micro: 0.4271, F1 Macro: 0.4080, Accuracy: 0.4271\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8889, Val Loss: 1.8024, F1 Micro: 0.2396, F1 Macro: 0.1207, Accuracy: 0.2396\n","Epoch 2, Train Loss: 1.7652, Val Loss: 1.7982, F1 Micro: 0.2188, F1 Macro: 0.1362, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7471, Val Loss: 1.7603, F1 Micro: 0.3021, F1 Macro: 0.2381, Accuracy: 0.3021\n","Epoch 4, Train Loss: 1.7377, Val Loss: 1.7820, F1 Micro: 0.2708, F1 Macro: 0.1996, Accuracy: 0.2708\n","Epoch 5, Train Loss: 1.7269, Val Loss: 1.8337, F1 Micro: 0.2500, F1 Macro: 0.1738, Accuracy: 0.2500\n","Epoch 6, Train Loss: 1.7251, Val Loss: 1.7425, F1 Micro: 0.2604, F1 Macro: 0.1626, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.7121, Val Loss: 1.7389, F1 Micro: 0.2812, F1 Macro: 0.2296, Accuracy: 0.2812\n","Epoch 8, Train Loss: 1.6978, Val Loss: 2.2457, F1 Micro: 0.1667, F1 Macro: 0.1352, Accuracy: 0.1667\n","Epoch 9, Train Loss: 1.7117, Val Loss: 1.7594, F1 Micro: 0.2604, F1 Macro: 0.1863, Accuracy: 0.2604\n","Epoch 10, Train Loss: 1.7023, Val Loss: 2.0757, F1 Micro: 0.1667, F1 Macro: 0.1529, Accuracy: 0.1667\n","Epoch 11, Train Loss: 1.6887, Val Loss: 1.7290, F1 Micro: 0.2188, F1 Macro: 0.2103, Accuracy: 0.2188\n","Epoch 12, Train Loss: 1.6898, Val Loss: 1.8659, F1 Micro: 0.2500, F1 Macro: 0.2360, Accuracy: 0.2500\n","Epoch 13, Train Loss: 1.6716, Val Loss: 1.6990, F1 Micro: 0.3438, F1 Macro: 0.3174, Accuracy: 0.3438\n","Epoch 14, Train Loss: 1.6542, Val Loss: 1.7620, F1 Micro: 0.2604, F1 Macro: 0.2511, Accuracy: 0.2604\n","Epoch 15, Train Loss: 1.6324, Val Loss: 1.8368, F1 Micro: 0.2812, F1 Macro: 0.2598, Accuracy: 0.2812\n","Epoch 16, Train Loss: 1.6494, Val Loss: 1.7400, F1 Micro: 0.3021, F1 Macro: 0.2755, Accuracy: 0.3021\n","Epoch 17, Train Loss: 1.6380, Val Loss: 1.7493, F1 Micro: 0.2396, F1 Macro: 0.1899, Accuracy: 0.2396\n","Epoch 18, Train Loss: 1.5935, Val Loss: 1.7032, F1 Micro: 0.3125, F1 Macro: 0.2644, Accuracy: 0.3125\n","Epoch 19, Train Loss: 1.5927, Val Loss: 1.6991, F1 Micro: 0.3854, F1 Macro: 0.3587, Accuracy: 0.3854\n","Epoch 20, Train Loss: 1.5684, Val Loss: 1.6386, F1 Micro: 0.3542, F1 Macro: 0.3119, Accuracy: 0.3542\n","Epoch 21, Train Loss: 1.5763, Val Loss: 1.7739, F1 Micro: 0.2917, F1 Macro: 0.2643, Accuracy: 0.2917\n","Epoch 22, Train Loss: 1.5456, Val Loss: 2.1389, F1 Micro: 0.2604, F1 Macro: 0.2275, Accuracy: 0.2604\n","Epoch 23, Train Loss: 1.5513, Val Loss: 1.6421, F1 Micro: 0.3333, F1 Macro: 0.2968, Accuracy: 0.3333\n","Epoch 24, Train Loss: 1.5724, Val Loss: 1.6769, F1 Micro: 0.3750, F1 Macro: 0.3257, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.5423, Val Loss: 1.6435, F1 Micro: 0.3542, F1 Macro: 0.3426, Accuracy: 0.3542\n","Epoch 26, Train Loss: 1.5300, Val Loss: 1.8501, F1 Micro: 0.3229, F1 Macro: 0.2930, Accuracy: 0.3229\n","Epoch 27, Train Loss: 1.5363, Val Loss: 1.9386, F1 Micro: 0.3021, F1 Macro: 0.2268, Accuracy: 0.3021\n","Epoch 28, Train Loss: 1.5315, Val Loss: 1.6700, F1 Micro: 0.3750, F1 Macro: 0.2914, Accuracy: 0.3750\n","Epoch 29, Train Loss: 1.5424, Val Loss: 1.6416, F1 Micro: 0.3229, F1 Macro: 0.2804, Accuracy: 0.3229\n","Epoch 30, Train Loss: 1.4887, Val Loss: 1.6170, F1 Micro: 0.4167, F1 Macro: 0.4124, Accuracy: 0.4167\n","Epoch 31, Train Loss: 1.5036, Val Loss: 1.8555, F1 Micro: 0.3021, F1 Macro: 0.2511, Accuracy: 0.3021\n","Epoch 32, Train Loss: 1.4997, Val Loss: 1.6864, F1 Micro: 0.3750, F1 Macro: 0.3445, Accuracy: 0.3750\n","Epoch 33, Train Loss: 1.5123, Val Loss: 1.6540, F1 Micro: 0.3021, F1 Macro: 0.2987, Accuracy: 0.3021\n","Epoch 34, Train Loss: 1.4792, Val Loss: 1.5880, F1 Micro: 0.4375, F1 Macro: 0.4235, Accuracy: 0.4375\n","Epoch 35, Train Loss: 1.4675, Val Loss: 1.6155, F1 Micro: 0.3438, F1 Macro: 0.3417, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.4545, Val Loss: 1.8519, F1 Micro: 0.3021, F1 Macro: 0.2213, Accuracy: 0.3021\n","Epoch 37, Train Loss: 1.4977, Val Loss: 2.0681, F1 Micro: 0.3125, F1 Macro: 0.3231, Accuracy: 0.3125\n","Epoch 38, Train Loss: 1.4967, Val Loss: 1.6378, F1 Micro: 0.3542, F1 Macro: 0.2904, Accuracy: 0.3542\n","Epoch 39, Train Loss: 1.4823, Val Loss: 1.6017, F1 Micro: 0.5000, F1 Macro: 0.4820, Accuracy: 0.5000\n","Epoch 40, Train Loss: 1.4379, Val Loss: 1.7157, F1 Micro: 0.3750, F1 Macro: 0.3167, Accuracy: 0.3750\n","Epoch 41, Train Loss: 1.4529, Val Loss: 1.6513, F1 Micro: 0.3750, F1 Macro: 0.3311, Accuracy: 0.3750\n","Epoch 42, Train Loss: 1.4173, Val Loss: 1.6244, F1 Micro: 0.3854, F1 Macro: 0.3517, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.4332, Val Loss: 1.7737, F1 Micro: 0.3854, F1 Macro: 0.3285, Accuracy: 0.3854\n","Epoch 44, Train Loss: 1.4091, Val Loss: 1.6359, F1 Micro: 0.3958, F1 Macro: 0.3484, Accuracy: 0.3958\n","Epoch 45, Train Loss: 1.3943, Val Loss: 1.5823, F1 Micro: 0.4479, F1 Macro: 0.3963, Accuracy: 0.4479\n","Epoch 46, Train Loss: 1.3736, Val Loss: 1.5999, F1 Micro: 0.4375, F1 Macro: 0.3663, Accuracy: 0.4375\n","Epoch 47, Train Loss: 1.3495, Val Loss: 2.0245, F1 Micro: 0.3438, F1 Macro: 0.2601, Accuracy: 0.3438\n","Epoch 48, Train Loss: 1.4236, Val Loss: 1.8007, F1 Micro: 0.3958, F1 Macro: 0.3232, Accuracy: 0.3958\n","Epoch 49, Train Loss: 1.4199, Val Loss: 1.5322, F1 Micro: 0.4479, F1 Macro: 0.4241, Accuracy: 0.4479\n","Epoch 50, Train Loss: 1.3641, Val Loss: 1.9149, F1 Micro: 0.2812, F1 Macro: 0.1850, Accuracy: 0.2812\n","Epoch 51, Train Loss: 1.3201, Val Loss: 1.6260, F1 Micro: 0.3542, F1 Macro: 0.2957, Accuracy: 0.3542\n","Epoch 52, Train Loss: 1.3301, Val Loss: 1.8413, F1 Micro: 0.4375, F1 Macro: 0.4312, Accuracy: 0.4375\n","Epoch 53, Train Loss: 1.3018, Val Loss: 2.0329, F1 Micro: 0.2812, F1 Macro: 0.1855, Accuracy: 0.2812\n","Epoch 54, Train Loss: 1.3313, Val Loss: 1.6515, F1 Micro: 0.4167, F1 Macro: 0.3816, Accuracy: 0.4167\n","Epoch 55, Train Loss: 1.2986, Val Loss: 1.6697, F1 Micro: 0.3646, F1 Macro: 0.2992, Accuracy: 0.3646\n","Epoch 56, Train Loss: 1.2884, Val Loss: 1.7336, F1 Micro: 0.4375, F1 Macro: 0.4048, Accuracy: 0.4375\n","Epoch 57, Train Loss: 1.2826, Val Loss: 1.8693, F1 Micro: 0.3438, F1 Macro: 0.3049, Accuracy: 0.3438\n","Epoch 58, Train Loss: 1.2568, Val Loss: 1.6012, F1 Micro: 0.4271, F1 Macro: 0.4000, Accuracy: 0.4271\n","Epoch 59, Train Loss: 1.2629, Val Loss: 1.9281, F1 Micro: 0.4062, F1 Macro: 0.3545, Accuracy: 0.4062\n","Epoch 60, Train Loss: 1.2327, Val Loss: 1.7405, F1 Micro: 0.4167, F1 Macro: 0.3835, Accuracy: 0.4167\n","Epoch 61, Train Loss: 1.1938, Val Loss: 1.6864, F1 Micro: 0.4167, F1 Macro: 0.3449, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.2179, Val Loss: 1.8955, F1 Micro: 0.3750, F1 Macro: 0.3305, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.2318, Val Loss: 1.5689, F1 Micro: 0.3958, F1 Macro: 0.3502, Accuracy: 0.3958\n","Epoch 64, Train Loss: 1.2107, Val Loss: 1.7639, F1 Micro: 0.3646, F1 Macro: 0.2958, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.2179, Val Loss: 1.9111, F1 Micro: 0.3854, F1 Macro: 0.3677, Accuracy: 0.3854\n","Epoch 66, Train Loss: 1.2115, Val Loss: 2.0103, F1 Micro: 0.3125, F1 Macro: 0.2312, Accuracy: 0.3125\n","Epoch 67, Train Loss: 1.2130, Val Loss: 1.9662, F1 Micro: 0.4271, F1 Macro: 0.4024, Accuracy: 0.4271\n","Epoch 68, Train Loss: 1.2139, Val Loss: 1.6317, F1 Micro: 0.4062, F1 Macro: 0.3771, Accuracy: 0.4062\n","Epoch 69, Train Loss: 1.2037, Val Loss: 1.7574, F1 Micro: 0.4479, F1 Macro: 0.4116, Accuracy: 0.4479\n","Epoch 70, Train Loss: 1.1623, Val Loss: 2.3432, F1 Micro: 0.2812, F1 Macro: 0.2814, Accuracy: 0.2812\n","Epoch 71, Train Loss: 1.1616, Val Loss: 1.7771, F1 Micro: 0.4688, F1 Macro: 0.4395, Accuracy: 0.4688\n","Epoch 72, Train Loss: 1.1281, Val Loss: 1.6120, F1 Micro: 0.4583, F1 Macro: 0.4065, Accuracy: 0.4583\n","Epoch 73, Train Loss: 1.1371, Val Loss: 1.6062, F1 Micro: 0.4167, F1 Macro: 0.3929, Accuracy: 0.4167\n","Epoch 74, Train Loss: 1.1524, Val Loss: 1.6696, F1 Micro: 0.4688, F1 Macro: 0.4312, Accuracy: 0.4688\n","Epoch 75, Train Loss: 1.1791, Val Loss: 1.6436, F1 Micro: 0.3646, F1 Macro: 0.3337, Accuracy: 0.3646\n","Epoch 76, Train Loss: 1.1723, Val Loss: 1.7713, F1 Micro: 0.4583, F1 Macro: 0.4073, Accuracy: 0.4583\n","Epoch 77, Train Loss: 1.1306, Val Loss: 1.7094, F1 Micro: 0.3958, F1 Macro: 0.3607, Accuracy: 0.3958\n","Epoch 78, Train Loss: 1.1203, Val Loss: 1.9425, F1 Micro: 0.3750, F1 Macro: 0.3210, Accuracy: 0.3750\n","Epoch 79, Train Loss: 1.1283, Val Loss: 1.6547, F1 Micro: 0.3958, F1 Macro: 0.3591, Accuracy: 0.3958\n","Epoch 80, Train Loss: 1.0905, Val Loss: 1.6749, F1 Micro: 0.4062, F1 Macro: 0.3456, Accuracy: 0.4062\n","Epoch 81, Train Loss: 1.1015, Val Loss: 2.5788, F1 Micro: 0.3750, F1 Macro: 0.3308, Accuracy: 0.3750\n","Epoch 82, Train Loss: 1.0997, Val Loss: 1.5999, F1 Micro: 0.4688, F1 Macro: 0.4381, Accuracy: 0.4688\n","Epoch 83, Train Loss: 1.0820, Val Loss: 2.1360, F1 Micro: 0.3438, F1 Macro: 0.2676, Accuracy: 0.3438\n","Epoch 84, Train Loss: 1.0580, Val Loss: 1.7537, F1 Micro: 0.4375, F1 Macro: 0.4179, Accuracy: 0.4375\n","Epoch 85, Train Loss: 1.0491, Val Loss: 1.8017, F1 Micro: 0.4583, F1 Macro: 0.4485, Accuracy: 0.4583\n","Epoch 86, Train Loss: 1.0349, Val Loss: 1.6071, F1 Micro: 0.4062, F1 Macro: 0.3314, Accuracy: 0.4062\n","Epoch 87, Train Loss: 1.0759, Val Loss: 1.6005, F1 Micro: 0.4479, F1 Macro: 0.4140, Accuracy: 0.4479\n","Epoch 88, Train Loss: 1.0689, Val Loss: 1.7574, F1 Micro: 0.4271, F1 Macro: 0.3882, Accuracy: 0.4271\n","Epoch 89, Train Loss: 1.0457, Val Loss: 1.8192, F1 Micro: 0.4167, F1 Macro: 0.3816, Accuracy: 0.4167\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8382, Val Loss: 1.9204, F1 Micro: 0.1979, F1 Macro: 0.0551, Accuracy: 0.1979\n","Epoch 2, Train Loss: 1.7585, Val Loss: 1.7403, F1 Micro: 0.2188, F1 Macro: 0.0979, Accuracy: 0.2188\n","Epoch 3, Train Loss: 1.7349, Val Loss: 1.8519, F1 Micro: 0.2188, F1 Macro: 0.1370, Accuracy: 0.2188\n","Epoch 4, Train Loss: 1.7245, Val Loss: 1.7597, F1 Micro: 0.1979, F1 Macro: 0.0943, Accuracy: 0.1979\n","Epoch 5, Train Loss: 1.7234, Val Loss: 1.8441, F1 Micro: 0.1979, F1 Macro: 0.1264, Accuracy: 0.1979\n","Epoch 6, Train Loss: 1.7172, Val Loss: 1.7313, F1 Micro: 0.2292, F1 Macro: 0.1394, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.6966, Val Loss: 1.7719, F1 Micro: 0.2188, F1 Macro: 0.1304, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.7072, Val Loss: 1.7538, F1 Micro: 0.2083, F1 Macro: 0.1342, Accuracy: 0.2083\n","Epoch 9, Train Loss: 1.7230, Val Loss: 1.7599, F1 Micro: 0.2292, F1 Macro: 0.1475, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.7050, Val Loss: 1.7244, F1 Micro: 0.2083, F1 Macro: 0.1245, Accuracy: 0.2083\n","Epoch 11, Train Loss: 1.6859, Val Loss: 1.7313, F1 Micro: 0.2396, F1 Macro: 0.1764, Accuracy: 0.2396\n","Epoch 12, Train Loss: 1.6583, Val Loss: 1.7444, F1 Micro: 0.2188, F1 Macro: 0.1366, Accuracy: 0.2188\n","Epoch 13, Train Loss: 1.6719, Val Loss: 1.7520, F1 Micro: 0.2188, F1 Macro: 0.1586, Accuracy: 0.2188\n","Epoch 14, Train Loss: 1.6712, Val Loss: 1.8424, F1 Micro: 0.2188, F1 Macro: 0.1434, Accuracy: 0.2188\n","Epoch 15, Train Loss: 1.6646, Val Loss: 1.7610, F1 Micro: 0.1667, F1 Macro: 0.1365, Accuracy: 0.1667\n","Epoch 16, Train Loss: 1.6689, Val Loss: 1.7667, F1 Micro: 0.1875, F1 Macro: 0.1563, Accuracy: 0.1875\n","Epoch 17, Train Loss: 1.6597, Val Loss: 1.8440, F1 Micro: 0.1458, F1 Macro: 0.1258, Accuracy: 0.1458\n","Epoch 18, Train Loss: 1.6402, Val Loss: 1.8051, F1 Micro: 0.1562, F1 Macro: 0.1434, Accuracy: 0.1562\n","Epoch 19, Train Loss: 1.6293, Val Loss: 1.7720, F1 Micro: 0.1354, F1 Macro: 0.1264, Accuracy: 0.1354\n","Epoch 20, Train Loss: 1.6256, Val Loss: 1.7261, F1 Micro: 0.1667, F1 Macro: 0.1460, Accuracy: 0.1667\n","Epoch 21, Train Loss: 1.6108, Val Loss: 2.0239, F1 Micro: 0.1979, F1 Macro: 0.1578, Accuracy: 0.1979\n","Epoch 22, Train Loss: 1.6005, Val Loss: 1.8460, F1 Micro: 0.2396, F1 Macro: 0.1966, Accuracy: 0.2396\n","Epoch 23, Train Loss: 1.6021, Val Loss: 1.7632, F1 Micro: 0.2292, F1 Macro: 0.2052, Accuracy: 0.2292\n","Epoch 24, Train Loss: 1.5966, Val Loss: 1.7198, F1 Micro: 0.2188, F1 Macro: 0.1776, Accuracy: 0.2188\n","Epoch 25, Train Loss: 1.5885, Val Loss: 1.8434, F1 Micro: 0.2604, F1 Macro: 0.1734, Accuracy: 0.2604\n","Epoch 26, Train Loss: 1.5905, Val Loss: 1.7410, F1 Micro: 0.2708, F1 Macro: 0.2492, Accuracy: 0.2708\n","Epoch 27, Train Loss: 1.5668, Val Loss: 1.7306, F1 Micro: 0.2604, F1 Macro: 0.2424, Accuracy: 0.2604\n","Epoch 28, Train Loss: 1.5662, Val Loss: 1.7258, F1 Micro: 0.2500, F1 Macro: 0.2264, Accuracy: 0.2500\n","Epoch 29, Train Loss: 1.5766, Val Loss: 1.8076, F1 Micro: 0.2917, F1 Macro: 0.2463, Accuracy: 0.2917\n","Epoch 30, Train Loss: 1.5570, Val Loss: 2.2186, F1 Micro: 0.2188, F1 Macro: 0.1778, Accuracy: 0.2188\n","Epoch 31, Train Loss: 1.5677, Val Loss: 1.7295, F1 Micro: 0.3125, F1 Macro: 0.2682, Accuracy: 0.3125\n","Epoch 32, Train Loss: 1.5368, Val Loss: 2.4181, F1 Micro: 0.1979, F1 Macro: 0.1341, Accuracy: 0.1979\n","Epoch 33, Train Loss: 1.5297, Val Loss: 1.8459, F1 Micro: 0.2500, F1 Macro: 0.1902, Accuracy: 0.2500\n","Epoch 34, Train Loss: 1.5072, Val Loss: 2.1172, F1 Micro: 0.2292, F1 Macro: 0.1322, Accuracy: 0.2292\n","Epoch 35, Train Loss: 1.5400, Val Loss: 1.7131, F1 Micro: 0.3333, F1 Macro: 0.2485, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.5381, Val Loss: 2.3809, F1 Micro: 0.2604, F1 Macro: 0.1595, Accuracy: 0.2604\n","Epoch 37, Train Loss: 1.5341, Val Loss: 1.7316, F1 Micro: 0.3021, F1 Macro: 0.2571, Accuracy: 0.3021\n","Epoch 38, Train Loss: 1.4992, Val Loss: 1.8868, F1 Micro: 0.3229, F1 Macro: 0.2501, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.5020, Val Loss: 1.9438, F1 Micro: 0.2604, F1 Macro: 0.2391, Accuracy: 0.2604\n","Epoch 40, Train Loss: 1.4744, Val Loss: 1.7269, F1 Micro: 0.3438, F1 Macro: 0.2879, Accuracy: 0.3438\n","Epoch 41, Train Loss: 1.4855, Val Loss: 2.1328, F1 Micro: 0.3021, F1 Macro: 0.2291, Accuracy: 0.3021\n","Epoch 42, Train Loss: 1.4635, Val Loss: 1.9493, F1 Micro: 0.2812, F1 Macro: 0.2472, Accuracy: 0.2812\n","Epoch 43, Train Loss: 1.5011, Val Loss: 1.7783, F1 Micro: 0.3333, F1 Macro: 0.2889, Accuracy: 0.3333\n","Epoch 44, Train Loss: 1.4381, Val Loss: 1.9198, F1 Micro: 0.3229, F1 Macro: 0.2667, Accuracy: 0.3229\n","Epoch 45, Train Loss: 1.4768, Val Loss: 1.8374, F1 Micro: 0.3333, F1 Macro: 0.2435, Accuracy: 0.3333\n","Epoch 46, Train Loss: 1.4439, Val Loss: 2.6213, F1 Micro: 0.2604, F1 Macro: 0.2258, Accuracy: 0.2604\n","Epoch 47, Train Loss: 1.4101, Val Loss: 1.7959, F1 Micro: 0.3333, F1 Macro: 0.2488, Accuracy: 0.3333\n","Epoch 48, Train Loss: 1.4499, Val Loss: 1.8037, F1 Micro: 0.3438, F1 Macro: 0.2953, Accuracy: 0.3438\n","Epoch 49, Train Loss: 1.4415, Val Loss: 2.5901, F1 Micro: 0.2500, F1 Macro: 0.2399, Accuracy: 0.2500\n","Epoch 50, Train Loss: 1.4471, Val Loss: 1.8025, F1 Micro: 0.3438, F1 Macro: 0.2889, Accuracy: 0.3438\n","Epoch 51, Train Loss: 1.4158, Val Loss: 1.7796, F1 Micro: 0.3646, F1 Macro: 0.3191, Accuracy: 0.3646\n","Epoch 52, Train Loss: 1.3831, Val Loss: 2.0202, F1 Micro: 0.2917, F1 Macro: 0.2170, Accuracy: 0.2917\n","Epoch 53, Train Loss: 1.4244, Val Loss: 1.7051, F1 Micro: 0.3229, F1 Macro: 0.2849, Accuracy: 0.3229\n","Epoch 54, Train Loss: 1.3941, Val Loss: 1.7304, F1 Micro: 0.3333, F1 Macro: 0.2904, Accuracy: 0.3333\n","Epoch 55, Train Loss: 1.3575, Val Loss: 2.1035, F1 Micro: 0.3229, F1 Macro: 0.2559, Accuracy: 0.3229\n","Epoch 56, Train Loss: 1.3149, Val Loss: 2.0322, F1 Micro: 0.2917, F1 Macro: 0.2395, Accuracy: 0.2917\n","Epoch 57, Train Loss: 1.3498, Val Loss: 2.1249, F1 Micro: 0.3021, F1 Macro: 0.2255, Accuracy: 0.3021\n","Epoch 58, Train Loss: 1.3504, Val Loss: 1.7225, F1 Micro: 0.3438, F1 Macro: 0.3138, Accuracy: 0.3438\n","Epoch 59, Train Loss: 1.3334, Val Loss: 1.7013, F1 Micro: 0.3542, F1 Macro: 0.3356, Accuracy: 0.3542\n","Epoch 60, Train Loss: 1.3358, Val Loss: 2.4471, F1 Micro: 0.3021, F1 Macro: 0.2065, Accuracy: 0.3021\n","Epoch 61, Train Loss: 1.3204, Val Loss: 2.1881, F1 Micro: 0.3542, F1 Macro: 0.3250, Accuracy: 0.3542\n","Epoch 62, Train Loss: 1.3049, Val Loss: 2.0796, F1 Micro: 0.3542, F1 Macro: 0.2531, Accuracy: 0.3542\n","Epoch 63, Train Loss: 1.2639, Val Loss: 2.0091, F1 Micro: 0.3333, F1 Macro: 0.2949, Accuracy: 0.3333\n","Epoch 64, Train Loss: 1.2331, Val Loss: 2.1610, F1 Micro: 0.3125, F1 Macro: 0.3072, Accuracy: 0.3125\n","Epoch 65, Train Loss: 1.2580, Val Loss: 3.7288, F1 Micro: 0.2396, F1 Macro: 0.1541, Accuracy: 0.2396\n","Epoch 66, Train Loss: 1.2436, Val Loss: 1.6817, F1 Micro: 0.3750, F1 Macro: 0.3464, Accuracy: 0.3750\n","Epoch 67, Train Loss: 1.2208, Val Loss: 1.9158, F1 Micro: 0.3854, F1 Macro: 0.3454, Accuracy: 0.3854\n","Epoch 68, Train Loss: 1.2398, Val Loss: 2.1579, F1 Micro: 0.3542, F1 Macro: 0.3000, Accuracy: 0.3542\n","Epoch 69, Train Loss: 1.2199, Val Loss: 1.8354, F1 Micro: 0.3438, F1 Macro: 0.3077, Accuracy: 0.3438\n","Epoch 70, Train Loss: 1.2230, Val Loss: 2.1776, F1 Micro: 0.3646, F1 Macro: 0.2964, Accuracy: 0.3646\n","Epoch 71, Train Loss: 1.2466, Val Loss: 2.2632, F1 Micro: 0.3542, F1 Macro: 0.2878, Accuracy: 0.3542\n","Epoch 72, Train Loss: 1.1703, Val Loss: 1.8926, F1 Micro: 0.3333, F1 Macro: 0.3048, Accuracy: 0.3333\n","Epoch 73, Train Loss: 1.1414, Val Loss: 1.8838, F1 Micro: 0.3646, F1 Macro: 0.3272, Accuracy: 0.3646\n","Epoch 74, Train Loss: 1.1439, Val Loss: 2.2921, F1 Micro: 0.3438, F1 Macro: 0.2852, Accuracy: 0.3438\n","Epoch 75, Train Loss: 1.2232, Val Loss: 2.1531, F1 Micro: 0.3542, F1 Macro: 0.3153, Accuracy: 0.3542\n","Epoch 76, Train Loss: 1.1796, Val Loss: 2.5192, F1 Micro: 0.3021, F1 Macro: 0.2592, Accuracy: 0.3021\n","Epoch 77, Train Loss: 1.1328, Val Loss: 1.9161, F1 Micro: 0.3333, F1 Macro: 0.2954, Accuracy: 0.3333\n","Epoch 78, Train Loss: 1.1244, Val Loss: 2.4666, F1 Micro: 0.3958, F1 Macro: 0.3159, Accuracy: 0.3958\n","Epoch 79, Train Loss: 1.1843, Val Loss: 2.3584, F1 Micro: 0.3333, F1 Macro: 0.2821, Accuracy: 0.3333\n","Epoch 80, Train Loss: 1.1130, Val Loss: 2.1533, F1 Micro: 0.3646, F1 Macro: 0.3016, Accuracy: 0.3646\n","Epoch 81, Train Loss: 1.0777, Val Loss: 1.8238, F1 Micro: 0.3958, F1 Macro: 0.3725, Accuracy: 0.3958\n","Epoch 82, Train Loss: 1.1151, Val Loss: 2.0094, F1 Micro: 0.4375, F1 Macro: 0.3422, Accuracy: 0.4375\n","Epoch 83, Train Loss: 1.1234, Val Loss: 1.9909, F1 Micro: 0.3854, F1 Macro: 0.3322, Accuracy: 0.3854\n","Epoch 84, Train Loss: 1.1308, Val Loss: 3.4650, F1 Micro: 0.2812, F1 Macro: 0.2165, Accuracy: 0.2812\n","Epoch 85, Train Loss: 1.1176, Val Loss: 1.8281, F1 Micro: 0.4583, F1 Macro: 0.4214, Accuracy: 0.4583\n","Epoch 86, Train Loss: 1.0841, Val Loss: 2.1172, F1 Micro: 0.4062, F1 Macro: 0.3100, Accuracy: 0.4062\n","Epoch 87, Train Loss: 1.0519, Val Loss: 1.8299, F1 Micro: 0.4167, F1 Macro: 0.3412, Accuracy: 0.4167\n","Epoch 88, Train Loss: 1.0853, Val Loss: 1.7655, F1 Micro: 0.3750, F1 Macro: 0.3483, Accuracy: 0.3750\n","Epoch 89, Train Loss: 1.0457, Val Loss: 1.6942, F1 Micro: 0.4271, F1 Macro: 0.3972, Accuracy: 0.4271\n","Epoch 90, Train Loss: 1.1168, Val Loss: 1.6982, F1 Micro: 0.4479, F1 Macro: 0.3935, Accuracy: 0.4479\n","Epoch 91, Train Loss: 1.1174, Val Loss: 1.6558, F1 Micro: 0.4271, F1 Macro: 0.3828, Accuracy: 0.4271\n","Epoch 92, Train Loss: 1.0637, Val Loss: 2.0503, F1 Micro: 0.3646, F1 Macro: 0.3420, Accuracy: 0.3646\n","Epoch 93, Train Loss: 1.0282, Val Loss: 1.6900, F1 Micro: 0.3958, F1 Macro: 0.3745, Accuracy: 0.3958\n","Epoch 94, Train Loss: 1.0100, Val Loss: 1.8007, F1 Micro: 0.4375, F1 Macro: 0.4147, Accuracy: 0.4375\n","Epoch 95, Train Loss: 1.0316, Val Loss: 1.8418, F1 Micro: 0.4062, F1 Macro: 0.3656, Accuracy: 0.4062\n","Epoch 96, Train Loss: 0.9994, Val Loss: 1.8867, F1 Micro: 0.3958, F1 Macro: 0.3427, Accuracy: 0.3958\n","Epoch 97, Train Loss: 1.0134, Val Loss: 1.8281, F1 Micro: 0.3958, F1 Macro: 0.3466, Accuracy: 0.3958\n","Epoch 98, Train Loss: 1.0304, Val Loss: 2.7828, F1 Micro: 0.3542, F1 Macro: 0.2876, Accuracy: 0.3542\n","Epoch 99, Train Loss: 0.9679, Val Loss: 1.6930, F1 Micro: 0.4271, F1 Macro: 0.4005, Accuracy: 0.4271\n","Epoch 100, Train Loss: 0.9852, Val Loss: 2.0713, F1 Micro: 0.4062, F1 Macro: 0.3586, Accuracy: 0.4062\n","Epoch 101, Train Loss: 0.9268, Val Loss: 1.9735, F1 Micro: 0.4688, F1 Macro: 0.4389, Accuracy: 0.4688\n","Epoch 102, Train Loss: 1.0200, Val Loss: 1.5806, F1 Micro: 0.4688, F1 Macro: 0.4421, Accuracy: 0.4688\n","Epoch 103, Train Loss: 0.9979, Val Loss: 2.6198, F1 Micro: 0.3125, F1 Macro: 0.3088, Accuracy: 0.3125\n","Epoch 104, Train Loss: 0.9594, Val Loss: 2.8451, F1 Micro: 0.3438, F1 Macro: 0.2910, Accuracy: 0.3438\n","Epoch 105, Train Loss: 0.9346, Val Loss: 2.6296, F1 Micro: 0.3229, F1 Macro: 0.3298, Accuracy: 0.3229\n","Epoch 106, Train Loss: 0.9985, Val Loss: 1.9813, F1 Micro: 0.4062, F1 Macro: 0.3704, Accuracy: 0.4062\n","Epoch 107, Train Loss: 0.9382, Val Loss: 2.0983, F1 Micro: 0.3646, F1 Macro: 0.2965, Accuracy: 0.3646\n","Epoch 108, Train Loss: 0.8858, Val Loss: 1.7006, F1 Micro: 0.4167, F1 Macro: 0.3980, Accuracy: 0.4167\n","Epoch 109, Train Loss: 0.9446, Val Loss: 1.7687, F1 Micro: 0.4583, F1 Macro: 0.4271, Accuracy: 0.4583\n","Epoch 110, Train Loss: 0.8895, Val Loss: 2.5599, F1 Micro: 0.3542, F1 Macro: 0.3559, Accuracy: 0.3542\n","Epoch 111, Train Loss: 0.9702, Val Loss: 1.7359, F1 Micro: 0.4896, F1 Macro: 0.4324, Accuracy: 0.4896\n","Epoch 112, Train Loss: 0.8775, Val Loss: 1.9454, F1 Micro: 0.4375, F1 Macro: 0.3996, Accuracy: 0.4375\n","Epoch 113, Train Loss: 0.8468, Val Loss: 2.3457, F1 Micro: 0.3750, F1 Macro: 0.3668, Accuracy: 0.3750\n","Epoch 114, Train Loss: 0.9016, Val Loss: 1.7922, F1 Micro: 0.4688, F1 Macro: 0.4139, Accuracy: 0.4688\n","Epoch 115, Train Loss: 0.8599, Val Loss: 2.2082, F1 Micro: 0.3750, F1 Macro: 0.3413, Accuracy: 0.3750\n","Epoch 116, Train Loss: 0.8700, Val Loss: 2.7244, F1 Micro: 0.3438, F1 Macro: 0.2813, Accuracy: 0.3438\n","Epoch 117, Train Loss: 0.8582, Val Loss: 1.9970, F1 Micro: 0.4688, F1 Macro: 0.4303, Accuracy: 0.4688\n","Epoch 118, Train Loss: 0.9368, Val Loss: 2.1445, F1 Micro: 0.3646, F1 Macro: 0.3049, Accuracy: 0.3646\n","Epoch 119, Train Loss: 0.9133, Val Loss: 1.8862, F1 Micro: 0.4375, F1 Macro: 0.4022, Accuracy: 0.4375\n","Epoch 120, Train Loss: 0.8436, Val Loss: 2.0185, F1 Micro: 0.4167, F1 Macro: 0.3766, Accuracy: 0.4167\n","Epoch 121, Train Loss: 0.8162, Val Loss: 1.9104, F1 Micro: 0.4167, F1 Macro: 0.3813, Accuracy: 0.4167\n","Epoch 122, Train Loss: 0.8223, Val Loss: 1.6966, F1 Micro: 0.5000, F1 Macro: 0.4596, Accuracy: 0.5000\n","Epoch 123, Train Loss: 0.8164, Val Loss: 2.5080, F1 Micro: 0.3438, F1 Macro: 0.3294, Accuracy: 0.3438\n","Epoch 124, Train Loss: 0.8333, Val Loss: 1.5355, F1 Micro: 0.5208, F1 Macro: 0.4833, Accuracy: 0.5208\n","Epoch 125, Train Loss: 0.8002, Val Loss: 1.6715, F1 Micro: 0.4792, F1 Macro: 0.4393, Accuracy: 0.4792\n","Epoch 126, Train Loss: 0.8058, Val Loss: 2.2707, F1 Micro: 0.3750, F1 Macro: 0.3097, Accuracy: 0.3750\n","Epoch 127, Train Loss: 0.8698, Val Loss: 1.8218, F1 Micro: 0.5417, F1 Macro: 0.5122, Accuracy: 0.5417\n","Epoch 128, Train Loss: 0.7715, Val Loss: 1.7315, F1 Micro: 0.5000, F1 Macro: 0.4777, Accuracy: 0.5000\n","Epoch 129, Train Loss: 0.8286, Val Loss: 2.5594, F1 Micro: 0.3958, F1 Macro: 0.3452, Accuracy: 0.3958\n","Epoch 130, Train Loss: 0.7583, Val Loss: 1.9448, F1 Micro: 0.4479, F1 Macro: 0.4001, Accuracy: 0.4479\n","Epoch 131, Train Loss: 0.7670, Val Loss: 2.4162, F1 Micro: 0.4167, F1 Macro: 0.3500, Accuracy: 0.4167\n","Epoch 132, Train Loss: 0.7172, Val Loss: 1.8192, F1 Micro: 0.4896, F1 Macro: 0.4806, Accuracy: 0.4896\n","Epoch 133, Train Loss: 0.7589, Val Loss: 2.2176, F1 Micro: 0.4271, F1 Macro: 0.3921, Accuracy: 0.4271\n","Epoch 134, Train Loss: 0.8369, Val Loss: 2.0669, F1 Micro: 0.4271, F1 Macro: 0.4048, Accuracy: 0.4271\n","Epoch 135, Train Loss: 0.7502, Val Loss: 2.2276, F1 Micro: 0.4167, F1 Macro: 0.3584, Accuracy: 0.4167\n","Epoch 136, Train Loss: 0.7717, Val Loss: 1.6063, F1 Micro: 0.4896, F1 Macro: 0.4280, Accuracy: 0.4896\n","Epoch 137, Train Loss: 0.7559, Val Loss: 1.7338, F1 Micro: 0.4583, F1 Macro: 0.4010, Accuracy: 0.4583\n","Epoch 138, Train Loss: 0.6794, Val Loss: 1.9323, F1 Micro: 0.4792, F1 Macro: 0.4753, Accuracy: 0.4792\n","Epoch 139, Train Loss: 0.6878, Val Loss: 1.8154, F1 Micro: 0.5000, F1 Macro: 0.4456, Accuracy: 0.5000\n","Epoch 140, Train Loss: 0.7322, Val Loss: 2.2509, F1 Micro: 0.3958, F1 Macro: 0.3732, Accuracy: 0.3958\n","Epoch 141, Train Loss: 0.7285, Val Loss: 2.3314, F1 Micro: 0.3854, F1 Macro: 0.3347, Accuracy: 0.3854\n","Epoch 142, Train Loss: 0.7497, Val Loss: 2.3438, F1 Micro: 0.3958, F1 Macro: 0.3541, Accuracy: 0.3958\n","Epoch 143, Train Loss: 0.6948, Val Loss: 2.9623, F1 Micro: 0.3229, F1 Macro: 0.2749, Accuracy: 0.3229\n","Epoch 144, Train Loss: 0.7555, Val Loss: 1.8078, F1 Micro: 0.4792, F1 Macro: 0.4383, Accuracy: 0.4792\n","Epoch 145, Train Loss: 0.7163, Val Loss: 2.0514, F1 Micro: 0.4375, F1 Macro: 0.3654, Accuracy: 0.4375\n","Epoch 146, Train Loss: 0.7133, Val Loss: 2.2508, F1 Micro: 0.4062, F1 Macro: 0.3246, Accuracy: 0.4062\n","Epoch 147, Train Loss: 0.6808, Val Loss: 1.6898, F1 Micro: 0.6146, F1 Macro: 0.5716, Accuracy: 0.6146\n","Epoch 148, Train Loss: 0.7264, Val Loss: 1.7440, F1 Micro: 0.5625, F1 Macro: 0.5358, Accuracy: 0.5625\n","Epoch 149, Train Loss: 0.6618, Val Loss: 1.8441, F1 Micro: 0.5000, F1 Macro: 0.4342, Accuracy: 0.5000\n","Epoch 150, Train Loss: 0.6763, Val Loss: 1.7521, F1 Micro: 0.5833, F1 Macro: 0.5511, Accuracy: 0.5833\n","Epoch 151, Train Loss: 0.7120, Val Loss: 1.7185, F1 Micro: 0.5000, F1 Macro: 0.4405, Accuracy: 0.5000\n","Epoch 152, Train Loss: 0.6522, Val Loss: 1.7529, F1 Micro: 0.5833, F1 Macro: 0.5454, Accuracy: 0.5833\n","Epoch 153, Train Loss: 0.6852, Val Loss: 1.5936, F1 Micro: 0.5729, F1 Macro: 0.5084, Accuracy: 0.5729\n","Epoch 154, Train Loss: 0.6691, Val Loss: 2.8689, F1 Micro: 0.4062, F1 Macro: 0.3127, Accuracy: 0.4062\n","Epoch 155, Train Loss: 0.6679, Val Loss: 1.6802, F1 Micro: 0.5625, F1 Macro: 0.5324, Accuracy: 0.5625\n","Epoch 156, Train Loss: 0.6126, Val Loss: 1.7915, F1 Micro: 0.5833, F1 Macro: 0.5401, Accuracy: 0.5833\n","Epoch 157, Train Loss: 0.7434, Val Loss: 2.3296, F1 Micro: 0.4271, F1 Macro: 0.3728, Accuracy: 0.4271\n","Epoch 158, Train Loss: 0.7452, Val Loss: 1.9410, F1 Micro: 0.4583, F1 Macro: 0.4071, Accuracy: 0.4583\n","Epoch 159, Train Loss: 0.6555, Val Loss: 1.6076, F1 Micro: 0.5729, F1 Macro: 0.5488, Accuracy: 0.5729\n","Epoch 160, Train Loss: 0.6390, Val Loss: 2.0069, F1 Micro: 0.5208, F1 Macro: 0.4711, Accuracy: 0.5208\n","Epoch 161, Train Loss: 0.6243, Val Loss: 1.8328, F1 Micro: 0.5104, F1 Macro: 0.4677, Accuracy: 0.5104\n","Epoch 162, Train Loss: 0.5686, Val Loss: 1.7229, F1 Micro: 0.5417, F1 Macro: 0.5011, Accuracy: 0.5417\n","Epoch 163, Train Loss: 0.6231, Val Loss: 1.6725, F1 Micro: 0.5521, F1 Macro: 0.5279, Accuracy: 0.5521\n","Epoch 164, Train Loss: 0.5650, Val Loss: 2.1356, F1 Micro: 0.5312, F1 Macro: 0.4696, Accuracy: 0.5312\n","Epoch 165, Train Loss: 0.6305, Val Loss: 2.0813, F1 Micro: 0.5208, F1 Macro: 0.4914, Accuracy: 0.5208\n","Epoch 166, Train Loss: 0.6491, Val Loss: 2.2504, F1 Micro: 0.5000, F1 Macro: 0.4661, Accuracy: 0.5000\n","Epoch 167, Train Loss: 0.7063, Val Loss: 2.1885, F1 Micro: 0.4479, F1 Macro: 0.4108, Accuracy: 0.4479\n","Epoch 168, Train Loss: 0.6353, Val Loss: 2.0003, F1 Micro: 0.4792, F1 Macro: 0.4276, Accuracy: 0.4792\n","Epoch 169, Train Loss: 0.6362, Val Loss: 1.8238, F1 Micro: 0.4896, F1 Macro: 0.4466, Accuracy: 0.4896\n","Epoch 170, Train Loss: 0.5377, Val Loss: 1.5940, F1 Micro: 0.5833, F1 Macro: 0.5382, Accuracy: 0.5833\n","Epoch 171, Train Loss: 0.6173, Val Loss: 1.8572, F1 Micro: 0.5208, F1 Macro: 0.5007, Accuracy: 0.5208\n","Epoch 172, Train Loss: 0.5732, Val Loss: 1.7000, F1 Micro: 0.6146, F1 Macro: 0.5837, Accuracy: 0.6146\n","Epoch 173, Train Loss: 0.6321, Val Loss: 2.1151, F1 Micro: 0.5417, F1 Macro: 0.5079, Accuracy: 0.5417\n","Epoch 174, Train Loss: 0.6619, Val Loss: 2.1588, F1 Micro: 0.4688, F1 Macro: 0.4438, Accuracy: 0.4688\n","Epoch 175, Train Loss: 0.6335, Val Loss: 2.1853, F1 Micro: 0.5104, F1 Macro: 0.4744, Accuracy: 0.5104\n","Epoch 176, Train Loss: 0.5748, Val Loss: 1.8187, F1 Micro: 0.5104, F1 Macro: 0.4476, Accuracy: 0.5104\n","Epoch 177, Train Loss: 0.6197, Val Loss: 1.8578, F1 Micro: 0.5417, F1 Macro: 0.5115, Accuracy: 0.5417\n","Epoch 178, Train Loss: 0.5989, Val Loss: 1.5893, F1 Micro: 0.5625, F1 Macro: 0.5261, Accuracy: 0.5625\n","Epoch 179, Train Loss: 0.6265, Val Loss: 2.1785, F1 Micro: 0.5312, F1 Macro: 0.5097, Accuracy: 0.5312\n","Epoch 180, Train Loss: 0.5617, Val Loss: 2.3335, F1 Micro: 0.4896, F1 Macro: 0.4143, Accuracy: 0.4896\n","Epoch 181, Train Loss: 0.5424, Val Loss: 2.0726, F1 Micro: 0.5521, F1 Macro: 0.4968, Accuracy: 0.5521\n","Epoch 182, Train Loss: 0.5529, Val Loss: 2.8682, F1 Micro: 0.4479, F1 Macro: 0.3655, Accuracy: 0.4479\n","Epoch 183, Train Loss: 0.5473, Val Loss: 2.0274, F1 Micro: 0.5417, F1 Macro: 0.5108, Accuracy: 0.5417\n","Epoch 184, Train Loss: 0.5561, Val Loss: 2.6807, F1 Micro: 0.4688, F1 Macro: 0.3839, Accuracy: 0.4688\n","Epoch 185, Train Loss: 0.5746, Val Loss: 2.0841, F1 Micro: 0.5833, F1 Macro: 0.5686, Accuracy: 0.5833\n","Epoch 186, Train Loss: 0.6020, Val Loss: 3.0706, F1 Micro: 0.3542, F1 Macro: 0.3252, Accuracy: 0.3542\n","Epoch 187, Train Loss: 0.5820, Val Loss: 1.9398, F1 Micro: 0.6042, F1 Macro: 0.5687, Accuracy: 0.6042\n","Epoch 188, Train Loss: 0.4693, Val Loss: 1.7181, F1 Micro: 0.5938, F1 Macro: 0.5622, Accuracy: 0.5938\n","Epoch 189, Train Loss: 0.4778, Val Loss: 1.9646, F1 Micro: 0.5521, F1 Macro: 0.5065, Accuracy: 0.5521\n","Epoch 190, Train Loss: 0.5012, Val Loss: 2.0013, F1 Micro: 0.5938, F1 Macro: 0.5590, Accuracy: 0.5938\n","Epoch 191, Train Loss: 0.5147, Val Loss: 2.7747, F1 Micro: 0.4792, F1 Macro: 0.3850, Accuracy: 0.4792\n","Epoch 192, Train Loss: 0.5946, Val Loss: 2.5246, F1 Micro: 0.4688, F1 Macro: 0.4382, Accuracy: 0.4688\n","Epoch 193, Train Loss: 0.5496, Val Loss: 2.1058, F1 Micro: 0.5729, F1 Macro: 0.5099, Accuracy: 0.5729\n","Epoch 194, Train Loss: 0.4774, Val Loss: 2.0213, F1 Micro: 0.5938, F1 Macro: 0.5702, Accuracy: 0.5938\n","Epoch 195, Train Loss: 0.5532, Val Loss: 2.6058, F1 Micro: 0.5208, F1 Macro: 0.4767, Accuracy: 0.5208\n","Epoch 196, Train Loss: 0.5020, Val Loss: 1.9856, F1 Micro: 0.6042, F1 Macro: 0.5933, Accuracy: 0.6042\n","Epoch 197, Train Loss: 0.4339, Val Loss: 2.1771, F1 Micro: 0.5208, F1 Macro: 0.4846, Accuracy: 0.5208\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8332, Val Loss: 1.8223, F1 Micro: 0.1771, F1 Macro: 0.0530, Accuracy: 0.1771\n","Epoch 2, Train Loss: 1.7685, Val Loss: 1.9332, F1 Micro: 0.2604, F1 Macro: 0.1948, Accuracy: 0.2604\n","Epoch 3, Train Loss: 1.7524, Val Loss: 2.0882, F1 Micro: 0.2500, F1 Macro: 0.1521, Accuracy: 0.2500\n","Epoch 4, Train Loss: 1.7282, Val Loss: 1.7427, F1 Micro: 0.2812, F1 Macro: 0.2201, Accuracy: 0.2812\n","Epoch 5, Train Loss: 1.6917, Val Loss: 1.7446, F1 Micro: 0.1562, F1 Macro: 0.1572, Accuracy: 0.1562\n","Epoch 6, Train Loss: 1.7240, Val Loss: 1.7398, F1 Micro: 0.2292, F1 Macro: 0.1896, Accuracy: 0.2292\n","Epoch 7, Train Loss: 1.6652, Val Loss: 1.7425, F1 Micro: 0.2917, F1 Macro: 0.2610, Accuracy: 0.2917\n","Epoch 8, Train Loss: 1.6795, Val Loss: 1.6749, F1 Micro: 0.2708, F1 Macro: 0.2818, Accuracy: 0.2708\n","Epoch 9, Train Loss: 1.6196, Val Loss: 1.7900, F1 Micro: 0.3229, F1 Macro: 0.2878, Accuracy: 0.3229\n","Epoch 10, Train Loss: 1.6472, Val Loss: 1.6808, F1 Micro: 0.2604, F1 Macro: 0.1944, Accuracy: 0.2604\n","Epoch 11, Train Loss: 1.6407, Val Loss: 1.7629, F1 Micro: 0.3021, F1 Macro: 0.2573, Accuracy: 0.3021\n","Epoch 12, Train Loss: 1.6259, Val Loss: 1.7087, F1 Micro: 0.3125, F1 Macro: 0.2733, Accuracy: 0.3125\n","Epoch 13, Train Loss: 1.6075, Val Loss: 1.7031, F1 Micro: 0.3854, F1 Macro: 0.3702, Accuracy: 0.3854\n","Epoch 14, Train Loss: 1.6006, Val Loss: 1.7630, F1 Micro: 0.3438, F1 Macro: 0.2779, Accuracy: 0.3438\n","Epoch 15, Train Loss: 1.5962, Val Loss: 1.9100, F1 Micro: 0.3229, F1 Macro: 0.2909, Accuracy: 0.3229\n","Epoch 16, Train Loss: 1.5866, Val Loss: 1.6645, F1 Micro: 0.3125, F1 Macro: 0.2935, Accuracy: 0.3125\n","Epoch 17, Train Loss: 1.5784, Val Loss: 1.7316, F1 Micro: 0.3438, F1 Macro: 0.2990, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5470, Val Loss: 2.0951, F1 Micro: 0.2500, F1 Macro: 0.1992, Accuracy: 0.2500\n","Epoch 19, Train Loss: 1.5436, Val Loss: 1.7250, F1 Micro: 0.2917, F1 Macro: 0.2414, Accuracy: 0.2917\n","Epoch 20, Train Loss: 1.5405, Val Loss: 1.7109, F1 Micro: 0.3646, F1 Macro: 0.3233, Accuracy: 0.3646\n","Epoch 21, Train Loss: 1.5475, Val Loss: 1.6151, F1 Micro: 0.3542, F1 Macro: 0.3526, Accuracy: 0.3542\n","Epoch 22, Train Loss: 1.5059, Val Loss: 1.7690, F1 Micro: 0.3438, F1 Macro: 0.2612, Accuracy: 0.3438\n","Epoch 23, Train Loss: 1.5365, Val Loss: 1.8534, F1 Micro: 0.3229, F1 Macro: 0.2797, Accuracy: 0.3229\n","Epoch 24, Train Loss: 1.5213, Val Loss: 1.6651, F1 Micro: 0.3750, F1 Macro: 0.3709, Accuracy: 0.3750\n","Epoch 25, Train Loss: 1.5174, Val Loss: 2.0865, F1 Micro: 0.2396, F1 Macro: 0.1610, Accuracy: 0.2396\n","Epoch 26, Train Loss: 1.5183, Val Loss: 1.6784, F1 Micro: 0.3542, F1 Macro: 0.3376, Accuracy: 0.3542\n","Epoch 27, Train Loss: 1.4808, Val Loss: 1.9967, F1 Micro: 0.2708, F1 Macro: 0.2285, Accuracy: 0.2708\n","Epoch 28, Train Loss: 1.4839, Val Loss: 1.7467, F1 Micro: 0.3021, F1 Macro: 0.2687, Accuracy: 0.3021\n","Epoch 29, Train Loss: 1.4601, Val Loss: 1.7493, F1 Micro: 0.2917, F1 Macro: 0.2733, Accuracy: 0.2917\n","Epoch 30, Train Loss: 1.4299, Val Loss: 3.0322, F1 Micro: 0.2396, F1 Macro: 0.1599, Accuracy: 0.2396\n","Epoch 31, Train Loss: 1.4755, Val Loss: 1.9010, F1 Micro: 0.2292, F1 Macro: 0.1701, Accuracy: 0.2292\n","Epoch 32, Train Loss: 1.4264, Val Loss: 1.8194, F1 Micro: 0.3333, F1 Macro: 0.2948, Accuracy: 0.3333\n","Epoch 33, Train Loss: 1.3949, Val Loss: 1.7457, F1 Micro: 0.3021, F1 Macro: 0.2670, Accuracy: 0.3021\n","Epoch 34, Train Loss: 1.4472, Val Loss: 1.6180, F1 Micro: 0.3333, F1 Macro: 0.3147, Accuracy: 0.3333\n","Epoch 35, Train Loss: 1.4140, Val Loss: 1.6873, F1 Micro: 0.3333, F1 Macro: 0.2975, Accuracy: 0.3333\n","Epoch 36, Train Loss: 1.3948, Val Loss: 2.2223, F1 Micro: 0.3021, F1 Macro: 0.2660, Accuracy: 0.3021\n","Epoch 37, Train Loss: 1.4019, Val Loss: 1.5394, F1 Micro: 0.3542, F1 Macro: 0.3432, Accuracy: 0.3542\n","Epoch 38, Train Loss: 1.3526, Val Loss: 1.7040, F1 Micro: 0.3229, F1 Macro: 0.2978, Accuracy: 0.3229\n","Epoch 39, Train Loss: 1.3459, Val Loss: 1.7250, F1 Micro: 0.2917, F1 Macro: 0.2765, Accuracy: 0.2917\n","Epoch 40, Train Loss: 1.3743, Val Loss: 2.3862, F1 Micro: 0.1875, F1 Macro: 0.1285, Accuracy: 0.1875\n","Epoch 41, Train Loss: 1.3677, Val Loss: 1.5405, F1 Micro: 0.4375, F1 Macro: 0.4349, Accuracy: 0.4375\n","Epoch 42, Train Loss: 1.3199, Val Loss: 1.8119, F1 Micro: 0.3229, F1 Macro: 0.2752, Accuracy: 0.3229\n","Epoch 43, Train Loss: 1.3089, Val Loss: 1.7158, F1 Micro: 0.3333, F1 Macro: 0.2996, Accuracy: 0.3333\n","Epoch 44, Train Loss: 1.2656, Val Loss: 1.5580, F1 Micro: 0.4375, F1 Macro: 0.4028, Accuracy: 0.4375\n","Epoch 45, Train Loss: 1.3478, Val Loss: 2.3167, F1 Micro: 0.2604, F1 Macro: 0.2289, Accuracy: 0.2604\n","Epoch 46, Train Loss: 1.3493, Val Loss: 1.5426, F1 Micro: 0.3646, F1 Macro: 0.3237, Accuracy: 0.3646\n","Epoch 47, Train Loss: 1.2402, Val Loss: 2.4170, F1 Micro: 0.2812, F1 Macro: 0.2496, Accuracy: 0.2812\n","Epoch 48, Train Loss: 1.2726, Val Loss: 1.7636, F1 Micro: 0.3229, F1 Macro: 0.2659, Accuracy: 0.3229\n","Epoch 49, Train Loss: 1.2287, Val Loss: 1.6143, F1 Micro: 0.3958, F1 Macro: 0.3855, Accuracy: 0.3958\n","Epoch 50, Train Loss: 1.1920, Val Loss: 2.4270, F1 Micro: 0.2812, F1 Macro: 0.2004, Accuracy: 0.2812\n","Epoch 51, Train Loss: 1.1947, Val Loss: 1.5563, F1 Micro: 0.4062, F1 Macro: 0.3618, Accuracy: 0.4062\n","Epoch 52, Train Loss: 1.1715, Val Loss: 2.3781, F1 Micro: 0.3542, F1 Macro: 0.3330, Accuracy: 0.3542\n","Epoch 53, Train Loss: 1.1514, Val Loss: 1.9315, F1 Micro: 0.3646, F1 Macro: 0.2999, Accuracy: 0.3646\n","Epoch 54, Train Loss: 1.1946, Val Loss: 1.4716, F1 Micro: 0.4479, F1 Macro: 0.4424, Accuracy: 0.4479\n","Epoch 55, Train Loss: 1.1726, Val Loss: 2.1771, F1 Micro: 0.3333, F1 Macro: 0.2887, Accuracy: 0.3333\n","Epoch 56, Train Loss: 1.1832, Val Loss: 1.5165, F1 Micro: 0.3438, F1 Macro: 0.3252, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.1579, Val Loss: 1.7740, F1 Micro: 0.3333, F1 Macro: 0.3016, Accuracy: 0.3333\n","Epoch 58, Train Loss: 1.1389, Val Loss: 1.6259, F1 Micro: 0.4167, F1 Macro: 0.4071, Accuracy: 0.4167\n","Epoch 59, Train Loss: 1.0815, Val Loss: 2.2342, F1 Micro: 0.3646, F1 Macro: 0.3506, Accuracy: 0.3646\n","Epoch 60, Train Loss: 1.0787, Val Loss: 2.2688, F1 Micro: 0.2604, F1 Macro: 0.2458, Accuracy: 0.2604\n","Epoch 61, Train Loss: 1.0860, Val Loss: 2.0393, F1 Micro: 0.3438, F1 Macro: 0.3227, Accuracy: 0.3438\n","Epoch 62, Train Loss: 1.0630, Val Loss: 3.1474, F1 Micro: 0.2292, F1 Macro: 0.1504, Accuracy: 0.2292\n","Epoch 63, Train Loss: 1.0620, Val Loss: 1.4850, F1 Micro: 0.4792, F1 Macro: 0.4437, Accuracy: 0.4792\n","Epoch 64, Train Loss: 1.0160, Val Loss: 1.7528, F1 Micro: 0.4167, F1 Macro: 0.3778, Accuracy: 0.4167\n","Epoch 65, Train Loss: 1.0731, Val Loss: 1.8329, F1 Micro: 0.4062, F1 Macro: 0.3850, Accuracy: 0.4062\n","Epoch 66, Train Loss: 1.0613, Val Loss: 2.4960, F1 Micro: 0.3333, F1 Macro: 0.2601, Accuracy: 0.3333\n","Epoch 67, Train Loss: 1.0298, Val Loss: 3.0249, F1 Micro: 0.2708, F1 Macro: 0.2482, Accuracy: 0.2708\n","Epoch 68, Train Loss: 1.0231, Val Loss: 1.5955, F1 Micro: 0.4583, F1 Macro: 0.4584, Accuracy: 0.4583\n","Epoch 69, Train Loss: 0.9954, Val Loss: 1.5717, F1 Micro: 0.4583, F1 Macro: 0.4514, Accuracy: 0.4583\n","Epoch 70, Train Loss: 0.9751, Val Loss: 1.7524, F1 Micro: 0.3438, F1 Macro: 0.3377, Accuracy: 0.3438\n","Epoch 71, Train Loss: 0.9214, Val Loss: 2.0507, F1 Micro: 0.3854, F1 Macro: 0.3848, Accuracy: 0.3854\n","Epoch 72, Train Loss: 0.9588, Val Loss: 2.2603, F1 Micro: 0.3438, F1 Macro: 0.3162, Accuracy: 0.3438\n","Epoch 73, Train Loss: 0.9780, Val Loss: 1.6672, F1 Micro: 0.4583, F1 Macro: 0.4678, Accuracy: 0.4583\n","Epoch 74, Train Loss: 0.9191, Val Loss: 2.9454, F1 Micro: 0.3333, F1 Macro: 0.3380, Accuracy: 0.3333\n","Epoch 75, Train Loss: 0.9713, Val Loss: 1.5511, F1 Micro: 0.4167, F1 Macro: 0.4207, Accuracy: 0.4167\n","Epoch 76, Train Loss: 0.9176, Val Loss: 2.1229, F1 Micro: 0.3646, F1 Macro: 0.3350, Accuracy: 0.3646\n","Epoch 77, Train Loss: 0.9171, Val Loss: 2.2998, F1 Micro: 0.3750, F1 Macro: 0.3402, Accuracy: 0.3750\n","Epoch 78, Train Loss: 0.9752, Val Loss: 1.4924, F1 Micro: 0.4583, F1 Macro: 0.4558, Accuracy: 0.4583\n","Epoch 79, Train Loss: 0.9154, Val Loss: 1.7067, F1 Micro: 0.3750, F1 Macro: 0.3871, Accuracy: 0.3750\n","Epoch 80, Train Loss: 0.9138, Val Loss: 3.2024, F1 Micro: 0.2500, F1 Macro: 0.2064, Accuracy: 0.2500\n","Epoch 81, Train Loss: 0.9155, Val Loss: 1.8795, F1 Micro: 0.3750, F1 Macro: 0.3823, Accuracy: 0.3750\n","Epoch 82, Train Loss: 0.8748, Val Loss: 1.5398, F1 Micro: 0.4375, F1 Macro: 0.4322, Accuracy: 0.4375\n","Epoch 83, Train Loss: 0.8050, Val Loss: 1.6802, F1 Micro: 0.4375, F1 Macro: 0.4077, Accuracy: 0.4375\n","Epoch 84, Train Loss: 0.8940, Val Loss: 2.0198, F1 Micro: 0.3438, F1 Macro: 0.2936, Accuracy: 0.3438\n","Epoch 85, Train Loss: 0.8687, Val Loss: 1.7989, F1 Micro: 0.4167, F1 Macro: 0.4022, Accuracy: 0.4167\n","Epoch 86, Train Loss: 0.8465, Val Loss: 1.4659, F1 Micro: 0.4792, F1 Macro: 0.4733, Accuracy: 0.4792\n","Epoch 87, Train Loss: 0.8115, Val Loss: 1.7984, F1 Micro: 0.4167, F1 Macro: 0.4173, Accuracy: 0.4167\n","Epoch 88, Train Loss: 0.8537, Val Loss: 1.8891, F1 Micro: 0.4167, F1 Macro: 0.4187, Accuracy: 0.4167\n","Epoch 89, Train Loss: 0.8249, Val Loss: 1.4964, F1 Micro: 0.4479, F1 Macro: 0.4491, Accuracy: 0.4479\n","Epoch 90, Train Loss: 0.8063, Val Loss: 2.0398, F1 Micro: 0.3542, F1 Macro: 0.3274, Accuracy: 0.3542\n","Epoch 91, Train Loss: 0.7472, Val Loss: 1.6558, F1 Micro: 0.3854, F1 Macro: 0.3851, Accuracy: 0.3854\n","Epoch 92, Train Loss: 0.7261, Val Loss: 3.4890, F1 Micro: 0.2708, F1 Macro: 0.2006, Accuracy: 0.2708\n","Epoch 93, Train Loss: 0.8010, Val Loss: 1.6456, F1 Micro: 0.3854, F1 Macro: 0.3908, Accuracy: 0.3854\n","Epoch 94, Train Loss: 0.8500, Val Loss: 1.8751, F1 Micro: 0.3854, F1 Macro: 0.3875, Accuracy: 0.3854\n","Epoch 95, Train Loss: 0.7756, Val Loss: 1.7695, F1 Micro: 0.4479, F1 Macro: 0.4531, Accuracy: 0.4479\n","Epoch 96, Train Loss: 0.7551, Val Loss: 1.6198, F1 Micro: 0.4479, F1 Macro: 0.4383, Accuracy: 0.4479\n","Epoch 97, Train Loss: 0.7670, Val Loss: 1.5629, F1 Micro: 0.4896, F1 Macro: 0.4830, Accuracy: 0.4896\n","Epoch 98, Train Loss: 0.7646, Val Loss: 2.4432, F1 Micro: 0.3333, F1 Macro: 0.3150, Accuracy: 0.3333\n","Epoch 99, Train Loss: 0.7395, Val Loss: 1.6371, F1 Micro: 0.4583, F1 Macro: 0.4695, Accuracy: 0.4583\n","Epoch 100, Train Loss: 0.7211, Val Loss: 1.7028, F1 Micro: 0.4688, F1 Macro: 0.4614, Accuracy: 0.4688\n","Epoch 101, Train Loss: 0.6959, Val Loss: 1.6642, F1 Micro: 0.5000, F1 Macro: 0.4810, Accuracy: 0.5000\n","Epoch 102, Train Loss: 0.7419, Val Loss: 1.5634, F1 Micro: 0.4479, F1 Macro: 0.4529, Accuracy: 0.4479\n","Epoch 103, Train Loss: 0.7770, Val Loss: 1.5789, F1 Micro: 0.4583, F1 Macro: 0.4532, Accuracy: 0.4583\n","Epoch 104, Train Loss: 0.7103, Val Loss: 1.5521, F1 Micro: 0.4583, F1 Macro: 0.4721, Accuracy: 0.4583\n","Epoch 105, Train Loss: 0.6748, Val Loss: 2.3140, F1 Micro: 0.3958, F1 Macro: 0.3647, Accuracy: 0.3958\n","Epoch 106, Train Loss: 0.6978, Val Loss: 1.5017, F1 Micro: 0.5000, F1 Macro: 0.5013, Accuracy: 0.5000\n","Epoch 107, Train Loss: 0.6941, Val Loss: 1.5869, F1 Micro: 0.5417, F1 Macro: 0.5194, Accuracy: 0.5417\n","Epoch 108, Train Loss: 0.6825, Val Loss: 1.7628, F1 Micro: 0.4167, F1 Macro: 0.4045, Accuracy: 0.4167\n","Epoch 109, Train Loss: 0.6753, Val Loss: 2.0040, F1 Micro: 0.4375, F1 Macro: 0.3954, Accuracy: 0.4375\n","Epoch 110, Train Loss: 0.7019, Val Loss: 1.6389, F1 Micro: 0.4479, F1 Macro: 0.4334, Accuracy: 0.4479\n","Epoch 111, Train Loss: 0.7062, Val Loss: 1.6840, F1 Micro: 0.5104, F1 Macro: 0.4996, Accuracy: 0.5104\n","Epoch 112, Train Loss: 0.6588, Val Loss: 1.7288, F1 Micro: 0.4479, F1 Macro: 0.4565, Accuracy: 0.4479\n","Epoch 113, Train Loss: 0.6330, Val Loss: 1.9998, F1 Micro: 0.3750, F1 Macro: 0.3573, Accuracy: 0.3750\n","Epoch 114, Train Loss: 0.6270, Val Loss: 1.7962, F1 Micro: 0.4688, F1 Macro: 0.4602, Accuracy: 0.4688\n","Epoch 115, Train Loss: 0.6973, Val Loss: 1.6235, F1 Micro: 0.5208, F1 Macro: 0.5146, Accuracy: 0.5208\n","Epoch 116, Train Loss: 0.6423, Val Loss: 1.6527, F1 Micro: 0.5208, F1 Macro: 0.5191, Accuracy: 0.5208\n","Epoch 117, Train Loss: 0.6699, Val Loss: 1.6689, F1 Micro: 0.5312, F1 Macro: 0.5336, Accuracy: 0.5312\n","Epoch 118, Train Loss: 0.6543, Val Loss: 1.4386, F1 Micro: 0.5104, F1 Macro: 0.5021, Accuracy: 0.5104\n","Epoch 119, Train Loss: 0.6402, Val Loss: 2.1390, F1 Micro: 0.4062, F1 Macro: 0.3840, Accuracy: 0.4062\n","Epoch 120, Train Loss: 0.6762, Val Loss: 1.5000, F1 Micro: 0.4167, F1 Macro: 0.4087, Accuracy: 0.4167\n","Epoch 121, Train Loss: 0.7124, Val Loss: 1.6180, F1 Micro: 0.4792, F1 Macro: 0.4661, Accuracy: 0.4792\n","Epoch 122, Train Loss: 0.6556, Val Loss: 1.7949, F1 Micro: 0.5104, F1 Macro: 0.4896, Accuracy: 0.5104\n","Epoch 123, Train Loss: 0.6686, Val Loss: 1.5433, F1 Micro: 0.4896, F1 Macro: 0.5024, Accuracy: 0.4896\n","Epoch 124, Train Loss: 0.5670, Val Loss: 1.5447, F1 Micro: 0.4896, F1 Macro: 0.4931, Accuracy: 0.4896\n","Epoch 125, Train Loss: 0.5731, Val Loss: 1.9027, F1 Micro: 0.5000, F1 Macro: 0.4899, Accuracy: 0.5000\n","Epoch 126, Train Loss: 0.6082, Val Loss: 1.9904, F1 Micro: 0.4167, F1 Macro: 0.4208, Accuracy: 0.4167\n","Epoch 127, Train Loss: 0.5577, Val Loss: 2.0217, F1 Micro: 0.4167, F1 Macro: 0.3909, Accuracy: 0.4167\n","Epoch 128, Train Loss: 0.5817, Val Loss: 1.7591, F1 Micro: 0.4583, F1 Macro: 0.4833, Accuracy: 0.4583\n","Epoch 129, Train Loss: 0.5935, Val Loss: 2.3407, F1 Micro: 0.4062, F1 Macro: 0.3708, Accuracy: 0.4062\n","Epoch 130, Train Loss: 0.5591, Val Loss: 2.7526, F1 Micro: 0.4167, F1 Macro: 0.3847, Accuracy: 0.4167\n","Epoch 131, Train Loss: 0.6404, Val Loss: 1.8828, F1 Micro: 0.4167, F1 Macro: 0.4017, Accuracy: 0.4167\n","Epoch 132, Train Loss: 0.5395, Val Loss: 2.0173, F1 Micro: 0.4062, F1 Macro: 0.3979, Accuracy: 0.4062\n","Epoch 133, Train Loss: 0.5644, Val Loss: 1.7298, F1 Micro: 0.4479, F1 Macro: 0.4611, Accuracy: 0.4479\n","Epoch 134, Train Loss: 0.5109, Val Loss: 1.9939, F1 Micro: 0.4062, F1 Macro: 0.3868, Accuracy: 0.4062\n","Epoch 135, Train Loss: 0.4888, Val Loss: 1.6092, F1 Micro: 0.5312, F1 Macro: 0.5264, Accuracy: 0.5312\n","Epoch 136, Train Loss: 0.5224, Val Loss: 2.0999, F1 Micro: 0.4375, F1 Macro: 0.4396, Accuracy: 0.4375\n","Epoch 137, Train Loss: 0.5356, Val Loss: 2.0645, F1 Micro: 0.3958, F1 Macro: 0.3350, Accuracy: 0.3958\n","Epoch 138, Train Loss: 0.5658, Val Loss: 2.3959, F1 Micro: 0.4375, F1 Macro: 0.3887, Accuracy: 0.4375\n","Epoch 139, Train Loss: 0.5268, Val Loss: 1.8832, F1 Micro: 0.4271, F1 Macro: 0.4298, Accuracy: 0.4271\n","Epoch 140, Train Loss: 0.4947, Val Loss: 2.5046, F1 Micro: 0.3750, F1 Macro: 0.3574, Accuracy: 0.3750\n","Epoch 141, Train Loss: 0.4967, Val Loss: 1.9039, F1 Micro: 0.4688, F1 Macro: 0.4473, Accuracy: 0.4688\n","Epoch 142, Train Loss: 0.5350, Val Loss: 1.7631, F1 Micro: 0.4688, F1 Macro: 0.4625, Accuracy: 0.4688\n","Epoch 143, Train Loss: 0.5504, Val Loss: 2.1052, F1 Micro: 0.5000, F1 Macro: 0.5072, Accuracy: 0.5000\n","Epoch 144, Train Loss: 0.4934, Val Loss: 1.4756, F1 Micro: 0.5104, F1 Macro: 0.5167, Accuracy: 0.5104\n","Epoch 145, Train Loss: 0.4774, Val Loss: 1.6118, F1 Micro: 0.5521, F1 Macro: 0.5520, Accuracy: 0.5521\n","Epoch 146, Train Loss: 0.4903, Val Loss: 1.5450, F1 Micro: 0.5208, F1 Macro: 0.5243, Accuracy: 0.5208\n","Epoch 147, Train Loss: 0.5023, Val Loss: 1.9510, F1 Micro: 0.4271, F1 Macro: 0.4066, Accuracy: 0.4271\n","Epoch 148, Train Loss: 0.5339, Val Loss: 1.5910, F1 Micro: 0.4896, F1 Macro: 0.4945, Accuracy: 0.4896\n","Epoch 149, Train Loss: 0.5037, Val Loss: 2.1409, F1 Micro: 0.4375, F1 Macro: 0.4533, Accuracy: 0.4375\n","Epoch 150, Train Loss: 0.5161, Val Loss: 2.0339, F1 Micro: 0.5104, F1 Macro: 0.5102, Accuracy: 0.5104\n","Epoch 151, Train Loss: 0.4749, Val Loss: 2.2673, F1 Micro: 0.4583, F1 Macro: 0.4528, Accuracy: 0.4583\n","Epoch 152, Train Loss: 0.4541, Val Loss: 1.8936, F1 Micro: 0.5000, F1 Macro: 0.4945, Accuracy: 0.5000\n","Epoch 153, Train Loss: 0.5181, Val Loss: 1.9560, F1 Micro: 0.4479, F1 Macro: 0.4508, Accuracy: 0.4479\n","Epoch 154, Train Loss: 0.4558, Val Loss: 1.9340, F1 Micro: 0.5521, F1 Macro: 0.5585, Accuracy: 0.5521\n","Epoch 155, Train Loss: 0.4295, Val Loss: 2.4212, F1 Micro: 0.3958, F1 Macro: 0.3803, Accuracy: 0.3958\n","Epoch 156, Train Loss: 0.4580, Val Loss: 1.7650, F1 Micro: 0.5000, F1 Macro: 0.4980, Accuracy: 0.5000\n","Epoch 157, Train Loss: 0.4263, Val Loss: 2.1130, F1 Micro: 0.5104, F1 Macro: 0.4977, Accuracy: 0.5104\n","Epoch 158, Train Loss: 0.4549, Val Loss: 1.7445, F1 Micro: 0.5000, F1 Macro: 0.4972, Accuracy: 0.5000\n","Epoch 159, Train Loss: 0.4394, Val Loss: 1.6698, F1 Micro: 0.4792, F1 Macro: 0.4848, Accuracy: 0.4792\n","Epoch 160, Train Loss: 0.4854, Val Loss: 1.4788, F1 Micro: 0.5000, F1 Macro: 0.4918, Accuracy: 0.5000\n","Epoch 161, Train Loss: 0.5172, Val Loss: 2.0309, F1 Micro: 0.5208, F1 Macro: 0.5077, Accuracy: 0.5208\n","Epoch 162, Train Loss: 0.5278, Val Loss: 1.9946, F1 Micro: 0.4271, F1 Macro: 0.4291, Accuracy: 0.4271\n","Epoch 163, Train Loss: 0.4412, Val Loss: 2.0989, F1 Micro: 0.4896, F1 Macro: 0.4808, Accuracy: 0.4896\n","Epoch 164, Train Loss: 0.4955, Val Loss: 2.2555, F1 Micro: 0.4375, F1 Macro: 0.4227, Accuracy: 0.4375\n","Epoch 165, Train Loss: 0.4118, Val Loss: 1.5815, F1 Micro: 0.4896, F1 Macro: 0.4903, Accuracy: 0.4896\n","Epoch 166, Train Loss: 0.4026, Val Loss: 2.2296, F1 Micro: 0.4688, F1 Macro: 0.4146, Accuracy: 0.4688\n","Epoch 167, Train Loss: 0.4797, Val Loss: 1.6747, F1 Micro: 0.5521, F1 Macro: 0.5482, Accuracy: 0.5521\n","Epoch 168, Train Loss: 0.4200, Val Loss: 1.7796, F1 Micro: 0.5938, F1 Macro: 0.5945, Accuracy: 0.5938\n","Epoch 169, Train Loss: 0.3834, Val Loss: 1.6200, F1 Micro: 0.5312, F1 Macro: 0.5356, Accuracy: 0.5312\n","Epoch 170, Train Loss: 0.4411, Val Loss: 2.2819, F1 Micro: 0.4583, F1 Macro: 0.4379, Accuracy: 0.4583\n","Epoch 171, Train Loss: 0.4156, Val Loss: 2.0056, F1 Micro: 0.4896, F1 Macro: 0.4803, Accuracy: 0.4896\n","Epoch 172, Train Loss: 0.3830, Val Loss: 1.7381, F1 Micro: 0.5625, F1 Macro: 0.5542, Accuracy: 0.5625\n","Epoch 173, Train Loss: 0.3715, Val Loss: 1.5437, F1 Micro: 0.5625, F1 Macro: 0.5591, Accuracy: 0.5625\n","Epoch 174, Train Loss: 0.3803, Val Loss: 1.6695, F1 Micro: 0.5312, F1 Macro: 0.5272, Accuracy: 0.5312\n","Epoch 175, Train Loss: 0.3739, Val Loss: 1.6783, F1 Micro: 0.6042, F1 Macro: 0.6128, Accuracy: 0.6042\n","Epoch 176, Train Loss: 0.3612, Val Loss: 1.6014, F1 Micro: 0.5625, F1 Macro: 0.5442, Accuracy: 0.5625\n","Epoch 177, Train Loss: 0.3684, Val Loss: 2.2307, F1 Micro: 0.4479, F1 Macro: 0.4478, Accuracy: 0.4479\n","Epoch 178, Train Loss: 0.3615, Val Loss: 1.8533, F1 Micro: 0.5521, F1 Macro: 0.5503, Accuracy: 0.5521\n","Epoch 179, Train Loss: 0.3507, Val Loss: 1.9529, F1 Micro: 0.4479, F1 Macro: 0.4608, Accuracy: 0.4479\n","Epoch 180, Train Loss: 0.4044, Val Loss: 2.0472, F1 Micro: 0.4896, F1 Macro: 0.4848, Accuracy: 0.4896\n","Epoch 181, Train Loss: 0.4334, Val Loss: 1.8305, F1 Micro: 0.5104, F1 Macro: 0.5201, Accuracy: 0.5104\n","Epoch 182, Train Loss: 0.4477, Val Loss: 1.9764, F1 Micro: 0.5417, F1 Macro: 0.5254, Accuracy: 0.5417\n","Epoch 183, Train Loss: 0.3801, Val Loss: 1.9972, F1 Micro: 0.5104, F1 Macro: 0.5208, Accuracy: 0.5104\n","Epoch 184, Train Loss: 0.3807, Val Loss: 2.3315, F1 Micro: 0.4896, F1 Macro: 0.5042, Accuracy: 0.4896\n","Epoch 185, Train Loss: 0.3980, Val Loss: 1.8106, F1 Micro: 0.4792, F1 Macro: 0.4815, Accuracy: 0.4792\n","Epoch 186, Train Loss: 0.3250, Val Loss: 1.7717, F1 Micro: 0.5729, F1 Macro: 0.5844, Accuracy: 0.5729\n","Epoch 187, Train Loss: 0.3267, Val Loss: 2.2652, F1 Micro: 0.4479, F1 Macro: 0.4418, Accuracy: 0.4479\n","Epoch 188, Train Loss: 0.3378, Val Loss: 1.9944, F1 Micro: 0.6042, F1 Macro: 0.6062, Accuracy: 0.6042\n","Epoch 189, Train Loss: 0.3446, Val Loss: 1.6438, F1 Micro: 0.5521, F1 Macro: 0.5542, Accuracy: 0.5521\n","Epoch 190, Train Loss: 0.3241, Val Loss: 2.3260, F1 Micro: 0.5000, F1 Macro: 0.4924, Accuracy: 0.5000\n","Epoch 191, Train Loss: 0.3302, Val Loss: 1.7270, F1 Micro: 0.6042, F1 Macro: 0.6092, Accuracy: 0.6042\n","Epoch 192, Train Loss: 0.3572, Val Loss: 1.9626, F1 Micro: 0.5208, F1 Macro: 0.5234, Accuracy: 0.5208\n","Epoch 193, Train Loss: 0.3079, Val Loss: 2.1920, F1 Micro: 0.4375, F1 Macro: 0.4365, Accuracy: 0.4375\n","Epoch 194, Train Loss: 0.3157, Val Loss: 1.8292, F1 Micro: 0.5417, F1 Macro: 0.5521, Accuracy: 0.5417\n","Epoch 195, Train Loss: 0.2972, Val Loss: 1.7179, F1 Micro: 0.5625, F1 Macro: 0.5693, Accuracy: 0.5625\n","Epoch 196, Train Loss: 0.3045, Val Loss: 1.9447, F1 Micro: 0.5729, F1 Macro: 0.5549, Accuracy: 0.5729\n","Epoch 197, Train Loss: 0.3018, Val Loss: 2.2700, F1 Micro: 0.5000, F1 Macro: 0.5038, Accuracy: 0.5000\n","Epoch 198, Train Loss: 0.3039, Val Loss: 2.0663, F1 Micro: 0.4688, F1 Macro: 0.4723, Accuracy: 0.4688\n","Epoch 199, Train Loss: 0.4113, Val Loss: 2.2491, F1 Micro: 0.4792, F1 Macro: 0.4803, Accuracy: 0.4792\n","Epoch 200, Train Loss: 0.4032, Val Loss: 1.7494, F1 Micro: 0.5729, F1 Macro: 0.5652, Accuracy: 0.5729\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7870, Val Loss: 1.7587, F1 Micro: 0.2708, F1 Macro: 0.2270, Accuracy: 0.2708\n","Epoch 2, Train Loss: 1.7425, Val Loss: 1.7171, F1 Micro: 0.2917, F1 Macro: 0.2069, Accuracy: 0.2917\n","Epoch 3, Train Loss: 1.7344, Val Loss: 1.7072, F1 Micro: 0.2917, F1 Macro: 0.2521, Accuracy: 0.2917\n","Epoch 4, Train Loss: 1.6956, Val Loss: 1.7453, F1 Micro: 0.2396, F1 Macro: 0.1782, Accuracy: 0.2396\n","Epoch 5, Train Loss: 1.7057, Val Loss: 1.7038, F1 Micro: 0.2917, F1 Macro: 0.2407, Accuracy: 0.2917\n","Epoch 6, Train Loss: 1.6948, Val Loss: 1.7827, F1 Micro: 0.2604, F1 Macro: 0.1989, Accuracy: 0.2604\n","Epoch 7, Train Loss: 1.6697, Val Loss: 1.7897, F1 Micro: 0.2188, F1 Macro: 0.1446, Accuracy: 0.2188\n","Epoch 8, Train Loss: 1.6570, Val Loss: 1.8433, F1 Micro: 0.2500, F1 Macro: 0.1845, Accuracy: 0.2500\n","Epoch 9, Train Loss: 1.6511, Val Loss: 1.9307, F1 Micro: 0.2292, F1 Macro: 0.1639, Accuracy: 0.2292\n","Epoch 10, Train Loss: 1.6299, Val Loss: 1.7065, F1 Micro: 0.3021, F1 Macro: 0.2557, Accuracy: 0.3021\n","Epoch 11, Train Loss: 1.5966, Val Loss: 1.7490, F1 Micro: 0.3438, F1 Macro: 0.2954, Accuracy: 0.3438\n","Epoch 12, Train Loss: 1.6397, Val Loss: 1.7193, F1 Micro: 0.3333, F1 Macro: 0.2855, Accuracy: 0.3333\n","Epoch 13, Train Loss: 1.5926, Val Loss: 2.0261, F1 Micro: 0.2500, F1 Macro: 0.1697, Accuracy: 0.2500\n","Epoch 14, Train Loss: 1.6354, Val Loss: 1.7591, F1 Micro: 0.3333, F1 Macro: 0.2698, Accuracy: 0.3333\n","Epoch 15, Train Loss: 1.5872, Val Loss: 1.6874, F1 Micro: 0.3542, F1 Macro: 0.2979, Accuracy: 0.3542\n","Epoch 16, Train Loss: 1.5821, Val Loss: 1.7901, F1 Micro: 0.3229, F1 Macro: 0.2836, Accuracy: 0.3229\n","Epoch 17, Train Loss: 1.5644, Val Loss: 1.7335, F1 Micro: 0.3438, F1 Macro: 0.3019, Accuracy: 0.3438\n","Epoch 18, Train Loss: 1.5579, Val Loss: 1.8488, F1 Micro: 0.3229, F1 Macro: 0.2519, Accuracy: 0.3229\n","Epoch 19, Train Loss: 1.5475, Val Loss: 1.7572, F1 Micro: 0.3438, F1 Macro: 0.3001, Accuracy: 0.3438\n","Epoch 20, Train Loss: 1.5176, Val Loss: 1.8613, F1 Micro: 0.3125, F1 Macro: 0.2577, Accuracy: 0.3125\n","Epoch 21, Train Loss: 1.5288, Val Loss: 1.6753, F1 Micro: 0.3750, F1 Macro: 0.3347, Accuracy: 0.3750\n","Epoch 22, Train Loss: 1.5144, Val Loss: 1.7394, F1 Micro: 0.3438, F1 Macro: 0.2922, Accuracy: 0.3438\n","Epoch 23, Train Loss: 1.5123, Val Loss: 2.0023, F1 Micro: 0.2708, F1 Macro: 0.2066, Accuracy: 0.2708\n","Epoch 24, Train Loss: 1.4809, Val Loss: 1.9553, F1 Micro: 0.2917, F1 Macro: 0.2243, Accuracy: 0.2917\n","Epoch 25, Train Loss: 1.4907, Val Loss: 1.6916, F1 Micro: 0.3646, F1 Macro: 0.3433, Accuracy: 0.3646\n","Epoch 26, Train Loss: 1.4539, Val Loss: 2.1876, F1 Micro: 0.2604, F1 Macro: 0.1925, Accuracy: 0.2604\n","Epoch 27, Train Loss: 1.4576, Val Loss: 1.6897, F1 Micro: 0.3125, F1 Macro: 0.3003, Accuracy: 0.3125\n","Epoch 28, Train Loss: 1.4513, Val Loss: 1.6968, F1 Micro: 0.3646, F1 Macro: 0.2829, Accuracy: 0.3646\n","Epoch 29, Train Loss: 1.4392, Val Loss: 1.6885, F1 Micro: 0.3750, F1 Macro: 0.3348, Accuracy: 0.3750\n","Epoch 30, Train Loss: 1.4483, Val Loss: 1.6611, F1 Micro: 0.3438, F1 Macro: 0.3096, Accuracy: 0.3438\n","Epoch 31, Train Loss: 1.4192, Val Loss: 1.8775, F1 Micro: 0.3542, F1 Macro: 0.2751, Accuracy: 0.3542\n","Epoch 32, Train Loss: 1.4385, Val Loss: 1.7177, F1 Micro: 0.3542, F1 Macro: 0.3189, Accuracy: 0.3542\n","Epoch 33, Train Loss: 1.4034, Val Loss: 2.5300, F1 Micro: 0.2292, F1 Macro: 0.1623, Accuracy: 0.2292\n","Epoch 34, Train Loss: 1.4006, Val Loss: 1.7460, F1 Micro: 0.3229, F1 Macro: 0.2994, Accuracy: 0.3229\n","Epoch 35, Train Loss: 1.4062, Val Loss: 1.6592, F1 Micro: 0.3438, F1 Macro: 0.3384, Accuracy: 0.3438\n","Epoch 36, Train Loss: 1.3665, Val Loss: 1.6896, F1 Micro: 0.3958, F1 Macro: 0.3731, Accuracy: 0.3958\n","Epoch 37, Train Loss: 1.4093, Val Loss: 2.0824, F1 Micro: 0.3021, F1 Macro: 0.2554, Accuracy: 0.3021\n","Epoch 38, Train Loss: 1.3734, Val Loss: 1.8540, F1 Micro: 0.3125, F1 Macro: 0.2863, Accuracy: 0.3125\n","Epoch 39, Train Loss: 1.3332, Val Loss: 1.5969, F1 Micro: 0.3646, F1 Macro: 0.3483, Accuracy: 0.3646\n","Epoch 40, Train Loss: 1.3824, Val Loss: 2.2346, F1 Micro: 0.3021, F1 Macro: 0.2401, Accuracy: 0.3021\n","Epoch 41, Train Loss: 1.3862, Val Loss: 1.9576, F1 Micro: 0.2917, F1 Macro: 0.2433, Accuracy: 0.2917\n","Epoch 42, Train Loss: 1.3895, Val Loss: 1.6177, F1 Micro: 0.3854, F1 Macro: 0.3550, Accuracy: 0.3854\n","Epoch 43, Train Loss: 1.3689, Val Loss: 1.8966, F1 Micro: 0.4062, F1 Macro: 0.3324, Accuracy: 0.4062\n","Epoch 44, Train Loss: 1.3199, Val Loss: 1.6422, F1 Micro: 0.3438, F1 Macro: 0.3390, Accuracy: 0.3438\n","Epoch 45, Train Loss: 1.3343, Val Loss: 1.6281, F1 Micro: 0.4167, F1 Macro: 0.3892, Accuracy: 0.4167\n","Epoch 46, Train Loss: 1.3048, Val Loss: 1.5463, F1 Micro: 0.4062, F1 Macro: 0.3905, Accuracy: 0.4062\n","Epoch 47, Train Loss: 1.3124, Val Loss: 1.9996, F1 Micro: 0.3125, F1 Macro: 0.2862, Accuracy: 0.3125\n","Epoch 48, Train Loss: 1.2783, Val Loss: 1.6598, F1 Micro: 0.3854, F1 Macro: 0.3781, Accuracy: 0.3854\n","Epoch 49, Train Loss: 1.3160, Val Loss: 1.5941, F1 Micro: 0.4167, F1 Macro: 0.4038, Accuracy: 0.4167\n","Epoch 50, Train Loss: 1.3121, Val Loss: 1.6265, F1 Micro: 0.4167, F1 Macro: 0.3886, Accuracy: 0.4167\n","Epoch 51, Train Loss: 1.3031, Val Loss: 2.0918, F1 Micro: 0.2396, F1 Macro: 0.1619, Accuracy: 0.2396\n","Epoch 52, Train Loss: 1.2757, Val Loss: 1.7123, F1 Micro: 0.3750, F1 Macro: 0.3486, Accuracy: 0.3750\n","Epoch 53, Train Loss: 1.2679, Val Loss: 1.7057, F1 Micro: 0.3646, F1 Macro: 0.3557, Accuracy: 0.3646\n","Epoch 54, Train Loss: 1.2783, Val Loss: 1.7512, F1 Micro: 0.3229, F1 Macro: 0.2936, Accuracy: 0.3229\n","Epoch 55, Train Loss: 1.2603, Val Loss: 1.6918, F1 Micro: 0.3646, F1 Macro: 0.3576, Accuracy: 0.3646\n","Epoch 56, Train Loss: 1.2684, Val Loss: 2.0885, F1 Micro: 0.3438, F1 Macro: 0.3216, Accuracy: 0.3438\n","Epoch 57, Train Loss: 1.2835, Val Loss: 2.5516, F1 Micro: 0.2708, F1 Macro: 0.2277, Accuracy: 0.2708\n","Epoch 58, Train Loss: 1.2647, Val Loss: 1.6800, F1 Micro: 0.3542, F1 Macro: 0.3461, Accuracy: 0.3542\n","Epoch 59, Train Loss: 1.2493, Val Loss: 1.6163, F1 Micro: 0.4271, F1 Macro: 0.3889, Accuracy: 0.4271\n","Epoch 60, Train Loss: 1.2594, Val Loss: 1.6468, F1 Micro: 0.4167, F1 Macro: 0.3757, Accuracy: 0.4167\n","Epoch 61, Train Loss: 1.2626, Val Loss: 1.6142, F1 Micro: 0.4167, F1 Macro: 0.3866, Accuracy: 0.4167\n","Epoch 62, Train Loss: 1.2344, Val Loss: 1.8106, F1 Micro: 0.3854, F1 Macro: 0.3435, Accuracy: 0.3854\n","Epoch 63, Train Loss: 1.2282, Val Loss: 1.7627, F1 Micro: 0.3854, F1 Macro: 0.3617, Accuracy: 0.3854\n","Epoch 64, Train Loss: 1.2387, Val Loss: 1.7272, F1 Micro: 0.3646, F1 Macro: 0.3372, Accuracy: 0.3646\n","Epoch 65, Train Loss: 1.1980, Val Loss: 1.6304, F1 Micro: 0.4479, F1 Macro: 0.4364, Accuracy: 0.4479\n","Epoch 66, Train Loss: 1.2151, Val Loss: 1.7202, F1 Micro: 0.3958, F1 Macro: 0.3592, Accuracy: 0.3958\n","Epoch 67, Train Loss: 1.2250, Val Loss: 1.6526, F1 Micro: 0.4062, F1 Macro: 0.4011, Accuracy: 0.4062\n","Epoch 68, Train Loss: 1.1735, Val Loss: 1.6523, F1 Micro: 0.4167, F1 Macro: 0.3845, Accuracy: 0.4167\n","Epoch 69, Train Loss: 1.1765, Val Loss: 1.6766, F1 Micro: 0.4167, F1 Macro: 0.4090, Accuracy: 0.4167\n","Epoch 70, Train Loss: 1.1537, Val Loss: 2.1846, F1 Micro: 0.3021, F1 Macro: 0.2424, Accuracy: 0.3021\n","Epoch 71, Train Loss: 1.2257, Val Loss: 1.7294, F1 Micro: 0.4375, F1 Macro: 0.4240, Accuracy: 0.4375\n","Epoch 72, Train Loss: 1.1740, Val Loss: 1.6152, F1 Micro: 0.4167, F1 Macro: 0.3673, Accuracy: 0.4167\n","Epoch 73, Train Loss: 1.1730, Val Loss: 1.5591, F1 Micro: 0.4688, F1 Macro: 0.4306, Accuracy: 0.4688\n","Epoch 74, Train Loss: 1.1589, Val Loss: 1.5732, F1 Micro: 0.4583, F1 Macro: 0.4156, Accuracy: 0.4583\n","Epoch 75, Train Loss: 1.1666, Val Loss: 1.6519, F1 Micro: 0.4375, F1 Macro: 0.4394, Accuracy: 0.4375\n","Epoch 76, Train Loss: 1.1370, Val Loss: 1.8737, F1 Micro: 0.4271, F1 Macro: 0.4137, Accuracy: 0.4271\n","Epoch 77, Train Loss: 1.0765, Val Loss: 1.7661, F1 Micro: 0.3854, F1 Macro: 0.3686, Accuracy: 0.3854\n","Epoch 78, Train Loss: 1.1064, Val Loss: 1.6842, F1 Micro: 0.4375, F1 Macro: 0.4206, Accuracy: 0.4375\n","Epoch 79, Train Loss: 1.1090, Val Loss: 1.7155, F1 Micro: 0.3958, F1 Macro: 0.3682, Accuracy: 0.3958\n","Epoch 80, Train Loss: 1.0766, Val Loss: 1.7468, F1 Micro: 0.4271, F1 Macro: 0.4192, Accuracy: 0.4271\n","Epoch 81, Train Loss: 1.0965, Val Loss: 1.5712, F1 Micro: 0.4479, F1 Macro: 0.4427, Accuracy: 0.4479\n","Epoch 82, Train Loss: 1.0786, Val Loss: 1.5186, F1 Micro: 0.4479, F1 Macro: 0.4393, Accuracy: 0.4479\n","Epoch 83, Train Loss: 1.0874, Val Loss: 1.5821, F1 Micro: 0.4271, F1 Macro: 0.4279, Accuracy: 0.4271\n","Epoch 84, Train Loss: 1.0394, Val Loss: 1.8942, F1 Micro: 0.4062, F1 Macro: 0.4094, Accuracy: 0.4062\n","Epoch 85, Train Loss: 1.0397, Val Loss: 1.7343, F1 Micro: 0.4062, F1 Macro: 0.3984, Accuracy: 0.4062\n","Epoch 86, Train Loss: 1.0415, Val Loss: 1.8062, F1 Micro: 0.3854, F1 Macro: 0.3779, Accuracy: 0.3854\n","Epoch 87, Train Loss: 1.0347, Val Loss: 1.7078, F1 Micro: 0.4062, F1 Macro: 0.4032, Accuracy: 0.4062\n","Epoch 88, Train Loss: 1.0199, Val Loss: 2.0303, F1 Micro: 0.3438, F1 Macro: 0.3060, Accuracy: 0.3438\n","Epoch 89, Train Loss: 1.1022, Val Loss: 1.7899, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 90, Train Loss: 1.0697, Val Loss: 1.8374, F1 Micro: 0.3750, F1 Macro: 0.3389, Accuracy: 0.3750\n","Epoch 91, Train Loss: 1.0276, Val Loss: 1.6784, F1 Micro: 0.5104, F1 Macro: 0.4888, Accuracy: 0.5104\n","Epoch 92, Train Loss: 0.9962, Val Loss: 1.8278, F1 Micro: 0.4375, F1 Macro: 0.4216, Accuracy: 0.4375\n","Epoch 93, Train Loss: 0.9543, Val Loss: 2.0008, F1 Micro: 0.3646, F1 Macro: 0.3513, Accuracy: 0.3646\n","Epoch 94, Train Loss: 0.9722, Val Loss: 1.4656, F1 Micro: 0.5000, F1 Macro: 0.4840, Accuracy: 0.5000\n","Epoch 95, Train Loss: 0.9576, Val Loss: 1.7455, F1 Micro: 0.4062, F1 Macro: 0.4077, Accuracy: 0.4062\n","Epoch 96, Train Loss: 1.0127, Val Loss: 1.5636, F1 Micro: 0.5000, F1 Macro: 0.4944, Accuracy: 0.5000\n","Epoch 97, Train Loss: 0.9432, Val Loss: 1.5989, F1 Micro: 0.4688, F1 Macro: 0.4631, Accuracy: 0.4688\n","Epoch 98, Train Loss: 0.9268, Val Loss: 1.4773, F1 Micro: 0.5104, F1 Macro: 0.5004, Accuracy: 0.5104\n","Epoch 99, Train Loss: 0.9944, Val Loss: 1.8660, F1 Micro: 0.4479, F1 Macro: 0.4404, Accuracy: 0.4479\n","Epoch 100, Train Loss: 0.9930, Val Loss: 1.7237, F1 Micro: 0.3854, F1 Macro: 0.3768, Accuracy: 0.3854\n","Epoch 101, Train Loss: 0.9298, Val Loss: 1.5041, F1 Micro: 0.4792, F1 Macro: 0.4751, Accuracy: 0.4792\n","Epoch 102, Train Loss: 0.9362, Val Loss: 1.9047, F1 Micro: 0.3542, F1 Macro: 0.3430, Accuracy: 0.3542\n","Epoch 103, Train Loss: 0.9314, Val Loss: 2.0000, F1 Micro: 0.4271, F1 Macro: 0.3853, Accuracy: 0.4271\n","Epoch 104, Train Loss: 0.9494, Val Loss: 2.3360, F1 Micro: 0.4167, F1 Macro: 0.3937, Accuracy: 0.4167\n","Epoch 105, Train Loss: 0.9258, Val Loss: 1.7656, F1 Micro: 0.4479, F1 Macro: 0.4085, Accuracy: 0.4479\n","Epoch 106, Train Loss: 0.9667, Val Loss: 1.5844, F1 Micro: 0.4688, F1 Macro: 0.4794, Accuracy: 0.4688\n","Epoch 107, Train Loss: 0.8737, Val Loss: 2.0918, F1 Micro: 0.4167, F1 Macro: 0.3959, Accuracy: 0.4167\n","Epoch 108, Train Loss: 0.8496, Val Loss: 1.8287, F1 Micro: 0.4271, F1 Macro: 0.4159, Accuracy: 0.4271\n","Epoch 109, Train Loss: 0.8808, Val Loss: 1.8245, F1 Micro: 0.3958, F1 Macro: 0.3989, Accuracy: 0.3958\n","Epoch 110, Train Loss: 0.8810, Val Loss: 1.7556, F1 Micro: 0.4375, F1 Macro: 0.4100, Accuracy: 0.4375\n","Epoch 111, Train Loss: 0.9023, Val Loss: 1.6130, F1 Micro: 0.4688, F1 Macro: 0.4620, Accuracy: 0.4688\n","Epoch 112, Train Loss: 0.8833, Val Loss: 1.8056, F1 Micro: 0.4271, F1 Macro: 0.3840, Accuracy: 0.4271\n","Epoch 113, Train Loss: 0.8758, Val Loss: 2.2087, F1 Micro: 0.3854, F1 Macro: 0.3615, Accuracy: 0.3854\n","Epoch 114, Train Loss: 0.8419, Val Loss: 2.0717, F1 Micro: 0.4375, F1 Macro: 0.4410, Accuracy: 0.4375\n","Epoch 115, Train Loss: 0.8562, Val Loss: 1.4859, F1 Micro: 0.5625, F1 Macro: 0.5656, Accuracy: 0.5625\n","Epoch 116, Train Loss: 0.8067, Val Loss: 1.5429, F1 Micro: 0.5104, F1 Macro: 0.4897, Accuracy: 0.5104\n","Epoch 117, Train Loss: 0.8693, Val Loss: 2.3180, F1 Micro: 0.3229, F1 Macro: 0.2680, Accuracy: 0.3229\n","Epoch 118, Train Loss: 0.8928, Val Loss: 1.9558, F1 Micro: 0.4271, F1 Macro: 0.4318, Accuracy: 0.4271\n","Epoch 119, Train Loss: 0.8231, Val Loss: 1.8647, F1 Micro: 0.4479, F1 Macro: 0.4387, Accuracy: 0.4479\n","Epoch 120, Train Loss: 0.8171, Val Loss: 1.6332, F1 Micro: 0.4896, F1 Macro: 0.4921, Accuracy: 0.4896\n","Epoch 121, Train Loss: 0.8525, Val Loss: 1.6702, F1 Micro: 0.5208, F1 Macro: 0.5122, Accuracy: 0.5208\n","Epoch 122, Train Loss: 0.8151, Val Loss: 1.6988, F1 Micro: 0.4479, F1 Macro: 0.4452, Accuracy: 0.4479\n","Epoch 123, Train Loss: 0.7735, Val Loss: 1.7853, F1 Micro: 0.4688, F1 Macro: 0.4608, Accuracy: 0.4688\n","Epoch 124, Train Loss: 0.8051, Val Loss: 1.9857, F1 Micro: 0.4688, F1 Macro: 0.4532, Accuracy: 0.4688\n","Epoch 125, Train Loss: 0.7641, Val Loss: 1.7063, F1 Micro: 0.4896, F1 Macro: 0.4810, Accuracy: 0.4896\n","Epoch 126, Train Loss: 0.7595, Val Loss: 2.1277, F1 Micro: 0.3750, F1 Macro: 0.3637, Accuracy: 0.3750\n","Epoch 127, Train Loss: 0.7817, Val Loss: 1.7344, F1 Micro: 0.4479, F1 Macro: 0.4521, Accuracy: 0.4479\n","Epoch 128, Train Loss: 0.7883, Val Loss: 2.0247, F1 Micro: 0.4271, F1 Macro: 0.4211, Accuracy: 0.4271\n","Epoch 129, Train Loss: 0.8252, Val Loss: 1.8661, F1 Micro: 0.4062, F1 Macro: 0.3838, Accuracy: 0.4062\n","Epoch 130, Train Loss: 0.7682, Val Loss: 1.6450, F1 Micro: 0.5208, F1 Macro: 0.5136, Accuracy: 0.5208\n","Epoch 131, Train Loss: 0.7747, Val Loss: 1.9931, F1 Micro: 0.4688, F1 Macro: 0.4281, Accuracy: 0.4688\n","Epoch 132, Train Loss: 0.7662, Val Loss: 1.6422, F1 Micro: 0.4792, F1 Macro: 0.4326, Accuracy: 0.4792\n","Epoch 133, Train Loss: 0.7580, Val Loss: 1.8207, F1 Micro: 0.4583, F1 Macro: 0.4829, Accuracy: 0.4583\n","Epoch 134, Train Loss: 0.7348, Val Loss: 1.7949, F1 Micro: 0.4375, F1 Macro: 0.4417, Accuracy: 0.4375\n","Epoch 135, Train Loss: 0.6816, Val Loss: 1.9259, F1 Micro: 0.4688, F1 Macro: 0.4586, Accuracy: 0.4688\n","Epoch 136, Train Loss: 0.8036, Val Loss: 2.3268, F1 Micro: 0.3958, F1 Macro: 0.3741, Accuracy: 0.3958\n","Epoch 137, Train Loss: 0.7538, Val Loss: 1.7074, F1 Micro: 0.5312, F1 Macro: 0.5279, Accuracy: 0.5312\n","Epoch 138, Train Loss: 0.7315, Val Loss: 1.4376, F1 Micro: 0.5521, F1 Macro: 0.5508, Accuracy: 0.5521\n","Epoch 139, Train Loss: 0.7019, Val Loss: 2.7909, F1 Micro: 0.4062, F1 Macro: 0.3840, Accuracy: 0.4062\n","Epoch 140, Train Loss: 0.6369, Val Loss: 1.7728, F1 Micro: 0.4271, F1 Macro: 0.4096, Accuracy: 0.4271\n","Epoch 141, Train Loss: 0.6416, Val Loss: 1.5625, F1 Micro: 0.6146, F1 Macro: 0.6239, Accuracy: 0.6146\n","Epoch 142, Train Loss: 0.6894, Val Loss: 1.8589, F1 Micro: 0.5312, F1 Macro: 0.5200, Accuracy: 0.5312\n","Epoch 143, Train Loss: 0.7844, Val Loss: 2.6084, F1 Micro: 0.3854, F1 Macro: 0.3511, Accuracy: 0.3854\n","Epoch 144, Train Loss: 0.7070, Val Loss: 2.0847, F1 Micro: 0.5000, F1 Macro: 0.4992, Accuracy: 0.5000\n","Epoch 145, Train Loss: 0.6928, Val Loss: 1.5954, F1 Micro: 0.5208, F1 Macro: 0.5176, Accuracy: 0.5208\n","Epoch 146, Train Loss: 0.6454, Val Loss: 2.1348, F1 Micro: 0.4792, F1 Macro: 0.4712, Accuracy: 0.4792\n","Epoch 147, Train Loss: 0.5989, Val Loss: 1.6310, F1 Micro: 0.5417, F1 Macro: 0.5420, Accuracy: 0.5417\n","Epoch 148, Train Loss: 0.6701, Val Loss: 2.1464, F1 Micro: 0.4271, F1 Macro: 0.4063, Accuracy: 0.4271\n","Epoch 149, Train Loss: 0.6890, Val Loss: 1.8954, F1 Micro: 0.4479, F1 Macro: 0.4489, Accuracy: 0.4479\n","Epoch 150, Train Loss: 0.6201, Val Loss: 1.8685, F1 Micro: 0.4688, F1 Macro: 0.4717, Accuracy: 0.4688\n","Epoch 151, Train Loss: 0.6435, Val Loss: 2.2929, F1 Micro: 0.4583, F1 Macro: 0.4480, Accuracy: 0.4583\n","Epoch 152, Train Loss: 0.6620, Val Loss: 1.6743, F1 Micro: 0.5312, F1 Macro: 0.5119, Accuracy: 0.5312\n","Epoch 153, Train Loss: 0.6364, Val Loss: 1.9314, F1 Micro: 0.4792, F1 Macro: 0.4696, Accuracy: 0.4792\n","Epoch 154, Train Loss: 0.5964, Val Loss: 1.5570, F1 Micro: 0.4896, F1 Macro: 0.4724, Accuracy: 0.4896\n","Epoch 155, Train Loss: 0.5658, Val Loss: 1.8911, F1 Micro: 0.5312, F1 Macro: 0.5303, Accuracy: 0.5312\n","Epoch 156, Train Loss: 0.5912, Val Loss: 2.3329, F1 Micro: 0.3958, F1 Macro: 0.3758, Accuracy: 0.3958\n","Epoch 157, Train Loss: 0.6736, Val Loss: 1.7663, F1 Micro: 0.5000, F1 Macro: 0.4774, Accuracy: 0.5000\n","Epoch 158, Train Loss: 0.5709, Val Loss: 1.7434, F1 Micro: 0.5208, F1 Macro: 0.5106, Accuracy: 0.5208\n","Epoch 159, Train Loss: 0.5973, Val Loss: 1.8408, F1 Micro: 0.5000, F1 Macro: 0.4971, Accuracy: 0.5000\n","Epoch 160, Train Loss: 0.6022, Val Loss: 1.7967, F1 Micro: 0.5000, F1 Macro: 0.4902, Accuracy: 0.5000\n","Epoch 161, Train Loss: 0.6067, Val Loss: 1.8368, F1 Micro: 0.5000, F1 Macro: 0.5029, Accuracy: 0.5000\n","Epoch 162, Train Loss: 0.5934, Val Loss: 1.7118, F1 Micro: 0.5208, F1 Macro: 0.5311, Accuracy: 0.5208\n","Epoch 163, Train Loss: 0.5763, Val Loss: 2.1048, F1 Micro: 0.4792, F1 Macro: 0.4841, Accuracy: 0.4792\n","Epoch 164, Train Loss: 0.5635, Val Loss: 1.8613, F1 Micro: 0.4688, F1 Macro: 0.4624, Accuracy: 0.4688\n","Epoch 165, Train Loss: 0.6096, Val Loss: 1.8398, F1 Micro: 0.5104, F1 Macro: 0.5194, Accuracy: 0.5104\n","Epoch 166, Train Loss: 0.5713, Val Loss: 1.9196, F1 Micro: 0.5729, F1 Macro: 0.5676, Accuracy: 0.5729\n","Epoch 167, Train Loss: 0.5629, Val Loss: 1.7245, F1 Micro: 0.4896, F1 Macro: 0.4777, Accuracy: 0.4896\n","Epoch 168, Train Loss: 0.6333, Val Loss: 2.3258, F1 Micro: 0.4167, F1 Macro: 0.3699, Accuracy: 0.4167\n","Epoch 169, Train Loss: 0.6085, Val Loss: 1.9244, F1 Micro: 0.5000, F1 Macro: 0.5054, Accuracy: 0.5000\n","Epoch 170, Train Loss: 0.6022, Val Loss: 1.7202, F1 Micro: 0.5417, F1 Macro: 0.5482, Accuracy: 0.5417\n","Epoch 171, Train Loss: 0.6193, Val Loss: 2.0648, F1 Micro: 0.4896, F1 Macro: 0.4916, Accuracy: 0.4896\n","Epoch 172, Train Loss: 0.5006, Val Loss: 1.6721, F1 Micro: 0.5417, F1 Macro: 0.5306, Accuracy: 0.5417\n","Epoch 173, Train Loss: 0.4912, Val Loss: 1.6025, F1 Micro: 0.6042, F1 Macro: 0.6164, Accuracy: 0.6042\n","Epoch 174, Train Loss: 0.5247, Val Loss: 1.9111, F1 Micro: 0.5104, F1 Macro: 0.5108, Accuracy: 0.5104\n","Epoch 175, Train Loss: 0.5158, Val Loss: 1.7625, F1 Micro: 0.4896, F1 Macro: 0.4734, Accuracy: 0.4896\n","Epoch 176, Train Loss: 0.4847, Val Loss: 1.8409, F1 Micro: 0.5000, F1 Macro: 0.4855, Accuracy: 0.5000\n","Epoch 177, Train Loss: 0.5372, Val Loss: 2.4075, F1 Micro: 0.4271, F1 Macro: 0.3997, Accuracy: 0.4271\n","Epoch 178, Train Loss: 0.4610, Val Loss: 1.7034, F1 Micro: 0.5625, F1 Macro: 0.5497, Accuracy: 0.5625\n","Epoch 179, Train Loss: 0.5677, Val Loss: 2.3471, F1 Micro: 0.5521, F1 Macro: 0.5532, Accuracy: 0.5521\n","Epoch 180, Train Loss: 0.4836, Val Loss: 1.8181, F1 Micro: 0.5312, F1 Macro: 0.5212, Accuracy: 0.5312\n","Epoch 181, Train Loss: 0.5050, Val Loss: 1.7309, F1 Micro: 0.5729, F1 Macro: 0.5586, Accuracy: 0.5729\n","Epoch 182, Train Loss: 0.4914, Val Loss: 2.1927, F1 Micro: 0.4583, F1 Macro: 0.4382, Accuracy: 0.4583\n","Epoch 183, Train Loss: 0.5530, Val Loss: 2.0088, F1 Micro: 0.4688, F1 Macro: 0.4640, Accuracy: 0.4688\n","Epoch 184, Train Loss: 0.5794, Val Loss: 1.7553, F1 Micro: 0.5312, F1 Macro: 0.5387, Accuracy: 0.5312\n","Epoch 185, Train Loss: 0.4869, Val Loss: 1.7754, F1 Micro: 0.5417, F1 Macro: 0.5558, Accuracy: 0.5417\n","Epoch 186, Train Loss: 0.4623, Val Loss: 2.0156, F1 Micro: 0.4271, F1 Macro: 0.3854, Accuracy: 0.4271\n","Epoch 187, Train Loss: 0.4993, Val Loss: 1.9958, F1 Micro: 0.5312, F1 Macro: 0.5308, Accuracy: 0.5312\n","Epoch 188, Train Loss: 0.5071, Val Loss: 1.6171, F1 Micro: 0.5729, F1 Macro: 0.5719, Accuracy: 0.5729\n","Epoch 189, Train Loss: 0.4646, Val Loss: 2.1911, F1 Micro: 0.5312, F1 Macro: 0.5020, Accuracy: 0.5312\n","Epoch 190, Train Loss: 0.4513, Val Loss: 1.9237, F1 Micro: 0.5000, F1 Macro: 0.4828, Accuracy: 0.5000\n","Epoch 191, Train Loss: 0.5661, Val Loss: 2.1393, F1 Micro: 0.4896, F1 Macro: 0.4653, Accuracy: 0.4896\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.5645833333333333\n","Best hyperparameters for Outer FOLD 4: (0.001, 16, 50) with score 0.5645833333333333\n","Epoch 1, Train Loss: 1.8179, Val Loss: 1.7911, F1 Micro: 0.1667, F1 Macro: 0.0752, Accuracy: 0.1667\n","Epoch 2, Train Loss: 1.7825, Val Loss: 1.7993, F1 Micro: 0.1667, F1 Macro: 0.0752, Accuracy: 0.1667\n","Epoch 3, Train Loss: 1.7585, Val Loss: 1.7689, F1 Micro: 0.1750, F1 Macro: 0.0857, Accuracy: 0.1750\n","Epoch 4, Train Loss: 1.7605, Val Loss: 1.7478, F1 Micro: 0.2167, F1 Macro: 0.1079, Accuracy: 0.2167\n","Epoch 5, Train Loss: 1.7542, Val Loss: 1.7644, F1 Micro: 0.2167, F1 Macro: 0.1143, Accuracy: 0.2167\n","Epoch 6, Train Loss: 1.7528, Val Loss: 1.7714, F1 Micro: 0.1917, F1 Macro: 0.1255, Accuracy: 0.1917\n","Epoch 7, Train Loss: 1.7545, Val Loss: 1.7860, F1 Micro: 0.1750, F1 Macro: 0.0873, Accuracy: 0.1750\n","Epoch 8, Train Loss: 1.7471, Val Loss: 1.7598, F1 Micro: 0.2000, F1 Macro: 0.1221, Accuracy: 0.2000\n","Epoch 9, Train Loss: 1.7350, Val Loss: 1.7692, F1 Micro: 0.1833, F1 Macro: 0.1056, Accuracy: 0.1833\n","Epoch 10, Train Loss: 1.7414, Val Loss: 1.9740, F1 Micro: 0.2333, F1 Macro: 0.1227, Accuracy: 0.2333\n","Epoch 11, Train Loss: 1.7322, Val Loss: 1.7619, F1 Micro: 0.2167, F1 Macro: 0.1513, Accuracy: 0.2167\n","Epoch 12, Train Loss: 1.7094, Val Loss: 1.9808, F1 Micro: 0.2000, F1 Macro: 0.1247, Accuracy: 0.2000\n","Epoch 13, Train Loss: 1.7238, Val Loss: 1.7413, F1 Micro: 0.2750, F1 Macro: 0.2499, Accuracy: 0.2750\n","Epoch 14, Train Loss: 1.7084, Val Loss: 1.8014, F1 Micro: 0.2417, F1 Macro: 0.1793, Accuracy: 0.2417\n","Epoch 15, Train Loss: 1.7010, Val Loss: 1.9871, F1 Micro: 0.2000, F1 Macro: 0.1351, Accuracy: 0.2000\n","Epoch 16, Train Loss: 1.6901, Val Loss: 1.7527, F1 Micro: 0.2250, F1 Macro: 0.1555, Accuracy: 0.2250\n","Epoch 17, Train Loss: 1.6945, Val Loss: 1.7308, F1 Micro: 0.2667, F1 Macro: 0.2280, Accuracy: 0.2667\n","Epoch 18, Train Loss: 1.6839, Val Loss: 1.7486, F1 Micro: 0.1833, F1 Macro: 0.1149, Accuracy: 0.1833\n","Epoch 19, Train Loss: 1.6716, Val Loss: 1.7443, F1 Micro: 0.2667, F1 Macro: 0.2091, Accuracy: 0.2667\n","Epoch 20, Train Loss: 1.6633, Val Loss: 1.7429, F1 Micro: 0.2250, F1 Macro: 0.1706, Accuracy: 0.2250\n","Epoch 21, Train Loss: 1.6497, Val Loss: 1.7257, F1 Micro: 0.2667, F1 Macro: 0.2260, Accuracy: 0.2667\n","Epoch 22, Train Loss: 1.6693, Val Loss: 1.7792, F1 Micro: 0.2500, F1 Macro: 0.1902, Accuracy: 0.2500\n","Epoch 23, Train Loss: 1.6311, Val Loss: 1.6853, F1 Micro: 0.2667, F1 Macro: 0.2322, Accuracy: 0.2667\n","Epoch 24, Train Loss: 1.6186, Val Loss: 1.7247, F1 Micro: 0.2167, F1 Macro: 0.1654, Accuracy: 0.2167\n","Epoch 25, Train Loss: 1.6317, Val Loss: 1.6632, F1 Micro: 0.3167, F1 Macro: 0.3048, Accuracy: 0.3167\n","Epoch 26, Train Loss: 1.5586, Val Loss: 1.9007, F1 Micro: 0.2500, F1 Macro: 0.2162, Accuracy: 0.2500\n","Epoch 27, Train Loss: 1.5755, Val Loss: 1.6080, F1 Micro: 0.3917, F1 Macro: 0.3758, Accuracy: 0.3917\n","Epoch 28, Train Loss: 1.5338, Val Loss: 1.9228, F1 Micro: 0.2500, F1 Macro: 0.1728, Accuracy: 0.2500\n","Epoch 29, Train Loss: 1.5342, Val Loss: 1.7187, F1 Micro: 0.2833, F1 Macro: 0.2684, Accuracy: 0.2833\n","Epoch 30, Train Loss: 1.5182, Val Loss: 1.8168, F1 Micro: 0.2417, F1 Macro: 0.1596, Accuracy: 0.2417\n","Epoch 31, Train Loss: 1.4856, Val Loss: 1.6624, F1 Micro: 0.3333, F1 Macro: 0.3267, Accuracy: 0.3333\n","Epoch 32, Train Loss: 1.4619, Val Loss: 1.6054, F1 Micro: 0.3583, F1 Macro: 0.3013, Accuracy: 0.3583\n","Epoch 33, Train Loss: 1.4848, Val Loss: 1.7523, F1 Micro: 0.3083, F1 Macro: 0.2894, Accuracy: 0.3083\n","Epoch 34, Train Loss: 1.4615, Val Loss: 2.0445, F1 Micro: 0.2667, F1 Macro: 0.2185, Accuracy: 0.2667\n","Epoch 35, Train Loss: 1.4090, Val Loss: 1.6382, F1 Micro: 0.3500, F1 Macro: 0.2995, Accuracy: 0.3500\n","Epoch 36, Train Loss: 1.4440, Val Loss: 1.6611, F1 Micro: 0.4250, F1 Macro: 0.3767, Accuracy: 0.4250\n","Epoch 37, Train Loss: 1.4058, Val Loss: 2.6305, F1 Micro: 0.2333, F1 Macro: 0.1808, Accuracy: 0.2333\n","Epoch 38, Train Loss: 1.3960, Val Loss: 1.7478, F1 Micro: 0.3583, F1 Macro: 0.3270, Accuracy: 0.3583\n","Epoch 39, Train Loss: 1.4050, Val Loss: 1.6722, F1 Micro: 0.4250, F1 Macro: 0.4123, Accuracy: 0.4250\n","Epoch 40, Train Loss: 1.4309, Val Loss: 1.7298, F1 Micro: 0.3833, F1 Macro: 0.3001, Accuracy: 0.3833\n","Epoch 41, Train Loss: 1.3621, Val Loss: 1.8992, F1 Micro: 0.3167, F1 Macro: 0.2552, Accuracy: 0.3167\n","Epoch 42, Train Loss: 1.3672, Val Loss: 1.6691, F1 Micro: 0.3833, F1 Macro: 0.3458, Accuracy: 0.3833\n","Epoch 43, Train Loss: 1.3328, Val Loss: 1.5946, F1 Micro: 0.4417, F1 Macro: 0.4235, Accuracy: 0.4417\n","Epoch 44, Train Loss: 1.3112, Val Loss: 2.3527, F1 Micro: 0.2500, F1 Macro: 0.1987, Accuracy: 0.2500\n","Epoch 45, Train Loss: 1.3157, Val Loss: 1.6828, F1 Micro: 0.4167, F1 Macro: 0.3858, Accuracy: 0.4167\n","Epoch 46, Train Loss: 1.3092, Val Loss: 1.6506, F1 Micro: 0.4500, F1 Macro: 0.4206, Accuracy: 0.4500\n","Epoch 47, Train Loss: 1.3143, Val Loss: 1.7246, F1 Micro: 0.3417, F1 Macro: 0.3086, Accuracy: 0.3417\n","Epoch 48, Train Loss: 1.3026, Val Loss: 2.7025, F1 Micro: 0.2833, F1 Macro: 0.1982, Accuracy: 0.2833\n","Epoch 49, Train Loss: 1.2776, Val Loss: 1.6710, F1 Micro: 0.4417, F1 Macro: 0.4119, Accuracy: 0.4417\n","Epoch 50, Train Loss: 1.2385, Val Loss: 1.8517, F1 Micro: 0.3750, F1 Macro: 0.3519, Accuracy: 0.3750\n","Epoch 51, Train Loss: 1.2743, Val Loss: 1.6902, F1 Micro: 0.3917, F1 Macro: 0.3529, Accuracy: 0.3917\n","Epoch 52, Train Loss: 1.2720, Val Loss: 3.0070, F1 Micro: 0.2500, F1 Macro: 0.1916, Accuracy: 0.2500\n","Epoch 53, Train Loss: 1.2643, Val Loss: 2.1658, F1 Micro: 0.3333, F1 Macro: 0.2563, Accuracy: 0.3333\n","Epoch 54, Train Loss: 1.2187, Val Loss: 1.8121, F1 Micro: 0.3833, F1 Macro: 0.3339, Accuracy: 0.3833\n","Epoch 55, Train Loss: 1.2518, Val Loss: 2.0222, F1 Micro: 0.3250, F1 Macro: 0.3007, Accuracy: 0.3250\n","Epoch 56, Train Loss: 1.2163, Val Loss: 1.7898, F1 Micro: 0.4583, F1 Macro: 0.4481, Accuracy: 0.4583\n","Epoch 57, Train Loss: 1.2044, Val Loss: 1.8800, F1 Micro: 0.3833, F1 Macro: 0.3367, Accuracy: 0.3833\n","Epoch 58, Train Loss: 1.2260, Val Loss: 1.8534, F1 Micro: 0.4667, F1 Macro: 0.4452, Accuracy: 0.4667\n","Epoch 59, Train Loss: 1.2288, Val Loss: 3.4568, F1 Micro: 0.3583, F1 Macro: 0.3343, Accuracy: 0.3583\n","Epoch 60, Train Loss: 1.2025, Val Loss: 1.9595, F1 Micro: 0.4000, F1 Macro: 0.3057, Accuracy: 0.4000\n","Epoch 61, Train Loss: 1.2040, Val Loss: 1.7660, F1 Micro: 0.4750, F1 Macro: 0.4432, Accuracy: 0.4750\n","Epoch 62, Train Loss: 1.1625, Val Loss: 2.2194, F1 Micro: 0.4167, F1 Macro: 0.4029, Accuracy: 0.4167\n","Epoch 63, Train Loss: 1.1926, Val Loss: 2.1938, F1 Micro: 0.3500, F1 Macro: 0.3073, Accuracy: 0.3500\n","Epoch 64, Train Loss: 1.1818, Val Loss: 2.1082, F1 Micro: 0.4000, F1 Macro: 0.3656, Accuracy: 0.4000\n","Epoch 65, Train Loss: 1.1561, Val Loss: 1.8376, F1 Micro: 0.4000, F1 Macro: 0.3710, Accuracy: 0.4000\n","Epoch 66, Train Loss: 1.1460, Val Loss: 1.9993, F1 Micro: 0.4083, F1 Macro: 0.3764, Accuracy: 0.4083\n","Epoch 67, Train Loss: 1.1664, Val Loss: 1.9900, F1 Micro: 0.3833, F1 Macro: 0.3683, Accuracy: 0.3833\n","Epoch 68, Train Loss: 1.1342, Val Loss: 2.2038, F1 Micro: 0.3333, F1 Macro: 0.2947, Accuracy: 0.3333\n","Epoch 69, Train Loss: 1.0876, Val Loss: 2.0032, F1 Micro: 0.3917, F1 Macro: 0.3701, Accuracy: 0.3917\n","Epoch 70, Train Loss: 1.0907, Val Loss: 1.9866, F1 Micro: 0.3750, F1 Macro: 0.3534, Accuracy: 0.3750\n","Epoch 71, Train Loss: 1.1168, Val Loss: 1.8807, F1 Micro: 0.4333, F1 Macro: 0.4216, Accuracy: 0.4333\n","Epoch 72, Train Loss: 1.0773, Val Loss: 2.0969, F1 Micro: 0.3667, F1 Macro: 0.3588, Accuracy: 0.3667\n","Epoch 73, Train Loss: 1.0902, Val Loss: 2.3189, F1 Micro: 0.4250, F1 Macro: 0.3880, Accuracy: 0.4250\n","Epoch 74, Train Loss: 1.0868, Val Loss: 1.9508, F1 Micro: 0.4250, F1 Macro: 0.4017, Accuracy: 0.4250\n","Epoch 75, Train Loss: 1.0565, Val Loss: 2.0190, F1 Micro: 0.4250, F1 Macro: 0.3827, Accuracy: 0.4250\n","Epoch 76, Train Loss: 1.0821, Val Loss: 1.9233, F1 Micro: 0.5083, F1 Macro: 0.4838, Accuracy: 0.5083\n","Epoch 77, Train Loss: 1.0566, Val Loss: 1.8529, F1 Micro: 0.4917, F1 Macro: 0.4818, Accuracy: 0.4917\n","Epoch 78, Train Loss: 1.0650, Val Loss: 1.8130, F1 Micro: 0.4500, F1 Macro: 0.4309, Accuracy: 0.4500\n","Epoch 79, Train Loss: 1.0363, Val Loss: 1.8917, F1 Micro: 0.5000, F1 Macro: 0.4920, Accuracy: 0.5000\n","Epoch 80, Train Loss: 0.9848, Val Loss: 2.6250, F1 Micro: 0.4167, F1 Macro: 0.3753, Accuracy: 0.4167\n","Epoch 81, Train Loss: 1.0226, Val Loss: 2.5980, F1 Micro: 0.3833, F1 Macro: 0.3143, Accuracy: 0.3833\n","Epoch 82, Train Loss: 1.0337, Val Loss: 2.4066, F1 Micro: 0.3917, F1 Macro: 0.3710, Accuracy: 0.3917\n","Epoch 83, Train Loss: 1.0514, Val Loss: 2.4047, F1 Micro: 0.3333, F1 Macro: 0.3078, Accuracy: 0.3333\n","Epoch 84, Train Loss: 1.0018, Val Loss: 2.0574, F1 Micro: 0.4000, F1 Macro: 0.3820, Accuracy: 0.4000\n","Epoch 85, Train Loss: 0.9814, Val Loss: 2.2978, F1 Micro: 0.3583, F1 Macro: 0.3108, Accuracy: 0.3583\n","Epoch 86, Train Loss: 0.9758, Val Loss: 2.1470, F1 Micro: 0.4250, F1 Macro: 0.4083, Accuracy: 0.4250\n","Epoch 87, Train Loss: 1.0088, Val Loss: 2.1148, F1 Micro: 0.4333, F1 Macro: 0.4068, Accuracy: 0.4333\n","Epoch 88, Train Loss: 0.9887, Val Loss: 2.1501, F1 Micro: 0.4417, F1 Macro: 0.4286, Accuracy: 0.4417\n","Epoch 89, Train Loss: 0.9802, Val Loss: 2.2613, F1 Micro: 0.4583, F1 Macro: 0.4588, Accuracy: 0.4583\n","Epoch 90, Train Loss: 0.9897, Val Loss: 2.1704, F1 Micro: 0.4250, F1 Macro: 0.4045, Accuracy: 0.4250\n","Epoch 91, Train Loss: 0.9914, Val Loss: 2.1048, F1 Micro: 0.4167, F1 Macro: 0.4007, Accuracy: 0.4167\n","Epoch 92, Train Loss: 0.9805, Val Loss: 2.1711, F1 Micro: 0.4500, F1 Macro: 0.4315, Accuracy: 0.4500\n","Epoch 93, Train Loss: 0.9491, Val Loss: 2.1714, F1 Micro: 0.5250, F1 Macro: 0.5308, Accuracy: 0.5250\n","Epoch 94, Train Loss: 0.9383, Val Loss: 2.0990, F1 Micro: 0.4500, F1 Macro: 0.4262, Accuracy: 0.4500\n","Epoch 95, Train Loss: 0.9187, Val Loss: 2.2601, F1 Micro: 0.3917, F1 Macro: 0.3687, Accuracy: 0.3917\n","Epoch 96, Train Loss: 0.9131, Val Loss: 2.1679, F1 Micro: 0.4750, F1 Macro: 0.4573, Accuracy: 0.4750\n","Epoch 97, Train Loss: 0.9211, Val Loss: 3.2107, F1 Micro: 0.3333, F1 Macro: 0.2903, Accuracy: 0.3333\n","Epoch 98, Train Loss: 0.9309, Val Loss: 2.2286, F1 Micro: 0.4250, F1 Macro: 0.4173, Accuracy: 0.4250\n","Epoch 99, Train Loss: 0.9227, Val Loss: 2.2288, F1 Micro: 0.3917, F1 Macro: 0.3769, Accuracy: 0.3917\n","Epoch 100, Train Loss: 0.8960, Val Loss: 3.1683, F1 Micro: 0.2917, F1 Macro: 0.2623, Accuracy: 0.2917\n","Epoch 101, Train Loss: 0.9463, Val Loss: 2.0757, F1 Micro: 0.5167, F1 Macro: 0.5053, Accuracy: 0.5167\n","Epoch 102, Train Loss: 0.8806, Val Loss: 2.0766, F1 Micro: 0.4833, F1 Macro: 0.4779, Accuracy: 0.4833\n","Epoch 103, Train Loss: 0.8953, Val Loss: 2.2259, F1 Micro: 0.4833, F1 Macro: 0.4759, Accuracy: 0.4833\n","Epoch 104, Train Loss: 0.8638, Val Loss: 2.5419, F1 Micro: 0.4833, F1 Macro: 0.4699, Accuracy: 0.4833\n","Epoch 105, Train Loss: 0.9004, Val Loss: 2.1224, F1 Micro: 0.4833, F1 Macro: 0.4841, Accuracy: 0.4833\n","Epoch 106, Train Loss: 0.8438, Val Loss: 2.3733, F1 Micro: 0.4833, F1 Macro: 0.4409, Accuracy: 0.4833\n","Epoch 107, Train Loss: 0.8382, Val Loss: 2.4247, F1 Micro: 0.4667, F1 Macro: 0.4426, Accuracy: 0.4667\n","Epoch 108, Train Loss: 0.8279, Val Loss: 2.2753, F1 Micro: 0.4417, F1 Macro: 0.4318, Accuracy: 0.4417\n","Epoch 109, Train Loss: 0.8275, Val Loss: 2.6425, F1 Micro: 0.4167, F1 Macro: 0.3920, Accuracy: 0.4167\n","Epoch 110, Train Loss: 0.8013, Val Loss: 2.3863, F1 Micro: 0.4667, F1 Macro: 0.4615, Accuracy: 0.4667\n","Epoch 111, Train Loss: 0.7880, Val Loss: 2.4242, F1 Micro: 0.5000, F1 Macro: 0.4894, Accuracy: 0.5000\n","Epoch 112, Train Loss: 0.7854, Val Loss: 2.2172, F1 Micro: 0.4667, F1 Macro: 0.4385, Accuracy: 0.4667\n","Epoch 113, Train Loss: 0.7967, Val Loss: 2.4596, F1 Micro: 0.4833, F1 Macro: 0.4880, Accuracy: 0.4833\n","Epoch 114, Train Loss: 0.7810, Val Loss: 3.5120, F1 Micro: 0.3500, F1 Macro: 0.3193, Accuracy: 0.3500\n","Epoch 115, Train Loss: 0.8362, Val Loss: 2.2309, F1 Micro: 0.5167, F1 Macro: 0.5028, Accuracy: 0.5167\n","Epoch 116, Train Loss: 0.8484, Val Loss: 2.4231, F1 Micro: 0.4167, F1 Macro: 0.3775, Accuracy: 0.4167\n","Epoch 117, Train Loss: 0.7620, Val Loss: 2.6084, F1 Micro: 0.4083, F1 Macro: 0.3540, Accuracy: 0.4083\n","Epoch 118, Train Loss: 0.7747, Val Loss: 2.2759, F1 Micro: 0.5000, F1 Macro: 0.4928, Accuracy: 0.5000\n","Epoch 119, Train Loss: 0.7745, Val Loss: 2.4586, F1 Micro: 0.5000, F1 Macro: 0.4830, Accuracy: 0.5000\n","Epoch 120, Train Loss: 0.7275, Val Loss: 2.6204, F1 Micro: 0.4417, F1 Macro: 0.4115, Accuracy: 0.4417\n","Epoch 121, Train Loss: 0.7696, Val Loss: 2.4125, F1 Micro: 0.5000, F1 Macro: 0.4959, Accuracy: 0.5000\n","Epoch 122, Train Loss: 0.7393, Val Loss: 2.3867, F1 Micro: 0.5250, F1 Macro: 0.5186, Accuracy: 0.5250\n","Epoch 123, Train Loss: 0.7630, Val Loss: 2.3464, F1 Micro: 0.5333, F1 Macro: 0.5222, Accuracy: 0.5333\n","Epoch 124, Train Loss: 0.7286, Val Loss: 2.7227, F1 Micro: 0.4833, F1 Macro: 0.4861, Accuracy: 0.4833\n","Epoch 125, Train Loss: 0.8342, Val Loss: 2.7271, F1 Micro: 0.4500, F1 Macro: 0.4291, Accuracy: 0.4500\n","Epoch 126, Train Loss: 0.7627, Val Loss: 2.2649, F1 Micro: 0.5167, F1 Macro: 0.5050, Accuracy: 0.5167\n","Epoch 127, Train Loss: 0.7673, Val Loss: 2.6117, F1 Micro: 0.4333, F1 Macro: 0.4057, Accuracy: 0.4333\n","Epoch 128, Train Loss: 0.6965, Val Loss: 2.3710, F1 Micro: 0.4750, F1 Macro: 0.4585, Accuracy: 0.4750\n","Epoch 129, Train Loss: 0.6848, Val Loss: 2.2846, F1 Micro: 0.5417, F1 Macro: 0.5397, Accuracy: 0.5417\n","Epoch 130, Train Loss: 0.6553, Val Loss: 2.7486, F1 Micro: 0.4167, F1 Macro: 0.3811, Accuracy: 0.4167\n","Epoch 131, Train Loss: 0.6992, Val Loss: 2.7849, F1 Micro: 0.4917, F1 Macro: 0.4809, Accuracy: 0.4917\n","Epoch 132, Train Loss: 0.6881, Val Loss: 2.5942, F1 Micro: 0.4833, F1 Macro: 0.4615, Accuracy: 0.4833\n","Epoch 133, Train Loss: 0.6906, Val Loss: 3.2746, F1 Micro: 0.3833, F1 Macro: 0.3594, Accuracy: 0.3833\n","Epoch 134, Train Loss: 0.7836, Val Loss: 2.8946, F1 Micro: 0.4250, F1 Macro: 0.3901, Accuracy: 0.4250\n","Epoch 135, Train Loss: 0.7098, Val Loss: 2.3864, F1 Micro: 0.5583, F1 Macro: 0.5447, Accuracy: 0.5583\n","Epoch 136, Train Loss: 0.7024, Val Loss: 2.7578, F1 Micro: 0.4833, F1 Macro: 0.4856, Accuracy: 0.4833\n","Epoch 137, Train Loss: 0.6835, Val Loss: 2.4666, F1 Micro: 0.5500, F1 Macro: 0.5483, Accuracy: 0.5500\n","Epoch 138, Train Loss: 0.6686, Val Loss: 2.5322, F1 Micro: 0.5333, F1 Macro: 0.5205, Accuracy: 0.5333\n","Epoch 139, Train Loss: 0.6885, Val Loss: 2.6945, F1 Micro: 0.4667, F1 Macro: 0.4491, Accuracy: 0.4667\n","Epoch 140, Train Loss: 0.6901, Val Loss: 3.0857, F1 Micro: 0.4500, F1 Macro: 0.4308, Accuracy: 0.4500\n","Epoch 141, Train Loss: 0.6733, Val Loss: 3.5172, F1 Micro: 0.4750, F1 Macro: 0.4477, Accuracy: 0.4750\n","Epoch 142, Train Loss: 0.6650, Val Loss: 2.7301, F1 Micro: 0.5500, F1 Macro: 0.5330, Accuracy: 0.5500\n","Epoch 143, Train Loss: 0.6679, Val Loss: 2.7824, F1 Micro: 0.4750, F1 Macro: 0.4671, Accuracy: 0.4750\n","Epoch 144, Train Loss: 0.6344, Val Loss: 2.6676, F1 Micro: 0.5250, F1 Macro: 0.5097, Accuracy: 0.5250\n","Epoch 145, Train Loss: 0.6316, Val Loss: 2.9870, F1 Micro: 0.4667, F1 Macro: 0.4604, Accuracy: 0.4667\n","Epoch 146, Train Loss: 0.6047, Val Loss: 3.3952, F1 Micro: 0.4167, F1 Macro: 0.3798, Accuracy: 0.4167\n","Epoch 147, Train Loss: 0.6288, Val Loss: 2.9463, F1 Micro: 0.4833, F1 Macro: 0.4324, Accuracy: 0.4833\n","Epoch 148, Train Loss: 0.5970, Val Loss: 2.7268, F1 Micro: 0.5000, F1 Macro: 0.4870, Accuracy: 0.5000\n","Epoch 149, Train Loss: 0.5548, Val Loss: 3.0405, F1 Micro: 0.5250, F1 Macro: 0.5014, Accuracy: 0.5250\n","Epoch 150, Train Loss: 0.6424, Val Loss: 2.7981, F1 Micro: 0.5417, F1 Macro: 0.5239, Accuracy: 0.5417\n","Epoch 151, Train Loss: 0.6105, Val Loss: 3.6444, F1 Micro: 0.4500, F1 Macro: 0.4064, Accuracy: 0.4500\n","Epoch 152, Train Loss: 0.6255, Val Loss: 4.3855, F1 Micro: 0.3417, F1 Macro: 0.2927, Accuracy: 0.3417\n","Epoch 153, Train Loss: 0.6387, Val Loss: 2.8641, F1 Micro: 0.5583, F1 Macro: 0.5607, Accuracy: 0.5583\n","Epoch 154, Train Loss: 0.5965, Val Loss: 2.9821, F1 Micro: 0.4750, F1 Macro: 0.4751, Accuracy: 0.4750\n","Epoch 155, Train Loss: 0.5707, Val Loss: 2.8983, F1 Micro: 0.4583, F1 Macro: 0.4350, Accuracy: 0.4583\n","Epoch 156, Train Loss: 0.6067, Val Loss: 2.6904, F1 Micro: 0.5083, F1 Macro: 0.4855, Accuracy: 0.5083\n","Epoch 157, Train Loss: 0.5870, Val Loss: 3.0443, F1 Micro: 0.4750, F1 Macro: 0.4625, Accuracy: 0.4750\n","Epoch 158, Train Loss: 0.6440, Val Loss: 2.9543, F1 Micro: 0.4750, F1 Macro: 0.4774, Accuracy: 0.4750\n","Epoch 159, Train Loss: 0.6398, Val Loss: 3.2558, F1 Micro: 0.4833, F1 Macro: 0.4695, Accuracy: 0.4833\n","Epoch 160, Train Loss: 0.5422, Val Loss: 3.0399, F1 Micro: 0.5083, F1 Macro: 0.4669, Accuracy: 0.5083\n","Epoch 161, Train Loss: 0.5614, Val Loss: 3.0133, F1 Micro: 0.5167, F1 Macro: 0.4892, Accuracy: 0.5167\n","Epoch 162, Train Loss: 0.5819, Val Loss: 2.9324, F1 Micro: 0.5333, F1 Macro: 0.5311, Accuracy: 0.5333\n","Epoch 163, Train Loss: 0.5655, Val Loss: 3.3509, F1 Micro: 0.4917, F1 Macro: 0.4921, Accuracy: 0.4917\n","Epoch 164, Train Loss: 0.5781, Val Loss: 3.3498, F1 Micro: 0.4500, F1 Macro: 0.4109, Accuracy: 0.4500\n","Epoch 165, Train Loss: 0.5516, Val Loss: 3.7672, F1 Micro: 0.3917, F1 Macro: 0.3823, Accuracy: 0.3917\n","Epoch 166, Train Loss: 0.5961, Val Loss: 2.9198, F1 Micro: 0.5500, F1 Macro: 0.5424, Accuracy: 0.5500\n","Epoch 167, Train Loss: 0.5676, Val Loss: 2.9033, F1 Micro: 0.5583, F1 Macro: 0.5526, Accuracy: 0.5583\n","Epoch 168, Train Loss: 0.5709, Val Loss: 3.0142, F1 Micro: 0.5750, F1 Macro: 0.5734, Accuracy: 0.5750\n","Epoch 169, Train Loss: 0.5459, Val Loss: 3.5842, F1 Micro: 0.5167, F1 Macro: 0.5096, Accuracy: 0.5167\n","Epoch 170, Train Loss: 0.5628, Val Loss: 3.3999, F1 Micro: 0.4833, F1 Macro: 0.4731, Accuracy: 0.4833\n","Epoch 171, Train Loss: 0.5645, Val Loss: 3.0666, F1 Micro: 0.5000, F1 Macro: 0.4932, Accuracy: 0.5000\n","Epoch 172, Train Loss: 0.5575, Val Loss: 3.1026, F1 Micro: 0.4917, F1 Macro: 0.4868, Accuracy: 0.4917\n","Epoch 173, Train Loss: 0.5326, Val Loss: 3.0618, F1 Micro: 0.5417, F1 Macro: 0.5326, Accuracy: 0.5417\n","Epoch 174, Train Loss: 0.5250, Val Loss: 3.5610, F1 Micro: 0.4500, F1 Macro: 0.4254, Accuracy: 0.4500\n","Epoch 175, Train Loss: 0.5855, Val Loss: 3.3383, F1 Micro: 0.5000, F1 Macro: 0.4518, Accuracy: 0.5000\n","Epoch 176, Train Loss: 0.6418, Val Loss: 4.2932, F1 Micro: 0.4167, F1 Macro: 0.3797, Accuracy: 0.4167\n","Epoch 177, Train Loss: 0.6077, Val Loss: 3.2562, F1 Micro: 0.4417, F1 Macro: 0.3992, Accuracy: 0.4417\n","Epoch 178, Train Loss: 0.5518, Val Loss: 3.2831, F1 Micro: 0.4833, F1 Macro: 0.4530, Accuracy: 0.4833\n","Epoch 179, Train Loss: 0.5309, Val Loss: 2.9921, F1 Micro: 0.5750, F1 Macro: 0.5571, Accuracy: 0.5750\n","Epoch 180, Train Loss: 0.5745, Val Loss: 2.8108, F1 Micro: 0.5500, F1 Macro: 0.5438, Accuracy: 0.5500\n","Epoch 181, Train Loss: 0.4908, Val Loss: 3.2044, F1 Micro: 0.5667, F1 Macro: 0.5617, Accuracy: 0.5667\n","Epoch 182, Train Loss: 0.4828, Val Loss: 3.4856, F1 Micro: 0.5583, F1 Macro: 0.5511, Accuracy: 0.5583\n","Epoch 183, Train Loss: 0.5158, Val Loss: 3.6746, F1 Micro: 0.4833, F1 Macro: 0.4874, Accuracy: 0.4833\n","Epoch 184, Train Loss: 0.5388, Val Loss: 3.2634, F1 Micro: 0.5333, F1 Macro: 0.5299, Accuracy: 0.5333\n","Epoch 185, Train Loss: 0.5468, Val Loss: 3.2222, F1 Micro: 0.5083, F1 Macro: 0.5061, Accuracy: 0.5083\n","Epoch 186, Train Loss: 0.4866, Val Loss: 3.1174, F1 Micro: 0.5250, F1 Macro: 0.5212, Accuracy: 0.5250\n","Epoch 187, Train Loss: 0.4559, Val Loss: 3.1593, F1 Micro: 0.5500, F1 Macro: 0.5543, Accuracy: 0.5500\n","Epoch 188, Train Loss: 0.4649, Val Loss: 3.5082, F1 Micro: 0.5417, F1 Macro: 0.5281, Accuracy: 0.5417\n","Epoch 189, Train Loss: 0.4518, Val Loss: 3.1957, F1 Micro: 0.5250, F1 Macro: 0.4936, Accuracy: 0.5250\n","Epoch 190, Train Loss: 0.4980, Val Loss: 3.1582, F1 Micro: 0.5833, F1 Macro: 0.5757, Accuracy: 0.5833\n","Epoch 191, Train Loss: 0.5138, Val Loss: 3.4990, F1 Micro: 0.4833, F1 Macro: 0.4557, Accuracy: 0.4833\n","Epoch 192, Train Loss: 0.4459, Val Loss: 3.2471, F1 Micro: 0.5750, F1 Macro: 0.5479, Accuracy: 0.5750\n","Epoch 193, Train Loss: 0.5494, Val Loss: 3.2542, F1 Micro: 0.5167, F1 Macro: 0.5112, Accuracy: 0.5167\n","Epoch 194, Train Loss: 0.4813, Val Loss: 3.0906, F1 Micro: 0.5583, F1 Macro: 0.5554, Accuracy: 0.5583\n","Epoch 195, Train Loss: 0.4751, Val Loss: 2.9871, F1 Micro: 0.6000, F1 Macro: 0.5944, Accuracy: 0.6000\n","Epoch 196, Train Loss: 0.4590, Val Loss: 3.2117, F1 Micro: 0.5333, F1 Macro: 0.5301, Accuracy: 0.5333\n","Epoch 197, Train Loss: 0.4475, Val Loss: 3.3791, F1 Micro: 0.5250, F1 Macro: 0.4794, Accuracy: 0.5250\n","Epoch 198, Train Loss: 0.4573, Val Loss: 3.3576, F1 Micro: 0.5500, F1 Macro: 0.5251, Accuracy: 0.5500\n","Epoch 199, Train Loss: 0.4360, Val Loss: 3.2960, F1 Micro: 0.5667, F1 Macro: 0.5693, Accuracy: 0.5667\n","Epoch 200, Train Loss: 0.4394, Val Loss: 3.6311, F1 Micro: 0.5167, F1 Macro: 0.5209, Accuracy: 0.5167\n","Test set evaluation - F1 Micro: 0.5167, F1 Macro: 0.5209, Accuracy: 0.5167\n"]}]},{"cell_type":"code","source":["#models_evaluation_metrics['GINModel']['f1_micro_test_list2']=0\n","#models_evaluation_metrics['GINModel']['f1_macro_test_list2']=0\n","#models_evaluation_metrics['GINModel']['accuracy_test_list2']=0\n","\n","update_model_metrics('GINModel', f1_micro_test_list3, f1_macro_test_list3, accuracy_test_list3)\n","print(models_evaluation_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vY_vlFwOvYgv","executionInfo":{"status":"ok","timestamp":1711227248717,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"b8a67b26-6141-42c1-ae40-e392ca99316c"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.5416666666666666, 0.575, 0.575, 0.6083333333333333, 0.5583333333333333]], 'f1_macro': [[0.5216981751875497, 0.5734944050949523, 0.5641898378231431, 0.6101596293233924, 0.5597313275538554]], 'accuracy': [[0.5416666666666666, 0.575, 0.575, 0.6083333333333333, 0.5583333333333333]]}, 'GraphSAGEModel': {'f1_micro': [[0.5916666666666667, 0.6, 0.6333333333333333, 0.6583333333333333, 0.5083333333333333]], 'f1_macro': [[0.6040470090032383, 0.5977082905775605, 0.6285090585090586, 0.6539447051206633, 0.5127822164358357]], 'accuracy': [[0.5916666666666667, 0.6, 0.6333333333333333, 0.6583333333333333, 0.5083333333333333]]}, 'GINModel': {'f1_micro': [[0.5916666666666667, 0.4166666666666667, 0.5166666666666667, 0.55, 0.5166666666666667]], 'f1_macro': [[0.5938997746174508, 0.4003812470564388, 0.5118082202875694, 0.5469489826498971, 0.5208997141658859]], 'accuracy': [[0.5916666666666667, 0.4166666666666667, 0.5166666666666667, 0.55, 0.5166666666666667]]}}\n"]}]},{"cell_type":"code","source":["models_evaluation_metrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeaNdQ0WF5wX","executionInfo":{"status":"ok","timestamp":1711227260847,"user_tz":-60,"elapsed":365,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"28944747-bc12-40eb-cc31-ee138b95183a"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'BasicGraphModel': {'f1_micro': [[0.5416666666666666,\n","    0.575,\n","    0.575,\n","    0.6083333333333333,\n","    0.5583333333333333]],\n","  'f1_macro': [[0.5216981751875497,\n","    0.5734944050949523,\n","    0.5641898378231431,\n","    0.6101596293233924,\n","    0.5597313275538554]],\n","  'accuracy': [[0.5416666666666666,\n","    0.575,\n","    0.575,\n","    0.6083333333333333,\n","    0.5583333333333333]]},\n"," 'GraphSAGEModel': {'f1_micro': [[0.5916666666666667,\n","    0.6,\n","    0.6333333333333333,\n","    0.6583333333333333,\n","    0.5083333333333333]],\n","  'f1_macro': [[0.6040470090032383,\n","    0.5977082905775605,\n","    0.6285090585090586,\n","    0.6539447051206633,\n","    0.5127822164358357]],\n","  'accuracy': [[0.5916666666666667,\n","    0.6,\n","    0.6333333333333333,\n","    0.6583333333333333,\n","    0.5083333333333333]]},\n"," 'GINModel': {'f1_micro': [[0.5916666666666667,\n","    0.4166666666666667,\n","    0.5166666666666667,\n","    0.55,\n","    0.5166666666666667]],\n","  'f1_macro': [[0.5938997746174508,\n","    0.4003812470564388,\n","    0.5118082202875694,\n","    0.5469489826498971,\n","    0.5208997141658859]],\n","  'accuracy': [[0.5916666666666667,\n","    0.4166666666666667,\n","    0.5166666666666667,\n","    0.55,\n","    0.5166666666666667]]}}"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["import pandas as pd\n","data = {\n","    'BasicGraphModel': {'f1_micro': [[0.5416666666666666, 0.575, 0.575, 0.6083333333333333, 0.5583333333333333]],\n","    'f1_macro': [[0.5216981751875497, 0.5734944050949523, 0.5641898378231431, 0.6101596293233924, 0.5597313275538554]],\n","    'accuracy': [[0.5416666666666666, 0.575, 0.575, 0.6083333333333333, 0.5583333333333333]]},\n","    'GraphSAGEModel': {'f1_micro': [[0.5416666666666666, 0.5916666666666667, 0.55, 0.625, 0.625]],\n","    'f1_macro': [[0.5416629853341376, 0.5733081992486917, 0.5063247285356819, 0.6092964760197358, 0.6286759471141622]],\n","    'accuracy': [[0.5416666666666666, 0.5916666666666667, 0.55, 0.625, 0.625]]},\n","    'GINModel': {'f1_micro': [[0.5916666666666667, 0.4166666666666667, 0.5166666666666667, 0.55, 0.5166666666666667]],\n","    'f1_macro': [[0.5938997746174508, 0.4003812470564388, 0.5118082202875694, 0.5469489826498971, 0.5208997141658859]],\n","    'accuracy': [[0.5916666666666667, 0.4166666666666667, 0.5166666666666667, 0.55, 0.5166666666666667]]}\n","}\n","\n","# Convert the nested structure to a flat structure suitable for DataFrame\n","records = []\n","for model_name, metrics in data.items():\n","    for metric_name, metric_values in metrics.items():\n","        for values in metric_values:  # metric_values is a list of lists\n","            record = {\"Model\": model_name, \"Metric\": metric_name}\n","            # Assuming a fixed number of folds, e.g., 5\n","            for fold_index, value in enumerate(values, start=1):\n","                record[f\"Fold{fold_index}\"] = value\n","            records.append(record)\n","\n","# Create DataFrame\n","df = pd.DataFrame(records)\n","df['Mean'] = df.mean(axis=1)\n","\n","print(df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SuHxnLqOF8yY","executionInfo":{"status":"ok","timestamp":1711555689140,"user_tz":-60,"elapsed":355,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"3b381990-9052-4305-93c5-b2781da4d4cc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["             Model    Metric     Fold1     Fold2     Fold3     Fold4  \\\n","0  BasicGraphModel  f1_micro  0.541667  0.575000  0.575000  0.608333   \n","1  BasicGraphModel  f1_macro  0.521698  0.573494  0.564190  0.610160   \n","2  BasicGraphModel  accuracy  0.541667  0.575000  0.575000  0.608333   \n","3   GraphSAGEModel  f1_micro  0.541667  0.591667  0.550000  0.625000   \n","4   GraphSAGEModel  f1_macro  0.541663  0.573308  0.506325  0.609296   \n","5   GraphSAGEModel  accuracy  0.541667  0.591667  0.550000  0.625000   \n","6         GINModel  f1_micro  0.591667  0.416667  0.516667  0.550000   \n","7         GINModel  f1_macro  0.593900  0.400381  0.511808  0.546949   \n","8         GINModel  accuracy  0.591667  0.416667  0.516667  0.550000   \n","\n","      Fold5      Mean  \n","0  0.558333  0.571667  \n","1  0.559731  0.565855  \n","2  0.558333  0.571667  \n","3  0.625000  0.586667  \n","4  0.628676  0.571854  \n","5  0.625000  0.586667  \n","6  0.516667  0.518333  \n","7  0.520900  0.514788  \n","8  0.516667  0.518333  \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-8d1cc06b60a3>:27: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  df['Mean'] = df.mean(axis=1)\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"yH3a5NFAQXsf","executionInfo":{"status":"ok","timestamp":1711555693540,"user_tz":-60,"elapsed":3,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"b002c6cc-03f5-42ad-da2e-ca8a5701ce8d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             Model    Metric     Fold1     Fold2     Fold3     Fold4  \\\n","0  BasicGraphModel  f1_micro  0.541667  0.575000  0.575000  0.608333   \n","1  BasicGraphModel  f1_macro  0.521698  0.573494  0.564190  0.610160   \n","2  BasicGraphModel  accuracy  0.541667  0.575000  0.575000  0.608333   \n","3   GraphSAGEModel  f1_micro  0.541667  0.591667  0.550000  0.625000   \n","4   GraphSAGEModel  f1_macro  0.541663  0.573308  0.506325  0.609296   \n","5   GraphSAGEModel  accuracy  0.541667  0.591667  0.550000  0.625000   \n","6         GINModel  f1_micro  0.591667  0.416667  0.516667  0.550000   \n","7         GINModel  f1_macro  0.593900  0.400381  0.511808  0.546949   \n","8         GINModel  accuracy  0.591667  0.416667  0.516667  0.550000   \n","\n","      Fold5      Mean  \n","0  0.558333  0.571667  \n","1  0.559731  0.565855  \n","2  0.558333  0.571667  \n","3  0.625000  0.586667  \n","4  0.628676  0.571854  \n","5  0.625000  0.586667  \n","6  0.516667  0.518333  \n","7  0.520900  0.514788  \n","8  0.516667  0.518333  "],"text/html":["\n","  <div id=\"df-18b8ebf3-1cb1-4142-bcff-d82a55aec6c5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Metric</th>\n","      <th>Fold1</th>\n","      <th>Fold2</th>\n","      <th>Fold3</th>\n","      <th>Fold4</th>\n","      <th>Fold5</th>\n","      <th>Mean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BasicGraphModel</td>\n","      <td>f1_micro</td>\n","      <td>0.541667</td>\n","      <td>0.575000</td>\n","      <td>0.575000</td>\n","      <td>0.608333</td>\n","      <td>0.558333</td>\n","      <td>0.571667</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BasicGraphModel</td>\n","      <td>f1_macro</td>\n","      <td>0.521698</td>\n","      <td>0.573494</td>\n","      <td>0.564190</td>\n","      <td>0.610160</td>\n","      <td>0.559731</td>\n","      <td>0.565855</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BasicGraphModel</td>\n","      <td>accuracy</td>\n","      <td>0.541667</td>\n","      <td>0.575000</td>\n","      <td>0.575000</td>\n","      <td>0.608333</td>\n","      <td>0.558333</td>\n","      <td>0.571667</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GraphSAGEModel</td>\n","      <td>f1_micro</td>\n","      <td>0.541667</td>\n","      <td>0.591667</td>\n","      <td>0.550000</td>\n","      <td>0.625000</td>\n","      <td>0.625000</td>\n","      <td>0.586667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GraphSAGEModel</td>\n","      <td>f1_macro</td>\n","      <td>0.541663</td>\n","      <td>0.573308</td>\n","      <td>0.506325</td>\n","      <td>0.609296</td>\n","      <td>0.628676</td>\n","      <td>0.571854</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>GraphSAGEModel</td>\n","      <td>accuracy</td>\n","      <td>0.541667</td>\n","      <td>0.591667</td>\n","      <td>0.550000</td>\n","      <td>0.625000</td>\n","      <td>0.625000</td>\n","      <td>0.586667</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>GINModel</td>\n","      <td>f1_micro</td>\n","      <td>0.591667</td>\n","      <td>0.416667</td>\n","      <td>0.516667</td>\n","      <td>0.550000</td>\n","      <td>0.516667</td>\n","      <td>0.518333</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>GINModel</td>\n","      <td>f1_macro</td>\n","      <td>0.593900</td>\n","      <td>0.400381</td>\n","      <td>0.511808</td>\n","      <td>0.546949</td>\n","      <td>0.520900</td>\n","      <td>0.514788</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>GINModel</td>\n","      <td>accuracy</td>\n","      <td>0.591667</td>\n","      <td>0.416667</td>\n","      <td>0.516667</td>\n","      <td>0.550000</td>\n","      <td>0.516667</td>\n","      <td>0.518333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b8ebf3-1cb1-4142-bcff-d82a55aec6c5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-18b8ebf3-1cb1-4142-bcff-d82a55aec6c5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-18b8ebf3-1cb1-4142-bcff-d82a55aec6c5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-de19eb41-9d42-4726-ada2-7774b8778652\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de19eb41-9d42-4726-ada2-7774b8778652')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-de19eb41-9d42-4726-ada2-7774b8778652 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BasicGraphModel\",\n          \"GraphSAGEModel\",\n          \"GINModel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"f1_micro\",\n          \"f1_macro\",\n          \"accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027801476060293987,\n        \"min\": 0.5216981751875497,\n        \"max\": 0.5938997746174508,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5216981751875497,\n          0.5938997746174508,\n          0.5416629853341376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0848252039556916,\n        \"min\": 0.4003812470564388,\n        \"max\": 0.5916666666666667,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.575,\n          0.5734944050949523,\n          0.4003812470564388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02794924610290949,\n        \"min\": 0.5063247285356819,\n        \"max\": 0.575,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.575,\n          0.5641898378231431,\n          0.5118082202875694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.033345224287820524,\n        \"min\": 0.5469489826498971,\n        \"max\": 0.625,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6083333333333333,\n          0.6101596293233924,\n          0.5469489826498971\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04733218213708016,\n        \"min\": 0.5166666666666667,\n        \"max\": 0.6286759471141622,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5583333333333333,\n          0.5597313275538554,\n          0.5208997141658859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03011618717658713,\n        \"min\": 0.5147875877554484,\n        \"max\": 0.5866666666666667,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5716666666666667,\n          0.5658546749965786,\n          0.5147875877554484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Do the same thing to the dataset REDDIT-BINARY\n","\n"],"metadata":{"id":"uFZAzmj7Ti4-"}},{"cell_type":"code","source":["# The dataset Reddit-Binary has no node_features, so we use node_degree as its feature\n","import torch\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.transforms import BaseTransform\n","from torch_geometric.utils import degree\n","\n","class AddDegreeFeature(BaseTransform):\n","    def __call__(self, data):\n","        deg = degree(data.edge_index[0], dtype=torch.float)\n","        data.x = deg.unsqueeze(-1)  # Make it a 2D tensor [num_nodes, 1]\n","        return data\n","\n","# Load your dataset and apply the transformation\n","dataset_rd = TUDataset(root='/tmp/REDDIT-BINARY', name='REDDIT-BINARY', transform=AddDegreeFeature())\n","\n","# Now verify by printing the features of the first few graphs\n","for i, data in enumerate(dataset_rd):\n","    if i >= 5:  # Check the first 5 graphs\n","        break\n","    print(data.x)\n"],"metadata":{"id":"Ctjmv3c2YhBv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Basic model for reddit"],"metadata":{"id":"T9K9USzWtqTz"}},{"cell_type":"code","source":["from torch.utils.data import Subset\n","\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_rd)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_subset = Subset(dataset_rd, train_val_idx)\n","    test_subset = Subset(dataset_rd, test_idx)\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_subset = Subset(train_val_subset, inner_train_idx)\n","            inner_val_subset = Subset(train_val_subset, inner_val_idx)\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_subset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_subset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = BasicGraphModel(\n","                input_size=1,\n","                hidden_size=256,\n","                output_size=dataset_rd.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_subset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_subset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = BasicGraphModel(\n","        input_size=1,\n","        hidden_size=256,\n","        output_size=dataset_rd.num_classes,\n","        dropout_rate=0.5  # You could also tune the dropout rate if you wanted\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'rd_Basic_model_fold_{fold}.pth')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bT7YpY-7KvoV","outputId":"a1460c96-ad63-4fb7-f2e8-ef4960274979"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 154, Train Loss: 0.5199, Val Loss: 0.4386, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 155, Train Loss: 0.4836, Val Loss: 0.4516, F1 Micro: 0.8156, F1 Macro: 0.8143, Accuracy: 0.8156\n","Epoch 156, Train Loss: 0.4814, Val Loss: 0.3971, F1 Micro: 0.7906, F1 Macro: 0.7864, Accuracy: 0.7906\n","Epoch 157, Train Loss: 0.4927, Val Loss: 0.4502, F1 Micro: 0.7500, F1 Macro: 0.7333, Accuracy: 0.7500\n","Epoch 158, Train Loss: 0.5153, Val Loss: 0.4213, F1 Micro: 0.7625, F1 Macro: 0.7475, Accuracy: 0.7625\n","Epoch 159, Train Loss: 0.5047, Val Loss: 0.4833, F1 Micro: 0.7312, F1 Macro: 0.7047, Accuracy: 0.7312\n","Epoch 160, Train Loss: 0.5170, Val Loss: 0.5018, F1 Micro: 0.7531, F1 Macro: 0.7362, Accuracy: 0.7531\n","Epoch 161, Train Loss: 0.4849, Val Loss: 0.4317, F1 Micro: 0.7781, F1 Macro: 0.7728, Accuracy: 0.7781\n","Epoch 162, Train Loss: 0.4976, Val Loss: 0.6837, F1 Micro: 0.5062, F1 Macro: 0.3974, Accuracy: 0.5062\n","Epoch 163, Train Loss: 0.4808, Val Loss: 0.4630, F1 Micro: 0.8406, F1 Macro: 0.8406, Accuracy: 0.8406\n","Epoch 164, Train Loss: 0.4824, Val Loss: 0.4370, F1 Micro: 0.8438, F1 Macro: 0.8437, Accuracy: 0.8438\n","Epoch 165, Train Loss: 0.4894, Val Loss: 0.5315, F1 Micro: 0.7656, F1 Macro: 0.7595, Accuracy: 0.7656\n","Epoch 166, Train Loss: 0.4839, Val Loss: 0.4282, F1 Micro: 0.7875, F1 Macro: 0.7848, Accuracy: 0.7875\n","Epoch 167, Train Loss: 0.4887, Val Loss: 0.4324, F1 Micro: 0.8500, F1 Macro: 0.8499, Accuracy: 0.8500\n","Epoch 168, Train Loss: 0.4815, Val Loss: 0.4213, F1 Micro: 0.8000, F1 Macro: 0.7995, Accuracy: 0.8000\n","Epoch 169, Train Loss: 0.4787, Val Loss: 0.4366, F1 Micro: 0.7594, F1 Macro: 0.7557, Accuracy: 0.7594\n","Epoch 170, Train Loss: 0.4937, Val Loss: 0.6361, F1 Micro: 0.6188, F1 Macro: 0.5844, Accuracy: 0.6188\n","Epoch 171, Train Loss: 0.4950, Val Loss: 0.7901, F1 Micro: 0.5719, F1 Macro: 0.5394, Accuracy: 0.5719\n","Epoch 172, Train Loss: 0.4990, Val Loss: 0.4308, F1 Micro: 0.8000, F1 Macro: 0.7980, Accuracy: 0.8000\n","Epoch 173, Train Loss: 0.4884, Val Loss: 0.4115, F1 Micro: 0.8125, F1 Macro: 0.8106, Accuracy: 0.8125\n","Epoch 174, Train Loss: 0.4675, Val Loss: 0.6474, F1 Micro: 0.5781, F1 Macro: 0.5228, Accuracy: 0.5781\n","Epoch 175, Train Loss: 0.5062, Val Loss: 0.4285, F1 Micro: 0.8031, F1 Macro: 0.8015, Accuracy: 0.8031\n","Epoch 176, Train Loss: 0.5377, Val Loss: 0.4957, F1 Micro: 0.7656, F1 Macro: 0.7651, Accuracy: 0.7656\n","Epoch 177, Train Loss: 0.5058, Val Loss: 0.4593, F1 Micro: 0.7562, F1 Macro: 0.7373, Accuracy: 0.7562\n","Epoch 178, Train Loss: 0.5106, Val Loss: 0.5683, F1 Micro: 0.6750, F1 Macro: 0.6566, Accuracy: 0.6750\n","Epoch 179, Train Loss: 0.5622, Val Loss: 0.5255, F1 Micro: 0.7156, F1 Macro: 0.6906, Accuracy: 0.7156\n","Epoch 180, Train Loss: 0.5055, Val Loss: 0.5838, F1 Micro: 0.7406, F1 Macro: 0.7349, Accuracy: 0.7406\n","Epoch 181, Train Loss: 0.4769, Val Loss: 0.8675, F1 Micro: 0.5281, F1 Macro: 0.4399, Accuracy: 0.5281\n","Epoch 182, Train Loss: 0.4875, Val Loss: 0.4792, F1 Micro: 0.7594, F1 Macro: 0.7438, Accuracy: 0.7594\n","Epoch 183, Train Loss: 0.4942, Val Loss: 0.4525, F1 Micro: 0.7625, F1 Macro: 0.7622, Accuracy: 0.7625\n","Epoch 184, Train Loss: 0.4960, Val Loss: 0.9011, F1 Micro: 0.5406, F1 Macro: 0.4725, Accuracy: 0.5406\n","Epoch 185, Train Loss: 0.5594, Val Loss: 0.6989, F1 Micro: 0.5844, F1 Macro: 0.5298, Accuracy: 0.5844\n","Epoch 186, Train Loss: 0.5015, Val Loss: 0.4352, F1 Micro: 0.7656, F1 Macro: 0.7574, Accuracy: 0.7656\n","Epoch 187, Train Loss: 0.4893, Val Loss: 0.4400, F1 Micro: 0.7594, F1 Macro: 0.7503, Accuracy: 0.7594\n","Epoch 188, Train Loss: 0.4773, Val Loss: 0.6208, F1 Micro: 0.6125, F1 Macro: 0.5759, Accuracy: 0.6125\n","Epoch 189, Train Loss: 0.5394, Val Loss: 0.6767, F1 Micro: 0.5625, F1 Macro: 0.5014, Accuracy: 0.5625\n","Epoch 190, Train Loss: 0.4858, Val Loss: 0.5175, F1 Micro: 0.7750, F1 Macro: 0.7714, Accuracy: 0.7750\n","Epoch 191, Train Loss: 0.4884, Val Loss: 0.4494, F1 Micro: 0.7719, F1 Macro: 0.7644, Accuracy: 0.7719\n","Epoch 192, Train Loss: 0.4987, Val Loss: 0.4067, F1 Micro: 0.7937, F1 Macro: 0.7894, Accuracy: 0.7937\n","Epoch 193, Train Loss: 0.4753, Val Loss: 0.4297, F1 Micro: 0.8156, F1 Macro: 0.8155, Accuracy: 0.8156\n","Epoch 194, Train Loss: 0.4707, Val Loss: 0.4494, F1 Micro: 0.7906, F1 Macro: 0.7906, Accuracy: 0.7906\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7700, Val Loss: 0.5450, F1 Micro: 0.7156, F1 Macro: 0.7129, Accuracy: 0.7156\n","Epoch 2, Train Loss: 0.5931, Val Loss: 0.5651, F1 Micro: 0.7000, F1 Macro: 0.6800, Accuracy: 0.7000\n","Epoch 3, Train Loss: 0.5830, Val Loss: 0.5588, F1 Micro: 0.7000, F1 Macro: 0.6821, Accuracy: 0.7000\n","Epoch 4, Train Loss: 0.5831, Val Loss: 0.5998, F1 Micro: 0.6969, F1 Macro: 0.6964, Accuracy: 0.6969\n","Epoch 5, Train Loss: 0.5745, Val Loss: 0.5476, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 6, Train Loss: 0.5802, Val Loss: 0.5634, F1 Micro: 0.7063, F1 Macro: 0.6897, Accuracy: 0.7063\n","Epoch 7, Train Loss: 0.5985, Val Loss: 0.5771, F1 Micro: 0.6937, F1 Macro: 0.6662, Accuracy: 0.6937\n","Epoch 8, Train Loss: 0.5975, Val Loss: 0.5405, F1 Micro: 0.7250, F1 Macro: 0.7187, Accuracy: 0.7250\n","Epoch 9, Train Loss: 0.5805, Val Loss: 0.5669, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 10, Train Loss: 0.5779, Val Loss: 0.5888, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 11, Train Loss: 0.5943, Val Loss: 0.5417, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 12, Train Loss: 0.5584, Val Loss: 0.5439, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 13, Train Loss: 0.6107, Val Loss: 0.5532, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 14, Train Loss: 0.5983, Val Loss: 0.5730, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 15, Train Loss: 0.5872, Val Loss: 0.5437, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 16, Train Loss: 0.5723, Val Loss: 0.5665, F1 Micro: 0.7219, F1 Macro: 0.7128, Accuracy: 0.7219\n","Epoch 17, Train Loss: 0.5757, Val Loss: 0.6281, F1 Micro: 0.6438, F1 Macro: 0.5759, Accuracy: 0.6438\n","Epoch 18, Train Loss: 0.5864, Val Loss: 0.5396, F1 Micro: 0.7031, F1 Macro: 0.6995, Accuracy: 0.7031\n","Epoch 19, Train Loss: 0.5695, Val Loss: 0.5620, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 20, Train Loss: 0.6102, Val Loss: 0.6010, F1 Micro: 0.6875, F1 Macro: 0.6522, Accuracy: 0.6875\n","Epoch 21, Train Loss: 0.6048, Val Loss: 0.5443, F1 Micro: 0.7188, F1 Macro: 0.7063, Accuracy: 0.7188\n","Epoch 22, Train Loss: 0.5970, Val Loss: 0.5456, F1 Micro: 0.7156, F1 Macro: 0.7026, Accuracy: 0.7156\n","Epoch 23, Train Loss: 0.7164, Val Loss: 0.5680, F1 Micro: 0.6906, F1 Macro: 0.6647, Accuracy: 0.6906\n","Epoch 24, Train Loss: 0.6209, Val Loss: 0.5657, F1 Micro: 0.7031, F1 Macro: 0.6806, Accuracy: 0.7031\n","Epoch 25, Train Loss: 0.5917, Val Loss: 0.6128, F1 Micro: 0.6875, F1 Macro: 0.6820, Accuracy: 0.6875\n","Epoch 26, Train Loss: 0.5990, Val Loss: 0.5745, F1 Micro: 0.7063, F1 Macro: 0.6856, Accuracy: 0.7063\n","Epoch 27, Train Loss: 0.5779, Val Loss: 0.5396, F1 Micro: 0.7031, F1 Macro: 0.6991, Accuracy: 0.7031\n","Epoch 28, Train Loss: 0.5668, Val Loss: 0.5304, F1 Micro: 0.7219, F1 Macro: 0.7189, Accuracy: 0.7219\n","Epoch 29, Train Loss: 0.5849, Val Loss: 0.5372, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 30, Train Loss: 0.5507, Val Loss: 0.5119, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 31, Train Loss: 0.5626, Val Loss: 0.5386, F1 Micro: 0.7250, F1 Macro: 0.7187, Accuracy: 0.7250\n","Epoch 32, Train Loss: 0.5718, Val Loss: 0.5209, F1 Micro: 0.7469, F1 Macro: 0.7456, Accuracy: 0.7469\n","Epoch 33, Train Loss: 0.5547, Val Loss: 0.5007, F1 Micro: 0.7219, F1 Macro: 0.7163, Accuracy: 0.7219\n","Epoch 34, Train Loss: 0.5811, Val Loss: 0.5173, F1 Micro: 0.7344, F1 Macro: 0.7344, Accuracy: 0.7344\n","Epoch 35, Train Loss: 0.5774, Val Loss: 0.5719, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 36, Train Loss: 0.5954, Val Loss: 0.5312, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 37, Train Loss: 0.5593, Val Loss: 0.5591, F1 Micro: 0.7125, F1 Macro: 0.6943, Accuracy: 0.7125\n","Epoch 38, Train Loss: 0.5470, Val Loss: 0.5121, F1 Micro: 0.7531, F1 Macro: 0.7524, Accuracy: 0.7531\n","Epoch 39, Train Loss: 0.5471, Val Loss: 0.5452, F1 Micro: 0.7000, F1 Macro: 0.6778, Accuracy: 0.7000\n","Epoch 40, Train Loss: 0.5520, Val Loss: 0.5039, F1 Micro: 0.7656, F1 Macro: 0.7655, Accuracy: 0.7656\n","Epoch 41, Train Loss: 0.5403, Val Loss: 0.5722, F1 Micro: 0.7125, F1 Macro: 0.7041, Accuracy: 0.7125\n","Epoch 42, Train Loss: 0.5527, Val Loss: 0.5101, F1 Micro: 0.7344, F1 Macro: 0.7344, Accuracy: 0.7344\n","Epoch 43, Train Loss: 0.5329, Val Loss: 0.4784, F1 Micro: 0.7781, F1 Macro: 0.7779, Accuracy: 0.7781\n","Epoch 44, Train Loss: 0.5354, Val Loss: 0.5084, F1 Micro: 0.7406, F1 Macro: 0.7349, Accuracy: 0.7406\n","Epoch 45, Train Loss: 0.5348, Val Loss: 0.4863, F1 Micro: 0.7906, F1 Macro: 0.7904, Accuracy: 0.7906\n","Epoch 46, Train Loss: 0.5426, Val Loss: 0.5513, F1 Micro: 0.7000, F1 Macro: 0.6966, Accuracy: 0.7000\n","Epoch 47, Train Loss: 0.5313, Val Loss: 0.4848, F1 Micro: 0.7594, F1 Macro: 0.7579, Accuracy: 0.7594\n","Epoch 48, Train Loss: 0.5317, Val Loss: 0.4913, F1 Micro: 0.7469, F1 Macro: 0.7462, Accuracy: 0.7469\n","Epoch 49, Train Loss: 0.5371, Val Loss: 0.5431, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 50, Train Loss: 0.5588, Val Loss: 0.4920, F1 Micro: 0.7688, F1 Macro: 0.7674, Accuracy: 0.7688\n","Epoch 51, Train Loss: 0.5553, Val Loss: 0.5005, F1 Micro: 0.7375, F1 Macro: 0.7365, Accuracy: 0.7375\n","Epoch 52, Train Loss: 0.5439, Val Loss: 0.4963, F1 Micro: 0.7844, F1 Macro: 0.7841, Accuracy: 0.7844\n","Epoch 53, Train Loss: 0.5540, Val Loss: 0.4718, F1 Micro: 0.8094, F1 Macro: 0.8092, Accuracy: 0.8094\n","Epoch 54, Train Loss: 0.5555, Val Loss: 0.5158, F1 Micro: 0.7312, F1 Macro: 0.7311, Accuracy: 0.7312\n","Epoch 55, Train Loss: 0.5396, Val Loss: 0.4582, F1 Micro: 0.7844, F1 Macro: 0.7842, Accuracy: 0.7844\n","Epoch 56, Train Loss: 0.5187, Val Loss: 0.5209, F1 Micro: 0.7656, F1 Macro: 0.7639, Accuracy: 0.7656\n","Epoch 57, Train Loss: 0.5228, Val Loss: 0.5056, F1 Micro: 0.7063, F1 Macro: 0.7051, Accuracy: 0.7063\n","Epoch 58, Train Loss: 0.5231, Val Loss: 0.7246, F1 Micro: 0.7375, F1 Macro: 0.7320, Accuracy: 0.7375\n","Epoch 59, Train Loss: 0.5922, Val Loss: 0.4760, F1 Micro: 0.7625, F1 Macro: 0.7619, Accuracy: 0.7625\n","Epoch 60, Train Loss: 0.5523, Val Loss: 0.4815, F1 Micro: 0.7937, F1 Macro: 0.7936, Accuracy: 0.7937\n","Epoch 61, Train Loss: 0.5452, Val Loss: 0.5108, F1 Micro: 0.7063, F1 Macro: 0.7055, Accuracy: 0.7063\n","Epoch 62, Train Loss: 0.5282, Val Loss: 0.4814, F1 Micro: 0.7906, F1 Macro: 0.7878, Accuracy: 0.7906\n","Epoch 63, Train Loss: 0.5308, Val Loss: 0.4952, F1 Micro: 0.7438, F1 Macro: 0.7397, Accuracy: 0.7438\n","Epoch 64, Train Loss: 0.5001, Val Loss: 0.5038, F1 Micro: 0.7500, F1 Macro: 0.7460, Accuracy: 0.7500\n","Epoch 65, Train Loss: 0.5737, Val Loss: 0.4913, F1 Micro: 0.7531, F1 Macro: 0.7524, Accuracy: 0.7531\n","Epoch 66, Train Loss: 0.5352, Val Loss: 0.4808, F1 Micro: 0.8031, F1 Macro: 0.8031, Accuracy: 0.8031\n","Epoch 67, Train Loss: 0.5780, Val Loss: 0.5267, F1 Micro: 0.7250, F1 Macro: 0.7175, Accuracy: 0.7250\n","Epoch 68, Train Loss: 0.5505, Val Loss: 0.5544, F1 Micro: 0.7625, F1 Macro: 0.7475, Accuracy: 0.7625\n","Epoch 69, Train Loss: 0.5259, Val Loss: 0.5233, F1 Micro: 0.7281, F1 Macro: 0.7123, Accuracy: 0.7281\n","Epoch 70, Train Loss: 0.5613, Val Loss: 0.4760, F1 Micro: 0.7719, F1 Macro: 0.7700, Accuracy: 0.7719\n","Epoch 71, Train Loss: 0.5839, Val Loss: 0.5911, F1 Micro: 0.5844, F1 Macro: 0.4612, Accuracy: 0.5844\n","Epoch 72, Train Loss: 0.5542, Val Loss: 0.5119, F1 Micro: 0.7344, F1 Macro: 0.7250, Accuracy: 0.7344\n","Epoch 73, Train Loss: 0.5545, Val Loss: 0.5143, F1 Micro: 0.7469, F1 Macro: 0.7267, Accuracy: 0.7469\n","Epoch 74, Train Loss: 0.5294, Val Loss: 0.4726, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 75, Train Loss: 0.5184, Val Loss: 0.5725, F1 Micro: 0.6875, F1 Macro: 0.6736, Accuracy: 0.6875\n","Epoch 76, Train Loss: 0.5320, Val Loss: 0.5051, F1 Micro: 0.7250, F1 Macro: 0.7181, Accuracy: 0.7250\n","Epoch 77, Train Loss: 0.5049, Val Loss: 0.4898, F1 Micro: 0.7406, F1 Macro: 0.7359, Accuracy: 0.7406\n","Epoch 78, Train Loss: 0.5002, Val Loss: 0.4593, F1 Micro: 0.7750, F1 Macro: 0.7741, Accuracy: 0.7750\n","Epoch 79, Train Loss: 0.5382, Val Loss: 0.4733, F1 Micro: 0.7719, F1 Macro: 0.7716, Accuracy: 0.7719\n","Epoch 80, Train Loss: 0.5131, Val Loss: 0.7042, F1 Micro: 0.7000, F1 Macro: 0.6883, Accuracy: 0.7000\n","Epoch 81, Train Loss: 0.5278, Val Loss: 0.4774, F1 Micro: 0.7750, F1 Macro: 0.7703, Accuracy: 0.7750\n","Epoch 82, Train Loss: 0.5247, Val Loss: 0.4798, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 83, Train Loss: 0.5148, Val Loss: 0.4766, F1 Micro: 0.7969, F1 Macro: 0.7968, Accuracy: 0.7969\n","Epoch 84, Train Loss: 0.5253, Val Loss: 0.4474, F1 Micro: 0.8062, F1 Macro: 0.8062, Accuracy: 0.8063\n","Epoch 85, Train Loss: 0.5526, Val Loss: 0.6342, F1 Micro: 0.7000, F1 Macro: 0.6891, Accuracy: 0.7000\n","Epoch 86, Train Loss: 0.5410, Val Loss: 0.5280, F1 Micro: 0.7688, F1 Macro: 0.7654, Accuracy: 0.7688\n","Epoch 87, Train Loss: 0.5347, Val Loss: 0.4502, F1 Micro: 0.7875, F1 Macro: 0.7874, Accuracy: 0.7875\n","Epoch 88, Train Loss: 0.5477, Val Loss: 0.5591, F1 Micro: 0.7219, F1 Macro: 0.7140, Accuracy: 0.7219\n","Epoch 89, Train Loss: 0.5232, Val Loss: 0.5054, F1 Micro: 0.7406, F1 Macro: 0.7359, Accuracy: 0.7406\n","Epoch 90, Train Loss: 0.5420, Val Loss: 0.5288, F1 Micro: 0.7281, F1 Macro: 0.6967, Accuracy: 0.7281\n","Epoch 91, Train Loss: 0.5392, Val Loss: 0.5237, F1 Micro: 0.7031, F1 Macro: 0.7021, Accuracy: 0.7031\n","Epoch 92, Train Loss: 0.5004, Val Loss: 0.5949, F1 Micro: 0.7000, F1 Macro: 0.6891, Accuracy: 0.7000\n","Epoch 93, Train Loss: 0.5206, Val Loss: 0.7214, F1 Micro: 0.5813, F1 Macro: 0.5251, Accuracy: 0.5813\n","Epoch 94, Train Loss: 0.5068, Val Loss: 0.4989, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 95, Train Loss: 0.5139, Val Loss: 0.5248, F1 Micro: 0.7000, F1 Macro: 0.6912, Accuracy: 0.7000\n","Epoch 96, Train Loss: 0.5050, Val Loss: 0.4587, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 97, Train Loss: 0.5512, Val Loss: 0.6426, F1 Micro: 0.6625, F1 Macro: 0.6375, Accuracy: 0.6625\n","Epoch 98, Train Loss: 0.5120, Val Loss: 0.4463, F1 Micro: 0.7969, F1 Macro: 0.7956, Accuracy: 0.7969\n","Epoch 99, Train Loss: 0.5323, Val Loss: 0.5921, F1 Micro: 0.6438, F1 Macro: 0.6362, Accuracy: 0.6438\n","Epoch 100, Train Loss: 0.5437, Val Loss: 0.5144, F1 Micro: 0.7125, F1 Macro: 0.7088, Accuracy: 0.7125\n","Epoch 101, Train Loss: 0.5142, Val Loss: 0.6821, F1 Micro: 0.6000, F1 Macro: 0.5567, Accuracy: 0.6000\n","Epoch 102, Train Loss: 0.5348, Val Loss: 0.4501, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 103, Train Loss: 0.5222, Val Loss: 0.5973, F1 Micro: 0.7031, F1 Macro: 0.6912, Accuracy: 0.7031\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.818125\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6004, Val Loss: 0.5697, F1 Micro: 0.7250, F1 Macro: 0.7246, Accuracy: 0.7250\n","Epoch 2, Train Loss: 0.5835, Val Loss: 0.6014, F1 Micro: 0.6813, F1 Macro: 0.6733, Accuracy: 0.6813\n","Epoch 3, Train Loss: 0.5814, Val Loss: 0.5886, F1 Micro: 0.6813, F1 Macro: 0.6600, Accuracy: 0.6813\n","Epoch 4, Train Loss: 0.5809, Val Loss: 0.6041, F1 Micro: 0.6594, F1 Macro: 0.6249, Accuracy: 0.6594\n","Epoch 5, Train Loss: 0.5650, Val Loss: 0.5960, F1 Micro: 0.6875, F1 Macro: 0.6809, Accuracy: 0.6875\n","Epoch 6, Train Loss: 0.5726, Val Loss: 0.5672, F1 Micro: 0.6906, F1 Macro: 0.6764, Accuracy: 0.6906\n","Epoch 7, Train Loss: 0.5664, Val Loss: 0.5736, F1 Micro: 0.7094, F1 Macro: 0.7079, Accuracy: 0.7094\n","Epoch 8, Train Loss: 0.5600, Val Loss: 0.5612, F1 Micro: 0.7281, F1 Macro: 0.7279, Accuracy: 0.7281\n","Epoch 9, Train Loss: 0.5619, Val Loss: 0.5486, F1 Micro: 0.7094, F1 Macro: 0.7050, Accuracy: 0.7094\n","Epoch 10, Train Loss: 0.5606, Val Loss: 0.5751, F1 Micro: 0.7000, F1 Macro: 0.6980, Accuracy: 0.7000\n","Epoch 11, Train Loss: 0.5580, Val Loss: 0.5438, F1 Micro: 0.7156, F1 Macro: 0.7146, Accuracy: 0.7156\n","Epoch 12, Train Loss: 0.5533, Val Loss: 0.5541, F1 Micro: 0.6875, F1 Macro: 0.6790, Accuracy: 0.6875\n","Epoch 13, Train Loss: 0.5507, Val Loss: 0.6030, F1 Micro: 0.6781, F1 Macro: 0.6651, Accuracy: 0.6781\n","Epoch 14, Train Loss: 0.5613, Val Loss: 0.5462, F1 Micro: 0.7000, F1 Macro: 0.6977, Accuracy: 0.7000\n","Epoch 15, Train Loss: 0.5589, Val Loss: 0.5431, F1 Micro: 0.7125, F1 Macro: 0.7111, Accuracy: 0.7125\n","Epoch 16, Train Loss: 0.5596, Val Loss: 0.5421, F1 Micro: 0.7125, F1 Macro: 0.7114, Accuracy: 0.7125\n","Epoch 17, Train Loss: 0.5510, Val Loss: 0.5411, F1 Micro: 0.7031, F1 Macro: 0.7013, Accuracy: 0.7031\n","Epoch 18, Train Loss: 0.5515, Val Loss: 0.5586, F1 Micro: 0.6813, F1 Macro: 0.6704, Accuracy: 0.6813\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6251, Val Loss: 0.5238, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 2, Train Loss: 0.5937, Val Loss: 0.5286, F1 Micro: 0.7438, F1 Macro: 0.7368, Accuracy: 0.7438\n","Epoch 3, Train Loss: 0.5896, Val Loss: 0.5277, F1 Micro: 0.7469, F1 Macro: 0.7338, Accuracy: 0.7469\n","Epoch 4, Train Loss: 0.5766, Val Loss: 0.5616, F1 Micro: 0.6969, F1 Macro: 0.6966, Accuracy: 0.6969\n","Epoch 5, Train Loss: 0.5767, Val Loss: 0.5557, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 6, Train Loss: 0.5750, Val Loss: 0.5302, F1 Micro: 0.7500, F1 Macro: 0.7468, Accuracy: 0.7500\n","Epoch 7, Train Loss: 0.5730, Val Loss: 0.5240, F1 Micro: 0.7500, F1 Macro: 0.7471, Accuracy: 0.7500\n","Epoch 8, Train Loss: 0.5713, Val Loss: 0.5268, F1 Micro: 0.7438, F1 Macro: 0.7301, Accuracy: 0.7438\n","Epoch 9, Train Loss: 0.5712, Val Loss: 0.5246, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 10, Train Loss: 0.5683, Val Loss: 0.5252, F1 Micro: 0.7438, F1 Macro: 0.7405, Accuracy: 0.7438\n","Epoch 11, Train Loss: 0.5600, Val Loss: 0.5513, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 12, Train Loss: 0.5695, Val Loss: 0.5295, F1 Micro: 0.7312, F1 Macro: 0.7114, Accuracy: 0.7312\n","Epoch 13, Train Loss: 0.5614, Val Loss: 0.5335, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 14, Train Loss: 0.5689, Val Loss: 0.5324, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 15, Train Loss: 0.5699, Val Loss: 0.5196, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 16, Train Loss: 0.5591, Val Loss: 0.5389, F1 Micro: 0.6969, F1 Macro: 0.6969, Accuracy: 0.6969\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6162, Val Loss: 0.7957, F1 Micro: 0.5687, F1 Macro: 0.5368, Accuracy: 0.5687\n","Epoch 2, Train Loss: 0.5701, Val Loss: 0.6136, F1 Micro: 0.6906, F1 Macro: 0.6869, Accuracy: 0.6906\n","Epoch 3, Train Loss: 0.5438, Val Loss: 0.6365, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 4, Train Loss: 0.5410, Val Loss: 0.6316, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 5, Train Loss: 0.5441, Val Loss: 0.6211, F1 Micro: 0.6875, F1 Macro: 0.6857, Accuracy: 0.6875\n","Epoch 6, Train Loss: 0.5720, Val Loss: 0.6689, F1 Micro: 0.6562, F1 Macro: 0.6554, Accuracy: 0.6562\n","Epoch 7, Train Loss: 0.5478, Val Loss: 0.6136, F1 Micro: 0.6844, F1 Macro: 0.6806, Accuracy: 0.6844\n","Epoch 8, Train Loss: 0.5625, Val Loss: 0.6155, F1 Micro: 0.6875, F1 Macro: 0.6854, Accuracy: 0.6875\n","Epoch 9, Train Loss: 0.5514, Val Loss: 0.6079, F1 Micro: 0.6875, F1 Macro: 0.6835, Accuracy: 0.6875\n","Epoch 10, Train Loss: 0.5508, Val Loss: 0.6271, F1 Micro: 0.6750, F1 Macro: 0.6623, Accuracy: 0.6750\n","Epoch 11, Train Loss: 0.5451, Val Loss: 0.6009, F1 Micro: 0.6844, F1 Macro: 0.6761, Accuracy: 0.6844\n","Epoch 12, Train Loss: 0.5454, Val Loss: 0.6811, F1 Micro: 0.6219, F1 Macro: 0.6187, Accuracy: 0.6219\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6291, Val Loss: 0.5662, F1 Micro: 0.6781, F1 Macro: 0.6697, Accuracy: 0.6781\n","Epoch 2, Train Loss: 0.5917, Val Loss: 0.5878, F1 Micro: 0.6687, F1 Macro: 0.6549, Accuracy: 0.6687\n","Epoch 3, Train Loss: 0.5799, Val Loss: 0.5991, F1 Micro: 0.6719, F1 Macro: 0.6568, Accuracy: 0.6719\n","Epoch 4, Train Loss: 0.5750, Val Loss: 0.5832, F1 Micro: 0.6687, F1 Macro: 0.6540, Accuracy: 0.6687\n","Epoch 5, Train Loss: 0.5643, Val Loss: 0.5377, F1 Micro: 0.7031, F1 Macro: 0.7025, Accuracy: 0.7031\n","Epoch 6, Train Loss: 0.5760, Val Loss: 0.5612, F1 Micro: 0.7438, F1 Macro: 0.7362, Accuracy: 0.7438\n","Epoch 7, Train Loss: 0.5731, Val Loss: 0.5680, F1 Micro: 0.6750, F1 Macro: 0.6662, Accuracy: 0.6750\n","Epoch 8, Train Loss: 0.5807, Val Loss: 0.5700, F1 Micro: 0.6813, F1 Macro: 0.6719, Accuracy: 0.6813\n","Epoch 9, Train Loss: 0.5659, Val Loss: 0.5289, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 10, Train Loss: 0.5648, Val Loss: 0.5277, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 11, Train Loss: 0.5696, Val Loss: 0.5536, F1 Micro: 0.6844, F1 Macro: 0.6791, Accuracy: 0.6844\n","Epoch 12, Train Loss: 0.5655, Val Loss: 0.5301, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.5660, Val Loss: 0.5688, F1 Micro: 0.7344, F1 Macro: 0.7257, Accuracy: 0.7344\n","Epoch 14, Train Loss: 0.5705, Val Loss: 0.5298, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 15, Train Loss: 0.5588, Val Loss: 0.5292, F1 Micro: 0.7219, F1 Macro: 0.7199, Accuracy: 0.7219\n","Epoch 16, Train Loss: 0.5612, Val Loss: 0.5498, F1 Micro: 0.6844, F1 Macro: 0.6806, Accuracy: 0.6844\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6147, Val Loss: 0.5523, F1 Micro: 0.7063, F1 Macro: 0.6867, Accuracy: 0.7063\n","Epoch 2, Train Loss: 0.5761, Val Loss: 0.5525, F1 Micro: 0.7063, F1 Macro: 0.6867, Accuracy: 0.7063\n","Epoch 3, Train Loss: 0.5718, Val Loss: 0.5391, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 4, Train Loss: 0.5714, Val Loss: 0.5843, F1 Micro: 0.6937, F1 Macro: 0.6606, Accuracy: 0.6937\n","Epoch 5, Train Loss: 0.5834, Val Loss: 0.5407, F1 Micro: 0.7219, F1 Macro: 0.7181, Accuracy: 0.7219\n","Epoch 6, Train Loss: 0.5659, Val Loss: 0.5779, F1 Micro: 0.7031, F1 Macro: 0.7023, Accuracy: 0.7031\n","Epoch 7, Train Loss: 0.5639, Val Loss: 0.5455, F1 Micro: 0.7063, F1 Macro: 0.6897, Accuracy: 0.7063\n","Epoch 8, Train Loss: 0.5675, Val Loss: 0.5329, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 9, Train Loss: 0.5676, Val Loss: 0.5340, F1 Micro: 0.7281, F1 Macro: 0.7205, Accuracy: 0.7281\n","Epoch 10, Train Loss: 0.5679, Val Loss: 0.5550, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 11, Train Loss: 0.5672, Val Loss: 0.5356, F1 Micro: 0.7281, F1 Macro: 0.7244, Accuracy: 0.7281\n","Epoch 12, Train Loss: 0.5619, Val Loss: 0.5386, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 13, Train Loss: 0.5657, Val Loss: 0.5458, F1 Micro: 0.7219, F1 Macro: 0.7207, Accuracy: 0.7219\n","Epoch 14, Train Loss: 0.5502, Val Loss: 0.5358, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 15, Train Loss: 0.5648, Val Loss: 0.5831, F1 Micro: 0.6906, F1 Macro: 0.6884, Accuracy: 0.6906\n","Epoch 16, Train Loss: 0.5656, Val Loss: 0.5705, F1 Micro: 0.7063, F1 Macro: 0.7053, Accuracy: 0.7063\n","Epoch 17, Train Loss: 0.5535, Val Loss: 0.5356, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 18, Train Loss: 0.5520, Val Loss: 0.5371, F1 Micro: 0.7125, F1 Macro: 0.7013, Accuracy: 0.7125\n","Epoch 19, Train Loss: 0.5545, Val Loss: 0.5535, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.728125\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6098, Val Loss: 0.5515, F1 Micro: 0.7125, F1 Macro: 0.7109, Accuracy: 0.7125\n","Epoch 2, Train Loss: 0.5769, Val Loss: 0.6010, F1 Micro: 0.6687, F1 Macro: 0.6430, Accuracy: 0.6687\n","Epoch 3, Train Loss: 0.5745, Val Loss: 0.5787, F1 Micro: 0.6844, F1 Macro: 0.6650, Accuracy: 0.6844\n","Epoch 4, Train Loss: 0.5692, Val Loss: 0.5990, F1 Micro: 0.6656, F1 Macro: 0.6389, Accuracy: 0.6656\n","Epoch 5, Train Loss: 0.5741, Val Loss: 0.5696, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 6, Train Loss: 0.5599, Val Loss: 0.5497, F1 Micro: 0.7094, F1 Macro: 0.7081, Accuracy: 0.7094\n","Epoch 7, Train Loss: 0.5544, Val Loss: 0.5744, F1 Micro: 0.6906, F1 Macro: 0.6764, Accuracy: 0.6906\n","Epoch 8, Train Loss: 0.5693, Val Loss: 0.5504, F1 Micro: 0.7031, F1 Macro: 0.7007, Accuracy: 0.7031\n","Epoch 9, Train Loss: 0.5817, Val Loss: 0.5594, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 10, Train Loss: 0.5654, Val Loss: 0.5486, F1 Micro: 0.7094, F1 Macro: 0.7054, Accuracy: 0.7094\n","Epoch 11, Train Loss: 0.5629, Val Loss: 0.5462, F1 Micro: 0.7031, F1 Macro: 0.7003, Accuracy: 0.7031\n","Epoch 12, Train Loss: 0.5518, Val Loss: 0.5473, F1 Micro: 0.7250, F1 Macro: 0.7246, Accuracy: 0.7250\n","Epoch 13, Train Loss: 0.5538, Val Loss: 0.5518, F1 Micro: 0.6969, F1 Macro: 0.6923, Accuracy: 0.6969\n","Epoch 14, Train Loss: 0.5577, Val Loss: 0.5445, F1 Micro: 0.7188, F1 Macro: 0.7185, Accuracy: 0.7188\n","Epoch 15, Train Loss: 0.5578, Val Loss: 0.5428, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 16, Train Loss: 0.5500, Val Loss: 0.5420, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 17, Train Loss: 0.5487, Val Loss: 0.5554, F1 Micro: 0.6906, F1 Macro: 0.6819, Accuracy: 0.6906\n","Epoch 18, Train Loss: 0.5531, Val Loss: 0.5473, F1 Micro: 0.6969, F1 Macro: 0.6913, Accuracy: 0.6969\n","Epoch 19, Train Loss: 0.5497, Val Loss: 0.5438, F1 Micro: 0.6937, F1 Macro: 0.6907, Accuracy: 0.6937\n","Epoch 20, Train Loss: 0.5598, Val Loss: 0.5439, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 21, Train Loss: 0.5577, Val Loss: 0.5561, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 22, Train Loss: 0.5498, Val Loss: 0.5430, F1 Micro: 0.7094, F1 Macro: 0.7091, Accuracy: 0.7094\n","Epoch 23, Train Loss: 0.5497, Val Loss: 0.5577, F1 Micro: 0.6875, F1 Macro: 0.6776, Accuracy: 0.6875\n","Epoch 24, Train Loss: 0.5448, Val Loss: 0.5393, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 25, Train Loss: 0.5469, Val Loss: 0.5405, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 26, Train Loss: 0.5431, Val Loss: 0.5386, F1 Micro: 0.7156, F1 Macro: 0.7146, Accuracy: 0.7156\n","Epoch 27, Train Loss: 0.5493, Val Loss: 0.5396, F1 Micro: 0.7031, F1 Macro: 0.7007, Accuracy: 0.7031\n","Epoch 28, Train Loss: 0.5475, Val Loss: 0.5496, F1 Micro: 0.6969, F1 Macro: 0.6908, Accuracy: 0.6969\n","Epoch 29, Train Loss: 0.5436, Val Loss: 0.5437, F1 Micro: 0.7063, F1 Macro: 0.7055, Accuracy: 0.7063\n","Epoch 30, Train Loss: 0.5425, Val Loss: 0.5784, F1 Micro: 0.6813, F1 Macro: 0.6688, Accuracy: 0.6813\n","Epoch 31, Train Loss: 0.5456, Val Loss: 0.5419, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 32, Train Loss: 0.5535, Val Loss: 0.5617, F1 Micro: 0.7063, F1 Macro: 0.7020, Accuracy: 0.7063\n","Epoch 33, Train Loss: 0.5471, Val Loss: 0.5520, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 34, Train Loss: 0.5438, Val Loss: 0.5389, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 35, Train Loss: 0.5446, Val Loss: 0.5346, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 36, Train Loss: 0.5483, Val Loss: 0.5437, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 37, Train Loss: 0.5407, Val Loss: 0.5640, F1 Micro: 0.6969, F1 Macro: 0.6862, Accuracy: 0.6969\n","Epoch 38, Train Loss: 0.5452, Val Loss: 0.5347, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 39, Train Loss: 0.5402, Val Loss: 0.5377, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 40, Train Loss: 0.5432, Val Loss: 0.5361, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 41, Train Loss: 0.5405, Val Loss: 0.5350, F1 Micro: 0.7063, F1 Macro: 0.7036, Accuracy: 0.7063\n","Epoch 42, Train Loss: 0.5341, Val Loss: 0.5903, F1 Micro: 0.6750, F1 Macro: 0.6497, Accuracy: 0.6750\n","Epoch 43, Train Loss: 0.5345, Val Loss: 0.5345, F1 Micro: 0.7063, F1 Macro: 0.7040, Accuracy: 0.7063\n","Epoch 44, Train Loss: 0.5469, Val Loss: 0.5366, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 45, Train Loss: 0.5318, Val Loss: 0.5321, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 46, Train Loss: 0.5393, Val Loss: 0.5480, F1 Micro: 0.7156, F1 Macro: 0.7146, Accuracy: 0.7156\n","Epoch 47, Train Loss: 0.5378, Val Loss: 0.5312, F1 Micro: 0.7156, F1 Macro: 0.7144, Accuracy: 0.7156\n","Epoch 48, Train Loss: 0.5411, Val Loss: 0.5509, F1 Micro: 0.6969, F1 Macro: 0.6883, Accuracy: 0.6969\n","Epoch 49, Train Loss: 0.5374, Val Loss: 0.5355, F1 Micro: 0.7250, F1 Macro: 0.7249, Accuracy: 0.7250\n","Epoch 50, Train Loss: 0.5383, Val Loss: 0.5276, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 51, Train Loss: 0.5350, Val Loss: 0.5377, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 52, Train Loss: 0.5331, Val Loss: 0.5367, F1 Micro: 0.7031, F1 Macro: 0.6986, Accuracy: 0.7031\n","Epoch 53, Train Loss: 0.5390, Val Loss: 0.5311, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 54, Train Loss: 0.5290, Val Loss: 0.5334, F1 Micro: 0.7281, F1 Macro: 0.7278, Accuracy: 0.7281\n","Epoch 55, Train Loss: 0.5414, Val Loss: 0.5383, F1 Micro: 0.7281, F1 Macro: 0.7267, Accuracy: 0.7281\n","Epoch 56, Train Loss: 0.5481, Val Loss: 0.5458, F1 Micro: 0.7063, F1 Macro: 0.7043, Accuracy: 0.7063\n","Epoch 57, Train Loss: 0.5416, Val Loss: 0.5290, F1 Micro: 0.7063, F1 Macro: 0.7033, Accuracy: 0.7063\n","Epoch 58, Train Loss: 0.5379, Val Loss: 0.5232, F1 Micro: 0.7156, F1 Macro: 0.7141, Accuracy: 0.7156\n","Epoch 59, Train Loss: 0.5291, Val Loss: 0.5216, F1 Micro: 0.7250, F1 Macro: 0.7246, Accuracy: 0.7250\n","Epoch 60, Train Loss: 0.5306, Val Loss: 0.5318, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 61, Train Loss: 0.5347, Val Loss: 0.5340, F1 Micro: 0.6969, F1 Macro: 0.6913, Accuracy: 0.6969\n","Epoch 62, Train Loss: 0.5292, Val Loss: 0.5280, F1 Micro: 0.7188, F1 Macro: 0.7169, Accuracy: 0.7188\n","Epoch 63, Train Loss: 0.5261, Val Loss: 0.5194, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 64, Train Loss: 0.5282, Val Loss: 0.5212, F1 Micro: 0.7188, F1 Macro: 0.7176, Accuracy: 0.7188\n","Epoch 65, Train Loss: 0.5286, Val Loss: 0.5802, F1 Micro: 0.7031, F1 Macro: 0.6849, Accuracy: 0.7031\n","Epoch 66, Train Loss: 0.5237, Val Loss: 0.5154, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 67, Train Loss: 0.5248, Val Loss: 0.5183, F1 Micro: 0.7250, F1 Macro: 0.7234, Accuracy: 0.7250\n","Epoch 68, Train Loss: 0.5307, Val Loss: 0.5181, F1 Micro: 0.7375, F1 Macro: 0.7375, Accuracy: 0.7375\n","Epoch 69, Train Loss: 0.5219, Val Loss: 0.5374, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 70, Train Loss: 0.5288, Val Loss: 0.5129, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 71, Train Loss: 0.5271, Val Loss: 0.5282, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 72, Train Loss: 0.5209, Val Loss: 0.5186, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 73, Train Loss: 0.5243, Val Loss: 0.5169, F1 Micro: 0.7406, F1 Macro: 0.7402, Accuracy: 0.7406\n","Epoch 74, Train Loss: 0.5187, Val Loss: 0.5092, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 75, Train Loss: 0.5218, Val Loss: 0.5225, F1 Micro: 0.7375, F1 Macro: 0.7373, Accuracy: 0.7375\n","Epoch 76, Train Loss: 0.5217, Val Loss: 0.5176, F1 Micro: 0.7375, F1 Macro: 0.7370, Accuracy: 0.7375\n","Epoch 77, Train Loss: 0.5175, Val Loss: 0.5200, F1 Micro: 0.7344, F1 Macro: 0.7327, Accuracy: 0.7344\n","Epoch 78, Train Loss: 0.5245, Val Loss: 0.5202, F1 Micro: 0.7125, F1 Macro: 0.7088, Accuracy: 0.7125\n","Epoch 79, Train Loss: 0.5118, Val Loss: 0.5056, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 80, Train Loss: 0.5151, Val Loss: 0.5057, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 81, Train Loss: 0.5064, Val Loss: 0.5679, F1 Micro: 0.7719, F1 Macro: 0.7702, Accuracy: 0.7719\n","Epoch 82, Train Loss: 0.5182, Val Loss: 0.5082, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 83, Train Loss: 0.5071, Val Loss: 0.5175, F1 Micro: 0.7125, F1 Macro: 0.7088, Accuracy: 0.7125\n","Epoch 84, Train Loss: 0.5177, Val Loss: 0.5386, F1 Micro: 0.7125, F1 Macro: 0.7034, Accuracy: 0.7125\n","Epoch 85, Train Loss: 0.5109, Val Loss: 0.5250, F1 Micro: 0.7094, F1 Macro: 0.7063, Accuracy: 0.7094\n","Epoch 86, Train Loss: 0.5313, Val Loss: 0.5008, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 87, Train Loss: 0.5182, Val Loss: 0.5033, F1 Micro: 0.7438, F1 Macro: 0.7433, Accuracy: 0.7438\n","Epoch 88, Train Loss: 0.5231, Val Loss: 0.5012, F1 Micro: 0.7406, F1 Macro: 0.7406, Accuracy: 0.7406\n","Epoch 89, Train Loss: 0.5198, Val Loss: 0.5035, F1 Micro: 0.7500, F1 Macro: 0.7495, Accuracy: 0.7500\n","Epoch 90, Train Loss: 0.5102, Val Loss: 0.4995, F1 Micro: 0.7375, F1 Macro: 0.7375, Accuracy: 0.7375\n","Epoch 91, Train Loss: 0.5123, Val Loss: 0.5077, F1 Micro: 0.7188, F1 Macro: 0.7169, Accuracy: 0.7188\n","Epoch 92, Train Loss: 0.5132, Val Loss: 0.5206, F1 Micro: 0.7250, F1 Macro: 0.7211, Accuracy: 0.7250\n","Epoch 93, Train Loss: 0.5074, Val Loss: 0.4981, F1 Micro: 0.7312, F1 Macro: 0.7306, Accuracy: 0.7312\n","Epoch 94, Train Loss: 0.5128, Val Loss: 0.4954, F1 Micro: 0.7344, F1 Macro: 0.7343, Accuracy: 0.7344\n","Epoch 95, Train Loss: 0.5090, Val Loss: 0.5087, F1 Micro: 0.7188, F1 Macro: 0.7155, Accuracy: 0.7188\n","Epoch 96, Train Loss: 0.5107, Val Loss: 0.5054, F1 Micro: 0.7562, F1 Macro: 0.7553, Accuracy: 0.7562\n","Epoch 97, Train Loss: 0.5124, Val Loss: 0.4946, F1 Micro: 0.7375, F1 Macro: 0.7375, Accuracy: 0.7375\n","Epoch 98, Train Loss: 0.5045, Val Loss: 0.4971, F1 Micro: 0.7250, F1 Macro: 0.7239, Accuracy: 0.7250\n","Epoch 99, Train Loss: 0.5047, Val Loss: 0.5231, F1 Micro: 0.7188, F1 Macro: 0.7133, Accuracy: 0.7188\n","Epoch 100, Train Loss: 0.5086, Val Loss: 0.4906, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 101, Train Loss: 0.5200, Val Loss: 0.5660, F1 Micro: 0.7188, F1 Macro: 0.7054, Accuracy: 0.7188\n","Epoch 102, Train Loss: 0.5166, Val Loss: 0.5302, F1 Micro: 0.7156, F1 Macro: 0.7088, Accuracy: 0.7156\n","Epoch 103, Train Loss: 0.5124, Val Loss: 0.4930, F1 Micro: 0.7406, F1 Macro: 0.7405, Accuracy: 0.7406\n","Epoch 104, Train Loss: 0.5102, Val Loss: 0.4910, F1 Micro: 0.7438, F1 Macro: 0.7438, Accuracy: 0.7438\n","Epoch 105, Train Loss: 0.5036, Val Loss: 0.5085, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 106, Train Loss: 0.5169, Val Loss: 0.4925, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 107, Train Loss: 0.5133, Val Loss: 0.4898, F1 Micro: 0.7375, F1 Macro: 0.7372, Accuracy: 0.7375\n","Epoch 108, Train Loss: 0.5235, Val Loss: 0.5040, F1 Micro: 0.7781, F1 Macro: 0.7765, Accuracy: 0.7781\n","Epoch 109, Train Loss: 0.5016, Val Loss: 0.4894, F1 Micro: 0.7469, F1 Macro: 0.7465, Accuracy: 0.7469\n","Epoch 110, Train Loss: 0.5005, Val Loss: 0.4960, F1 Micro: 0.7312, F1 Macro: 0.7302, Accuracy: 0.7312\n","Epoch 111, Train Loss: 0.5069, Val Loss: 0.4919, F1 Micro: 0.7406, F1 Macro: 0.7405, Accuracy: 0.7406\n","Epoch 112, Train Loss: 0.5023, Val Loss: 0.4891, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 113, Train Loss: 0.4979, Val Loss: 0.4844, F1 Micro: 0.7469, F1 Macro: 0.7468, Accuracy: 0.7469\n","Epoch 114, Train Loss: 0.5102, Val Loss: 0.5005, F1 Micro: 0.7656, F1 Macro: 0.7653, Accuracy: 0.7656\n","Epoch 115, Train Loss: 0.4982, Val Loss: 0.4829, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 116, Train Loss: 0.4945, Val Loss: 0.4903, F1 Micro: 0.7656, F1 Macro: 0.7644, Accuracy: 0.7656\n","Epoch 117, Train Loss: 0.5136, Val Loss: 0.5025, F1 Micro: 0.7375, F1 Macro: 0.7363, Accuracy: 0.7375\n","Epoch 118, Train Loss: 0.5053, Val Loss: 0.4964, F1 Micro: 0.7656, F1 Macro: 0.7654, Accuracy: 0.7656\n","Epoch 119, Train Loss: 0.4981, Val Loss: 0.5017, F1 Micro: 0.7812, F1 Macro: 0.7793, Accuracy: 0.7812\n","Epoch 120, Train Loss: 0.5008, Val Loss: 0.5035, F1 Micro: 0.7562, F1 Macro: 0.7563, Accuracy: 0.7562\n","Epoch 121, Train Loss: 0.5006, Val Loss: 0.5034, F1 Micro: 0.7719, F1 Macro: 0.7691, Accuracy: 0.7719\n","Epoch 122, Train Loss: 0.5048, Val Loss: 0.4967, F1 Micro: 0.7344, F1 Macro: 0.7327, Accuracy: 0.7344\n","Epoch 123, Train Loss: 0.5099, Val Loss: 0.5038, F1 Micro: 0.7406, F1 Macro: 0.7367, Accuracy: 0.7406\n","Epoch 124, Train Loss: 0.5042, Val Loss: 0.5247, F1 Micro: 0.7375, F1 Macro: 0.7320, Accuracy: 0.7375\n","Epoch 125, Train Loss: 0.4993, Val Loss: 0.4943, F1 Micro: 0.7500, F1 Macro: 0.7475, Accuracy: 0.7500\n","Epoch 126, Train Loss: 0.5021, Val Loss: 0.4891, F1 Micro: 0.7312, F1 Macro: 0.7302, Accuracy: 0.7312\n","Epoch 127, Train Loss: 0.4942, Val Loss: 0.5380, F1 Micro: 0.7469, F1 Macro: 0.7392, Accuracy: 0.7469\n","Epoch 128, Train Loss: 0.5034, Val Loss: 0.4808, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 129, Train Loss: 0.4958, Val Loss: 0.5185, F1 Micro: 0.7406, F1 Macro: 0.7359, Accuracy: 0.7406\n","Epoch 130, Train Loss: 0.4976, Val Loss: 0.5255, F1 Micro: 0.7312, F1 Macro: 0.7208, Accuracy: 0.7312\n","Epoch 131, Train Loss: 0.4966, Val Loss: 0.4946, F1 Micro: 0.7844, F1 Macro: 0.7826, Accuracy: 0.7844\n","Epoch 132, Train Loss: 0.4817, Val Loss: 0.4926, F1 Micro: 0.7688, F1 Macro: 0.7678, Accuracy: 0.7688\n","Epoch 133, Train Loss: 0.4943, Val Loss: 0.4961, F1 Micro: 0.7438, F1 Macro: 0.7415, Accuracy: 0.7438\n","Epoch 134, Train Loss: 0.5006, Val Loss: 0.4794, F1 Micro: 0.7531, F1 Macro: 0.7530, Accuracy: 0.7531\n","Epoch 135, Train Loss: 0.5025, Val Loss: 0.4838, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 136, Train Loss: 0.5023, Val Loss: 0.4768, F1 Micro: 0.7500, F1 Macro: 0.7500, Accuracy: 0.7500\n","Epoch 137, Train Loss: 0.5020, Val Loss: 0.4885, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 138, Train Loss: 0.4965, Val Loss: 0.5116, F1 Micro: 0.7438, F1 Macro: 0.7379, Accuracy: 0.7438\n","Epoch 139, Train Loss: 0.4919, Val Loss: 0.5230, F1 Micro: 0.7344, F1 Macro: 0.7263, Accuracy: 0.7344\n","Epoch 140, Train Loss: 0.4893, Val Loss: 0.4791, F1 Micro: 0.7469, F1 Macro: 0.7468, Accuracy: 0.7469\n","Epoch 141, Train Loss: 0.4926, Val Loss: 0.5855, F1 Micro: 0.7344, F1 Macro: 0.7237, Accuracy: 0.7344\n","Epoch 142, Train Loss: 0.5066, Val Loss: 0.4787, F1 Micro: 0.7500, F1 Macro: 0.7500, Accuracy: 0.7500\n","Epoch 143, Train Loss: 0.4937, Val Loss: 0.4939, F1 Micro: 0.7500, F1 Macro: 0.7471, Accuracy: 0.7500\n","Epoch 144, Train Loss: 0.4929, Val Loss: 0.4759, F1 Micro: 0.7531, F1 Macro: 0.7526, Accuracy: 0.7531\n","Epoch 145, Train Loss: 0.4948, Val Loss: 0.4825, F1 Micro: 0.7531, F1 Macro: 0.7514, Accuracy: 0.7531\n","Epoch 146, Train Loss: 0.4959, Val Loss: 0.5385, F1 Micro: 0.7469, F1 Macro: 0.7397, Accuracy: 0.7469\n","Epoch 147, Train Loss: 0.4848, Val Loss: 0.4869, F1 Micro: 0.7812, F1 Macro: 0.7800, Accuracy: 0.7812\n","Epoch 148, Train Loss: 0.4939, Val Loss: 0.4877, F1 Micro: 0.7438, F1 Macro: 0.7427, Accuracy: 0.7438\n","Epoch 149, Train Loss: 0.4970, Val Loss: 0.4745, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 150, Train Loss: 0.4945, Val Loss: 0.4904, F1 Micro: 0.7781, F1 Macro: 0.7751, Accuracy: 0.7781\n","Epoch 151, Train Loss: 0.5001, Val Loss: 0.4705, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 152, Train Loss: 0.4917, Val Loss: 0.4896, F1 Micro: 0.7531, F1 Macro: 0.7508, Accuracy: 0.7531\n","Epoch 153, Train Loss: 0.5001, Val Loss: 0.4784, F1 Micro: 0.7438, F1 Macro: 0.7435, Accuracy: 0.7438\n","Epoch 154, Train Loss: 0.5015, Val Loss: 0.4707, F1 Micro: 0.7406, F1 Macro: 0.7406, Accuracy: 0.7406\n","Epoch 155, Train Loss: 0.4930, Val Loss: 0.4783, F1 Micro: 0.7500, F1 Macro: 0.7498, Accuracy: 0.7500\n","Epoch 156, Train Loss: 0.4991, Val Loss: 0.4869, F1 Micro: 0.7406, F1 Macro: 0.7393, Accuracy: 0.7406\n","Epoch 157, Train Loss: 0.4960, Val Loss: 0.4809, F1 Micro: 0.7562, F1 Macro: 0.7562, Accuracy: 0.7562\n","Epoch 158, Train Loss: 0.4950, Val Loss: 0.5160, F1 Micro: 0.7531, F1 Macro: 0.7472, Accuracy: 0.7531\n","Epoch 159, Train Loss: 0.4866, Val Loss: 0.4763, F1 Micro: 0.7438, F1 Macro: 0.7434, Accuracy: 0.7438\n","Epoch 160, Train Loss: 0.4967, Val Loss: 0.5006, F1 Micro: 0.7469, F1 Macro: 0.7408, Accuracy: 0.7469\n","Epoch 161, Train Loss: 0.4973, Val Loss: 0.5074, F1 Micro: 0.7469, F1 Macro: 0.7418, Accuracy: 0.7469\n","Epoch 162, Train Loss: 0.5107, Val Loss: 0.4984, F1 Micro: 0.7594, F1 Macro: 0.7557, Accuracy: 0.7594\n","Epoch 163, Train Loss: 0.4994, Val Loss: 0.4714, F1 Micro: 0.7469, F1 Macro: 0.7468, Accuracy: 0.7469\n","Epoch 164, Train Loss: 0.4991, Val Loss: 0.4850, F1 Micro: 0.7750, F1 Macro: 0.7743, Accuracy: 0.7750\n","Epoch 165, Train Loss: 0.4911, Val Loss: 0.4763, F1 Micro: 0.7469, F1 Macro: 0.7466, Accuracy: 0.7469\n","Epoch 166, Train Loss: 0.4939, Val Loss: 0.4835, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 167, Train Loss: 0.5013, Val Loss: 0.4835, F1 Micro: 0.7562, F1 Macro: 0.7556, Accuracy: 0.7562\n","Epoch 168, Train Loss: 0.4818, Val Loss: 0.5190, F1 Micro: 0.7531, F1 Macro: 0.7462, Accuracy: 0.7531\n","Epoch 169, Train Loss: 0.4872, Val Loss: 0.4673, F1 Micro: 0.7469, F1 Macro: 0.7467, Accuracy: 0.7469\n","Epoch 170, Train Loss: 0.5034, Val Loss: 0.4678, F1 Micro: 0.7562, F1 Macro: 0.7560, Accuracy: 0.7562\n","Epoch 171, Train Loss: 0.4898, Val Loss: 0.4856, F1 Micro: 0.7844, F1 Macro: 0.7823, Accuracy: 0.7844\n","Epoch 172, Train Loss: 0.4918, Val Loss: 0.4697, F1 Micro: 0.7562, F1 Macro: 0.7562, Accuracy: 0.7562\n","Epoch 173, Train Loss: 0.4869, Val Loss: 0.4712, F1 Micro: 0.7625, F1 Macro: 0.7614, Accuracy: 0.7625\n","Epoch 174, Train Loss: 0.4815, Val Loss: 0.4707, F1 Micro: 0.7625, F1 Macro: 0.7620, Accuracy: 0.7625\n","Epoch 175, Train Loss: 0.4866, Val Loss: 0.4773, F1 Micro: 0.7531, F1 Macro: 0.7528, Accuracy: 0.7531\n","Epoch 176, Train Loss: 0.4871, Val Loss: 0.4710, F1 Micro: 0.7531, F1 Macro: 0.7528, Accuracy: 0.7531\n","Epoch 177, Train Loss: 0.4900, Val Loss: 0.5247, F1 Micro: 0.7250, F1 Macro: 0.7112, Accuracy: 0.7250\n","Epoch 178, Train Loss: 0.4857, Val Loss: 0.4800, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 179, Train Loss: 0.4979, Val Loss: 0.4819, F1 Micro: 0.7500, F1 Macro: 0.7490, Accuracy: 0.7500\n","Epoch 180, Train Loss: 0.4868, Val Loss: 0.4903, F1 Micro: 0.7594, F1 Macro: 0.7571, Accuracy: 0.7594\n","Epoch 181, Train Loss: 0.4997, Val Loss: 0.4884, F1 Micro: 0.7438, F1 Macro: 0.7368, Accuracy: 0.7438\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6293, Val Loss: 0.5447, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 2, Train Loss: 0.5864, Val Loss: 0.5469, F1 Micro: 0.6937, F1 Macro: 0.6937, Accuracy: 0.6937\n","Epoch 3, Train Loss: 0.5887, Val Loss: 0.5243, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 4, Train Loss: 0.5752, Val Loss: 0.5234, F1 Micro: 0.7406, F1 Macro: 0.7333, Accuracy: 0.7406\n","Epoch 5, Train Loss: 0.5806, Val Loss: 0.5515, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 6, Train Loss: 0.5626, Val Loss: 0.5580, F1 Micro: 0.7031, F1 Macro: 0.6673, Accuracy: 0.7031\n","Epoch 7, Train Loss: 0.5689, Val Loss: 0.5630, F1 Micro: 0.7000, F1 Macro: 0.6614, Accuracy: 0.7000\n","Epoch 8, Train Loss: 0.5624, Val Loss: 0.5272, F1 Micro: 0.7438, F1 Macro: 0.7405, Accuracy: 0.7438\n","Epoch 9, Train Loss: 0.5626, Val Loss: 0.5472, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 10, Train Loss: 0.5675, Val Loss: 0.5382, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 11, Train Loss: 0.5635, Val Loss: 0.5249, F1 Micro: 0.7375, F1 Macro: 0.7227, Accuracy: 0.7375\n","Epoch 12, Train Loss: 0.5724, Val Loss: 0.5198, F1 Micro: 0.7344, F1 Macro: 0.7229, Accuracy: 0.7344\n","Epoch 13, Train Loss: 0.5653, Val Loss: 0.5189, F1 Micro: 0.7312, F1 Macro: 0.7201, Accuracy: 0.7312\n","Epoch 14, Train Loss: 0.5614, Val Loss: 0.5142, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 15, Train Loss: 0.5594, Val Loss: 0.5351, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 16, Train Loss: 0.5660, Val Loss: 0.5190, F1 Micro: 0.7344, F1 Macro: 0.7229, Accuracy: 0.7344\n","Epoch 17, Train Loss: 0.5587, Val Loss: 0.5270, F1 Micro: 0.7312, F1 Macro: 0.7114, Accuracy: 0.7312\n","Epoch 18, Train Loss: 0.5656, Val Loss: 0.5359, F1 Micro: 0.6937, F1 Macro: 0.6937, Accuracy: 0.6937\n","Epoch 19, Train Loss: 0.5568, Val Loss: 0.5212, F1 Micro: 0.7344, F1 Macro: 0.7263, Accuracy: 0.7344\n","Epoch 20, Train Loss: 0.5593, Val Loss: 0.5164, F1 Micro: 0.7312, F1 Macro: 0.7208, Accuracy: 0.7312\n","Epoch 21, Train Loss: 0.5572, Val Loss: 0.5566, F1 Micro: 0.7031, F1 Macro: 0.6673, Accuracy: 0.7031\n","Epoch 22, Train Loss: 0.5514, Val Loss: 0.5263, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 23, Train Loss: 0.5608, Val Loss: 0.5215, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 24, Train Loss: 0.5543, Val Loss: 0.5322, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 25, Train Loss: 0.5557, Val Loss: 0.5208, F1 Micro: 0.7312, F1 Macro: 0.7143, Accuracy: 0.7312\n","Epoch 26, Train Loss: 0.5506, Val Loss: 0.5115, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 27, Train Loss: 0.5581, Val Loss: 0.5183, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 28, Train Loss: 0.5527, Val Loss: 0.5175, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 29, Train Loss: 0.5485, Val Loss: 0.5139, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 30, Train Loss: 0.5540, Val Loss: 0.5321, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 31, Train Loss: 0.5556, Val Loss: 0.5163, F1 Micro: 0.7344, F1 Macro: 0.7290, Accuracy: 0.7344\n","Epoch 32, Train Loss: 0.5523, Val Loss: 0.5116, F1 Micro: 0.7438, F1 Macro: 0.7338, Accuracy: 0.7438\n","Epoch 33, Train Loss: 0.5511, Val Loss: 0.5144, F1 Micro: 0.7344, F1 Macro: 0.7214, Accuracy: 0.7344\n","Epoch 34, Train Loss: 0.5512, Val Loss: 0.5289, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 35, Train Loss: 0.5513, Val Loss: 0.5122, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 36, Train Loss: 0.5476, Val Loss: 0.5062, F1 Micro: 0.7344, F1 Macro: 0.7290, Accuracy: 0.7344\n","Epoch 37, Train Loss: 0.5475, Val Loss: 0.5179, F1 Micro: 0.7312, F1 Macro: 0.7193, Accuracy: 0.7312\n","Epoch 38, Train Loss: 0.5512, Val Loss: 0.5199, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 39, Train Loss: 0.5430, Val Loss: 0.6339, F1 Micro: 0.6906, F1 Macro: 0.6844, Accuracy: 0.6906\n","Epoch 40, Train Loss: 0.5533, Val Loss: 0.5092, F1 Micro: 0.7344, F1 Macro: 0.7280, Accuracy: 0.7344\n","Epoch 41, Train Loss: 0.5394, Val Loss: 0.5351, F1 Micro: 0.7281, F1 Macro: 0.7042, Accuracy: 0.7281\n","Epoch 42, Train Loss: 0.5441, Val Loss: 0.5147, F1 Micro: 0.7281, F1 Macro: 0.7149, Accuracy: 0.7281\n","Epoch 43, Train Loss: 0.5551, Val Loss: 0.5071, F1 Micro: 0.7281, F1 Macro: 0.7252, Accuracy: 0.7281\n","Epoch 44, Train Loss: 0.5447, Val Loss: 0.5112, F1 Micro: 0.7188, F1 Macro: 0.7174, Accuracy: 0.7188\n","Epoch 45, Train Loss: 0.5416, Val Loss: 0.5040, F1 Micro: 0.7188, F1 Macro: 0.7169, Accuracy: 0.7188\n","Epoch 46, Train Loss: 0.5420, Val Loss: 0.5022, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 47, Train Loss: 0.5441, Val Loss: 0.5163, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 48, Train Loss: 0.5456, Val Loss: 0.5194, F1 Micro: 0.7281, F1 Macro: 0.7105, Accuracy: 0.7281\n","Epoch 49, Train Loss: 0.5421, Val Loss: 0.5037, F1 Micro: 0.7312, F1 Macro: 0.7240, Accuracy: 0.7312\n","Epoch 50, Train Loss: 0.5389, Val Loss: 0.5026, F1 Micro: 0.7406, F1 Macro: 0.7375, Accuracy: 0.7406\n","Epoch 51, Train Loss: 0.5427, Val Loss: 0.5458, F1 Micro: 0.7375, F1 Macro: 0.7360, Accuracy: 0.7375\n","Epoch 52, Train Loss: 0.5411, Val Loss: 0.5026, F1 Micro: 0.7219, F1 Macro: 0.7121, Accuracy: 0.7219\n","Epoch 53, Train Loss: 0.5426, Val Loss: 0.4995, F1 Micro: 0.7281, F1 Macro: 0.7198, Accuracy: 0.7281\n","Epoch 54, Train Loss: 0.5403, Val Loss: 0.4952, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 55, Train Loss: 0.5423, Val Loss: 0.5025, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 56, Train Loss: 0.5358, Val Loss: 0.5016, F1 Micro: 0.7125, F1 Macro: 0.7121, Accuracy: 0.7125\n","Epoch 57, Train Loss: 0.5418, Val Loss: 0.5028, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 58, Train Loss: 0.5361, Val Loss: 0.5179, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.5959, Val Loss: 0.6288, F1 Micro: 0.6750, F1 Macro: 0.6577, Accuracy: 0.6750\n","Epoch 2, Train Loss: 0.5725, Val Loss: 0.6268, F1 Micro: 0.6781, F1 Macro: 0.6643, Accuracy: 0.6781\n","Epoch 3, Train Loss: 0.5751, Val Loss: 0.6724, F1 Micro: 0.6500, F1 Macro: 0.6499, Accuracy: 0.6500\n","Epoch 4, Train Loss: 0.5518, Val Loss: 0.6190, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 5, Train Loss: 0.5587, Val Loss: 0.6190, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 6, Train Loss: 0.5491, Val Loss: 0.6728, F1 Micro: 0.6625, F1 Macro: 0.6619, Accuracy: 0.6625\n","Epoch 7, Train Loss: 0.5487, Val Loss: 0.6114, F1 Micro: 0.6844, F1 Macro: 0.6806, Accuracy: 0.6844\n","Epoch 8, Train Loss: 0.5460, Val Loss: 0.6125, F1 Micro: 0.6687, F1 Macro: 0.6567, Accuracy: 0.6687\n","Epoch 9, Train Loss: 0.5443, Val Loss: 0.6573, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 10, Train Loss: 0.5432, Val Loss: 0.7531, F1 Micro: 0.5875, F1 Macro: 0.5668, Accuracy: 0.5875\n","Epoch 11, Train Loss: 0.5492, Val Loss: 0.6082, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 12, Train Loss: 0.5478, Val Loss: 0.6076, F1 Micro: 0.6906, F1 Macro: 0.6849, Accuracy: 0.6906\n","Epoch 13, Train Loss: 0.5483, Val Loss: 0.6066, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 14, Train Loss: 0.5462, Val Loss: 0.6386, F1 Micro: 0.6781, F1 Macro: 0.6594, Accuracy: 0.6781\n","Epoch 15, Train Loss: 0.5388, Val Loss: 0.6118, F1 Micro: 0.6844, F1 Macro: 0.6810, Accuracy: 0.6844\n","Epoch 16, Train Loss: 0.5424, Val Loss: 0.6124, F1 Micro: 0.6781, F1 Macro: 0.6774, Accuracy: 0.6781\n","Epoch 17, Train Loss: 0.5395, Val Loss: 0.6308, F1 Micro: 0.6875, F1 Macro: 0.6830, Accuracy: 0.6875\n","Epoch 18, Train Loss: 0.5409, Val Loss: 0.6408, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 19, Train Loss: 0.5376, Val Loss: 0.6408, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 20, Train Loss: 0.5378, Val Loss: 0.6290, F1 Micro: 0.6750, F1 Macro: 0.6742, Accuracy: 0.6750\n","Epoch 21, Train Loss: 0.5430, Val Loss: 0.6188, F1 Micro: 0.6750, F1 Macro: 0.6742, Accuracy: 0.6750\n","Epoch 22, Train Loss: 0.5390, Val Loss: 0.6218, F1 Micro: 0.6906, F1 Macro: 0.6873, Accuracy: 0.6906\n","Epoch 23, Train Loss: 0.5369, Val Loss: 0.6301, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 24, Train Loss: 0.5359, Val Loss: 0.6194, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 25, Train Loss: 0.5410, Val Loss: 0.6033, F1 Micro: 0.6781, F1 Macro: 0.6772, Accuracy: 0.6781\n","Epoch 26, Train Loss: 0.5309, Val Loss: 0.6659, F1 Micro: 0.6594, F1 Macro: 0.6592, Accuracy: 0.6594\n","Epoch 27, Train Loss: 0.5338, Val Loss: 0.6528, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 28, Train Loss: 0.5333, Val Loss: 0.6168, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 29, Train Loss: 0.5307, Val Loss: 0.6182, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 30, Train Loss: 0.5337, Val Loss: 0.6071, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 31, Train Loss: 0.5331, Val Loss: 0.5962, F1 Micro: 0.6875, F1 Macro: 0.6809, Accuracy: 0.6875\n","Epoch 32, Train Loss: 0.5338, Val Loss: 0.5874, F1 Micro: 0.6937, F1 Macro: 0.6894, Accuracy: 0.6937\n","Epoch 33, Train Loss: 0.5399, Val Loss: 0.6054, F1 Micro: 0.6906, F1 Macro: 0.6826, Accuracy: 0.6906\n","Epoch 34, Train Loss: 0.5306, Val Loss: 0.5958, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 35, Train Loss: 0.5337, Val Loss: 0.6065, F1 Micro: 0.6875, F1 Macro: 0.6860, Accuracy: 0.6875\n","Epoch 36, Train Loss: 0.5290, Val Loss: 0.6062, F1 Micro: 0.6937, F1 Macro: 0.6920, Accuracy: 0.6937\n","Epoch 37, Train Loss: 0.5265, Val Loss: 0.6363, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 38, Train Loss: 0.5249, Val Loss: 0.5992, F1 Micro: 0.6687, F1 Macro: 0.6684, Accuracy: 0.6687\n","Epoch 39, Train Loss: 0.5339, Val Loss: 0.5908, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 40, Train Loss: 0.5342, Val Loss: 0.6049, F1 Micro: 0.6594, F1 Macro: 0.6593, Accuracy: 0.6594\n","Epoch 41, Train Loss: 0.5253, Val Loss: 0.6122, F1 Micro: 0.6594, F1 Macro: 0.6593, Accuracy: 0.6594\n","Epoch 42, Train Loss: 0.5300, Val Loss: 0.5966, F1 Micro: 0.6750, F1 Macro: 0.6742, Accuracy: 0.6750\n","Epoch 43, Train Loss: 0.5237, Val Loss: 0.6236, F1 Micro: 0.6500, F1 Macro: 0.6493, Accuracy: 0.6500\n","Epoch 44, Train Loss: 0.5214, Val Loss: 0.6240, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 45, Train Loss: 0.5342, Val Loss: 0.5917, F1 Micro: 0.6906, F1 Macro: 0.6890, Accuracy: 0.6906\n","Epoch 46, Train Loss: 0.5279, Val Loss: 0.6297, F1 Micro: 0.6719, F1 Macro: 0.6719, Accuracy: 0.6719\n","Epoch 47, Train Loss: 0.5262, Val Loss: 0.6073, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 48, Train Loss: 0.5216, Val Loss: 0.5971, F1 Micro: 0.6781, F1 Macro: 0.6776, Accuracy: 0.6781\n","Epoch 49, Train Loss: 0.5300, Val Loss: 0.6100, F1 Micro: 0.6781, F1 Macro: 0.6668, Accuracy: 0.6781\n","Epoch 50, Train Loss: 0.5400, Val Loss: 0.6185, F1 Micro: 0.6625, F1 Macro: 0.6625, Accuracy: 0.6625\n","Epoch 51, Train Loss: 0.5249, Val Loss: 0.5798, F1 Micro: 0.6906, F1 Macro: 0.6849, Accuracy: 0.6906\n","Epoch 52, Train Loss: 0.5238, Val Loss: 0.6146, F1 Micro: 0.6531, F1 Macro: 0.6529, Accuracy: 0.6531\n","Epoch 53, Train Loss: 0.5167, Val Loss: 0.5964, F1 Micro: 0.6719, F1 Macro: 0.6715, Accuracy: 0.6719\n","Epoch 54, Train Loss: 0.5175, Val Loss: 0.6504, F1 Micro: 0.6687, F1 Macro: 0.6688, Accuracy: 0.6687\n","Epoch 55, Train Loss: 0.5206, Val Loss: 0.5877, F1 Micro: 0.7000, F1 Macro: 0.6937, Accuracy: 0.7000\n","Epoch 56, Train Loss: 0.5257, Val Loss: 0.5934, F1 Micro: 0.6969, F1 Macro: 0.6944, Accuracy: 0.6969\n","Epoch 57, Train Loss: 0.5347, Val Loss: 0.5882, F1 Micro: 0.7031, F1 Macro: 0.7010, Accuracy: 0.7031\n","Epoch 58, Train Loss: 0.5231, Val Loss: 0.5942, F1 Micro: 0.6687, F1 Macro: 0.6679, Accuracy: 0.6687\n","Epoch 59, Train Loss: 0.5124, Val Loss: 0.6356, F1 Micro: 0.6594, F1 Macro: 0.6584, Accuracy: 0.6594\n","Epoch 60, Train Loss: 0.5194, Val Loss: 0.5940, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 61, Train Loss: 0.5134, Val Loss: 0.6402, F1 Micro: 0.6969, F1 Macro: 0.6953, Accuracy: 0.6969\n","Epoch 62, Train Loss: 0.5097, Val Loss: 0.5928, F1 Micro: 0.6625, F1 Macro: 0.6617, Accuracy: 0.6625\n","Epoch 63, Train Loss: 0.5177, Val Loss: 0.6262, F1 Micro: 0.6562, F1 Macro: 0.6560, Accuracy: 0.6562\n","Epoch 64, Train Loss: 0.5197, Val Loss: 0.5919, F1 Micro: 0.6750, F1 Macro: 0.6744, Accuracy: 0.6750\n","Epoch 65, Train Loss: 0.5151, Val Loss: 0.5859, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 66, Train Loss: 0.5120, Val Loss: 0.5970, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 67, Train Loss: 0.5218, Val Loss: 0.5783, F1 Micro: 0.6781, F1 Macro: 0.6772, Accuracy: 0.6781\n","Epoch 68, Train Loss: 0.5083, Val Loss: 0.5797, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 69, Train Loss: 0.5067, Val Loss: 0.5775, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 70, Train Loss: 0.5180, Val Loss: 0.5852, F1 Micro: 0.6937, F1 Macro: 0.6914, Accuracy: 0.6937\n","Epoch 71, Train Loss: 0.5122, Val Loss: 0.5780, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 72, Train Loss: 0.5105, Val Loss: 0.5989, F1 Micro: 0.6687, F1 Macro: 0.6679, Accuracy: 0.6687\n","Epoch 73, Train Loss: 0.5100, Val Loss: 0.5877, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 74, Train Loss: 0.5133, Val Loss: 0.5950, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 75, Train Loss: 0.5073, Val Loss: 0.5972, F1 Micro: 0.6625, F1 Macro: 0.6620, Accuracy: 0.6625\n","Epoch 76, Train Loss: 0.5167, Val Loss: 0.5918, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 77, Train Loss: 0.5159, Val Loss: 0.5864, F1 Micro: 0.6719, F1 Macro: 0.6713, Accuracy: 0.6719\n","Epoch 78, Train Loss: 0.5028, Val Loss: 0.5835, F1 Micro: 0.6687, F1 Macro: 0.6681, Accuracy: 0.6687\n","Epoch 79, Train Loss: 0.5091, Val Loss: 0.5802, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 80, Train Loss: 0.5035, Val Loss: 0.5683, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 81, Train Loss: 0.5023, Val Loss: 0.5757, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 82, Train Loss: 0.5063, Val Loss: 0.5717, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 83, Train Loss: 0.5013, Val Loss: 0.5767, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 84, Train Loss: 0.5060, Val Loss: 0.6229, F1 Micro: 0.6500, F1 Macro: 0.6450, Accuracy: 0.6500\n","Epoch 85, Train Loss: 0.5086, Val Loss: 0.6200, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 86, Train Loss: 0.5121, Val Loss: 0.5884, F1 Micro: 0.6625, F1 Macro: 0.6619, Accuracy: 0.6625\n","Epoch 87, Train Loss: 0.5006, Val Loss: 0.5715, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 88, Train Loss: 0.4991, Val Loss: 0.5906, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 89, Train Loss: 0.5057, Val Loss: 0.5727, F1 Micro: 0.6719, F1 Macro: 0.6713, Accuracy: 0.6719\n","Epoch 90, Train Loss: 0.5036, Val Loss: 0.5799, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 91, Train Loss: 0.4967, Val Loss: 0.5691, F1 Micro: 0.7063, F1 Macro: 0.7063, Accuracy: 0.7063\n","Epoch 92, Train Loss: 0.4984, Val Loss: 0.5678, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 93, Train Loss: 0.4973, Val Loss: 0.5789, F1 Micro: 0.6906, F1 Macro: 0.6881, Accuracy: 0.6906\n","Epoch 94, Train Loss: 0.5034, Val Loss: 0.6061, F1 Micro: 0.6844, F1 Macro: 0.6796, Accuracy: 0.6844\n","Epoch 95, Train Loss: 0.5084, Val Loss: 0.5659, F1 Micro: 0.6781, F1 Macro: 0.6774, Accuracy: 0.6781\n","Epoch 96, Train Loss: 0.4923, Val Loss: 0.5748, F1 Micro: 0.6875, F1 Macro: 0.6860, Accuracy: 0.6875\n","Epoch 97, Train Loss: 0.4955, Val Loss: 0.6157, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 98, Train Loss: 0.5006, Val Loss: 0.5655, F1 Micro: 0.6781, F1 Macro: 0.6767, Accuracy: 0.6781\n","Epoch 99, Train Loss: 0.5006, Val Loss: 0.5910, F1 Micro: 0.6813, F1 Macro: 0.6811, Accuracy: 0.6813\n","Epoch 100, Train Loss: 0.4964, Val Loss: 0.5640, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 101, Train Loss: 0.4984, Val Loss: 0.5609, F1 Micro: 0.6844, F1 Macro: 0.6840, Accuracy: 0.6844\n","Epoch 102, Train Loss: 0.4881, Val Loss: 0.5829, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 103, Train Loss: 0.4944, Val Loss: 0.5785, F1 Micro: 0.6906, F1 Macro: 0.6895, Accuracy: 0.6906\n","Epoch 104, Train Loss: 0.5034, Val Loss: 0.5619, F1 Micro: 0.7031, F1 Macro: 0.7016, Accuracy: 0.7031\n","Epoch 105, Train Loss: 0.4867, Val Loss: 0.5800, F1 Micro: 0.6781, F1 Macro: 0.6780, Accuracy: 0.6781\n","Epoch 106, Train Loss: 0.5020, Val Loss: 0.5607, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 107, Train Loss: 0.4834, Val Loss: 0.5980, F1 Micro: 0.6781, F1 Macro: 0.6780, Accuracy: 0.6781\n","Epoch 108, Train Loss: 0.4907, Val Loss: 0.6149, F1 Micro: 0.7063, F1 Macro: 0.6989, Accuracy: 0.7063\n","Epoch 109, Train Loss: 0.4889, Val Loss: 0.5759, F1 Micro: 0.6813, F1 Macro: 0.6809, Accuracy: 0.6813\n","Epoch 110, Train Loss: 0.4879, Val Loss: 0.5554, F1 Micro: 0.7125, F1 Macro: 0.7075, Accuracy: 0.7125\n","Epoch 111, Train Loss: 0.4878, Val Loss: 0.5944, F1 Micro: 0.6937, F1 Macro: 0.6936, Accuracy: 0.6937\n","Epoch 112, Train Loss: 0.4862, Val Loss: 0.5620, F1 Micro: 0.6937, F1 Macro: 0.6937, Accuracy: 0.6937\n","Epoch 113, Train Loss: 0.4936, Val Loss: 0.5785, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 114, Train Loss: 0.4855, Val Loss: 0.5668, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 115, Train Loss: 0.4975, Val Loss: 0.5875, F1 Micro: 0.6844, F1 Macro: 0.6821, Accuracy: 0.6844\n","Epoch 116, Train Loss: 0.4861, Val Loss: 0.5592, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 117, Train Loss: 0.5002, Val Loss: 0.5723, F1 Micro: 0.6937, F1 Macro: 0.6936, Accuracy: 0.6937\n","Epoch 118, Train Loss: 0.4798, Val Loss: 0.5657, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 119, Train Loss: 0.4827, Val Loss: 0.5585, F1 Micro: 0.6937, F1 Macro: 0.6930, Accuracy: 0.6937\n","Epoch 120, Train Loss: 0.4838, Val Loss: 0.5729, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 121, Train Loss: 0.4878, Val Loss: 0.5494, F1 Micro: 0.7000, F1 Macro: 0.6994, Accuracy: 0.7000\n","Epoch 122, Train Loss: 0.4847, Val Loss: 0.5643, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 123, Train Loss: 0.4793, Val Loss: 0.5953, F1 Micro: 0.6969, F1 Macro: 0.6936, Accuracy: 0.6969\n","Epoch 124, Train Loss: 0.4880, Val Loss: 0.5661, F1 Micro: 0.6937, F1 Macro: 0.6920, Accuracy: 0.6937\n","Epoch 125, Train Loss: 0.4865, Val Loss: 0.5652, F1 Micro: 0.6969, F1 Macro: 0.6965, Accuracy: 0.6969\n","Epoch 126, Train Loss: 0.4806, Val Loss: 0.5804, F1 Micro: 0.6937, F1 Macro: 0.6917, Accuracy: 0.6937\n","Epoch 127, Train Loss: 0.4883, Val Loss: 0.5631, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 128, Train Loss: 0.4863, Val Loss: 0.5601, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 129, Train Loss: 0.4827, Val Loss: 0.5531, F1 Micro: 0.7000, F1 Macro: 0.6973, Accuracy: 0.7000\n","Epoch 130, Train Loss: 0.4809, Val Loss: 0.5666, F1 Micro: 0.7188, F1 Macro: 0.7128, Accuracy: 0.7188\n","Epoch 131, Train Loss: 0.4748, Val Loss: 0.5586, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 132, Train Loss: 0.4892, Val Loss: 0.5560, F1 Micro: 0.7063, F1 Macro: 0.7043, Accuracy: 0.7063\n","Epoch 133, Train Loss: 0.4782, Val Loss: 0.5747, F1 Micro: 0.7125, F1 Macro: 0.7119, Accuracy: 0.7125\n","Epoch 134, Train Loss: 0.4766, Val Loss: 0.5740, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 135, Train Loss: 0.4929, Val Loss: 0.5643, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 136, Train Loss: 0.4860, Val Loss: 0.5538, F1 Micro: 0.7156, F1 Macro: 0.7104, Accuracy: 0.7156\n","Epoch 137, Train Loss: 0.4901, Val Loss: 0.5668, F1 Micro: 0.7125, F1 Macro: 0.7092, Accuracy: 0.7125\n","Epoch 138, Train Loss: 0.4819, Val Loss: 0.5865, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 139, Train Loss: 0.4756, Val Loss: 0.5869, F1 Micro: 0.6969, F1 Macro: 0.6953, Accuracy: 0.6969\n","Epoch 140, Train Loss: 0.4857, Val Loss: 0.5507, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 141, Train Loss: 0.4712, Val Loss: 0.5595, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 142, Train Loss: 0.4699, Val Loss: 0.5585, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 143, Train Loss: 0.4736, Val Loss: 0.5614, F1 Micro: 0.7063, F1 Macro: 0.7055, Accuracy: 0.7063\n","Epoch 144, Train Loss: 0.4747, Val Loss: 0.5808, F1 Micro: 0.7406, F1 Macro: 0.7344, Accuracy: 0.7406\n","Epoch 145, Train Loss: 0.4707, Val Loss: 0.5606, F1 Micro: 0.7000, F1 Macro: 0.6998, Accuracy: 0.7000\n","Epoch 146, Train Loss: 0.4888, Val Loss: 0.5457, F1 Micro: 0.7250, F1 Macro: 0.7249, Accuracy: 0.7250\n","Epoch 147, Train Loss: 0.4791, Val Loss: 0.5533, F1 Micro: 0.7031, F1 Macro: 0.7021, Accuracy: 0.7031\n","Epoch 148, Train Loss: 0.4811, Val Loss: 0.5707, F1 Micro: 0.7063, F1 Macro: 0.7040, Accuracy: 0.7063\n","Epoch 149, Train Loss: 0.4672, Val Loss: 0.5545, F1 Micro: 0.7125, F1 Macro: 0.7088, Accuracy: 0.7125\n","Epoch 150, Train Loss: 0.4750, Val Loss: 0.5468, F1 Micro: 0.7188, F1 Macro: 0.7188, Accuracy: 0.7188\n","Epoch 151, Train Loss: 0.4790, Val Loss: 0.5719, F1 Micro: 0.7063, F1 Macro: 0.7036, Accuracy: 0.7063\n","Epoch 152, Train Loss: 0.4839, Val Loss: 0.5543, F1 Micro: 0.7125, F1 Macro: 0.7109, Accuracy: 0.7125\n","Epoch 153, Train Loss: 0.4779, Val Loss: 0.5593, F1 Micro: 0.7094, F1 Macro: 0.7076, Accuracy: 0.7094\n","Epoch 154, Train Loss: 0.4725, Val Loss: 0.5808, F1 Micro: 0.6906, F1 Macro: 0.6838, Accuracy: 0.6906\n","Epoch 155, Train Loss: 0.4822, Val Loss: 0.5610, F1 Micro: 0.7188, F1 Macro: 0.7138, Accuracy: 0.7188\n","Epoch 156, Train Loss: 0.4789, Val Loss: 0.5723, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 157, Train Loss: 0.4713, Val Loss: 0.5591, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 158, Train Loss: 0.4779, Val Loss: 0.5791, F1 Micro: 0.7125, F1 Macro: 0.7119, Accuracy: 0.7125\n","Epoch 159, Train Loss: 0.4770, Val Loss: 0.5638, F1 Micro: 0.7125, F1 Macro: 0.7123, Accuracy: 0.7125\n","Epoch 160, Train Loss: 0.4871, Val Loss: 0.5490, F1 Micro: 0.7156, F1 Macro: 0.7146, Accuracy: 0.7156\n","Epoch 161, Train Loss: 0.4636, Val Loss: 0.5536, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 162, Train Loss: 0.4721, Val Loss: 0.5621, F1 Micro: 0.7031, F1 Macro: 0.7013, Accuracy: 0.7031\n","Epoch 163, Train Loss: 0.4680, Val Loss: 0.5677, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 164, Train Loss: 0.4827, Val Loss: 0.5649, F1 Micro: 0.7094, F1 Macro: 0.7081, Accuracy: 0.7094\n","Epoch 165, Train Loss: 0.4667, Val Loss: 0.5482, F1 Micro: 0.7469, F1 Macro: 0.7467, Accuracy: 0.7469\n","Epoch 166, Train Loss: 0.4715, Val Loss: 0.5541, F1 Micro: 0.7125, F1 Macro: 0.7116, Accuracy: 0.7125\n","Epoch 167, Train Loss: 0.4762, Val Loss: 0.5555, F1 Micro: 0.7469, F1 Macro: 0.7466, Accuracy: 0.7469\n","Epoch 168, Train Loss: 0.4828, Val Loss: 0.5614, F1 Micro: 0.7031, F1 Macro: 0.7029, Accuracy: 0.7031\n","Epoch 169, Train Loss: 0.4874, Val Loss: 0.6267, F1 Micro: 0.7250, F1 Macro: 0.7143, Accuracy: 0.7250\n","Epoch 170, Train Loss: 0.4717, Val Loss: 0.5569, F1 Micro: 0.7000, F1 Macro: 0.6988, Accuracy: 0.7000\n","Epoch 171, Train Loss: 0.4730, Val Loss: 0.5689, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 172, Train Loss: 0.4752, Val Loss: 0.5513, F1 Micro: 0.7125, F1 Macro: 0.7121, Accuracy: 0.7125\n","Epoch 173, Train Loss: 0.4678, Val Loss: 0.5627, F1 Micro: 0.7031, F1 Macro: 0.7010, Accuracy: 0.7031\n","Epoch 174, Train Loss: 0.4707, Val Loss: 0.6009, F1 Micro: 0.7156, F1 Macro: 0.7122, Accuracy: 0.7156\n","Epoch 175, Train Loss: 0.4739, Val Loss: 0.5641, F1 Micro: 0.7125, F1 Macro: 0.7109, Accuracy: 0.7125\n","Epoch 176, Train Loss: 0.4726, Val Loss: 0.5587, F1 Micro: 0.7188, F1 Macro: 0.7185, Accuracy: 0.7188\n","Epoch 177, Train Loss: 0.4701, Val Loss: 0.5858, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 178, Train Loss: 0.4670, Val Loss: 0.5661, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 179, Train Loss: 0.4809, Val Loss: 0.5526, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 180, Train Loss: 0.4718, Val Loss: 0.5688, F1 Micro: 0.7219, F1 Macro: 0.7192, Accuracy: 0.7219\n","Epoch 181, Train Loss: 0.4638, Val Loss: 0.5810, F1 Micro: 0.7031, F1 Macro: 0.7003, Accuracy: 0.7031\n","Epoch 182, Train Loss: 0.4744, Val Loss: 0.5712, F1 Micro: 0.6969, F1 Macro: 0.6923, Accuracy: 0.6969\n","Epoch 183, Train Loss: 0.4728, Val Loss: 0.5652, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 184, Train Loss: 0.4721, Val Loss: 0.5764, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 185, Train Loss: 0.4708, Val Loss: 0.5735, F1 Micro: 0.7125, F1 Macro: 0.7119, Accuracy: 0.7125\n","Epoch 186, Train Loss: 0.4829, Val Loss: 0.5502, F1 Micro: 0.7500, F1 Macro: 0.7494, Accuracy: 0.7500\n","Epoch 187, Train Loss: 0.4706, Val Loss: 0.5565, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 188, Train Loss: 0.4744, Val Loss: 0.5456, F1 Micro: 0.7500, F1 Macro: 0.7496, Accuracy: 0.7500\n","Epoch 189, Train Loss: 0.4778, Val Loss: 0.5690, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 190, Train Loss: 0.4724, Val Loss: 0.5570, F1 Micro: 0.7125, F1 Macro: 0.7116, Accuracy: 0.7125\n","Epoch 191, Train Loss: 0.4608, Val Loss: 0.5404, F1 Micro: 0.7312, F1 Macro: 0.7310, Accuracy: 0.7312\n","Epoch 192, Train Loss: 0.4646, Val Loss: 0.5616, F1 Micro: 0.7031, F1 Macro: 0.6999, Accuracy: 0.7031\n","Epoch 193, Train Loss: 0.4657, Val Loss: 0.5484, F1 Micro: 0.7469, F1 Macro: 0.7466, Accuracy: 0.7469\n","Epoch 194, Train Loss: 0.4729, Val Loss: 0.5620, F1 Micro: 0.7250, F1 Macro: 0.7211, Accuracy: 0.7250\n","Epoch 195, Train Loss: 0.4653, Val Loss: 0.5661, F1 Micro: 0.7094, F1 Macro: 0.7079, Accuracy: 0.7094\n","Epoch 196, Train Loss: 0.4659, Val Loss: 0.6253, F1 Micro: 0.6750, F1 Macro: 0.6615, Accuracy: 0.6750\n","Epoch 197, Train Loss: 0.4700, Val Loss: 0.5486, F1 Micro: 0.7531, F1 Macro: 0.7530, Accuracy: 0.7531\n","Epoch 198, Train Loss: 0.4626, Val Loss: 0.5726, F1 Micro: 0.6969, F1 Macro: 0.6913, Accuracy: 0.6969\n","Epoch 199, Train Loss: 0.4644, Val Loss: 0.5523, F1 Micro: 0.7125, F1 Macro: 0.7092, Accuracy: 0.7125\n","Epoch 200, Train Loss: 0.4608, Val Loss: 0.5739, F1 Micro: 0.7188, F1 Macro: 0.7159, Accuracy: 0.7188\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6079, Val Loss: 0.6483, F1 Micro: 0.6438, F1 Macro: 0.6174, Accuracy: 0.6438\n","Epoch 2, Train Loss: 0.5892, Val Loss: 0.5614, F1 Micro: 0.7344, F1 Macro: 0.7257, Accuracy: 0.7344\n","Epoch 3, Train Loss: 0.5796, Val Loss: 0.5471, F1 Micro: 0.7406, F1 Macro: 0.7363, Accuracy: 0.7406\n","Epoch 4, Train Loss: 0.5813, Val Loss: 0.5336, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 5, Train Loss: 0.5677, Val Loss: 0.5314, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 6, Train Loss: 0.5849, Val Loss: 0.5298, F1 Micro: 0.7125, F1 Macro: 0.7123, Accuracy: 0.7125\n","Epoch 7, Train Loss: 0.5744, Val Loss: 0.5918, F1 Micro: 0.7188, F1 Macro: 0.6979, Accuracy: 0.7188\n","Epoch 8, Train Loss: 0.5768, Val Loss: 0.5297, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.5637, Val Loss: 0.5332, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 10, Train Loss: 0.5651, Val Loss: 0.5303, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 11, Train Loss: 0.5687, Val Loss: 0.5389, F1 Micro: 0.7375, F1 Macro: 0.7337, Accuracy: 0.7375\n","Epoch 12, Train Loss: 0.5591, Val Loss: 0.5251, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 13, Train Loss: 0.5643, Val Loss: 0.5240, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 14, Train Loss: 0.5614, Val Loss: 0.5302, F1 Micro: 0.7188, F1 Macro: 0.7185, Accuracy: 0.7188\n","Epoch 15, Train Loss: 0.5653, Val Loss: 0.5222, F1 Micro: 0.7281, F1 Macro: 0.7274, Accuracy: 0.7281\n","Epoch 16, Train Loss: 0.5589, Val Loss: 0.5219, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 17, Train Loss: 0.5658, Val Loss: 0.5307, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 18, Train Loss: 0.5577, Val Loss: 0.5302, F1 Micro: 0.7031, F1 Macro: 0.7023, Accuracy: 0.7031\n","Epoch 19, Train Loss: 0.5628, Val Loss: 0.5465, F1 Micro: 0.6813, F1 Macro: 0.6767, Accuracy: 0.6813\n","Epoch 20, Train Loss: 0.5567, Val Loss: 0.5282, F1 Micro: 0.7281, F1 Macro: 0.7248, Accuracy: 0.7281\n","Epoch 21, Train Loss: 0.5591, Val Loss: 0.5459, F1 Micro: 0.6813, F1 Macro: 0.6767, Accuracy: 0.6813\n","Epoch 22, Train Loss: 0.5590, Val Loss: 0.5249, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 23, Train Loss: 0.5663, Val Loss: 0.5157, F1 Micro: 0.7250, F1 Macro: 0.7241, Accuracy: 0.7250\n","Epoch 24, Train Loss: 0.5526, Val Loss: 0.5231, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 25, Train Loss: 0.5609, Val Loss: 0.5134, F1 Micro: 0.7312, F1 Macro: 0.7306, Accuracy: 0.7312\n","Epoch 26, Train Loss: 0.5594, Val Loss: 0.5177, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 27, Train Loss: 0.5516, Val Loss: 0.5214, F1 Micro: 0.7031, F1 Macro: 0.7029, Accuracy: 0.7031\n","Epoch 28, Train Loss: 0.5565, Val Loss: 0.5125, F1 Micro: 0.7312, F1 Macro: 0.7306, Accuracy: 0.7312\n","Epoch 29, Train Loss: 0.5554, Val Loss: 0.5236, F1 Micro: 0.7375, F1 Macro: 0.7337, Accuracy: 0.7375\n","Epoch 30, Train Loss: 0.5534, Val Loss: 0.5175, F1 Micro: 0.7250, F1 Macro: 0.7219, Accuracy: 0.7250\n","Epoch 31, Train Loss: 0.5564, Val Loss: 0.5207, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 32, Train Loss: 0.5546, Val Loss: 0.5133, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 33, Train Loss: 0.5504, Val Loss: 0.5128, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 34, Train Loss: 0.5488, Val Loss: 0.5225, F1 Micro: 0.7063, F1 Macro: 0.7058, Accuracy: 0.7063\n","Epoch 35, Train Loss: 0.5548, Val Loss: 0.5143, F1 Micro: 0.7344, F1 Macro: 0.7312, Accuracy: 0.7344\n","Epoch 36, Train Loss: 0.5469, Val Loss: 0.5107, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 37, Train Loss: 0.5555, Val Loss: 0.5193, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 38, Train Loss: 0.5542, Val Loss: 0.5248, F1 Micro: 0.7125, F1 Macro: 0.7116, Accuracy: 0.7125\n","Epoch 39, Train Loss: 0.5547, Val Loss: 0.5056, F1 Micro: 0.7219, F1 Macro: 0.7204, Accuracy: 0.7219\n","Epoch 40, Train Loss: 0.5487, Val Loss: 0.5250, F1 Micro: 0.7125, F1 Macro: 0.7114, Accuracy: 0.7125\n","Epoch 41, Train Loss: 0.5569, Val Loss: 0.5060, F1 Micro: 0.7188, F1 Macro: 0.7166, Accuracy: 0.7188\n","Epoch 42, Train Loss: 0.5548, Val Loss: 0.5048, F1 Micro: 0.7188, F1 Macro: 0.7172, Accuracy: 0.7188\n","Epoch 43, Train Loss: 0.5514, Val Loss: 0.5116, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 44, Train Loss: 0.5510, Val Loss: 0.5073, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 45, Train Loss: 0.5513, Val Loss: 0.5090, F1 Micro: 0.7188, F1 Macro: 0.7188, Accuracy: 0.7188\n","Epoch 46, Train Loss: 0.5505, Val Loss: 0.5085, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 47, Train Loss: 0.5498, Val Loss: 0.5005, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 48, Train Loss: 0.5554, Val Loss: 0.5068, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 49, Train Loss: 0.5543, Val Loss: 0.5055, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 50, Train Loss: 0.5476, Val Loss: 0.5135, F1 Micro: 0.7000, F1 Macro: 0.6996, Accuracy: 0.7000\n","Epoch 51, Train Loss: 0.5477, Val Loss: 0.4987, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 52, Train Loss: 0.5472, Val Loss: 0.5034, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 53, Train Loss: 0.5459, Val Loss: 0.5041, F1 Micro: 0.7312, F1 Macro: 0.7282, Accuracy: 0.7312\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6068, Val Loss: 0.5364, F1 Micro: 0.7375, F1 Macro: 0.7320, Accuracy: 0.7375\n","Epoch 2, Train Loss: 0.5839, Val Loss: 0.5650, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 3, Train Loss: 0.5734, Val Loss: 0.5538, F1 Micro: 0.7063, F1 Macro: 0.6867, Accuracy: 0.7063\n","Epoch 4, Train Loss: 0.5769, Val Loss: 0.5353, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 5, Train Loss: 0.5690, Val Loss: 0.5418, F1 Micro: 0.7125, F1 Macro: 0.6981, Accuracy: 0.7125\n","Epoch 6, Train Loss: 0.5650, Val Loss: 0.5379, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 7, Train Loss: 0.5717, Val Loss: 0.5359, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 8, Train Loss: 0.5664, Val Loss: 0.5466, F1 Micro: 0.7219, F1 Macro: 0.7209, Accuracy: 0.7219\n","Epoch 9, Train Loss: 0.5707, Val Loss: 0.5518, F1 Micro: 0.7063, F1 Macro: 0.7058, Accuracy: 0.7063\n","Epoch 10, Train Loss: 0.5679, Val Loss: 0.5341, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 11, Train Loss: 0.5646, Val Loss: 0.5349, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 12, Train Loss: 0.5586, Val Loss: 0.5356, F1 Micro: 0.7281, F1 Macro: 0.7205, Accuracy: 0.7281\n","Epoch 13, Train Loss: 0.5532, Val Loss: 0.5301, F1 Micro: 0.7219, F1 Macro: 0.7152, Accuracy: 0.7219\n","Epoch 14, Train Loss: 0.5641, Val Loss: 0.5456, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 15, Train Loss: 0.5617, Val Loss: 0.5345, F1 Micro: 0.7188, F1 Macro: 0.7155, Accuracy: 0.7188\n","Epoch 16, Train Loss: 0.5622, Val Loss: 0.5309, F1 Micro: 0.7250, F1 Macro: 0.7150, Accuracy: 0.7250\n","Epoch 17, Train Loss: 0.5597, Val Loss: 0.5297, F1 Micro: 0.7188, F1 Macro: 0.7092, Accuracy: 0.7188\n","Epoch 18, Train Loss: 0.5548, Val Loss: 0.5294, F1 Micro: 0.7281, F1 Macro: 0.7205, Accuracy: 0.7281\n","Epoch 19, Train Loss: 0.5559, Val Loss: 0.5399, F1 Micro: 0.7063, F1 Macro: 0.6906, Accuracy: 0.7063\n","Epoch 20, Train Loss: 0.5537, Val Loss: 0.5428, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 21, Train Loss: 0.5491, Val Loss: 0.5288, F1 Micro: 0.7156, F1 Macro: 0.7049, Accuracy: 0.7156\n","Epoch 22, Train Loss: 0.5546, Val Loss: 0.5430, F1 Micro: 0.7031, F1 Macro: 0.6868, Accuracy: 0.7031\n","Epoch 23, Train Loss: 0.5508, Val Loss: 0.5265, F1 Micro: 0.7250, F1 Macro: 0.7181, Accuracy: 0.7250\n","Epoch 24, Train Loss: 0.5540, Val Loss: 0.5377, F1 Micro: 0.7063, F1 Macro: 0.6906, Accuracy: 0.7063\n","Epoch 25, Train Loss: 0.5545, Val Loss: 0.5253, F1 Micro: 0.7250, F1 Macro: 0.7187, Accuracy: 0.7250\n","Epoch 26, Train Loss: 0.5524, Val Loss: 0.5490, F1 Micro: 0.7031, F1 Macro: 0.6849, Accuracy: 0.7031\n","Epoch 27, Train Loss: 0.5542, Val Loss: 0.5335, F1 Micro: 0.7188, F1 Macro: 0.7176, Accuracy: 0.7188\n","Epoch 28, Train Loss: 0.5522, Val Loss: 0.5582, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 29, Train Loss: 0.5491, Val Loss: 0.5300, F1 Micro: 0.7250, F1 Macro: 0.7163, Accuracy: 0.7250\n","Epoch 30, Train Loss: 0.5433, Val Loss: 0.5269, F1 Micro: 0.7312, F1 Macro: 0.7278, Accuracy: 0.7312\n","Epoch 31, Train Loss: 0.5488, Val Loss: 0.5314, F1 Micro: 0.7250, F1 Macro: 0.7239, Accuracy: 0.7250\n","Epoch 32, Train Loss: 0.5489, Val Loss: 0.5277, F1 Micro: 0.7156, F1 Macro: 0.7109, Accuracy: 0.7156\n","Epoch 33, Train Loss: 0.5441, Val Loss: 0.5320, F1 Micro: 0.7250, F1 Macro: 0.7163, Accuracy: 0.7250\n","Epoch 34, Train Loss: 0.5496, Val Loss: 0.5305, F1 Micro: 0.7156, F1 Macro: 0.7129, Accuracy: 0.7156\n","Epoch 35, Train Loss: 0.5484, Val Loss: 0.5229, F1 Micro: 0.7156, F1 Macro: 0.7104, Accuracy: 0.7156\n","Epoch 36, Train Loss: 0.5541, Val Loss: 0.5325, F1 Micro: 0.7344, F1 Macro: 0.7336, Accuracy: 0.7344\n","Epoch 37, Train Loss: 0.5464, Val Loss: 0.5290, F1 Micro: 0.7188, F1 Macro: 0.7174, Accuracy: 0.7188\n","Epoch 38, Train Loss: 0.5507, Val Loss: 0.5392, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 39, Train Loss: 0.5496, Val Loss: 0.5273, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 40, Train Loss: 0.5449, Val Loss: 0.5202, F1 Micro: 0.7188, F1 Macro: 0.7078, Accuracy: 0.7188\n","Epoch 41, Train Loss: 0.5431, Val Loss: 0.5289, F1 Micro: 0.7063, F1 Macro: 0.6915, Accuracy: 0.7063\n","Epoch 42, Train Loss: 0.5420, Val Loss: 0.5269, F1 Micro: 0.7063, F1 Macro: 0.6924, Accuracy: 0.7063\n","Epoch 43, Train Loss: 0.5442, Val Loss: 0.5187, F1 Micro: 0.7219, F1 Macro: 0.7114, Accuracy: 0.7219\n","Epoch 44, Train Loss: 0.5569, Val Loss: 0.5220, F1 Micro: 0.7344, F1 Macro: 0.7319, Accuracy: 0.7344\n","Epoch 45, Train Loss: 0.5478, Val Loss: 0.5174, F1 Micro: 0.7281, F1 Macro: 0.7244, Accuracy: 0.7281\n","Epoch 46, Train Loss: 0.5431, Val Loss: 0.5178, F1 Micro: 0.7281, F1 Macro: 0.7240, Accuracy: 0.7281\n","Epoch 47, Train Loss: 0.5443, Val Loss: 0.5666, F1 Micro: 0.6937, F1 Macro: 0.6914, Accuracy: 0.6937\n","Epoch 48, Train Loss: 0.5405, Val Loss: 0.5208, F1 Micro: 0.7312, F1 Macro: 0.7234, Accuracy: 0.7312\n","Epoch 49, Train Loss: 0.5426, Val Loss: 0.5423, F1 Micro: 0.7375, F1 Macro: 0.7375, Accuracy: 0.7375\n","Epoch 50, Train Loss: 0.5402, Val Loss: 0.5195, F1 Micro: 0.7281, F1 Macro: 0.7186, Accuracy: 0.7281\n","Epoch 51, Train Loss: 0.5429, Val Loss: 0.5152, F1 Micro: 0.7344, F1 Macro: 0.7257, Accuracy: 0.7344\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7518750000000001\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6181, Val Loss: 0.5561, F1 Micro: 0.6969, F1 Macro: 0.6883, Accuracy: 0.6969\n","Epoch 2, Train Loss: 0.5711, Val Loss: 0.5685, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 3, Train Loss: 0.5840, Val Loss: 0.6108, F1 Micro: 0.6875, F1 Macro: 0.6776, Accuracy: 0.6875\n","Epoch 4, Train Loss: 0.5741, Val Loss: 0.5519, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 5, Train Loss: 0.5690, Val Loss: 0.5519, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 6, Train Loss: 0.5581, Val Loss: 0.5478, F1 Micro: 0.7031, F1 Macro: 0.7007, Accuracy: 0.7031\n","Epoch 7, Train Loss: 0.5687, Val Loss: 0.5614, F1 Micro: 0.6813, F1 Macro: 0.6696, Accuracy: 0.6813\n","Epoch 8, Train Loss: 0.5538, Val Loss: 0.5654, F1 Micro: 0.7094, F1 Macro: 0.7086, Accuracy: 0.7094\n","Epoch 9, Train Loss: 0.5774, Val Loss: 0.6372, F1 Micro: 0.6344, F1 Macro: 0.5864, Accuracy: 0.6344\n","Epoch 10, Train Loss: 0.5593, Val Loss: 0.5510, F1 Micro: 0.6969, F1 Macro: 0.6908, Accuracy: 0.6969\n","Epoch 11, Train Loss: 0.5578, Val Loss: 0.5511, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 12, Train Loss: 0.5634, Val Loss: 0.5690, F1 Micro: 0.7000, F1 Macro: 0.6983, Accuracy: 0.7000\n","Epoch 13, Train Loss: 0.5690, Val Loss: 0.5800, F1 Micro: 0.6844, F1 Macro: 0.6650, Accuracy: 0.6844\n","Epoch 14, Train Loss: 0.5611, Val Loss: 0.5520, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6107, Val Loss: 0.5409, F1 Micro: 0.7281, F1 Macro: 0.7006, Accuracy: 0.7281\n","Epoch 2, Train Loss: 0.5736, Val Loss: 0.5243, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 3, Train Loss: 0.5696, Val Loss: 0.5407, F1 Micro: 0.7344, F1 Macro: 0.7087, Accuracy: 0.7344\n","Epoch 4, Train Loss: 0.5848, Val Loss: 0.5286, F1 Micro: 0.7281, F1 Macro: 0.7226, Accuracy: 0.7281\n","Epoch 5, Train Loss: 0.5730, Val Loss: 0.5241, F1 Micro: 0.7281, F1 Macro: 0.7231, Accuracy: 0.7281\n","Epoch 6, Train Loss: 0.5688, Val Loss: 0.5491, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 7, Train Loss: 0.5661, Val Loss: 0.5237, F1 Micro: 0.7406, F1 Macro: 0.7308, Accuracy: 0.7406\n","Epoch 8, Train Loss: 0.5870, Val Loss: 0.5504, F1 Micro: 0.7125, F1 Macro: 0.6800, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.5734, Val Loss: 0.5320, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 10, Train Loss: 0.5657, Val Loss: 0.5311, F1 Micro: 0.7312, F1 Macro: 0.7302, Accuracy: 0.7312\n","Epoch 11, Train Loss: 0.5713, Val Loss: 0.5540, F1 Micro: 0.6937, F1 Macro: 0.6936, Accuracy: 0.6937\n","Epoch 12, Train Loss: 0.5689, Val Loss: 0.5211, F1 Micro: 0.7406, F1 Macro: 0.7327, Accuracy: 0.7406\n","Epoch 13, Train Loss: 0.5621, Val Loss: 0.5363, F1 Micro: 0.7312, F1 Macro: 0.7093, Accuracy: 0.7312\n","Epoch 14, Train Loss: 0.5703, Val Loss: 0.5226, F1 Micro: 0.7406, F1 Macro: 0.7272, Accuracy: 0.7406\n","Epoch 15, Train Loss: 0.5621, Val Loss: 0.5370, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 16, Train Loss: 0.5579, Val Loss: 0.5204, F1 Micro: 0.7344, F1 Macro: 0.7257, Accuracy: 0.7344\n","Epoch 17, Train Loss: 0.5593, Val Loss: 0.5456, F1 Micro: 0.7250, F1 Macro: 0.6965, Accuracy: 0.7250\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6245, Val Loss: 0.6950, F1 Micro: 0.6125, F1 Macro: 0.6086, Accuracy: 0.6125\n","Epoch 2, Train Loss: 0.5717, Val Loss: 0.6550, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 3, Train Loss: 0.5438, Val Loss: 0.6385, F1 Micro: 0.6813, F1 Macro: 0.6588, Accuracy: 0.6813\n","Epoch 4, Train Loss: 0.5541, Val Loss: 0.6205, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 5, Train Loss: 0.5424, Val Loss: 0.6187, F1 Micro: 0.6875, F1 Macro: 0.6857, Accuracy: 0.6875\n","Epoch 6, Train Loss: 0.5494, Val Loss: 0.6482, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 7, Train Loss: 0.5480, Val Loss: 0.6246, F1 Micro: 0.6875, F1 Macro: 0.6857, Accuracy: 0.6875\n","Epoch 8, Train Loss: 0.5485, Val Loss: 0.6345, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 9, Train Loss: 0.5445, Val Loss: 0.6195, F1 Micro: 0.6875, F1 Macro: 0.6797, Accuracy: 0.6875\n","Epoch 10, Train Loss: 0.5407, Val Loss: 0.6610, F1 Micro: 0.6625, F1 Macro: 0.6625, Accuracy: 0.6625\n","Epoch 11, Train Loss: 0.5455, Val Loss: 0.6192, F1 Micro: 0.6937, F1 Macro: 0.6914, Accuracy: 0.6937\n","Epoch 12, Train Loss: 0.5481, Val Loss: 0.6132, F1 Micro: 0.6937, F1 Macro: 0.6914, Accuracy: 0.6937\n","Epoch 13, Train Loss: 0.5291, Val Loss: 0.6299, F1 Micro: 0.6813, F1 Macro: 0.6809, Accuracy: 0.6813\n","Epoch 14, Train Loss: 0.5400, Val Loss: 0.6236, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 15, Train Loss: 0.5462, Val Loss: 0.6170, F1 Micro: 0.6906, F1 Macro: 0.6884, Accuracy: 0.6906\n","Epoch 16, Train Loss: 0.5377, Val Loss: 0.6254, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 17, Train Loss: 0.5501, Val Loss: 0.6080, F1 Micro: 0.6906, F1 Macro: 0.6864, Accuracy: 0.6906\n","Epoch 18, Train Loss: 0.5395, Val Loss: 0.6601, F1 Micro: 0.6500, F1 Macro: 0.6491, Accuracy: 0.6500\n","Epoch 19, Train Loss: 0.5317, Val Loss: 0.6108, F1 Micro: 0.6875, F1 Macro: 0.6857, Accuracy: 0.6875\n","Epoch 20, Train Loss: 0.5320, Val Loss: 0.6176, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 21, Train Loss: 0.5358, Val Loss: 0.6083, F1 Micro: 0.6875, F1 Macro: 0.6783, Accuracy: 0.6875\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6170, Val Loss: 0.5367, F1 Micro: 0.7000, F1 Macro: 0.6994, Accuracy: 0.7000\n","Epoch 2, Train Loss: 0.6138, Val Loss: 0.5448, F1 Micro: 0.6844, F1 Macro: 0.6810, Accuracy: 0.6844\n","Epoch 3, Train Loss: 0.5639, Val Loss: 0.5905, F1 Micro: 0.7219, F1 Macro: 0.7028, Accuracy: 0.7219\n","Epoch 4, Train Loss: 0.5688, Val Loss: 0.5287, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 5, Train Loss: 0.5827, Val Loss: 0.6177, F1 Micro: 0.6594, F1 Macro: 0.6373, Accuracy: 0.6594\n","Epoch 6, Train Loss: 0.6047, Val Loss: 0.5465, F1 Micro: 0.7406, F1 Macro: 0.7363, Accuracy: 0.7406\n","Epoch 7, Train Loss: 0.5667, Val Loss: 0.5308, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 8, Train Loss: 0.5595, Val Loss: 0.5389, F1 Micro: 0.7125, F1 Macro: 0.7111, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.5734, Val Loss: 0.5616, F1 Micro: 0.6781, F1 Macro: 0.6697, Accuracy: 0.6781\n","Epoch 10, Train Loss: 0.5817, Val Loss: 0.5321, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 11, Train Loss: 0.5632, Val Loss: 0.5602, F1 Micro: 0.6781, F1 Macro: 0.6697, Accuracy: 0.6781\n","Epoch 12, Train Loss: 0.5625, Val Loss: 0.5313, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.5643, Val Loss: 0.5346, F1 Micro: 0.7312, F1 Macro: 0.7282, Accuracy: 0.7312\n","Epoch 14, Train Loss: 0.5583, Val Loss: 0.5248, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 15, Train Loss: 0.5557, Val Loss: 0.5490, F1 Micro: 0.6844, F1 Macro: 0.6801, Accuracy: 0.6844\n","Epoch 16, Train Loss: 0.5622, Val Loss: 0.5223, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6008, Val Loss: 0.5733, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 2, Train Loss: 0.5785, Val Loss: 0.5549, F1 Micro: 0.7031, F1 Macro: 0.6839, Accuracy: 0.7031\n","Epoch 3, Train Loss: 0.5782, Val Loss: 0.6896, F1 Micro: 0.6344, F1 Macro: 0.6106, Accuracy: 0.6344\n","Epoch 4, Train Loss: 0.5857, Val Loss: 0.5355, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 5, Train Loss: 0.5658, Val Loss: 0.5354, F1 Micro: 0.7188, F1 Macro: 0.7070, Accuracy: 0.7188\n","Epoch 6, Train Loss: 0.5796, Val Loss: 0.5715, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 7, Train Loss: 0.5829, Val Loss: 0.5509, F1 Micro: 0.7188, F1 Macro: 0.7174, Accuracy: 0.7188\n","Epoch 8, Train Loss: 0.5721, Val Loss: 0.6007, F1 Micro: 0.6906, F1 Macro: 0.6564, Accuracy: 0.6906\n","Epoch 9, Train Loss: 0.5668, Val Loss: 0.5380, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 10, Train Loss: 0.5609, Val Loss: 0.5346, F1 Micro: 0.7250, F1 Macro: 0.7181, Accuracy: 0.7250\n","Epoch 11, Train Loss: 0.5758, Val Loss: 0.5735, F1 Micro: 0.6875, F1 Macro: 0.6580, Accuracy: 0.6875\n","Epoch 12, Train Loss: 0.5598, Val Loss: 0.5429, F1 Micro: 0.7063, F1 Macro: 0.6897, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.5623, Val Loss: 0.5336, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 14, Train Loss: 0.5643, Val Loss: 0.5336, F1 Micro: 0.7219, F1 Macro: 0.7128, Accuracy: 0.7219\n","Epoch 15, Train Loss: 0.5592, Val Loss: 0.5316, F1 Micro: 0.7250, F1 Macro: 0.7163, Accuracy: 0.7250\n","Epoch 16, Train Loss: 0.5553, Val Loss: 0.5335, F1 Micro: 0.7312, F1 Macro: 0.7274, Accuracy: 0.7312\n","Epoch 17, Train Loss: 0.5671, Val Loss: 0.5327, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 18, Train Loss: 0.5550, Val Loss: 0.5356, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 19, Train Loss: 0.5547, Val Loss: 0.5346, F1 Micro: 0.7156, F1 Macro: 0.7129, Accuracy: 0.7156\n","Epoch 20, Train Loss: 0.5509, Val Loss: 0.5614, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 21, Train Loss: 0.5543, Val Loss: 0.5324, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 22, Train Loss: 0.5486, Val Loss: 0.5438, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 23, Train Loss: 0.5580, Val Loss: 0.5284, F1 Micro: 0.7281, F1 Macro: 0.7244, Accuracy: 0.7281\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.725625\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6538, Val Loss: 0.5506, F1 Micro: 0.7031, F1 Macro: 0.7007, Accuracy: 0.7031\n","Epoch 2, Train Loss: 0.5606, Val Loss: 0.5972, F1 Micro: 0.6719, F1 Macro: 0.6482, Accuracy: 0.6719\n","Epoch 3, Train Loss: 0.5742, Val Loss: 0.5633, F1 Micro: 0.6844, F1 Macro: 0.6725, Accuracy: 0.6844\n","Epoch 4, Train Loss: 0.5608, Val Loss: 0.5664, F1 Micro: 0.6844, F1 Macro: 0.6699, Accuracy: 0.6844\n","Epoch 5, Train Loss: 0.5624, Val Loss: 0.5567, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 6, Train Loss: 0.5765, Val Loss: 0.5502, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 7, Train Loss: 0.5683, Val Loss: 0.5494, F1 Micro: 0.7063, F1 Macro: 0.7036, Accuracy: 0.7063\n","Epoch 8, Train Loss: 0.5602, Val Loss: 0.5515, F1 Micro: 0.7000, F1 Macro: 0.6942, Accuracy: 0.7000\n","Epoch 9, Train Loss: 0.5716, Val Loss: 0.5471, F1 Micro: 0.7063, F1 Macro: 0.7040, Accuracy: 0.7063\n","Epoch 10, Train Loss: 0.5561, Val Loss: 0.5465, F1 Micro: 0.7063, F1 Macro: 0.7043, Accuracy: 0.7063\n","Epoch 11, Train Loss: 0.5649, Val Loss: 0.5692, F1 Micro: 0.6937, F1 Macro: 0.6784, Accuracy: 0.6937\n","Epoch 12, Train Loss: 0.5559, Val Loss: 0.5502, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 13, Train Loss: 0.5544, Val Loss: 0.5550, F1 Micro: 0.6969, F1 Macro: 0.6883, Accuracy: 0.6969\n","Epoch 14, Train Loss: 0.5612, Val Loss: 0.5734, F1 Micro: 0.6906, F1 Macro: 0.6736, Accuracy: 0.6906\n","Epoch 15, Train Loss: 0.5634, Val Loss: 0.5797, F1 Micro: 0.6844, F1 Macro: 0.6806, Accuracy: 0.6844\n","Epoch 16, Train Loss: 0.5581, Val Loss: 0.5870, F1 Micro: 0.6844, F1 Macro: 0.6650, Accuracy: 0.6844\n","Epoch 17, Train Loss: 0.5551, Val Loss: 0.5555, F1 Micro: 0.6937, F1 Macro: 0.6848, Accuracy: 0.6937\n","Epoch 18, Train Loss: 0.5513, Val Loss: 0.5461, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 19, Train Loss: 0.5477, Val Loss: 0.5472, F1 Micro: 0.6969, F1 Macro: 0.6928, Accuracy: 0.6969\n","Epoch 20, Train Loss: 0.5527, Val Loss: 0.5644, F1 Micro: 0.7125, F1 Macro: 0.7111, Accuracy: 0.7125\n","Epoch 21, Train Loss: 0.5517, Val Loss: 0.5567, F1 Micro: 0.6875, F1 Macro: 0.6776, Accuracy: 0.6875\n","Epoch 22, Train Loss: 0.5541, Val Loss: 0.5513, F1 Micro: 0.7156, F1 Macro: 0.7144, Accuracy: 0.7156\n","Epoch 23, Train Loss: 0.5558, Val Loss: 0.5429, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 24, Train Loss: 0.5570, Val Loss: 0.5420, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 25, Train Loss: 0.5419, Val Loss: 0.5408, F1 Micro: 0.7125, F1 Macro: 0.7114, Accuracy: 0.7125\n","Epoch 26, Train Loss: 0.5521, Val Loss: 0.5396, F1 Micro: 0.7156, F1 Macro: 0.7146, Accuracy: 0.7156\n","Epoch 27, Train Loss: 0.5455, Val Loss: 0.5426, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 28, Train Loss: 0.5533, Val Loss: 0.5441, F1 Micro: 0.6969, F1 Macro: 0.6940, Accuracy: 0.6969\n","Epoch 29, Train Loss: 0.5486, Val Loss: 0.5496, F1 Micro: 0.7000, F1 Macro: 0.6952, Accuracy: 0.7000\n","Epoch 30, Train Loss: 0.5437, Val Loss: 0.5775, F1 Micro: 0.6969, F1 Macro: 0.6812, Accuracy: 0.6969\n","Epoch 31, Train Loss: 0.5429, Val Loss: 0.5375, F1 Micro: 0.7094, F1 Macro: 0.7079, Accuracy: 0.7094\n","Epoch 32, Train Loss: 0.5470, Val Loss: 0.5382, F1 Micro: 0.7000, F1 Macro: 0.6977, Accuracy: 0.7000\n","Epoch 33, Train Loss: 0.5475, Val Loss: 0.5374, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 34, Train Loss: 0.5430, Val Loss: 0.5371, F1 Micro: 0.7125, F1 Macro: 0.7123, Accuracy: 0.7125\n","Epoch 35, Train Loss: 0.5401, Val Loss: 0.5364, F1 Micro: 0.7063, F1 Macro: 0.7049, Accuracy: 0.7063\n","Epoch 36, Train Loss: 0.5519, Val Loss: 0.5560, F1 Micro: 0.6875, F1 Macro: 0.6783, Accuracy: 0.6875\n","Epoch 37, Train Loss: 0.5397, Val Loss: 0.5393, F1 Micro: 0.7000, F1 Macro: 0.6973, Accuracy: 0.7000\n","Epoch 38, Train Loss: 0.5378, Val Loss: 0.5373, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 39, Train Loss: 0.5381, Val Loss: 0.5344, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 40, Train Loss: 0.5459, Val Loss: 0.5381, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 41, Train Loss: 0.5434, Val Loss: 0.5341, F1 Micro: 0.7094, F1 Macro: 0.7083, Accuracy: 0.7094\n","Epoch 42, Train Loss: 0.5414, Val Loss: 0.5718, F1 Micro: 0.6937, F1 Macro: 0.6818, Accuracy: 0.6937\n","Epoch 43, Train Loss: 0.5445, Val Loss: 0.5347, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 44, Train Loss: 0.5416, Val Loss: 0.5357, F1 Micro: 0.7094, F1 Macro: 0.7076, Accuracy: 0.7094\n","Epoch 45, Train Loss: 0.5411, Val Loss: 0.5438, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Epoch 46, Train Loss: 0.5390, Val Loss: 0.5662, F1 Micro: 0.6844, F1 Macro: 0.6755, Accuracy: 0.6844\n","Epoch 47, Train Loss: 0.5421, Val Loss: 0.5473, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 48, Train Loss: 0.5369, Val Loss: 0.5533, F1 Micro: 0.7156, F1 Macro: 0.7152, Accuracy: 0.7156\n","Epoch 49, Train Loss: 0.5435, Val Loss: 0.5354, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 50, Train Loss: 0.5365, Val Loss: 0.5363, F1 Micro: 0.7063, F1 Macro: 0.7025, Accuracy: 0.7063\n","Epoch 51, Train Loss: 0.5353, Val Loss: 0.5394, F1 Micro: 0.7000, F1 Macro: 0.6952, Accuracy: 0.7000\n","Epoch 52, Train Loss: 0.5346, Val Loss: 0.5301, F1 Micro: 0.7125, F1 Macro: 0.7111, Accuracy: 0.7125\n","Epoch 53, Train Loss: 0.5348, Val Loss: 0.5670, F1 Micro: 0.6875, F1 Macro: 0.6776, Accuracy: 0.6875\n","Epoch 54, Train Loss: 0.5319, Val Loss: 0.5360, F1 Micro: 0.7094, F1 Macro: 0.7063, Accuracy: 0.7094\n","Epoch 55, Train Loss: 0.5353, Val Loss: 0.5416, F1 Micro: 0.6937, F1 Macro: 0.6878, Accuracy: 0.6937\n","Epoch 56, Train Loss: 0.5275, Val Loss: 0.5588, F1 Micro: 0.7031, F1 Macro: 0.6954, Accuracy: 0.7031\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6051, Val Loss: 0.5893, F1 Micro: 0.7188, F1 Macro: 0.7163, Accuracy: 0.7188\n","Epoch 2, Train Loss: 0.5904, Val Loss: 0.5249, F1 Micro: 0.7469, F1 Macro: 0.7380, Accuracy: 0.7469\n","Epoch 3, Train Loss: 0.5669, Val Loss: 0.5204, F1 Micro: 0.7312, F1 Macro: 0.7245, Accuracy: 0.7312\n","Epoch 4, Train Loss: 0.5771, Val Loss: 0.5299, F1 Micro: 0.7406, F1 Macro: 0.7393, Accuracy: 0.7406\n","Epoch 5, Train Loss: 0.5693, Val Loss: 0.5725, F1 Micro: 0.7000, F1 Macro: 0.6990, Accuracy: 0.7000\n","Epoch 6, Train Loss: 0.5861, Val Loss: 0.5264, F1 Micro: 0.7406, F1 Macro: 0.7255, Accuracy: 0.7406\n","Epoch 7, Train Loss: 0.5638, Val Loss: 0.5318, F1 Micro: 0.7375, F1 Macro: 0.7171, Accuracy: 0.7375\n","Epoch 8, Train Loss: 0.5739, Val Loss: 0.5260, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 9, Train Loss: 0.5636, Val Loss: 0.5373, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 10, Train Loss: 0.5704, Val Loss: 0.5330, F1 Micro: 0.7406, F1 Macro: 0.7367, Accuracy: 0.7406\n","Epoch 11, Train Loss: 0.5674, Val Loss: 0.5223, F1 Micro: 0.7406, F1 Macro: 0.7327, Accuracy: 0.7406\n","Epoch 12, Train Loss: 0.5580, Val Loss: 0.5309, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 13, Train Loss: 0.5634, Val Loss: 0.5222, F1 Micro: 0.7375, F1 Macro: 0.7352, Accuracy: 0.7375\n","Epoch 14, Train Loss: 0.5608, Val Loss: 0.5243, F1 Micro: 0.7312, F1 Macro: 0.7143, Accuracy: 0.7312\n","Epoch 15, Train Loss: 0.5735, Val Loss: 0.5289, F1 Micro: 0.7156, F1 Macro: 0.7152, Accuracy: 0.7156\n","Epoch 16, Train Loss: 0.5622, Val Loss: 0.5269, F1 Micro: 0.7312, F1 Macro: 0.7114, Accuracy: 0.7312\n","Epoch 17, Train Loss: 0.5657, Val Loss: 0.5229, F1 Micro: 0.7438, F1 Macro: 0.7401, Accuracy: 0.7438\n","Epoch 18, Train Loss: 0.5596, Val Loss: 0.5469, F1 Micro: 0.7312, F1 Macro: 0.7047, Accuracy: 0.7312\n","Epoch 19, Train Loss: 0.5629, Val Loss: 0.5307, F1 Micro: 0.7281, F1 Macro: 0.7269, Accuracy: 0.7281\n","Epoch 20, Train Loss: 0.5548, Val Loss: 0.5307, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Epoch 21, Train Loss: 0.5594, Val Loss: 0.5353, F1 Micro: 0.7344, F1 Macro: 0.7121, Accuracy: 0.7344\n","Epoch 22, Train Loss: 0.5672, Val Loss: 0.6047, F1 Micro: 0.6781, F1 Macro: 0.6244, Accuracy: 0.6781\n","Epoch 23, Train Loss: 0.5714, Val Loss: 0.5272, F1 Micro: 0.7281, F1 Macro: 0.7085, Accuracy: 0.7281\n","Epoch 24, Train Loss: 0.5520, Val Loss: 0.5210, F1 Micro: 0.7375, F1 Macro: 0.7304, Accuracy: 0.7375\n","Epoch 25, Train Loss: 0.5537, Val Loss: 0.5207, F1 Micro: 0.7344, F1 Macro: 0.7308, Accuracy: 0.7344\n","Epoch 26, Train Loss: 0.5559, Val Loss: 0.5161, F1 Micro: 0.7312, F1 Macro: 0.7208, Accuracy: 0.7312\n","Epoch 27, Train Loss: 0.5563, Val Loss: 0.5546, F1 Micro: 0.7000, F1 Macro: 0.6994, Accuracy: 0.7000\n","Epoch 28, Train Loss: 0.5606, Val Loss: 0.5115, F1 Micro: 0.7375, F1 Macro: 0.7324, Accuracy: 0.7375\n","Epoch 29, Train Loss: 0.5539, Val Loss: 0.5312, F1 Micro: 0.7344, F1 Macro: 0.7132, Accuracy: 0.7344\n","Epoch 30, Train Loss: 0.5543, Val Loss: 0.5172, F1 Micro: 0.7281, F1 Macro: 0.7265, Accuracy: 0.7281\n","Epoch 31, Train Loss: 0.5583, Val Loss: 0.5302, F1 Micro: 0.7312, F1 Macro: 0.7114, Accuracy: 0.7312\n","Epoch 32, Train Loss: 0.5692, Val Loss: 0.5177, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 33, Train Loss: 0.5534, Val Loss: 0.5195, F1 Micro: 0.7250, F1 Macro: 0.7086, Accuracy: 0.7250\n","Epoch 34, Train Loss: 0.5516, Val Loss: 0.5161, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 35, Train Loss: 0.5514, Val Loss: 0.5099, F1 Micro: 0.7312, F1 Macro: 0.7265, Accuracy: 0.7312\n","Epoch 36, Train Loss: 0.5545, Val Loss: 0.5137, F1 Micro: 0.7344, F1 Macro: 0.7237, Accuracy: 0.7344\n","Epoch 37, Train Loss: 0.5504, Val Loss: 0.5165, F1 Micro: 0.7281, F1 Macro: 0.7210, Accuracy: 0.7281\n","Epoch 38, Train Loss: 0.5516, Val Loss: 0.5248, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 39, Train Loss: 0.5543, Val Loss: 0.5128, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 40, Train Loss: 0.5492, Val Loss: 0.5199, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 41, Train Loss: 0.5482, Val Loss: 0.5147, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 42, Train Loss: 0.5485, Val Loss: 0.5319, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 43, Train Loss: 0.5494, Val Loss: 0.5172, F1 Micro: 0.7250, F1 Macro: 0.7095, Accuracy: 0.7250\n","Epoch 44, Train Loss: 0.5484, Val Loss: 0.5134, F1 Micro: 0.7312, F1 Macro: 0.7208, Accuracy: 0.7312\n","Epoch 45, Train Loss: 0.5437, Val Loss: 0.5277, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 46, Train Loss: 0.5467, Val Loss: 0.5092, F1 Micro: 0.7375, F1 Macro: 0.7341, Accuracy: 0.7375\n","Epoch 47, Train Loss: 0.5511, Val Loss: 0.5061, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 48, Train Loss: 0.5453, Val Loss: 0.5389, F1 Micro: 0.6969, F1 Macro: 0.6966, Accuracy: 0.6969\n","Epoch 49, Train Loss: 0.5510, Val Loss: 0.5111, F1 Micro: 0.7312, F1 Macro: 0.7285, Accuracy: 0.7312\n","Epoch 50, Train Loss: 0.5497, Val Loss: 0.5142, F1 Micro: 0.7281, F1 Macro: 0.7140, Accuracy: 0.7281\n","Epoch 51, Train Loss: 0.5390, Val Loss: 0.5122, F1 Micro: 0.7063, F1 Macro: 0.7053, Accuracy: 0.7063\n","Epoch 52, Train Loss: 0.5424, Val Loss: 0.5101, F1 Micro: 0.7219, F1 Macro: 0.7199, Accuracy: 0.7219\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.5979, Val Loss: 0.6586, F1 Micro: 0.6594, F1 Macro: 0.6593, Accuracy: 0.6594\n","Epoch 2, Train Loss: 0.5527, Val Loss: 0.6147, F1 Micro: 0.6844, F1 Macro: 0.6761, Accuracy: 0.6844\n","Epoch 3, Train Loss: 0.5517, Val Loss: 0.6183, F1 Micro: 0.6937, F1 Macro: 0.6878, Accuracy: 0.6937\n","Epoch 4, Train Loss: 0.5534, Val Loss: 0.6278, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 5, Train Loss: 0.5544, Val Loss: 0.6270, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 6, Train Loss: 0.5408, Val Loss: 0.7050, F1 Micro: 0.6219, F1 Macro: 0.6187, Accuracy: 0.6219\n","Epoch 7, Train Loss: 0.5491, Val Loss: 0.6302, F1 Micro: 0.6844, F1 Macro: 0.6835, Accuracy: 0.6844\n","Epoch 8, Train Loss: 0.5512, Val Loss: 0.6203, F1 Micro: 0.6875, F1 Macro: 0.6860, Accuracy: 0.6875\n","Epoch 9, Train Loss: 0.5530, Val Loss: 0.6159, F1 Micro: 0.6937, F1 Macro: 0.6873, Accuracy: 0.6937\n","Epoch 10, Train Loss: 0.5504, Val Loss: 0.6200, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 11, Train Loss: 0.5483, Val Loss: 0.6137, F1 Micro: 0.6875, F1 Macro: 0.6839, Accuracy: 0.6875\n","Epoch 12, Train Loss: 0.5510, Val Loss: 0.6145, F1 Micro: 0.6906, F1 Macro: 0.6855, Accuracy: 0.6906\n","Epoch 13, Train Loss: 0.5371, Val Loss: 0.6531, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 14, Train Loss: 0.5481, Val Loss: 0.6653, F1 Micro: 0.6625, F1 Macro: 0.6619, Accuracy: 0.6625\n","Epoch 15, Train Loss: 0.5520, Val Loss: 0.6130, F1 Micro: 0.6875, F1 Macro: 0.6860, Accuracy: 0.6875\n","Epoch 16, Train Loss: 0.5487, Val Loss: 0.6138, F1 Micro: 0.6875, F1 Macro: 0.6854, Accuracy: 0.6875\n","Epoch 17, Train Loss: 0.5347, Val Loss: 0.6150, F1 Micro: 0.6875, F1 Macro: 0.6857, Accuracy: 0.6875\n","Epoch 18, Train Loss: 0.5390, Val Loss: 0.6248, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 19, Train Loss: 0.5349, Val Loss: 0.6128, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 20, Train Loss: 0.5393, Val Loss: 0.6675, F1 Micro: 0.6625, F1 Macro: 0.6624, Accuracy: 0.6625\n","Epoch 21, Train Loss: 0.5421, Val Loss: 0.6166, F1 Micro: 0.6719, F1 Macro: 0.6713, Accuracy: 0.6719\n","Epoch 22, Train Loss: 0.5442, Val Loss: 0.6360, F1 Micro: 0.6594, F1 Macro: 0.6593, Accuracy: 0.6594\n","Epoch 23, Train Loss: 0.5378, Val Loss: 0.5947, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 24, Train Loss: 0.5498, Val Loss: 0.6037, F1 Micro: 0.6875, F1 Macro: 0.6839, Accuracy: 0.6875\n","Epoch 25, Train Loss: 0.5397, Val Loss: 0.6189, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 26, Train Loss: 0.5413, Val Loss: 0.6158, F1 Micro: 0.6750, F1 Macro: 0.6640, Accuracy: 0.6750\n","Epoch 27, Train Loss: 0.5331, Val Loss: 0.6004, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 28, Train Loss: 0.5286, Val Loss: 0.6287, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 29, Train Loss: 0.5291, Val Loss: 0.6214, F1 Micro: 0.6687, F1 Macro: 0.6684, Accuracy: 0.6687\n","Epoch 30, Train Loss: 0.5380, Val Loss: 0.6096, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 31, Train Loss: 0.5329, Val Loss: 0.5899, F1 Micro: 0.6750, F1 Macro: 0.6725, Accuracy: 0.6750\n","Epoch 32, Train Loss: 0.5395, Val Loss: 0.5987, F1 Micro: 0.6844, F1 Macro: 0.6774, Accuracy: 0.6844\n","Epoch 33, Train Loss: 0.5339, Val Loss: 0.6145, F1 Micro: 0.6687, F1 Macro: 0.6684, Accuracy: 0.6687\n","Epoch 34, Train Loss: 0.5255, Val Loss: 0.6139, F1 Micro: 0.6813, F1 Macro: 0.6805, Accuracy: 0.6813\n","Epoch 35, Train Loss: 0.5280, Val Loss: 0.6195, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 36, Train Loss: 0.5276, Val Loss: 0.6462, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 37, Train Loss: 0.5384, Val Loss: 0.6119, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 38, Train Loss: 0.5307, Val Loss: 0.6050, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 39, Train Loss: 0.5279, Val Loss: 0.6007, F1 Micro: 0.6875, F1 Macro: 0.6843, Accuracy: 0.6875\n","Epoch 40, Train Loss: 0.5260, Val Loss: 0.6167, F1 Micro: 0.6719, F1 Macro: 0.6715, Accuracy: 0.6719\n","Epoch 41, Train Loss: 0.5290, Val Loss: 0.6090, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 42, Train Loss: 0.5238, Val Loss: 0.6217, F1 Micro: 0.6719, F1 Macro: 0.6716, Accuracy: 0.6719\n","Epoch 43, Train Loss: 0.5335, Val Loss: 0.6330, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 44, Train Loss: 0.5224, Val Loss: 0.6320, F1 Micro: 0.6625, F1 Macro: 0.6624, Accuracy: 0.6625\n","Epoch 45, Train Loss: 0.5233, Val Loss: 0.5970, F1 Micro: 0.6969, F1 Macro: 0.6890, Accuracy: 0.6969\n","Epoch 46, Train Loss: 0.5240, Val Loss: 0.6028, F1 Micro: 0.6719, F1 Macro: 0.6707, Accuracy: 0.6719\n","Epoch 47, Train Loss: 0.5246, Val Loss: 0.6048, F1 Micro: 0.6875, F1 Macro: 0.6860, Accuracy: 0.6875\n","Epoch 48, Train Loss: 0.5273, Val Loss: 0.6349, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 49, Train Loss: 0.5210, Val Loss: 0.6046, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 50, Train Loss: 0.5216, Val Loss: 0.6030, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 51, Train Loss: 0.5203, Val Loss: 0.6003, F1 Micro: 0.6906, F1 Macro: 0.6819, Accuracy: 0.6906\n","Epoch 52, Train Loss: 0.5325, Val Loss: 0.5957, F1 Micro: 0.6656, F1 Macro: 0.6651, Accuracy: 0.6656\n","Epoch 53, Train Loss: 0.5205, Val Loss: 0.5967, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 54, Train Loss: 0.5206, Val Loss: 0.5868, F1 Micro: 0.6781, F1 Macro: 0.6758, Accuracy: 0.6781\n","Epoch 55, Train Loss: 0.5210, Val Loss: 0.6096, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 56, Train Loss: 0.5200, Val Loss: 0.5891, F1 Micro: 0.6969, F1 Macro: 0.6902, Accuracy: 0.6969\n","Epoch 57, Train Loss: 0.5218, Val Loss: 0.5959, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 58, Train Loss: 0.5305, Val Loss: 0.5940, F1 Micro: 0.6594, F1 Macro: 0.6593, Accuracy: 0.6594\n","Epoch 59, Train Loss: 0.5249, Val Loss: 0.6108, F1 Micro: 0.6719, F1 Macro: 0.6716, Accuracy: 0.6719\n","Epoch 60, Train Loss: 0.5148, Val Loss: 0.5939, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 61, Train Loss: 0.5157, Val Loss: 0.5974, F1 Micro: 0.6781, F1 Macro: 0.6770, Accuracy: 0.6781\n","Epoch 62, Train Loss: 0.5206, Val Loss: 0.5850, F1 Micro: 0.6781, F1 Macro: 0.6767, Accuracy: 0.6781\n","Epoch 63, Train Loss: 0.5180, Val Loss: 0.5901, F1 Micro: 0.6875, F1 Macro: 0.6857, Accuracy: 0.6875\n","Epoch 64, Train Loss: 0.5181, Val Loss: 0.6063, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 65, Train Loss: 0.5184, Val Loss: 0.5821, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 66, Train Loss: 0.5221, Val Loss: 0.5856, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 67, Train Loss: 0.5166, Val Loss: 0.5997, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 68, Train Loss: 0.5085, Val Loss: 0.5945, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 69, Train Loss: 0.5253, Val Loss: 0.5975, F1 Micro: 0.6719, F1 Macro: 0.6712, Accuracy: 0.6719\n","Epoch 70, Train Loss: 0.5174, Val Loss: 0.5910, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 71, Train Loss: 0.5109, Val Loss: 0.6055, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 72, Train Loss: 0.5168, Val Loss: 0.5834, F1 Micro: 0.6875, F1 Macro: 0.6835, Accuracy: 0.6875\n","Epoch 73, Train Loss: 0.5180, Val Loss: 0.6013, F1 Micro: 0.6781, F1 Macro: 0.6776, Accuracy: 0.6781\n","Epoch 74, Train Loss: 0.5075, Val Loss: 0.5936, F1 Micro: 0.6875, F1 Macro: 0.6854, Accuracy: 0.6875\n","Epoch 75, Train Loss: 0.5066, Val Loss: 0.5930, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 76, Train Loss: 0.5217, Val Loss: 0.5848, F1 Micro: 0.6875, F1 Macro: 0.6865, Accuracy: 0.6875\n","Epoch 77, Train Loss: 0.5141, Val Loss: 0.5916, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 78, Train Loss: 0.5150, Val Loss: 0.5949, F1 Micro: 0.6625, F1 Macro: 0.6624, Accuracy: 0.6625\n","Epoch 79, Train Loss: 0.5087, Val Loss: 0.6079, F1 Micro: 0.6625, F1 Macro: 0.6609, Accuracy: 0.6625\n","Epoch 80, Train Loss: 0.5159, Val Loss: 0.5908, F1 Micro: 0.6875, F1 Macro: 0.6872, Accuracy: 0.6875\n","Epoch 81, Train Loss: 0.5081, Val Loss: 0.6307, F1 Micro: 0.6625, F1 Macro: 0.6624, Accuracy: 0.6625\n","Epoch 82, Train Loss: 0.5168, Val Loss: 0.5961, F1 Micro: 0.6750, F1 Macro: 0.6745, Accuracy: 0.6750\n","Epoch 83, Train Loss: 0.5185, Val Loss: 0.5952, F1 Micro: 0.6625, F1 Macro: 0.6624, Accuracy: 0.6625\n","Epoch 84, Train Loss: 0.5023, Val Loss: 0.6523, F1 Micro: 0.6375, F1 Macro: 0.6323, Accuracy: 0.6375\n","Epoch 85, Train Loss: 0.5156, Val Loss: 0.5941, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 86, Train Loss: 0.5104, Val Loss: 0.5869, F1 Micro: 0.6719, F1 Macro: 0.6715, Accuracy: 0.6719\n","Epoch 87, Train Loss: 0.5099, Val Loss: 0.5839, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 88, Train Loss: 0.5205, Val Loss: 0.5914, F1 Micro: 0.6781, F1 Macro: 0.6774, Accuracy: 0.6781\n","Epoch 89, Train Loss: 0.5126, Val Loss: 0.6054, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 90, Train Loss: 0.5014, Val Loss: 0.5761, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 91, Train Loss: 0.5178, Val Loss: 0.5917, F1 Micro: 0.6969, F1 Macro: 0.6908, Accuracy: 0.6969\n","Epoch 92, Train Loss: 0.5176, Val Loss: 0.5702, F1 Micro: 0.6781, F1 Macro: 0.6767, Accuracy: 0.6781\n","Epoch 93, Train Loss: 0.5048, Val Loss: 0.5766, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 94, Train Loss: 0.5182, Val Loss: 0.5773, F1 Micro: 0.6844, F1 Macro: 0.6833, Accuracy: 0.6844\n","Epoch 95, Train Loss: 0.5031, Val Loss: 0.5752, F1 Micro: 0.7000, F1 Macro: 0.6957, Accuracy: 0.7000\n","Epoch 96, Train Loss: 0.4992, Val Loss: 0.5731, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 97, Train Loss: 0.5167, Val Loss: 0.5914, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 98, Train Loss: 0.5087, Val Loss: 0.5793, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 99, Train Loss: 0.5027, Val Loss: 0.6163, F1 Micro: 0.6594, F1 Macro: 0.6582, Accuracy: 0.6594\n","Epoch 100, Train Loss: 0.5000, Val Loss: 0.5965, F1 Micro: 0.7000, F1 Macro: 0.6942, Accuracy: 0.7000\n","Epoch 101, Train Loss: 0.5104, Val Loss: 0.5714, F1 Micro: 0.6937, F1 Macro: 0.6937, Accuracy: 0.6937\n","Epoch 102, Train Loss: 0.4979, Val Loss: 0.6207, F1 Micro: 0.7031, F1 Macro: 0.6960, Accuracy: 0.7031\n","Epoch 103, Train Loss: 0.5069, Val Loss: 0.5731, F1 Micro: 0.6937, F1 Macro: 0.6923, Accuracy: 0.6937\n","Epoch 104, Train Loss: 0.5043, Val Loss: 0.5841, F1 Micro: 0.6781, F1 Macro: 0.6770, Accuracy: 0.6781\n","Epoch 105, Train Loss: 0.5018, Val Loss: 0.6044, F1 Micro: 0.6656, F1 Macro: 0.6654, Accuracy: 0.6656\n","Epoch 106, Train Loss: 0.5008, Val Loss: 0.5825, F1 Micro: 0.6844, F1 Macro: 0.6835, Accuracy: 0.6844\n","Epoch 107, Train Loss: 0.4969, Val Loss: 0.5840, F1 Micro: 0.6750, F1 Macro: 0.6745, Accuracy: 0.6750\n","Epoch 108, Train Loss: 0.4985, Val Loss: 0.6001, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 109, Train Loss: 0.4993, Val Loss: 0.5935, F1 Micro: 0.6937, F1 Macro: 0.6917, Accuracy: 0.6937\n","Epoch 110, Train Loss: 0.5023, Val Loss: 0.5812, F1 Micro: 0.6781, F1 Macro: 0.6777, Accuracy: 0.6781\n","Epoch 111, Train Loss: 0.4981, Val Loss: 0.5797, F1 Micro: 0.6781, F1 Macro: 0.6779, Accuracy: 0.6781\n","Epoch 112, Train Loss: 0.5084, Val Loss: 0.5713, F1 Micro: 0.6875, F1 Macro: 0.6863, Accuracy: 0.6875\n","Epoch 113, Train Loss: 0.4976, Val Loss: 0.5907, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 114, Train Loss: 0.4972, Val Loss: 0.6050, F1 Micro: 0.6687, F1 Macro: 0.6669, Accuracy: 0.6687\n","Epoch 115, Train Loss: 0.4989, Val Loss: 0.5770, F1 Micro: 0.6719, F1 Macro: 0.6716, Accuracy: 0.6719\n","Epoch 116, Train Loss: 0.4973, Val Loss: 0.5659, F1 Micro: 0.6813, F1 Macro: 0.6806, Accuracy: 0.6813\n","Epoch 117, Train Loss: 0.5003, Val Loss: 0.5801, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 118, Train Loss: 0.5014, Val Loss: 0.5753, F1 Micro: 0.6750, F1 Macro: 0.6745, Accuracy: 0.6750\n","Epoch 119, Train Loss: 0.4966, Val Loss: 0.5731, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 120, Train Loss: 0.4946, Val Loss: 0.5643, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 121, Train Loss: 0.4950, Val Loss: 0.5899, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 122, Train Loss: 0.5026, Val Loss: 0.5930, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 123, Train Loss: 0.4968, Val Loss: 0.6091, F1 Micro: 0.6813, F1 Macro: 0.6794, Accuracy: 0.6813\n","Epoch 124, Train Loss: 0.4955, Val Loss: 0.5890, F1 Micro: 0.6875, F1 Macro: 0.6869, Accuracy: 0.6875\n","Epoch 125, Train Loss: 0.4961, Val Loss: 0.5818, F1 Micro: 0.7000, F1 Macro: 0.6962, Accuracy: 0.7000\n","Epoch 126, Train Loss: 0.4890, Val Loss: 0.5952, F1 Micro: 0.6813, F1 Macro: 0.6809, Accuracy: 0.6813\n","Epoch 127, Train Loss: 0.5040, Val Loss: 0.6280, F1 Micro: 0.6500, F1 Macro: 0.6473, Accuracy: 0.6500\n","Epoch 128, Train Loss: 0.4933, Val Loss: 0.5597, F1 Micro: 0.6875, F1 Macro: 0.6860, Accuracy: 0.6875\n","Epoch 129, Train Loss: 0.5020, Val Loss: 0.5825, F1 Micro: 0.6844, F1 Macro: 0.6837, Accuracy: 0.6844\n","Epoch 130, Train Loss: 0.4959, Val Loss: 0.5792, F1 Micro: 0.6844, F1 Macro: 0.6841, Accuracy: 0.6844\n","Epoch 131, Train Loss: 0.4913, Val Loss: 0.5644, F1 Micro: 0.6906, F1 Macro: 0.6897, Accuracy: 0.6906\n","Epoch 132, Train Loss: 0.4898, Val Loss: 0.5914, F1 Micro: 0.6781, F1 Macro: 0.6765, Accuracy: 0.6781\n","Epoch 133, Train Loss: 0.4867, Val Loss: 0.5631, F1 Micro: 0.6906, F1 Macro: 0.6890, Accuracy: 0.6906\n","Epoch 134, Train Loss: 0.4940, Val Loss: 0.5812, F1 Micro: 0.6906, F1 Macro: 0.6881, Accuracy: 0.6906\n","Epoch 135, Train Loss: 0.5089, Val Loss: 0.5724, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 136, Train Loss: 0.4863, Val Loss: 0.5855, F1 Micro: 0.7000, F1 Macro: 0.6977, Accuracy: 0.7000\n","Epoch 137, Train Loss: 0.5001, Val Loss: 0.5878, F1 Micro: 0.7031, F1 Macro: 0.7007, Accuracy: 0.7031\n","Epoch 138, Train Loss: 0.4972, Val Loss: 0.5643, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 139, Train Loss: 0.4979, Val Loss: 0.5914, F1 Micro: 0.6937, F1 Macro: 0.6914, Accuracy: 0.6937\n","Epoch 140, Train Loss: 0.4896, Val Loss: 0.5748, F1 Micro: 0.7063, F1 Macro: 0.7001, Accuracy: 0.7063\n","Epoch 141, Train Loss: 0.4838, Val Loss: 0.5541, F1 Micro: 0.6906, F1 Macro: 0.6893, Accuracy: 0.6906\n","Epoch 142, Train Loss: 0.4820, Val Loss: 0.6162, F1 Micro: 0.7125, F1 Macro: 0.7027, Accuracy: 0.7125\n","Epoch 143, Train Loss: 0.4928, Val Loss: 0.5656, F1 Micro: 0.6813, F1 Macro: 0.6809, Accuracy: 0.6813\n","Epoch 144, Train Loss: 0.4821, Val Loss: 0.5556, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 145, Train Loss: 0.4961, Val Loss: 0.5959, F1 Micro: 0.7000, F1 Macro: 0.6957, Accuracy: 0.7000\n","Epoch 146, Train Loss: 0.4937, Val Loss: 0.5788, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 147, Train Loss: 0.4807, Val Loss: 0.5806, F1 Micro: 0.6813, F1 Macro: 0.6812, Accuracy: 0.6813\n","Epoch 148, Train Loss: 0.4777, Val Loss: 0.5796, F1 Micro: 0.6937, F1 Macro: 0.6894, Accuracy: 0.6937\n","Epoch 149, Train Loss: 0.4830, Val Loss: 0.5598, F1 Micro: 0.6844, F1 Macro: 0.6841, Accuracy: 0.6844\n","Epoch 150, Train Loss: 0.4747, Val Loss: 0.5501, F1 Micro: 0.7063, F1 Macro: 0.7049, Accuracy: 0.7063\n","Epoch 151, Train Loss: 0.4881, Val Loss: 0.5592, F1 Micro: 0.6969, F1 Macro: 0.6962, Accuracy: 0.6969\n","Epoch 152, Train Loss: 0.4869, Val Loss: 0.5634, F1 Micro: 0.6906, F1 Macro: 0.6897, Accuracy: 0.6906\n","Epoch 153, Train Loss: 0.4885, Val Loss: 0.5666, F1 Micro: 0.6969, F1 Macro: 0.6969, Accuracy: 0.6969\n","Epoch 154, Train Loss: 0.4794, Val Loss: 0.6085, F1 Micro: 0.7188, F1 Macro: 0.7105, Accuracy: 0.7188\n","Epoch 155, Train Loss: 0.4956, Val Loss: 0.5667, F1 Micro: 0.6906, F1 Macro: 0.6881, Accuracy: 0.6906\n","Epoch 156, Train Loss: 0.4849, Val Loss: 0.5863, F1 Micro: 0.6969, F1 Macro: 0.6947, Accuracy: 0.6969\n","Epoch 157, Train Loss: 0.4806, Val Loss: 0.5545, F1 Micro: 0.6906, F1 Macro: 0.6906, Accuracy: 0.6906\n","Epoch 158, Train Loss: 0.4877, Val Loss: 0.5647, F1 Micro: 0.6969, F1 Macro: 0.6962, Accuracy: 0.6969\n","Epoch 159, Train Loss: 0.4906, Val Loss: 0.5793, F1 Micro: 0.6906, F1 Macro: 0.6877, Accuracy: 0.6906\n","Epoch 160, Train Loss: 0.4875, Val Loss: 0.5549, F1 Micro: 0.7219, F1 Macro: 0.7192, Accuracy: 0.7219\n","Epoch 161, Train Loss: 0.4824, Val Loss: 0.5721, F1 Micro: 0.7063, F1 Macro: 0.7051, Accuracy: 0.7063\n","Epoch 162, Train Loss: 0.4911, Val Loss: 0.5806, F1 Micro: 0.7094, F1 Macro: 0.7045, Accuracy: 0.7094\n","Epoch 163, Train Loss: 0.4851, Val Loss: 0.5537, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 164, Train Loss: 0.4835, Val Loss: 0.5747, F1 Micro: 0.7125, F1 Macro: 0.7070, Accuracy: 0.7125\n","Epoch 165, Train Loss: 0.4806, Val Loss: 0.5805, F1 Micro: 0.7094, F1 Macro: 0.7045, Accuracy: 0.7094\n","Epoch 166, Train Loss: 0.4808, Val Loss: 0.5775, F1 Micro: 0.7063, F1 Macro: 0.7055, Accuracy: 0.7063\n","Epoch 167, Train Loss: 0.4851, Val Loss: 0.5729, F1 Micro: 0.6875, F1 Macro: 0.6865, Accuracy: 0.6875\n","Epoch 168, Train Loss: 0.4871, Val Loss: 0.5659, F1 Micro: 0.7063, F1 Macro: 0.7057, Accuracy: 0.7063\n","Epoch 169, Train Loss: 0.4877, Val Loss: 0.5502, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 170, Train Loss: 0.4752, Val Loss: 0.5877, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 171, Train Loss: 0.4778, Val Loss: 0.5700, F1 Micro: 0.7312, F1 Macro: 0.7221, Accuracy: 0.7312\n","Epoch 172, Train Loss: 0.4824, Val Loss: 0.6109, F1 Micro: 0.7094, F1 Macro: 0.7040, Accuracy: 0.7094\n","Epoch 173, Train Loss: 0.4966, Val Loss: 0.5624, F1 Micro: 0.7031, F1 Macro: 0.7013, Accuracy: 0.7031\n","Epoch 174, Train Loss: 0.4753, Val Loss: 0.5687, F1 Micro: 0.6969, F1 Macro: 0.6944, Accuracy: 0.6969\n","Epoch 175, Train Loss: 0.4764, Val Loss: 0.5593, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 176, Train Loss: 0.4674, Val Loss: 0.5679, F1 Micro: 0.7000, F1 Macro: 0.6977, Accuracy: 0.7000\n","Epoch 177, Train Loss: 0.4830, Val Loss: 0.6737, F1 Micro: 0.6500, F1 Macro: 0.6241, Accuracy: 0.6500\n","Epoch 178, Train Loss: 0.4867, Val Loss: 0.5706, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 179, Train Loss: 0.4831, Val Loss: 0.5639, F1 Micro: 0.7063, F1 Macro: 0.7025, Accuracy: 0.7063\n","Epoch 180, Train Loss: 0.4694, Val Loss: 0.5700, F1 Micro: 0.7031, F1 Macro: 0.6986, Accuracy: 0.7031\n","Epoch 181, Train Loss: 0.4712, Val Loss: 0.5504, F1 Micro: 0.7219, F1 Macro: 0.7209, Accuracy: 0.7219\n","Epoch 182, Train Loss: 0.4654, Val Loss: 0.5514, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 183, Train Loss: 0.4875, Val Loss: 0.5654, F1 Micro: 0.7000, F1 Macro: 0.6980, Accuracy: 0.7000\n","Epoch 184, Train Loss: 0.4947, Val Loss: 0.5576, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 185, Train Loss: 0.4835, Val Loss: 0.5533, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 186, Train Loss: 0.4892, Val Loss: 0.5517, F1 Micro: 0.7219, F1 Macro: 0.7185, Accuracy: 0.7219\n","Epoch 187, Train Loss: 0.4772, Val Loss: 0.5564, F1 Micro: 0.7406, F1 Macro: 0.7405, Accuracy: 0.7406\n","Epoch 188, Train Loss: 0.4772, Val Loss: 0.5491, F1 Micro: 0.7250, F1 Macro: 0.7239, Accuracy: 0.7250\n","Epoch 189, Train Loss: 0.4753, Val Loss: 0.5802, F1 Micro: 0.7281, F1 Macro: 0.7198, Accuracy: 0.7281\n","Epoch 190, Train Loss: 0.4741, Val Loss: 0.5587, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 191, Train Loss: 0.4734, Val Loss: 0.5665, F1 Micro: 0.7156, F1 Macro: 0.7126, Accuracy: 0.7156\n","Epoch 192, Train Loss: 0.4734, Val Loss: 0.5956, F1 Micro: 0.6813, F1 Macro: 0.6772, Accuracy: 0.6813\n","Epoch 193, Train Loss: 0.4769, Val Loss: 0.5711, F1 Micro: 0.7063, F1 Macro: 0.7036, Accuracy: 0.7063\n","Epoch 194, Train Loss: 0.4608, Val Loss: 0.5563, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 195, Train Loss: 0.4843, Val Loss: 0.5486, F1 Micro: 0.7125, F1 Macro: 0.7119, Accuracy: 0.7125\n","Epoch 196, Train Loss: 0.4757, Val Loss: 0.5548, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 197, Train Loss: 0.4791, Val Loss: 0.5526, F1 Micro: 0.7219, F1 Macro: 0.7213, Accuracy: 0.7219\n","Epoch 198, Train Loss: 0.4733, Val Loss: 0.5570, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 199, Train Loss: 0.4714, Val Loss: 0.5664, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 200, Train Loss: 0.4731, Val Loss: 0.5742, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6141, Val Loss: 0.5504, F1 Micro: 0.6906, F1 Macro: 0.6864, Accuracy: 0.6906\n","Epoch 2, Train Loss: 0.5893, Val Loss: 0.5466, F1 Micro: 0.6844, F1 Macro: 0.6810, Accuracy: 0.6844\n","Epoch 3, Train Loss: 0.5779, Val Loss: 0.5424, F1 Micro: 0.6937, F1 Macro: 0.6910, Accuracy: 0.6937\n","Epoch 4, Train Loss: 0.5624, Val Loss: 0.5292, F1 Micro: 0.7312, F1 Macro: 0.7307, Accuracy: 0.7312\n","Epoch 5, Train Loss: 0.5794, Val Loss: 0.5326, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 6, Train Loss: 0.5771, Val Loss: 0.5842, F1 Micro: 0.6719, F1 Macro: 0.6578, Accuracy: 0.6719\n","Epoch 7, Train Loss: 0.5825, Val Loss: 0.5303, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 8, Train Loss: 0.5659, Val Loss: 0.5293, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.5583, Val Loss: 0.5330, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 10, Train Loss: 0.5672, Val Loss: 0.5284, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 11, Train Loss: 0.5638, Val Loss: 0.5451, F1 Micro: 0.7469, F1 Macro: 0.7422, Accuracy: 0.7469\n","Epoch 12, Train Loss: 0.5663, Val Loss: 0.5253, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 13, Train Loss: 0.5668, Val Loss: 0.5302, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 14, Train Loss: 0.5628, Val Loss: 0.5323, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 15, Train Loss: 0.5617, Val Loss: 0.5309, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 16, Train Loss: 0.5585, Val Loss: 0.5345, F1 Micro: 0.7094, F1 Macro: 0.7083, Accuracy: 0.7094\n","Epoch 17, Train Loss: 0.5628, Val Loss: 0.5258, F1 Micro: 0.7250, F1 Macro: 0.7229, Accuracy: 0.7250\n","Epoch 18, Train Loss: 0.5626, Val Loss: 0.5255, F1 Micro: 0.7188, F1 Macro: 0.7169, Accuracy: 0.7188\n","Epoch 19, Train Loss: 0.5586, Val Loss: 0.5218, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 20, Train Loss: 0.5599, Val Loss: 0.5254, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 21, Train Loss: 0.5549, Val Loss: 0.5347, F1 Micro: 0.7063, F1 Macro: 0.7049, Accuracy: 0.7063\n","Epoch 22, Train Loss: 0.5613, Val Loss: 0.5287, F1 Micro: 0.7219, F1 Macro: 0.7192, Accuracy: 0.7219\n","Epoch 23, Train Loss: 0.5616, Val Loss: 0.5242, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 24, Train Loss: 0.5655, Val Loss: 0.5437, F1 Micro: 0.6844, F1 Macro: 0.6806, Accuracy: 0.6844\n","Epoch 25, Train Loss: 0.5633, Val Loss: 0.5181, F1 Micro: 0.7250, F1 Macro: 0.7241, Accuracy: 0.7250\n","Epoch 26, Train Loss: 0.5538, Val Loss: 0.5211, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 27, Train Loss: 0.5494, Val Loss: 0.5483, F1 Micro: 0.6844, F1 Macro: 0.6791, Accuracy: 0.6844\n","Epoch 28, Train Loss: 0.5553, Val Loss: 0.5302, F1 Micro: 0.6969, F1 Macro: 0.6953, Accuracy: 0.6969\n","Epoch 29, Train Loss: 0.5550, Val Loss: 0.5159, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 30, Train Loss: 0.5540, Val Loss: 0.5424, F1 Micro: 0.6844, F1 Macro: 0.6806, Accuracy: 0.6844\n","Epoch 31, Train Loss: 0.5548, Val Loss: 0.5182, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 32, Train Loss: 0.5601, Val Loss: 0.5151, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 33, Train Loss: 0.5576, Val Loss: 0.5453, F1 Micro: 0.6844, F1 Macro: 0.6796, Accuracy: 0.6844\n","Epoch 34, Train Loss: 0.5517, Val Loss: 0.5196, F1 Micro: 0.7031, F1 Macro: 0.7029, Accuracy: 0.7031\n","Epoch 35, Train Loss: 0.5489, Val Loss: 0.5386, F1 Micro: 0.6906, F1 Macro: 0.6873, Accuracy: 0.6906\n","Epoch 36, Train Loss: 0.5530, Val Loss: 0.5272, F1 Micro: 0.7156, F1 Macro: 0.7148, Accuracy: 0.7156\n","Epoch 37, Train Loss: 0.5552, Val Loss: 0.5111, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 38, Train Loss: 0.5474, Val Loss: 0.5108, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 39, Train Loss: 0.5540, Val Loss: 0.5177, F1 Micro: 0.7031, F1 Macro: 0.7029, Accuracy: 0.7031\n","Epoch 40, Train Loss: 0.5530, Val Loss: 0.5112, F1 Micro: 0.7188, F1 Macro: 0.7166, Accuracy: 0.7188\n","Epoch 41, Train Loss: 0.5574, Val Loss: 0.5107, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 42, Train Loss: 0.5453, Val Loss: 0.5322, F1 Micro: 0.6937, F1 Macro: 0.6914, Accuracy: 0.6937\n","Epoch 43, Train Loss: 0.5492, Val Loss: 0.5063, F1 Micro: 0.7219, F1 Macro: 0.7213, Accuracy: 0.7219\n","Epoch 44, Train Loss: 0.5532, Val Loss: 0.5090, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 45, Train Loss: 0.5511, Val Loss: 0.5215, F1 Micro: 0.7469, F1 Macro: 0.7431, Accuracy: 0.7469\n","Epoch 46, Train Loss: 0.5466, Val Loss: 0.5067, F1 Micro: 0.7219, F1 Macro: 0.7204, Accuracy: 0.7219\n","Epoch 47, Train Loss: 0.5544, Val Loss: 0.5511, F1 Micro: 0.7469, F1 Macro: 0.7330, Accuracy: 0.7469\n","Epoch 48, Train Loss: 0.5480, Val Loss: 0.5052, F1 Micro: 0.7281, F1 Macro: 0.7274, Accuracy: 0.7281\n","Epoch 49, Train Loss: 0.5545, Val Loss: 0.5179, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 50, Train Loss: 0.5429, Val Loss: 0.5068, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 51, Train Loss: 0.5488, Val Loss: 0.5045, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 52, Train Loss: 0.5539, Val Loss: 0.5111, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 53, Train Loss: 0.5441, Val Loss: 0.5109, F1 Micro: 0.7156, F1 Macro: 0.7141, Accuracy: 0.7156\n","Epoch 54, Train Loss: 0.5529, Val Loss: 0.5069, F1 Micro: 0.7188, F1 Macro: 0.7166, Accuracy: 0.7188\n","Epoch 55, Train Loss: 0.5492, Val Loss: 0.5076, F1 Micro: 0.7125, F1 Macro: 0.7106, Accuracy: 0.7125\n","Epoch 56, Train Loss: 0.5483, Val Loss: 0.5071, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 57, Train Loss: 0.5473, Val Loss: 0.5047, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 58, Train Loss: 0.5438, Val Loss: 0.5118, F1 Micro: 0.7000, F1 Macro: 0.6998, Accuracy: 0.7000\n","Epoch 59, Train Loss: 0.5532, Val Loss: 0.5037, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 60, Train Loss: 0.5433, Val Loss: 0.5201, F1 Micro: 0.6969, F1 Macro: 0.6947, Accuracy: 0.6969\n","Epoch 61, Train Loss: 0.5560, Val Loss: 0.5202, F1 Micro: 0.7500, F1 Macro: 0.7452, Accuracy: 0.7500\n","Epoch 62, Train Loss: 0.5447, Val Loss: 0.5015, F1 Micro: 0.7281, F1 Macro: 0.7274, Accuracy: 0.7281\n","Epoch 63, Train Loss: 0.5444, Val Loss: 0.5016, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 64, Train Loss: 0.5477, Val Loss: 0.4974, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 65, Train Loss: 0.5467, Val Loss: 0.5114, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 66, Train Loss: 0.5483, Val Loss: 0.4966, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 67, Train Loss: 0.5411, Val Loss: 0.4965, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 68, Train Loss: 0.5420, Val Loss: 0.4953, F1 Micro: 0.7250, F1 Macro: 0.7234, Accuracy: 0.7250\n","Epoch 69, Train Loss: 0.5416, Val Loss: 0.4978, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 70, Train Loss: 0.5389, Val Loss: 0.4949, F1 Micro: 0.7312, F1 Macro: 0.7306, Accuracy: 0.7312\n","Epoch 71, Train Loss: 0.5464, Val Loss: 0.4940, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 72, Train Loss: 0.5448, Val Loss: 0.4944, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 73, Train Loss: 0.5492, Val Loss: 0.4997, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 74, Train Loss: 0.5423, Val Loss: 0.5041, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 75, Train Loss: 0.5373, Val Loss: 0.4918, F1 Micro: 0.7188, F1 Macro: 0.7169, Accuracy: 0.7188\n","Epoch 76, Train Loss: 0.5417, Val Loss: 0.4954, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 77, Train Loss: 0.5333, Val Loss: 0.4957, F1 Micro: 0.7281, F1 Macro: 0.7280, Accuracy: 0.7281\n","Epoch 78, Train Loss: 0.5414, Val Loss: 0.4908, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 79, Train Loss: 0.5378, Val Loss: 0.4881, F1 Micro: 0.7125, F1 Macro: 0.7106, Accuracy: 0.7125\n","Epoch 80, Train Loss: 0.5330, Val Loss: 0.4868, F1 Micro: 0.7188, F1 Macro: 0.7186, Accuracy: 0.7188\n","Epoch 81, Train Loss: 0.5414, Val Loss: 0.4883, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 82, Train Loss: 0.5344, Val Loss: 0.4911, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 83, Train Loss: 0.5363, Val Loss: 0.4869, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 84, Train Loss: 0.5404, Val Loss: 0.4884, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 85, Train Loss: 0.5391, Val Loss: 0.4910, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 86, Train Loss: 0.5379, Val Loss: 0.5040, F1 Micro: 0.7656, F1 Macro: 0.7579, Accuracy: 0.7656\n","Epoch 87, Train Loss: 0.5433, Val Loss: 0.4838, F1 Micro: 0.7312, F1 Macro: 0.7304, Accuracy: 0.7312\n","Epoch 88, Train Loss: 0.5365, Val Loss: 0.5072, F1 Micro: 0.7125, F1 Macro: 0.7114, Accuracy: 0.7125\n","Epoch 89, Train Loss: 0.5385, Val Loss: 0.5094, F1 Micro: 0.7156, F1 Macro: 0.7144, Accuracy: 0.7156\n","Epoch 90, Train Loss: 0.5337, Val Loss: 0.4917, F1 Micro: 0.7312, F1 Macro: 0.7309, Accuracy: 0.7312\n","Epoch 91, Train Loss: 0.5374, Val Loss: 0.4864, F1 Micro: 0.7344, F1 Macro: 0.7339, Accuracy: 0.7344\n","Epoch 92, Train Loss: 0.5348, Val Loss: 0.4809, F1 Micro: 0.7250, F1 Macro: 0.7232, Accuracy: 0.7250\n","Epoch 93, Train Loss: 0.5380, Val Loss: 0.5383, F1 Micro: 0.7031, F1 Macro: 0.6986, Accuracy: 0.7031\n","Epoch 94, Train Loss: 0.5503, Val Loss: 0.4995, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 95, Train Loss: 0.5354, Val Loss: 0.5076, F1 Micro: 0.7125, F1 Macro: 0.7114, Accuracy: 0.7125\n","Epoch 96, Train Loss: 0.5363, Val Loss: 0.5010, F1 Micro: 0.7094, F1 Macro: 0.7091, Accuracy: 0.7094\n","Epoch 97, Train Loss: 0.5440, Val Loss: 0.4862, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 98, Train Loss: 0.5317, Val Loss: 0.4828, F1 Micro: 0.7344, F1 Macro: 0.7336, Accuracy: 0.7344\n","Epoch 99, Train Loss: 0.5360, Val Loss: 0.4844, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 100, Train Loss: 0.5263, Val Loss: 0.4758, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 101, Train Loss: 0.5324, Val Loss: 0.4809, F1 Micro: 0.7344, F1 Macro: 0.7315, Accuracy: 0.7344\n","Epoch 102, Train Loss: 0.5289, Val Loss: 0.4783, F1 Micro: 0.7344, F1 Macro: 0.7315, Accuracy: 0.7344\n","Epoch 103, Train Loss: 0.5328, Val Loss: 0.4855, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 104, Train Loss: 0.5338, Val Loss: 0.4743, F1 Micro: 0.7312, F1 Macro: 0.7297, Accuracy: 0.7312\n","Epoch 105, Train Loss: 0.5261, Val Loss: 0.4858, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 106, Train Loss: 0.5341, Val Loss: 0.4781, F1 Micro: 0.7344, F1 Macro: 0.7343, Accuracy: 0.7344\n","Epoch 107, Train Loss: 0.5298, Val Loss: 0.4828, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 108, Train Loss: 0.5323, Val Loss: 0.4840, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 109, Train Loss: 0.5344, Val Loss: 0.4786, F1 Micro: 0.7438, F1 Macro: 0.7429, Accuracy: 0.7438\n","Epoch 110, Train Loss: 0.5322, Val Loss: 0.4885, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 111, Train Loss: 0.5298, Val Loss: 0.4777, F1 Micro: 0.7562, F1 Macro: 0.7551, Accuracy: 0.7562\n","Epoch 112, Train Loss: 0.5308, Val Loss: 0.4717, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 113, Train Loss: 0.5250, Val Loss: 0.4698, F1 Micro: 0.7469, F1 Macro: 0.7442, Accuracy: 0.7469\n","Epoch 114, Train Loss: 0.5333, Val Loss: 0.4677, F1 Micro: 0.7375, F1 Macro: 0.7368, Accuracy: 0.7375\n","Epoch 115, Train Loss: 0.5305, Val Loss: 0.4713, F1 Micro: 0.7406, F1 Macro: 0.7375, Accuracy: 0.7406\n","Epoch 116, Train Loss: 0.5249, Val Loss: 0.4975, F1 Micro: 0.7125, F1 Macro: 0.7114, Accuracy: 0.7125\n","Epoch 117, Train Loss: 0.5381, Val Loss: 0.5016, F1 Micro: 0.7094, F1 Macro: 0.7089, Accuracy: 0.7094\n","Epoch 118, Train Loss: 0.5269, Val Loss: 0.4770, F1 Micro: 0.7594, F1 Macro: 0.7585, Accuracy: 0.7594\n","Epoch 119, Train Loss: 0.5347, Val Loss: 0.5192, F1 Micro: 0.7125, F1 Macro: 0.7075, Accuracy: 0.7125\n","Epoch 120, Train Loss: 0.5308, Val Loss: 0.4805, F1 Micro: 0.7438, F1 Macro: 0.7401, Accuracy: 0.7438\n","Epoch 121, Train Loss: 0.5277, Val Loss: 0.4732, F1 Micro: 0.7438, F1 Macro: 0.7429, Accuracy: 0.7438\n","Epoch 122, Train Loss: 0.5316, Val Loss: 0.4737, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 123, Train Loss: 0.5303, Val Loss: 0.4983, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 124, Train Loss: 0.5348, Val Loss: 0.4879, F1 Micro: 0.7250, F1 Macro: 0.7248, Accuracy: 0.7250\n","Epoch 125, Train Loss: 0.5275, Val Loss: 0.4713, F1 Micro: 0.7406, F1 Macro: 0.7397, Accuracy: 0.7406\n","Epoch 126, Train Loss: 0.5249, Val Loss: 0.4736, F1 Micro: 0.7562, F1 Macro: 0.7516, Accuracy: 0.7562\n","Epoch 127, Train Loss: 0.5336, Val Loss: 0.4823, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 128, Train Loss: 0.5369, Val Loss: 0.4732, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 129, Train Loss: 0.5309, Val Loss: 0.4762, F1 Micro: 0.7344, F1 Macro: 0.7343, Accuracy: 0.7344\n","Epoch 130, Train Loss: 0.5216, Val Loss: 0.4654, F1 Micro: 0.7438, F1 Macro: 0.7427, Accuracy: 0.7438\n","Epoch 131, Train Loss: 0.5186, Val Loss: 0.4645, F1 Micro: 0.7531, F1 Macro: 0.7494, Accuracy: 0.7531\n","Epoch 132, Train Loss: 0.5230, Val Loss: 0.4657, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 133, Train Loss: 0.5317, Val Loss: 0.5032, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 134, Train Loss: 0.5264, Val Loss: 0.4650, F1 Micro: 0.7594, F1 Macro: 0.7554, Accuracy: 0.7594\n","Epoch 135, Train Loss: 0.5228, Val Loss: 0.4582, F1 Micro: 0.7594, F1 Macro: 0.7568, Accuracy: 0.7594\n","Epoch 136, Train Loss: 0.5254, Val Loss: 0.4656, F1 Micro: 0.7375, F1 Macro: 0.7348, Accuracy: 0.7375\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6187, Val Loss: 0.5445, F1 Micro: 0.7063, F1 Macro: 0.6897, Accuracy: 0.7063\n","Epoch 2, Train Loss: 0.5789, Val Loss: 0.5399, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 3, Train Loss: 0.5636, Val Loss: 0.5444, F1 Micro: 0.7156, F1 Macro: 0.7129, Accuracy: 0.7156\n","Epoch 4, Train Loss: 0.5765, Val Loss: 0.5378, F1 Micro: 0.7125, F1 Macro: 0.6981, Accuracy: 0.7125\n","Epoch 5, Train Loss: 0.5793, Val Loss: 0.5380, F1 Micro: 0.7125, F1 Macro: 0.6981, Accuracy: 0.7125\n","Epoch 6, Train Loss: 0.5699, Val Loss: 0.5410, F1 Micro: 0.7250, F1 Macro: 0.7211, Accuracy: 0.7250\n","Epoch 7, Train Loss: 0.5705, Val Loss: 0.5460, F1 Micro: 0.7094, F1 Macro: 0.6925, Accuracy: 0.7094\n","Epoch 8, Train Loss: 0.5674, Val Loss: 0.5367, F1 Micro: 0.7125, F1 Macro: 0.6981, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.5597, Val Loss: 0.5492, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 10, Train Loss: 0.5633, Val Loss: 0.5373, F1 Micro: 0.7281, F1 Macro: 0.7240, Accuracy: 0.7281\n","Epoch 11, Train Loss: 0.5615, Val Loss: 0.5366, F1 Micro: 0.7344, F1 Macro: 0.7290, Accuracy: 0.7344\n","Epoch 12, Train Loss: 0.5568, Val Loss: 0.5363, F1 Micro: 0.7188, F1 Macro: 0.7151, Accuracy: 0.7188\n","Epoch 13, Train Loss: 0.5812, Val Loss: 0.5320, F1 Micro: 0.7312, F1 Macro: 0.7234, Accuracy: 0.7312\n","Epoch 14, Train Loss: 0.5668, Val Loss: 0.5425, F1 Micro: 0.7156, F1 Macro: 0.7141, Accuracy: 0.7156\n","Epoch 15, Train Loss: 0.5542, Val Loss: 0.5326, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 16, Train Loss: 0.5619, Val Loss: 0.5368, F1 Micro: 0.7188, F1 Macro: 0.7155, Accuracy: 0.7188\n","Epoch 17, Train Loss: 0.5628, Val Loss: 0.5502, F1 Micro: 0.7031, F1 Macro: 0.6839, Accuracy: 0.7031\n","Epoch 18, Train Loss: 0.5655, Val Loss: 0.5390, F1 Micro: 0.7063, F1 Macro: 0.6906, Accuracy: 0.7063\n","Epoch 19, Train Loss: 0.5658, Val Loss: 0.5412, F1 Micro: 0.7063, F1 Macro: 0.6897, Accuracy: 0.7063\n","Epoch 20, Train Loss: 0.5592, Val Loss: 0.5300, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 21, Train Loss: 0.5664, Val Loss: 0.5336, F1 Micro: 0.7188, F1 Macro: 0.7155, Accuracy: 0.7188\n","Epoch 22, Train Loss: 0.5535, Val Loss: 0.5303, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 23, Train Loss: 0.5596, Val Loss: 0.5309, F1 Micro: 0.7219, F1 Macro: 0.7185, Accuracy: 0.7219\n","Epoch 24, Train Loss: 0.5478, Val Loss: 0.5281, F1 Micro: 0.7250, F1 Macro: 0.7163, Accuracy: 0.7250\n","Epoch 25, Train Loss: 0.5449, Val Loss: 0.5292, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 26, Train Loss: 0.5583, Val Loss: 0.5347, F1 Micro: 0.7219, F1 Macro: 0.7189, Accuracy: 0.7219\n","Epoch 27, Train Loss: 0.5511, Val Loss: 0.5287, F1 Micro: 0.7219, F1 Macro: 0.7114, Accuracy: 0.7219\n","Epoch 28, Train Loss: 0.5458, Val Loss: 0.5266, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 29, Train Loss: 0.5531, Val Loss: 0.5463, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 30, Train Loss: 0.5483, Val Loss: 0.5297, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 31, Train Loss: 0.5494, Val Loss: 0.5319, F1 Micro: 0.7094, F1 Macro: 0.6961, Accuracy: 0.7094\n","Epoch 32, Train Loss: 0.5571, Val Loss: 0.5246, F1 Micro: 0.7281, F1 Macro: 0.7240, Accuracy: 0.7281\n","Epoch 33, Train Loss: 0.5521, Val Loss: 0.5258, F1 Micro: 0.7250, F1 Macro: 0.7219, Accuracy: 0.7250\n","Epoch 34, Train Loss: 0.5654, Val Loss: 0.5372, F1 Micro: 0.7094, F1 Macro: 0.6943, Accuracy: 0.7094\n","Epoch 35, Train Loss: 0.5587, Val Loss: 0.5443, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 36, Train Loss: 0.5559, Val Loss: 0.5290, F1 Micro: 0.7188, F1 Macro: 0.7163, Accuracy: 0.7188\n","Epoch 37, Train Loss: 0.5477, Val Loss: 0.5254, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 38, Train Loss: 0.5439, Val Loss: 0.5320, F1 Micro: 0.7063, F1 Macro: 0.6915, Accuracy: 0.7063\n","Epoch 39, Train Loss: 0.5456, Val Loss: 0.5231, F1 Micro: 0.7250, F1 Macro: 0.7175, Accuracy: 0.7250\n","Epoch 40, Train Loss: 0.5521, Val Loss: 0.5322, F1 Micro: 0.7094, F1 Macro: 0.7086, Accuracy: 0.7094\n","Epoch 41, Train Loss: 0.5461, Val Loss: 0.5675, F1 Micro: 0.6969, F1 Macro: 0.6956, Accuracy: 0.6969\n","Epoch 42, Train Loss: 0.5490, Val Loss: 0.5278, F1 Micro: 0.7219, F1 Macro: 0.7199, Accuracy: 0.7219\n","Epoch 43, Train Loss: 0.5395, Val Loss: 0.5288, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 44, Train Loss: 0.5441, Val Loss: 0.5201, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 45, Train Loss: 0.5399, Val Loss: 0.5496, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 46, Train Loss: 0.5488, Val Loss: 0.5683, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 47, Train Loss: 0.5498, Val Loss: 0.5242, F1 Micro: 0.7219, F1 Macro: 0.7114, Accuracy: 0.7219\n","Epoch 48, Train Loss: 0.5494, Val Loss: 0.5226, F1 Micro: 0.7219, F1 Macro: 0.7189, Accuracy: 0.7219\n","Epoch 49, Train Loss: 0.5455, Val Loss: 0.5243, F1 Micro: 0.7156, F1 Macro: 0.7034, Accuracy: 0.7156\n","Epoch 50, Train Loss: 0.5438, Val Loss: 0.5232, F1 Micro: 0.7188, F1 Macro: 0.7163, Accuracy: 0.7188\n","Epoch 51, Train Loss: 0.5424, Val Loss: 0.5223, F1 Micro: 0.7219, F1 Macro: 0.7177, Accuracy: 0.7219\n","Epoch 52, Train Loss: 0.5430, Val Loss: 0.5213, F1 Micro: 0.7250, F1 Macro: 0.7215, Accuracy: 0.7250\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7431249999999999\n","Best hyperparameters for Outer FOLD 3: (0.01, 8, 50) with score 0.825\n","Epoch 1, Train Loss: 0.7492, Val Loss: 0.5867, F1 Micro: 0.6525, F1 Macro: 0.6511, Accuracy: 0.6525\n","Epoch 2, Train Loss: 0.6056, Val Loss: 0.6440, F1 Micro: 0.6625, F1 Macro: 0.6191, Accuracy: 0.6625\n","Epoch 3, Train Loss: 0.6075, Val Loss: 0.6772, F1 Micro: 0.5750, F1 Macro: 0.5330, Accuracy: 0.5750\n","Epoch 4, Train Loss: 0.5801, Val Loss: 0.6589, F1 Micro: 0.6525, F1 Macro: 0.6511, Accuracy: 0.6525\n","Epoch 5, Train Loss: 0.5865, Val Loss: 0.5997, F1 Micro: 0.6575, F1 Macro: 0.6539, Accuracy: 0.6575\n","Epoch 6, Train Loss: 0.6138, Val Loss: 0.6437, F1 Micro: 0.6500, F1 Macro: 0.6402, Accuracy: 0.6500\n","Epoch 7, Train Loss: 0.6043, Val Loss: 0.6075, F1 Micro: 0.6525, F1 Macro: 0.6484, Accuracy: 0.6525\n","Epoch 8, Train Loss: 0.6435, Val Loss: 0.6419, F1 Micro: 0.6350, F1 Macro: 0.6051, Accuracy: 0.6350\n","Epoch 9, Train Loss: 0.6089, Val Loss: 0.5834, F1 Micro: 0.6475, F1 Macro: 0.6472, Accuracy: 0.6475\n","Epoch 10, Train Loss: 0.5945, Val Loss: 0.7833, F1 Micro: 0.6175, F1 Macro: 0.5976, Accuracy: 0.6175\n","Epoch 11, Train Loss: 0.5878, Val Loss: 0.5857, F1 Micro: 0.6450, F1 Macro: 0.6338, Accuracy: 0.6450\n","Epoch 12, Train Loss: 0.5760, Val Loss: 0.5946, F1 Micro: 0.6300, F1 Macro: 0.6112, Accuracy: 0.6300\n","Epoch 13, Train Loss: 0.5841, Val Loss: 0.5861, F1 Micro: 0.6400, F1 Macro: 0.6305, Accuracy: 0.6400\n","Epoch 14, Train Loss: 0.6076, Val Loss: 0.5970, F1 Micro: 0.6525, F1 Macro: 0.6509, Accuracy: 0.6525\n","Epoch 15, Train Loss: 0.6118, Val Loss: 0.6288, F1 Micro: 0.6350, F1 Macro: 0.6190, Accuracy: 0.6350\n","Epoch 16, Train Loss: 0.6063, Val Loss: 0.6063, F1 Micro: 0.6350, F1 Macro: 0.6074, Accuracy: 0.6350\n","Epoch 17, Train Loss: 0.5897, Val Loss: 0.6058, F1 Micro: 0.6525, F1 Macro: 0.6515, Accuracy: 0.6525\n","Epoch 18, Train Loss: 0.5857, Val Loss: 0.6348, F1 Micro: 0.6450, F1 Macro: 0.6324, Accuracy: 0.6450\n","Epoch 19, Train Loss: 0.5677, Val Loss: 0.6212, F1 Micro: 0.6400, F1 Macro: 0.6272, Accuracy: 0.6400\n","Epoch 20, Train Loss: 0.5956, Val Loss: 0.6666, F1 Micro: 0.6475, F1 Macro: 0.6402, Accuracy: 0.6475\n","Epoch 21, Train Loss: 0.5770, Val Loss: 0.5746, F1 Micro: 0.6500, F1 Macro: 0.6444, Accuracy: 0.6500\n","Epoch 22, Train Loss: 0.5849, Val Loss: 0.5889, F1 Micro: 0.6550, F1 Macro: 0.6550, Accuracy: 0.6550\n","Epoch 23, Train Loss: 0.6090, Val Loss: 0.7952, F1 Micro: 0.6500, F1 Macro: 0.6500, Accuracy: 0.6500\n","Epoch 24, Train Loss: 0.7760, Val Loss: 0.6219, F1 Micro: 0.6575, F1 Macro: 0.6413, Accuracy: 0.6575\n","Epoch 25, Train Loss: 0.7073, Val Loss: 0.6180, F1 Micro: 0.6825, F1 Macro: 0.6229, Accuracy: 0.6825\n","Epoch 26, Train Loss: 0.6501, Val Loss: 0.5680, F1 Micro: 0.6400, F1 Macro: 0.6258, Accuracy: 0.6400\n","Epoch 27, Train Loss: 0.5872, Val Loss: 0.9598, F1 Micro: 0.6000, F1 Macro: 0.5660, Accuracy: 0.6000\n","Epoch 28, Train Loss: 0.6243, Val Loss: 0.5446, F1 Micro: 0.6525, F1 Macro: 0.6504, Accuracy: 0.6525\n","Epoch 29, Train Loss: 0.6021, Val Loss: 0.9538, F1 Micro: 0.6700, F1 Macro: 0.6596, Accuracy: 0.6700\n","Epoch 30, Train Loss: 0.6072, Val Loss: 0.6476, F1 Micro: 0.6275, F1 Macro: 0.6032, Accuracy: 0.6275\n","Epoch 31, Train Loss: 0.5989, Val Loss: 0.6059, F1 Micro: 0.6700, F1 Macro: 0.6700, Accuracy: 0.6700\n","Epoch 32, Train Loss: 0.5878, Val Loss: 0.5476, F1 Micro: 0.6600, F1 Macro: 0.6480, Accuracy: 0.6600\n","Epoch 33, Train Loss: 0.5627, Val Loss: 0.5895, F1 Micro: 0.6925, F1 Macro: 0.6922, Accuracy: 0.6925\n","Epoch 34, Train Loss: 0.5486, Val Loss: 0.5771, F1 Micro: 0.6725, F1 Macro: 0.6642, Accuracy: 0.6725\n","Epoch 35, Train Loss: 0.5476, Val Loss: 0.5660, F1 Micro: 0.7325, F1 Macro: 0.7056, Accuracy: 0.7325\n","Epoch 36, Train Loss: 0.5752, Val Loss: 0.5450, F1 Micro: 0.6825, F1 Macro: 0.6728, Accuracy: 0.6825\n","Epoch 37, Train Loss: 0.5380, Val Loss: 0.5040, F1 Micro: 0.7225, F1 Macro: 0.7087, Accuracy: 0.7225\n","Epoch 38, Train Loss: 0.6042, Val Loss: 0.5210, F1 Micro: 0.7325, F1 Macro: 0.7238, Accuracy: 0.7325\n","Epoch 39, Train Loss: 0.5511, Val Loss: 0.5021, F1 Micro: 0.7025, F1 Macro: 0.6972, Accuracy: 0.7025\n","Epoch 40, Train Loss: 0.5454, Val Loss: 0.4916, F1 Micro: 0.7150, F1 Macro: 0.6917, Accuracy: 0.7150\n","Epoch 41, Train Loss: 0.5176, Val Loss: 0.5282, F1 Micro: 0.7275, F1 Macro: 0.7029, Accuracy: 0.7275\n","Epoch 42, Train Loss: 0.5156, Val Loss: 0.5052, F1 Micro: 0.7300, F1 Macro: 0.7300, Accuracy: 0.7300\n","Epoch 43, Train Loss: 0.5723, Val Loss: 0.8413, F1 Micro: 0.4925, F1 Macro: 0.3944, Accuracy: 0.4925\n","Epoch 44, Train Loss: 0.5672, Val Loss: 0.7651, F1 Micro: 0.7025, F1 Macro: 0.6499, Accuracy: 0.7025\n","Epoch 45, Train Loss: 0.5344, Val Loss: 0.4399, F1 Micro: 0.7550, F1 Macro: 0.7394, Accuracy: 0.7550\n","Epoch 46, Train Loss: 0.5357, Val Loss: 0.6429, F1 Micro: 0.7050, F1 Macro: 0.6982, Accuracy: 0.7050\n","Epoch 47, Train Loss: 0.5411, Val Loss: 0.4421, F1 Micro: 0.7775, F1 Macro: 0.7689, Accuracy: 0.7775\n","Epoch 48, Train Loss: 0.5208, Val Loss: 0.4976, F1 Micro: 0.7675, F1 Macro: 0.7675, Accuracy: 0.7675\n","Epoch 49, Train Loss: 0.4914, Val Loss: 0.5184, F1 Micro: 0.7125, F1 Macro: 0.7117, Accuracy: 0.7125\n","Epoch 50, Train Loss: 0.5479, Val Loss: 0.4514, F1 Micro: 0.7325, F1 Macro: 0.7102, Accuracy: 0.7325\n","Epoch 51, Train Loss: 0.5240, Val Loss: 0.5977, F1 Micro: 0.6800, F1 Macro: 0.6687, Accuracy: 0.6800\n","Epoch 52, Train Loss: 0.4986, Val Loss: 0.4396, F1 Micro: 0.7350, F1 Macro: 0.7188, Accuracy: 0.7350\n","Epoch 53, Train Loss: 0.5714, Val Loss: 0.8191, F1 Micro: 0.6925, F1 Macro: 0.6847, Accuracy: 0.6925\n","Epoch 54, Train Loss: 0.5713, Val Loss: 0.5803, F1 Micro: 0.7150, F1 Macro: 0.7144, Accuracy: 0.7150\n","Epoch 55, Train Loss: 0.4749, Val Loss: 0.4832, F1 Micro: 0.7800, F1 Macro: 0.7742, Accuracy: 0.7800\n","Epoch 56, Train Loss: 0.5270, Val Loss: 0.4327, F1 Micro: 0.7575, F1 Macro: 0.7449, Accuracy: 0.7575\n","Epoch 57, Train Loss: 0.4965, Val Loss: 0.5223, F1 Micro: 0.7425, F1 Macro: 0.7278, Accuracy: 0.7425\n","Epoch 58, Train Loss: 0.5679, Val Loss: 0.5003, F1 Micro: 0.7375, F1 Macro: 0.7204, Accuracy: 0.7375\n","Epoch 59, Train Loss: 0.5067, Val Loss: 0.4479, F1 Micro: 0.8150, F1 Macro: 0.8135, Accuracy: 0.8150\n","Epoch 60, Train Loss: 0.5320, Val Loss: 0.4747, F1 Micro: 0.8375, F1 Macro: 0.8375, Accuracy: 0.8375\n","Epoch 61, Train Loss: 0.5036, Val Loss: 1.1740, F1 Micro: 0.4875, F1 Macro: 0.3884, Accuracy: 0.4875\n","Epoch 62, Train Loss: 0.5353, Val Loss: 0.6450, F1 Micro: 0.6950, F1 Macro: 0.6854, Accuracy: 0.6950\n","Epoch 63, Train Loss: 0.5005, Val Loss: 0.4809, F1 Micro: 0.7275, F1 Macro: 0.7126, Accuracy: 0.7275\n","Epoch 64, Train Loss: 0.5265, Val Loss: 0.4599, F1 Micro: 0.7450, F1 Macro: 0.7257, Accuracy: 0.7450\n","Epoch 65, Train Loss: 0.5258, Val Loss: 0.4501, F1 Micro: 0.7450, F1 Macro: 0.7257, Accuracy: 0.7450\n","Epoch 66, Train Loss: 0.5442, Val Loss: 0.5473, F1 Micro: 0.7075, F1 Macro: 0.7062, Accuracy: 0.7075\n","Epoch 67, Train Loss: 0.5194, Val Loss: 0.4394, F1 Micro: 0.8350, F1 Macro: 0.8345, Accuracy: 0.8350\n","Epoch 68, Train Loss: 0.5054, Val Loss: 0.5265, F1 Micro: 0.7750, F1 Macro: 0.7743, Accuracy: 0.7750\n","Epoch 69, Train Loss: 0.4974, Val Loss: 0.4493, F1 Micro: 0.7375, F1 Macro: 0.7173, Accuracy: 0.7375\n","Epoch 70, Train Loss: 0.5186, Val Loss: 0.8511, F1 Micro: 0.6275, F1 Macro: 0.5999, Accuracy: 0.6275\n","Epoch 71, Train Loss: 0.5000, Val Loss: 0.4715, F1 Micro: 0.7375, F1 Macro: 0.7101, Accuracy: 0.7375\n","Epoch 72, Train Loss: 0.5075, Val Loss: 0.5748, F1 Micro: 0.7025, F1 Macro: 0.6499, Accuracy: 0.7025\n","Epoch 73, Train Loss: 0.4778, Val Loss: 0.5901, F1 Micro: 0.7100, F1 Macro: 0.6640, Accuracy: 0.7100\n","Epoch 74, Train Loss: 0.5039, Val Loss: 0.6275, F1 Micro: 0.6975, F1 Macro: 0.6441, Accuracy: 0.6975\n","Epoch 75, Train Loss: 0.5282, Val Loss: 0.4574, F1 Micro: 0.8250, F1 Macro: 0.8246, Accuracy: 0.8250\n","Epoch 76, Train Loss: 0.5354, Val Loss: 0.5612, F1 Micro: 0.7175, F1 Macro: 0.6748, Accuracy: 0.7175\n","Epoch 77, Train Loss: 0.5084, Val Loss: 0.4850, F1 Micro: 0.7575, F1 Macro: 0.7403, Accuracy: 0.7575\n","Epoch 78, Train Loss: 0.5212, Val Loss: 0.4347, F1 Micro: 0.8050, F1 Macro: 0.8037, Accuracy: 0.8050\n","Epoch 79, Train Loss: 0.5318, Val Loss: 0.5066, F1 Micro: 0.7300, F1 Macro: 0.6947, Accuracy: 0.7300\n","Epoch 80, Train Loss: 0.5088, Val Loss: 0.7201, F1 Micro: 0.5850, F1 Macro: 0.5424, Accuracy: 0.5850\n","Epoch 81, Train Loss: 0.4967, Val Loss: 0.4567, F1 Micro: 0.7325, F1 Macro: 0.7119, Accuracy: 0.7325\n","Epoch 82, Train Loss: 0.5753, Val Loss: 0.5149, F1 Micro: 0.7875, F1 Macro: 0.7870, Accuracy: 0.7875\n","Epoch 83, Train Loss: 0.5257, Val Loss: 0.5038, F1 Micro: 0.7450, F1 Macro: 0.7188, Accuracy: 0.7450\n","Epoch 84, Train Loss: 0.5819, Val Loss: 0.4424, F1 Micro: 0.7425, F1 Macro: 0.7264, Accuracy: 0.7425\n","Epoch 85, Train Loss: 0.4888, Val Loss: 0.9494, F1 Micro: 0.5075, F1 Macro: 0.4257, Accuracy: 0.5075\n","Epoch 86, Train Loss: 0.5307, Val Loss: 0.4374, F1 Micro: 0.7800, F1 Macro: 0.7718, Accuracy: 0.7800\n","Epoch 87, Train Loss: 0.5537, Val Loss: 0.4722, F1 Micro: 0.8150, F1 Macro: 0.8150, Accuracy: 0.8150\n","Epoch 88, Train Loss: 0.5092, Val Loss: 0.4551, F1 Micro: 0.7400, F1 Macro: 0.7227, Accuracy: 0.7400\n","Epoch 89, Train Loss: 0.5522, Val Loss: 0.5988, F1 Micro: 0.6875, F1 Macro: 0.6773, Accuracy: 0.6875\n","Epoch 90, Train Loss: 0.4864, Val Loss: 1.0503, F1 Micro: 0.5075, F1 Macro: 0.4231, Accuracy: 0.5075\n","Epoch 91, Train Loss: 0.5507, Val Loss: 0.5041, F1 Micro: 0.8075, F1 Macro: 0.8074, Accuracy: 0.8075\n","Epoch 92, Train Loss: 0.5069, Val Loss: 0.5093, F1 Micro: 0.7300, F1 Macro: 0.6935, Accuracy: 0.7300\n","Epoch 93, Train Loss: 0.5330, Val Loss: 0.4379, F1 Micro: 0.8275, F1 Macro: 0.8257, Accuracy: 0.8275\n","Epoch 94, Train Loss: 0.5166, Val Loss: 0.5355, F1 Micro: 0.7175, F1 Macro: 0.7121, Accuracy: 0.7175\n","Epoch 95, Train Loss: 0.5107, Val Loss: 0.6267, F1 Micro: 0.6925, F1 Macro: 0.6365, Accuracy: 0.6925\n","Epoch 96, Train Loss: 0.5022, Val Loss: 0.5184, F1 Micro: 0.7175, F1 Macro: 0.7142, Accuracy: 0.7175\n","Epoch 97, Train Loss: 0.5417, Val Loss: 0.5639, F1 Micro: 0.7200, F1 Macro: 0.6809, Accuracy: 0.7200\n","Epoch 98, Train Loss: 0.5068, Val Loss: 0.8383, F1 Micro: 0.5875, F1 Macro: 0.5517, Accuracy: 0.5875\n","Epoch 99, Train Loss: 0.5107, Val Loss: 0.4686, F1 Micro: 0.7700, F1 Macro: 0.7681, Accuracy: 0.7700\n","Epoch 100, Train Loss: 0.5521, Val Loss: 0.7086, F1 Micro: 0.6000, F1 Macro: 0.5633, Accuracy: 0.6000\n","Epoch 101, Train Loss: 0.5078, Val Loss: 0.4387, F1 Micro: 0.8200, F1 Macro: 0.8169, Accuracy: 0.8200\n","Epoch 102, Train Loss: 0.4999, Val Loss: 0.7582, F1 Micro: 0.5975, F1 Macro: 0.5652, Accuracy: 0.5975\n","Epoch 103, Train Loss: 0.5382, Val Loss: 0.6339, F1 Micro: 0.6000, F1 Macro: 0.5745, Accuracy: 0.6000\n","Epoch 104, Train Loss: 0.5479, Val Loss: 0.5213, F1 Micro: 0.8025, F1 Macro: 0.8024, Accuracy: 0.8025\n","Epoch 105, Train Loss: 0.5467, Val Loss: 1.5121, F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Epoch 106, Train Loss: 0.5331, Val Loss: 0.7792, F1 Micro: 0.6725, F1 Macro: 0.6562, Accuracy: 0.6725\n","Epoch 107, Train Loss: 0.5448, Val Loss: 0.6987, F1 Micro: 0.5625, F1 Macro: 0.5099, Accuracy: 0.5625\n","Epoch 108, Train Loss: 0.5019, Val Loss: 0.4369, F1 Micro: 0.7450, F1 Macro: 0.7265, Accuracy: 0.7450\n","Epoch 109, Train Loss: 0.5130, Val Loss: 0.5467, F1 Micro: 0.6875, F1 Macro: 0.6869, Accuracy: 0.6875\n","Epoch 110, Train Loss: 0.5065, Val Loss: 0.5912, F1 Micro: 0.7175, F1 Macro: 0.7162, Accuracy: 0.7175\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.7175, F1 Macro: 0.7162, Accuracy: 0.7175\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7724, Val Loss: 0.5852, F1 Micro: 0.6438, F1 Macro: 0.6397, Accuracy: 0.6438\n","Epoch 2, Train Loss: 0.6200, Val Loss: 0.5912, F1 Micro: 0.6438, F1 Macro: 0.6355, Accuracy: 0.6438\n","Epoch 3, Train Loss: 0.6204, Val Loss: 0.6444, F1 Micro: 0.6094, F1 Macro: 0.5514, Accuracy: 0.6094\n","Epoch 4, Train Loss: 0.5966, Val Loss: 0.6318, F1 Micro: 0.6344, F1 Macro: 0.6006, Accuracy: 0.6344\n","Epoch 5, Train Loss: 0.6415, Val Loss: 0.6357, F1 Micro: 0.6375, F1 Macro: 0.6133, Accuracy: 0.6375\n","Epoch 6, Train Loss: 0.6157, Val Loss: 0.5848, F1 Micro: 0.6594, F1 Macro: 0.6566, Accuracy: 0.6594\n","Epoch 7, Train Loss: 0.6080, Val Loss: 0.6631, F1 Micro: 0.6844, F1 Macro: 0.6680, Accuracy: 0.6844\n","Epoch 8, Train Loss: 0.6247, Val Loss: 0.5880, F1 Micro: 0.6813, F1 Macro: 0.6813, Accuracy: 0.6813\n","Epoch 9, Train Loss: 0.5888, Val Loss: 0.5953, F1 Micro: 0.6469, F1 Macro: 0.6377, Accuracy: 0.6469\n","Epoch 10, Train Loss: 0.6451, Val Loss: 0.6321, F1 Micro: 0.6406, F1 Macro: 0.6160, Accuracy: 0.6406\n","Epoch 11, Train Loss: 0.6065, Val Loss: 0.6427, F1 Micro: 0.6781, F1 Macro: 0.6634, Accuracy: 0.6781\n","Epoch 12, Train Loss: 0.5942, Val Loss: 0.6634, F1 Micro: 0.6438, F1 Macro: 0.6289, Accuracy: 0.6438\n","Epoch 13, Train Loss: 0.6060, Val Loss: 0.5830, F1 Micro: 0.6469, F1 Macro: 0.6416, Accuracy: 0.6469\n","Epoch 14, Train Loss: 0.6344, Val Loss: 0.6203, F1 Micro: 0.6438, F1 Macro: 0.6236, Accuracy: 0.6438\n","Epoch 15, Train Loss: 0.5772, Val Loss: 0.5956, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 16, Train Loss: 0.6073, Val Loss: 0.5912, F1 Micro: 0.6469, F1 Macro: 0.6369, Accuracy: 0.6469\n","Epoch 17, Train Loss: 0.5859, Val Loss: 0.5937, F1 Micro: 0.6406, F1 Macro: 0.6313, Accuracy: 0.6406\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6839, Val Loss: 0.6121, F1 Micro: 0.6750, F1 Macro: 0.6414, Accuracy: 0.6750\n","Epoch 2, Train Loss: 0.6667, Val Loss: 0.8098, F1 Micro: 0.5781, F1 Macro: 0.5428, Accuracy: 0.5781\n","Epoch 3, Train Loss: 0.6243, Val Loss: 0.5728, F1 Micro: 0.7000, F1 Macro: 0.6957, Accuracy: 0.7000\n","Epoch 4, Train Loss: 0.5963, Val Loss: 0.5708, F1 Micro: 0.6875, F1 Macro: 0.6872, Accuracy: 0.6875\n","Epoch 5, Train Loss: 0.5933, Val Loss: 0.5880, F1 Micro: 0.7219, F1 Macro: 0.7121, Accuracy: 0.7219\n","Epoch 6, Train Loss: 0.6123, Val Loss: 0.5934, F1 Micro: 0.6719, F1 Macro: 0.6715, Accuracy: 0.6719\n","Epoch 7, Train Loss: 0.6368, Val Loss: 0.5936, F1 Micro: 0.7125, F1 Macro: 0.6878, Accuracy: 0.7125\n","Epoch 8, Train Loss: 0.6878, Val Loss: 0.6057, F1 Micro: 0.7125, F1 Macro: 0.7070, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.6122, Val Loss: 0.7534, F1 Micro: 0.6031, F1 Macro: 0.5760, Accuracy: 0.6031\n","Epoch 10, Train Loss: 0.6078, Val Loss: 0.5561, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 11, Train Loss: 0.6035, Val Loss: 0.5718, F1 Micro: 0.7063, F1 Macro: 0.7020, Accuracy: 0.7063\n","Epoch 12, Train Loss: 0.6481, Val Loss: 0.8106, F1 Micro: 0.6750, F1 Macro: 0.6349, Accuracy: 0.6750\n","Epoch 13, Train Loss: 0.6280, Val Loss: 0.7355, F1 Micro: 0.5500, F1 Macro: 0.4097, Accuracy: 0.5500\n","Epoch 14, Train Loss: 0.6526, Val Loss: 0.6116, F1 Micro: 0.6500, F1 Macro: 0.5970, Accuracy: 0.6500\n","Epoch 15, Train Loss: 0.6451, Val Loss: 0.5905, F1 Micro: 0.6875, F1 Macro: 0.6865, Accuracy: 0.6875\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6885, Val Loss: 0.6348, F1 Micro: 0.6594, F1 Macro: 0.6586, Accuracy: 0.6594\n","Epoch 2, Train Loss: 0.6098, Val Loss: 0.6390, F1 Micro: 0.6438, F1 Macro: 0.6414, Accuracy: 0.6438\n","Epoch 3, Train Loss: 0.5809, Val Loss: 0.6674, F1 Micro: 0.6625, F1 Macro: 0.6586, Accuracy: 0.6625\n","Epoch 4, Train Loss: 0.6077, Val Loss: 0.7085, F1 Micro: 0.6438, F1 Macro: 0.6414, Accuracy: 0.6438\n","Epoch 5, Train Loss: 0.6453, Val Loss: 0.6925, F1 Micro: 0.5906, F1 Macro: 0.5082, Accuracy: 0.5906\n","Epoch 6, Train Loss: 0.5938, Val Loss: 0.6313, F1 Micro: 0.6531, F1 Macro: 0.6516, Accuracy: 0.6531\n","Epoch 7, Train Loss: 0.5827, Val Loss: 0.6086, F1 Micro: 0.6469, F1 Macro: 0.6263, Accuracy: 0.6469\n","Epoch 8, Train Loss: 0.5880, Val Loss: 0.8155, F1 Micro: 0.5687, F1 Macro: 0.4896, Accuracy: 0.5687\n","Epoch 9, Train Loss: 0.6021, Val Loss: 0.7469, F1 Micro: 0.6656, F1 Macro: 0.6415, Accuracy: 0.6656\n","Epoch 10, Train Loss: 0.6395, Val Loss: 0.6582, F1 Micro: 0.6531, F1 Macro: 0.6211, Accuracy: 0.6531\n","Epoch 11, Train Loss: 0.6480, Val Loss: 0.6624, F1 Micro: 0.6281, F1 Macro: 0.6013, Accuracy: 0.6281\n","Epoch 12, Train Loss: 0.5998, Val Loss: 0.6079, F1 Micro: 0.6500, F1 Macro: 0.6473, Accuracy: 0.6500\n","Epoch 13, Train Loss: 0.5860, Val Loss: 0.6328, F1 Micro: 0.6438, F1 Macro: 0.6421, Accuracy: 0.6438\n","Epoch 14, Train Loss: 0.6268, Val Loss: 0.7074, F1 Micro: 0.6562, F1 Macro: 0.6345, Accuracy: 0.6562\n","Epoch 15, Train Loss: 0.6173, Val Loss: 0.6418, F1 Micro: 0.6406, F1 Macro: 0.6384, Accuracy: 0.6406\n","Epoch 16, Train Loss: 0.5909, Val Loss: 0.6302, F1 Micro: 0.6562, F1 Macro: 0.6253, Accuracy: 0.6562\n","Epoch 17, Train Loss: 0.5809, Val Loss: 0.6498, F1 Micro: 0.6594, F1 Macro: 0.6512, Accuracy: 0.6594\n","Epoch 18, Train Loss: 0.5817, Val Loss: 0.6691, F1 Micro: 0.6250, F1 Macro: 0.6178, Accuracy: 0.6250\n","Epoch 19, Train Loss: 0.5827, Val Loss: 0.6153, F1 Micro: 0.6594, F1 Macro: 0.6438, Accuracy: 0.6594\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6756, Val Loss: 0.5309, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 2, Train Loss: 0.6446, Val Loss: 0.5825, F1 Micro: 0.7156, F1 Macro: 0.7056, Accuracy: 0.7156\n","Epoch 3, Train Loss: 0.6382, Val Loss: 0.5435, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 4, Train Loss: 0.6715, Val Loss: 0.6542, F1 Micro: 0.6281, F1 Macro: 0.6065, Accuracy: 0.6281\n","Epoch 5, Train Loss: 0.6170, Val Loss: 0.5830, F1 Micro: 0.6750, F1 Macro: 0.6693, Accuracy: 0.6750\n","Epoch 6, Train Loss: 0.6406, Val Loss: 0.5408, F1 Micro: 0.7125, F1 Macro: 0.7047, Accuracy: 0.7125\n","Epoch 7, Train Loss: 0.6281, Val Loss: 0.5506, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 8, Train Loss: 0.6237, Val Loss: 0.5538, F1 Micro: 0.6844, F1 Macro: 0.6821, Accuracy: 0.6844\n","Epoch 9, Train Loss: 0.6051, Val Loss: 0.5342, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 10, Train Loss: 0.6515, Val Loss: 0.6286, F1 Micro: 0.5500, F1 Macro: 0.3548, Accuracy: 0.5500\n","Epoch 11, Train Loss: 0.6109, Val Loss: 0.5372, F1 Micro: 0.7250, F1 Macro: 0.7202, Accuracy: 0.7250\n","Epoch 12, Train Loss: 0.6188, Val Loss: 0.5308, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.6304, Val Loss: 0.6010, F1 Micro: 0.6750, F1 Macro: 0.6662, Accuracy: 0.6750\n","Epoch 14, Train Loss: 0.6455, Val Loss: 0.8162, F1 Micro: 0.6406, F1 Macro: 0.6220, Accuracy: 0.6406\n","Epoch 15, Train Loss: 0.6057, Val Loss: 0.5758, F1 Micro: 0.7000, F1 Macro: 0.6849, Accuracy: 0.7000\n","Epoch 16, Train Loss: 0.6466, Val Loss: 0.5645, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 17, Train Loss: 0.6545, Val Loss: 0.5373, F1 Micro: 0.7188, F1 Macro: 0.7185, Accuracy: 0.7188\n","Epoch 18, Train Loss: 0.6020, Val Loss: 0.5948, F1 Micro: 0.6750, F1 Macro: 0.6675, Accuracy: 0.6750\n","Epoch 19, Train Loss: 0.6187, Val Loss: 0.6932, F1 Micro: 0.5500, F1 Macro: 0.3548, Accuracy: 0.5500\n","Epoch 20, Train Loss: 0.6535, Val Loss: 0.5540, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 21, Train Loss: 0.6210, Val Loss: 0.5583, F1 Micro: 0.6906, F1 Macro: 0.6716, Accuracy: 0.6906\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7121, Val Loss: 0.6760, F1 Micro: 0.4750, F1 Macro: 0.3220, Accuracy: 0.4750\n","Epoch 2, Train Loss: 0.6692, Val Loss: 0.5438, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 3, Train Loss: 0.6344, Val Loss: 0.5696, F1 Micro: 0.6844, F1 Macro: 0.6579, Accuracy: 0.6844\n","Epoch 4, Train Loss: 0.6171, Val Loss: 0.5407, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 5, Train Loss: 0.6349, Val Loss: 0.5986, F1 Micro: 0.7063, F1 Macro: 0.6915, Accuracy: 0.7063\n","Epoch 6, Train Loss: 0.6073, Val Loss: 0.5777, F1 Micro: 0.6969, F1 Macro: 0.6793, Accuracy: 0.6969\n","Epoch 7, Train Loss: 0.6110, Val Loss: 0.6204, F1 Micro: 0.6875, F1 Macro: 0.6490, Accuracy: 0.6875\n","Epoch 8, Train Loss: 0.6075, Val Loss: 0.5528, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 9, Train Loss: 0.6178, Val Loss: 0.5505, F1 Micro: 0.7281, F1 Macro: 0.7240, Accuracy: 0.7281\n","Epoch 10, Train Loss: 0.6299, Val Loss: 0.5443, F1 Micro: 0.7031, F1 Macro: 0.6912, Accuracy: 0.7031\n","Epoch 11, Train Loss: 0.7514, Val Loss: 0.5966, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 12, Train Loss: 0.6400, Val Loss: 0.6228, F1 Micro: 0.6156, F1 Macro: 0.5907, Accuracy: 0.6156\n","Epoch 13, Train Loss: 0.7059, Val Loss: 0.5546, F1 Micro: 0.7125, F1 Macro: 0.7047, Accuracy: 0.7125\n","Epoch 14, Train Loss: 0.6500, Val Loss: 0.5444, F1 Micro: 0.7063, F1 Macro: 0.6963, Accuracy: 0.7063\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.70625\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7496, Val Loss: 0.5951, F1 Micro: 0.6469, F1 Macro: 0.6384, Accuracy: 0.6469\n","Epoch 2, Train Loss: 0.6028, Val Loss: 0.6021, F1 Micro: 0.6469, F1 Macro: 0.6336, Accuracy: 0.6469\n","Epoch 3, Train Loss: 0.6919, Val Loss: 0.8492, F1 Micro: 0.5750, F1 Macro: 0.4879, Accuracy: 0.5750\n","Epoch 4, Train Loss: 0.7161, Val Loss: 0.8531, F1 Micro: 0.5531, F1 Macro: 0.4455, Accuracy: 0.5531\n","Epoch 5, Train Loss: 0.6278, Val Loss: 0.6094, F1 Micro: 0.6438, F1 Macro: 0.6225, Accuracy: 0.6438\n","Epoch 6, Train Loss: 0.6045, Val Loss: 0.6059, F1 Micro: 0.6813, F1 Macro: 0.6805, Accuracy: 0.6813\n","Epoch 7, Train Loss: 0.6234, Val Loss: 0.6065, F1 Micro: 0.6562, F1 Macro: 0.6552, Accuracy: 0.6562\n","Epoch 8, Train Loss: 0.6072, Val Loss: 0.6550, F1 Micro: 0.6594, F1 Macro: 0.6512, Accuracy: 0.6594\n","Epoch 9, Train Loss: 0.6049, Val Loss: 0.5811, F1 Micro: 0.6719, F1 Macro: 0.6715, Accuracy: 0.6719\n","Epoch 10, Train Loss: 0.5881, Val Loss: 0.5882, F1 Micro: 0.6687, F1 Macro: 0.6675, Accuracy: 0.6687\n","Epoch 11, Train Loss: 0.5962, Val Loss: 0.6065, F1 Micro: 0.6562, F1 Macro: 0.6513, Accuracy: 0.6562\n","Epoch 12, Train Loss: 0.6207, Val Loss: 0.6269, F1 Micro: 0.6219, F1 Macro: 0.5782, Accuracy: 0.6219\n","Epoch 13, Train Loss: 0.5958, Val Loss: 0.6078, F1 Micro: 0.6375, F1 Macro: 0.6133, Accuracy: 0.6375\n","Epoch 14, Train Loss: 0.6057, Val Loss: 0.6016, F1 Micro: 0.6469, F1 Macro: 0.6440, Accuracy: 0.6469\n","Epoch 15, Train Loss: 0.5910, Val Loss: 0.5800, F1 Micro: 0.6687, F1 Macro: 0.6675, Accuracy: 0.6687\n","Epoch 16, Train Loss: 0.6059, Val Loss: 0.6444, F1 Micro: 0.6438, F1 Macro: 0.6069, Accuracy: 0.6438\n","Epoch 17, Train Loss: 0.6267, Val Loss: 0.7164, F1 Micro: 0.6719, F1 Macro: 0.6705, Accuracy: 0.6719\n","Epoch 18, Train Loss: 0.6240, Val Loss: 0.5759, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 19, Train Loss: 0.5893, Val Loss: 0.5735, F1 Micro: 0.6625, F1 Macro: 0.6606, Accuracy: 0.6625\n","Epoch 20, Train Loss: 0.5851, Val Loss: 0.6107, F1 Micro: 0.6969, F1 Macro: 0.6838, Accuracy: 0.6969\n","Epoch 21, Train Loss: 0.6038, Val Loss: 0.6710, F1 Micro: 0.6281, F1 Macro: 0.5773, Accuracy: 0.6281\n","Epoch 22, Train Loss: 0.6596, Val Loss: 0.7895, F1 Micro: 0.6250, F1 Macro: 0.5768, Accuracy: 0.6250\n","Epoch 23, Train Loss: 0.6568, Val Loss: 0.6217, F1 Micro: 0.6531, F1 Macro: 0.6489, Accuracy: 0.6531\n","Epoch 24, Train Loss: 0.6551, Val Loss: 0.7473, F1 Micro: 0.6562, F1 Macro: 0.6223, Accuracy: 0.6562\n","Epoch 25, Train Loss: 0.6061, Val Loss: 0.6304, F1 Micro: 0.5938, F1 Macro: 0.5347, Accuracy: 0.5938\n","Epoch 26, Train Loss: 0.6432, Val Loss: 0.5583, F1 Micro: 0.6844, F1 Macro: 0.6843, Accuracy: 0.6844\n","Epoch 27, Train Loss: 0.6080, Val Loss: 0.5629, F1 Micro: 0.6781, F1 Macro: 0.6774, Accuracy: 0.6781\n","Epoch 28, Train Loss: 0.6200, Val Loss: 0.7293, F1 Micro: 0.5250, F1 Macro: 0.3818, Accuracy: 0.5250\n","Epoch 29, Train Loss: 0.5705, Val Loss: 0.5508, F1 Micro: 0.6875, F1 Macro: 0.6874, Accuracy: 0.6875\n","Epoch 30, Train Loss: 0.6267, Val Loss: 0.5768, F1 Micro: 0.6750, F1 Macro: 0.6577, Accuracy: 0.6750\n","Epoch 31, Train Loss: 0.5825, Val Loss: 0.5928, F1 Micro: 0.6875, F1 Macro: 0.6632, Accuracy: 0.6875\n","Epoch 32, Train Loss: 0.6340, Val Loss: 0.5757, F1 Micro: 0.6781, F1 Macro: 0.6643, Accuracy: 0.6781\n","Epoch 33, Train Loss: 0.5858, Val Loss: 0.5299, F1 Micro: 0.7156, F1 Macro: 0.7139, Accuracy: 0.7156\n","Epoch 34, Train Loss: 0.5456, Val Loss: 0.5249, F1 Micro: 0.7375, F1 Macro: 0.7358, Accuracy: 0.7375\n","Epoch 35, Train Loss: 0.5578, Val Loss: 0.5750, F1 Micro: 0.7031, F1 Macro: 0.6859, Accuracy: 0.7031\n","Epoch 36, Train Loss: 0.6024, Val Loss: 0.5471, F1 Micro: 0.6844, F1 Macro: 0.6839, Accuracy: 0.6844\n","Epoch 37, Train Loss: 0.6081, Val Loss: 0.5803, F1 Micro: 0.6813, F1 Macro: 0.6680, Accuracy: 0.6813\n","Epoch 38, Train Loss: 0.5887, Val Loss: 0.5932, F1 Micro: 0.7063, F1 Macro: 0.6948, Accuracy: 0.7063\n","Epoch 39, Train Loss: 0.5668, Val Loss: 0.5695, F1 Micro: 0.7063, F1 Macro: 0.6940, Accuracy: 0.7063\n","Epoch 40, Train Loss: 0.5521, Val Loss: 0.5393, F1 Micro: 0.6937, F1 Macro: 0.6801, Accuracy: 0.6937\n","Epoch 41, Train Loss: 0.5418, Val Loss: 0.5825, F1 Micro: 0.6656, F1 Macro: 0.6362, Accuracy: 0.6656\n","Epoch 42, Train Loss: 0.5459, Val Loss: 0.6938, F1 Micro: 0.5906, F1 Macro: 0.5492, Accuracy: 0.5906\n","Epoch 43, Train Loss: 0.5984, Val Loss: 0.6275, F1 Micro: 0.7125, F1 Macro: 0.6933, Accuracy: 0.7125\n","Epoch 44, Train Loss: 0.5624, Val Loss: 0.7403, F1 Micro: 0.7000, F1 Macro: 0.6755, Accuracy: 0.7000\n","Epoch 45, Train Loss: 0.5990, Val Loss: 0.5024, F1 Micro: 0.7438, F1 Macro: 0.7434, Accuracy: 0.7438\n","Epoch 46, Train Loss: 0.5885, Val Loss: 0.5372, F1 Micro: 0.7094, F1 Macro: 0.7059, Accuracy: 0.7094\n","Epoch 47, Train Loss: 0.5695, Val Loss: 0.5943, F1 Micro: 0.6969, F1 Macro: 0.6896, Accuracy: 0.6969\n","Epoch 48, Train Loss: 0.5697, Val Loss: 0.5505, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 49, Train Loss: 0.5681, Val Loss: 0.5361, F1 Micro: 0.6906, F1 Macro: 0.6764, Accuracy: 0.6906\n","Epoch 50, Train Loss: 0.5946, Val Loss: 0.7243, F1 Micro: 0.6406, F1 Macro: 0.5894, Accuracy: 0.6406\n","Epoch 51, Train Loss: 0.5702, Val Loss: 0.5849, F1 Micro: 0.6875, F1 Macro: 0.6593, Accuracy: 0.6875\n","Epoch 52, Train Loss: 0.6358, Val Loss: 0.5041, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 53, Train Loss: 0.5397, Val Loss: 0.7470, F1 Micro: 0.6813, F1 Macro: 0.6468, Accuracy: 0.6813\n","Epoch 54, Train Loss: 0.5692, Val Loss: 0.5116, F1 Micro: 0.7375, F1 Macro: 0.7372, Accuracy: 0.7375\n","Epoch 55, Train Loss: 0.5489, Val Loss: 0.8357, F1 Micro: 0.6656, F1 Macro: 0.6217, Accuracy: 0.6656\n","Epoch 56, Train Loss: 0.5654, Val Loss: 0.5143, F1 Micro: 0.7156, F1 Macro: 0.7136, Accuracy: 0.7156\n","Epoch 57, Train Loss: 0.5629, Val Loss: 0.5355, F1 Micro: 0.6844, F1 Macro: 0.6699, Accuracy: 0.6844\n","Epoch 58, Train Loss: 0.5622, Val Loss: 0.6215, F1 Micro: 0.6406, F1 Macro: 0.5894, Accuracy: 0.6406\n","Epoch 59, Train Loss: 0.5652, Val Loss: 0.5022, F1 Micro: 0.7469, F1 Macro: 0.7451, Accuracy: 0.7469\n","Epoch 60, Train Loss: 0.5758, Val Loss: 0.5997, F1 Micro: 0.6500, F1 Macro: 0.6104, Accuracy: 0.6500\n","Epoch 61, Train Loss: 0.5715, Val Loss: 0.8538, F1 Micro: 0.5250, F1 Macro: 0.3912, Accuracy: 0.5250\n","Epoch 62, Train Loss: 0.6054, Val Loss: 0.5066, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 63, Train Loss: 0.5671, Val Loss: 0.5817, F1 Micro: 0.7125, F1 Macro: 0.6890, Accuracy: 0.7125\n","Epoch 64, Train Loss: 0.5572, Val Loss: 0.5022, F1 Micro: 0.7625, F1 Macro: 0.7622, Accuracy: 0.7625\n","Epoch 65, Train Loss: 0.5941, Val Loss: 0.7506, F1 Micro: 0.5813, F1 Macro: 0.5073, Accuracy: 0.5813\n","Epoch 66, Train Loss: 0.5670, Val Loss: 0.5316, F1 Micro: 0.7875, F1 Macro: 0.7822, Accuracy: 0.7875\n","Epoch 67, Train Loss: 0.5476, Val Loss: 0.5608, F1 Micro: 0.7719, F1 Macro: 0.7638, Accuracy: 0.7719\n","Epoch 68, Train Loss: 0.5979, Val Loss: 0.5247, F1 Micro: 0.6906, F1 Macro: 0.6899, Accuracy: 0.6906\n","Epoch 69, Train Loss: 0.5708, Val Loss: 0.4923, F1 Micro: 0.7188, F1 Macro: 0.7169, Accuracy: 0.7188\n","Epoch 70, Train Loss: 0.5432, Val Loss: 0.5301, F1 Micro: 0.6781, F1 Macro: 0.6710, Accuracy: 0.6781\n","Epoch 71, Train Loss: 0.5391, Val Loss: 0.5141, F1 Micro: 0.6937, F1 Macro: 0.6801, Accuracy: 0.6937\n","Epoch 72, Train Loss: 0.5722, Val Loss: 0.7458, F1 Micro: 0.6062, F1 Macro: 0.5393, Accuracy: 0.6062\n","Epoch 73, Train Loss: 0.6177, Val Loss: 0.8145, F1 Micro: 0.5625, F1 Macro: 0.4552, Accuracy: 0.5625\n","Epoch 74, Train Loss: 0.5810, Val Loss: 0.5289, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 75, Train Loss: 0.5409, Val Loss: 0.4894, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 76, Train Loss: 0.5393, Val Loss: 0.6712, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 77, Train Loss: 0.5739, Val Loss: 0.7728, F1 Micro: 0.5437, F1 Macro: 0.4279, Accuracy: 0.5437\n","Epoch 78, Train Loss: 0.5374, Val Loss: 0.4854, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 79, Train Loss: 0.5808, Val Loss: 0.4947, F1 Micro: 0.7750, F1 Macro: 0.7747, Accuracy: 0.7750\n","Epoch 80, Train Loss: 0.5464, Val Loss: 0.5023, F1 Micro: 0.7094, F1 Macro: 0.6984, Accuracy: 0.7094\n","Epoch 81, Train Loss: 0.5844, Val Loss: 0.6705, F1 Micro: 0.6937, F1 Macro: 0.6635, Accuracy: 0.6937\n","Epoch 82, Train Loss: 0.5697, Val Loss: 0.6869, F1 Micro: 0.6844, F1 Macro: 0.6660, Accuracy: 0.6844\n","Epoch 83, Train Loss: 0.6245, Val Loss: 0.7325, F1 Micro: 0.5156, F1 Macro: 0.3721, Accuracy: 0.5156\n","Epoch 84, Train Loss: 0.5595, Val Loss: 0.5791, F1 Micro: 0.6906, F1 Macro: 0.6716, Accuracy: 0.6906\n","Epoch 85, Train Loss: 0.5529, Val Loss: 0.5068, F1 Micro: 0.7812, F1 Macro: 0.7811, Accuracy: 0.7812\n","Epoch 86, Train Loss: 0.5475, Val Loss: 0.5015, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 87, Train Loss: 0.5790, Val Loss: 0.5601, F1 Micro: 0.7469, F1 Macro: 0.7373, Accuracy: 0.7469\n","Epoch 88, Train Loss: 0.5457, Val Loss: 0.5509, F1 Micro: 0.6656, F1 Macro: 0.6493, Accuracy: 0.6656\n","Epoch 89, Train Loss: 0.5439, Val Loss: 0.5795, F1 Micro: 0.7469, F1 Macro: 0.7322, Accuracy: 0.7469\n","Epoch 90, Train Loss: 0.5214, Val Loss: 0.5565, F1 Micro: 0.7406, F1 Macro: 0.7375, Accuracy: 0.7406\n","Epoch 91, Train Loss: 0.5674, Val Loss: 0.7219, F1 Micro: 0.6375, F1 Macro: 0.5869, Accuracy: 0.6375\n","Epoch 92, Train Loss: 0.5871, Val Loss: 0.7871, F1 Micro: 0.6781, F1 Macro: 0.6456, Accuracy: 0.6781\n","Epoch 93, Train Loss: 0.6268, Val Loss: 0.6447, F1 Micro: 0.7125, F1 Macro: 0.6901, Accuracy: 0.7125\n","Epoch 94, Train Loss: 0.5810, Val Loss: 0.7175, F1 Micro: 0.6562, F1 Macro: 0.6121, Accuracy: 0.6562\n","Epoch 95, Train Loss: 0.5325, Val Loss: 0.8020, F1 Micro: 0.6781, F1 Macro: 0.6409, Accuracy: 0.6781\n","Epoch 96, Train Loss: 0.5459, Val Loss: 0.5047, F1 Micro: 0.6969, F1 Macro: 0.6830, Accuracy: 0.6969\n","Epoch 97, Train Loss: 0.5491, Val Loss: 0.5660, F1 Micro: 0.7281, F1 Macro: 0.7157, Accuracy: 0.7281\n","Epoch 98, Train Loss: 0.5359, Val Loss: 0.4816, F1 Micro: 0.7500, F1 Macro: 0.7481, Accuracy: 0.7500\n","Epoch 99, Train Loss: 0.5405, Val Loss: 0.5716, F1 Micro: 0.6844, F1 Macro: 0.6650, Accuracy: 0.6844\n","Epoch 100, Train Loss: 0.6076, Val Loss: 0.4827, F1 Micro: 0.7656, F1 Macro: 0.7654, Accuracy: 0.7656\n","Epoch 101, Train Loss: 0.5142, Val Loss: 1.3005, F1 Micro: 0.5000, F1 Macro: 0.3388, Accuracy: 0.5000\n","Epoch 102, Train Loss: 0.5923, Val Loss: 0.6790, F1 Micro: 0.6094, F1 Macro: 0.5417, Accuracy: 0.6094\n","Epoch 103, Train Loss: 0.5518, Val Loss: 0.6260, F1 Micro: 0.5906, F1 Macro: 0.5141, Accuracy: 0.5906\n","Epoch 104, Train Loss: 0.5686, Val Loss: 0.4762, F1 Micro: 0.7562, F1 Macro: 0.7562, Accuracy: 0.7562\n","Epoch 105, Train Loss: 0.5230, Val Loss: 0.4645, F1 Micro: 0.7438, F1 Macro: 0.7383, Accuracy: 0.7438\n","Epoch 106, Train Loss: 0.5092, Val Loss: 0.4642, F1 Micro: 0.7531, F1 Macro: 0.7490, Accuracy: 0.7531\n","Epoch 107, Train Loss: 0.5043, Val Loss: 0.4927, F1 Micro: 0.7250, F1 Macro: 0.7175, Accuracy: 0.7250\n","Epoch 108, Train Loss: 0.5438, Val Loss: 0.7717, F1 Micro: 0.6719, F1 Macro: 0.6506, Accuracy: 0.6719\n","Epoch 109, Train Loss: 0.5471, Val Loss: 0.6332, F1 Micro: 0.6094, F1 Macro: 0.5417, Accuracy: 0.6094\n","Epoch 110, Train Loss: 0.5082, Val Loss: 0.6026, F1 Micro: 0.6250, F1 Macro: 0.5683, Accuracy: 0.6250\n","Epoch 111, Train Loss: 0.5402, Val Loss: 0.4577, F1 Micro: 0.7625, F1 Macro: 0.7609, Accuracy: 0.7625\n","Epoch 112, Train Loss: 0.5190, Val Loss: 0.5131, F1 Micro: 0.7844, F1 Macro: 0.7844, Accuracy: 0.7844\n","Epoch 113, Train Loss: 0.5455, Val Loss: 0.4589, F1 Micro: 0.7781, F1 Macro: 0.7781, Accuracy: 0.7781\n","Epoch 114, Train Loss: 0.5195, Val Loss: 0.5225, F1 Micro: 0.7844, F1 Macro: 0.7788, Accuracy: 0.7844\n","Epoch 115, Train Loss: 0.5242, Val Loss: 0.4689, F1 Micro: 0.7562, F1 Macro: 0.7562, Accuracy: 0.7562\n","Epoch 116, Train Loss: 0.5216, Val Loss: 0.8218, F1 Micro: 0.6031, F1 Macro: 0.5394, Accuracy: 0.6031\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7607, Val Loss: 0.6008, F1 Micro: 0.6594, F1 Macro: 0.6561, Accuracy: 0.6594\n","Epoch 2, Train Loss: 0.6338, Val Loss: 0.7235, F1 Micro: 0.5813, F1 Macro: 0.5453, Accuracy: 0.5813\n","Epoch 3, Train Loss: 0.6140, Val Loss: 0.5900, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 4, Train Loss: 0.6065, Val Loss: 0.5684, F1 Micro: 0.7188, F1 Macro: 0.7128, Accuracy: 0.7188\n","Epoch 5, Train Loss: 0.6369, Val Loss: 0.9593, F1 Micro: 0.4781, F1 Macro: 0.3235, Accuracy: 0.4781\n","Epoch 6, Train Loss: 0.6385, Val Loss: 0.5817, F1 Micro: 0.7125, F1 Macro: 0.7070, Accuracy: 0.7125\n","Epoch 7, Train Loss: 0.6251, Val Loss: 0.6218, F1 Micro: 0.6438, F1 Macro: 0.5877, Accuracy: 0.6438\n","Epoch 8, Train Loss: 0.6132, Val Loss: 0.5685, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 9, Train Loss: 0.5916, Val Loss: 0.5902, F1 Micro: 0.7219, F1 Macro: 0.7057, Accuracy: 0.7219\n","Epoch 10, Train Loss: 0.6379, Val Loss: 0.6032, F1 Micro: 0.6906, F1 Macro: 0.6564, Accuracy: 0.6906\n","Epoch 11, Train Loss: 0.6890, Val Loss: 0.7762, F1 Micro: 0.6344, F1 Macro: 0.5734, Accuracy: 0.6344\n","Epoch 12, Train Loss: 0.6451, Val Loss: 0.5939, F1 Micro: 0.7063, F1 Macro: 0.6772, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.6191, Val Loss: 0.5641, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 14, Train Loss: 0.6080, Val Loss: 0.6669, F1 Micro: 0.6250, F1 Macro: 0.5509, Accuracy: 0.6250\n","Epoch 15, Train Loss: 0.6185, Val Loss: 0.6088, F1 Micro: 0.6594, F1 Macro: 0.6128, Accuracy: 0.6594\n","Epoch 16, Train Loss: 0.5990, Val Loss: 0.5626, F1 Micro: 0.7094, F1 Macro: 0.7050, Accuracy: 0.7094\n","Epoch 17, Train Loss: 0.6083, Val Loss: 0.5900, F1 Micro: 0.7219, F1 Macro: 0.7008, Accuracy: 0.7219\n","Epoch 18, Train Loss: 0.5997, Val Loss: 0.5784, F1 Micro: 0.6844, F1 Macro: 0.6843, Accuracy: 0.6844\n","Epoch 19, Train Loss: 0.6887, Val Loss: 0.5602, F1 Micro: 0.6813, F1 Macro: 0.6784, Accuracy: 0.6813\n","Epoch 20, Train Loss: 0.6662, Val Loss: 0.6417, F1 Micro: 0.6219, F1 Macro: 0.5429, Accuracy: 0.6219\n","Epoch 21, Train Loss: 0.6861, Val Loss: 0.6776, F1 Micro: 0.6500, F1 Macro: 0.6397, Accuracy: 0.6500\n","Epoch 22, Train Loss: 0.6283, Val Loss: 0.5787, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 23, Train Loss: 0.6026, Val Loss: 0.5788, F1 Micro: 0.7188, F1 Macro: 0.7078, Accuracy: 0.7188\n","Epoch 24, Train Loss: 0.5856, Val Loss: 0.5627, F1 Micro: 0.6844, F1 Macro: 0.6814, Accuracy: 0.6844\n","Epoch 25, Train Loss: 0.6130, Val Loss: 0.5931, F1 Micro: 0.7344, F1 Macro: 0.7214, Accuracy: 0.7344\n","Epoch 26, Train Loss: 0.5909, Val Loss: 0.5612, F1 Micro: 0.6750, F1 Macro: 0.6737, Accuracy: 0.6750\n","Epoch 27, Train Loss: 0.5849, Val Loss: 0.5602, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 28, Train Loss: 0.5875, Val Loss: 0.5636, F1 Micro: 0.7188, F1 Macro: 0.7078, Accuracy: 0.7188\n","Epoch 29, Train Loss: 0.6297, Val Loss: 0.7609, F1 Micro: 0.6438, F1 Macro: 0.6325, Accuracy: 0.6438\n","Epoch 30, Train Loss: 0.6309, Val Loss: 0.5993, F1 Micro: 0.6500, F1 Macro: 0.6450, Accuracy: 0.6500\n","Epoch 31, Train Loss: 0.6918, Val Loss: 0.9214, F1 Micro: 0.5687, F1 Macro: 0.5261, Accuracy: 0.5687\n","Epoch 32, Train Loss: 0.6354, Val Loss: 0.5650, F1 Micro: 0.6781, F1 Macro: 0.6765, Accuracy: 0.6781\n","Epoch 33, Train Loss: 0.6090, Val Loss: 0.6491, F1 Micro: 0.5969, F1 Macro: 0.4998, Accuracy: 0.5969\n","Epoch 34, Train Loss: 0.5858, Val Loss: 0.5602, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 35, Train Loss: 0.5940, Val Loss: 0.5591, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 36, Train Loss: 0.6295, Val Loss: 0.8774, F1 Micro: 0.6031, F1 Macro: 0.5714, Accuracy: 0.6031\n","Epoch 37, Train Loss: 0.6272, Val Loss: 0.5609, F1 Micro: 0.6875, F1 Macro: 0.6851, Accuracy: 0.6875\n","Epoch 38, Train Loss: 0.5822, Val Loss: 0.5605, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 39, Train Loss: 0.5918, Val Loss: 0.6746, F1 Micro: 0.6500, F1 Macro: 0.6473, Accuracy: 0.6500\n","Epoch 40, Train Loss: 0.6460, Val Loss: 0.5549, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 41, Train Loss: 0.6030, Val Loss: 0.5583, F1 Micro: 0.6937, F1 Macro: 0.6936, Accuracy: 0.6937\n","Epoch 42, Train Loss: 0.5908, Val Loss: 0.6001, F1 Micro: 0.7063, F1 Macro: 0.6940, Accuracy: 0.7063\n","Epoch 43, Train Loss: 0.5950, Val Loss: 0.6743, F1 Micro: 0.6250, F1 Macro: 0.5536, Accuracy: 0.6250\n","Epoch 44, Train Loss: 0.5916, Val Loss: 0.5657, F1 Micro: 0.6625, F1 Macro: 0.6622, Accuracy: 0.6625\n","Epoch 45, Train Loss: 0.6465, Val Loss: 0.6000, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 46, Train Loss: 0.6396, Val Loss: 0.6730, F1 Micro: 0.6625, F1 Macro: 0.6582, Accuracy: 0.6625\n","Epoch 47, Train Loss: 0.6919, Val Loss: 0.5866, F1 Micro: 0.6719, F1 Macro: 0.6707, Accuracy: 0.6719\n","Epoch 48, Train Loss: 0.6063, Val Loss: 0.6092, F1 Micro: 0.6844, F1 Macro: 0.6708, Accuracy: 0.6844\n","Epoch 49, Train Loss: 0.5921, Val Loss: 0.5924, F1 Micro: 0.7094, F1 Macro: 0.6884, Accuracy: 0.7094\n","Epoch 50, Train Loss: 0.6103, Val Loss: 0.6647, F1 Micro: 0.5969, F1 Macro: 0.5561, Accuracy: 0.5969\n","Epoch 51, Train Loss: 0.6069, Val Loss: 0.5747, F1 Micro: 0.7094, F1 Macro: 0.6813, Accuracy: 0.7094\n","Epoch 52, Train Loss: 0.5650, Val Loss: 0.6699, F1 Micro: 0.7125, F1 Macro: 0.6890, Accuracy: 0.7125\n","Epoch 53, Train Loss: 0.5704, Val Loss: 0.5302, F1 Micro: 0.6937, F1 Macro: 0.6867, Accuracy: 0.6937\n","Epoch 54, Train Loss: 0.5437, Val Loss: 0.5478, F1 Micro: 0.6969, F1 Macro: 0.6964, Accuracy: 0.6969\n","Epoch 55, Train Loss: 0.5488, Val Loss: 0.5984, F1 Micro: 0.7156, F1 Macro: 0.7104, Accuracy: 0.7156\n","Epoch 56, Train Loss: 0.5650, Val Loss: 0.7572, F1 Micro: 0.6406, F1 Macro: 0.6026, Accuracy: 0.6406\n","Epoch 57, Train Loss: 0.5582, Val Loss: 0.5039, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 58, Train Loss: 0.6092, Val Loss: 0.5805, F1 Micro: 0.6937, F1 Macro: 0.6936, Accuracy: 0.6937\n","Epoch 59, Train Loss: 0.5844, Val Loss: 0.5233, F1 Micro: 0.7406, F1 Macro: 0.7367, Accuracy: 0.7406\n","Epoch 60, Train Loss: 0.5465, Val Loss: 0.5487, F1 Micro: 0.7094, F1 Macro: 0.7054, Accuracy: 0.7094\n","Epoch 61, Train Loss: 0.5742, Val Loss: 0.5106, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 62, Train Loss: 0.5693, Val Loss: 0.6152, F1 Micro: 0.6656, F1 Macro: 0.6199, Accuracy: 0.6656\n","Epoch 63, Train Loss: 0.5621, Val Loss: 0.5376, F1 Micro: 0.7250, F1 Macro: 0.7192, Accuracy: 0.7250\n","Epoch 64, Train Loss: 0.5813, Val Loss: 0.5466, F1 Micro: 0.7219, F1 Macro: 0.7172, Accuracy: 0.7219\n","Epoch 65, Train Loss: 0.5625, Val Loss: 0.6257, F1 Micro: 0.7219, F1 Macro: 0.7107, Accuracy: 0.7219\n","Epoch 66, Train Loss: 0.5729, Val Loss: 0.5080, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 67, Train Loss: 0.5526, Val Loss: 0.5312, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 68, Train Loss: 0.5680, Val Loss: 0.5141, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 69, Train Loss: 0.5869, Val Loss: 0.5180, F1 Micro: 0.7094, F1 Macro: 0.7079, Accuracy: 0.7094\n","Epoch 70, Train Loss: 0.5571, Val Loss: 0.5597, F1 Micro: 0.7375, F1 Macro: 0.7320, Accuracy: 0.7375\n","Epoch 71, Train Loss: 0.5594, Val Loss: 0.5996, F1 Micro: 0.6750, F1 Macro: 0.6522, Accuracy: 0.6750\n","Epoch 72, Train Loss: 0.5435, Val Loss: 0.6593, F1 Micro: 0.6844, F1 Macro: 0.6660, Accuracy: 0.6844\n","Epoch 73, Train Loss: 0.5836, Val Loss: 0.6564, F1 Micro: 0.6188, F1 Macro: 0.6187, Accuracy: 0.6188\n","Epoch 74, Train Loss: 0.5527, Val Loss: 0.5688, F1 Micro: 0.6687, F1 Macro: 0.6629, Accuracy: 0.6687\n","Epoch 75, Train Loss: 0.5439, Val Loss: 0.5583, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 76, Train Loss: 0.5732, Val Loss: 0.6545, F1 Micro: 0.6813, F1 Macro: 0.6611, Accuracy: 0.6813\n","Epoch 77, Train Loss: 0.6032, Val Loss: 0.5584, F1 Micro: 0.7375, F1 Macro: 0.7243, Accuracy: 0.7375\n","Epoch 78, Train Loss: 0.5628, Val Loss: 0.5152, F1 Micro: 0.7250, F1 Macro: 0.7239, Accuracy: 0.7250\n","Epoch 79, Train Loss: 0.5467, Val Loss: 0.5207, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 80, Train Loss: 0.5688, Val Loss: 0.5556, F1 Micro: 0.7531, F1 Macro: 0.7450, Accuracy: 0.7531\n","Epoch 81, Train Loss: 0.5546, Val Loss: 0.5506, F1 Micro: 0.7531, F1 Macro: 0.7462, Accuracy: 0.7531\n","Epoch 82, Train Loss: 0.5360, Val Loss: 0.5230, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 83, Train Loss: 0.5593, Val Loss: 0.6283, F1 Micro: 0.6813, F1 Macro: 0.6611, Accuracy: 0.6813\n","Epoch 84, Train Loss: 0.5606, Val Loss: 0.5328, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 85, Train Loss: 0.5531, Val Loss: 0.5233, F1 Micro: 0.7375, F1 Macro: 0.7345, Accuracy: 0.7375\n","Epoch 86, Train Loss: 0.5622, Val Loss: 0.5524, F1 Micro: 0.7469, F1 Macro: 0.7373, Accuracy: 0.7469\n","Epoch 87, Train Loss: 0.5562, Val Loss: 0.7702, F1 Micro: 0.5687, F1 Macro: 0.4954, Accuracy: 0.5687\n","Epoch 88, Train Loss: 0.6001, Val Loss: 0.6193, F1 Micro: 0.6906, F1 Macro: 0.6773, Accuracy: 0.6906\n","Epoch 89, Train Loss: 0.5589, Val Loss: 0.6253, F1 Micro: 0.7219, F1 Macro: 0.7140, Accuracy: 0.7219\n","Epoch 90, Train Loss: 0.5415, Val Loss: 0.5555, F1 Micro: 0.7000, F1 Macro: 0.6952, Accuracy: 0.7000\n","Epoch 91, Train Loss: 0.5658, Val Loss: 0.6049, F1 Micro: 0.6562, F1 Macro: 0.6139, Accuracy: 0.6562\n","Epoch 92, Train Loss: 0.5530, Val Loss: 0.5171, F1 Micro: 0.7562, F1 Macro: 0.7549, Accuracy: 0.7562\n","Epoch 93, Train Loss: 0.5356, Val Loss: 0.6040, F1 Micro: 0.6813, F1 Macro: 0.6622, Accuracy: 0.6813\n","Epoch 94, Train Loss: 0.5804, Val Loss: 0.5054, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 95, Train Loss: 0.5712, Val Loss: 0.5202, F1 Micro: 0.7250, F1 Macro: 0.7222, Accuracy: 0.7250\n","Epoch 96, Train Loss: 0.7376, Val Loss: 0.6245, F1 Micro: 0.7063, F1 Macro: 0.6932, Accuracy: 0.7063\n","Epoch 97, Train Loss: 0.5704, Val Loss: 0.6248, F1 Micro: 0.6625, F1 Macro: 0.6375, Accuracy: 0.6625\n","Epoch 98, Train Loss: 0.5739, Val Loss: 0.5872, F1 Micro: 0.6438, F1 Macro: 0.6212, Accuracy: 0.6438\n","Epoch 99, Train Loss: 0.5575, Val Loss: 0.5565, F1 Micro: 0.6844, F1 Macro: 0.6670, Accuracy: 0.6844\n","Epoch 100, Train Loss: 0.5450, Val Loss: 0.5519, F1 Micro: 0.7188, F1 Macro: 0.7092, Accuracy: 0.7188\n","Epoch 101, Train Loss: 0.5120, Val Loss: 0.5047, F1 Micro: 0.7344, F1 Macro: 0.7315, Accuracy: 0.7344\n","Epoch 102, Train Loss: 0.5307, Val Loss: 0.5692, F1 Micro: 0.6656, F1 Macro: 0.6415, Accuracy: 0.6656\n","Epoch 103, Train Loss: 0.5198, Val Loss: 0.6875, F1 Micro: 0.5625, F1 Macro: 0.4435, Accuracy: 0.5625\n","Epoch 104, Train Loss: 0.5411, Val Loss: 0.6468, F1 Micro: 0.5219, F1 Macro: 0.3429, Accuracy: 0.5219\n","Epoch 105, Train Loss: 0.5518, Val Loss: 0.5473, F1 Micro: 0.7188, F1 Macro: 0.7029, Accuracy: 0.7188\n","Epoch 106, Train Loss: 0.5299, Val Loss: 0.5392, F1 Micro: 0.7469, F1 Macro: 0.7380, Accuracy: 0.7469\n","Epoch 107, Train Loss: 0.5506, Val Loss: 0.5060, F1 Micro: 0.7688, F1 Macro: 0.7639, Accuracy: 0.7688\n","Epoch 108, Train Loss: 0.5465, Val Loss: 0.6067, F1 Micro: 0.6594, F1 Macro: 0.6322, Accuracy: 0.6594\n","Epoch 109, Train Loss: 0.5517, Val Loss: 0.6853, F1 Micro: 0.6781, F1 Macro: 0.6561, Accuracy: 0.6781\n","Epoch 110, Train Loss: 0.5163, Val Loss: 0.6445, F1 Micro: 0.6687, F1 Macro: 0.6416, Accuracy: 0.6687\n","Epoch 111, Train Loss: 0.5554, Val Loss: 0.5399, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 112, Train Loss: 0.5681, Val Loss: 0.5250, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 113, Train Loss: 0.5546, Val Loss: 0.6399, F1 Micro: 0.6125, F1 Macro: 0.5440, Accuracy: 0.6125\n","Epoch 114, Train Loss: 0.5287, Val Loss: 0.6173, F1 Micro: 0.6969, F1 Macro: 0.6812, Accuracy: 0.6969\n","Epoch 115, Train Loss: 0.5443, Val Loss: 0.5614, F1 Micro: 0.7000, F1 Macro: 0.6858, Accuracy: 0.7000\n","Epoch 116, Train Loss: 0.5305, Val Loss: 0.6653, F1 Micro: 0.5656, F1 Macro: 0.4494, Accuracy: 0.5656\n","Epoch 117, Train Loss: 0.5476, Val Loss: 0.5170, F1 Micro: 0.7469, F1 Macro: 0.7422, Accuracy: 0.7469\n","Epoch 118, Train Loss: 0.5360, Val Loss: 0.5645, F1 Micro: 0.7063, F1 Macro: 0.6970, Accuracy: 0.7063\n","Epoch 119, Train Loss: 0.5371, Val Loss: 0.5152, F1 Micro: 0.6875, F1 Macro: 0.6727, Accuracy: 0.6875\n","Epoch 120, Train Loss: 0.5495, Val Loss: 0.4913, F1 Micro: 0.7406, F1 Macro: 0.7385, Accuracy: 0.7406\n","Epoch 121, Train Loss: 0.5431, Val Loss: 0.4753, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 122, Train Loss: 0.5368, Val Loss: 0.5412, F1 Micro: 0.7562, F1 Macro: 0.7425, Accuracy: 0.7562\n","Epoch 123, Train Loss: 0.5426, Val Loss: 0.6998, F1 Micro: 0.6625, F1 Macro: 0.6321, Accuracy: 0.6625\n","Epoch 124, Train Loss: 0.5514, Val Loss: 0.4855, F1 Micro: 0.7688, F1 Macro: 0.7658, Accuracy: 0.7688\n","Epoch 125, Train Loss: 0.5228, Val Loss: 0.5678, F1 Micro: 0.6687, F1 Macro: 0.6329, Accuracy: 0.6687\n","Epoch 126, Train Loss: 0.5134, Val Loss: 0.4828, F1 Micro: 0.7656, F1 Macro: 0.7585, Accuracy: 0.7656\n","Epoch 127, Train Loss: 0.5382, Val Loss: 0.6265, F1 Micro: 0.6156, F1 Macro: 0.5354, Accuracy: 0.6156\n","Epoch 128, Train Loss: 0.5103, Val Loss: 0.4884, F1 Micro: 0.7156, F1 Macro: 0.7109, Accuracy: 0.7156\n","Epoch 129, Train Loss: 0.5130, Val Loss: 0.5927, F1 Micro: 0.6906, F1 Macro: 0.6621, Accuracy: 0.6906\n","Epoch 130, Train Loss: 0.5176, Val Loss: 0.6166, F1 Micro: 0.6719, F1 Macro: 0.6470, Accuracy: 0.6719\n","Epoch 131, Train Loss: 0.6193, Val Loss: 0.6282, F1 Micro: 0.6687, F1 Macro: 0.6430, Accuracy: 0.6687\n","Epoch 132, Train Loss: 0.5413, Val Loss: 0.4653, F1 Micro: 0.7312, F1 Macro: 0.7304, Accuracy: 0.7312\n","Epoch 133, Train Loss: 0.5074, Val Loss: 0.4923, F1 Micro: 0.8000, F1 Macro: 0.7958, Accuracy: 0.8000\n","Epoch 134, Train Loss: 0.5486, Val Loss: 0.7570, F1 Micro: 0.6781, F1 Macro: 0.6549, Accuracy: 0.6781\n","Epoch 135, Train Loss: 0.5399, Val Loss: 0.6643, F1 Micro: 0.6813, F1 Macro: 0.6368, Accuracy: 0.6813\n","Epoch 136, Train Loss: 0.5363, Val Loss: 0.8625, F1 Micro: 0.6719, F1 Macro: 0.6494, Accuracy: 0.6719\n","Epoch 137, Train Loss: 0.5144, Val Loss: 0.4619, F1 Micro: 0.7344, F1 Macro: 0.7341, Accuracy: 0.7344\n","Epoch 138, Train Loss: 0.5242, Val Loss: 0.5293, F1 Micro: 0.6906, F1 Macro: 0.6860, Accuracy: 0.6906\n","Epoch 139, Train Loss: 0.5175, Val Loss: 0.5075, F1 Micro: 0.7562, F1 Macro: 0.7502, Accuracy: 0.7562\n","Epoch 140, Train Loss: 0.5458, Val Loss: 0.5043, F1 Micro: 0.7719, F1 Macro: 0.7659, Accuracy: 0.7719\n","Epoch 141, Train Loss: 0.5513, Val Loss: 0.4693, F1 Micro: 0.7406, F1 Macro: 0.7404, Accuracy: 0.7406\n","Epoch 142, Train Loss: 0.5065, Val Loss: 0.4774, F1 Micro: 0.7281, F1 Macro: 0.7262, Accuracy: 0.7281\n","Epoch 143, Train Loss: 0.4870, Val Loss: 0.4942, F1 Micro: 0.7844, F1 Macro: 0.7773, Accuracy: 0.7844\n","Epoch 144, Train Loss: 0.4899, Val Loss: 0.4391, F1 Micro: 0.8156, F1 Macro: 0.8143, Accuracy: 0.8156\n","Epoch 145, Train Loss: 0.5285, Val Loss: 0.4550, F1 Micro: 0.7469, F1 Macro: 0.7465, Accuracy: 0.7469\n","Epoch 146, Train Loss: 0.5239, Val Loss: 0.4983, F1 Micro: 0.7125, F1 Macro: 0.7034, Accuracy: 0.7125\n","Epoch 147, Train Loss: 0.5034, Val Loss: 0.6660, F1 Micro: 0.5781, F1 Macro: 0.4653, Accuracy: 0.5781\n","Epoch 148, Train Loss: 0.5696, Val Loss: 0.4588, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 149, Train Loss: 0.5092, Val Loss: 0.5158, F1 Micro: 0.7125, F1 Macro: 0.7020, Accuracy: 0.7125\n","Epoch 150, Train Loss: 0.5287, Val Loss: 0.5266, F1 Micro: 0.7000, F1 Macro: 0.6840, Accuracy: 0.7000\n","Epoch 151, Train Loss: 0.5280, Val Loss: 0.5215, F1 Micro: 0.7719, F1 Macro: 0.7614, Accuracy: 0.7719\n","Epoch 152, Train Loss: 0.5096, Val Loss: 0.6118, F1 Micro: 0.6625, F1 Macro: 0.6375, Accuracy: 0.6625\n","Epoch 153, Train Loss: 0.4856, Val Loss: 0.5763, F1 Micro: 0.6906, F1 Macro: 0.6746, Accuracy: 0.6906\n","Epoch 154, Train Loss: 0.5068, Val Loss: 0.4579, F1 Micro: 0.7562, F1 Macro: 0.7559, Accuracy: 0.7562\n","Epoch 155, Train Loss: 0.4859, Val Loss: 1.0729, F1 Micro: 0.5406, F1 Macro: 0.3950, Accuracy: 0.5406\n","Epoch 156, Train Loss: 0.4830, Val Loss: 0.4459, F1 Micro: 0.7844, F1 Macro: 0.7836, Accuracy: 0.7844\n","Epoch 157, Train Loss: 0.5967, Val Loss: 0.5580, F1 Micro: 0.6813, F1 Macro: 0.6611, Accuracy: 0.6813\n","Epoch 158, Train Loss: 0.5336, Val Loss: 0.4690, F1 Micro: 0.8031, F1 Macro: 0.7988, Accuracy: 0.8031\n","Epoch 159, Train Loss: 0.5236, Val Loss: 0.5141, F1 Micro: 0.7781, F1 Macro: 0.7719, Accuracy: 0.7781\n","Epoch 160, Train Loss: 0.5231, Val Loss: 0.4635, F1 Micro: 0.7937, F1 Macro: 0.7935, Accuracy: 0.7937\n","Epoch 161, Train Loss: 0.4954, Val Loss: 0.6246, F1 Micro: 0.6375, F1 Macro: 0.5758, Accuracy: 0.6375\n","Epoch 162, Train Loss: 0.5244, Val Loss: 0.4389, F1 Micro: 0.8062, F1 Macro: 0.8055, Accuracy: 0.8063\n","Epoch 163, Train Loss: 0.4957, Val Loss: 0.5378, F1 Micro: 0.7594, F1 Macro: 0.7565, Accuracy: 0.7594\n","Epoch 164, Train Loss: 0.5661, Val Loss: 0.4532, F1 Micro: 0.7688, F1 Macro: 0.7686, Accuracy: 0.7688\n","Epoch 165, Train Loss: 0.5117, Val Loss: 0.5869, F1 Micro: 0.6875, F1 Macro: 0.6655, Accuracy: 0.6875\n","Epoch 166, Train Loss: 0.5218, Val Loss: 0.4622, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 167, Train Loss: 0.5309, Val Loss: 0.5536, F1 Micro: 0.6844, F1 Macro: 0.6510, Accuracy: 0.6844\n","Epoch 168, Train Loss: 0.5362, Val Loss: 0.5320, F1 Micro: 0.7344, F1 Macro: 0.7171, Accuracy: 0.7344\n","Epoch 169, Train Loss: 0.5049, Val Loss: 0.4817, F1 Micro: 0.7063, F1 Macro: 0.7011, Accuracy: 0.7063\n","Epoch 170, Train Loss: 0.5172, Val Loss: 0.4896, F1 Micro: 0.7969, F1 Macro: 0.7911, Accuracy: 0.7969\n","Epoch 171, Train Loss: 0.5223, Val Loss: 0.7627, F1 Micro: 0.6719, F1 Macro: 0.6430, Accuracy: 0.6719\n","Epoch 172, Train Loss: 0.4857, Val Loss: 0.5653, F1 Micro: 0.7438, F1 Macro: 0.7267, Accuracy: 0.7438\n","Epoch 173, Train Loss: 0.5377, Val Loss: 0.5620, F1 Micro: 0.6969, F1 Macro: 0.6953, Accuracy: 0.6969\n","Epoch 174, Train Loss: 0.4956, Val Loss: 0.6403, F1 Micro: 0.6344, F1 Macro: 0.5685, Accuracy: 0.6344\n","Epoch 175, Train Loss: 0.5046, Val Loss: 0.6014, F1 Micro: 0.6344, F1 Macro: 0.5710, Accuracy: 0.6344\n","Epoch 176, Train Loss: 0.5017, Val Loss: 0.7783, F1 Micro: 0.6781, F1 Macro: 0.6549, Accuracy: 0.6781\n","Epoch 177, Train Loss: 0.4861, Val Loss: 0.5081, F1 Micro: 0.7750, F1 Macro: 0.7656, Accuracy: 0.7750\n","Epoch 178, Train Loss: 0.5500, Val Loss: 0.5155, F1 Micro: 0.7188, F1 Macro: 0.7099, Accuracy: 0.7188\n","Epoch 179, Train Loss: 0.5000, Val Loss: 0.5456, F1 Micro: 0.7438, F1 Macro: 0.7436, Accuracy: 0.7438\n","Epoch 180, Train Loss: 0.5354, Val Loss: 0.6675, F1 Micro: 0.6125, F1 Macro: 0.5330, Accuracy: 0.6125\n","Epoch 181, Train Loss: 0.4978, Val Loss: 0.6380, F1 Micro: 0.6094, F1 Macro: 0.5956, Accuracy: 0.6094\n","Epoch 182, Train Loss: 0.5695, Val Loss: 0.5843, F1 Micro: 0.6875, F1 Macro: 0.6667, Accuracy: 0.6875\n","Epoch 183, Train Loss: 0.5354, Val Loss: 0.4602, F1 Micro: 0.8000, F1 Macro: 0.7985, Accuracy: 0.8000\n","Epoch 184, Train Loss: 0.5437, Val Loss: 0.4906, F1 Micro: 0.7031, F1 Macro: 0.6948, Accuracy: 0.7031\n","Epoch 185, Train Loss: 0.5114, Val Loss: 0.6464, F1 Micro: 0.5875, F1 Macro: 0.4828, Accuracy: 0.5875\n","Epoch 186, Train Loss: 0.5381, Val Loss: 0.4537, F1 Micro: 0.7969, F1 Macro: 0.7958, Accuracy: 0.7969\n","Epoch 187, Train Loss: 0.5004, Val Loss: 0.4666, F1 Micro: 0.8187, F1 Macro: 0.8159, Accuracy: 0.8187\n","Epoch 188, Train Loss: 0.4991, Val Loss: 0.6916, F1 Micro: 0.6969, F1 Macro: 0.6802, Accuracy: 0.6969\n","Epoch 189, Train Loss: 0.5257, Val Loss: 0.5784, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 190, Train Loss: 0.5058, Val Loss: 0.6394, F1 Micro: 0.7594, F1 Macro: 0.7476, Accuracy: 0.7594\n","Epoch 191, Train Loss: 0.5092, Val Loss: 0.4684, F1 Micro: 0.7375, F1 Macro: 0.7348, Accuracy: 0.7375\n","Epoch 192, Train Loss: 0.5008, Val Loss: 0.5045, F1 Micro: 0.7875, F1 Macro: 0.7803, Accuracy: 0.7875\n","Epoch 193, Train Loss: 0.5022, Val Loss: 0.7463, F1 Micro: 0.7000, F1 Macro: 0.6821, Accuracy: 0.7000\n","Epoch 194, Train Loss: 0.5054, Val Loss: 0.6998, F1 Micro: 0.5875, F1 Macro: 0.4828, Accuracy: 0.5875\n","Epoch 195, Train Loss: 0.5097, Val Loss: 0.5948, F1 Micro: 0.7188, F1 Macro: 0.7085, Accuracy: 0.7188\n","Epoch 196, Train Loss: 0.5113, Val Loss: 1.1202, F1 Micro: 0.6062, F1 Macro: 0.5513, Accuracy: 0.6062\n","Epoch 197, Train Loss: 0.5382, Val Loss: 0.7063, F1 Micro: 0.6219, F1 Macro: 0.5512, Accuracy: 0.6219\n","Epoch 198, Train Loss: 0.4998, Val Loss: 1.1316, F1 Micro: 0.5219, F1 Macro: 0.3487, Accuracy: 0.5219\n","Epoch 199, Train Loss: 0.5023, Val Loss: 0.6684, F1 Micro: 0.7000, F1 Macro: 0.6983, Accuracy: 0.7000\n","Epoch 200, Train Loss: 0.5202, Val Loss: 0.6092, F1 Micro: 0.6813, F1 Macro: 0.6588, Accuracy: 0.6813\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6978, Val Loss: 0.6009, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 2, Train Loss: 0.6052, Val Loss: 0.7254, F1 Micro: 0.6094, F1 Macro: 0.5946, Accuracy: 0.6094\n","Epoch 3, Train Loss: 0.6240, Val Loss: 0.6391, F1 Micro: 0.6625, F1 Macro: 0.6510, Accuracy: 0.6625\n","Epoch 4, Train Loss: 0.6341, Val Loss: 0.6083, F1 Micro: 0.6531, F1 Macro: 0.6521, Accuracy: 0.6531\n","Epoch 5, Train Loss: 0.5907, Val Loss: 0.7184, F1 Micro: 0.6156, F1 Macro: 0.5991, Accuracy: 0.6156\n","Epoch 6, Train Loss: 0.6031, Val Loss: 0.9928, F1 Micro: 0.6281, F1 Macro: 0.5751, Accuracy: 0.6281\n","Epoch 7, Train Loss: 0.7475, Val Loss: 0.8392, F1 Micro: 0.4969, F1 Macro: 0.3319, Accuracy: 0.4969\n","Epoch 8, Train Loss: 0.6627, Val Loss: 0.6524, F1 Micro: 0.6594, F1 Macro: 0.6591, Accuracy: 0.6594\n","Epoch 9, Train Loss: 0.6647, Val Loss: 0.6366, F1 Micro: 0.6594, F1 Macro: 0.6579, Accuracy: 0.6594\n","Epoch 10, Train Loss: 0.6064, Val Loss: 0.6640, F1 Micro: 0.6562, F1 Macro: 0.6281, Accuracy: 0.6562\n","Epoch 11, Train Loss: 0.6063, Val Loss: 0.7151, F1 Micro: 0.6156, F1 Macro: 0.5991, Accuracy: 0.6156\n","Epoch 12, Train Loss: 0.6225, Val Loss: 0.6250, F1 Micro: 0.6656, F1 Macro: 0.6362, Accuracy: 0.6656\n","Epoch 13, Train Loss: 0.6436, Val Loss: 0.6325, F1 Micro: 0.6531, F1 Macro: 0.6531, Accuracy: 0.6531\n","Epoch 14, Train Loss: 0.6401, Val Loss: 0.6925, F1 Micro: 0.4969, F1 Macro: 0.3319, Accuracy: 0.4969\n","Epoch 15, Train Loss: 0.5801, Val Loss: 0.6343, F1 Micro: 0.6438, F1 Macro: 0.6258, Accuracy: 0.6438\n","Epoch 16, Train Loss: 0.5915, Val Loss: 0.6264, F1 Micro: 0.6531, F1 Macro: 0.6513, Accuracy: 0.6531\n","Epoch 17, Train Loss: 0.5869, Val Loss: 0.6312, F1 Micro: 0.6594, F1 Macro: 0.6588, Accuracy: 0.6594\n","Epoch 18, Train Loss: 0.5899, Val Loss: 0.6285, F1 Micro: 0.6594, F1 Macro: 0.6582, Accuracy: 0.6594\n","Epoch 19, Train Loss: 0.5878, Val Loss: 0.6071, F1 Micro: 0.6375, F1 Macro: 0.6193, Accuracy: 0.6375\n","Epoch 20, Train Loss: 0.5649, Val Loss: 0.6679, F1 Micro: 0.6312, F1 Macro: 0.6275, Accuracy: 0.6312\n","Epoch 21, Train Loss: 0.5858, Val Loss: 0.5946, F1 Micro: 0.6531, F1 Macro: 0.6484, Accuracy: 0.6531\n","Epoch 22, Train Loss: 0.6314, Val Loss: 0.6795, F1 Micro: 0.6312, F1 Macro: 0.6270, Accuracy: 0.6312\n","Epoch 23, Train Loss: 0.5798, Val Loss: 0.6245, F1 Micro: 0.6344, F1 Macro: 0.6176, Accuracy: 0.6344\n","Epoch 24, Train Loss: 0.5919, Val Loss: 0.7014, F1 Micro: 0.6594, F1 Macro: 0.6576, Accuracy: 0.6594\n","Epoch 25, Train Loss: 0.5787, Val Loss: 0.6254, F1 Micro: 0.6531, F1 Macro: 0.6461, Accuracy: 0.6531\n","Epoch 26, Train Loss: 0.6020, Val Loss: 0.5825, F1 Micro: 0.6625, F1 Macro: 0.6609, Accuracy: 0.6625\n","Epoch 27, Train Loss: 0.5898, Val Loss: 0.5993, F1 Micro: 0.6562, F1 Macro: 0.6483, Accuracy: 0.6562\n","Epoch 28, Train Loss: 0.6212, Val Loss: 0.5999, F1 Micro: 0.6469, F1 Macro: 0.6361, Accuracy: 0.6469\n","Epoch 29, Train Loss: 0.6038, Val Loss: 0.5862, F1 Micro: 0.6531, F1 Macro: 0.6498, Accuracy: 0.6531\n","Epoch 30, Train Loss: 0.5882, Val Loss: 0.5597, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 31, Train Loss: 0.5664, Val Loss: 0.5695, F1 Micro: 0.6781, F1 Macro: 0.6651, Accuracy: 0.6781\n","Epoch 32, Train Loss: 0.5539, Val Loss: 0.5864, F1 Micro: 0.6406, F1 Macro: 0.6394, Accuracy: 0.6406\n","Epoch 33, Train Loss: 0.6713, Val Loss: 0.9165, F1 Micro: 0.6344, F1 Macro: 0.5939, Accuracy: 0.6344\n","Epoch 34, Train Loss: 0.7014, Val Loss: 0.6767, F1 Micro: 0.6312, F1 Macro: 0.6204, Accuracy: 0.6312\n","Epoch 35, Train Loss: 0.6088, Val Loss: 0.7185, F1 Micro: 0.6469, F1 Macro: 0.6456, Accuracy: 0.6469\n","Epoch 36, Train Loss: 0.5748, Val Loss: 0.5529, F1 Micro: 0.6625, F1 Macro: 0.6518, Accuracy: 0.6625\n","Epoch 37, Train Loss: 0.5506, Val Loss: 0.6774, F1 Micro: 0.6594, F1 Macro: 0.6407, Accuracy: 0.6594\n","Epoch 38, Train Loss: 0.5504, Val Loss: 0.5407, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 39, Train Loss: 0.5396, Val Loss: 0.5342, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 40, Train Loss: 0.5489, Val Loss: 0.6524, F1 Micro: 0.6625, F1 Macro: 0.6493, Accuracy: 0.6625\n","Epoch 41, Train Loss: 0.5464, Val Loss: 0.5359, F1 Micro: 0.6594, F1 Macro: 0.6553, Accuracy: 0.6594\n","Epoch 42, Train Loss: 0.5615, Val Loss: 0.5469, F1 Micro: 0.6781, F1 Macro: 0.6777, Accuracy: 0.6781\n","Epoch 43, Train Loss: 0.5586, Val Loss: 0.8531, F1 Micro: 0.6656, F1 Macro: 0.6503, Accuracy: 0.6656\n","Epoch 44, Train Loss: 0.5624, Val Loss: 0.6123, F1 Micro: 0.6656, F1 Macro: 0.6451, Accuracy: 0.6656\n","Epoch 45, Train Loss: 0.5447, Val Loss: 0.6316, F1 Micro: 0.6531, F1 Macro: 0.6418, Accuracy: 0.6531\n","Epoch 46, Train Loss: 0.5546, Val Loss: 0.5246, F1 Micro: 0.6906, F1 Macro: 0.6899, Accuracy: 0.6906\n","Epoch 47, Train Loss: 0.6895, Val Loss: 0.5583, F1 Micro: 0.6750, F1 Macro: 0.6744, Accuracy: 0.6750\n","Epoch 48, Train Loss: 0.6233, Val Loss: 0.6050, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 49, Train Loss: 0.5637, Val Loss: 0.5420, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 50, Train Loss: 0.5377, Val Loss: 0.5657, F1 Micro: 0.6656, F1 Macro: 0.6427, Accuracy: 0.6656\n","Epoch 51, Train Loss: 0.5685, Val Loss: 0.5561, F1 Micro: 0.6937, F1 Macro: 0.6873, Accuracy: 0.6937\n","Epoch 52, Train Loss: 0.5518, Val Loss: 0.5369, F1 Micro: 0.7656, F1 Macro: 0.7639, Accuracy: 0.7656\n","Epoch 53, Train Loss: 0.5426, Val Loss: 0.6241, F1 Micro: 0.6594, F1 Macro: 0.6428, Accuracy: 0.6594\n","Epoch 54, Train Loss: 0.5190, Val Loss: 0.5988, F1 Micro: 0.6406, F1 Macro: 0.5894, Accuracy: 0.6406\n","Epoch 55, Train Loss: 0.5492, Val Loss: 0.5193, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 56, Train Loss: 0.5413, Val Loss: 0.7929, F1 Micro: 0.6344, F1 Macro: 0.5823, Accuracy: 0.6344\n","Epoch 57, Train Loss: 0.5998, Val Loss: 0.5401, F1 Micro: 0.7781, F1 Macro: 0.7770, Accuracy: 0.7781\n","Epoch 58, Train Loss: 0.6036, Val Loss: 0.5619, F1 Micro: 0.6750, F1 Macro: 0.6737, Accuracy: 0.6750\n","Epoch 59, Train Loss: 0.5394, Val Loss: 0.5821, F1 Micro: 0.6625, F1 Macro: 0.6388, Accuracy: 0.6625\n","Epoch 60, Train Loss: 0.5688, Val Loss: 0.6028, F1 Micro: 0.6656, F1 Macro: 0.6376, Accuracy: 0.6656\n","Epoch 61, Train Loss: 0.5414, Val Loss: 0.5098, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 62, Train Loss: 0.5757, Val Loss: 0.5748, F1 Micro: 0.6406, F1 Macro: 0.6368, Accuracy: 0.6406\n","Epoch 63, Train Loss: 0.5788, Val Loss: 0.6002, F1 Micro: 0.6281, F1 Macro: 0.6258, Accuracy: 0.6281\n","Epoch 64, Train Loss: 0.5876, Val Loss: 0.7195, F1 Micro: 0.6250, F1 Macro: 0.5705, Accuracy: 0.6250\n","Epoch 65, Train Loss: 0.5473, Val Loss: 0.7507, F1 Micro: 0.6469, F1 Macro: 0.6043, Accuracy: 0.6469\n","Epoch 66, Train Loss: 0.5626, Val Loss: 0.5697, F1 Micro: 0.7000, F1 Macro: 0.6905, Accuracy: 0.7000\n","Epoch 67, Train Loss: 0.5274, Val Loss: 0.7878, F1 Micro: 0.6562, F1 Macro: 0.6157, Accuracy: 0.6562\n","Epoch 68, Train Loss: 0.5657, Val Loss: 0.5839, F1 Micro: 0.6625, F1 Macro: 0.6375, Accuracy: 0.6625\n","Epoch 69, Train Loss: 0.5597, Val Loss: 0.5381, F1 Micro: 0.6719, F1 Macro: 0.6586, Accuracy: 0.6719\n","Epoch 70, Train Loss: 0.5425, Val Loss: 0.5465, F1 Micro: 0.6813, F1 Macro: 0.6611, Accuracy: 0.6813\n","Epoch 71, Train Loss: 0.5604, Val Loss: 0.6205, F1 Micro: 0.6625, F1 Macro: 0.6388, Accuracy: 0.6625\n","Epoch 72, Train Loss: 0.5403, Val Loss: 0.5152, F1 Micro: 0.7031, F1 Macro: 0.6941, Accuracy: 0.7031\n","Epoch 73, Train Loss: 0.5949, Val Loss: 0.6425, F1 Micro: 0.6656, F1 Macro: 0.6439, Accuracy: 0.6656\n","Epoch 74, Train Loss: 0.5440, Val Loss: 0.5872, F1 Micro: 0.6906, F1 Macro: 0.6671, Accuracy: 0.6906\n","Epoch 75, Train Loss: 0.5620, Val Loss: 0.7346, F1 Micro: 0.6312, F1 Macro: 0.5776, Accuracy: 0.6312\n","Epoch 76, Train Loss: 0.5435, Val Loss: 0.5080, F1 Micro: 0.7156, F1 Macro: 0.7088, Accuracy: 0.7156\n","Epoch 77, Train Loss: 0.5884, Val Loss: 0.5944, F1 Micro: 0.6594, F1 Macro: 0.6384, Accuracy: 0.6594\n","Epoch 78, Train Loss: 0.5645, Val Loss: 0.5521, F1 Micro: 0.6687, F1 Macro: 0.6442, Accuracy: 0.6687\n","Epoch 79, Train Loss: 0.5407, Val Loss: 0.5337, F1 Micro: 0.7406, F1 Macro: 0.7315, Accuracy: 0.7406\n","Epoch 80, Train Loss: 0.5621, Val Loss: 0.8898, F1 Micro: 0.6125, F1 Macro: 0.5466, Accuracy: 0.6125\n","Epoch 81, Train Loss: 0.5567, Val Loss: 0.5927, F1 Micro: 0.6594, F1 Macro: 0.6280, Accuracy: 0.6594\n","Epoch 82, Train Loss: 0.5581, Val Loss: 0.5606, F1 Micro: 0.6813, F1 Macro: 0.6622, Accuracy: 0.6813\n","Epoch 83, Train Loss: 0.6105, Val Loss: 0.4999, F1 Micro: 0.7031, F1 Macro: 0.6971, Accuracy: 0.7031\n","Epoch 84, Train Loss: 0.5682, Val Loss: 0.5697, F1 Micro: 0.6312, F1 Macro: 0.6295, Accuracy: 0.6312\n","Epoch 85, Train Loss: 0.5591, Val Loss: 0.6372, F1 Micro: 0.6281, F1 Macro: 0.5730, Accuracy: 0.6281\n","Epoch 86, Train Loss: 0.5399, Val Loss: 0.5567, F1 Micro: 0.6625, F1 Macro: 0.6335, Accuracy: 0.6625\n","Epoch 87, Train Loss: 0.5675, Val Loss: 0.5110, F1 Micro: 0.7937, F1 Macro: 0.7937, Accuracy: 0.7937\n","Epoch 88, Train Loss: 0.5684, Val Loss: 0.6030, F1 Micro: 0.6656, F1 Macro: 0.6493, Accuracy: 0.6656\n","Epoch 89, Train Loss: 0.5592, Val Loss: 0.5988, F1 Micro: 0.6719, F1 Macro: 0.6494, Accuracy: 0.6719\n","Epoch 90, Train Loss: 0.5162, Val Loss: 0.5064, F1 Micro: 0.7781, F1 Macro: 0.7779, Accuracy: 0.7781\n","Epoch 91, Train Loss: 0.5291, Val Loss: 0.5592, F1 Micro: 0.6687, F1 Macro: 0.6511, Accuracy: 0.6687\n","Epoch 92, Train Loss: 0.5451, Val Loss: 0.6252, F1 Micro: 0.6469, F1 Macro: 0.6078, Accuracy: 0.6469\n","Epoch 93, Train Loss: 0.5656, Val Loss: 0.7901, F1 Micro: 0.5531, F1 Macro: 0.4455, Accuracy: 0.5531\n","Epoch 94, Train Loss: 0.5611, Val Loss: 0.8481, F1 Micro: 0.6281, F1 Macro: 0.5707, Accuracy: 0.6281\n","Epoch 95, Train Loss: 0.5864, Val Loss: 0.6055, F1 Micro: 0.6625, F1 Macro: 0.6335, Accuracy: 0.6625\n","Epoch 96, Train Loss: 0.5574, Val Loss: 0.6503, F1 Micro: 0.6406, F1 Macro: 0.6119, Accuracy: 0.6406\n","Epoch 97, Train Loss: 0.5239, Val Loss: 0.5297, F1 Micro: 0.6500, F1 Macro: 0.6324, Accuracy: 0.6500\n","Epoch 98, Train Loss: 0.5681, Val Loss: 0.5943, F1 Micro: 0.7438, F1 Macro: 0.7267, Accuracy: 0.7438\n","Epoch 99, Train Loss: 0.5418, Val Loss: 0.6317, F1 Micro: 0.6094, F1 Macro: 0.5491, Accuracy: 0.6094\n","Epoch 100, Train Loss: 0.5280, Val Loss: 0.6220, F1 Micro: 0.5875, F1 Macro: 0.5029, Accuracy: 0.5875\n","Epoch 101, Train Loss: 0.5293, Val Loss: 0.5470, F1 Micro: 0.6594, F1 Macro: 0.6384, Accuracy: 0.6594\n","Epoch 102, Train Loss: 0.5618, Val Loss: 0.5500, F1 Micro: 0.6687, F1 Macro: 0.6455, Accuracy: 0.6687\n","Epoch 103, Train Loss: 0.5396, Val Loss: 0.5589, F1 Micro: 0.7063, F1 Macro: 0.7029, Accuracy: 0.7063\n","Epoch 104, Train Loss: 0.5737, Val Loss: 0.5813, F1 Micro: 0.6281, F1 Macro: 0.5707, Accuracy: 0.6281\n","Epoch 105, Train Loss: 0.5322, Val Loss: 0.7643, F1 Micro: 0.6344, F1 Macro: 0.5823, Accuracy: 0.6344\n","Epoch 106, Train Loss: 0.5487, Val Loss: 0.5252, F1 Micro: 0.6750, F1 Macro: 0.6596, Accuracy: 0.6750\n","Epoch 107, Train Loss: 0.5245, Val Loss: 0.5727, F1 Micro: 0.7625, F1 Macro: 0.7579, Accuracy: 0.7625\n","Epoch 108, Train Loss: 0.5779, Val Loss: 0.6333, F1 Micro: 0.6094, F1 Macro: 0.5467, Accuracy: 0.6094\n","Epoch 109, Train Loss: 0.5534, Val Loss: 1.1361, F1 Micro: 0.6281, F1 Macro: 0.5773, Accuracy: 0.6281\n","Epoch 110, Train Loss: 0.5429, Val Loss: 0.5060, F1 Micro: 0.7125, F1 Macro: 0.7084, Accuracy: 0.7125\n","Epoch 111, Train Loss: 0.5398, Val Loss: 0.7549, F1 Micro: 0.6562, F1 Macro: 0.6207, Accuracy: 0.6562\n","Epoch 112, Train Loss: 0.5376, Val Loss: 0.5572, F1 Micro: 0.7844, F1 Macro: 0.7831, Accuracy: 0.7844\n","Epoch 113, Train Loss: 0.5176, Val Loss: 0.5859, F1 Micro: 0.6656, F1 Macro: 0.6253, Accuracy: 0.6656\n","Epoch 114, Train Loss: 0.5183, Val Loss: 0.6781, F1 Micro: 0.5969, F1 Macro: 0.5322, Accuracy: 0.5969\n","Epoch 115, Train Loss: 0.5769, Val Loss: 0.7929, F1 Micro: 0.5687, F1 Macro: 0.4737, Accuracy: 0.5687\n","Epoch 116, Train Loss: 0.5398, Val Loss: 0.6079, F1 Micro: 0.6562, F1 Macro: 0.6190, Accuracy: 0.6562\n","Epoch 117, Train Loss: 0.5434, Val Loss: 0.6670, F1 Micro: 0.6531, F1 Macro: 0.6196, Accuracy: 0.6531\n","Epoch 118, Train Loss: 0.5741, Val Loss: 0.6312, F1 Micro: 0.6406, F1 Macro: 0.5991, Accuracy: 0.6406\n","Epoch 119, Train Loss: 0.5437, Val Loss: 0.6222, F1 Micro: 0.6656, F1 Macro: 0.6302, Accuracy: 0.6656\n","Epoch 120, Train Loss: 0.5317, Val Loss: 0.7059, F1 Micro: 0.6375, F1 Macro: 0.5947, Accuracy: 0.6375\n","Epoch 121, Train Loss: 0.5274, Val Loss: 0.5130, F1 Micro: 0.8313, F1 Macro: 0.8295, Accuracy: 0.8313\n","Epoch 122, Train Loss: 0.5085, Val Loss: 0.9187, F1 Micro: 0.5844, F1 Macro: 0.5067, Accuracy: 0.5844\n","Epoch 123, Train Loss: 0.5501, Val Loss: 0.5350, F1 Micro: 0.6625, F1 Macro: 0.6400, Accuracy: 0.6625\n","Epoch 124, Train Loss: 0.5297, Val Loss: 0.4985, F1 Micro: 0.6750, F1 Macro: 0.6623, Accuracy: 0.6750\n","Epoch 125, Train Loss: 0.5134, Val Loss: 0.6155, F1 Micro: 0.6406, F1 Macro: 0.5954, Accuracy: 0.6406\n","Epoch 126, Train Loss: 0.5159, Val Loss: 0.6056, F1 Micro: 0.6656, F1 Macro: 0.6389, Accuracy: 0.6656\n","Epoch 127, Train Loss: 0.5131, Val Loss: 0.6319, F1 Micro: 0.6562, F1 Macro: 0.6253, Accuracy: 0.6562\n","Epoch 128, Train Loss: 0.5292, Val Loss: 0.6615, F1 Micro: 0.6562, F1 Macro: 0.6102, Accuracy: 0.6562\n","Epoch 129, Train Loss: 0.5223, Val Loss: 0.5798, F1 Micro: 0.6531, F1 Macro: 0.6226, Accuracy: 0.6531\n","Epoch 130, Train Loss: 0.5268, Val Loss: 0.6560, F1 Micro: 0.6031, F1 Macro: 0.5443, Accuracy: 0.6031\n","Epoch 131, Train Loss: 0.5258, Val Loss: 0.5637, F1 Micro: 0.6500, F1 Macro: 0.6214, Accuracy: 0.6500\n","Epoch 132, Train Loss: 0.4906, Val Loss: 0.9494, F1 Micro: 0.6469, F1 Macro: 0.6111, Accuracy: 0.6469\n","Epoch 133, Train Loss: 0.5050, Val Loss: 0.5029, F1 Micro: 0.7469, F1 Macro: 0.7434, Accuracy: 0.7469\n","Epoch 134, Train Loss: 0.5469, Val Loss: 0.5705, F1 Micro: 0.6375, F1 Macro: 0.6000, Accuracy: 0.6375\n","Epoch 135, Train Loss: 0.5060, Val Loss: 0.5318, F1 Micro: 0.6969, F1 Macro: 0.6890, Accuracy: 0.6969\n","Epoch 136, Train Loss: 0.5276, Val Loss: 0.6878, F1 Micro: 0.5406, F1 Macro: 0.4178, Accuracy: 0.5406\n","Epoch 137, Train Loss: 0.4902, Val Loss: 0.4971, F1 Micro: 0.7719, F1 Macro: 0.7715, Accuracy: 0.7719\n","Epoch 138, Train Loss: 0.4948, Val Loss: 0.5226, F1 Micro: 0.7688, F1 Macro: 0.7614, Accuracy: 0.7688\n","Epoch 139, Train Loss: 0.5397, Val Loss: 0.5786, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 140, Train Loss: 0.5138, Val Loss: 0.5697, F1 Micro: 0.7188, F1 Macro: 0.7000, Accuracy: 0.7188\n","Epoch 141, Train Loss: 0.5053, Val Loss: 0.6243, F1 Micro: 0.6469, F1 Macro: 0.6095, Accuracy: 0.6469\n","Epoch 142, Train Loss: 0.5256, Val Loss: 1.0142, F1 Micro: 0.5469, F1 Macro: 0.4338, Accuracy: 0.5469\n","Epoch 143, Train Loss: 0.4946, Val Loss: 0.4977, F1 Micro: 0.7500, F1 Macro: 0.7500, Accuracy: 0.7500\n","Epoch 144, Train Loss: 0.5344, Val Loss: 0.5769, F1 Micro: 0.6625, F1 Macro: 0.6306, Accuracy: 0.6625\n","Epoch 145, Train Loss: 0.5499, Val Loss: 0.5226, F1 Micro: 0.8000, F1 Macro: 0.7954, Accuracy: 0.8000\n","Epoch 146, Train Loss: 0.5141, Val Loss: 0.4987, F1 Micro: 0.7188, F1 Macro: 0.7117, Accuracy: 0.7188\n","Epoch 147, Train Loss: 0.5073, Val Loss: 0.6447, F1 Micro: 0.6625, F1 Macro: 0.6321, Accuracy: 0.6625\n","Epoch 148, Train Loss: 0.5510, Val Loss: 0.8014, F1 Micro: 0.6406, F1 Macro: 0.5935, Accuracy: 0.6406\n","Epoch 149, Train Loss: 0.5116, Val Loss: 0.4974, F1 Micro: 0.7937, F1 Macro: 0.7929, Accuracy: 0.7937\n","Epoch 150, Train Loss: 0.5025, Val Loss: 0.5161, F1 Micro: 0.8062, F1 Macro: 0.8029, Accuracy: 0.8063\n","Epoch 151, Train Loss: 0.5328, Val Loss: 0.6879, F1 Micro: 0.6562, F1 Macro: 0.6357, Accuracy: 0.6562\n","Epoch 152, Train Loss: 0.5019, Val Loss: 1.3177, F1 Micro: 0.5000, F1 Macro: 0.3333, Accuracy: 0.5000\n","Epoch 153, Train Loss: 0.6001, Val Loss: 0.5301, F1 Micro: 0.7781, F1 Macro: 0.7714, Accuracy: 0.7781\n","Epoch 154, Train Loss: 0.5115, Val Loss: 0.4884, F1 Micro: 0.8094, F1 Macro: 0.8082, Accuracy: 0.8094\n","Epoch 155, Train Loss: 0.5132, Val Loss: 0.5244, F1 Micro: 0.8156, F1 Macro: 0.8112, Accuracy: 0.8156\n","Epoch 156, Train Loss: 0.4797, Val Loss: 0.8719, F1 Micro: 0.5469, F1 Macro: 0.4298, Accuracy: 0.5469\n","Epoch 157, Train Loss: 0.4943, Val Loss: 0.4827, F1 Micro: 0.7500, F1 Macro: 0.7464, Accuracy: 0.7500\n","Epoch 158, Train Loss: 0.4819, Val Loss: 0.5376, F1 Micro: 0.7781, F1 Macro: 0.7770, Accuracy: 0.7781\n","Epoch 159, Train Loss: 0.4880, Val Loss: 1.1468, F1 Micro: 0.5500, F1 Macro: 0.4472, Accuracy: 0.5500\n","Epoch 160, Train Loss: 0.4936, Val Loss: 0.5464, F1 Micro: 0.7312, F1 Macro: 0.7185, Accuracy: 0.7312\n","Epoch 161, Train Loss: 0.4969, Val Loss: 0.4922, F1 Micro: 0.8031, F1 Macro: 0.8019, Accuracy: 0.8031\n","Epoch 162, Train Loss: 0.5056, Val Loss: 0.9538, F1 Micro: 0.5469, F1 Macro: 0.4298, Accuracy: 0.5469\n","Epoch 163, Train Loss: 0.4861, Val Loss: 0.4713, F1 Micro: 0.7781, F1 Macro: 0.7779, Accuracy: 0.7781\n","Epoch 164, Train Loss: 0.5429, Val Loss: 0.6466, F1 Micro: 0.6500, F1 Macro: 0.6185, Accuracy: 0.6500\n","Epoch 165, Train Loss: 0.4976, Val Loss: 0.4758, F1 Micro: 0.7688, F1 Macro: 0.7672, Accuracy: 0.7688\n","Epoch 166, Train Loss: 0.4929, Val Loss: 0.5449, F1 Micro: 0.6719, F1 Macro: 0.6506, Accuracy: 0.6719\n","Epoch 167, Train Loss: 0.5157, Val Loss: 0.5209, F1 Micro: 0.7969, F1 Macro: 0.7916, Accuracy: 0.7969\n","Epoch 168, Train Loss: 0.4829, Val Loss: 0.5381, F1 Micro: 0.7406, F1 Macro: 0.7280, Accuracy: 0.7406\n","Epoch 169, Train Loss: 0.4809, Val Loss: 0.4817, F1 Micro: 0.7937, F1 Macro: 0.7938, Accuracy: 0.7937\n","Epoch 170, Train Loss: 0.4747, Val Loss: 0.5132, F1 Micro: 0.7594, F1 Macro: 0.7592, Accuracy: 0.7594\n","Epoch 171, Train Loss: 0.5136, Val Loss: 1.0750, F1 Micro: 0.5344, F1 Macro: 0.4055, Accuracy: 0.5344\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8012, Val Loss: 0.5425, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 2, Train Loss: 0.6213, Val Loss: 0.5600, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 3, Train Loss: 0.6103, Val Loss: 0.6276, F1 Micro: 0.6219, F1 Macro: 0.5973, Accuracy: 0.6219\n","Epoch 4, Train Loss: 0.6170, Val Loss: 0.5649, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 5, Train Loss: 0.6485, Val Loss: 0.5624, F1 Micro: 0.6906, F1 Macro: 0.6869, Accuracy: 0.6906\n","Epoch 6, Train Loss: 0.7098, Val Loss: 0.5661, F1 Micro: 0.7063, F1 Macro: 0.7001, Accuracy: 0.7063\n","Epoch 7, Train Loss: 0.6409, Val Loss: 0.5924, F1 Micro: 0.6875, F1 Macro: 0.6644, Accuracy: 0.6875\n","Epoch 8, Train Loss: 0.6258, Val Loss: 0.6178, F1 Micro: 0.7156, F1 Macro: 0.7122, Accuracy: 0.7156\n","Epoch 9, Train Loss: 0.6213, Val Loss: 0.5545, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 10, Train Loss: 0.6412, Val Loss: 0.5580, F1 Micro: 0.6969, F1 Macro: 0.6802, Accuracy: 0.6969\n","Epoch 11, Train Loss: 0.5996, Val Loss: 0.5434, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 12, Train Loss: 0.6070, Val Loss: 0.5342, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.6209, Val Loss: 0.5326, F1 Micro: 0.7188, F1 Macro: 0.7186, Accuracy: 0.7188\n","Epoch 14, Train Loss: 0.6581, Val Loss: 0.5410, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 15, Train Loss: 0.6424, Val Loss: 0.5469, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 16, Train Loss: 0.6396, Val Loss: 0.5795, F1 Micro: 0.6813, F1 Macro: 0.6577, Accuracy: 0.6813\n","Epoch 17, Train Loss: 0.5974, Val Loss: 0.5538, F1 Micro: 0.6937, F1 Macro: 0.6928, Accuracy: 0.6937\n","Epoch 18, Train Loss: 0.5936, Val Loss: 0.6195, F1 Micro: 0.6750, F1 Macro: 0.6655, Accuracy: 0.6750\n","Epoch 19, Train Loss: 0.6412, Val Loss: 0.5812, F1 Micro: 0.6844, F1 Macro: 0.6780, Accuracy: 0.6844\n","Epoch 20, Train Loss: 0.6379, Val Loss: 0.5448, F1 Micro: 0.6969, F1 Macro: 0.6958, Accuracy: 0.6969\n","Epoch 21, Train Loss: 0.6277, Val Loss: 0.5280, F1 Micro: 0.7156, F1 Macro: 0.7070, Accuracy: 0.7156\n","Epoch 22, Train Loss: 0.5963, Val Loss: 0.5233, F1 Micro: 0.7250, F1 Macro: 0.7239, Accuracy: 0.7250\n","Epoch 23, Train Loss: 0.5838, Val Loss: 0.6097, F1 Micro: 0.6594, F1 Macro: 0.6465, Accuracy: 0.6594\n","Epoch 24, Train Loss: 0.6371, Val Loss: 0.5775, F1 Micro: 0.6969, F1 Macro: 0.6913, Accuracy: 0.6969\n","Epoch 25, Train Loss: 0.6716, Val Loss: 0.6977, F1 Micro: 0.5312, F1 Macro: 0.5142, Accuracy: 0.5312\n","Epoch 26, Train Loss: 0.6658, Val Loss: 0.5786, F1 Micro: 0.7156, F1 Macro: 0.7118, Accuracy: 0.7156\n","Epoch 27, Train Loss: 0.6077, Val Loss: 0.5343, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 28, Train Loss: 0.6025, Val Loss: 0.5927, F1 Micro: 0.6875, F1 Macro: 0.6830, Accuracy: 0.6875\n","Epoch 29, Train Loss: 0.6048, Val Loss: 0.6045, F1 Micro: 0.7063, F1 Macro: 0.7057, Accuracy: 0.7063\n","Epoch 30, Train Loss: 0.5868, Val Loss: 0.5153, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 31, Train Loss: 0.6496, Val Loss: 0.5975, F1 Micro: 0.6906, F1 Macro: 0.6887, Accuracy: 0.6906\n","Epoch 32, Train Loss: 0.6557, Val Loss: 0.5733, F1 Micro: 0.6844, F1 Macro: 0.6524, Accuracy: 0.6844\n","Epoch 33, Train Loss: 0.6253, Val Loss: 0.5216, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 34, Train Loss: 0.5812, Val Loss: 0.6386, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 35, Train Loss: 0.5897, Val Loss: 0.5206, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 36, Train Loss: 0.6141, Val Loss: 0.5303, F1 Micro: 0.7250, F1 Macro: 0.7247, Accuracy: 0.7250\n","Epoch 37, Train Loss: 0.5744, Val Loss: 0.5245, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 38, Train Loss: 0.5725, Val Loss: 0.5017, F1 Micro: 0.7281, F1 Macro: 0.7179, Accuracy: 0.7281\n","Epoch 39, Train Loss: 0.5984, Val Loss: 0.4896, F1 Micro: 0.7531, F1 Macro: 0.7477, Accuracy: 0.7531\n","Epoch 40, Train Loss: 0.5715, Val Loss: 0.4890, F1 Micro: 0.7469, F1 Macro: 0.7418, Accuracy: 0.7469\n","Epoch 41, Train Loss: 0.5786, Val Loss: 0.5548, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 42, Train Loss: 0.5662, Val Loss: 0.5734, F1 Micro: 0.7219, F1 Macro: 0.7177, Accuracy: 0.7219\n","Epoch 43, Train Loss: 0.5715, Val Loss: 0.5282, F1 Micro: 0.7594, F1 Macro: 0.7588, Accuracy: 0.7594\n","Epoch 44, Train Loss: 0.5651, Val Loss: 0.7308, F1 Micro: 0.6188, F1 Macro: 0.5038, Accuracy: 0.6188\n","Epoch 45, Train Loss: 0.5708, Val Loss: 0.4961, F1 Micro: 0.7375, F1 Macro: 0.7200, Accuracy: 0.7375\n","Epoch 46, Train Loss: 0.6129, Val Loss: 0.4710, F1 Micro: 0.7594, F1 Macro: 0.7557, Accuracy: 0.7594\n","Epoch 47, Train Loss: 0.6203, Val Loss: 0.5675, F1 Micro: 0.7188, F1 Macro: 0.6946, Accuracy: 0.7188\n","Epoch 48, Train Loss: 0.5508, Val Loss: 0.7972, F1 Micro: 0.4688, F1 Macro: 0.3474, Accuracy: 0.4688\n","Epoch 49, Train Loss: 0.5941, Val Loss: 0.6639, F1 Micro: 0.7250, F1 Macro: 0.6911, Accuracy: 0.7250\n","Epoch 50, Train Loss: 0.5693, Val Loss: 0.5086, F1 Micro: 0.7125, F1 Macro: 0.7121, Accuracy: 0.7125\n","Epoch 51, Train Loss: 0.5721, Val Loss: 0.4924, F1 Micro: 0.7375, F1 Macro: 0.7337, Accuracy: 0.7375\n","Epoch 52, Train Loss: 0.5765, Val Loss: 0.6534, F1 Micro: 0.7188, F1 Macro: 0.6841, Accuracy: 0.7188\n","Epoch 53, Train Loss: 0.5808, Val Loss: 0.5805, F1 Micro: 0.8000, F1 Macro: 0.7999, Accuracy: 0.8000\n","Epoch 54, Train Loss: 0.5609, Val Loss: 0.6160, F1 Micro: 0.7438, F1 Macro: 0.7160, Accuracy: 0.7438\n","Epoch 55, Train Loss: 0.5426, Val Loss: 0.4689, F1 Micro: 0.7531, F1 Macro: 0.7498, Accuracy: 0.7531\n","Epoch 56, Train Loss: 0.5911, Val Loss: 0.9268, F1 Micro: 0.5375, F1 Macro: 0.4675, Accuracy: 0.5375\n","Epoch 57, Train Loss: 0.5989, Val Loss: 0.5024, F1 Micro: 0.7688, F1 Macro: 0.7489, Accuracy: 0.7688\n","Epoch 58, Train Loss: 0.5601, Val Loss: 0.5160, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 59, Train Loss: 0.5698, Val Loss: 0.4798, F1 Micro: 0.7500, F1 Macro: 0.7478, Accuracy: 0.7500\n","Epoch 60, Train Loss: 0.5617, Val Loss: 0.4937, F1 Micro: 0.7625, F1 Macro: 0.7624, Accuracy: 0.7625\n","Epoch 61, Train Loss: 0.5626, Val Loss: 0.5144, F1 Micro: 0.7188, F1 Macro: 0.6957, Accuracy: 0.7188\n","Epoch 62, Train Loss: 0.5540, Val Loss: 0.5307, F1 Micro: 0.7500, F1 Macro: 0.7264, Accuracy: 0.7500\n","Epoch 63, Train Loss: 0.5829, Val Loss: 0.5217, F1 Micro: 0.7594, F1 Macro: 0.7382, Accuracy: 0.7594\n","Epoch 64, Train Loss: 0.5868, Val Loss: 0.4948, F1 Micro: 0.7500, F1 Macro: 0.7475, Accuracy: 0.7500\n","Epoch 65, Train Loss: 0.5703, Val Loss: 0.6068, F1 Micro: 0.5844, F1 Macro: 0.5423, Accuracy: 0.5844\n","Epoch 66, Train Loss: 0.5786, Val Loss: 0.5413, F1 Micro: 0.7312, F1 Macro: 0.6995, Accuracy: 0.7312\n","Epoch 67, Train Loss: 0.6197, Val Loss: 0.4876, F1 Micro: 0.7594, F1 Macro: 0.7392, Accuracy: 0.7594\n","Epoch 68, Train Loss: 0.5720, Val Loss: 0.6649, F1 Micro: 0.7219, F1 Macro: 0.6883, Accuracy: 0.7219\n","Epoch 69, Train Loss: 0.5840, Val Loss: 0.5143, F1 Micro: 0.7188, F1 Macro: 0.7166, Accuracy: 0.7188\n","Epoch 70, Train Loss: 0.6218, Val Loss: 0.6338, F1 Micro: 0.5500, F1 Macro: 0.4945, Accuracy: 0.5500\n","Epoch 71, Train Loss: 0.5325, Val Loss: 0.6608, F1 Micro: 0.6375, F1 Macro: 0.5486, Accuracy: 0.6375\n","Epoch 72, Train Loss: 0.5425, Val Loss: 0.4826, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 73, Train Loss: 0.5366, Val Loss: 0.6478, F1 Micro: 0.4906, F1 Macro: 0.3918, Accuracy: 0.4906\n","Epoch 74, Train Loss: 0.5620, Val Loss: 0.4741, F1 Micro: 0.7469, F1 Macro: 0.7330, Accuracy: 0.7469\n","Epoch 75, Train Loss: 0.5660, Val Loss: 0.5774, F1 Micro: 0.7156, F1 Macro: 0.6767, Accuracy: 0.7156\n","Epoch 76, Train Loss: 0.5402, Val Loss: 0.4825, F1 Micro: 0.7719, F1 Macro: 0.7554, Accuracy: 0.7719\n","Epoch 77, Train Loss: 0.5409, Val Loss: 0.5813, F1 Micro: 0.7125, F1 Macro: 0.7106, Accuracy: 0.7125\n","Epoch 78, Train Loss: 0.6569, Val Loss: 0.5243, F1 Micro: 0.7562, F1 Macro: 0.7382, Accuracy: 0.7562\n","Epoch 79, Train Loss: 0.7077, Val Loss: 0.6769, F1 Micro: 0.5125, F1 Macro: 0.4264, Accuracy: 0.5125\n","Epoch 80, Train Loss: 0.6244, Val Loss: 0.4778, F1 Micro: 0.7531, F1 Macro: 0.7334, Accuracy: 0.7531\n","Epoch 81, Train Loss: 0.5630, Val Loss: 0.6797, F1 Micro: 0.5000, F1 Macro: 0.4117, Accuracy: 0.5000\n","Epoch 82, Train Loss: 0.5517, Val Loss: 0.8571, F1 Micro: 0.5125, F1 Macro: 0.4643, Accuracy: 0.5125\n","Epoch 83, Train Loss: 0.5616, Val Loss: 0.4738, F1 Micro: 0.7969, F1 Macro: 0.7931, Accuracy: 0.7969\n","Epoch 84, Train Loss: 0.5312, Val Loss: 0.5211, F1 Micro: 0.7438, F1 Macro: 0.7148, Accuracy: 0.7438\n","Epoch 85, Train Loss: 0.5546, Val Loss: 0.4963, F1 Micro: 0.7719, F1 Macro: 0.7627, Accuracy: 0.7719\n","Epoch 86, Train Loss: 0.5544, Val Loss: 0.7122, F1 Micro: 0.7156, F1 Macro: 0.6767, Accuracy: 0.7156\n","Epoch 87, Train Loss: 0.5490, Val Loss: 0.5577, F1 Micro: 0.7781, F1 Macro: 0.7772, Accuracy: 0.7781\n","Epoch 88, Train Loss: 0.5753, Val Loss: 0.7103, F1 Micro: 0.6594, F1 Macro: 0.5829, Accuracy: 0.6594\n","Epoch 89, Train Loss: 0.5759, Val Loss: 0.6033, F1 Micro: 0.6781, F1 Macro: 0.6133, Accuracy: 0.6781\n","Epoch 90, Train Loss: 0.5490, Val Loss: 0.5983, F1 Micro: 0.6594, F1 Macro: 0.6438, Accuracy: 0.6594\n","Epoch 91, Train Loss: 0.5819, Val Loss: 0.5357, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 92, Train Loss: 0.5689, Val Loss: 0.4836, F1 Micro: 0.8031, F1 Macro: 0.7962, Accuracy: 0.8031\n","Epoch 93, Train Loss: 0.5437, Val Loss: 0.4861, F1 Micro: 0.7281, F1 Macro: 0.7114, Accuracy: 0.7281\n","Epoch 94, Train Loss: 0.5511, Val Loss: 0.6058, F1 Micro: 0.7281, F1 Macro: 0.7205, Accuracy: 0.7281\n","Epoch 95, Train Loss: 0.5774, Val Loss: 0.5644, F1 Micro: 0.7594, F1 Macro: 0.7554, Accuracy: 0.7594\n","Epoch 96, Train Loss: 0.5782, Val Loss: 0.4853, F1 Micro: 0.7719, F1 Macro: 0.7563, Accuracy: 0.7719\n","Epoch 97, Train Loss: 0.5788, Val Loss: 0.5211, F1 Micro: 0.8187, F1 Macro: 0.8156, Accuracy: 0.8187\n","Epoch 98, Train Loss: 0.5203, Val Loss: 0.4914, F1 Micro: 0.7719, F1 Macro: 0.7707, Accuracy: 0.7719\n","Epoch 99, Train Loss: 0.5333, Val Loss: 0.5425, F1 Micro: 0.7125, F1 Macro: 0.6690, Accuracy: 0.7125\n","Epoch 100, Train Loss: 0.5667, Val Loss: 0.6535, F1 Micro: 0.5687, F1 Macro: 0.5626, Accuracy: 0.5687\n","Epoch 101, Train Loss: 0.5229, Val Loss: 0.5535, F1 Micro: 0.7344, F1 Macro: 0.7023, Accuracy: 0.7344\n","Epoch 102, Train Loss: 0.5174, Val Loss: 1.1603, F1 Micro: 0.4562, F1 Macro: 0.3275, Accuracy: 0.4562\n","Epoch 103, Train Loss: 0.5268, Val Loss: 0.9330, F1 Micro: 0.5125, F1 Macro: 0.4416, Accuracy: 0.5125\n","Epoch 104, Train Loss: 0.5506, Val Loss: 0.9649, F1 Micro: 0.4969, F1 Macro: 0.4028, Accuracy: 0.4969\n","Epoch 105, Train Loss: 0.5276, Val Loss: 0.9406, F1 Micro: 0.4531, F1 Macro: 0.3214, Accuracy: 0.4531\n","Epoch 106, Train Loss: 0.5245, Val Loss: 0.5077, F1 Micro: 0.8281, F1 Macro: 0.8278, Accuracy: 0.8281\n","Epoch 107, Train Loss: 0.5449, Val Loss: 1.3016, F1 Micro: 0.4469, F1 Macro: 0.3089, Accuracy: 0.4469\n","Epoch 108, Train Loss: 0.5653, Val Loss: 0.4343, F1 Micro: 0.7750, F1 Macro: 0.7608, Accuracy: 0.7750\n","Epoch 109, Train Loss: 0.5413, Val Loss: 0.4992, F1 Micro: 0.8156, F1 Macro: 0.8150, Accuracy: 0.8156\n","Epoch 110, Train Loss: 0.5309, Val Loss: 0.4652, F1 Micro: 0.7500, F1 Macro: 0.7305, Accuracy: 0.7500\n","Epoch 111, Train Loss: 0.5522, Val Loss: 0.6024, F1 Micro: 0.6687, F1 Macro: 0.6567, Accuracy: 0.6687\n","Epoch 112, Train Loss: 0.5432, Val Loss: 1.1987, F1 Micro: 0.4562, F1 Macro: 0.3229, Accuracy: 0.4562\n","Epoch 113, Train Loss: 0.5030, Val Loss: 0.4524, F1 Micro: 0.8375, F1 Macro: 0.8354, Accuracy: 0.8375\n","Epoch 114, Train Loss: 0.5493, Val Loss: 0.4410, F1 Micro: 0.8125, F1 Macro: 0.8074, Accuracy: 0.8125\n","Epoch 115, Train Loss: 0.5608, Val Loss: 0.6768, F1 Micro: 0.5469, F1 Macro: 0.4823, Accuracy: 0.5469\n","Epoch 116, Train Loss: 0.5311, Val Loss: 0.4570, F1 Micro: 0.8094, F1 Macro: 0.8090, Accuracy: 0.8094\n","Epoch 117, Train Loss: 0.5237, Val Loss: 0.7915, F1 Micro: 0.6969, F1 Macro: 0.6423, Accuracy: 0.6969\n","Epoch 118, Train Loss: 0.5393, Val Loss: 0.4346, F1 Micro: 0.8313, F1 Macro: 0.8286, Accuracy: 0.8313\n","Epoch 119, Train Loss: 0.5189, Val Loss: 0.4226, F1 Micro: 0.8062, F1 Macro: 0.8006, Accuracy: 0.8063\n","Epoch 120, Train Loss: 0.5065, Val Loss: 0.4243, F1 Micro: 0.8000, F1 Macro: 0.7965, Accuracy: 0.8000\n","Epoch 121, Train Loss: 0.5372, Val Loss: 1.4496, F1 Micro: 0.4562, F1 Macro: 0.3275, Accuracy: 0.4562\n","Epoch 122, Train Loss: 0.5206, Val Loss: 0.6936, F1 Micro: 0.5188, F1 Macro: 0.4459, Accuracy: 0.5188\n","Epoch 123, Train Loss: 0.5411, Val Loss: 0.5507, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 124, Train Loss: 0.5183, Val Loss: 0.4451, F1 Micro: 0.8187, F1 Macro: 0.8180, Accuracy: 0.8187\n","Epoch 125, Train Loss: 0.5121, Val Loss: 0.5260, F1 Micro: 0.7969, F1 Macro: 0.7963, Accuracy: 0.7969\n","Epoch 126, Train Loss: 0.5429, Val Loss: 0.4731, F1 Micro: 0.8438, F1 Macro: 0.8436, Accuracy: 0.8438\n","Epoch 127, Train Loss: 0.4991, Val Loss: 1.2508, F1 Micro: 0.4875, F1 Macro: 0.3862, Accuracy: 0.4875\n","Epoch 128, Train Loss: 0.5136, Val Loss: 0.6468, F1 Micro: 0.7188, F1 Macro: 0.6779, Accuracy: 0.7188\n","Epoch 129, Train Loss: 0.5081, Val Loss: 0.5147, F1 Micro: 0.8031, F1 Macro: 0.8024, Accuracy: 0.8031\n","Epoch 130, Train Loss: 0.5199, Val Loss: 0.4263, F1 Micro: 0.7969, F1 Macro: 0.7935, Accuracy: 0.7969\n","Epoch 131, Train Loss: 0.5053, Val Loss: 0.5757, F1 Micro: 0.6594, F1 Macro: 0.6428, Accuracy: 0.6594\n","Epoch 132, Train Loss: 0.5041, Val Loss: 0.4344, F1 Micro: 0.8156, F1 Macro: 0.8136, Accuracy: 0.8156\n","Epoch 133, Train Loss: 0.5381, Val Loss: 0.4232, F1 Micro: 0.8094, F1 Macro: 0.8044, Accuracy: 0.8094\n","Epoch 134, Train Loss: 0.5123, Val Loss: 0.5097, F1 Micro: 0.7156, F1 Macro: 0.6828, Accuracy: 0.7156\n","Epoch 135, Train Loss: 0.5086, Val Loss: 0.4186, F1 Micro: 0.8250, F1 Macro: 0.8225, Accuracy: 0.8250\n","Epoch 136, Train Loss: 0.5370, Val Loss: 1.4922, F1 Micro: 0.4500, F1 Macro: 0.3103, Accuracy: 0.4500\n","Epoch 137, Train Loss: 0.4901, Val Loss: 0.4196, F1 Micro: 0.8062, F1 Macro: 0.8010, Accuracy: 0.8063\n","Epoch 138, Train Loss: 0.5134, Val Loss: 0.7592, F1 Micro: 0.5188, F1 Macro: 0.4400, Accuracy: 0.5188\n","Epoch 139, Train Loss: 0.5235, Val Loss: 0.6099, F1 Micro: 0.7125, F1 Macro: 0.6636, Accuracy: 0.7125\n","Epoch 140, Train Loss: 0.5071, Val Loss: 0.4055, F1 Micro: 0.8219, F1 Macro: 0.8189, Accuracy: 0.8219\n","Epoch 141, Train Loss: 0.5679, Val Loss: 0.6277, F1 Micro: 0.6469, F1 Macro: 0.6263, Accuracy: 0.6469\n","Epoch 142, Train Loss: 0.5187, Val Loss: 0.4327, F1 Micro: 0.8313, F1 Macro: 0.8270, Accuracy: 0.8313\n","Epoch 143, Train Loss: 0.5736, Val Loss: 0.6304, F1 Micro: 0.7312, F1 Macro: 0.7034, Accuracy: 0.7312\n","Epoch 144, Train Loss: 0.5338, Val Loss: 0.4335, F1 Micro: 0.7656, F1 Macro: 0.7520, Accuracy: 0.7656\n","Epoch 145, Train Loss: 0.5118, Val Loss: 0.5098, F1 Micro: 0.7312, F1 Macro: 0.7022, Accuracy: 0.7312\n","Epoch 146, Train Loss: 0.5214, Val Loss: 0.4525, F1 Micro: 0.8156, F1 Macro: 0.8119, Accuracy: 0.8156\n","Epoch 147, Train Loss: 0.5164, Val Loss: 0.4615, F1 Micro: 0.8375, F1 Macro: 0.8373, Accuracy: 0.8375\n","Epoch 148, Train Loss: 0.5239, Val Loss: 0.5378, F1 Micro: 0.7719, F1 Macro: 0.7694, Accuracy: 0.7719\n","Epoch 149, Train Loss: 0.5243, Val Loss: 0.4151, F1 Micro: 0.8156, F1 Macro: 0.8119, Accuracy: 0.8156\n","Epoch 150, Train Loss: 0.5183, Val Loss: 0.4616, F1 Micro: 0.8062, F1 Macro: 0.8035, Accuracy: 0.8063\n","Epoch 151, Train Loss: 0.4984, Val Loss: 0.8749, F1 Micro: 0.5125, F1 Macro: 0.4296, Accuracy: 0.5125\n","Epoch 152, Train Loss: 0.4968, Val Loss: 0.4296, F1 Micro: 0.8344, F1 Macro: 0.8328, Accuracy: 0.8344\n","Epoch 153, Train Loss: 0.5318, Val Loss: 0.4492, F1 Micro: 0.7937, F1 Macro: 0.7821, Accuracy: 0.7937\n","Epoch 154, Train Loss: 0.4974, Val Loss: 0.4125, F1 Micro: 0.7937, F1 Macro: 0.7862, Accuracy: 0.7937\n","Epoch 155, Train Loss: 0.5086, Val Loss: 0.5069, F1 Micro: 0.8250, F1 Macro: 0.8248, Accuracy: 0.8250\n","Epoch 156, Train Loss: 0.5432, Val Loss: 1.3018, F1 Micro: 0.4813, F1 Macro: 0.3749, Accuracy: 0.4813\n","Epoch 157, Train Loss: 0.5112, Val Loss: 0.4481, F1 Micro: 0.7812, F1 Macro: 0.7703, Accuracy: 0.7812\n","Epoch 158, Train Loss: 0.5085, Val Loss: 0.4439, F1 Micro: 0.8156, F1 Macro: 0.8122, Accuracy: 0.8156\n","Epoch 159, Train Loss: 0.5271, Val Loss: 0.4658, F1 Micro: 0.8094, F1 Macro: 0.8031, Accuracy: 0.8094\n","Epoch 160, Train Loss: 0.5003, Val Loss: 0.4894, F1 Micro: 0.7562, F1 Macro: 0.7373, Accuracy: 0.7562\n","Epoch 161, Train Loss: 0.5156, Val Loss: 0.9887, F1 Micro: 0.4750, F1 Macro: 0.3593, Accuracy: 0.4750\n","Epoch 162, Train Loss: 0.5815, Val Loss: 0.6193, F1 Micro: 0.7281, F1 Macro: 0.7198, Accuracy: 0.7281\n","Epoch 163, Train Loss: 0.5449, Val Loss: 0.4247, F1 Micro: 0.7781, F1 Macro: 0.7673, Accuracy: 0.7781\n","Epoch 164, Train Loss: 0.5164, Val Loss: 0.7330, F1 Micro: 0.7156, F1 Macro: 0.6700, Accuracy: 0.7156\n","Epoch 165, Train Loss: 0.4900, Val Loss: 0.4542, F1 Micro: 0.8187, F1 Macro: 0.8146, Accuracy: 0.8187\n","Epoch 166, Train Loss: 0.5429, Val Loss: 0.6277, F1 Micro: 0.7031, F1 Macro: 0.6536, Accuracy: 0.7031\n","Epoch 167, Train Loss: 0.5239, Val Loss: 0.4297, F1 Micro: 0.7844, F1 Macro: 0.7745, Accuracy: 0.7844\n","Epoch 168, Train Loss: 0.4995, Val Loss: 0.4651, F1 Micro: 0.7469, F1 Macro: 0.7267, Accuracy: 0.7469\n","Epoch 169, Train Loss: 0.5068, Val Loss: 0.4181, F1 Micro: 0.8313, F1 Macro: 0.8280, Accuracy: 0.8313\n","Epoch 170, Train Loss: 0.5203, Val Loss: 0.5507, F1 Micro: 0.7812, F1 Macro: 0.7793, Accuracy: 0.7812\n","Epoch 171, Train Loss: 0.5373, Val Loss: 0.7729, F1 Micro: 0.5000, F1 Macro: 0.4048, Accuracy: 0.5000\n","Epoch 172, Train Loss: 0.4962, Val Loss: 0.4363, F1 Micro: 0.7750, F1 Macro: 0.7623, Accuracy: 0.7750\n","Epoch 173, Train Loss: 0.5312, Val Loss: 0.4267, F1 Micro: 0.7750, F1 Macro: 0.7650, Accuracy: 0.7750\n","Epoch 174, Train Loss: 0.5214, Val Loss: 0.6501, F1 Micro: 0.7156, F1 Macro: 0.6767, Accuracy: 0.7156\n","Epoch 175, Train Loss: 0.5134, Val Loss: 0.4765, F1 Micro: 0.7375, F1 Macro: 0.7138, Accuracy: 0.7375\n","Epoch 176, Train Loss: 0.4840, Val Loss: 1.3831, F1 Micro: 0.4656, F1 Macro: 0.3457, Accuracy: 0.4656\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7743, Val Loss: 0.6758, F1 Micro: 0.6406, F1 Macro: 0.5709, Accuracy: 0.6406\n","Epoch 2, Train Loss: 0.6335, Val Loss: 0.6135, F1 Micro: 0.6625, F1 Macro: 0.6209, Accuracy: 0.6625\n","Epoch 3, Train Loss: 0.6354, Val Loss: 0.5494, F1 Micro: 0.7125, F1 Macro: 0.7123, Accuracy: 0.7125\n","Epoch 4, Train Loss: 0.6277, Val Loss: 0.9763, F1 Micro: 0.5000, F1 Macro: 0.3730, Accuracy: 0.5000\n","Epoch 5, Train Loss: 0.6380, Val Loss: 0.5679, F1 Micro: 0.6813, F1 Macro: 0.6552, Accuracy: 0.6813\n","Epoch 6, Train Loss: 0.6113, Val Loss: 0.5542, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 7, Train Loss: 0.6492, Val Loss: 0.6246, F1 Micro: 0.6469, F1 Macro: 0.5857, Accuracy: 0.6469\n","Epoch 8, Train Loss: 0.6403, Val Loss: 0.5910, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 9, Train Loss: 0.6315, Val Loss: 0.6703, F1 Micro: 0.6062, F1 Macro: 0.5097, Accuracy: 0.6062\n","Epoch 10, Train Loss: 0.6262, Val Loss: 0.5451, F1 Micro: 0.7063, F1 Macro: 0.6932, Accuracy: 0.7063\n","Epoch 11, Train Loss: 0.6164, Val Loss: 0.5814, F1 Micro: 0.6813, F1 Macro: 0.6497, Accuracy: 0.6813\n","Epoch 12, Train Loss: 0.6209, Val Loss: 0.5817, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 13, Train Loss: 0.6542, Val Loss: 0.5417, F1 Micro: 0.7156, F1 Macro: 0.7152, Accuracy: 0.7156\n","Epoch 14, Train Loss: 0.6194, Val Loss: 0.5430, F1 Micro: 0.7250, F1 Macro: 0.7197, Accuracy: 0.7250\n","Epoch 15, Train Loss: 0.6317, Val Loss: 0.5576, F1 Micro: 0.6937, F1 Macro: 0.6744, Accuracy: 0.6937\n","Epoch 16, Train Loss: 0.6128, Val Loss: 0.5817, F1 Micro: 0.6719, F1 Macro: 0.6695, Accuracy: 0.6719\n","Epoch 17, Train Loss: 0.6153, Val Loss: 0.5709, F1 Micro: 0.7094, F1 Macro: 0.7005, Accuracy: 0.7094\n","Epoch 18, Train Loss: 0.6180, Val Loss: 0.5689, F1 Micro: 0.6969, F1 Macro: 0.6830, Accuracy: 0.6969\n","Epoch 19, Train Loss: 0.6475, Val Loss: 0.5937, F1 Micro: 0.6438, F1 Macro: 0.6362, Accuracy: 0.6438\n","Epoch 20, Train Loss: 0.6844, Val Loss: 0.5427, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 21, Train Loss: 0.6236, Val Loss: 0.6489, F1 Micro: 0.6438, F1 Macro: 0.6236, Accuracy: 0.6438\n","Epoch 22, Train Loss: 0.6632, Val Loss: 0.5415, F1 Micro: 0.7188, F1 Macro: 0.7186, Accuracy: 0.7188\n","Epoch 23, Train Loss: 0.6071, Val Loss: 0.5365, F1 Micro: 0.7156, F1 Macro: 0.7153, Accuracy: 0.7156\n","Epoch 24, Train Loss: 0.6125, Val Loss: 0.6705, F1 Micro: 0.6344, F1 Macro: 0.6006, Accuracy: 0.6344\n","Epoch 25, Train Loss: 0.6137, Val Loss: 0.6741, F1 Micro: 0.6156, F1 Macro: 0.5262, Accuracy: 0.6156\n","Epoch 26, Train Loss: 0.6130, Val Loss: 0.5428, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 27, Train Loss: 0.6540, Val Loss: 0.5744, F1 Micro: 0.6937, F1 Macro: 0.6923, Accuracy: 0.6937\n","Epoch 28, Train Loss: 0.6004, Val Loss: 0.5499, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 29, Train Loss: 0.6081, Val Loss: 0.5312, F1 Micro: 0.7125, F1 Macro: 0.7034, Accuracy: 0.7125\n","Epoch 30, Train Loss: 0.6123, Val Loss: 0.6237, F1 Micro: 0.6969, F1 Macro: 0.6750, Accuracy: 0.6969\n","Epoch 31, Train Loss: 0.5918, Val Loss: 0.5694, F1 Micro: 0.7188, F1 Macro: 0.7143, Accuracy: 0.7188\n","Epoch 32, Train Loss: 0.5836, Val Loss: 0.7622, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 33, Train Loss: 0.6403, Val Loss: 0.6217, F1 Micro: 0.6969, F1 Macro: 0.6689, Accuracy: 0.6969\n","Epoch 34, Train Loss: 0.6027, Val Loss: 0.5091, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 35, Train Loss: 0.5820, Val Loss: 0.5271, F1 Micro: 0.7094, F1 Macro: 0.7091, Accuracy: 0.7094\n","Epoch 36, Train Loss: 0.5898, Val Loss: 0.5313, F1 Micro: 0.6969, F1 Macro: 0.6962, Accuracy: 0.6969\n","Epoch 37, Train Loss: 0.5924, Val Loss: 0.5125, F1 Micro: 0.7000, F1 Macro: 0.6992, Accuracy: 0.7000\n","Epoch 38, Train Loss: 0.6532, Val Loss: 0.6166, F1 Micro: 0.7063, F1 Macro: 0.6810, Accuracy: 0.7063\n","Epoch 39, Train Loss: 0.6912, Val Loss: 0.5521, F1 Micro: 0.6844, F1 Macro: 0.6814, Accuracy: 0.6844\n","Epoch 40, Train Loss: 0.5914, Val Loss: 0.5930, F1 Micro: 0.6969, F1 Macro: 0.6633, Accuracy: 0.6969\n","Epoch 41, Train Loss: 0.5796, Val Loss: 0.5516, F1 Micro: 0.7250, F1 Macro: 0.7095, Accuracy: 0.7250\n","Epoch 42, Train Loss: 0.6041, Val Loss: 0.5061, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 43, Train Loss: 0.5638, Val Loss: 0.5066, F1 Micro: 0.7063, F1 Macro: 0.7043, Accuracy: 0.7063\n","Epoch 44, Train Loss: 0.5719, Val Loss: 0.6051, F1 Micro: 0.6875, F1 Macro: 0.6769, Accuracy: 0.6875\n","Epoch 45, Train Loss: 0.5621, Val Loss: 0.6746, F1 Micro: 0.5594, F1 Macro: 0.4914, Accuracy: 0.5594\n","Epoch 46, Train Loss: 0.6383, Val Loss: 0.5347, F1 Micro: 0.7406, F1 Macro: 0.7295, Accuracy: 0.7406\n","Epoch 47, Train Loss: 0.5515, Val Loss: 0.5334, F1 Micro: 0.7125, F1 Macro: 0.7034, Accuracy: 0.7125\n","Epoch 48, Train Loss: 0.5695, Val Loss: 0.4795, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 49, Train Loss: 0.5909, Val Loss: 0.5385, F1 Micro: 0.7156, F1 Macro: 0.7063, Accuracy: 0.7156\n","Epoch 50, Train Loss: 0.5710, Val Loss: 0.5245, F1 Micro: 0.7469, F1 Macro: 0.7397, Accuracy: 0.7469\n","Epoch 51, Train Loss: 0.6004, Val Loss: 0.7403, F1 Micro: 0.5281, F1 Macro: 0.3682, Accuracy: 0.5281\n","Epoch 52, Train Loss: 0.5857, Val Loss: 0.6875, F1 Micro: 0.5406, F1 Macro: 0.3849, Accuracy: 0.5406\n","Epoch 53, Train Loss: 0.5701, Val Loss: 0.7876, F1 Micro: 0.6937, F1 Macro: 0.6793, Accuracy: 0.6937\n","Epoch 54, Train Loss: 0.5895, Val Loss: 0.5453, F1 Micro: 0.7063, F1 Macro: 0.6955, Accuracy: 0.7063\n","Epoch 55, Train Loss: 0.5713, Val Loss: 0.5602, F1 Micro: 0.6969, F1 Macro: 0.6936, Accuracy: 0.6969\n","Epoch 56, Train Loss: 0.5703, Val Loss: 0.4983, F1 Micro: 0.7344, F1 Macro: 0.7295, Accuracy: 0.7344\n","Epoch 57, Train Loss: 0.5681, Val Loss: 0.5526, F1 Micro: 0.7156, F1 Macro: 0.7042, Accuracy: 0.7156\n","Epoch 58, Train Loss: 0.5729, Val Loss: 0.5236, F1 Micro: 0.6906, F1 Macro: 0.6844, Accuracy: 0.6906\n","Epoch 59, Train Loss: 0.5992, Val Loss: 0.5204, F1 Micro: 0.7937, F1 Macro: 0.7908, Accuracy: 0.7937\n","Epoch 60, Train Loss: 0.5897, Val Loss: 0.5028, F1 Micro: 0.7906, F1 Macro: 0.7886, Accuracy: 0.7906\n","Epoch 61, Train Loss: 0.6105, Val Loss: 0.5328, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 62, Train Loss: 0.5917, Val Loss: 0.6142, F1 Micro: 0.6312, F1 Macro: 0.5685, Accuracy: 0.6312\n","Epoch 63, Train Loss: 0.5911, Val Loss: 0.5094, F1 Micro: 0.7281, F1 Macro: 0.7231, Accuracy: 0.7281\n","Epoch 64, Train Loss: 0.5695, Val Loss: 0.5162, F1 Micro: 0.7937, F1 Macro: 0.7934, Accuracy: 0.7937\n","Epoch 65, Train Loss: 0.5448, Val Loss: 0.5661, F1 Micro: 0.7344, F1 Macro: 0.7110, Accuracy: 0.7344\n","Epoch 66, Train Loss: 0.5810, Val Loss: 0.5096, F1 Micro: 0.7281, F1 Macro: 0.7226, Accuracy: 0.7281\n","Epoch 67, Train Loss: 0.5621, Val Loss: 0.4848, F1 Micro: 0.7562, F1 Macro: 0.7556, Accuracy: 0.7562\n","Epoch 68, Train Loss: 0.5881, Val Loss: 0.4695, F1 Micro: 0.7656, F1 Macro: 0.7650, Accuracy: 0.7656\n","Epoch 69, Train Loss: 0.6032, Val Loss: 0.5687, F1 Micro: 0.6844, F1 Macro: 0.6680, Accuracy: 0.6844\n","Epoch 70, Train Loss: 0.5680, Val Loss: 0.5830, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 71, Train Loss: 0.5565, Val Loss: 0.7392, F1 Micro: 0.6781, F1 Macro: 0.6605, Accuracy: 0.6781\n","Epoch 72, Train Loss: 0.6142, Val Loss: 0.4992, F1 Micro: 0.7094, F1 Macro: 0.7079, Accuracy: 0.7094\n","Epoch 73, Train Loss: 0.5583, Val Loss: 1.0561, F1 Micro: 0.6000, F1 Macro: 0.5464, Accuracy: 0.6000\n","Epoch 74, Train Loss: 0.5732, Val Loss: 0.5051, F1 Micro: 0.7188, F1 Macro: 0.7105, Accuracy: 0.7188\n","Epoch 75, Train Loss: 0.5512, Val Loss: 0.5265, F1 Micro: 0.7156, F1 Macro: 0.7063, Accuracy: 0.7156\n","Epoch 76, Train Loss: 0.5633, Val Loss: 0.5310, F1 Micro: 0.6937, F1 Macro: 0.6884, Accuracy: 0.6937\n","Epoch 77, Train Loss: 0.5812, Val Loss: 0.4786, F1 Micro: 0.7750, F1 Macro: 0.7741, Accuracy: 0.7750\n","Epoch 78, Train Loss: 0.6411, Val Loss: 1.1214, F1 Micro: 0.6031, F1 Macro: 0.5488, Accuracy: 0.6031\n","Epoch 79, Train Loss: 0.5749, Val Loss: 0.5202, F1 Micro: 0.7344, F1 Macro: 0.7290, Accuracy: 0.7344\n","Epoch 80, Train Loss: 0.5533, Val Loss: 0.4920, F1 Micro: 0.7719, F1 Macro: 0.7691, Accuracy: 0.7719\n","Epoch 81, Train Loss: 0.5801, Val Loss: 0.5317, F1 Micro: 0.7844, F1 Macro: 0.7831, Accuracy: 0.7844\n","Epoch 82, Train Loss: 0.5803, Val Loss: 0.6756, F1 Micro: 0.6344, F1 Macro: 0.5957, Accuracy: 0.6344\n","Epoch 83, Train Loss: 0.5572, Val Loss: 0.5951, F1 Micro: 0.5906, F1 Macro: 0.4849, Accuracy: 0.5906\n","Epoch 84, Train Loss: 0.5735, Val Loss: 0.5516, F1 Micro: 0.7094, F1 Macro: 0.6961, Accuracy: 0.7094\n","Epoch 85, Train Loss: 0.5793, Val Loss: 0.5306, F1 Micro: 0.7656, F1 Macro: 0.7574, Accuracy: 0.7656\n","Epoch 86, Train Loss: 0.5683, Val Loss: 0.6603, F1 Micro: 0.6594, F1 Macro: 0.6308, Accuracy: 0.6594\n","Epoch 87, Train Loss: 0.5694, Val Loss: 0.5278, F1 Micro: 0.7719, F1 Macro: 0.7715, Accuracy: 0.7719\n","Epoch 88, Train Loss: 0.5509, Val Loss: 0.5166, F1 Micro: 0.7375, F1 Macro: 0.7352, Accuracy: 0.7375\n","Epoch 89, Train Loss: 0.5561, Val Loss: 0.5133, F1 Micro: 0.6875, F1 Macro: 0.6803, Accuracy: 0.6875\n","Epoch 90, Train Loss: 0.5518, Val Loss: 0.5753, F1 Micro: 0.7031, F1 Macro: 0.6770, Accuracy: 0.7031\n","Epoch 91, Train Loss: 0.5527, Val Loss: 0.4834, F1 Micro: 0.7594, F1 Macro: 0.7576, Accuracy: 0.7594\n","Epoch 92, Train Loss: 0.5466, Val Loss: 0.5056, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 93, Train Loss: 0.5479, Val Loss: 0.5104, F1 Micro: 0.7719, F1 Macro: 0.7714, Accuracy: 0.7719\n","Epoch 94, Train Loss: 0.5616, Val Loss: 0.5634, F1 Micro: 0.6781, F1 Macro: 0.6624, Accuracy: 0.6781\n","Epoch 95, Train Loss: 0.5708, Val Loss: 0.5021, F1 Micro: 0.7875, F1 Macro: 0.7826, Accuracy: 0.7875\n","Epoch 96, Train Loss: 0.5430, Val Loss: 0.5331, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 97, Train Loss: 0.5668, Val Loss: 0.5010, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 98, Train Loss: 0.5562, Val Loss: 0.5801, F1 Micro: 0.6875, F1 Macro: 0.6769, Accuracy: 0.6875\n","Epoch 99, Train Loss: 0.5649, Val Loss: 0.7031, F1 Micro: 0.6062, F1 Macro: 0.5617, Accuracy: 0.6062\n","Epoch 100, Train Loss: 0.5511, Val Loss: 0.6571, F1 Micro: 0.6906, F1 Macro: 0.6736, Accuracy: 0.6906\n","Epoch 101, Train Loss: 0.5544, Val Loss: 0.5921, F1 Micro: 0.6406, F1 Macro: 0.6261, Accuracy: 0.6406\n","Epoch 102, Train Loss: 0.5615, Val Loss: 0.5416, F1 Micro: 0.7562, F1 Macro: 0.7433, Accuracy: 0.7562\n","Epoch 103, Train Loss: 0.5581, Val Loss: 0.5017, F1 Micro: 0.7281, F1 Macro: 0.7231, Accuracy: 0.7281\n","Epoch 104, Train Loss: 0.6077, Val Loss: 0.5047, F1 Micro: 0.7500, F1 Macro: 0.7442, Accuracy: 0.7500\n","Epoch 105, Train Loss: 0.5829, Val Loss: 0.5650, F1 Micro: 0.6937, F1 Macro: 0.6774, Accuracy: 0.6937\n","Epoch 106, Train Loss: 0.5401, Val Loss: 0.5612, F1 Micro: 0.6875, F1 Macro: 0.6761, Accuracy: 0.6875\n","Epoch 107, Train Loss: 0.5365, Val Loss: 0.5651, F1 Micro: 0.6937, F1 Macro: 0.6754, Accuracy: 0.6937\n","Epoch 108, Train Loss: 0.5787, Val Loss: 0.4740, F1 Micro: 0.7625, F1 Macro: 0.7614, Accuracy: 0.7625\n","Epoch 109, Train Loss: 0.5646, Val Loss: 0.5967, F1 Micro: 0.6781, F1 Macro: 0.6409, Accuracy: 0.6781\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.8150000000000001\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8309, Val Loss: 0.6028, F1 Micro: 0.6531, F1 Macro: 0.6498, Accuracy: 0.6531\n","Epoch 2, Train Loss: 0.6008, Val Loss: 0.6713, F1 Micro: 0.6062, F1 Macro: 0.5418, Accuracy: 0.6062\n","Epoch 3, Train Loss: 0.5869, Val Loss: 0.6262, F1 Micro: 0.6250, F1 Macro: 0.5879, Accuracy: 0.6250\n","Epoch 4, Train Loss: 0.5855, Val Loss: 0.6305, F1 Micro: 0.6188, F1 Macro: 0.5718, Accuracy: 0.6188\n","Epoch 5, Train Loss: 0.5740, Val Loss: 0.5818, F1 Micro: 0.6594, F1 Macro: 0.6576, Accuracy: 0.6594\n","Epoch 6, Train Loss: 0.5813, Val Loss: 0.6019, F1 Micro: 0.6531, F1 Macro: 0.6341, Accuracy: 0.6531\n","Epoch 7, Train Loss: 0.5781, Val Loss: 0.5917, F1 Micro: 0.6687, F1 Macro: 0.6672, Accuracy: 0.6687\n","Epoch 8, Train Loss: 0.5777, Val Loss: 0.5810, F1 Micro: 0.6375, F1 Macro: 0.6323, Accuracy: 0.6375\n","Epoch 9, Train Loss: 0.5776, Val Loss: 0.6111, F1 Micro: 0.6531, F1 Macro: 0.6341, Accuracy: 0.6531\n","Epoch 10, Train Loss: 0.5888, Val Loss: 0.5866, F1 Micro: 0.6562, F1 Macro: 0.6543, Accuracy: 0.6562\n","Epoch 11, Train Loss: 0.6080, Val Loss: 0.5909, F1 Micro: 0.6562, F1 Macro: 0.6532, Accuracy: 0.6562\n","Epoch 12, Train Loss: 0.5872, Val Loss: 0.6020, F1 Micro: 0.6531, F1 Macro: 0.6391, Accuracy: 0.6531\n","Epoch 13, Train Loss: 0.5775, Val Loss: 0.5836, F1 Micro: 0.6406, F1 Macro: 0.6334, Accuracy: 0.6406\n","Epoch 14, Train Loss: 0.5752, Val Loss: 0.5739, F1 Micro: 0.6625, F1 Macro: 0.6603, Accuracy: 0.6625\n","Epoch 15, Train Loss: 0.5790, Val Loss: 0.6204, F1 Micro: 0.6375, F1 Macro: 0.6120, Accuracy: 0.6375\n","Epoch 16, Train Loss: 0.5899, Val Loss: 0.6065, F1 Micro: 0.6594, F1 Macro: 0.6447, Accuracy: 0.6594\n","Epoch 17, Train Loss: 0.5710, Val Loss: 0.5806, F1 Micro: 0.6531, F1 Macro: 0.6455, Accuracy: 0.6531\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7984, Val Loss: 0.6959, F1 Micro: 0.6250, F1 Macro: 0.5509, Accuracy: 0.6250\n","Epoch 2, Train Loss: 0.6007, Val Loss: 0.5735, F1 Micro: 0.7156, F1 Macro: 0.7049, Accuracy: 0.7156\n","Epoch 3, Train Loss: 0.5853, Val Loss: 0.6051, F1 Micro: 0.6594, F1 Macro: 0.6576, Accuracy: 0.6594\n","Epoch 4, Train Loss: 0.5862, Val Loss: 0.5639, F1 Micro: 0.6781, F1 Macro: 0.6765, Accuracy: 0.6781\n","Epoch 5, Train Loss: 0.5953, Val Loss: 0.7008, F1 Micro: 0.6469, F1 Macro: 0.6361, Accuracy: 0.6469\n","Epoch 6, Train Loss: 0.5999, Val Loss: 0.5864, F1 Micro: 0.7250, F1 Macro: 0.7057, Accuracy: 0.7250\n","Epoch 7, Train Loss: 0.5954, Val Loss: 0.6489, F1 Micro: 0.7188, F1 Macro: 0.7063, Accuracy: 0.7188\n","Epoch 8, Train Loss: 0.5996, Val Loss: 0.5744, F1 Micro: 0.7250, F1 Macro: 0.7120, Accuracy: 0.7250\n","Epoch 9, Train Loss: 0.5797, Val Loss: 0.5739, F1 Micro: 0.6844, F1 Macro: 0.6841, Accuracy: 0.6844\n","Epoch 10, Train Loss: 0.5993, Val Loss: 0.5742, F1 Micro: 0.7125, F1 Macro: 0.7070, Accuracy: 0.7125\n","Epoch 11, Train Loss: 0.5931, Val Loss: 0.5845, F1 Micro: 0.7250, F1 Macro: 0.7076, Accuracy: 0.7250\n","Epoch 12, Train Loss: 0.5979, Val Loss: 0.5909, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 13, Train Loss: 0.5963, Val Loss: 0.5848, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 14, Train Loss: 0.5896, Val Loss: 0.5695, F1 Micro: 0.7250, F1 Macro: 0.7120, Accuracy: 0.7250\n","Epoch 15, Train Loss: 0.5964, Val Loss: 0.5766, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 16, Train Loss: 0.5987, Val Loss: 0.5736, F1 Micro: 0.6625, F1 Macro: 0.6617, Accuracy: 0.6625\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7191, Val Loss: 0.6205, F1 Micro: 0.6531, F1 Macro: 0.6467, Accuracy: 0.6531\n","Epoch 2, Train Loss: 0.6004, Val Loss: 0.6116, F1 Micro: 0.6531, F1 Macro: 0.6318, Accuracy: 0.6531\n","Epoch 3, Train Loss: 0.5663, Val Loss: 0.6079, F1 Micro: 0.6594, F1 Macro: 0.6579, Accuracy: 0.6594\n","Epoch 4, Train Loss: 0.5790, Val Loss: 0.6202, F1 Micro: 0.6562, F1 Macro: 0.6253, Accuracy: 0.6562\n","Epoch 5, Train Loss: 0.5831, Val Loss: 0.6865, F1 Micro: 0.6312, F1 Macro: 0.6265, Accuracy: 0.6312\n","Epoch 6, Train Loss: 0.5703, Val Loss: 0.6543, F1 Micro: 0.6344, F1 Macro: 0.6304, Accuracy: 0.6344\n","Epoch 7, Train Loss: 0.5752, Val Loss: 0.6482, F1 Micro: 0.6250, F1 Macro: 0.6148, Accuracy: 0.6250\n","Epoch 8, Train Loss: 0.5746, Val Loss: 0.5979, F1 Micro: 0.6469, F1 Macro: 0.6404, Accuracy: 0.6469\n","Epoch 9, Train Loss: 0.5741, Val Loss: 0.6300, F1 Micro: 0.6625, F1 Macro: 0.6620, Accuracy: 0.6625\n","Epoch 10, Train Loss: 0.5836, Val Loss: 0.6206, F1 Micro: 0.6406, F1 Macro: 0.6394, Accuracy: 0.6406\n","Epoch 11, Train Loss: 0.5779, Val Loss: 0.6088, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 12, Train Loss: 0.5867, Val Loss: 0.6117, F1 Micro: 0.6531, F1 Macro: 0.6531, Accuracy: 0.6531\n","Epoch 13, Train Loss: 0.5802, Val Loss: 0.5968, F1 Micro: 0.6656, F1 Macro: 0.6644, Accuracy: 0.6656\n","Epoch 14, Train Loss: 0.5714, Val Loss: 0.6123, F1 Micro: 0.6406, F1 Macro: 0.6384, Accuracy: 0.6406\n","Epoch 15, Train Loss: 0.6167, Val Loss: 0.7456, F1 Micro: 0.6031, F1 Macro: 0.5510, Accuracy: 0.6031\n","Epoch 16, Train Loss: 0.6075, Val Loss: 0.6311, F1 Micro: 0.6281, F1 Macro: 0.6241, Accuracy: 0.6281\n","Epoch 17, Train Loss: 0.5793, Val Loss: 0.6035, F1 Micro: 0.6562, F1 Macro: 0.6523, Accuracy: 0.6562\n","Epoch 18, Train Loss: 0.5745, Val Loss: 0.7028, F1 Micro: 0.6312, F1 Macro: 0.6265, Accuracy: 0.6312\n","Epoch 19, Train Loss: 0.6062, Val Loss: 0.6370, F1 Micro: 0.6656, F1 Macro: 0.6652, Accuracy: 0.6656\n","Epoch 20, Train Loss: 0.5907, Val Loss: 0.7096, F1 Micro: 0.6125, F1 Macro: 0.5984, Accuracy: 0.6125\n","Epoch 21, Train Loss: 0.6070, Val Loss: 0.7132, F1 Micro: 0.6219, F1 Macro: 0.6149, Accuracy: 0.6219\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.9019, Val Loss: 0.5359, F1 Micro: 0.7250, F1 Macro: 0.7239, Accuracy: 0.7250\n","Epoch 2, Train Loss: 0.5920, Val Loss: 0.5493, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 3, Train Loss: 0.5907, Val Loss: 0.5317, F1 Micro: 0.7188, F1 Macro: 0.7186, Accuracy: 0.7188\n","Epoch 4, Train Loss: 0.6146, Val Loss: 0.5748, F1 Micro: 0.6875, F1 Macro: 0.6820, Accuracy: 0.6875\n","Epoch 5, Train Loss: 0.6195, Val Loss: 0.5539, F1 Micro: 0.7375, F1 Macro: 0.7337, Accuracy: 0.7375\n","Epoch 6, Train Loss: 0.6078, Val Loss: 0.5352, F1 Micro: 0.7375, F1 Macro: 0.7341, Accuracy: 0.7375\n","Epoch 7, Train Loss: 0.6136, Val Loss: 0.5372, F1 Micro: 0.7094, F1 Macro: 0.7035, Accuracy: 0.7094\n","Epoch 8, Train Loss: 0.5987, Val Loss: 0.5355, F1 Micro: 0.7125, F1 Macro: 0.7122, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.6015, Val Loss: 0.5368, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 10, Train Loss: 0.5982, Val Loss: 0.5540, F1 Micro: 0.7156, F1 Macro: 0.7152, Accuracy: 0.7156\n","Epoch 11, Train Loss: 0.6012, Val Loss: 0.5291, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 12, Train Loss: 0.5936, Val Loss: 0.5298, F1 Micro: 0.7188, F1 Macro: 0.7185, Accuracy: 0.7188\n","Epoch 13, Train Loss: 0.6131, Val Loss: 0.5369, F1 Micro: 0.7156, F1 Macro: 0.7109, Accuracy: 0.7156\n","Epoch 14, Train Loss: 0.6352, Val Loss: 0.5657, F1 Micro: 0.6875, F1 Macro: 0.6607, Accuracy: 0.6875\n","Epoch 15, Train Loss: 0.5942, Val Loss: 0.5510, F1 Micro: 0.6875, F1 Macro: 0.6863, Accuracy: 0.6875\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7665, Val Loss: 0.5634, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 2, Train Loss: 0.5993, Val Loss: 0.5766, F1 Micro: 0.6844, F1 Macro: 0.6616, Accuracy: 0.6844\n","Epoch 3, Train Loss: 0.5960, Val Loss: 0.5835, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 4, Train Loss: 0.6037, Val Loss: 0.5567, F1 Micro: 0.6969, F1 Macro: 0.6782, Accuracy: 0.6969\n","Epoch 5, Train Loss: 0.5930, Val Loss: 0.5816, F1 Micro: 0.6906, F1 Macro: 0.6893, Accuracy: 0.6906\n","Epoch 6, Train Loss: 0.5922, Val Loss: 0.5559, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 7, Train Loss: 0.5989, Val Loss: 0.5381, F1 Micro: 0.7250, F1 Macro: 0.7206, Accuracy: 0.7250\n","Epoch 8, Train Loss: 0.5835, Val Loss: 0.5596, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 9, Train Loss: 0.5887, Val Loss: 0.5653, F1 Micro: 0.7000, F1 Macro: 0.6858, Accuracy: 0.7000\n","Epoch 10, Train Loss: 0.5886, Val Loss: 0.6179, F1 Micro: 0.6469, F1 Macro: 0.5857, Accuracy: 0.6469\n","Epoch 11, Train Loss: 0.6383, Val Loss: 0.6577, F1 Micro: 0.6156, F1 Macro: 0.5262, Accuracy: 0.6156\n","Epoch 12, Train Loss: 0.6392, Val Loss: 0.5500, F1 Micro: 0.7188, F1 Macro: 0.7128, Accuracy: 0.7188\n","Epoch 13, Train Loss: 0.5966, Val Loss: 0.5427, F1 Micro: 0.7281, F1 Macro: 0.7269, Accuracy: 0.7281\n","Epoch 14, Train Loss: 0.5910, Val Loss: 0.5478, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 15, Train Loss: 0.5944, Val Loss: 0.6086, F1 Micro: 0.6312, F1 Macro: 0.6178, Accuracy: 0.6312\n","Epoch 16, Train Loss: 0.6200, Val Loss: 0.5545, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 17, Train Loss: 0.5903, Val Loss: 0.5660, F1 Micro: 0.6906, F1 Macro: 0.6716, Accuracy: 0.6906\n","Epoch 18, Train Loss: 0.6031, Val Loss: 0.6073, F1 Micro: 0.6906, F1 Macro: 0.6819, Accuracy: 0.6906\n","Epoch 19, Train Loss: 0.5906, Val Loss: 0.6002, F1 Micro: 0.6594, F1 Macro: 0.6089, Accuracy: 0.6594\n","Epoch 20, Train Loss: 0.5961, Val Loss: 0.6333, F1 Micro: 0.6562, F1 Macro: 0.6390, Accuracy: 0.6562\n","Epoch 21, Train Loss: 0.5784, Val Loss: 0.5342, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 22, Train Loss: 0.5623, Val Loss: 0.5409, F1 Micro: 0.7438, F1 Macro: 0.7401, Accuracy: 0.7438\n","Epoch 23, Train Loss: 0.5708, Val Loss: 0.5386, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 24, Train Loss: 0.5766, Val Loss: 0.6764, F1 Micro: 0.6656, F1 Macro: 0.6521, Accuracy: 0.6656\n","Epoch 25, Train Loss: 0.6607, Val Loss: 0.5406, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 26, Train Loss: 0.5850, Val Loss: 0.5084, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 27, Train Loss: 0.5879, Val Loss: 0.5203, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 28, Train Loss: 0.5524, Val Loss: 0.5020, F1 Micro: 0.7312, F1 Macro: 0.7304, Accuracy: 0.7312\n","Epoch 29, Train Loss: 0.6145, Val Loss: 0.6987, F1 Micro: 0.6531, F1 Macro: 0.6254, Accuracy: 0.6531\n","Epoch 30, Train Loss: 0.5770, Val Loss: 0.5223, F1 Micro: 0.7469, F1 Macro: 0.7386, Accuracy: 0.7469\n","Epoch 31, Train Loss: 0.5573, Val Loss: 0.5059, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 32, Train Loss: 0.5475, Val Loss: 0.5051, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 33, Train Loss: 0.5632, Val Loss: 0.5620, F1 Micro: 0.6844, F1 Macro: 0.6786, Accuracy: 0.6844\n","Epoch 34, Train Loss: 0.5953, Val Loss: 0.7059, F1 Micro: 0.5000, F1 Macro: 0.3898, Accuracy: 0.5000\n","Epoch 35, Train Loss: 0.6136, Val Loss: 0.5174, F1 Micro: 0.7250, F1 Macro: 0.7150, Accuracy: 0.7250\n","Epoch 36, Train Loss: 0.5856, Val Loss: 0.5132, F1 Micro: 0.7406, F1 Macro: 0.7385, Accuracy: 0.7406\n","Epoch 37, Train Loss: 0.6058, Val Loss: 0.5241, F1 Micro: 0.7906, F1 Macro: 0.7903, Accuracy: 0.7906\n","Epoch 38, Train Loss: 0.5566, Val Loss: 0.5602, F1 Micro: 0.7219, F1 Macro: 0.7028, Accuracy: 0.7219\n","Epoch 39, Train Loss: 0.5442, Val Loss: 0.5792, F1 Micro: 0.7094, F1 Macro: 0.7018, Accuracy: 0.7094\n","Epoch 40, Train Loss: 0.5631, Val Loss: 0.5119, F1 Micro: 0.7438, F1 Macro: 0.7350, Accuracy: 0.7438\n","Epoch 41, Train Loss: 0.5648, Val Loss: 0.5105, F1 Micro: 0.7063, F1 Macro: 0.7057, Accuracy: 0.7063\n","Epoch 42, Train Loss: 0.5724, Val Loss: 0.6358, F1 Micro: 0.6687, F1 Macro: 0.6467, Accuracy: 0.6687\n","Epoch 43, Train Loss: 0.5876, Val Loss: 0.5272, F1 Micro: 0.7750, F1 Macro: 0.7737, Accuracy: 0.7750\n","Epoch 44, Train Loss: 0.5462, Val Loss: 0.4969, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 45, Train Loss: 0.5575, Val Loss: 0.4875, F1 Micro: 0.7375, F1 Macro: 0.7355, Accuracy: 0.7375\n","Epoch 46, Train Loss: 0.5581, Val Loss: 0.5403, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 47, Train Loss: 0.5475, Val Loss: 0.4860, F1 Micro: 0.7375, F1 Macro: 0.7358, Accuracy: 0.7375\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.7175\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6935, Val Loss: 0.5847, F1 Micro: 0.6438, F1 Macro: 0.6392, Accuracy: 0.6438\n","Epoch 2, Train Loss: 0.6033, Val Loss: 0.5842, F1 Micro: 0.6594, F1 Macro: 0.6576, Accuracy: 0.6594\n","Epoch 3, Train Loss: 0.5819, Val Loss: 0.5813, F1 Micro: 0.6469, F1 Macro: 0.6435, Accuracy: 0.6469\n","Epoch 4, Train Loss: 0.5772, Val Loss: 0.5791, F1 Micro: 0.6625, F1 Macro: 0.6603, Accuracy: 0.6625\n","Epoch 5, Train Loss: 0.5891, Val Loss: 0.6421, F1 Micro: 0.6438, F1 Macro: 0.6085, Accuracy: 0.6438\n","Epoch 6, Train Loss: 0.5986, Val Loss: 0.5867, F1 Micro: 0.6438, F1 Macro: 0.6362, Accuracy: 0.6438\n","Epoch 7, Train Loss: 0.6011, Val Loss: 0.5952, F1 Micro: 0.6625, F1 Macro: 0.6622, Accuracy: 0.6625\n","Epoch 8, Train Loss: 0.6001, Val Loss: 0.5979, F1 Micro: 0.6469, F1 Macro: 0.6431, Accuracy: 0.6469\n","Epoch 9, Train Loss: 0.5811, Val Loss: 0.6109, F1 Micro: 0.6406, F1 Macro: 0.6160, Accuracy: 0.6406\n","Epoch 10, Train Loss: 0.5822, Val Loss: 0.5845, F1 Micro: 0.6406, F1 Macro: 0.6340, Accuracy: 0.6406\n","Epoch 11, Train Loss: 0.5765, Val Loss: 0.5896, F1 Micro: 0.6469, F1 Macro: 0.6369, Accuracy: 0.6469\n","Epoch 12, Train Loss: 0.5819, Val Loss: 0.5884, F1 Micro: 0.6438, F1 Macro: 0.6355, Accuracy: 0.6438\n","Epoch 13, Train Loss: 0.5773, Val Loss: 0.5903, F1 Micro: 0.6438, F1 Macro: 0.6341, Accuracy: 0.6438\n","Epoch 14, Train Loss: 0.6103, Val Loss: 0.5879, F1 Micro: 0.6625, F1 Macro: 0.6603, Accuracy: 0.6625\n","Epoch 15, Train Loss: 0.5982, Val Loss: 0.5838, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 16, Train Loss: 0.5865, Val Loss: 0.5836, F1 Micro: 0.6500, F1 Macro: 0.6433, Accuracy: 0.6500\n","Epoch 17, Train Loss: 0.6039, Val Loss: 0.6358, F1 Micro: 0.7031, F1 Macro: 0.6934, Accuracy: 0.7031\n","Epoch 18, Train Loss: 0.5949, Val Loss: 0.5751, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 19, Train Loss: 0.5770, Val Loss: 0.5724, F1 Micro: 0.6531, F1 Macro: 0.6494, Accuracy: 0.6531\n","Epoch 20, Train Loss: 0.5686, Val Loss: 0.5958, F1 Micro: 0.6562, F1 Macro: 0.6437, Accuracy: 0.6562\n","Epoch 21, Train Loss: 0.5773, Val Loss: 0.6271, F1 Micro: 0.6906, F1 Macro: 0.6782, Accuracy: 0.6906\n","Epoch 22, Train Loss: 0.5651, Val Loss: 0.5608, F1 Micro: 0.6562, F1 Macro: 0.6518, Accuracy: 0.6562\n","Epoch 23, Train Loss: 0.6015, Val Loss: 0.5745, F1 Micro: 0.6906, F1 Macro: 0.6906, Accuracy: 0.6906\n","Epoch 24, Train Loss: 0.5681, Val Loss: 0.5474, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 25, Train Loss: 0.5983, Val Loss: 0.5441, F1 Micro: 0.6750, F1 Macro: 0.6750, Accuracy: 0.6750\n","Epoch 26, Train Loss: 0.5846, Val Loss: 0.5804, F1 Micro: 0.7438, F1 Macro: 0.7431, Accuracy: 0.7438\n","Epoch 27, Train Loss: 0.5591, Val Loss: 0.5533, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 28, Train Loss: 0.5765, Val Loss: 0.5369, F1 Micro: 0.6937, F1 Macro: 0.6936, Accuracy: 0.6937\n","Epoch 29, Train Loss: 0.5526, Val Loss: 0.5394, F1 Micro: 0.6750, F1 Macro: 0.6732, Accuracy: 0.6750\n","Epoch 30, Train Loss: 0.5613, Val Loss: 0.5616, F1 Micro: 0.7125, F1 Macro: 0.7027, Accuracy: 0.7125\n","Epoch 31, Train Loss: 0.5563, Val Loss: 0.6098, F1 Micro: 0.6813, F1 Macro: 0.6564, Accuracy: 0.6813\n","Epoch 32, Train Loss: 0.5579, Val Loss: 0.6901, F1 Micro: 0.6687, F1 Macro: 0.6540, Accuracy: 0.6687\n","Epoch 33, Train Loss: 0.5579, Val Loss: 0.5297, F1 Micro: 0.7125, F1 Macro: 0.7111, Accuracy: 0.7125\n","Epoch 34, Train Loss: 0.5402, Val Loss: 0.5950, F1 Micro: 0.6969, F1 Macro: 0.6821, Accuracy: 0.6969\n","Epoch 35, Train Loss: 0.5658, Val Loss: 0.5565, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 36, Train Loss: 0.5584, Val Loss: 0.5574, F1 Micro: 0.7094, F1 Macro: 0.7018, Accuracy: 0.7094\n","Epoch 37, Train Loss: 0.5802, Val Loss: 0.5825, F1 Micro: 0.6781, F1 Macro: 0.6738, Accuracy: 0.6781\n","Epoch 38, Train Loss: 0.5663, Val Loss: 0.5377, F1 Micro: 0.6906, F1 Macro: 0.6881, Accuracy: 0.6906\n","Epoch 39, Train Loss: 0.5578, Val Loss: 0.5264, F1 Micro: 0.7063, F1 Macro: 0.7058, Accuracy: 0.7063\n","Epoch 40, Train Loss: 0.5472, Val Loss: 0.5501, F1 Micro: 0.7000, F1 Macro: 0.6867, Accuracy: 0.7000\n","Epoch 41, Train Loss: 0.5479, Val Loss: 0.5196, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 42, Train Loss: 0.5824, Val Loss: 0.5579, F1 Micro: 0.7000, F1 Macro: 0.6867, Accuracy: 0.7000\n","Epoch 43, Train Loss: 0.5801, Val Loss: 0.5192, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 44, Train Loss: 0.5609, Val Loss: 0.5225, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 45, Train Loss: 0.5654, Val Loss: 0.5376, F1 Micro: 0.7063, F1 Macro: 0.7053, Accuracy: 0.7063\n","Epoch 46, Train Loss: 0.5470, Val Loss: 0.5919, F1 Micro: 0.7000, F1 Macro: 0.6821, Accuracy: 0.7000\n","Epoch 47, Train Loss: 0.5449, Val Loss: 0.5145, F1 Micro: 0.7031, F1 Macro: 0.6999, Accuracy: 0.7031\n","Epoch 48, Train Loss: 0.5493, Val Loss: 0.5377, F1 Micro: 0.7281, F1 Macro: 0.7231, Accuracy: 0.7281\n","Epoch 49, Train Loss: 0.5469, Val Loss: 0.5153, F1 Micro: 0.6875, F1 Macro: 0.6825, Accuracy: 0.6875\n","Epoch 50, Train Loss: 0.5595, Val Loss: 0.5211, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 51, Train Loss: 0.5445, Val Loss: 0.5122, F1 Micro: 0.7344, F1 Macro: 0.7344, Accuracy: 0.7344\n","Epoch 52, Train Loss: 0.5305, Val Loss: 0.5201, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 53, Train Loss: 0.5413, Val Loss: 0.5177, F1 Micro: 0.7063, F1 Macro: 0.7001, Accuracy: 0.7063\n","Epoch 54, Train Loss: 0.5399, Val Loss: 0.5372, F1 Micro: 0.6813, F1 Macro: 0.6680, Accuracy: 0.6813\n","Epoch 55, Train Loss: 0.5361, Val Loss: 0.6019, F1 Micro: 0.6937, F1 Macro: 0.6801, Accuracy: 0.6937\n","Epoch 56, Train Loss: 0.5545, Val Loss: 0.5185, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 57, Train Loss: 0.5508, Val Loss: 0.5083, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 58, Train Loss: 0.5476, Val Loss: 0.5563, F1 Micro: 0.7594, F1 Macro: 0.7554, Accuracy: 0.7594\n","Epoch 59, Train Loss: 0.5475, Val Loss: 0.5570, F1 Micro: 0.7000, F1 Macro: 0.6831, Accuracy: 0.7000\n","Epoch 60, Train Loss: 0.5322, Val Loss: 0.5260, F1 Micro: 0.6937, F1 Macro: 0.6810, Accuracy: 0.6937\n","Epoch 61, Train Loss: 0.5468, Val Loss: 0.5688, F1 Micro: 0.7063, F1 Macro: 0.6940, Accuracy: 0.7063\n","Epoch 62, Train Loss: 0.5625, Val Loss: 0.5146, F1 Micro: 0.7000, F1 Macro: 0.6992, Accuracy: 0.7000\n","Epoch 63, Train Loss: 0.5408, Val Loss: 0.5327, F1 Micro: 0.7094, F1 Macro: 0.6991, Accuracy: 0.7094\n","Epoch 64, Train Loss: 0.5842, Val Loss: 1.0250, F1 Micro: 0.5719, F1 Macro: 0.4792, Accuracy: 0.5719\n","Epoch 65, Train Loss: 0.7779, Val Loss: 0.8122, F1 Micro: 0.5437, F1 Macro: 0.4196, Accuracy: 0.5437\n","Epoch 66, Train Loss: 0.5945, Val Loss: 0.5578, F1 Micro: 0.6937, F1 Macro: 0.6801, Accuracy: 0.6937\n","Epoch 67, Train Loss: 0.5596, Val Loss: 0.5454, F1 Micro: 0.6781, F1 Macro: 0.6751, Accuracy: 0.6781\n","Epoch 68, Train Loss: 0.5539, Val Loss: 0.5380, F1 Micro: 0.6969, F1 Macro: 0.6838, Accuracy: 0.6969\n","Epoch 69, Train Loss: 0.5496, Val Loss: 0.5224, F1 Micro: 0.7031, F1 Macro: 0.6934, Accuracy: 0.7031\n","Epoch 70, Train Loss: 0.5541, Val Loss: 0.5085, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 71, Train Loss: 0.5493, Val Loss: 0.5818, F1 Micro: 0.6969, F1 Macro: 0.6890, Accuracy: 0.6969\n","Epoch 72, Train Loss: 0.5593, Val Loss: 0.5572, F1 Micro: 0.7156, F1 Macro: 0.7063, Accuracy: 0.7156\n","Epoch 73, Train Loss: 0.5511, Val Loss: 0.4980, F1 Micro: 0.7438, F1 Macro: 0.7425, Accuracy: 0.7438\n","Epoch 74, Train Loss: 0.5504, Val Loss: 0.5307, F1 Micro: 0.6875, F1 Macro: 0.6843, Accuracy: 0.6875\n","Epoch 75, Train Loss: 0.5315, Val Loss: 0.6236, F1 Micro: 0.7000, F1 Macro: 0.6755, Accuracy: 0.7000\n","Epoch 76, Train Loss: 0.5445, Val Loss: 0.6305, F1 Micro: 0.6625, F1 Macro: 0.6291, Accuracy: 0.6625\n","Epoch 77, Train Loss: 0.5161, Val Loss: 0.5547, F1 Micro: 0.8031, F1 Macro: 0.7995, Accuracy: 0.8031\n","Epoch 78, Train Loss: 0.5423, Val Loss: 0.4992, F1 Micro: 0.7625, F1 Macro: 0.7620, Accuracy: 0.7625\n","Epoch 79, Train Loss: 0.5265, Val Loss: 0.5014, F1 Micro: 0.7812, F1 Macro: 0.7812, Accuracy: 0.7812\n","Epoch 80, Train Loss: 0.5481, Val Loss: 0.5103, F1 Micro: 0.7312, F1 Macro: 0.7311, Accuracy: 0.7312\n","Epoch 81, Train Loss: 0.5489, Val Loss: 0.5345, F1 Micro: 0.7031, F1 Macro: 0.7007, Accuracy: 0.7031\n","Epoch 82, Train Loss: 0.5344, Val Loss: 0.4925, F1 Micro: 0.7375, F1 Macro: 0.7373, Accuracy: 0.7375\n","Epoch 83, Train Loss: 0.5729, Val Loss: 0.5857, F1 Micro: 0.7031, F1 Macro: 0.6868, Accuracy: 0.7031\n","Epoch 84, Train Loss: 0.5554, Val Loss: 0.7437, F1 Micro: 0.6531, F1 Macro: 0.6057, Accuracy: 0.6531\n","Epoch 85, Train Loss: 0.5411, Val Loss: 0.5371, F1 Micro: 0.6750, F1 Macro: 0.6545, Accuracy: 0.6750\n","Epoch 86, Train Loss: 0.5380, Val Loss: 0.5617, F1 Micro: 0.7063, F1 Macro: 0.7040, Accuracy: 0.7063\n","Epoch 87, Train Loss: 0.5312, Val Loss: 0.5363, F1 Micro: 0.6969, F1 Macro: 0.6838, Accuracy: 0.6969\n","Epoch 88, Train Loss: 0.5381, Val Loss: 0.4975, F1 Micro: 0.7344, F1 Macro: 0.7312, Accuracy: 0.7344\n","Epoch 89, Train Loss: 0.5451, Val Loss: 0.5714, F1 Micro: 0.6969, F1 Macro: 0.6702, Accuracy: 0.6969\n","Epoch 90, Train Loss: 0.5145, Val Loss: 0.5403, F1 Micro: 0.7844, F1 Macro: 0.7843, Accuracy: 0.7844\n","Epoch 91, Train Loss: 0.5230, Val Loss: 0.5223, F1 Micro: 0.6781, F1 Macro: 0.6605, Accuracy: 0.6781\n","Epoch 92, Train Loss: 0.5949, Val Loss: 0.5040, F1 Micro: 0.7781, F1 Macro: 0.7775, Accuracy: 0.7781\n","Epoch 93, Train Loss: 0.5400, Val Loss: 0.4979, F1 Micro: 0.7719, F1 Macro: 0.7707, Accuracy: 0.7719\n","Epoch 94, Train Loss: 0.5414, Val Loss: 0.5664, F1 Micro: 0.6719, F1 Macro: 0.6457, Accuracy: 0.6719\n","Epoch 95, Train Loss: 0.5851, Val Loss: 0.4882, F1 Micro: 0.7438, F1 Macro: 0.7405, Accuracy: 0.7438\n","Epoch 96, Train Loss: 0.5553, Val Loss: 0.5972, F1 Micro: 0.7438, F1 Macro: 0.7293, Accuracy: 0.7438\n","Epoch 97, Train Loss: 0.5169, Val Loss: 0.4802, F1 Micro: 0.7594, F1 Macro: 0.7591, Accuracy: 0.7594\n","Epoch 98, Train Loss: 0.5548, Val Loss: 0.5205, F1 Micro: 0.7594, F1 Macro: 0.7587, Accuracy: 0.7594\n","Epoch 99, Train Loss: 0.5170, Val Loss: 0.4787, F1 Micro: 0.7281, F1 Macro: 0.7240, Accuracy: 0.7281\n","Epoch 100, Train Loss: 0.5345, Val Loss: 0.4858, F1 Micro: 0.7281, F1 Macro: 0.7221, Accuracy: 0.7281\n","Epoch 101, Train Loss: 0.5277, Val Loss: 0.5007, F1 Micro: 0.6969, F1 Macro: 0.6830, Accuracy: 0.6969\n","Epoch 102, Train Loss: 0.5228, Val Loss: 0.4807, F1 Micro: 0.7469, F1 Macro: 0.7456, Accuracy: 0.7469\n","Epoch 103, Train Loss: 0.5126, Val Loss: 0.4824, F1 Micro: 0.7125, F1 Macro: 0.7034, Accuracy: 0.7125\n","Epoch 104, Train Loss: 0.5139, Val Loss: 0.5093, F1 Micro: 0.7000, F1 Macro: 0.6840, Accuracy: 0.7000\n","Epoch 105, Train Loss: 0.5178, Val Loss: 0.4759, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 106, Train Loss: 0.4836, Val Loss: 0.5346, F1 Micro: 0.7812, F1 Macro: 0.7748, Accuracy: 0.7812\n","Epoch 107, Train Loss: 0.5308, Val Loss: 0.4660, F1 Micro: 0.7906, F1 Macro: 0.7900, Accuracy: 0.7906\n","Epoch 108, Train Loss: 0.5105, Val Loss: 0.5499, F1 Micro: 0.6625, F1 Macro: 0.6349, Accuracy: 0.6625\n","Epoch 109, Train Loss: 0.5241, Val Loss: 0.4695, F1 Micro: 0.7406, F1 Macro: 0.7363, Accuracy: 0.7406\n","Epoch 110, Train Loss: 0.5212, Val Loss: 0.5337, F1 Micro: 0.7531, F1 Macro: 0.7403, Accuracy: 0.7531\n","Epoch 111, Train Loss: 0.5158, Val Loss: 0.4572, F1 Micro: 0.7531, F1 Macro: 0.7514, Accuracy: 0.7531\n","Epoch 112, Train Loss: 0.4866, Val Loss: 0.4668, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 113, Train Loss: 0.5349, Val Loss: 0.4740, F1 Micro: 0.7219, F1 Macro: 0.7163, Accuracy: 0.7219\n","Epoch 114, Train Loss: 0.5087, Val Loss: 0.4837, F1 Micro: 0.7188, F1 Macro: 0.7099, Accuracy: 0.7188\n","Epoch 115, Train Loss: 0.5106, Val Loss: 0.4504, F1 Micro: 0.7531, F1 Macro: 0.7498, Accuracy: 0.7531\n","Epoch 116, Train Loss: 0.5135, Val Loss: 0.4594, F1 Micro: 0.7781, F1 Macro: 0.7779, Accuracy: 0.7781\n","Epoch 117, Train Loss: 0.4842, Val Loss: 0.7456, F1 Micro: 0.6844, F1 Macro: 0.6539, Accuracy: 0.6844\n","Epoch 118, Train Loss: 0.5381, Val Loss: 0.6561, F1 Micro: 0.6344, F1 Macro: 0.5802, Accuracy: 0.6344\n","Epoch 119, Train Loss: 0.5144, Val Loss: 0.5499, F1 Micro: 0.6750, F1 Macro: 0.6662, Accuracy: 0.6750\n","Epoch 120, Train Loss: 0.4791, Val Loss: 0.6386, F1 Micro: 0.7531, F1 Macro: 0.7380, Accuracy: 0.7531\n","Epoch 121, Train Loss: 0.5090, Val Loss: 0.4532, F1 Micro: 0.7906, F1 Macro: 0.7906, Accuracy: 0.7906\n","Epoch 122, Train Loss: 0.5175, Val Loss: 0.8467, F1 Micro: 0.4969, F1 Macro: 0.3319, Accuracy: 0.4969\n","Epoch 123, Train Loss: 0.5245, Val Loss: 0.5401, F1 Micro: 0.7063, F1 Macro: 0.6845, Accuracy: 0.7063\n","Epoch 124, Train Loss: 0.5139, Val Loss: 0.4566, F1 Micro: 0.8219, F1 Macro: 0.8206, Accuracy: 0.8219\n","Epoch 125, Train Loss: 0.5013, Val Loss: 0.4767, F1 Micro: 0.7406, F1 Macro: 0.7359, Accuracy: 0.7406\n","Epoch 126, Train Loss: 0.5007, Val Loss: 0.4915, F1 Micro: 0.8094, F1 Macro: 0.8055, Accuracy: 0.8094\n","Epoch 127, Train Loss: 0.4915, Val Loss: 0.4857, F1 Micro: 0.8219, F1 Macro: 0.8195, Accuracy: 0.8219\n","Epoch 128, Train Loss: 0.4921, Val Loss: 0.4596, F1 Micro: 0.7812, F1 Macro: 0.7812, Accuracy: 0.7812\n","Epoch 129, Train Loss: 0.4771, Val Loss: 0.6475, F1 Micro: 0.6406, F1 Macro: 0.5935, Accuracy: 0.6406\n","Epoch 130, Train Loss: 0.4837, Val Loss: 0.4608, F1 Micro: 0.7438, F1 Macro: 0.7379, Accuracy: 0.7438\n","Epoch 131, Train Loss: 0.4943, Val Loss: 0.4584, F1 Micro: 0.7906, F1 Macro: 0.7905, Accuracy: 0.7906\n","Epoch 132, Train Loss: 0.4770, Val Loss: 0.5309, F1 Micro: 0.7750, F1 Macro: 0.7662, Accuracy: 0.7750\n","Epoch 133, Train Loss: 0.5151, Val Loss: 0.5601, F1 Micro: 0.7094, F1 Macro: 0.6943, Accuracy: 0.7094\n","Epoch 134, Train Loss: 0.4897, Val Loss: 0.4583, F1 Micro: 0.7531, F1 Macro: 0.7518, Accuracy: 0.7531\n","Epoch 135, Train Loss: 0.5009, Val Loss: 0.4563, F1 Micro: 0.7500, F1 Macro: 0.7456, Accuracy: 0.7500\n","Epoch 136, Train Loss: 0.4871, Val Loss: 0.9701, F1 Micro: 0.5719, F1 Macro: 0.4825, Accuracy: 0.5719\n","Epoch 137, Train Loss: 0.5074, Val Loss: 0.4677, F1 Micro: 0.7594, F1 Macro: 0.7568, Accuracy: 0.7594\n","Epoch 138, Train Loss: 0.4902, Val Loss: 0.4749, F1 Micro: 0.8187, F1 Macro: 0.8171, Accuracy: 0.8187\n","Epoch 139, Train Loss: 0.4925, Val Loss: 0.4512, F1 Micro: 0.7312, F1 Macro: 0.7245, Accuracy: 0.7312\n","Epoch 140, Train Loss: 0.4849, Val Loss: 0.4956, F1 Micro: 0.8156, F1 Macro: 0.8128, Accuracy: 0.8156\n","Epoch 141, Train Loss: 0.5057, Val Loss: 0.4619, F1 Micro: 0.7438, F1 Macro: 0.7388, Accuracy: 0.7438\n","Epoch 142, Train Loss: 0.4776, Val Loss: 0.4953, F1 Micro: 0.8031, F1 Macro: 0.7988, Accuracy: 0.8031\n","Epoch 143, Train Loss: 0.5157, Val Loss: 0.5471, F1 Micro: 0.7562, F1 Macro: 0.7447, Accuracy: 0.7562\n","Epoch 144, Train Loss: 0.4734, Val Loss: 0.4716, F1 Micro: 0.8094, F1 Macro: 0.8092, Accuracy: 0.8094\n","Epoch 145, Train Loss: 0.4853, Val Loss: 0.4422, F1 Micro: 0.7719, F1 Macro: 0.7712, Accuracy: 0.7719\n","Epoch 146, Train Loss: 0.5114, Val Loss: 0.4548, F1 Micro: 0.7562, F1 Macro: 0.7511, Accuracy: 0.7562\n","Epoch 147, Train Loss: 0.4743, Val Loss: 0.6310, F1 Micro: 0.7719, F1 Macro: 0.7601, Accuracy: 0.7719\n","Epoch 148, Train Loss: 0.4893, Val Loss: 0.5386, F1 Micro: 0.7250, F1 Macro: 0.7135, Accuracy: 0.7250\n","Epoch 149, Train Loss: 0.5022, Val Loss: 0.6486, F1 Micro: 0.7625, F1 Macro: 0.7491, Accuracy: 0.7625\n","Epoch 150, Train Loss: 0.5327, Val Loss: 0.5637, F1 Micro: 0.7531, F1 Macro: 0.7432, Accuracy: 0.7531\n","Epoch 151, Train Loss: 0.5171, Val Loss: 0.5461, F1 Micro: 0.7375, F1 Macro: 0.7209, Accuracy: 0.7375\n","Epoch 152, Train Loss: 0.4959, Val Loss: 0.4906, F1 Micro: 0.7156, F1 Macro: 0.7009, Accuracy: 0.7156\n","Epoch 153, Train Loss: 0.4563, Val Loss: 0.4588, F1 Micro: 0.8219, F1 Macro: 0.8211, Accuracy: 0.8219\n","Epoch 154, Train Loss: 0.4804, Val Loss: 0.4512, F1 Micro: 0.8094, F1 Macro: 0.8093, Accuracy: 0.8094\n","Epoch 155, Train Loss: 0.4817, Val Loss: 0.5021, F1 Micro: 0.7875, F1 Macro: 0.7834, Accuracy: 0.7875\n","Epoch 156, Train Loss: 0.5028, Val Loss: 0.5204, F1 Micro: 0.7438, F1 Macro: 0.7425, Accuracy: 0.7438\n","Epoch 157, Train Loss: 0.4893, Val Loss: 0.5548, F1 Micro: 0.7562, F1 Macro: 0.7433, Accuracy: 0.7562\n","Epoch 158, Train Loss: 0.4776, Val Loss: 0.4504, F1 Micro: 0.7812, F1 Macro: 0.7793, Accuracy: 0.7812\n","Epoch 159, Train Loss: 0.5063, Val Loss: 0.5087, F1 Micro: 0.7937, F1 Macro: 0.7886, Accuracy: 0.7937\n","Epoch 160, Train Loss: 0.4800, Val Loss: 0.4586, F1 Micro: 0.8219, F1 Macro: 0.8212, Accuracy: 0.8219\n","Epoch 161, Train Loss: 0.4856, Val Loss: 0.5597, F1 Micro: 0.7688, F1 Macro: 0.7591, Accuracy: 0.7688\n","Epoch 162, Train Loss: 0.4862, Val Loss: 0.5134, F1 Micro: 0.7188, F1 Macro: 0.7111, Accuracy: 0.7188\n","Epoch 163, Train Loss: 0.4882, Val Loss: 0.4567, F1 Micro: 0.7469, F1 Macro: 0.7408, Accuracy: 0.7469\n","Epoch 164, Train Loss: 0.5218, Val Loss: 0.4500, F1 Micro: 0.7781, F1 Macro: 0.7776, Accuracy: 0.7781\n","Epoch 165, Train Loss: 0.4952, Val Loss: 0.5101, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 166, Train Loss: 0.5059, Val Loss: 0.6653, F1 Micro: 0.6906, F1 Macro: 0.6647, Accuracy: 0.6906\n","Epoch 167, Train Loss: 0.4994, Val Loss: 0.4926, F1 Micro: 0.7219, F1 Macro: 0.7091, Accuracy: 0.7219\n","Epoch 168, Train Loss: 0.4849, Val Loss: 0.9429, F1 Micro: 0.5094, F1 Macro: 0.3590, Accuracy: 0.5094\n","Epoch 169, Train Loss: 0.4875, Val Loss: 0.4430, F1 Micro: 0.7781, F1 Macro: 0.7775, Accuracy: 0.7781\n","Epoch 170, Train Loss: 0.4687, Val Loss: 0.5653, F1 Micro: 0.7469, F1 Macro: 0.7322, Accuracy: 0.7469\n","Epoch 171, Train Loss: 0.4694, Val Loss: 0.6059, F1 Micro: 0.6656, F1 Macro: 0.6318, Accuracy: 0.6656\n","Epoch 172, Train Loss: 0.4829, Val Loss: 0.4458, F1 Micro: 0.8031, F1 Macro: 0.8030, Accuracy: 0.8031\n","Epoch 173, Train Loss: 0.4732, Val Loss: 0.5854, F1 Micro: 0.6594, F1 Macro: 0.6183, Accuracy: 0.6594\n","Epoch 174, Train Loss: 0.4739, Val Loss: 0.4493, F1 Micro: 0.7594, F1 Macro: 0.7561, Accuracy: 0.7594\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8184, Val Loss: 0.6434, F1 Micro: 0.5938, F1 Macro: 0.5347, Accuracy: 0.5938\n","Epoch 2, Train Loss: 0.6054, Val Loss: 0.6026, F1 Micro: 0.7156, F1 Macro: 0.6894, Accuracy: 0.7156\n","Epoch 3, Train Loss: 0.5908, Val Loss: 0.5658, F1 Micro: 0.7219, F1 Macro: 0.7121, Accuracy: 0.7219\n","Epoch 4, Train Loss: 0.5900, Val Loss: 0.5736, F1 Micro: 0.6813, F1 Macro: 0.6811, Accuracy: 0.6813\n","Epoch 5, Train Loss: 0.5866, Val Loss: 0.5917, F1 Micro: 0.7000, F1 Macro: 0.6962, Accuracy: 0.7000\n","Epoch 6, Train Loss: 0.5957, Val Loss: 0.5844, F1 Micro: 0.7250, F1 Macro: 0.7046, Accuracy: 0.7250\n","Epoch 7, Train Loss: 0.5834, Val Loss: 0.5625, F1 Micro: 0.7063, F1 Macro: 0.7011, Accuracy: 0.7063\n","Epoch 8, Train Loss: 0.5857, Val Loss: 0.5943, F1 Micro: 0.7312, F1 Macro: 0.7208, Accuracy: 0.7312\n","Epoch 9, Train Loss: 0.5879, Val Loss: 0.5695, F1 Micro: 0.6844, F1 Macro: 0.6810, Accuracy: 0.6844\n","Epoch 10, Train Loss: 0.6123, Val Loss: 0.7204, F1 Micro: 0.4125, F1 Macro: 0.4110, Accuracy: 0.4125\n","Epoch 11, Train Loss: 0.6086, Val Loss: 0.5757, F1 Micro: 0.6844, F1 Macro: 0.6840, Accuracy: 0.6844\n","Epoch 12, Train Loss: 0.6051, Val Loss: 0.5684, F1 Micro: 0.7063, F1 Macro: 0.6970, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.5862, Val Loss: 0.5605, F1 Micro: 0.7125, F1 Macro: 0.7070, Accuracy: 0.7125\n","Epoch 14, Train Loss: 0.5813, Val Loss: 0.5688, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 15, Train Loss: 0.6029, Val Loss: 0.5608, F1 Micro: 0.6844, F1 Macro: 0.6818, Accuracy: 0.6844\n","Epoch 16, Train Loss: 0.6068, Val Loss: 0.5690, F1 Micro: 0.7094, F1 Macro: 0.7040, Accuracy: 0.7094\n","Epoch 17, Train Loss: 0.6111, Val Loss: 0.6347, F1 Micro: 0.6438, F1 Macro: 0.6316, Accuracy: 0.6438\n","Epoch 18, Train Loss: 0.6083, Val Loss: 0.5640, F1 Micro: 0.7156, F1 Macro: 0.7082, Accuracy: 0.7156\n","Epoch 19, Train Loss: 0.5875, Val Loss: 0.5762, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 20, Train Loss: 0.6069, Val Loss: 0.6029, F1 Micro: 0.7219, F1 Macro: 0.7048, Accuracy: 0.7219\n","Epoch 21, Train Loss: 0.5887, Val Loss: 0.6080, F1 Micro: 0.7063, F1 Macro: 0.6785, Accuracy: 0.7063\n","Epoch 22, Train Loss: 0.6074, Val Loss: 0.5867, F1 Micro: 0.6781, F1 Macro: 0.6781, Accuracy: 0.6781\n","Epoch 23, Train Loss: 0.6348, Val Loss: 0.5769, F1 Micro: 0.6875, F1 Macro: 0.6873, Accuracy: 0.6875\n","Epoch 24, Train Loss: 0.5937, Val Loss: 0.5718, F1 Micro: 0.6750, F1 Macro: 0.6737, Accuracy: 0.6750\n","Epoch 25, Train Loss: 0.5839, Val Loss: 0.5843, F1 Micro: 0.7188, F1 Macro: 0.7019, Accuracy: 0.7188\n","Epoch 26, Train Loss: 0.5886, Val Loss: 0.5562, F1 Micro: 0.6906, F1 Macro: 0.6869, Accuracy: 0.6906\n","Epoch 27, Train Loss: 0.5865, Val Loss: 0.5815, F1 Micro: 0.7188, F1 Macro: 0.7070, Accuracy: 0.7188\n","Epoch 28, Train Loss: 0.5964, Val Loss: 0.5967, F1 Micro: 0.7000, F1 Macro: 0.6690, Accuracy: 0.7000\n","Epoch 29, Train Loss: 0.6142, Val Loss: 0.5922, F1 Micro: 0.7250, F1 Macro: 0.7046, Accuracy: 0.7250\n","Epoch 30, Train Loss: 0.6370, Val Loss: 0.5686, F1 Micro: 0.6813, F1 Macro: 0.6784, Accuracy: 0.6813\n","Epoch 31, Train Loss: 0.6048, Val Loss: 0.5610, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 32, Train Loss: 0.5972, Val Loss: 0.5752, F1 Micro: 0.6750, F1 Macro: 0.6737, Accuracy: 0.6750\n","Epoch 33, Train Loss: 0.6117, Val Loss: 0.5866, F1 Micro: 0.7094, F1 Macro: 0.6884, Accuracy: 0.7094\n","Epoch 34, Train Loss: 0.5929, Val Loss: 0.5730, F1 Micro: 0.6750, F1 Macro: 0.6737, Accuracy: 0.6750\n","Epoch 35, Train Loss: 0.5872, Val Loss: 0.5618, F1 Micro: 0.7125, F1 Macro: 0.7059, Accuracy: 0.7125\n","Epoch 36, Train Loss: 0.5785, Val Loss: 0.5577, F1 Micro: 0.6813, F1 Macro: 0.6791, Accuracy: 0.6813\n","Epoch 37, Train Loss: 0.6056, Val Loss: 0.6878, F1 Micro: 0.6937, F1 Macro: 0.6606, Accuracy: 0.6937\n","Epoch 38, Train Loss: 0.6032, Val Loss: 0.5780, F1 Micro: 0.7219, F1 Macro: 0.7099, Accuracy: 0.7219\n","Epoch 39, Train Loss: 0.5906, Val Loss: 0.5570, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 40, Train Loss: 0.5938, Val Loss: 0.5606, F1 Micro: 0.7219, F1 Macro: 0.7152, Accuracy: 0.7219\n","Epoch 41, Train Loss: 0.5945, Val Loss: 0.5621, F1 Micro: 0.6875, F1 Macro: 0.6873, Accuracy: 0.6875\n","Epoch 42, Train Loss: 0.5837, Val Loss: 0.5608, F1 Micro: 0.7156, F1 Macro: 0.7088, Accuracy: 0.7156\n","Epoch 43, Train Loss: 0.5875, Val Loss: 0.5961, F1 Micro: 0.7281, F1 Macro: 0.7123, Accuracy: 0.7281\n","Epoch 44, Train Loss: 0.5766, Val Loss: 0.5574, F1 Micro: 0.7000, F1 Macro: 0.6966, Accuracy: 0.7000\n","Epoch 45, Train Loss: 0.5825, Val Loss: 0.5870, F1 Micro: 0.7094, F1 Macro: 0.6873, Accuracy: 0.7094\n","Epoch 46, Train Loss: 0.5965, Val Loss: 0.6662, F1 Micro: 0.7156, F1 Macro: 0.7042, Accuracy: 0.7156\n","Epoch 47, Train Loss: 0.5996, Val Loss: 0.5674, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 48, Train Loss: 0.5645, Val Loss: 0.5546, F1 Micro: 0.7125, F1 Macro: 0.7084, Accuracy: 0.7125\n","Epoch 49, Train Loss: 0.5703, Val Loss: 0.5552, F1 Micro: 0.7063, F1 Macro: 0.6989, Accuracy: 0.7063\n","Epoch 50, Train Loss: 0.5845, Val Loss: 0.5609, F1 Micro: 0.7094, F1 Macro: 0.6991, Accuracy: 0.7094\n","Epoch 51, Train Loss: 0.5745, Val Loss: 0.5617, F1 Micro: 0.7063, F1 Macro: 0.6995, Accuracy: 0.7063\n","Epoch 52, Train Loss: 0.5718, Val Loss: 0.5488, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 53, Train Loss: 0.5639, Val Loss: 0.5528, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 54, Train Loss: 0.5576, Val Loss: 0.5654, F1 Micro: 0.7188, F1 Macro: 0.7070, Accuracy: 0.7188\n","Epoch 55, Train Loss: 0.5607, Val Loss: 0.5350, F1 Micro: 0.7094, F1 Macro: 0.7024, Accuracy: 0.7094\n","Epoch 56, Train Loss: 0.5715, Val Loss: 0.5616, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 57, Train Loss: 0.5703, Val Loss: 0.6134, F1 Micro: 0.6719, F1 Macro: 0.6603, Accuracy: 0.6719\n","Epoch 58, Train Loss: 0.5712, Val Loss: 0.5505, F1 Micro: 0.6844, F1 Macro: 0.6837, Accuracy: 0.6844\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7365, Val Loss: 0.6155, F1 Micro: 0.6562, F1 Macro: 0.6490, Accuracy: 0.6562\n","Epoch 2, Train Loss: 0.6105, Val Loss: 0.6670, F1 Micro: 0.6375, F1 Macro: 0.6329, Accuracy: 0.6375\n","Epoch 3, Train Loss: 0.5827, Val Loss: 0.7150, F1 Micro: 0.6344, F1 Macro: 0.6299, Accuracy: 0.6344\n","Epoch 4, Train Loss: 0.5758, Val Loss: 0.6248, F1 Micro: 0.6500, F1 Macro: 0.6486, Accuracy: 0.6500\n","Epoch 5, Train Loss: 0.5741, Val Loss: 0.6160, F1 Micro: 0.6531, F1 Macro: 0.6516, Accuracy: 0.6531\n","Epoch 6, Train Loss: 0.5711, Val Loss: 0.6169, F1 Micro: 0.6562, F1 Macro: 0.6546, Accuracy: 0.6562\n","Epoch 7, Train Loss: 0.5781, Val Loss: 0.6166, F1 Micro: 0.6656, F1 Macro: 0.6649, Accuracy: 0.6656\n","Epoch 8, Train Loss: 0.5737, Val Loss: 0.7570, F1 Micro: 0.6062, F1 Macro: 0.5909, Accuracy: 0.6062\n","Epoch 9, Train Loss: 0.5792, Val Loss: 0.7672, F1 Micro: 0.6188, F1 Macro: 0.6092, Accuracy: 0.6188\n","Epoch 10, Train Loss: 0.5871, Val Loss: 0.6147, F1 Micro: 0.6500, F1 Macro: 0.6499, Accuracy: 0.6500\n","Epoch 11, Train Loss: 0.5681, Val Loss: 0.7075, F1 Micro: 0.6312, F1 Macro: 0.6265, Accuracy: 0.6312\n","Epoch 12, Train Loss: 0.5778, Val Loss: 0.6060, F1 Micro: 0.6438, F1 Macro: 0.6299, Accuracy: 0.6438\n","Epoch 13, Train Loss: 0.5681, Val Loss: 0.6327, F1 Micro: 0.6594, F1 Macro: 0.6474, Accuracy: 0.6594\n","Epoch 14, Train Loss: 0.5756, Val Loss: 0.6225, F1 Micro: 0.6531, F1 Macro: 0.6494, Accuracy: 0.6531\n","Epoch 15, Train Loss: 0.5660, Val Loss: 0.6139, F1 Micro: 0.6531, F1 Macro: 0.6521, Accuracy: 0.6531\n","Epoch 16, Train Loss: 0.6301, Val Loss: 0.6744, F1 Micro: 0.6562, F1 Macro: 0.6562, Accuracy: 0.6562\n","Epoch 17, Train Loss: 0.6650, Val Loss: 0.7588, F1 Micro: 0.6281, F1 Macro: 0.6168, Accuracy: 0.6281\n","Epoch 18, Train Loss: 0.5827, Val Loss: 0.6661, F1 Micro: 0.6156, F1 Macro: 0.6056, Accuracy: 0.6156\n","Epoch 19, Train Loss: 0.5845, Val Loss: 0.6071, F1 Micro: 0.6531, F1 Macro: 0.6506, Accuracy: 0.6531\n","Epoch 20, Train Loss: 0.5969, Val Loss: 0.5947, F1 Micro: 0.6625, F1 Macro: 0.6603, Accuracy: 0.6625\n","Epoch 21, Train Loss: 0.5611, Val Loss: 0.6344, F1 Micro: 0.6312, F1 Macro: 0.6270, Accuracy: 0.6312\n","Epoch 22, Train Loss: 0.5721, Val Loss: 0.6162, F1 Micro: 0.6562, F1 Macro: 0.6561, Accuracy: 0.6562\n","Epoch 23, Train Loss: 0.5692, Val Loss: 0.6228, F1 Micro: 0.6625, F1 Macro: 0.6620, Accuracy: 0.6625\n","Epoch 24, Train Loss: 0.5674, Val Loss: 0.7313, F1 Micro: 0.6094, F1 Macro: 0.5956, Accuracy: 0.6094\n","Epoch 25, Train Loss: 0.5982, Val Loss: 0.6344, F1 Micro: 0.6375, F1 Macro: 0.6329, Accuracy: 0.6375\n","Epoch 26, Train Loss: 0.5846, Val Loss: 0.5974, F1 Micro: 0.6531, F1 Macro: 0.6530, Accuracy: 0.6531\n","Epoch 27, Train Loss: 0.5618, Val Loss: 0.6462, F1 Micro: 0.6188, F1 Macro: 0.6058, Accuracy: 0.6188\n","Epoch 28, Train Loss: 0.5900, Val Loss: 0.6647, F1 Micro: 0.6406, F1 Macro: 0.6391, Accuracy: 0.6406\n","Epoch 29, Train Loss: 0.5726, Val Loss: 0.6346, F1 Micro: 0.6281, F1 Macro: 0.6176, Accuracy: 0.6281\n","Epoch 30, Train Loss: 0.5937, Val Loss: 0.6527, F1 Micro: 0.6562, F1 Macro: 0.6559, Accuracy: 0.6562\n","Epoch 31, Train Loss: 0.6324, Val Loss: 0.5963, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 32, Train Loss: 0.5782, Val Loss: 0.7124, F1 Micro: 0.6625, F1 Macro: 0.6624, Accuracy: 0.6625\n","Epoch 33, Train Loss: 0.6046, Val Loss: 0.5948, F1 Micro: 0.6531, F1 Macro: 0.6530, Accuracy: 0.6531\n","Epoch 34, Train Loss: 0.5789, Val Loss: 0.6231, F1 Micro: 0.6406, F1 Macro: 0.6391, Accuracy: 0.6406\n","Epoch 35, Train Loss: 0.5774, Val Loss: 0.5903, F1 Micro: 0.6531, F1 Macro: 0.6441, Accuracy: 0.6531\n","Epoch 36, Train Loss: 0.5732, Val Loss: 0.5976, F1 Micro: 0.6594, F1 Macro: 0.6573, Accuracy: 0.6594\n","Epoch 37, Train Loss: 0.5700, Val Loss: 0.5918, F1 Micro: 0.6656, F1 Macro: 0.6539, Accuracy: 0.6656\n","Epoch 38, Train Loss: 0.5685, Val Loss: 0.6176, F1 Micro: 0.6281, F1 Macro: 0.6213, Accuracy: 0.6281\n","Epoch 39, Train Loss: 0.5883, Val Loss: 0.5781, F1 Micro: 0.6531, F1 Macro: 0.6526, Accuracy: 0.6531\n","Epoch 40, Train Loss: 0.5760, Val Loss: 0.6020, F1 Micro: 0.6438, F1 Macro: 0.6421, Accuracy: 0.6438\n","Epoch 41, Train Loss: 0.6001, Val Loss: 0.5965, F1 Micro: 0.6562, F1 Macro: 0.6508, Accuracy: 0.6562\n","Epoch 42, Train Loss: 0.5622, Val Loss: 0.5996, F1 Micro: 0.6719, F1 Macro: 0.6568, Accuracy: 0.6719\n","Epoch 43, Train Loss: 0.5435, Val Loss: 0.5963, F1 Micro: 0.6813, F1 Macro: 0.6704, Accuracy: 0.6813\n","Epoch 44, Train Loss: 0.5376, Val Loss: 0.5435, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 45, Train Loss: 0.5482, Val Loss: 0.7784, F1 Micro: 0.6438, F1 Macro: 0.6146, Accuracy: 0.6438\n","Epoch 46, Train Loss: 0.5910, Val Loss: 0.5692, F1 Micro: 0.6719, F1 Macro: 0.6669, Accuracy: 0.6719\n","Epoch 47, Train Loss: 0.5621, Val Loss: 0.6741, F1 Micro: 0.5781, F1 Macro: 0.4868, Accuracy: 0.5781\n","Epoch 48, Train Loss: 0.5406, Val Loss: 0.5795, F1 Micro: 0.6937, F1 Macro: 0.6818, Accuracy: 0.6937\n","Epoch 49, Train Loss: 0.5248, Val Loss: 0.6782, F1 Micro: 0.6656, F1 Macro: 0.6427, Accuracy: 0.6656\n","Epoch 50, Train Loss: 0.5621, Val Loss: 0.5577, F1 Micro: 0.6438, F1 Macro: 0.6387, Accuracy: 0.6438\n","Epoch 51, Train Loss: 0.5587, Val Loss: 0.5879, F1 Micro: 0.6500, F1 Macro: 0.6489, Accuracy: 0.6500\n","Epoch 52, Train Loss: 0.5525, Val Loss: 0.5834, F1 Micro: 0.6562, F1 Macro: 0.6462, Accuracy: 0.6562\n","Epoch 53, Train Loss: 0.5602, Val Loss: 0.5924, F1 Micro: 0.6656, F1 Macro: 0.6427, Accuracy: 0.6656\n","Epoch 54, Train Loss: 0.5241, Val Loss: 0.5531, F1 Micro: 0.7094, F1 Macro: 0.6991, Accuracy: 0.7094\n","Epoch 55, Train Loss: 0.5630, Val Loss: 0.7040, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 56, Train Loss: 0.5503, Val Loss: 0.6024, F1 Micro: 0.6781, F1 Macro: 0.6441, Accuracy: 0.6781\n","Epoch 57, Train Loss: 0.5402, Val Loss: 0.5746, F1 Micro: 0.6562, F1 Macro: 0.6446, Accuracy: 0.6562\n","Epoch 58, Train Loss: 0.5239, Val Loss: 0.5413, F1 Micro: 0.6813, F1 Macro: 0.6680, Accuracy: 0.6813\n","Epoch 59, Train Loss: 0.5361, Val Loss: 0.6850, F1 Micro: 0.6687, F1 Macro: 0.6489, Accuracy: 0.6687\n","Epoch 60, Train Loss: 0.5630, Val Loss: 0.6315, F1 Micro: 0.6750, F1 Macro: 0.6429, Accuracy: 0.6750\n","Epoch 61, Train Loss: 0.5679, Val Loss: 0.5766, F1 Micro: 0.6781, F1 Macro: 0.6634, Accuracy: 0.6781\n","Epoch 62, Train Loss: 0.5462, Val Loss: 0.5713, F1 Micro: 0.6281, F1 Macro: 0.6199, Accuracy: 0.6281\n","Epoch 63, Train Loss: 0.5384, Val Loss: 0.6188, F1 Micro: 0.6531, F1 Macro: 0.6418, Accuracy: 0.6531\n","Epoch 64, Train Loss: 0.5278, Val Loss: 0.6575, F1 Micro: 0.6625, F1 Macro: 0.6388, Accuracy: 0.6625\n","Epoch 65, Train Loss: 0.5379, Val Loss: 0.5449, F1 Micro: 0.6594, F1 Macro: 0.6474, Accuracy: 0.6594\n","Epoch 66, Train Loss: 0.5372, Val Loss: 0.7477, F1 Micro: 0.6719, F1 Macro: 0.6430, Accuracy: 0.6719\n","Epoch 67, Train Loss: 0.5452, Val Loss: 0.5534, F1 Micro: 0.6719, F1 Macro: 0.6653, Accuracy: 0.6719\n","Epoch 68, Train Loss: 0.5319, Val Loss: 0.5780, F1 Micro: 0.6750, F1 Macro: 0.6596, Accuracy: 0.6750\n","Epoch 69, Train Loss: 0.5358, Val Loss: 0.5899, F1 Micro: 0.7063, F1 Macro: 0.6798, Accuracy: 0.7063\n","Epoch 70, Train Loss: 0.5231, Val Loss: 0.6155, F1 Micro: 0.6719, F1 Macro: 0.6444, Accuracy: 0.6719\n","Epoch 71, Train Loss: 0.5411, Val Loss: 0.5346, F1 Micro: 0.6781, F1 Macro: 0.6624, Accuracy: 0.6781\n","Epoch 72, Train Loss: 0.5427, Val Loss: 0.6426, F1 Micro: 0.6625, F1 Macro: 0.6388, Accuracy: 0.6625\n","Epoch 73, Train Loss: 0.5568, Val Loss: 0.6044, F1 Micro: 0.6281, F1 Macro: 0.5707, Accuracy: 0.6281\n","Epoch 74, Train Loss: 0.5527, Val Loss: 0.5189, F1 Micro: 0.7844, F1 Macro: 0.7838, Accuracy: 0.7844\n","Epoch 75, Train Loss: 0.5258, Val Loss: 0.5484, F1 Micro: 0.7469, F1 Macro: 0.7465, Accuracy: 0.7469\n","Epoch 76, Train Loss: 0.5170, Val Loss: 0.5246, F1 Micro: 0.6750, F1 Macro: 0.6693, Accuracy: 0.6750\n","Epoch 77, Train Loss: 0.5322, Val Loss: 0.5369, F1 Micro: 0.7781, F1 Macro: 0.7748, Accuracy: 0.7781\n","Epoch 78, Train Loss: 0.5273, Val Loss: 0.5931, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 79, Train Loss: 0.5246, Val Loss: 0.6077, F1 Micro: 0.6750, F1 Macro: 0.6566, Accuracy: 0.6750\n","Epoch 80, Train Loss: 0.5314, Val Loss: 0.5771, F1 Micro: 0.6750, F1 Macro: 0.6587, Accuracy: 0.6750\n","Epoch 81, Train Loss: 0.5264, Val Loss: 0.5175, F1 Micro: 0.6813, F1 Macro: 0.6680, Accuracy: 0.6813\n","Epoch 82, Train Loss: 0.5101, Val Loss: 0.5247, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 83, Train Loss: 0.5209, Val Loss: 0.5628, F1 Micro: 0.6687, F1 Macro: 0.6455, Accuracy: 0.6687\n","Epoch 84, Train Loss: 0.5235, Val Loss: 0.6108, F1 Micro: 0.6750, F1 Macro: 0.6566, Accuracy: 0.6750\n","Epoch 85, Train Loss: 0.5428, Val Loss: 0.5578, F1 Micro: 0.7219, F1 Macro: 0.7091, Accuracy: 0.7219\n","Epoch 86, Train Loss: 0.5213, Val Loss: 0.6875, F1 Micro: 0.6625, F1 Macro: 0.6349, Accuracy: 0.6625\n","Epoch 87, Train Loss: 0.5233, Val Loss: 0.5735, F1 Micro: 0.6813, F1 Macro: 0.6643, Accuracy: 0.6813\n","Epoch 88, Train Loss: 0.5225, Val Loss: 0.6318, F1 Micro: 0.6656, F1 Macro: 0.6389, Accuracy: 0.6656\n","Epoch 89, Train Loss: 0.5028, Val Loss: 0.5040, F1 Micro: 0.7906, F1 Macro: 0.7904, Accuracy: 0.7906\n","Epoch 90, Train Loss: 0.5187, Val Loss: 0.6992, F1 Micro: 0.6281, F1 Macro: 0.5751, Accuracy: 0.6281\n","Epoch 91, Train Loss: 0.5547, Val Loss: 0.5862, F1 Micro: 0.6656, F1 Macro: 0.6362, Accuracy: 0.6656\n","Epoch 92, Train Loss: 0.5328, Val Loss: 0.8150, F1 Micro: 0.6500, F1 Macro: 0.6087, Accuracy: 0.6500\n","Epoch 93, Train Loss: 0.5358, Val Loss: 0.7018, F1 Micro: 0.6656, F1 Macro: 0.6348, Accuracy: 0.6656\n","Epoch 94, Train Loss: 0.5485, Val Loss: 0.5028, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 95, Train Loss: 0.5187, Val Loss: 0.8292, F1 Micro: 0.6406, F1 Macro: 0.5915, Accuracy: 0.6406\n","Epoch 96, Train Loss: 0.5272, Val Loss: 0.5087, F1 Micro: 0.7156, F1 Macro: 0.7099, Accuracy: 0.7156\n","Epoch 97, Train Loss: 0.5315, Val Loss: 0.5114, F1 Micro: 0.7250, F1 Macro: 0.7197, Accuracy: 0.7250\n","Epoch 98, Train Loss: 0.5211, Val Loss: 0.7426, F1 Micro: 0.6656, F1 Macro: 0.6348, Accuracy: 0.6656\n","Epoch 99, Train Loss: 0.5391, Val Loss: 0.5890, F1 Micro: 0.7188, F1 Macro: 0.7010, Accuracy: 0.7188\n","Epoch 100, Train Loss: 0.5870, Val Loss: 0.5065, F1 Micro: 0.6906, F1 Macro: 0.6797, Accuracy: 0.6906\n","Epoch 101, Train Loss: 0.5513, Val Loss: 0.5119, F1 Micro: 0.6937, F1 Macro: 0.6841, Accuracy: 0.6937\n","Epoch 102, Train Loss: 0.5278, Val Loss: 0.5607, F1 Micro: 0.6594, F1 Macro: 0.6348, Accuracy: 0.6594\n","Epoch 103, Train Loss: 0.5316, Val Loss: 0.6851, F1 Micro: 0.6625, F1 Macro: 0.6510, Accuracy: 0.6625\n","Epoch 104, Train Loss: 0.5389, Val Loss: 0.5487, F1 Micro: 0.6844, F1 Macro: 0.6699, Accuracy: 0.6844\n","Epoch 105, Train Loss: 0.5153, Val Loss: 0.5842, F1 Micro: 0.6656, F1 Macro: 0.6402, Accuracy: 0.6656\n","Epoch 106, Train Loss: 0.5361, Val Loss: 0.6241, F1 Micro: 0.6625, F1 Macro: 0.6362, Accuracy: 0.6625\n","Epoch 107, Train Loss: 0.5183, Val Loss: 0.5095, F1 Micro: 0.6844, F1 Macro: 0.6761, Accuracy: 0.6844\n","Epoch 108, Train Loss: 0.5124, Val Loss: 0.5096, F1 Micro: 0.7875, F1 Macro: 0.7865, Accuracy: 0.7875\n","Epoch 109, Train Loss: 0.5220, Val Loss: 0.5286, F1 Micro: 0.6719, F1 Macro: 0.6669, Accuracy: 0.6719\n","Epoch 110, Train Loss: 0.5397, Val Loss: 0.5558, F1 Micro: 0.6781, F1 Macro: 0.6615, Accuracy: 0.6781\n","Epoch 111, Train Loss: 0.5589, Val Loss: 0.4989, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 112, Train Loss: 0.5336, Val Loss: 0.6011, F1 Micro: 0.6656, F1 Macro: 0.6348, Accuracy: 0.6656\n","Epoch 113, Train Loss: 0.5242, Val Loss: 0.5235, F1 Micro: 0.6687, F1 Macro: 0.6645, Accuracy: 0.6687\n","Epoch 114, Train Loss: 0.5161, Val Loss: 0.7615, F1 Micro: 0.6531, F1 Macro: 0.6147, Accuracy: 0.6531\n","Epoch 115, Train Loss: 0.5046, Val Loss: 0.5393, F1 Micro: 0.7531, F1 Macro: 0.7508, Accuracy: 0.7531\n","Epoch 116, Train Loss: 0.5236, Val Loss: 0.5229, F1 Micro: 0.7031, F1 Macro: 0.6982, Accuracy: 0.7031\n","Epoch 117, Train Loss: 0.5363, Val Loss: 0.6859, F1 Micro: 0.6469, F1 Macro: 0.6005, Accuracy: 0.6469\n","Epoch 118, Train Loss: 0.5350, Val Loss: 0.4988, F1 Micro: 0.7812, F1 Macro: 0.7812, Accuracy: 0.7812\n","Epoch 119, Train Loss: 0.5328, Val Loss: 0.6650, F1 Micro: 0.6687, F1 Macro: 0.6455, Accuracy: 0.6687\n","Epoch 120, Train Loss: 0.5966, Val Loss: 0.6705, F1 Micro: 0.5844, F1 Macro: 0.5007, Accuracy: 0.5844\n","Epoch 121, Train Loss: 0.5426, Val Loss: 0.7873, F1 Micro: 0.6312, F1 Macro: 0.5776, Accuracy: 0.6312\n","Epoch 122, Train Loss: 0.5159, Val Loss: 0.5725, F1 Micro: 0.6406, F1 Macro: 0.6059, Accuracy: 0.6406\n","Epoch 123, Train Loss: 0.5181, Val Loss: 0.5062, F1 Micro: 0.7000, F1 Macro: 0.6925, Accuracy: 0.7000\n","Epoch 124, Train Loss: 0.5197, Val Loss: 0.5020, F1 Micro: 0.7094, F1 Macro: 0.7059, Accuracy: 0.7094\n","Epoch 125, Train Loss: 0.5182, Val Loss: 0.5089, F1 Micro: 0.6906, F1 Macro: 0.6764, Accuracy: 0.6906\n","Epoch 126, Train Loss: 0.5112, Val Loss: 0.5177, F1 Micro: 0.8344, F1 Macro: 0.8321, Accuracy: 0.8344\n","Epoch 127, Train Loss: 0.5037, Val Loss: 0.5630, F1 Micro: 0.6750, F1 Macro: 0.6522, Accuracy: 0.6750\n","Epoch 128, Train Loss: 0.5082, Val Loss: 0.6385, F1 Micro: 0.6687, F1 Macro: 0.6403, Accuracy: 0.6687\n","Epoch 129, Train Loss: 0.5113, Val Loss: 0.5138, F1 Micro: 0.7844, F1 Macro: 0.7843, Accuracy: 0.7844\n","Epoch 130, Train Loss: 0.5239, Val Loss: 0.5473, F1 Micro: 0.6656, F1 Macro: 0.6389, Accuracy: 0.6656\n","Epoch 131, Train Loss: 0.5960, Val Loss: 0.5907, F1 Micro: 0.6687, F1 Macro: 0.6442, Accuracy: 0.6687\n","Epoch 132, Train Loss: 0.5305, Val Loss: 0.6321, F1 Micro: 0.6562, F1 Macro: 0.6281, Accuracy: 0.6562\n","Epoch 133, Train Loss: 0.5095, Val Loss: 0.4876, F1 Micro: 0.7625, F1 Macro: 0.7620, Accuracy: 0.7625\n","Epoch 134, Train Loss: 0.5022, Val Loss: 0.5629, F1 Micro: 0.7281, F1 Macro: 0.7172, Accuracy: 0.7281\n","Epoch 135, Train Loss: 0.5246, Val Loss: 0.4990, F1 Micro: 0.7094, F1 Macro: 0.7079, Accuracy: 0.7094\n","Epoch 136, Train Loss: 0.5141, Val Loss: 0.5882, F1 Micro: 0.6750, F1 Macro: 0.6545, Accuracy: 0.6750\n","Epoch 137, Train Loss: 0.5144, Val Loss: 0.5556, F1 Micro: 0.6594, F1 Macro: 0.6335, Accuracy: 0.6594\n","Epoch 138, Train Loss: 0.4950, Val Loss: 0.5514, F1 Micro: 0.7344, F1 Macro: 0.7152, Accuracy: 0.7344\n","Epoch 139, Train Loss: 0.5065, Val Loss: 0.5125, F1 Micro: 0.7000, F1 Macro: 0.6957, Accuracy: 0.7000\n","Epoch 140, Train Loss: 0.5185, Val Loss: 0.5140, F1 Micro: 0.7937, F1 Macro: 0.7872, Accuracy: 0.7937\n","Epoch 141, Train Loss: 0.5508, Val Loss: 0.6242, F1 Micro: 0.6687, F1 Macro: 0.6430, Accuracy: 0.6687\n","Epoch 142, Train Loss: 0.5193, Val Loss: 0.5055, F1 Micro: 0.6844, F1 Macro: 0.6708, Accuracy: 0.6844\n","Epoch 143, Train Loss: 0.5210, Val Loss: 0.5995, F1 Micro: 0.6344, F1 Macro: 0.6224, Accuracy: 0.6344\n","Epoch 144, Train Loss: 0.5227, Val Loss: 0.5088, F1 Micro: 0.6719, F1 Macro: 0.6549, Accuracy: 0.6719\n","Epoch 145, Train Loss: 0.5077, Val Loss: 0.7881, F1 Micro: 0.6531, F1 Macro: 0.6113, Accuracy: 0.6531\n","Epoch 146, Train Loss: 0.5221, Val Loss: 0.5460, F1 Micro: 0.6719, F1 Macro: 0.6482, Accuracy: 0.6719\n","Epoch 147, Train Loss: 0.5146, Val Loss: 0.6898, F1 Micro: 0.6750, F1 Macro: 0.6414, Accuracy: 0.6750\n","Epoch 148, Train Loss: 0.5117, Val Loss: 0.4934, F1 Micro: 0.7406, F1 Macro: 0.7363, Accuracy: 0.7406\n","Epoch 149, Train Loss: 0.5217, Val Loss: 0.6673, F1 Micro: 0.6562, F1 Macro: 0.6174, Accuracy: 0.6562\n","Epoch 150, Train Loss: 0.5935, Val Loss: 0.4794, F1 Micro: 0.7750, F1 Macro: 0.7746, Accuracy: 0.7750\n","Epoch 151, Train Loss: 0.5364, Val Loss: 0.5308, F1 Micro: 0.6844, F1 Macro: 0.6748, Accuracy: 0.6844\n","Epoch 152, Train Loss: 0.5265, Val Loss: 0.5227, F1 Micro: 0.6656, F1 Macro: 0.6427, Accuracy: 0.6656\n","Epoch 153, Train Loss: 0.5274, Val Loss: 0.4924, F1 Micro: 0.6906, F1 Macro: 0.6773, Accuracy: 0.6906\n","Epoch 154, Train Loss: 0.5076, Val Loss: 0.5507, F1 Micro: 0.6750, F1 Macro: 0.6577, Accuracy: 0.6750\n","Epoch 155, Train Loss: 0.4952, Val Loss: 0.5582, F1 Micro: 0.6687, F1 Macro: 0.6455, Accuracy: 0.6687\n","Epoch 156, Train Loss: 0.5047, Val Loss: 0.5198, F1 Micro: 0.6625, F1 Macro: 0.6423, Accuracy: 0.6625\n","Epoch 157, Train Loss: 0.5095, Val Loss: 0.5409, F1 Micro: 0.6719, F1 Macro: 0.6482, Accuracy: 0.6719\n","Epoch 158, Train Loss: 0.4953, Val Loss: 0.6278, F1 Micro: 0.6625, F1 Macro: 0.6291, Accuracy: 0.6625\n","Epoch 159, Train Loss: 0.5401, Val Loss: 0.5068, F1 Micro: 0.6781, F1 Macro: 0.6651, Accuracy: 0.6781\n","Epoch 160, Train Loss: 0.5044, Val Loss: 0.6005, F1 Micro: 0.6625, F1 Macro: 0.6455, Accuracy: 0.6625\n","Epoch 161, Train Loss: 0.5261, Val Loss: 0.5294, F1 Micro: 0.7531, F1 Macro: 0.7396, Accuracy: 0.7531\n","Epoch 162, Train Loss: 0.4990, Val Loss: 0.5697, F1 Micro: 0.6937, F1 Macro: 0.6662, Accuracy: 0.6937\n","Epoch 163, Train Loss: 0.5001, Val Loss: 0.5623, F1 Micro: 0.6344, F1 Macro: 0.5990, Accuracy: 0.6344\n","Epoch 164, Train Loss: 0.5128, Val Loss: 0.4916, F1 Micro: 0.6813, F1 Macro: 0.6671, Accuracy: 0.6813\n","Epoch 165, Train Loss: 0.4843, Val Loss: 0.4964, F1 Micro: 0.6750, F1 Macro: 0.6606, Accuracy: 0.6750\n","Epoch 166, Train Loss: 0.5049, Val Loss: 0.4647, F1 Micro: 0.8062, F1 Macro: 0.8063, Accuracy: 0.8063\n","Epoch 167, Train Loss: 0.4853, Val Loss: 0.5098, F1 Micro: 0.7000, F1 Macro: 0.6931, Accuracy: 0.7000\n","Epoch 168, Train Loss: 0.4933, Val Loss: 0.4960, F1 Micro: 0.6937, F1 Macro: 0.6848, Accuracy: 0.6937\n","Epoch 169, Train Loss: 0.5204, Val Loss: 0.5539, F1 Micro: 0.7312, F1 Macro: 0.7114, Accuracy: 0.7312\n","Epoch 170, Train Loss: 0.4940, Val Loss: 0.4717, F1 Micro: 0.7312, F1 Macro: 0.7285, Accuracy: 0.7312\n","Epoch 171, Train Loss: 0.4837, Val Loss: 0.4721, F1 Micro: 0.8187, F1 Macro: 0.8187, Accuracy: 0.8187\n","Epoch 172, Train Loss: 0.4905, Val Loss: 0.5306, F1 Micro: 0.7312, F1 Macro: 0.7152, Accuracy: 0.7312\n","Epoch 173, Train Loss: 0.5267, Val Loss: 0.4676, F1 Micro: 0.7781, F1 Macro: 0.7781, Accuracy: 0.7781\n","Epoch 174, Train Loss: 0.5123, Val Loss: 0.5199, F1 Micro: 0.7844, F1 Macro: 0.7745, Accuracy: 0.7844\n","Epoch 175, Train Loss: 0.5117, Val Loss: 0.5142, F1 Micro: 0.6937, F1 Macro: 0.6784, Accuracy: 0.6937\n","Epoch 176, Train Loss: 0.4737, Val Loss: 0.4580, F1 Micro: 0.7812, F1 Macro: 0.7807, Accuracy: 0.7812\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8709, Val Loss: 0.5388, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 2, Train Loss: 0.6145, Val Loss: 0.5365, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 3, Train Loss: 0.5915, Val Loss: 0.5374, F1 Micro: 0.7406, F1 Macro: 0.7390, Accuracy: 0.7406\n","Epoch 4, Train Loss: 0.5942, Val Loss: 0.5356, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 5, Train Loss: 0.5914, Val Loss: 0.5681, F1 Micro: 0.6906, F1 Macro: 0.6864, Accuracy: 0.6906\n","Epoch 6, Train Loss: 0.5884, Val Loss: 0.5360, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 7, Train Loss: 0.5953, Val Loss: 0.5581, F1 Micro: 0.6969, F1 Macro: 0.6956, Accuracy: 0.6969\n","Epoch 8, Train Loss: 0.6058, Val Loss: 0.5511, F1 Micro: 0.7250, F1 Macro: 0.7206, Accuracy: 0.7250\n","Epoch 9, Train Loss: 0.5936, Val Loss: 0.5566, F1 Micro: 0.6906, F1 Macro: 0.6895, Accuracy: 0.6906\n","Epoch 10, Train Loss: 0.5955, Val Loss: 0.5315, F1 Micro: 0.7281, F1 Macro: 0.7259, Accuracy: 0.7281\n","Epoch 11, Train Loss: 0.5868, Val Loss: 0.5334, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 12, Train Loss: 0.5850, Val Loss: 0.5275, F1 Micro: 0.7281, F1 Macro: 0.7269, Accuracy: 0.7281\n","Epoch 13, Train Loss: 0.5924, Val Loss: 0.5402, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 14, Train Loss: 0.5889, Val Loss: 0.5316, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 15, Train Loss: 0.5841, Val Loss: 0.5332, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 16, Train Loss: 0.6576, Val Loss: 0.5742, F1 Micro: 0.7219, F1 Macro: 0.7189, Accuracy: 0.7219\n","Epoch 17, Train Loss: 0.6483, Val Loss: 0.5422, F1 Micro: 0.7063, F1 Macro: 0.7057, Accuracy: 0.7063\n","Epoch 18, Train Loss: 0.5941, Val Loss: 0.5513, F1 Micro: 0.7000, F1 Macro: 0.6858, Accuracy: 0.7000\n","Epoch 19, Train Loss: 0.5914, Val Loss: 0.5428, F1 Micro: 0.7281, F1 Macro: 0.7164, Accuracy: 0.7281\n","Epoch 20, Train Loss: 0.5849, Val Loss: 0.5428, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 21, Train Loss: 0.5788, Val Loss: 0.5255, F1 Micro: 0.7250, F1 Macro: 0.7229, Accuracy: 0.7250\n","Epoch 22, Train Loss: 0.5785, Val Loss: 0.5053, F1 Micro: 0.7375, F1 Macro: 0.7363, Accuracy: 0.7375\n","Epoch 23, Train Loss: 0.5907, Val Loss: 0.5318, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 24, Train Loss: 0.5741, Val Loss: 0.5264, F1 Micro: 0.7688, F1 Macro: 0.7603, Accuracy: 0.7688\n","Epoch 25, Train Loss: 0.5600, Val Loss: 0.5098, F1 Micro: 0.7500, F1 Macro: 0.7492, Accuracy: 0.7500\n","Epoch 26, Train Loss: 0.5647, Val Loss: 0.5169, F1 Micro: 0.7562, F1 Macro: 0.7541, Accuracy: 0.7562\n","Epoch 27, Train Loss: 0.5549, Val Loss: 0.6146, F1 Micro: 0.6969, F1 Macro: 0.6890, Accuracy: 0.6969\n","Epoch 28, Train Loss: 0.5581, Val Loss: 0.4857, F1 Micro: 0.7469, F1 Macro: 0.7448, Accuracy: 0.7469\n","Epoch 29, Train Loss: 0.6230, Val Loss: 0.5035, F1 Micro: 0.7375, F1 Macro: 0.7348, Accuracy: 0.7375\n","Epoch 30, Train Loss: 0.6184, Val Loss: 0.5233, F1 Micro: 0.7375, F1 Macro: 0.7375, Accuracy: 0.7375\n","Epoch 31, Train Loss: 0.5750, Val Loss: 0.5018, F1 Micro: 0.7281, F1 Macro: 0.7279, Accuracy: 0.7281\n","Epoch 32, Train Loss: 0.5423, Val Loss: 0.4897, F1 Micro: 0.7438, F1 Macro: 0.7393, Accuracy: 0.7438\n","Epoch 33, Train Loss: 0.5416, Val Loss: 0.4739, F1 Micro: 0.7688, F1 Macro: 0.7647, Accuracy: 0.7688\n","Epoch 34, Train Loss: 0.5655, Val Loss: 0.5103, F1 Micro: 0.7156, F1 Macro: 0.7144, Accuracy: 0.7156\n","Epoch 35, Train Loss: 0.5694, Val Loss: 0.4960, F1 Micro: 0.7656, F1 Macro: 0.7528, Accuracy: 0.7656\n","Epoch 36, Train Loss: 0.5759, Val Loss: 0.5775, F1 Micro: 0.7281, F1 Macro: 0.7236, Accuracy: 0.7281\n","Epoch 37, Train Loss: 0.5496, Val Loss: 0.4952, F1 Micro: 0.7406, F1 Macro: 0.7363, Accuracy: 0.7406\n","Epoch 38, Train Loss: 0.5921, Val Loss: 1.0619, F1 Micro: 0.4531, F1 Macro: 0.3167, Accuracy: 0.4531\n","Epoch 39, Train Loss: 0.6383, Val Loss: 0.5599, F1 Micro: 0.7969, F1 Macro: 0.7920, Accuracy: 0.7969\n","Epoch 40, Train Loss: 0.6068, Val Loss: 0.4838, F1 Micro: 0.7688, F1 Macro: 0.7647, Accuracy: 0.7688\n","Epoch 41, Train Loss: 0.5343, Val Loss: 0.6674, F1 Micro: 0.6937, F1 Macro: 0.6826, Accuracy: 0.6937\n","Epoch 42, Train Loss: 0.5716, Val Loss: 0.4891, F1 Micro: 0.7344, F1 Macro: 0.7250, Accuracy: 0.7344\n","Epoch 43, Train Loss: 0.5683, Val Loss: 0.4992, F1 Micro: 0.7875, F1 Macro: 0.7822, Accuracy: 0.7875\n","Epoch 44, Train Loss: 0.5640, Val Loss: 0.5057, F1 Micro: 0.7625, F1 Macro: 0.7449, Accuracy: 0.7625\n","Epoch 45, Train Loss: 0.5626, Val Loss: 0.5765, F1 Micro: 0.7281, F1 Macro: 0.7064, Accuracy: 0.7281\n","Epoch 46, Train Loss: 0.6017, Val Loss: 0.5350, F1 Micro: 0.7500, F1 Macro: 0.7285, Accuracy: 0.7500\n","Epoch 47, Train Loss: 0.5950, Val Loss: 0.4689, F1 Micro: 0.7688, F1 Macro: 0.7597, Accuracy: 0.7688\n","Epoch 48, Train Loss: 0.5676, Val Loss: 0.5606, F1 Micro: 0.7469, F1 Macro: 0.7445, Accuracy: 0.7469\n","Epoch 49, Train Loss: 0.5396, Val Loss: 0.4777, F1 Micro: 0.7531, F1 Macro: 0.7524, Accuracy: 0.7531\n","Epoch 50, Train Loss: 0.5328, Val Loss: 0.4877, F1 Micro: 0.7500, F1 Macro: 0.7351, Accuracy: 0.7500\n","Epoch 51, Train Loss: 0.5791, Val Loss: 0.4956, F1 Micro: 0.7438, F1 Macro: 0.7415, Accuracy: 0.7438\n","Epoch 52, Train Loss: 0.5500, Val Loss: 0.4633, F1 Micro: 0.7656, F1 Macro: 0.7617, Accuracy: 0.7656\n","Epoch 53, Train Loss: 0.5563, Val Loss: 0.4655, F1 Micro: 0.7531, F1 Macro: 0.7501, Accuracy: 0.7531\n","Epoch 54, Train Loss: 0.5424, Val Loss: 0.5062, F1 Micro: 0.7188, F1 Macro: 0.7176, Accuracy: 0.7188\n","Epoch 55, Train Loss: 0.5534, Val Loss: 0.4865, F1 Micro: 0.7688, F1 Macro: 0.7549, Accuracy: 0.7688\n","Epoch 56, Train Loss: 0.5575, Val Loss: 0.5308, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 57, Train Loss: 0.5530, Val Loss: 0.5302, F1 Micro: 0.7500, F1 Macro: 0.7488, Accuracy: 0.7500\n","Epoch 58, Train Loss: 0.5266, Val Loss: 0.4834, F1 Micro: 0.7844, F1 Macro: 0.7834, Accuracy: 0.7844\n","Epoch 59, Train Loss: 0.5340, Val Loss: 0.5084, F1 Micro: 0.7594, F1 Macro: 0.7392, Accuracy: 0.7594\n","Epoch 60, Train Loss: 0.5421, Val Loss: 0.5430, F1 Micro: 0.7250, F1 Macro: 0.6882, Accuracy: 0.7250\n","Epoch 61, Train Loss: 0.5509, Val Loss: 0.5223, F1 Micro: 0.7969, F1 Macro: 0.7968, Accuracy: 0.7969\n","Epoch 62, Train Loss: 0.5270, Val Loss: 0.4609, F1 Micro: 0.7937, F1 Macro: 0.7877, Accuracy: 0.7937\n","Epoch 63, Train Loss: 0.5275, Val Loss: 0.4694, F1 Micro: 0.8031, F1 Macro: 0.7988, Accuracy: 0.8031\n","Epoch 64, Train Loss: 0.5353, Val Loss: 0.4692, F1 Micro: 0.7469, F1 Macro: 0.7338, Accuracy: 0.7469\n","Epoch 65, Train Loss: 0.5334, Val Loss: 0.4739, F1 Micro: 0.7875, F1 Macro: 0.7781, Accuracy: 0.7875\n","Epoch 66, Train Loss: 0.5567, Val Loss: 0.4617, F1 Micro: 0.7906, F1 Macro: 0.7791, Accuracy: 0.7906\n","Epoch 67, Train Loss: 0.5328, Val Loss: 0.4682, F1 Micro: 0.7438, F1 Macro: 0.7293, Accuracy: 0.7438\n","Epoch 68, Train Loss: 0.5219, Val Loss: 0.4831, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 69, Train Loss: 0.5201, Val Loss: 0.5148, F1 Micro: 0.8156, F1 Macro: 0.8156, Accuracy: 0.8156\n","Epoch 70, Train Loss: 0.5265, Val Loss: 0.5236, F1 Micro: 0.7844, F1 Macro: 0.7833, Accuracy: 0.7844\n","Epoch 71, Train Loss: 0.5981, Val Loss: 0.5485, F1 Micro: 0.7250, F1 Macro: 0.6882, Accuracy: 0.7250\n","Epoch 72, Train Loss: 0.5578, Val Loss: 0.5306, F1 Micro: 0.7562, F1 Macro: 0.7321, Accuracy: 0.7562\n","Epoch 73, Train Loss: 0.5222, Val Loss: 0.4644, F1 Micro: 0.7469, F1 Macro: 0.7295, Accuracy: 0.7469\n","Epoch 74, Train Loss: 0.5435, Val Loss: 0.4747, F1 Micro: 0.7844, F1 Macro: 0.7783, Accuracy: 0.7844\n","Epoch 75, Train Loss: 0.5353, Val Loss: 0.4583, F1 Micro: 0.7688, F1 Macro: 0.7498, Accuracy: 0.7688\n","Epoch 76, Train Loss: 0.5626, Val Loss: 0.5065, F1 Micro: 0.7750, F1 Macro: 0.7747, Accuracy: 0.7750\n","Epoch 77, Train Loss: 0.5307, Val Loss: 0.5007, F1 Micro: 0.7406, F1 Macro: 0.7321, Accuracy: 0.7406\n","Epoch 78, Train Loss: 0.5367, Val Loss: 0.4903, F1 Micro: 0.8156, F1 Macro: 0.8156, Accuracy: 0.8156\n","Epoch 79, Train Loss: 0.5313, Val Loss: 0.4448, F1 Micro: 0.7906, F1 Macro: 0.7778, Accuracy: 0.7906\n","Epoch 80, Train Loss: 0.5392, Val Loss: 0.6026, F1 Micro: 0.7438, F1 Macro: 0.7388, Accuracy: 0.7438\n","Epoch 81, Train Loss: 0.5413, Val Loss: 0.4853, F1 Micro: 0.7812, F1 Macro: 0.7812, Accuracy: 0.7812\n","Epoch 82, Train Loss: 0.5278, Val Loss: 0.4329, F1 Micro: 0.7969, F1 Macro: 0.7950, Accuracy: 0.7969\n","Epoch 83, Train Loss: 0.5165, Val Loss: 0.4987, F1 Micro: 0.8344, F1 Macro: 0.8344, Accuracy: 0.8344\n","Epoch 84, Train Loss: 0.5388, Val Loss: 0.4429, F1 Micro: 0.7594, F1 Macro: 0.7531, Accuracy: 0.7594\n","Epoch 85, Train Loss: 0.5053, Val Loss: 0.4322, F1 Micro: 0.8344, F1 Macro: 0.8330, Accuracy: 0.8344\n","Epoch 86, Train Loss: 0.5105, Val Loss: 0.4605, F1 Micro: 0.7719, F1 Macro: 0.7571, Accuracy: 0.7719\n","Epoch 87, Train Loss: 0.5093, Val Loss: 0.5558, F1 Micro: 0.7125, F1 Macro: 0.7053, Accuracy: 0.7125\n","Epoch 88, Train Loss: 0.5383, Val Loss: 0.4769, F1 Micro: 0.7500, F1 Macro: 0.7275, Accuracy: 0.7500\n","Epoch 89, Train Loss: 0.5180, Val Loss: 0.4268, F1 Micro: 0.8031, F1 Macro: 0.8007, Accuracy: 0.8031\n","Epoch 90, Train Loss: 0.5255, Val Loss: 0.4302, F1 Micro: 0.7750, F1 Macro: 0.7608, Accuracy: 0.7750\n","Epoch 91, Train Loss: 0.5287, Val Loss: 0.5196, F1 Micro: 0.7937, F1 Macro: 0.7931, Accuracy: 0.7937\n","Epoch 92, Train Loss: 0.5019, Val Loss: 0.4668, F1 Micro: 0.8344, F1 Macro: 0.8338, Accuracy: 0.8344\n","Epoch 93, Train Loss: 0.5368, Val Loss: 0.5060, F1 Micro: 0.8250, F1 Macro: 0.8248, Accuracy: 0.8250\n","Epoch 94, Train Loss: 0.5255, Val Loss: 0.4305, F1 Micro: 0.8250, F1 Macro: 0.8210, Accuracy: 0.8250\n","Epoch 95, Train Loss: 0.5007, Val Loss: 0.5014, F1 Micro: 0.8000, F1 Macro: 0.7991, Accuracy: 0.8000\n","Epoch 96, Train Loss: 0.5264, Val Loss: 0.4210, F1 Micro: 0.7937, F1 Macro: 0.7917, Accuracy: 0.7937\n","Epoch 97, Train Loss: 0.5113, Val Loss: 0.4679, F1 Micro: 0.8187, F1 Macro: 0.8187, Accuracy: 0.8187\n","Epoch 98, Train Loss: 0.5179, Val Loss: 0.4544, F1 Micro: 0.7750, F1 Macro: 0.7600, Accuracy: 0.7750\n","Epoch 99, Train Loss: 0.4969, Val Loss: 0.4179, F1 Micro: 0.7750, F1 Macro: 0.7662, Accuracy: 0.7750\n","Epoch 100, Train Loss: 0.5437, Val Loss: 0.6526, F1 Micro: 0.6813, F1 Macro: 0.6270, Accuracy: 0.6813\n","Epoch 101, Train Loss: 0.5453, Val Loss: 0.4800, F1 Micro: 0.7969, F1 Macro: 0.7962, Accuracy: 0.7969\n","Epoch 102, Train Loss: 0.5462, Val Loss: 0.5535, F1 Micro: 0.7594, F1 Macro: 0.7545, Accuracy: 0.7594\n","Epoch 103, Train Loss: 0.4984, Val Loss: 0.5692, F1 Micro: 0.7219, F1 Macro: 0.6806, Accuracy: 0.7219\n","Epoch 104, Train Loss: 0.5355, Val Loss: 0.4412, F1 Micro: 0.8250, F1 Macro: 0.8247, Accuracy: 0.8250\n","Epoch 105, Train Loss: 0.5224, Val Loss: 0.4981, F1 Micro: 0.8219, F1 Macro: 0.8217, Accuracy: 0.8219\n","Epoch 106, Train Loss: 0.5105, Val Loss: 0.4323, F1 Micro: 0.7688, F1 Macro: 0.7564, Accuracy: 0.7688\n","Epoch 107, Train Loss: 0.5407, Val Loss: 0.4245, F1 Micro: 0.8094, F1 Macro: 0.8082, Accuracy: 0.8094\n","Epoch 108, Train Loss: 0.4877, Val Loss: 0.4321, F1 Micro: 0.7625, F1 Macro: 0.7458, Accuracy: 0.7625\n","Epoch 109, Train Loss: 0.5064, Val Loss: 0.4211, F1 Micro: 0.7656, F1 Macro: 0.7528, Accuracy: 0.7656\n","Epoch 110, Train Loss: 0.5118, Val Loss: 0.5262, F1 Micro: 0.7562, F1 Macro: 0.7524, Accuracy: 0.7562\n","Epoch 111, Train Loss: 0.5235, Val Loss: 0.3975, F1 Micro: 0.8500, F1 Macro: 0.8476, Accuracy: 0.8500\n","Epoch 112, Train Loss: 0.5040, Val Loss: 0.4689, F1 Micro: 0.8438, F1 Macro: 0.8437, Accuracy: 0.8438\n","Epoch 113, Train Loss: 0.5296, Val Loss: 0.4648, F1 Micro: 0.7375, F1 Macro: 0.7115, Accuracy: 0.7375\n","Epoch 114, Train Loss: 0.5103, Val Loss: 0.4169, F1 Micro: 0.8219, F1 Macro: 0.8172, Accuracy: 0.8219\n","Epoch 115, Train Loss: 0.5188, Val Loss: 0.4027, F1 Micro: 0.8344, F1 Macro: 0.8324, Accuracy: 0.8344\n","Epoch 116, Train Loss: 0.5186, Val Loss: 0.4225, F1 Micro: 0.8156, F1 Macro: 0.8091, Accuracy: 0.8156\n","Epoch 117, Train Loss: 0.4998, Val Loss: 0.4469, F1 Micro: 0.8438, F1 Macro: 0.8434, Accuracy: 0.8438\n","Epoch 118, Train Loss: 0.5217, Val Loss: 0.5138, F1 Micro: 0.8000, F1 Macro: 0.7991, Accuracy: 0.8000\n","Epoch 119, Train Loss: 0.5028, Val Loss: 0.4514, F1 Micro: 0.8250, F1 Macro: 0.8222, Accuracy: 0.8250\n","Epoch 120, Train Loss: 0.4991, Val Loss: 0.5179, F1 Micro: 0.8125, F1 Macro: 0.8119, Accuracy: 0.8125\n","Epoch 121, Train Loss: 0.5086, Val Loss: 0.5378, F1 Micro: 0.6937, F1 Macro: 0.6527, Accuracy: 0.6937\n","Epoch 122, Train Loss: 0.5216, Val Loss: 0.5009, F1 Micro: 0.7156, F1 Macro: 0.6842, Accuracy: 0.7156\n","Epoch 123, Train Loss: 0.4933, Val Loss: 0.4379, F1 Micro: 0.7906, F1 Macro: 0.7884, Accuracy: 0.7906\n","Epoch 124, Train Loss: 0.5079, Val Loss: 0.4411, F1 Micro: 0.8187, F1 Macro: 0.8149, Accuracy: 0.8187\n","Epoch 125, Train Loss: 0.5158, Val Loss: 0.4419, F1 Micro: 0.7438, F1 Macro: 0.7207, Accuracy: 0.7438\n","Epoch 126, Train Loss: 0.4953, Val Loss: 0.5014, F1 Micro: 0.7063, F1 Macro: 0.6700, Accuracy: 0.7063\n","Epoch 127, Train Loss: 0.5195, Val Loss: 0.4501, F1 Micro: 0.8438, F1 Macro: 0.8433, Accuracy: 0.8438\n","Epoch 128, Train Loss: 0.5108, Val Loss: 0.4181, F1 Micro: 0.7750, F1 Macro: 0.7644, Accuracy: 0.7750\n","Epoch 129, Train Loss: 0.5256, Val Loss: 0.5495, F1 Micro: 0.6937, F1 Macro: 0.6898, Accuracy: 0.6937\n","Epoch 130, Train Loss: 0.5287, Val Loss: 0.4461, F1 Micro: 0.7406, F1 Macro: 0.7199, Accuracy: 0.7406\n","Epoch 131, Train Loss: 0.4895, Val Loss: 0.4317, F1 Micro: 0.7719, F1 Macro: 0.7586, Accuracy: 0.7719\n","Epoch 132, Train Loss: 0.4785, Val Loss: 0.4298, F1 Micro: 0.8031, F1 Macro: 0.7941, Accuracy: 0.8031\n","Epoch 133, Train Loss: 0.5210, Val Loss: 0.4687, F1 Micro: 0.8406, F1 Macro: 0.8406, Accuracy: 0.8406\n","Epoch 134, Train Loss: 0.4924, Val Loss: 0.4743, F1 Micro: 0.8094, F1 Macro: 0.8044, Accuracy: 0.8094\n","Epoch 135, Train Loss: 0.5297, Val Loss: 0.4422, F1 Micro: 0.7562, F1 Macro: 0.7391, Accuracy: 0.7562\n","Epoch 136, Train Loss: 0.5237, Val Loss: 0.4430, F1 Micro: 0.8250, F1 Macro: 0.8243, Accuracy: 0.8250\n","Epoch 137, Train Loss: 0.5081, Val Loss: 0.6485, F1 Micro: 0.6344, F1 Macro: 0.6176, Accuracy: 0.6344\n","Epoch 138, Train Loss: 0.5157, Val Loss: 0.5920, F1 Micro: 0.6687, F1 Macro: 0.6531, Accuracy: 0.6687\n","Epoch 139, Train Loss: 0.5168, Val Loss: 0.7606, F1 Micro: 0.5531, F1 Macro: 0.4920, Accuracy: 0.5531\n","Epoch 140, Train Loss: 0.4877, Val Loss: 0.4205, F1 Micro: 0.7969, F1 Macro: 0.7897, Accuracy: 0.7969\n","Epoch 141, Train Loss: 0.4884, Val Loss: 0.6042, F1 Micro: 0.6469, F1 Macro: 0.6410, Accuracy: 0.6469\n","Epoch 142, Train Loss: 0.4893, Val Loss: 0.4243, F1 Micro: 0.7906, F1 Macro: 0.7816, Accuracy: 0.7906\n","Epoch 143, Train Loss: 0.5042, Val Loss: 0.4329, F1 Micro: 0.8187, F1 Macro: 0.8146, Accuracy: 0.8187\n","Epoch 144, Train Loss: 0.4891, Val Loss: 0.4991, F1 Micro: 0.8281, F1 Macro: 0.8280, Accuracy: 0.8281\n","Epoch 145, Train Loss: 0.4677, Val Loss: 0.4660, F1 Micro: 0.7312, F1 Macro: 0.7059, Accuracy: 0.7312\n","Epoch 146, Train Loss: 0.4893, Val Loss: 0.5656, F1 Micro: 0.7281, F1 Macro: 0.7210, Accuracy: 0.7281\n","Epoch 147, Train Loss: 0.4846, Val Loss: 0.4002, F1 Micro: 0.8438, F1 Macro: 0.8417, Accuracy: 0.8438\n","Epoch 148, Train Loss: 0.4795, Val Loss: 0.5593, F1 Micro: 0.7094, F1 Macro: 0.7063, Accuracy: 0.7094\n","Epoch 149, Train Loss: 0.4868, Val Loss: 0.4869, F1 Micro: 0.8406, F1 Macro: 0.8405, Accuracy: 0.8406\n","Epoch 150, Train Loss: 0.4948, Val Loss: 0.7755, F1 Micro: 0.6000, F1 Macro: 0.5656, Accuracy: 0.6000\n","Epoch 151, Train Loss: 0.4924, Val Loss: 0.4781, F1 Micro: 0.8438, F1 Macro: 0.8437, Accuracy: 0.8438\n","Epoch 152, Train Loss: 0.4974, Val Loss: 0.4136, F1 Micro: 0.8406, F1 Macro: 0.8385, Accuracy: 0.8406\n","Epoch 153, Train Loss: 0.5060, Val Loss: 0.3922, F1 Micro: 0.8438, F1 Macro: 0.8413, Accuracy: 0.8438\n","Epoch 154, Train Loss: 0.4967, Val Loss: 0.5684, F1 Micro: 0.7375, F1 Macro: 0.7078, Accuracy: 0.7375\n","Epoch 155, Train Loss: 0.4828, Val Loss: 0.4693, F1 Micro: 0.8313, F1 Macro: 0.8312, Accuracy: 0.8313\n","Epoch 156, Train Loss: 0.4945, Val Loss: 0.4081, F1 Micro: 0.7875, F1 Macro: 0.7803, Accuracy: 0.7875\n","Epoch 157, Train Loss: 0.4966, Val Loss: 0.3881, F1 Micro: 0.8375, F1 Macro: 0.8338, Accuracy: 0.8375\n","Epoch 158, Train Loss: 0.4891, Val Loss: 0.4289, F1 Micro: 0.7906, F1 Macro: 0.7798, Accuracy: 0.7906\n","Epoch 159, Train Loss: 0.4870, Val Loss: 0.4506, F1 Micro: 0.8500, F1 Macro: 0.8495, Accuracy: 0.8500\n","Epoch 160, Train Loss: 0.4920, Val Loss: 0.4042, F1 Micro: 0.8281, F1 Macro: 0.8253, Accuracy: 0.8281\n","Epoch 161, Train Loss: 0.5134, Val Loss: 0.4088, F1 Micro: 0.8250, F1 Macro: 0.8234, Accuracy: 0.8250\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7910, Val Loss: 0.5414, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 2, Train Loss: 0.5907, Val Loss: 0.5784, F1 Micro: 0.6656, F1 Macro: 0.6629, Accuracy: 0.6656\n","Epoch 3, Train Loss: 0.6335, Val Loss: 0.5763, F1 Micro: 0.7000, F1 Macro: 0.6858, Accuracy: 0.7000\n","Epoch 4, Train Loss: 0.5936, Val Loss: 0.5432, F1 Micro: 0.7031, F1 Macro: 0.6919, Accuracy: 0.7031\n","Epoch 5, Train Loss: 0.5905, Val Loss: 0.6317, F1 Micro: 0.6375, F1 Macro: 0.5658, Accuracy: 0.6375\n","Epoch 6, Train Loss: 0.6020, Val Loss: 0.5775, F1 Micro: 0.7250, F1 Macro: 0.7215, Accuracy: 0.7250\n","Epoch 7, Train Loss: 0.5966, Val Loss: 0.5371, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 8, Train Loss: 0.6036, Val Loss: 0.5374, F1 Micro: 0.7219, F1 Macro: 0.7192, Accuracy: 0.7219\n","Epoch 9, Train Loss: 0.6148, Val Loss: 0.5460, F1 Micro: 0.7281, F1 Macro: 0.7267, Accuracy: 0.7281\n","Epoch 10, Train Loss: 0.5858, Val Loss: 0.5760, F1 Micro: 0.6781, F1 Macro: 0.6761, Accuracy: 0.6781\n","Epoch 11, Train Loss: 0.5906, Val Loss: 0.6130, F1 Micro: 0.6937, F1 Macro: 0.6925, Accuracy: 0.6937\n","Epoch 12, Train Loss: 0.6040, Val Loss: 0.5979, F1 Micro: 0.6813, F1 Macro: 0.6436, Accuracy: 0.6813\n","Epoch 13, Train Loss: 0.6074, Val Loss: 0.5892, F1 Micro: 0.6719, F1 Macro: 0.6679, Accuracy: 0.6719\n","Epoch 14, Train Loss: 0.6053, Val Loss: 0.5576, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 15, Train Loss: 0.6027, Val Loss: 0.5554, F1 Micro: 0.6937, F1 Macro: 0.6764, Accuracy: 0.6937\n","Epoch 16, Train Loss: 0.5906, Val Loss: 0.5491, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 17, Train Loss: 0.5753, Val Loss: 0.5737, F1 Micro: 0.6719, F1 Macro: 0.6695, Accuracy: 0.6719\n","Epoch 18, Train Loss: 0.5957, Val Loss: 0.6153, F1 Micro: 0.6438, F1 Macro: 0.5808, Accuracy: 0.6438\n","Epoch 19, Train Loss: 0.6362, Val Loss: 0.5393, F1 Micro: 0.7219, F1 Macro: 0.7177, Accuracy: 0.7219\n","Epoch 20, Train Loss: 0.6079, Val Loss: 0.5910, F1 Micro: 0.6906, F1 Macro: 0.6877, Accuracy: 0.6906\n","Epoch 21, Train Loss: 0.6075, Val Loss: 0.5441, F1 Micro: 0.7219, F1 Macro: 0.7213, Accuracy: 0.7219\n","Epoch 22, Train Loss: 0.5940, Val Loss: 0.5380, F1 Micro: 0.7188, F1 Macro: 0.7117, Accuracy: 0.7188\n","Epoch 23, Train Loss: 0.5848, Val Loss: 0.5555, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 24, Train Loss: 0.5822, Val Loss: 0.5473, F1 Micro: 0.7125, F1 Macro: 0.7123, Accuracy: 0.7125\n","Epoch 25, Train Loss: 0.5931, Val Loss: 0.6091, F1 Micro: 0.6500, F1 Macro: 0.6381, Accuracy: 0.6500\n","Epoch 26, Train Loss: 0.6135, Val Loss: 0.5799, F1 Micro: 0.6813, F1 Macro: 0.6497, Accuracy: 0.6813\n","Epoch 27, Train Loss: 0.5981, Val Loss: 0.5569, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 28, Train Loss: 0.6012, Val Loss: 0.6189, F1 Micro: 0.7094, F1 Macro: 0.7063, Accuracy: 0.7094\n","Epoch 29, Train Loss: 0.5983, Val Loss: 0.6121, F1 Micro: 0.6562, F1 Macro: 0.6508, Accuracy: 0.6562\n","Epoch 30, Train Loss: 0.5934, Val Loss: 0.5361, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 31, Train Loss: 0.6181, Val Loss: 0.5415, F1 Micro: 0.7188, F1 Macro: 0.7155, Accuracy: 0.7188\n","Epoch 32, Train Loss: 0.6618, Val Loss: 0.7809, F1 Micro: 0.5969, F1 Macro: 0.5461, Accuracy: 0.5969\n","Epoch 33, Train Loss: 0.6822, Val Loss: 0.6043, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 34, Train Loss: 0.6108, Val Loss: 0.6077, F1 Micro: 0.7063, F1 Macro: 0.6940, Accuracy: 0.7063\n","Epoch 35, Train Loss: 0.6253, Val Loss: 0.5570, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 36, Train Loss: 0.5885, Val Loss: 0.5363, F1 Micro: 0.7156, F1 Macro: 0.7133, Accuracy: 0.7156\n","Epoch 37, Train Loss: 0.5802, Val Loss: 0.5620, F1 Micro: 0.7063, F1 Macro: 0.7057, Accuracy: 0.7063\n","Epoch 38, Train Loss: 0.5826, Val Loss: 0.5367, F1 Micro: 0.7250, F1 Macro: 0.7234, Accuracy: 0.7250\n","Epoch 39, Train Loss: 0.5740, Val Loss: 0.5304, F1 Micro: 0.7156, F1 Macro: 0.7133, Accuracy: 0.7156\n","Epoch 40, Train Loss: 0.5772, Val Loss: 0.5593, F1 Micro: 0.7000, F1 Macro: 0.6998, Accuracy: 0.7000\n","Epoch 41, Train Loss: 0.6068, Val Loss: 0.5357, F1 Micro: 0.7031, F1 Macro: 0.6927, Accuracy: 0.7031\n","Epoch 42, Train Loss: 0.6091, Val Loss: 0.5345, F1 Micro: 0.7250, F1 Macro: 0.7202, Accuracy: 0.7250\n","Epoch 43, Train Loss: 0.5866, Val Loss: 0.5610, F1 Micro: 0.6969, F1 Macro: 0.6854, Accuracy: 0.6969\n","Epoch 44, Train Loss: 0.5909, Val Loss: 0.5422, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 45, Train Loss: 0.6557, Val Loss: 0.6707, F1 Micro: 0.6969, F1 Macro: 0.6715, Accuracy: 0.6969\n","Epoch 46, Train Loss: 0.6273, Val Loss: 0.5380, F1 Micro: 0.7125, F1 Macro: 0.7118, Accuracy: 0.7125\n","Epoch 47, Train Loss: 0.6157, Val Loss: 0.5536, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 48, Train Loss: 0.5953, Val Loss: 0.5282, F1 Micro: 0.7219, F1 Macro: 0.7202, Accuracy: 0.7219\n","Epoch 49, Train Loss: 0.5930, Val Loss: 0.6617, F1 Micro: 0.5844, F1 Macro: 0.4693, Accuracy: 0.5844\n","Epoch 50, Train Loss: 0.5810, Val Loss: 0.6541, F1 Micro: 0.6875, F1 Macro: 0.6456, Accuracy: 0.6875\n","Epoch 51, Train Loss: 0.6069, Val Loss: 0.5387, F1 Micro: 0.7312, F1 Macro: 0.7245, Accuracy: 0.7312\n","Epoch 52, Train Loss: 0.5860, Val Loss: 0.6486, F1 Micro: 0.5969, F1 Macro: 0.4927, Accuracy: 0.5969\n","Epoch 53, Train Loss: 0.6096, Val Loss: 0.5508, F1 Micro: 0.6969, F1 Macro: 0.6802, Accuracy: 0.6969\n","Epoch 54, Train Loss: 0.5697, Val Loss: 0.5413, F1 Micro: 0.7063, F1 Macro: 0.6963, Accuracy: 0.7063\n","Epoch 55, Train Loss: 0.5846, Val Loss: 0.5848, F1 Micro: 0.6500, F1 Macro: 0.6412, Accuracy: 0.6500\n","Epoch 56, Train Loss: 0.5711, Val Loss: 0.5743, F1 Micro: 0.7031, F1 Macro: 0.6991, Accuracy: 0.7031\n","Epoch 57, Train Loss: 0.6118, Val Loss: 0.5704, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 58, Train Loss: 0.5919, Val Loss: 0.5201, F1 Micro: 0.7219, F1 Macro: 0.7140, Accuracy: 0.7219\n","Epoch 59, Train Loss: 0.5945, Val Loss: 0.5442, F1 Micro: 0.6969, F1 Macro: 0.6793, Accuracy: 0.6969\n","Epoch 60, Train Loss: 0.5958, Val Loss: 0.5440, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 61, Train Loss: 0.5810, Val Loss: 0.5138, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 62, Train Loss: 0.5614, Val Loss: 0.6947, F1 Micro: 0.6344, F1 Macro: 0.6006, Accuracy: 0.6344\n","Epoch 63, Train Loss: 0.5705, Val Loss: 0.5168, F1 Micro: 0.7375, F1 Macro: 0.7320, Accuracy: 0.7375\n","Epoch 64, Train Loss: 0.5406, Val Loss: 0.5160, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 65, Train Loss: 0.5668, Val Loss: 0.5681, F1 Micro: 0.7031, F1 Macro: 0.6934, Accuracy: 0.7031\n","Epoch 66, Train Loss: 0.5587, Val Loss: 0.5090, F1 Micro: 0.7312, F1 Macro: 0.7285, Accuracy: 0.7312\n","Epoch 67, Train Loss: 0.5627, Val Loss: 0.4996, F1 Micro: 0.7344, F1 Macro: 0.7325, Accuracy: 0.7344\n","Epoch 68, Train Loss: 0.5584, Val Loss: 0.5076, F1 Micro: 0.7469, F1 Macro: 0.7403, Accuracy: 0.7469\n","Epoch 69, Train Loss: 0.5403, Val Loss: 0.5442, F1 Micro: 0.7063, F1 Macro: 0.6955, Accuracy: 0.7063\n","Epoch 70, Train Loss: 0.5635, Val Loss: 0.5139, F1 Micro: 0.7688, F1 Macro: 0.7639, Accuracy: 0.7688\n","Epoch 71, Train Loss: 0.5478, Val Loss: 0.5480, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 72, Train Loss: 0.5673, Val Loss: 0.4965, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 73, Train Loss: 0.5429, Val Loss: 0.4847, F1 Micro: 0.7750, F1 Macro: 0.7750, Accuracy: 0.7750\n","Epoch 74, Train Loss: 0.5579, Val Loss: 0.4908, F1 Micro: 0.7531, F1 Macro: 0.7518, Accuracy: 0.7531\n","Epoch 75, Train Loss: 0.5627, Val Loss: 0.5038, F1 Micro: 0.7375, F1 Macro: 0.7341, Accuracy: 0.7375\n","Epoch 76, Train Loss: 0.5769, Val Loss: 0.4975, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 77, Train Loss: 0.5654, Val Loss: 0.4901, F1 Micro: 0.7219, F1 Macro: 0.7204, Accuracy: 0.7219\n","Epoch 78, Train Loss: 0.5554, Val Loss: 0.4853, F1 Micro: 0.7500, F1 Macro: 0.7500, Accuracy: 0.7500\n","Epoch 79, Train Loss: 0.5369, Val Loss: 0.5546, F1 Micro: 0.7312, F1 Macro: 0.7093, Accuracy: 0.7312\n","Epoch 80, Train Loss: 0.5544, Val Loss: 0.5055, F1 Micro: 0.7063, F1 Macro: 0.7053, Accuracy: 0.7063\n","Epoch 81, Train Loss: 0.5460, Val Loss: 0.5258, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 82, Train Loss: 0.5372, Val Loss: 0.5017, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 83, Train Loss: 0.5424, Val Loss: 0.5532, F1 Micro: 0.7125, F1 Macro: 0.7106, Accuracy: 0.7125\n","Epoch 84, Train Loss: 0.5627, Val Loss: 0.4883, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 85, Train Loss: 0.5561, Val Loss: 0.5447, F1 Micro: 0.7031, F1 Macro: 0.6941, Accuracy: 0.7031\n","Epoch 86, Train Loss: 0.5753, Val Loss: 0.5441, F1 Micro: 0.7125, F1 Macro: 0.7047, Accuracy: 0.7125\n","Epoch 87, Train Loss: 0.5481, Val Loss: 0.5000, F1 Micro: 0.7906, F1 Macro: 0.7903, Accuracy: 0.7906\n","Epoch 88, Train Loss: 0.5465, Val Loss: 0.4997, F1 Micro: 0.7625, F1 Macro: 0.7609, Accuracy: 0.7625\n","Epoch 89, Train Loss: 0.5558, Val Loss: 0.5063, F1 Micro: 0.7469, F1 Macro: 0.7418, Accuracy: 0.7469\n","Epoch 90, Train Loss: 0.5689, Val Loss: 0.5933, F1 Micro: 0.7344, F1 Macro: 0.7110, Accuracy: 0.7344\n","Epoch 91, Train Loss: 0.5405, Val Loss: 0.4841, F1 Micro: 0.7188, F1 Macro: 0.7155, Accuracy: 0.7188\n","Epoch 92, Train Loss: 0.5376, Val Loss: 0.5333, F1 Micro: 0.7562, F1 Macro: 0.7549, Accuracy: 0.7562\n","Epoch 93, Train Loss: 0.5495, Val Loss: 0.4945, F1 Micro: 0.7469, F1 Macro: 0.7456, Accuracy: 0.7469\n","Epoch 94, Train Loss: 0.5315, Val Loss: 0.5069, F1 Micro: 0.7469, F1 Macro: 0.7427, Accuracy: 0.7469\n","Epoch 95, Train Loss: 0.5291, Val Loss: 0.4752, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 96, Train Loss: 0.5562, Val Loss: 0.5009, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 97, Train Loss: 0.5847, Val Loss: 0.4708, F1 Micro: 0.7438, F1 Macro: 0.7438, Accuracy: 0.7438\n","Epoch 98, Train Loss: 0.5965, Val Loss: 0.6294, F1 Micro: 0.6844, F1 Macro: 0.6660, Accuracy: 0.6844\n","Epoch 99, Train Loss: 0.5431, Val Loss: 0.5174, F1 Micro: 0.7188, F1 Macro: 0.7123, Accuracy: 0.7188\n","Epoch 100, Train Loss: 0.5254, Val Loss: 0.5229, F1 Micro: 0.7250, F1 Macro: 0.7143, Accuracy: 0.7250\n","Epoch 101, Train Loss: 0.5454, Val Loss: 0.5831, F1 Micro: 0.7063, F1 Macro: 0.6745, Accuracy: 0.7063\n","Epoch 102, Train Loss: 0.5528, Val Loss: 0.5531, F1 Micro: 0.7250, F1 Macro: 0.7143, Accuracy: 0.7250\n","Epoch 103, Train Loss: 0.5326, Val Loss: 0.5287, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 104, Train Loss: 0.5316, Val Loss: 0.5068, F1 Micro: 0.7781, F1 Macro: 0.7732, Accuracy: 0.7781\n","Epoch 105, Train Loss: 0.5453, Val Loss: 0.6494, F1 Micro: 0.7188, F1 Macro: 0.7078, Accuracy: 0.7188\n","Epoch 106, Train Loss: 0.5359, Val Loss: 0.5035, F1 Micro: 0.7188, F1 Macro: 0.7105, Accuracy: 0.7188\n","Epoch 107, Train Loss: 0.5486, Val Loss: 0.4612, F1 Micro: 0.7688, F1 Macro: 0.7674, Accuracy: 0.7688\n","Epoch 108, Train Loss: 0.5749, Val Loss: 0.4729, F1 Micro: 0.7219, F1 Macro: 0.7207, Accuracy: 0.7219\n","Epoch 109, Train Loss: 0.5391, Val Loss: 0.4698, F1 Micro: 0.7438, F1 Macro: 0.7429, Accuracy: 0.7438\n","Epoch 110, Train Loss: 0.5247, Val Loss: 0.5575, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 111, Train Loss: 0.5408, Val Loss: 0.7233, F1 Micro: 0.7156, F1 Macro: 0.7049, Accuracy: 0.7156\n","Epoch 112, Train Loss: 0.5294, Val Loss: 0.4905, F1 Micro: 0.7562, F1 Macro: 0.7535, Accuracy: 0.7562\n","Epoch 113, Train Loss: 0.5492, Val Loss: 0.5375, F1 Micro: 0.6906, F1 Macro: 0.6773, Accuracy: 0.6906\n","Epoch 114, Train Loss: 0.5291, Val Loss: 0.5101, F1 Micro: 0.7125, F1 Macro: 0.7027, Accuracy: 0.7125\n","Epoch 115, Train Loss: 0.5340, Val Loss: 0.5173, F1 Micro: 0.7094, F1 Macro: 0.6991, Accuracy: 0.7094\n","Epoch 116, Train Loss: 0.5408, Val Loss: 0.5791, F1 Micro: 0.6469, F1 Macro: 0.5784, Accuracy: 0.6469\n","Epoch 117, Train Loss: 0.5308, Val Loss: 0.4751, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 118, Train Loss: 0.5252, Val Loss: 0.5879, F1 Micro: 0.6906, F1 Macro: 0.6564, Accuracy: 0.6906\n","Epoch 119, Train Loss: 0.6100, Val Loss: 0.5758, F1 Micro: 0.7156, F1 Macro: 0.7104, Accuracy: 0.7156\n","Epoch 120, Train Loss: 0.5793, Val Loss: 0.5210, F1 Micro: 0.6906, F1 Macro: 0.6773, Accuracy: 0.6906\n","Epoch 121, Train Loss: 0.5284, Val Loss: 0.6233, F1 Micro: 0.7125, F1 Macro: 0.7013, Accuracy: 0.7125\n","Epoch 122, Train Loss: 0.5261, Val Loss: 0.5152, F1 Micro: 0.7906, F1 Macro: 0.7816, Accuracy: 0.7906\n","Epoch 123, Train Loss: 0.5171, Val Loss: 0.4748, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 124, Train Loss: 0.5232, Val Loss: 0.5490, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 125, Train Loss: 0.5296, Val Loss: 0.4752, F1 Micro: 0.7969, F1 Macro: 0.7964, Accuracy: 0.7969\n","Epoch 126, Train Loss: 0.5209, Val Loss: 0.4767, F1 Micro: 0.7875, F1 Macro: 0.7822, Accuracy: 0.7875\n","Epoch 127, Train Loss: 0.5240, Val Loss: 0.4629, F1 Micro: 0.7500, F1 Macro: 0.7492, Accuracy: 0.7500\n","Epoch 128, Train Loss: 0.5158, Val Loss: 0.4792, F1 Micro: 0.7500, F1 Macro: 0.7464, Accuracy: 0.7500\n","Epoch 129, Train Loss: 0.5078, Val Loss: 0.4810, F1 Micro: 0.7219, F1 Macro: 0.7157, Accuracy: 0.7219\n","Epoch 130, Train Loss: 0.5523, Val Loss: 0.6033, F1 Micro: 0.6344, F1 Macro: 0.5634, Accuracy: 0.6344\n","Epoch 131, Train Loss: 0.5444, Val Loss: 0.5181, F1 Micro: 0.7031, F1 Macro: 0.6982, Accuracy: 0.7031\n","Epoch 132, Train Loss: 0.5559, Val Loss: 0.5251, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 133, Train Loss: 0.5193, Val Loss: 0.5088, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 134, Train Loss: 0.5091, Val Loss: 0.4728, F1 Micro: 0.7844, F1 Macro: 0.7838, Accuracy: 0.7844\n","Epoch 135, Train Loss: 0.5078, Val Loss: 0.7083, F1 Micro: 0.5906, F1 Macro: 0.4885, Accuracy: 0.5906\n","Epoch 136, Train Loss: 0.5219, Val Loss: 0.4751, F1 Micro: 0.8281, F1 Macro: 0.8265, Accuracy: 0.8281\n","Epoch 137, Train Loss: 0.5522, Val Loss: 0.5812, F1 Micro: 0.7094, F1 Macro: 0.6728, Accuracy: 0.7094\n","Epoch 138, Train Loss: 0.5609, Val Loss: 0.8422, F1 Micro: 0.5219, F1 Macro: 0.3487, Accuracy: 0.5219\n","Epoch 139, Train Loss: 0.5372, Val Loss: 0.5864, F1 Micro: 0.6906, F1 Macro: 0.6736, Accuracy: 0.6906\n","Epoch 140, Train Loss: 0.5133, Val Loss: 0.4705, F1 Micro: 0.7438, F1 Macro: 0.7383, Accuracy: 0.7438\n","Epoch 141, Train Loss: 0.5226, Val Loss: 0.4480, F1 Micro: 0.8031, F1 Macro: 0.8031, Accuracy: 0.8031\n","Epoch 142, Train Loss: 0.5120, Val Loss: 0.4946, F1 Micro: 0.7500, F1 Macro: 0.7456, Accuracy: 0.7500\n","Epoch 143, Train Loss: 0.5300, Val Loss: 0.5199, F1 Micro: 0.7969, F1 Macro: 0.7857, Accuracy: 0.7969\n","Epoch 144, Train Loss: 0.5298, Val Loss: 0.5153, F1 Micro: 0.7250, F1 Macro: 0.7169, Accuracy: 0.7250\n","Epoch 145, Train Loss: 0.5312, Val Loss: 0.4716, F1 Micro: 0.8094, F1 Macro: 0.8059, Accuracy: 0.8094\n","Epoch 146, Train Loss: 0.5023, Val Loss: 0.4702, F1 Micro: 0.7875, F1 Macro: 0.7874, Accuracy: 0.7875\n","Epoch 147, Train Loss: 0.5348, Val Loss: 0.5233, F1 Micro: 0.7375, F1 Macro: 0.7368, Accuracy: 0.7375\n","Epoch 148, Train Loss: 0.5293, Val Loss: 0.4418, F1 Micro: 0.7906, F1 Macro: 0.7895, Accuracy: 0.7906\n","Epoch 149, Train Loss: 0.4992, Val Loss: 0.5050, F1 Micro: 0.7875, F1 Macro: 0.7803, Accuracy: 0.7875\n","Epoch 150, Train Loss: 0.5373, Val Loss: 0.5683, F1 Micro: 0.6906, F1 Macro: 0.6805, Accuracy: 0.6906\n","Epoch 151, Train Loss: 0.4992, Val Loss: 0.4517, F1 Micro: 0.8062, F1 Macro: 0.8062, Accuracy: 0.8063\n","Epoch 152, Train Loss: 0.5362, Val Loss: 0.4768, F1 Micro: 0.7750, F1 Macro: 0.7689, Accuracy: 0.7750\n","Epoch 153, Train Loss: 0.5230, Val Loss: 0.5004, F1 Micro: 0.8156, F1 Macro: 0.8087, Accuracy: 0.8156\n","Epoch 154, Train Loss: 0.5033, Val Loss: 0.5679, F1 Micro: 0.6781, F1 Macro: 0.6359, Accuracy: 0.6781\n","Epoch 155, Train Loss: 0.5132, Val Loss: 0.5100, F1 Micro: 0.7656, F1 Macro: 0.7535, Accuracy: 0.7656\n","Epoch 156, Train Loss: 0.4904, Val Loss: 0.5613, F1 Micro: 0.6937, F1 Macro: 0.6687, Accuracy: 0.6937\n","Epoch 157, Train Loss: 0.4964, Val Loss: 0.4650, F1 Micro: 0.7469, F1 Macro: 0.7418, Accuracy: 0.7469\n","Epoch 158, Train Loss: 0.5088, Val Loss: 0.4456, F1 Micro: 0.7781, F1 Macro: 0.7760, Accuracy: 0.7781\n","Epoch 159, Train Loss: 0.4856, Val Loss: 0.4381, F1 Micro: 0.7750, F1 Macro: 0.7749, Accuracy: 0.7750\n","Epoch 160, Train Loss: 0.5002, Val Loss: 0.5597, F1 Micro: 0.7219, F1 Macro: 0.7114, Accuracy: 0.7219\n","Epoch 161, Train Loss: 0.4927, Val Loss: 0.5427, F1 Micro: 0.7000, F1 Macro: 0.6849, Accuracy: 0.7000\n","Epoch 162, Train Loss: 0.4901, Val Loss: 0.5235, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 163, Train Loss: 0.5122, Val Loss: 0.4593, F1 Micro: 0.7781, F1 Macro: 0.7763, Accuracy: 0.7781\n","Epoch 164, Train Loss: 0.4891, Val Loss: 0.4755, F1 Micro: 0.7406, F1 Macro: 0.7344, Accuracy: 0.7406\n","Epoch 165, Train Loss: 0.5049, Val Loss: 0.5584, F1 Micro: 0.7125, F1 Macro: 0.6981, Accuracy: 0.7125\n","Epoch 166, Train Loss: 0.5261, Val Loss: 0.4194, F1 Micro: 0.8125, F1 Macro: 0.8122, Accuracy: 0.8125\n","Epoch 167, Train Loss: 0.5371, Val Loss: 0.5302, F1 Micro: 0.7312, F1 Macro: 0.7022, Accuracy: 0.7312\n","Epoch 168, Train Loss: 0.5181, Val Loss: 0.6411, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 169, Train Loss: 0.4962, Val Loss: 0.4558, F1 Micro: 0.7844, F1 Macro: 0.7840, Accuracy: 0.7844\n","Epoch 170, Train Loss: 0.4994, Val Loss: 0.4485, F1 Micro: 0.7906, F1 Macro: 0.7895, Accuracy: 0.7906\n","Epoch 171, Train Loss: 0.4730, Val Loss: 0.4384, F1 Micro: 0.7656, F1 Macro: 0.7631, Accuracy: 0.7656\n","Epoch 172, Train Loss: 0.4869, Val Loss: 0.4324, F1 Micro: 0.7812, F1 Macro: 0.7790, Accuracy: 0.7812\n","Epoch 173, Train Loss: 0.4906, Val Loss: 0.4579, F1 Micro: 0.7469, F1 Macro: 0.7418, Accuracy: 0.7469\n","Epoch 174, Train Loss: 0.5003, Val Loss: 0.4814, F1 Micro: 0.7281, F1 Macro: 0.7192, Accuracy: 0.7281\n","Epoch 175, Train Loss: 0.5057, Val Loss: 0.4899, F1 Micro: 0.7281, F1 Macro: 0.7179, Accuracy: 0.7281\n","Epoch 176, Train Loss: 0.4874, Val Loss: 0.5013, F1 Micro: 0.7656, F1 Macro: 0.7520, Accuracy: 0.7656\n","Epoch 177, Train Loss: 0.4970, Val Loss: 0.6410, F1 Micro: 0.7063, F1 Macro: 0.6906, Accuracy: 0.7063\n","Epoch 178, Train Loss: 0.4946, Val Loss: 0.4837, F1 Micro: 0.7812, F1 Macro: 0.7790, Accuracy: 0.7812\n","Epoch 179, Train Loss: 0.5087, Val Loss: 0.4250, F1 Micro: 0.7937, F1 Macro: 0.7937, Accuracy: 0.7937\n","Epoch 180, Train Loss: 0.4963, Val Loss: 0.4460, F1 Micro: 0.7688, F1 Macro: 0.7654, Accuracy: 0.7688\n","Epoch 181, Train Loss: 0.4908, Val Loss: 0.6226, F1 Micro: 0.6375, F1 Macro: 0.5805, Accuracy: 0.6375\n","Epoch 182, Train Loss: 0.4971, Val Loss: 0.5116, F1 Micro: 0.7844, F1 Macro: 0.7732, Accuracy: 0.7844\n","Epoch 183, Train Loss: 0.5251, Val Loss: 0.4859, F1 Micro: 0.7281, F1 Macro: 0.7192, Accuracy: 0.7281\n","Epoch 184, Train Loss: 0.4681, Val Loss: 0.4208, F1 Micro: 0.8125, F1 Macro: 0.8120, Accuracy: 0.8125\n","Epoch 185, Train Loss: 0.4933, Val Loss: 0.4254, F1 Micro: 0.8219, F1 Macro: 0.8215, Accuracy: 0.8219\n","Epoch 186, Train Loss: 0.5151, Val Loss: 0.5175, F1 Micro: 0.7469, F1 Macro: 0.7422, Accuracy: 0.7469\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.8131250000000001\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6077, Val Loss: 0.6237, F1 Micro: 0.6469, F1 Macro: 0.6143, Accuracy: 0.6469\n","Epoch 2, Train Loss: 0.5967, Val Loss: 0.7250, F1 Micro: 0.6094, F1 Macro: 0.5467, Accuracy: 0.6094\n","Epoch 3, Train Loss: 0.5885, Val Loss: 0.5802, F1 Micro: 0.6438, F1 Macro: 0.6402, Accuracy: 0.6438\n","Epoch 4, Train Loss: 0.5810, Val Loss: 0.5801, F1 Micro: 0.6438, F1 Macro: 0.6402, Accuracy: 0.6438\n","Epoch 5, Train Loss: 0.5714, Val Loss: 0.5848, F1 Micro: 0.6813, F1 Macro: 0.6813, Accuracy: 0.6813\n","Epoch 6, Train Loss: 0.5759, Val Loss: 0.5847, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 7, Train Loss: 0.5746, Val Loss: 0.5892, F1 Micro: 0.6562, F1 Macro: 0.6476, Accuracy: 0.6562\n","Epoch 8, Train Loss: 0.5753, Val Loss: 0.6231, F1 Micro: 0.6375, F1 Macro: 0.6048, Accuracy: 0.6375\n","Epoch 9, Train Loss: 0.5766, Val Loss: 0.6287, F1 Micro: 0.6781, F1 Macro: 0.6683, Accuracy: 0.6781\n","Epoch 10, Train Loss: 0.5626, Val Loss: 0.5802, F1 Micro: 0.6406, F1 Macro: 0.6358, Accuracy: 0.6406\n","Epoch 11, Train Loss: 0.5690, Val Loss: 0.5770, F1 Micro: 0.6469, F1 Macro: 0.6435, Accuracy: 0.6469\n","Epoch 12, Train Loss: 0.5679, Val Loss: 0.5799, F1 Micro: 0.6406, F1 Macro: 0.6358, Accuracy: 0.6406\n","Epoch 13, Train Loss: 0.5647, Val Loss: 0.5998, F1 Micro: 0.6469, F1 Macro: 0.6344, Accuracy: 0.6469\n","Epoch 14, Train Loss: 0.5703, Val Loss: 0.6033, F1 Micro: 0.6438, F1 Macro: 0.6212, Accuracy: 0.6438\n","Epoch 15, Train Loss: 0.5766, Val Loss: 0.5998, F1 Micro: 0.6594, F1 Macro: 0.6542, Accuracy: 0.6594\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6167, Val Loss: 0.5760, F1 Micro: 0.7188, F1 Macro: 0.7000, Accuracy: 0.7188\n","Epoch 2, Train Loss: 0.5950, Val Loss: 0.5654, F1 Micro: 0.7250, F1 Macro: 0.7128, Accuracy: 0.7250\n","Epoch 3, Train Loss: 0.5900, Val Loss: 0.5760, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 4, Train Loss: 0.5877, Val Loss: 0.6783, F1 Micro: 0.6188, F1 Macro: 0.5406, Accuracy: 0.6188\n","Epoch 5, Train Loss: 0.5888, Val Loss: 0.5581, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 6, Train Loss: 0.5780, Val Loss: 0.5635, F1 Micro: 0.7344, F1 Macro: 0.7237, Accuracy: 0.7344\n","Epoch 7, Train Loss: 0.5740, Val Loss: 0.5657, F1 Micro: 0.7094, F1 Macro: 0.7035, Accuracy: 0.7094\n","Epoch 8, Train Loss: 0.5729, Val Loss: 0.5622, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 9, Train Loss: 0.5742, Val Loss: 0.5964, F1 Micro: 0.6625, F1 Macro: 0.6614, Accuracy: 0.6625\n","Epoch 10, Train Loss: 0.5732, Val Loss: 0.5551, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 11, Train Loss: 0.5834, Val Loss: 0.5958, F1 Micro: 0.6969, F1 Macro: 0.6648, Accuracy: 0.6969\n","Epoch 12, Train Loss: 0.5781, Val Loss: 0.6045, F1 Micro: 0.6531, F1 Macro: 0.6494, Accuracy: 0.6531\n","Epoch 13, Train Loss: 0.5747, Val Loss: 0.5650, F1 Micro: 0.7219, F1 Macro: 0.7083, Accuracy: 0.7219\n","Epoch 14, Train Loss: 0.5735, Val Loss: 0.5568, F1 Micro: 0.6750, F1 Macro: 0.6728, Accuracy: 0.6750\n","Epoch 15, Train Loss: 0.5685, Val Loss: 0.5541, F1 Micro: 0.6906, F1 Macro: 0.6869, Accuracy: 0.6906\n","Epoch 16, Train Loss: 0.5733, Val Loss: 0.5551, F1 Micro: 0.6906, F1 Macro: 0.6877, Accuracy: 0.6906\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6186, Val Loss: 0.6645, F1 Micro: 0.6312, F1 Macro: 0.6248, Accuracy: 0.6312\n","Epoch 2, Train Loss: 0.5765, Val Loss: 0.6269, F1 Micro: 0.6781, F1 Macro: 0.6779, Accuracy: 0.6781\n","Epoch 3, Train Loss: 0.5874, Val Loss: 0.6161, F1 Micro: 0.6562, F1 Macro: 0.6379, Accuracy: 0.6562\n","Epoch 4, Train Loss: 0.5799, Val Loss: 0.6217, F1 Micro: 0.6562, F1 Macro: 0.6357, Accuracy: 0.6562\n","Epoch 5, Train Loss: 0.5751, Val Loss: 0.6056, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 6, Train Loss: 0.5707, Val Loss: 0.6694, F1 Micro: 0.6312, F1 Macro: 0.6241, Accuracy: 0.6312\n","Epoch 7, Train Loss: 0.5702, Val Loss: 0.6661, F1 Micro: 0.6344, F1 Macro: 0.6309, Accuracy: 0.6344\n","Epoch 8, Train Loss: 0.5711, Val Loss: 0.6182, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 9, Train Loss: 0.5693, Val Loss: 0.6180, F1 Micro: 0.6719, F1 Macro: 0.6715, Accuracy: 0.6719\n","Epoch 10, Train Loss: 0.5649, Val Loss: 0.6449, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 11, Train Loss: 0.5624, Val Loss: 0.6026, F1 Micro: 0.6562, F1 Macro: 0.6502, Accuracy: 0.6562\n","Epoch 12, Train Loss: 0.5613, Val Loss: 0.6224, F1 Micro: 0.6625, F1 Macro: 0.6619, Accuracy: 0.6625\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6547, Val Loss: 0.5372, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 2, Train Loss: 0.6094, Val Loss: 0.5330, F1 Micro: 0.7125, F1 Macro: 0.7122, Accuracy: 0.7125\n","Epoch 3, Train Loss: 0.5835, Val Loss: 0.5335, F1 Micro: 0.7312, F1 Macro: 0.7300, Accuracy: 0.7312\n","Epoch 4, Train Loss: 0.5859, Val Loss: 0.5342, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 5, Train Loss: 0.5827, Val Loss: 0.5319, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 6, Train Loss: 0.5898, Val Loss: 0.5347, F1 Micro: 0.7406, F1 Macro: 0.7390, Accuracy: 0.7406\n","Epoch 7, Train Loss: 0.5882, Val Loss: 0.5317, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Epoch 8, Train Loss: 0.5895, Val Loss: 0.5412, F1 Micro: 0.7031, F1 Macro: 0.7025, Accuracy: 0.7031\n","Epoch 9, Train Loss: 0.5791, Val Loss: 0.5342, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 10, Train Loss: 0.5838, Val Loss: 0.5368, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 11, Train Loss: 0.5896, Val Loss: 0.5341, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6380, Val Loss: 0.5412, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 2, Train Loss: 0.5996, Val Loss: 0.6244, F1 Micro: 0.6656, F1 Macro: 0.6140, Accuracy: 0.6656\n","Epoch 3, Train Loss: 0.5989, Val Loss: 0.5746, F1 Micro: 0.6813, F1 Macro: 0.6511, Accuracy: 0.6813\n","Epoch 4, Train Loss: 0.5976, Val Loss: 0.5408, F1 Micro: 0.7094, F1 Macro: 0.6984, Accuracy: 0.7094\n","Epoch 5, Train Loss: 0.5945, Val Loss: 0.5499, F1 Micro: 0.6969, F1 Macro: 0.6793, Accuracy: 0.6969\n","Epoch 6, Train Loss: 0.5810, Val Loss: 0.6079, F1 Micro: 0.6844, F1 Macro: 0.6463, Accuracy: 0.6844\n","Epoch 7, Train Loss: 0.5947, Val Loss: 0.5547, F1 Micro: 0.6906, F1 Macro: 0.6705, Accuracy: 0.6906\n","Epoch 8, Train Loss: 0.5899, Val Loss: 0.5408, F1 Micro: 0.7281, F1 Macro: 0.7221, Accuracy: 0.7281\n","Epoch 9, Train Loss: 0.5823, Val Loss: 0.5382, F1 Micro: 0.7125, F1 Macro: 0.7013, Accuracy: 0.7125\n","Epoch 10, Train Loss: 0.5907, Val Loss: 0.5397, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 11, Train Loss: 0.5801, Val Loss: 0.5447, F1 Micro: 0.7094, F1 Macro: 0.6977, Accuracy: 0.7094\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.7125\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.5965, Val Loss: 0.6541, F1 Micro: 0.6344, F1 Macro: 0.5957, Accuracy: 0.6344\n","Epoch 2, Train Loss: 0.5809, Val Loss: 0.5954, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 3, Train Loss: 0.5900, Val Loss: 0.6232, F1 Micro: 0.6844, F1 Macro: 0.6748, Accuracy: 0.6844\n","Epoch 4, Train Loss: 0.5802, Val Loss: 0.6161, F1 Micro: 0.6406, F1 Macro: 0.6160, Accuracy: 0.6406\n","Epoch 5, Train Loss: 0.5706, Val Loss: 0.5832, F1 Micro: 0.6344, F1 Macro: 0.6283, Accuracy: 0.6344\n","Epoch 6, Train Loss: 0.5815, Val Loss: 0.5811, F1 Micro: 0.6406, F1 Macro: 0.6363, Accuracy: 0.6406\n","Epoch 7, Train Loss: 0.5809, Val Loss: 0.5812, F1 Micro: 0.6406, F1 Macro: 0.6363, Accuracy: 0.6406\n","Epoch 8, Train Loss: 0.5862, Val Loss: 0.6678, F1 Micro: 0.6219, F1 Macro: 0.5702, Accuracy: 0.6219\n","Epoch 9, Train Loss: 0.5738, Val Loss: 0.5865, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 10, Train Loss: 0.5705, Val Loss: 0.5959, F1 Micro: 0.6594, F1 Macro: 0.6438, Accuracy: 0.6594\n","Epoch 11, Train Loss: 0.5720, Val Loss: 0.5953, F1 Micro: 0.6594, F1 Macro: 0.6438, Accuracy: 0.6594\n","Epoch 12, Train Loss: 0.5707, Val Loss: 0.5871, F1 Micro: 0.6562, F1 Macro: 0.6483, Accuracy: 0.6562\n","Epoch 13, Train Loss: 0.5641, Val Loss: 0.6047, F1 Micro: 0.6594, F1 Macro: 0.6438, Accuracy: 0.6594\n","Epoch 14, Train Loss: 0.5668, Val Loss: 0.5766, F1 Micro: 0.6656, F1 Macro: 0.6642, Accuracy: 0.6656\n","Epoch 15, Train Loss: 0.5626, Val Loss: 0.5814, F1 Micro: 0.6719, F1 Macro: 0.6707, Accuracy: 0.6719\n","Epoch 16, Train Loss: 0.5629, Val Loss: 0.5788, F1 Micro: 0.6344, F1 Macro: 0.6289, Accuracy: 0.6344\n","Epoch 17, Train Loss: 0.5712, Val Loss: 0.5776, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 18, Train Loss: 0.5667, Val Loss: 0.5831, F1 Micro: 0.6531, F1 Macro: 0.6455, Accuracy: 0.6531\n","Epoch 19, Train Loss: 0.5694, Val Loss: 0.5730, F1 Micro: 0.6594, F1 Macro: 0.6569, Accuracy: 0.6594\n","Epoch 20, Train Loss: 0.5620, Val Loss: 0.5739, F1 Micro: 0.6625, F1 Macro: 0.6606, Accuracy: 0.6625\n","Epoch 21, Train Loss: 0.5603, Val Loss: 0.5754, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 22, Train Loss: 0.5693, Val Loss: 0.5719, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 23, Train Loss: 0.5679, Val Loss: 0.5816, F1 Micro: 0.6438, F1 Macro: 0.6392, Accuracy: 0.6438\n","Epoch 24, Train Loss: 0.5686, Val Loss: 0.5808, F1 Micro: 0.6562, F1 Macro: 0.6536, Accuracy: 0.6562\n","Epoch 25, Train Loss: 0.5634, Val Loss: 0.5721, F1 Micro: 0.6719, F1 Macro: 0.6707, Accuracy: 0.6719\n","Epoch 26, Train Loss: 0.5600, Val Loss: 0.5750, F1 Micro: 0.6719, F1 Macro: 0.6712, Accuracy: 0.6719\n","Epoch 27, Train Loss: 0.5649, Val Loss: 0.5755, F1 Micro: 0.6750, F1 Macro: 0.6748, Accuracy: 0.6750\n","Epoch 28, Train Loss: 0.5569, Val Loss: 0.5743, F1 Micro: 0.6406, F1 Macro: 0.6358, Accuracy: 0.6406\n","Epoch 29, Train Loss: 0.5620, Val Loss: 0.5698, F1 Micro: 0.6781, F1 Macro: 0.6776, Accuracy: 0.6781\n","Epoch 30, Train Loss: 0.5646, Val Loss: 0.5743, F1 Micro: 0.6625, F1 Macro: 0.6625, Accuracy: 0.6625\n","Epoch 31, Train Loss: 0.5637, Val Loss: 0.5682, F1 Micro: 0.6719, F1 Macro: 0.6707, Accuracy: 0.6719\n","Epoch 32, Train Loss: 0.5557, Val Loss: 0.5701, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 33, Train Loss: 0.5580, Val Loss: 0.5858, F1 Micro: 0.6469, F1 Macro: 0.6384, Accuracy: 0.6469\n","Epoch 34, Train Loss: 0.5617, Val Loss: 0.5702, F1 Micro: 0.6469, F1 Macro: 0.6431, Accuracy: 0.6469\n","Epoch 35, Train Loss: 0.5575, Val Loss: 0.5723, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 36, Train Loss: 0.5568, Val Loss: 0.5690, F1 Micro: 0.6531, F1 Macro: 0.6503, Accuracy: 0.6531\n","Epoch 37, Train Loss: 0.5542, Val Loss: 0.5760, F1 Micro: 0.6469, F1 Macro: 0.6410, Accuracy: 0.6469\n","Epoch 38, Train Loss: 0.5543, Val Loss: 0.5718, F1 Micro: 0.6719, F1 Macro: 0.6709, Accuracy: 0.6719\n","Epoch 39, Train Loss: 0.5544, Val Loss: 0.5744, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 40, Train Loss: 0.5563, Val Loss: 0.5646, F1 Micro: 0.6781, F1 Macro: 0.6779, Accuracy: 0.6781\n","Epoch 41, Train Loss: 0.5551, Val Loss: 0.6038, F1 Micro: 0.6750, F1 Macro: 0.6669, Accuracy: 0.6750\n","Epoch 42, Train Loss: 0.5553, Val Loss: 0.6116, F1 Micro: 0.6562, F1 Macro: 0.6357, Accuracy: 0.6562\n","Epoch 43, Train Loss: 0.5540, Val Loss: 0.5679, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 44, Train Loss: 0.5536, Val Loss: 0.5631, F1 Micro: 0.6781, F1 Macro: 0.6776, Accuracy: 0.6781\n","Epoch 45, Train Loss: 0.5548, Val Loss: 0.5753, F1 Micro: 0.6844, F1 Macro: 0.6843, Accuracy: 0.6844\n","Epoch 46, Train Loss: 0.5576, Val Loss: 0.5641, F1 Micro: 0.6719, F1 Macro: 0.6717, Accuracy: 0.6719\n","Epoch 47, Train Loss: 0.5537, Val Loss: 0.5665, F1 Micro: 0.6781, F1 Macro: 0.6779, Accuracy: 0.6781\n","Epoch 48, Train Loss: 0.5484, Val Loss: 0.5862, F1 Micro: 0.6594, F1 Macro: 0.6482, Accuracy: 0.6594\n","Epoch 49, Train Loss: 0.5565, Val Loss: 0.5622, F1 Micro: 0.6562, F1 Macro: 0.6532, Accuracy: 0.6562\n","Epoch 50, Train Loss: 0.5493, Val Loss: 0.5656, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 51, Train Loss: 0.5469, Val Loss: 0.5587, F1 Micro: 0.6750, F1 Macro: 0.6745, Accuracy: 0.6750\n","Epoch 52, Train Loss: 0.5514, Val Loss: 0.5615, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 53, Train Loss: 0.5487, Val Loss: 0.5646, F1 Micro: 0.6562, F1 Macro: 0.6523, Accuracy: 0.6562\n","Epoch 54, Train Loss: 0.5504, Val Loss: 0.5671, F1 Micro: 0.6406, F1 Macro: 0.6340, Accuracy: 0.6406\n","Epoch 55, Train Loss: 0.5488, Val Loss: 0.5580, F1 Micro: 0.6750, F1 Macro: 0.6745, Accuracy: 0.6750\n","Epoch 56, Train Loss: 0.5534, Val Loss: 0.5580, F1 Micro: 0.6719, F1 Macro: 0.6702, Accuracy: 0.6719\n","Epoch 57, Train Loss: 0.5437, Val Loss: 0.5616, F1 Micro: 0.6969, F1 Macro: 0.6956, Accuracy: 0.6969\n","Epoch 58, Train Loss: 0.5409, Val Loss: 0.5554, F1 Micro: 0.6719, F1 Macro: 0.6702, Accuracy: 0.6719\n","Epoch 59, Train Loss: 0.5499, Val Loss: 0.5529, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 60, Train Loss: 0.5424, Val Loss: 0.5712, F1 Micro: 0.6531, F1 Macro: 0.6455, Accuracy: 0.6531\n","Epoch 61, Train Loss: 0.5463, Val Loss: 0.5575, F1 Micro: 0.6562, F1 Macro: 0.6523, Accuracy: 0.6562\n","Epoch 62, Train Loss: 0.5436, Val Loss: 0.5626, F1 Micro: 0.6625, F1 Macro: 0.6577, Accuracy: 0.6625\n","Epoch 63, Train Loss: 0.5420, Val Loss: 0.5618, F1 Micro: 0.6438, F1 Macro: 0.6381, Accuracy: 0.6438\n","Epoch 64, Train Loss: 0.5413, Val Loss: 0.5655, F1 Micro: 0.6594, F1 Macro: 0.6525, Accuracy: 0.6594\n","Epoch 65, Train Loss: 0.5420, Val Loss: 0.5559, F1 Micro: 0.7000, F1 Macro: 0.6983, Accuracy: 0.7000\n","Epoch 66, Train Loss: 0.5420, Val Loss: 0.5552, F1 Micro: 0.6844, F1 Macro: 0.6841, Accuracy: 0.6844\n","Epoch 67, Train Loss: 0.5439, Val Loss: 0.5947, F1 Micro: 0.6781, F1 Macro: 0.6733, Accuracy: 0.6781\n","Epoch 68, Train Loss: 0.5426, Val Loss: 0.5511, F1 Micro: 0.6813, F1 Macro: 0.6805, Accuracy: 0.6813\n","Epoch 69, Train Loss: 0.5357, Val Loss: 0.5504, F1 Micro: 0.6687, F1 Macro: 0.6658, Accuracy: 0.6687\n","Epoch 70, Train Loss: 0.5447, Val Loss: 0.6061, F1 Micro: 0.6656, F1 Macro: 0.6415, Accuracy: 0.6656\n","Epoch 71, Train Loss: 0.5455, Val Loss: 0.5458, F1 Micro: 0.6906, F1 Macro: 0.6906, Accuracy: 0.6906\n","Epoch 72, Train Loss: 0.5462, Val Loss: 0.5627, F1 Micro: 0.6844, F1 Macro: 0.6791, Accuracy: 0.6844\n","Epoch 73, Train Loss: 0.5386, Val Loss: 0.5620, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 74, Train Loss: 0.5369, Val Loss: 0.5490, F1 Micro: 0.6687, F1 Macro: 0.6658, Accuracy: 0.6687\n","Epoch 75, Train Loss: 0.5365, Val Loss: 0.5597, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 76, Train Loss: 0.5405, Val Loss: 0.5458, F1 Micro: 0.6750, F1 Macro: 0.6750, Accuracy: 0.6750\n","Epoch 77, Train Loss: 0.5402, Val Loss: 0.5408, F1 Micro: 0.6844, F1 Macro: 0.6841, Accuracy: 0.6844\n","Epoch 78, Train Loss: 0.5387, Val Loss: 0.5609, F1 Micro: 0.6531, F1 Macro: 0.6484, Accuracy: 0.6531\n","Epoch 79, Train Loss: 0.5449, Val Loss: 0.5491, F1 Micro: 0.6687, F1 Macro: 0.6658, Accuracy: 0.6687\n","Epoch 80, Train Loss: 0.5373, Val Loss: 0.5400, F1 Micro: 0.6844, F1 Macro: 0.6843, Accuracy: 0.6844\n","Epoch 81, Train Loss: 0.5330, Val Loss: 0.5404, F1 Micro: 0.6844, F1 Macro: 0.6837, Accuracy: 0.6844\n","Epoch 82, Train Loss: 0.5356, Val Loss: 0.5448, F1 Micro: 0.7000, F1 Macro: 0.6977, Accuracy: 0.7000\n","Epoch 83, Train Loss: 0.5359, Val Loss: 0.5388, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 84, Train Loss: 0.5348, Val Loss: 0.5375, F1 Micro: 0.6969, F1 Macro: 0.6967, Accuracy: 0.6969\n","Epoch 85, Train Loss: 0.5330, Val Loss: 0.5595, F1 Micro: 0.6937, F1 Macro: 0.6841, Accuracy: 0.6937\n","Epoch 86, Train Loss: 0.5347, Val Loss: 0.5555, F1 Micro: 0.6813, F1 Macro: 0.6762, Accuracy: 0.6813\n","Epoch 87, Train Loss: 0.5286, Val Loss: 0.5352, F1 Micro: 0.6969, F1 Macro: 0.6967, Accuracy: 0.6969\n","Epoch 88, Train Loss: 0.5360, Val Loss: 0.5408, F1 Micro: 0.6750, F1 Macro: 0.6725, Accuracy: 0.6750\n","Epoch 89, Train Loss: 0.5386, Val Loss: 0.5429, F1 Micro: 0.6813, F1 Macro: 0.6791, Accuracy: 0.6813\n","Epoch 90, Train Loss: 0.5389, Val Loss: 0.5371, F1 Micro: 0.7219, F1 Macro: 0.7207, Accuracy: 0.7219\n","Epoch 91, Train Loss: 0.5298, Val Loss: 0.5328, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 92, Train Loss: 0.5395, Val Loss: 0.5417, F1 Micro: 0.6750, F1 Macro: 0.6725, Accuracy: 0.6750\n","Epoch 93, Train Loss: 0.5393, Val Loss: 0.5459, F1 Micro: 0.6687, F1 Macro: 0.6658, Accuracy: 0.6687\n","Epoch 94, Train Loss: 0.5310, Val Loss: 0.5510, F1 Micro: 0.6781, F1 Macro: 0.6742, Accuracy: 0.6781\n","Epoch 95, Train Loss: 0.5378, Val Loss: 0.5400, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 96, Train Loss: 0.5297, Val Loss: 0.5303, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 97, Train Loss: 0.5319, Val Loss: 0.5418, F1 Micro: 0.6719, F1 Macro: 0.6692, Accuracy: 0.6719\n","Epoch 98, Train Loss: 0.5284, Val Loss: 0.5291, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 99, Train Loss: 0.5312, Val Loss: 0.5312, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 100, Train Loss: 0.5312, Val Loss: 0.5312, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 101, Train Loss: 0.5287, Val Loss: 0.5321, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 102, Train Loss: 0.5229, Val Loss: 0.5370, F1 Micro: 0.7312, F1 Macro: 0.7274, Accuracy: 0.7312\n","Epoch 103, Train Loss: 0.5341, Val Loss: 0.5621, F1 Micro: 0.6719, F1 Macro: 0.6626, Accuracy: 0.6719\n","Epoch 104, Train Loss: 0.5320, Val Loss: 0.5300, F1 Micro: 0.7063, F1 Macro: 0.7058, Accuracy: 0.7063\n","Epoch 105, Train Loss: 0.5328, Val Loss: 0.5488, F1 Micro: 0.6719, F1 Macro: 0.6683, Accuracy: 0.6719\n","Epoch 106, Train Loss: 0.5253, Val Loss: 0.5464, F1 Micro: 0.6969, F1 Macro: 0.6902, Accuracy: 0.6969\n","Epoch 107, Train Loss: 0.5270, Val Loss: 0.5237, F1 Micro: 0.6969, F1 Macro: 0.6956, Accuracy: 0.6969\n","Epoch 108, Train Loss: 0.5237, Val Loss: 0.5237, F1 Micro: 0.6906, F1 Macro: 0.6895, Accuracy: 0.6906\n","Epoch 109, Train Loss: 0.5241, Val Loss: 0.5201, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 110, Train Loss: 0.5283, Val Loss: 0.5217, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 111, Train Loss: 0.5273, Val Loss: 0.5513, F1 Micro: 0.6906, F1 Macro: 0.6844, Accuracy: 0.6906\n","Epoch 112, Train Loss: 0.5239, Val Loss: 0.5283, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 113, Train Loss: 0.5216, Val Loss: 0.6012, F1 Micro: 0.6687, F1 Macro: 0.6583, Accuracy: 0.6687\n","Epoch 114, Train Loss: 0.5309, Val Loss: 0.5479, F1 Micro: 0.6781, F1 Macro: 0.6765, Accuracy: 0.6781\n","Epoch 115, Train Loss: 0.5296, Val Loss: 0.5211, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 116, Train Loss: 0.5222, Val Loss: 0.5155, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 117, Train Loss: 0.5192, Val Loss: 0.5302, F1 Micro: 0.6813, F1 Macro: 0.6780, Accuracy: 0.6813\n","Epoch 118, Train Loss: 0.5317, Val Loss: 0.5241, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 119, Train Loss: 0.5272, Val Loss: 0.5195, F1 Micro: 0.7281, F1 Macro: 0.7265, Accuracy: 0.7281\n","Epoch 120, Train Loss: 0.5311, Val Loss: 0.5159, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 121, Train Loss: 0.5202, Val Loss: 0.5136, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 122, Train Loss: 0.5241, Val Loss: 0.5186, F1 Micro: 0.7063, F1 Macro: 0.7053, Accuracy: 0.7063\n","Epoch 123, Train Loss: 0.5291, Val Loss: 0.5155, F1 Micro: 0.7000, F1 Macro: 0.6988, Accuracy: 0.7000\n","Epoch 124, Train Loss: 0.5166, Val Loss: 0.5203, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 125, Train Loss: 0.5237, Val Loss: 0.5341, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 126, Train Loss: 0.5242, Val Loss: 0.5186, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 127, Train Loss: 0.5199, Val Loss: 0.5131, F1 Micro: 0.7344, F1 Macro: 0.7338, Accuracy: 0.7344\n","Epoch 128, Train Loss: 0.5219, Val Loss: 0.5372, F1 Micro: 0.7063, F1 Macro: 0.6989, Accuracy: 0.7063\n","Epoch 129, Train Loss: 0.5198, Val Loss: 0.5178, F1 Micro: 0.7469, F1 Macro: 0.7451, Accuracy: 0.7469\n","Epoch 130, Train Loss: 0.5146, Val Loss: 0.5143, F1 Micro: 0.7406, F1 Macro: 0.7367, Accuracy: 0.7406\n","Epoch 131, Train Loss: 0.5046, Val Loss: 0.5128, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 132, Train Loss: 0.5250, Val Loss: 0.5118, F1 Micro: 0.7156, F1 Macro: 0.7126, Accuracy: 0.7156\n","Epoch 133, Train Loss: 0.5117, Val Loss: 0.5133, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 134, Train Loss: 0.5214, Val Loss: 0.5068, F1 Micro: 0.7375, F1 Macro: 0.7370, Accuracy: 0.7375\n","Epoch 135, Train Loss: 0.5197, Val Loss: 0.5041, F1 Micro: 0.7406, F1 Macro: 0.7404, Accuracy: 0.7406\n","Epoch 136, Train Loss: 0.5171, Val Loss: 0.5122, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 137, Train Loss: 0.5193, Val Loss: 0.5194, F1 Micro: 0.6937, F1 Macro: 0.6923, Accuracy: 0.6937\n","Epoch 138, Train Loss: 0.5202, Val Loss: 0.5034, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 139, Train Loss: 0.5223, Val Loss: 0.5132, F1 Micro: 0.7281, F1 Macro: 0.7279, Accuracy: 0.7281\n","Epoch 140, Train Loss: 0.5172, Val Loss: 0.5064, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 141, Train Loss: 0.5161, Val Loss: 0.5181, F1 Micro: 0.7250, F1 Macro: 0.7187, Accuracy: 0.7250\n","Epoch 142, Train Loss: 0.5108, Val Loss: 0.5290, F1 Micro: 0.7000, F1 Macro: 0.6962, Accuracy: 0.7000\n","Epoch 143, Train Loss: 0.5149, Val Loss: 0.5280, F1 Micro: 0.6969, F1 Macro: 0.6928, Accuracy: 0.6969\n","Epoch 144, Train Loss: 0.5209, Val Loss: 0.5066, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 145, Train Loss: 0.5116, Val Loss: 0.4980, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 146, Train Loss: 0.5147, Val Loss: 0.5036, F1 Micro: 0.7375, F1 Macro: 0.7372, Accuracy: 0.7375\n","Epoch 147, Train Loss: 0.5130, Val Loss: 0.5249, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 148, Train Loss: 0.5098, Val Loss: 0.5024, F1 Micro: 0.7375, F1 Macro: 0.7374, Accuracy: 0.7375\n","Epoch 149, Train Loss: 0.5052, Val Loss: 0.5100, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 150, Train Loss: 0.5157, Val Loss: 0.5203, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 151, Train Loss: 0.5194, Val Loss: 0.4989, F1 Micro: 0.7438, F1 Macro: 0.7425, Accuracy: 0.7438\n","Epoch 152, Train Loss: 0.5093, Val Loss: 0.5082, F1 Micro: 0.7094, F1 Macro: 0.7087, Accuracy: 0.7094\n","Epoch 153, Train Loss: 0.5132, Val Loss: 0.5053, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 154, Train Loss: 0.5077, Val Loss: 0.5326, F1 Micro: 0.6969, F1 Macro: 0.6932, Accuracy: 0.6969\n","Epoch 155, Train Loss: 0.5098, Val Loss: 0.5324, F1 Micro: 0.7000, F1 Macro: 0.6966, Accuracy: 0.7000\n","Epoch 156, Train Loss: 0.5137, Val Loss: 0.4968, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 157, Train Loss: 0.5047, Val Loss: 0.5304, F1 Micro: 0.7094, F1 Macro: 0.7045, Accuracy: 0.7094\n","Epoch 158, Train Loss: 0.5208, Val Loss: 0.4939, F1 Micro: 0.7375, F1 Macro: 0.7374, Accuracy: 0.7375\n","Epoch 159, Train Loss: 0.5150, Val Loss: 0.5185, F1 Micro: 0.7000, F1 Macro: 0.6970, Accuracy: 0.7000\n","Epoch 160, Train Loss: 0.5183, Val Loss: 0.5046, F1 Micro: 0.7281, F1 Macro: 0.7226, Accuracy: 0.7281\n","Epoch 161, Train Loss: 0.5105, Val Loss: 0.4992, F1 Micro: 0.7344, F1 Macro: 0.7339, Accuracy: 0.7344\n","Epoch 162, Train Loss: 0.5087, Val Loss: 0.5232, F1 Micro: 0.7063, F1 Macro: 0.7016, Accuracy: 0.7063\n","Epoch 163, Train Loss: 0.5223, Val Loss: 0.4960, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 164, Train Loss: 0.5087, Val Loss: 0.4926, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 165, Train Loss: 0.5152, Val Loss: 0.5797, F1 Micro: 0.6937, F1 Macro: 0.6833, Accuracy: 0.6937\n","Epoch 166, Train Loss: 0.5134, Val Loss: 0.5071, F1 Micro: 0.7031, F1 Macro: 0.7016, Accuracy: 0.7031\n","Epoch 167, Train Loss: 0.5067, Val Loss: 0.5081, F1 Micro: 0.7250, F1 Macro: 0.7197, Accuracy: 0.7250\n","Epoch 168, Train Loss: 0.5075, Val Loss: 0.4979, F1 Micro: 0.7375, F1 Macro: 0.7374, Accuracy: 0.7375\n","Epoch 169, Train Loss: 0.5134, Val Loss: 0.5100, F1 Micro: 0.7125, F1 Macro: 0.7047, Accuracy: 0.7125\n","Epoch 170, Train Loss: 0.5059, Val Loss: 0.5055, F1 Micro: 0.7594, F1 Macro: 0.7593, Accuracy: 0.7594\n","Epoch 171, Train Loss: 0.5052, Val Loss: 0.5112, F1 Micro: 0.7000, F1 Macro: 0.6970, Accuracy: 0.7000\n","Epoch 172, Train Loss: 0.5099, Val Loss: 0.4975, F1 Micro: 0.7406, F1 Macro: 0.7402, Accuracy: 0.7406\n","Epoch 173, Train Loss: 0.5003, Val Loss: 0.4924, F1 Micro: 0.7406, F1 Macro: 0.7406, Accuracy: 0.7406\n","Epoch 174, Train Loss: 0.5069, Val Loss: 0.4956, F1 Micro: 0.7531, F1 Macro: 0.7516, Accuracy: 0.7531\n","Epoch 175, Train Loss: 0.5066, Val Loss: 0.4893, F1 Micro: 0.7656, F1 Macro: 0.7655, Accuracy: 0.7656\n","Epoch 176, Train Loss: 0.5086, Val Loss: 0.4845, F1 Micro: 0.7406, F1 Macro: 0.7404, Accuracy: 0.7406\n","Epoch 177, Train Loss: 0.5150, Val Loss: 0.4938, F1 Micro: 0.7312, F1 Macro: 0.7310, Accuracy: 0.7312\n","Epoch 178, Train Loss: 0.5105, Val Loss: 0.4890, F1 Micro: 0.7406, F1 Macro: 0.7405, Accuracy: 0.7406\n","Epoch 179, Train Loss: 0.5038, Val Loss: 0.4927, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 180, Train Loss: 0.5104, Val Loss: 0.4929, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 181, Train Loss: 0.5053, Val Loss: 0.4943, F1 Micro: 0.7438, F1 Macro: 0.7433, Accuracy: 0.7438\n","Epoch 182, Train Loss: 0.5025, Val Loss: 0.5629, F1 Micro: 0.7094, F1 Macro: 0.6969, Accuracy: 0.7094\n","Epoch 183, Train Loss: 0.5126, Val Loss: 0.4855, F1 Micro: 0.7438, F1 Macro: 0.7412, Accuracy: 0.7438\n","Epoch 184, Train Loss: 0.5063, Val Loss: 0.5008, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 185, Train Loss: 0.5066, Val Loss: 0.4940, F1 Micro: 0.7438, F1 Macro: 0.7431, Accuracy: 0.7438\n","Epoch 186, Train Loss: 0.4962, Val Loss: 0.5158, F1 Micro: 0.6969, F1 Macro: 0.6847, Accuracy: 0.6969\n","Epoch 187, Train Loss: 0.5057, Val Loss: 0.4838, F1 Micro: 0.7344, F1 Macro: 0.7338, Accuracy: 0.7344\n","Epoch 188, Train Loss: 0.5033, Val Loss: 0.4970, F1 Micro: 0.7375, F1 Macro: 0.7365, Accuracy: 0.7375\n","Epoch 189, Train Loss: 0.4992, Val Loss: 0.4941, F1 Micro: 0.7781, F1 Macro: 0.7773, Accuracy: 0.7781\n","Epoch 190, Train Loss: 0.5030, Val Loss: 0.4932, F1 Micro: 0.7219, F1 Macro: 0.7177, Accuracy: 0.7219\n","Epoch 191, Train Loss: 0.4993, Val Loss: 0.4930, F1 Micro: 0.7281, F1 Macro: 0.7240, Accuracy: 0.7281\n","Epoch 192, Train Loss: 0.5188, Val Loss: 0.4996, F1 Micro: 0.7875, F1 Macro: 0.7870, Accuracy: 0.7875\n","Epoch 193, Train Loss: 0.5170, Val Loss: 0.4912, F1 Micro: 0.7469, F1 Macro: 0.7463, Accuracy: 0.7469\n","Epoch 194, Train Loss: 0.4936, Val Loss: 0.4947, F1 Micro: 0.7281, F1 Macro: 0.7236, Accuracy: 0.7281\n","Epoch 195, Train Loss: 0.4960, Val Loss: 0.4845, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 196, Train Loss: 0.4903, Val Loss: 0.4946, F1 Micro: 0.7625, F1 Macro: 0.7609, Accuracy: 0.7625\n","Epoch 197, Train Loss: 0.5028, Val Loss: 0.4788, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 198, Train Loss: 0.4996, Val Loss: 0.5115, F1 Micro: 0.7250, F1 Macro: 0.7211, Accuracy: 0.7250\n","Epoch 199, Train Loss: 0.5111, Val Loss: 0.4793, F1 Micro: 0.7406, F1 Macro: 0.7399, Accuracy: 0.7406\n","Epoch 200, Train Loss: 0.5048, Val Loss: 0.4941, F1 Micro: 0.7750, F1 Macro: 0.7733, Accuracy: 0.7750\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6300, Val Loss: 0.5627, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 2, Train Loss: 0.5872, Val Loss: 0.6115, F1 Micro: 0.6594, F1 Macro: 0.6557, Accuracy: 0.6594\n","Epoch 3, Train Loss: 0.5913, Val Loss: 0.5766, F1 Micro: 0.7188, F1 Macro: 0.6990, Accuracy: 0.7188\n","Epoch 4, Train Loss: 0.5860, Val Loss: 0.5606, F1 Micro: 0.6937, F1 Macro: 0.6903, Accuracy: 0.6937\n","Epoch 5, Train Loss: 0.5824, Val Loss: 0.5611, F1 Micro: 0.6906, F1 Macro: 0.6869, Accuracy: 0.6906\n","Epoch 6, Train Loss: 0.5824, Val Loss: 0.5675, F1 Micro: 0.7312, F1 Macro: 0.7201, Accuracy: 0.7312\n","Epoch 7, Train Loss: 0.5779, Val Loss: 0.5587, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 8, Train Loss: 0.5789, Val Loss: 0.5591, F1 Micro: 0.6937, F1 Macro: 0.6903, Accuracy: 0.6937\n","Epoch 9, Train Loss: 0.5678, Val Loss: 0.5713, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 10, Train Loss: 0.5856, Val Loss: 0.5605, F1 Micro: 0.7219, F1 Macro: 0.7140, Accuracy: 0.7219\n","Epoch 11, Train Loss: 0.5737, Val Loss: 0.5629, F1 Micro: 0.7250, F1 Macro: 0.7128, Accuracy: 0.7250\n","Epoch 12, Train Loss: 0.5749, Val Loss: 0.5735, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 13, Train Loss: 0.5770, Val Loss: 0.5545, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 14, Train Loss: 0.5729, Val Loss: 0.5674, F1 Micro: 0.7188, F1 Macro: 0.7070, Accuracy: 0.7188\n","Epoch 15, Train Loss: 0.5690, Val Loss: 0.5572, F1 Micro: 0.7281, F1 Macro: 0.7198, Accuracy: 0.7281\n","Epoch 16, Train Loss: 0.5742, Val Loss: 0.6064, F1 Micro: 0.6594, F1 Macro: 0.6557, Accuracy: 0.6594\n","Epoch 17, Train Loss: 0.5747, Val Loss: 0.5581, F1 Micro: 0.7188, F1 Macro: 0.7123, Accuracy: 0.7188\n","Epoch 18, Train Loss: 0.5704, Val Loss: 0.5546, F1 Micro: 0.7188, F1 Macro: 0.7123, Accuracy: 0.7188\n","Epoch 19, Train Loss: 0.5759, Val Loss: 0.5541, F1 Micro: 0.7094, F1 Macro: 0.7035, Accuracy: 0.7094\n","Epoch 20, Train Loss: 0.5689, Val Loss: 0.5602, F1 Micro: 0.6844, F1 Macro: 0.6840, Accuracy: 0.6844\n","Epoch 21, Train Loss: 0.5750, Val Loss: 0.5691, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 22, Train Loss: 0.5714, Val Loss: 0.5572, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 23, Train Loss: 0.5645, Val Loss: 0.5697, F1 Micro: 0.7250, F1 Macro: 0.7057, Accuracy: 0.7250\n","Epoch 24, Train Loss: 0.5714, Val Loss: 0.5747, F1 Micro: 0.7219, F1 Macro: 0.7018, Accuracy: 0.7219\n","Epoch 25, Train Loss: 0.5675, Val Loss: 0.5509, F1 Micro: 0.7031, F1 Macro: 0.6982, Accuracy: 0.7031\n","Epoch 26, Train Loss: 0.5664, Val Loss: 0.5519, F1 Micro: 0.7000, F1 Macro: 0.6952, Accuracy: 0.7000\n","Epoch 27, Train Loss: 0.5645, Val Loss: 0.5545, F1 Micro: 0.6781, F1 Macro: 0.6765, Accuracy: 0.6781\n","Epoch 28, Train Loss: 0.5680, Val Loss: 0.5544, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 29, Train Loss: 0.5673, Val Loss: 0.5615, F1 Micro: 0.7250, F1 Macro: 0.7135, Accuracy: 0.7250\n","Epoch 30, Train Loss: 0.5691, Val Loss: 0.5644, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 31, Train Loss: 0.5701, Val Loss: 0.5473, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 32, Train Loss: 0.5688, Val Loss: 0.5476, F1 Micro: 0.6875, F1 Macro: 0.6843, Accuracy: 0.6875\n","Epoch 33, Train Loss: 0.5644, Val Loss: 0.5537, F1 Micro: 0.7031, F1 Macro: 0.6977, Accuracy: 0.7031\n","Epoch 34, Train Loss: 0.5641, Val Loss: 0.5869, F1 Micro: 0.6656, F1 Macro: 0.6642, Accuracy: 0.6656\n","Epoch 35, Train Loss: 0.5724, Val Loss: 0.5494, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 36, Train Loss: 0.5606, Val Loss: 0.5742, F1 Micro: 0.6844, F1 Macro: 0.6824, Accuracy: 0.6844\n","Epoch 37, Train Loss: 0.5659, Val Loss: 0.5563, F1 Micro: 0.6813, F1 Macro: 0.6794, Accuracy: 0.6813\n","Epoch 38, Train Loss: 0.5645, Val Loss: 0.5540, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 39, Train Loss: 0.5593, Val Loss: 0.5449, F1 Micro: 0.6937, F1 Macro: 0.6889, Accuracy: 0.6937\n","Epoch 40, Train Loss: 0.5585, Val Loss: 0.6029, F1 Micro: 0.6687, F1 Macro: 0.6611, Accuracy: 0.6687\n","Epoch 41, Train Loss: 0.5596, Val Loss: 0.5482, F1 Micro: 0.6844, F1 Macro: 0.6810, Accuracy: 0.6844\n","Epoch 42, Train Loss: 0.5599, Val Loss: 0.5446, F1 Micro: 0.6781, F1 Macro: 0.6761, Accuracy: 0.6781\n","Epoch 43, Train Loss: 0.5569, Val Loss: 0.5657, F1 Micro: 0.7156, F1 Macro: 0.6972, Accuracy: 0.7156\n","Epoch 44, Train Loss: 0.5566, Val Loss: 0.5469, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 45, Train Loss: 0.5715, Val Loss: 0.5535, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 46, Train Loss: 0.5649, Val Loss: 0.5494, F1 Micro: 0.6813, F1 Macro: 0.6780, Accuracy: 0.6813\n","Epoch 47, Train Loss: 0.5622, Val Loss: 0.5451, F1 Micro: 0.6875, F1 Macro: 0.6839, Accuracy: 0.6875\n","Epoch 48, Train Loss: 0.5613, Val Loss: 0.5436, F1 Micro: 0.7000, F1 Macro: 0.6942, Accuracy: 0.7000\n","Epoch 49, Train Loss: 0.5586, Val Loss: 0.5439, F1 Micro: 0.6844, F1 Macro: 0.6818, Accuracy: 0.6844\n","Epoch 50, Train Loss: 0.5611, Val Loss: 0.5394, F1 Micro: 0.7063, F1 Macro: 0.7001, Accuracy: 0.7063\n","Epoch 51, Train Loss: 0.5581, Val Loss: 0.5469, F1 Micro: 0.6844, F1 Macro: 0.6837, Accuracy: 0.6844\n","Epoch 52, Train Loss: 0.5543, Val Loss: 0.5421, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 53, Train Loss: 0.5561, Val Loss: 0.5405, F1 Micro: 0.6937, F1 Macro: 0.6933, Accuracy: 0.6937\n","Epoch 54, Train Loss: 0.5516, Val Loss: 0.5370, F1 Micro: 0.7063, F1 Macro: 0.7001, Accuracy: 0.7063\n","Epoch 55, Train Loss: 0.5601, Val Loss: 0.5372, F1 Micro: 0.6906, F1 Macro: 0.6873, Accuracy: 0.6906\n","Epoch 56, Train Loss: 0.5571, Val Loss: 0.5491, F1 Micro: 0.7156, F1 Macro: 0.7049, Accuracy: 0.7156\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6518, Val Loss: 0.6043, F1 Micro: 0.6625, F1 Macro: 0.6510, Accuracy: 0.6625\n","Epoch 2, Train Loss: 0.5757, Val Loss: 0.6172, F1 Micro: 0.6750, F1 Macro: 0.6747, Accuracy: 0.6750\n","Epoch 3, Train Loss: 0.5677, Val Loss: 0.6112, F1 Micro: 0.6750, F1 Macro: 0.6735, Accuracy: 0.6750\n","Epoch 4, Train Loss: 0.5725, Val Loss: 0.6204, F1 Micro: 0.6562, F1 Macro: 0.6410, Accuracy: 0.6562\n","Epoch 5, Train Loss: 0.5697, Val Loss: 0.6560, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 6, Train Loss: 0.5746, Val Loss: 0.6163, F1 Micro: 0.6562, F1 Macro: 0.6419, Accuracy: 0.6562\n","Epoch 7, Train Loss: 0.5664, Val Loss: 0.6423, F1 Micro: 0.6344, F1 Macro: 0.6309, Accuracy: 0.6344\n","Epoch 8, Train Loss: 0.5577, Val Loss: 0.6323, F1 Micro: 0.6625, F1 Macro: 0.6617, Accuracy: 0.6625\n","Epoch 9, Train Loss: 0.5675, Val Loss: 0.6104, F1 Micro: 0.6687, F1 Macro: 0.6683, Accuracy: 0.6687\n","Epoch 10, Train Loss: 0.5716, Val Loss: 0.6111, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 11, Train Loss: 0.5693, Val Loss: 0.6053, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 12, Train Loss: 0.5576, Val Loss: 0.6579, F1 Micro: 0.6344, F1 Macro: 0.6277, Accuracy: 0.6344\n","Epoch 13, Train Loss: 0.5614, Val Loss: 0.6214, F1 Micro: 0.6687, F1 Macro: 0.6681, Accuracy: 0.6687\n","Epoch 14, Train Loss: 0.5660, Val Loss: 0.6304, F1 Micro: 0.6344, F1 Macro: 0.6304, Accuracy: 0.6344\n","Epoch 15, Train Loss: 0.5655, Val Loss: 0.7281, F1 Micro: 0.6219, F1 Macro: 0.6011, Accuracy: 0.6219\n","Epoch 16, Train Loss: 0.5662, Val Loss: 0.6383, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 17, Train Loss: 0.5518, Val Loss: 0.6485, F1 Micro: 0.6375, F1 Macro: 0.6343, Accuracy: 0.6375\n","Epoch 18, Train Loss: 0.5648, Val Loss: 0.6021, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 19, Train Loss: 0.5579, Val Loss: 0.6103, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 20, Train Loss: 0.5554, Val Loss: 0.6281, F1 Micro: 0.6438, F1 Macro: 0.6417, Accuracy: 0.6438\n","Epoch 21, Train Loss: 0.5555, Val Loss: 0.6238, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 22, Train Loss: 0.5546, Val Loss: 0.6005, F1 Micro: 0.6562, F1 Macro: 0.6556, Accuracy: 0.6562\n","Epoch 23, Train Loss: 0.5541, Val Loss: 0.6405, F1 Micro: 0.6344, F1 Macro: 0.6309, Accuracy: 0.6344\n","Epoch 24, Train Loss: 0.5525, Val Loss: 0.6143, F1 Micro: 0.6625, F1 Macro: 0.6622, Accuracy: 0.6625\n","Epoch 25, Train Loss: 0.5557, Val Loss: 0.6212, F1 Micro: 0.6562, F1 Macro: 0.6556, Accuracy: 0.6562\n","Epoch 26, Train Loss: 0.5607, Val Loss: 0.6881, F1 Micro: 0.6156, F1 Macro: 0.6064, Accuracy: 0.6156\n","Epoch 27, Train Loss: 0.5488, Val Loss: 0.5997, F1 Micro: 0.6500, F1 Macro: 0.6433, Accuracy: 0.6500\n","Epoch 28, Train Loss: 0.5543, Val Loss: 0.6075, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 29, Train Loss: 0.5585, Val Loss: 0.6083, F1 Micro: 0.6625, F1 Macro: 0.6620, Accuracy: 0.6625\n","Epoch 30, Train Loss: 0.5532, Val Loss: 0.6267, F1 Micro: 0.6406, F1 Macro: 0.6372, Accuracy: 0.6406\n","Epoch 31, Train Loss: 0.5560, Val Loss: 0.6040, F1 Micro: 0.6750, F1 Macro: 0.6737, Accuracy: 0.6750\n","Epoch 32, Train Loss: 0.5542, Val Loss: 0.6086, F1 Micro: 0.6531, F1 Macro: 0.6529, Accuracy: 0.6531\n","Epoch 33, Train Loss: 0.5597, Val Loss: 0.6561, F1 Micro: 0.6344, F1 Macro: 0.6309, Accuracy: 0.6344\n","Epoch 34, Train Loss: 0.5558, Val Loss: 0.6080, F1 Micro: 0.6344, F1 Macro: 0.6321, Accuracy: 0.6344\n","Epoch 35, Train Loss: 0.5508, Val Loss: 0.6297, F1 Micro: 0.6312, F1 Macro: 0.6275, Accuracy: 0.6312\n","Epoch 36, Train Loss: 0.5513, Val Loss: 0.6126, F1 Micro: 0.6531, F1 Macro: 0.6519, Accuracy: 0.6531\n","Epoch 37, Train Loss: 0.5484, Val Loss: 0.6177, F1 Micro: 0.6531, F1 Macro: 0.6529, Accuracy: 0.6531\n","Epoch 38, Train Loss: 0.5478, Val Loss: 0.5979, F1 Micro: 0.6594, F1 Macro: 0.6588, Accuracy: 0.6594\n","Epoch 39, Train Loss: 0.5556, Val Loss: 0.5999, F1 Micro: 0.6562, F1 Macro: 0.6536, Accuracy: 0.6562\n","Epoch 40, Train Loss: 0.5526, Val Loss: 0.5817, F1 Micro: 0.6594, F1 Macro: 0.6569, Accuracy: 0.6594\n","Epoch 41, Train Loss: 0.5444, Val Loss: 0.5829, F1 Micro: 0.6594, F1 Macro: 0.6525, Accuracy: 0.6594\n","Epoch 42, Train Loss: 0.5466, Val Loss: 0.5842, F1 Micro: 0.6562, F1 Macro: 0.6528, Accuracy: 0.6562\n","Epoch 43, Train Loss: 0.5469, Val Loss: 0.6407, F1 Micro: 0.6312, F1 Macro: 0.6275, Accuracy: 0.6312\n","Epoch 44, Train Loss: 0.5496, Val Loss: 0.5919, F1 Micro: 0.6625, F1 Macro: 0.6619, Accuracy: 0.6625\n","Epoch 45, Train Loss: 0.5433, Val Loss: 0.5847, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 46, Train Loss: 0.5451, Val Loss: 0.5922, F1 Micro: 0.6562, F1 Macro: 0.6469, Accuracy: 0.6562\n","Epoch 47, Train Loss: 0.5502, Val Loss: 0.5953, F1 Micro: 0.6719, F1 Macro: 0.6705, Accuracy: 0.6719\n","Epoch 48, Train Loss: 0.5484, Val Loss: 0.6056, F1 Micro: 0.6531, F1 Macro: 0.6529, Accuracy: 0.6531\n","Epoch 49, Train Loss: 0.5464, Val Loss: 0.6152, F1 Micro: 0.6375, F1 Macro: 0.6347, Accuracy: 0.6375\n","Epoch 50, Train Loss: 0.5517, Val Loss: 0.5872, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 51, Train Loss: 0.5547, Val Loss: 0.5883, F1 Micro: 0.6531, F1 Macro: 0.6527, Accuracy: 0.6531\n","Epoch 52, Train Loss: 0.5518, Val Loss: 0.5818, F1 Micro: 0.6594, F1 Macro: 0.6557, Accuracy: 0.6594\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6351, Val Loss: 0.5317, F1 Micro: 0.7125, F1 Macro: 0.7122, Accuracy: 0.7125\n","Epoch 2, Train Loss: 0.6002, Val Loss: 0.5320, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 3, Train Loss: 0.6014, Val Loss: 0.5315, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 4, Train Loss: 0.5900, Val Loss: 0.5337, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 5, Train Loss: 0.5866, Val Loss: 0.5393, F1 Micro: 0.7031, F1 Macro: 0.7029, Accuracy: 0.7031\n","Epoch 6, Train Loss: 0.5970, Val Loss: 0.5354, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 7, Train Loss: 0.5899, Val Loss: 0.5301, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 8, Train Loss: 0.5838, Val Loss: 0.5317, F1 Micro: 0.7438, F1 Macro: 0.7420, Accuracy: 0.7438\n","Epoch 9, Train Loss: 0.5821, Val Loss: 0.5603, F1 Micro: 0.6969, F1 Macro: 0.6936, Accuracy: 0.6969\n","Epoch 10, Train Loss: 0.5850, Val Loss: 0.5359, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 11, Train Loss: 0.5810, Val Loss: 0.6094, F1 Micro: 0.6906, F1 Macro: 0.6659, Accuracy: 0.6906\n","Epoch 12, Train Loss: 0.5950, Val Loss: 0.5294, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Epoch 13, Train Loss: 0.5779, Val Loss: 0.5375, F1 Micro: 0.6937, F1 Macro: 0.6935, Accuracy: 0.6937\n","Epoch 14, Train Loss: 0.5792, Val Loss: 0.5303, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 15, Train Loss: 0.5828, Val Loss: 0.5361, F1 Micro: 0.7406, F1 Macro: 0.7363, Accuracy: 0.7406\n","Epoch 16, Train Loss: 0.5805, Val Loss: 0.5276, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 17, Train Loss: 0.5754, Val Loss: 0.5258, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 18, Train Loss: 0.5737, Val Loss: 0.5704, F1 Micro: 0.6906, F1 Macro: 0.6855, Accuracy: 0.6906\n","Epoch 19, Train Loss: 0.5779, Val Loss: 0.5554, F1 Micro: 0.6875, F1 Macro: 0.6847, Accuracy: 0.6875\n","Epoch 20, Train Loss: 0.5745, Val Loss: 0.5705, F1 Micro: 0.6937, F1 Macro: 0.6889, Accuracy: 0.6937\n","Epoch 21, Train Loss: 0.5766, Val Loss: 0.5350, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 22, Train Loss: 0.5786, Val Loss: 0.5316, F1 Micro: 0.7406, F1 Macro: 0.7382, Accuracy: 0.7406\n","Epoch 23, Train Loss: 0.5834, Val Loss: 0.5312, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 24, Train Loss: 0.5691, Val Loss: 0.5226, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 25, Train Loss: 0.5682, Val Loss: 0.5363, F1 Micro: 0.7312, F1 Macro: 0.7234, Accuracy: 0.7312\n","Epoch 26, Train Loss: 0.5767, Val Loss: 0.5208, F1 Micro: 0.7063, F1 Macro: 0.7058, Accuracy: 0.7063\n","Epoch 27, Train Loss: 0.5722, Val Loss: 0.5370, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 28, Train Loss: 0.5658, Val Loss: 0.5220, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 29, Train Loss: 0.5678, Val Loss: 0.5400, F1 Micro: 0.7031, F1 Macro: 0.7021, Accuracy: 0.7031\n","Epoch 30, Train Loss: 0.5654, Val Loss: 0.5372, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 31, Train Loss: 0.5722, Val Loss: 0.5222, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 32, Train Loss: 0.5702, Val Loss: 0.5309, F1 Micro: 0.7344, F1 Macro: 0.7269, Accuracy: 0.7344\n","Epoch 33, Train Loss: 0.5758, Val Loss: 0.5255, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 34, Train Loss: 0.5668, Val Loss: 0.5236, F1 Micro: 0.7125, F1 Macro: 0.7121, Accuracy: 0.7125\n","Epoch 35, Train Loss: 0.5659, Val Loss: 0.5188, F1 Micro: 0.7375, F1 Macro: 0.7360, Accuracy: 0.7375\n","Epoch 36, Train Loss: 0.5658, Val Loss: 0.5189, F1 Micro: 0.7281, F1 Macro: 0.7267, Accuracy: 0.7281\n","Epoch 37, Train Loss: 0.5645, Val Loss: 0.5184, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Epoch 38, Train Loss: 0.5707, Val Loss: 0.5213, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 39, Train Loss: 0.5619, Val Loss: 0.5696, F1 Micro: 0.7063, F1 Macro: 0.6867, Accuracy: 0.7063\n","Epoch 40, Train Loss: 0.5691, Val Loss: 0.5494, F1 Micro: 0.7281, F1 Macro: 0.7132, Accuracy: 0.7281\n","Epoch 41, Train Loss: 0.5725, Val Loss: 0.5240, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 42, Train Loss: 0.5651, Val Loss: 0.5417, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 43, Train Loss: 0.5632, Val Loss: 0.5315, F1 Micro: 0.7438, F1 Macro: 0.7420, Accuracy: 0.7438\n","Epoch 44, Train Loss: 0.5618, Val Loss: 0.5487, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 45, Train Loss: 0.5650, Val Loss: 0.5143, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 46, Train Loss: 0.5736, Val Loss: 0.5179, F1 Micro: 0.7344, F1 Macro: 0.7315, Accuracy: 0.7344\n","Epoch 47, Train Loss: 0.5653, Val Loss: 0.5171, F1 Micro: 0.7438, F1 Macro: 0.7401, Accuracy: 0.7438\n","Epoch 48, Train Loss: 0.5647, Val Loss: 0.5393, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 49, Train Loss: 0.5614, Val Loss: 0.5146, F1 Micro: 0.7469, F1 Macro: 0.7453, Accuracy: 0.7469\n","Epoch 50, Train Loss: 0.5696, Val Loss: 0.5311, F1 Micro: 0.7188, F1 Macro: 0.7078, Accuracy: 0.7188\n","Epoch 51, Train Loss: 0.5620, Val Loss: 0.5132, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 52, Train Loss: 0.5621, Val Loss: 0.5226, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 53, Train Loss: 0.5589, Val Loss: 0.5235, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 54, Train Loss: 0.5612, Val Loss: 0.5243, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 55, Train Loss: 0.5535, Val Loss: 0.5283, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 56, Train Loss: 0.5587, Val Loss: 0.5140, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 57, Train Loss: 0.5565, Val Loss: 0.5266, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 58, Train Loss: 0.5581, Val Loss: 0.5085, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 59, Train Loss: 0.5538, Val Loss: 0.5127, F1 Micro: 0.7094, F1 Macro: 0.7090, Accuracy: 0.7094\n","Epoch 60, Train Loss: 0.5486, Val Loss: 0.5182, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 61, Train Loss: 0.5560, Val Loss: 0.5192, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 62, Train Loss: 0.5519, Val Loss: 0.5353, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Epoch 63, Train Loss: 0.5602, Val Loss: 0.5104, F1 Micro: 0.7531, F1 Macro: 0.7498, Accuracy: 0.7531\n","Epoch 64, Train Loss: 0.5546, Val Loss: 0.5115, F1 Micro: 0.7094, F1 Macro: 0.7091, Accuracy: 0.7094\n","Epoch 65, Train Loss: 0.5502, Val Loss: 0.5179, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 66, Train Loss: 0.5540, Val Loss: 0.5109, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 67, Train Loss: 0.5550, Val Loss: 0.5066, F1 Micro: 0.7531, F1 Macro: 0.7490, Accuracy: 0.7531\n","Epoch 68, Train Loss: 0.5533, Val Loss: 0.5378, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 69, Train Loss: 0.5519, Val Loss: 0.5179, F1 Micro: 0.7219, F1 Macro: 0.7219, Accuracy: 0.7219\n","Epoch 70, Train Loss: 0.5538, Val Loss: 0.5118, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 71, Train Loss: 0.5475, Val Loss: 0.5016, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 72, Train Loss: 0.5475, Val Loss: 0.5048, F1 Micro: 0.7125, F1 Macro: 0.7122, Accuracy: 0.7125\n","Epoch 73, Train Loss: 0.5497, Val Loss: 0.5127, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 74, Train Loss: 0.5472, Val Loss: 0.5480, F1 Micro: 0.7125, F1 Macro: 0.7111, Accuracy: 0.7125\n","Epoch 75, Train Loss: 0.5477, Val Loss: 0.5066, F1 Micro: 0.7344, F1 Macro: 0.7263, Accuracy: 0.7344\n","Epoch 76, Train Loss: 0.5518, Val Loss: 0.5084, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 77, Train Loss: 0.5489, Val Loss: 0.5224, F1 Micro: 0.7250, F1 Macro: 0.7249, Accuracy: 0.7250\n","Epoch 78, Train Loss: 0.5403, Val Loss: 0.4954, F1 Micro: 0.7531, F1 Macro: 0.7494, Accuracy: 0.7531\n","Epoch 79, Train Loss: 0.5435, Val Loss: 0.4953, F1 Micro: 0.7375, F1 Macro: 0.7363, Accuracy: 0.7375\n","Epoch 80, Train Loss: 0.5457, Val Loss: 0.5124, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 81, Train Loss: 0.5462, Val Loss: 0.4986, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 82, Train Loss: 0.5447, Val Loss: 0.5020, F1 Micro: 0.7625, F1 Macro: 0.7591, Accuracy: 0.7625\n","Epoch 83, Train Loss: 0.5468, Val Loss: 0.5121, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 84, Train Loss: 0.5438, Val Loss: 0.4986, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 85, Train Loss: 0.5476, Val Loss: 0.4962, F1 Micro: 0.7281, F1 Macro: 0.7274, Accuracy: 0.7281\n","Epoch 86, Train Loss: 0.5446, Val Loss: 0.5217, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 87, Train Loss: 0.5338, Val Loss: 0.5230, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 88, Train Loss: 0.5441, Val Loss: 0.4985, F1 Micro: 0.7625, F1 Macro: 0.7555, Accuracy: 0.7625\n","Epoch 89, Train Loss: 0.5348, Val Loss: 0.4945, F1 Micro: 0.7562, F1 Macro: 0.7535, Accuracy: 0.7562\n","Epoch 90, Train Loss: 0.5376, Val Loss: 0.4906, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 91, Train Loss: 0.5489, Val Loss: 0.5014, F1 Micro: 0.7562, F1 Macro: 0.7502, Accuracy: 0.7562\n","Epoch 92, Train Loss: 0.5439, Val Loss: 0.5126, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 93, Train Loss: 0.5426, Val Loss: 0.4975, F1 Micro: 0.7594, F1 Macro: 0.7521, Accuracy: 0.7594\n","Epoch 94, Train Loss: 0.5475, Val Loss: 0.5535, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 95, Train Loss: 0.5357, Val Loss: 0.5275, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 96, Train Loss: 0.5345, Val Loss: 0.5751, F1 Micro: 0.6969, F1 Macro: 0.6913, Accuracy: 0.6969\n","Epoch 97, Train Loss: 0.5478, Val Loss: 0.4993, F1 Micro: 0.7781, F1 Macro: 0.7703, Accuracy: 0.7781\n","Epoch 98, Train Loss: 0.5432, Val Loss: 0.5532, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 99, Train Loss: 0.5359, Val Loss: 0.5002, F1 Micro: 0.7469, F1 Macro: 0.7462, Accuracy: 0.7469\n","Epoch 100, Train Loss: 0.5370, Val Loss: 0.5014, F1 Micro: 0.7438, F1 Macro: 0.7431, Accuracy: 0.7438\n","Epoch 101, Train Loss: 0.5383, Val Loss: 0.4912, F1 Micro: 0.7312, F1 Macro: 0.7302, Accuracy: 0.7312\n","Epoch 102, Train Loss: 0.5394, Val Loss: 0.4863, F1 Micro: 0.7594, F1 Macro: 0.7557, Accuracy: 0.7594\n","Epoch 103, Train Loss: 0.5322, Val Loss: 0.4836, F1 Micro: 0.7531, F1 Macro: 0.7501, Accuracy: 0.7531\n","Epoch 104, Train Loss: 0.5342, Val Loss: 0.4868, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 105, Train Loss: 0.5400, Val Loss: 0.4856, F1 Micro: 0.7344, F1 Macro: 0.7334, Accuracy: 0.7344\n","Epoch 106, Train Loss: 0.5282, Val Loss: 0.5047, F1 Micro: 0.7500, F1 Macro: 0.7333, Accuracy: 0.7500\n","Epoch 107, Train Loss: 0.5273, Val Loss: 0.4984, F1 Micro: 0.7562, F1 Macro: 0.7531, Accuracy: 0.7562\n","Epoch 108, Train Loss: 0.5344, Val Loss: 0.4842, F1 Micro: 0.7375, F1 Macro: 0.7367, Accuracy: 0.7375\n","Epoch 109, Train Loss: 0.5358, Val Loss: 0.4852, F1 Micro: 0.7688, F1 Macro: 0.7609, Accuracy: 0.7688\n","Epoch 110, Train Loss: 0.5167, Val Loss: 0.5061, F1 Micro: 0.7719, F1 Macro: 0.7563, Accuracy: 0.7719\n","Epoch 111, Train Loss: 0.5233, Val Loss: 0.4984, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 112, Train Loss: 0.5327, Val Loss: 0.4804, F1 Micro: 0.7750, F1 Macro: 0.7707, Accuracy: 0.7750\n","Epoch 113, Train Loss: 0.5240, Val Loss: 0.4811, F1 Micro: 0.7438, F1 Macro: 0.7425, Accuracy: 0.7438\n","Epoch 114, Train Loss: 0.5267, Val Loss: 0.4732, F1 Micro: 0.7688, F1 Macro: 0.7647, Accuracy: 0.7688\n","Epoch 115, Train Loss: 0.5227, Val Loss: 0.5074, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 116, Train Loss: 0.5376, Val Loss: 0.5452, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 117, Train Loss: 0.5293, Val Loss: 0.4826, F1 Micro: 0.7750, F1 Macro: 0.7684, Accuracy: 0.7750\n","Epoch 118, Train Loss: 0.5247, Val Loss: 0.4803, F1 Micro: 0.7469, F1 Macro: 0.7458, Accuracy: 0.7469\n","Epoch 119, Train Loss: 0.5245, Val Loss: 0.4983, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 120, Train Loss: 0.5263, Val Loss: 0.4730, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 121, Train Loss: 0.5240, Val Loss: 0.4818, F1 Micro: 0.7531, F1 Macro: 0.7505, Accuracy: 0.7531\n","Epoch 122, Train Loss: 0.5316, Val Loss: 0.4731, F1 Micro: 0.7500, F1 Macro: 0.7486, Accuracy: 0.7500\n","Epoch 123, Train Loss: 0.5206, Val Loss: 0.4861, F1 Micro: 0.7594, F1 Macro: 0.7446, Accuracy: 0.7594\n","Epoch 124, Train Loss: 0.5247, Val Loss: 0.4891, F1 Micro: 0.7531, F1 Macro: 0.7530, Accuracy: 0.7531\n","Epoch 125, Train Loss: 0.5246, Val Loss: 0.4901, F1 Micro: 0.7406, F1 Macro: 0.7405, Accuracy: 0.7406\n","Epoch 126, Train Loss: 0.5296, Val Loss: 0.4713, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 127, Train Loss: 0.5287, Val Loss: 0.4748, F1 Micro: 0.7438, F1 Macro: 0.7427, Accuracy: 0.7438\n","Epoch 128, Train Loss: 0.5198, Val Loss: 0.4681, F1 Micro: 0.7688, F1 Macro: 0.7639, Accuracy: 0.7688\n","Epoch 129, Train Loss: 0.5286, Val Loss: 0.4804, F1 Micro: 0.7531, F1 Macro: 0.7501, Accuracy: 0.7531\n","Epoch 130, Train Loss: 0.5284, Val Loss: 0.4745, F1 Micro: 0.7438, F1 Macro: 0.7427, Accuracy: 0.7438\n","Epoch 131, Train Loss: 0.5197, Val Loss: 0.5340, F1 Micro: 0.7531, F1 Macro: 0.7526, Accuracy: 0.7531\n","Epoch 132, Train Loss: 0.5186, Val Loss: 0.4706, F1 Micro: 0.7500, F1 Macro: 0.7475, Accuracy: 0.7500\n","Epoch 133, Train Loss: 0.5340, Val Loss: 0.4760, F1 Micro: 0.7844, F1 Macro: 0.7751, Accuracy: 0.7844\n","Epoch 134, Train Loss: 0.5258, Val Loss: 0.5084, F1 Micro: 0.7562, F1 Macro: 0.7561, Accuracy: 0.7562\n","Epoch 135, Train Loss: 0.5278, Val Loss: 0.4757, F1 Micro: 0.7781, F1 Macro: 0.7714, Accuracy: 0.7781\n","Epoch 136, Train Loss: 0.5162, Val Loss: 0.4687, F1 Micro: 0.7531, F1 Macro: 0.7518, Accuracy: 0.7531\n","Epoch 137, Train Loss: 0.5264, Val Loss: 0.4792, F1 Micro: 0.7562, F1 Macro: 0.7425, Accuracy: 0.7562\n","Epoch 138, Train Loss: 0.5266, Val Loss: 0.4714, F1 Micro: 0.7719, F1 Macro: 0.7627, Accuracy: 0.7719\n","Epoch 139, Train Loss: 0.5128, Val Loss: 0.4914, F1 Micro: 0.7562, F1 Macro: 0.7562, Accuracy: 0.7562\n","Epoch 140, Train Loss: 0.5251, Val Loss: 0.4715, F1 Micro: 0.7625, F1 Macro: 0.7616, Accuracy: 0.7625\n","Epoch 141, Train Loss: 0.5290, Val Loss: 0.4805, F1 Micro: 0.7844, F1 Macro: 0.7838, Accuracy: 0.7844\n","Epoch 142, Train Loss: 0.5206, Val Loss: 0.4832, F1 Micro: 0.7656, F1 Macro: 0.7653, Accuracy: 0.7656\n","Epoch 143, Train Loss: 0.4998, Val Loss: 0.4629, F1 Micro: 0.7688, F1 Macro: 0.7651, Accuracy: 0.7688\n","Epoch 144, Train Loss: 0.5187, Val Loss: 0.4668, F1 Micro: 0.7625, F1 Macro: 0.7617, Accuracy: 0.7625\n","Epoch 145, Train Loss: 0.5171, Val Loss: 0.4864, F1 Micro: 0.7594, F1 Macro: 0.7594, Accuracy: 0.7594\n","Epoch 146, Train Loss: 0.5090, Val Loss: 0.4791, F1 Micro: 0.7875, F1 Macro: 0.7874, Accuracy: 0.7875\n","Epoch 147, Train Loss: 0.5187, Val Loss: 0.4808, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 148, Train Loss: 0.5161, Val Loss: 0.4916, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 149, Train Loss: 0.5161, Val Loss: 0.4620, F1 Micro: 0.7844, F1 Macro: 0.7783, Accuracy: 0.7844\n","Epoch 150, Train Loss: 0.5131, Val Loss: 0.4645, F1 Micro: 0.7469, F1 Macro: 0.7451, Accuracy: 0.7469\n","Epoch 151, Train Loss: 0.5119, Val Loss: 0.4653, F1 Micro: 0.7594, F1 Macro: 0.7585, Accuracy: 0.7594\n","Epoch 152, Train Loss: 0.5175, Val Loss: 0.4579, F1 Micro: 0.7531, F1 Macro: 0.7501, Accuracy: 0.7531\n","Epoch 153, Train Loss: 0.5161, Val Loss: 0.4635, F1 Micro: 0.7719, F1 Macro: 0.7627, Accuracy: 0.7719\n","Epoch 154, Train Loss: 0.5086, Val Loss: 0.4581, F1 Micro: 0.7562, F1 Macro: 0.7528, Accuracy: 0.7562\n","Epoch 155, Train Loss: 0.5151, Val Loss: 0.5109, F1 Micro: 0.7719, F1 Macro: 0.7715, Accuracy: 0.7719\n","Epoch 156, Train Loss: 0.5173, Val Loss: 0.4895, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 157, Train Loss: 0.5215, Val Loss: 0.4583, F1 Micro: 0.7625, F1 Macro: 0.7561, Accuracy: 0.7625\n","Epoch 158, Train Loss: 0.5112, Val Loss: 0.4644, F1 Micro: 0.7594, F1 Macro: 0.7585, Accuracy: 0.7594\n","Epoch 159, Train Loss: 0.5127, Val Loss: 0.5081, F1 Micro: 0.7750, F1 Macro: 0.7746, Accuracy: 0.7750\n","Epoch 160, Train Loss: 0.5212, Val Loss: 0.5219, F1 Micro: 0.7688, F1 Macro: 0.7683, Accuracy: 0.7688\n","Epoch 161, Train Loss: 0.5189, Val Loss: 0.4652, F1 Micro: 0.7812, F1 Macro: 0.7738, Accuracy: 0.7812\n","Epoch 162, Train Loss: 0.5150, Val Loss: 0.4554, F1 Micro: 0.7688, F1 Macro: 0.7647, Accuracy: 0.7688\n","Epoch 163, Train Loss: 0.5060, Val Loss: 0.4729, F1 Micro: 0.7562, F1 Macro: 0.7556, Accuracy: 0.7562\n","Epoch 164, Train Loss: 0.5109, Val Loss: 0.4778, F1 Micro: 0.7531, F1 Macro: 0.7529, Accuracy: 0.7531\n","Epoch 165, Train Loss: 0.5120, Val Loss: 0.4717, F1 Micro: 0.7875, F1 Macro: 0.7748, Accuracy: 0.7875\n","Epoch 166, Train Loss: 0.5195, Val Loss: 0.4705, F1 Micro: 0.7562, F1 Macro: 0.7558, Accuracy: 0.7562\n","Epoch 167, Train Loss: 0.5189, Val Loss: 0.4569, F1 Micro: 0.7688, F1 Macro: 0.7609, Accuracy: 0.7688\n","Epoch 168, Train Loss: 0.5198, Val Loss: 0.4978, F1 Micro: 0.7656, F1 Macro: 0.7655, Accuracy: 0.7656\n","Epoch 169, Train Loss: 0.5160, Val Loss: 0.4657, F1 Micro: 0.7594, F1 Macro: 0.7588, Accuracy: 0.7594\n","Epoch 170, Train Loss: 0.5058, Val Loss: 0.4622, F1 Micro: 0.7719, F1 Macro: 0.7654, Accuracy: 0.7719\n","Epoch 171, Train Loss: 0.5158, Val Loss: 0.4668, F1 Micro: 0.7594, F1 Macro: 0.7587, Accuracy: 0.7594\n","Epoch 172, Train Loss: 0.5069, Val Loss: 0.4618, F1 Micro: 0.7750, F1 Macro: 0.7741, Accuracy: 0.7750\n","Epoch 173, Train Loss: 0.4967, Val Loss: 0.4772, F1 Micro: 0.7844, F1 Macro: 0.7844, Accuracy: 0.7844\n","Epoch 174, Train Loss: 0.5018, Val Loss: 0.4552, F1 Micro: 0.7906, F1 Macro: 0.7833, Accuracy: 0.7906\n","Epoch 175, Train Loss: 0.5127, Val Loss: 0.4526, F1 Micro: 0.7719, F1 Macro: 0.7649, Accuracy: 0.7719\n","Epoch 176, Train Loss: 0.5100, Val Loss: 0.4512, F1 Micro: 0.7594, F1 Macro: 0.7557, Accuracy: 0.7594\n","Epoch 177, Train Loss: 0.5063, Val Loss: 0.4815, F1 Micro: 0.7594, F1 Macro: 0.7592, Accuracy: 0.7594\n","Epoch 178, Train Loss: 0.5111, Val Loss: 0.4603, F1 Micro: 0.7719, F1 Macro: 0.7711, Accuracy: 0.7719\n","Epoch 179, Train Loss: 0.5014, Val Loss: 0.4661, F1 Micro: 0.7531, F1 Macro: 0.7521, Accuracy: 0.7531\n","Epoch 180, Train Loss: 0.4957, Val Loss: 0.4716, F1 Micro: 0.7594, F1 Macro: 0.7588, Accuracy: 0.7594\n","Epoch 181, Train Loss: 0.5115, Val Loss: 0.4647, F1 Micro: 0.7625, F1 Macro: 0.7622, Accuracy: 0.7625\n","Epoch 182, Train Loss: 0.5194, Val Loss: 0.4531, F1 Micro: 0.7688, F1 Macro: 0.7614, Accuracy: 0.7688\n","Epoch 183, Train Loss: 0.5099, Val Loss: 0.4537, F1 Micro: 0.7719, F1 Macro: 0.7664, Accuracy: 0.7719\n","Epoch 184, Train Loss: 0.5139, Val Loss: 0.4606, F1 Micro: 0.7500, F1 Macro: 0.7486, Accuracy: 0.7500\n","Epoch 185, Train Loss: 0.5024, Val Loss: 0.4787, F1 Micro: 0.7719, F1 Macro: 0.7563, Accuracy: 0.7719\n","Epoch 186, Train Loss: 0.5113, Val Loss: 0.5010, F1 Micro: 0.7781, F1 Macro: 0.7778, Accuracy: 0.7781\n","Epoch 187, Train Loss: 0.5053, Val Loss: 0.4604, F1 Micro: 0.7469, F1 Macro: 0.7453, Accuracy: 0.7469\n","Epoch 188, Train Loss: 0.5124, Val Loss: 0.4591, F1 Micro: 0.7625, F1 Macro: 0.7617, Accuracy: 0.7625\n","Epoch 189, Train Loss: 0.5027, Val Loss: 0.4492, F1 Micro: 0.7562, F1 Macro: 0.7535, Accuracy: 0.7562\n","Epoch 190, Train Loss: 0.5026, Val Loss: 0.4581, F1 Micro: 0.7500, F1 Macro: 0.7478, Accuracy: 0.7500\n","Epoch 191, Train Loss: 0.5053, Val Loss: 0.4612, F1 Micro: 0.7937, F1 Macro: 0.7840, Accuracy: 0.7937\n","Epoch 192, Train Loss: 0.5019, Val Loss: 0.4537, F1 Micro: 0.7656, F1 Macro: 0.7644, Accuracy: 0.7656\n","Epoch 193, Train Loss: 0.5247, Val Loss: 0.5294, F1 Micro: 0.7656, F1 Macro: 0.7648, Accuracy: 0.7656\n","Epoch 194, Train Loss: 0.5207, Val Loss: 0.4734, F1 Micro: 0.7875, F1 Macro: 0.7826, Accuracy: 0.7875\n","Epoch 195, Train Loss: 0.5056, Val Loss: 0.4544, F1 Micro: 0.7625, F1 Macro: 0.7609, Accuracy: 0.7625\n","Epoch 196, Train Loss: 0.5126, Val Loss: 0.4808, F1 Micro: 0.7719, F1 Macro: 0.7719, Accuracy: 0.7719\n","Epoch 197, Train Loss: 0.5023, Val Loss: 0.4872, F1 Micro: 0.7906, F1 Macro: 0.7906, Accuracy: 0.7906\n","Epoch 198, Train Loss: 0.5039, Val Loss: 0.5153, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 199, Train Loss: 0.4993, Val Loss: 0.4879, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 200, Train Loss: 0.5177, Val Loss: 0.4567, F1 Micro: 0.7719, F1 Macro: 0.7688, Accuracy: 0.7719\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6362, Val Loss: 0.6357, F1 Micro: 0.6531, F1 Macro: 0.5907, Accuracy: 0.6531\n","Epoch 2, Train Loss: 0.5930, Val Loss: 0.5444, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 3, Train Loss: 0.6073, Val Loss: 0.6058, F1 Micro: 0.6781, F1 Macro: 0.6359, Accuracy: 0.6781\n","Epoch 4, Train Loss: 0.5947, Val Loss: 0.5379, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 5, Train Loss: 0.5911, Val Loss: 0.5419, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 6, Train Loss: 0.5994, Val Loss: 0.5471, F1 Micro: 0.7344, F1 Macro: 0.7322, Accuracy: 0.7344\n","Epoch 7, Train Loss: 0.5922, Val Loss: 0.5476, F1 Micro: 0.7094, F1 Macro: 0.6969, Accuracy: 0.7094\n","Epoch 8, Train Loss: 0.5792, Val Loss: 0.5450, F1 Micro: 0.7250, F1 Macro: 0.7222, Accuracy: 0.7250\n","Epoch 9, Train Loss: 0.5871, Val Loss: 0.5422, F1 Micro: 0.7125, F1 Macro: 0.7034, Accuracy: 0.7125\n","Epoch 10, Train Loss: 0.5779, Val Loss: 0.5447, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 11, Train Loss: 0.5783, Val Loss: 0.5375, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 12, Train Loss: 0.5861, Val Loss: 0.5418, F1 Micro: 0.7063, F1 Macro: 0.6932, Accuracy: 0.7063\n","Epoch 13, Train Loss: 0.5795, Val Loss: 0.5369, F1 Micro: 0.7281, F1 Macro: 0.7244, Accuracy: 0.7281\n","Epoch 14, Train Loss: 0.5724, Val Loss: 0.5354, F1 Micro: 0.7063, F1 Macro: 0.6955, Accuracy: 0.7063\n","Epoch 15, Train Loss: 0.5767, Val Loss: 0.5414, F1 Micro: 0.7281, F1 Macro: 0.7252, Accuracy: 0.7281\n","Epoch 16, Train Loss: 0.5785, Val Loss: 0.5335, F1 Micro: 0.7031, F1 Macro: 0.6927, Accuracy: 0.7031\n","Epoch 17, Train Loss: 0.5811, Val Loss: 0.5315, F1 Micro: 0.7281, F1 Macro: 0.7244, Accuracy: 0.7281\n","Epoch 18, Train Loss: 0.5723, Val Loss: 0.5418, F1 Micro: 0.7094, F1 Macro: 0.6969, Accuracy: 0.7094\n","Epoch 19, Train Loss: 0.5790, Val Loss: 0.5333, F1 Micro: 0.7250, F1 Macro: 0.7219, Accuracy: 0.7250\n","Epoch 20, Train Loss: 0.5745, Val Loss: 0.5336, F1 Micro: 0.7031, F1 Macro: 0.6927, Accuracy: 0.7031\n","Epoch 21, Train Loss: 0.5725, Val Loss: 0.5393, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 22, Train Loss: 0.5691, Val Loss: 0.5321, F1 Micro: 0.7344, F1 Macro: 0.7285, Accuracy: 0.7344\n","Epoch 23, Train Loss: 0.5685, Val Loss: 0.5455, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 24, Train Loss: 0.5699, Val Loss: 0.5343, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 25, Train Loss: 0.5691, Val Loss: 0.5434, F1 Micro: 0.7063, F1 Macro: 0.6940, Accuracy: 0.7063\n","Epoch 26, Train Loss: 0.5693, Val Loss: 0.5296, F1 Micro: 0.7250, F1 Macro: 0.7175, Accuracy: 0.7250\n","Epoch 27, Train Loss: 0.5671, Val Loss: 0.5284, F1 Micro: 0.7250, F1 Macro: 0.7219, Accuracy: 0.7250\n","Epoch 28, Train Loss: 0.5732, Val Loss: 0.5341, F1 Micro: 0.7344, F1 Macro: 0.7285, Accuracy: 0.7344\n","Epoch 29, Train Loss: 0.5637, Val Loss: 0.5575, F1 Micro: 0.6969, F1 Macro: 0.6968, Accuracy: 0.6969\n","Epoch 30, Train Loss: 0.5691, Val Loss: 0.5307, F1 Micro: 0.7281, F1 Macro: 0.7259, Accuracy: 0.7281\n","Epoch 31, Train Loss: 0.5724, Val Loss: 0.5338, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 32, Train Loss: 0.5665, Val Loss: 0.5299, F1 Micro: 0.7219, F1 Macro: 0.7185, Accuracy: 0.7219\n","Epoch 33, Train Loss: 0.5654, Val Loss: 0.5393, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 34, Train Loss: 0.5647, Val Loss: 0.5485, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 35, Train Loss: 0.5638, Val Loss: 0.5271, F1 Micro: 0.7219, F1 Macro: 0.7199, Accuracy: 0.7219\n","Epoch 36, Train Loss: 0.5633, Val Loss: 0.5314, F1 Micro: 0.7250, F1 Macro: 0.7232, Accuracy: 0.7250\n","Epoch 37, Train Loss: 0.5599, Val Loss: 0.5459, F1 Micro: 0.6969, F1 Macro: 0.6967, Accuracy: 0.6969\n","Epoch 38, Train Loss: 0.5617, Val Loss: 0.5230, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 39, Train Loss: 0.5589, Val Loss: 0.5301, F1 Micro: 0.7156, F1 Macro: 0.7148, Accuracy: 0.7156\n","Epoch 40, Train Loss: 0.5636, Val Loss: 0.5724, F1 Micro: 0.7094, F1 Macro: 0.7059, Accuracy: 0.7094\n","Epoch 41, Train Loss: 0.5669, Val Loss: 0.5240, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 42, Train Loss: 0.5649, Val Loss: 0.5224, F1 Micro: 0.7250, F1 Macro: 0.7232, Accuracy: 0.7250\n","Epoch 43, Train Loss: 0.5623, Val Loss: 0.5355, F1 Micro: 0.7125, F1 Macro: 0.6989, Accuracy: 0.7125\n","Epoch 44, Train Loss: 0.5564, Val Loss: 0.5530, F1 Micro: 0.6937, F1 Macro: 0.6928, Accuracy: 0.6937\n","Epoch 45, Train Loss: 0.5571, Val Loss: 0.5259, F1 Micro: 0.7312, F1 Macro: 0.7265, Accuracy: 0.7312\n","Epoch 46, Train Loss: 0.5530, Val Loss: 0.5248, F1 Micro: 0.7188, F1 Macro: 0.7174, Accuracy: 0.7188\n","Epoch 47, Train Loss: 0.5541, Val Loss: 0.5207, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 48, Train Loss: 0.5592, Val Loss: 0.5191, F1 Micro: 0.7250, F1 Macro: 0.7232, Accuracy: 0.7250\n","Epoch 49, Train Loss: 0.5523, Val Loss: 0.5305, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 50, Train Loss: 0.5540, Val Loss: 0.5223, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 51, Train Loss: 0.5584, Val Loss: 0.5325, F1 Micro: 0.7125, F1 Macro: 0.6997, Accuracy: 0.7125\n","Epoch 52, Train Loss: 0.5574, Val Loss: 0.5186, F1 Micro: 0.7406, F1 Macro: 0.7371, Accuracy: 0.7406\n","Epoch 53, Train Loss: 0.5544, Val Loss: 0.5286, F1 Micro: 0.7156, F1 Macro: 0.7049, Accuracy: 0.7156\n","Epoch 54, Train Loss: 0.5604, Val Loss: 0.5260, F1 Micro: 0.7125, F1 Macro: 0.7020, Accuracy: 0.7125\n","Epoch 55, Train Loss: 0.5549, Val Loss: 0.5188, F1 Micro: 0.7219, F1 Macro: 0.7185, Accuracy: 0.7219\n","Epoch 56, Train Loss: 0.5493, Val Loss: 0.5287, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 57, Train Loss: 0.5572, Val Loss: 0.5219, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 58, Train Loss: 0.5573, Val Loss: 0.5286, F1 Micro: 0.7312, F1 Macro: 0.7307, Accuracy: 0.7312\n","Epoch 59, Train Loss: 0.5481, Val Loss: 0.5416, F1 Micro: 0.7000, F1 Macro: 0.6986, Accuracy: 0.7000\n","Epoch 60, Train Loss: 0.5518, Val Loss: 0.5147, F1 Micro: 0.7312, F1 Macro: 0.7297, Accuracy: 0.7312\n","Epoch 61, Train Loss: 0.5505, Val Loss: 0.5146, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 62, Train Loss: 0.5579, Val Loss: 0.5480, F1 Micro: 0.6969, F1 Macro: 0.6944, Accuracy: 0.6969\n","Epoch 63, Train Loss: 0.5583, Val Loss: 0.5139, F1 Micro: 0.7312, F1 Macro: 0.7282, Accuracy: 0.7312\n","Epoch 64, Train Loss: 0.5523, Val Loss: 0.5211, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 65, Train Loss: 0.5496, Val Loss: 0.5172, F1 Micro: 0.7188, F1 Macro: 0.7111, Accuracy: 0.7188\n","Epoch 66, Train Loss: 0.5506, Val Loss: 0.5104, F1 Micro: 0.7312, F1 Macro: 0.7282, Accuracy: 0.7312\n","Epoch 67, Train Loss: 0.5450, Val Loss: 0.5125, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 68, Train Loss: 0.5513, Val Loss: 0.5262, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 69, Train Loss: 0.5506, Val Loss: 0.5326, F1 Micro: 0.7000, F1 Macro: 0.6994, Accuracy: 0.7000\n","Epoch 70, Train Loss: 0.5609, Val Loss: 0.5273, F1 Micro: 0.7188, F1 Macro: 0.7070, Accuracy: 0.7188\n","Epoch 71, Train Loss: 0.5471, Val Loss: 0.5136, F1 Micro: 0.7219, F1 Macro: 0.7207, Accuracy: 0.7219\n","Epoch 72, Train Loss: 0.5443, Val Loss: 0.5095, F1 Micro: 0.7312, F1 Macro: 0.7265, Accuracy: 0.7312\n","Epoch 73, Train Loss: 0.5425, Val Loss: 0.5133, F1 Micro: 0.7438, F1 Macro: 0.7405, Accuracy: 0.7438\n","Epoch 74, Train Loss: 0.5537, Val Loss: 0.5136, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 75, Train Loss: 0.5461, Val Loss: 0.5109, F1 Micro: 0.7312, F1 Macro: 0.7311, Accuracy: 0.7312\n","Epoch 76, Train Loss: 0.5463, Val Loss: 0.5126, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 77, Train Loss: 0.5448, Val Loss: 0.5247, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 78, Train Loss: 0.5451, Val Loss: 0.5095, F1 Micro: 0.7375, F1 Macro: 0.7371, Accuracy: 0.7375\n","Epoch 79, Train Loss: 0.5498, Val Loss: 0.5117, F1 Micro: 0.7312, F1 Macro: 0.7240, Accuracy: 0.7312\n","Epoch 80, Train Loss: 0.5423, Val Loss: 0.5038, F1 Micro: 0.7344, F1 Macro: 0.7332, Accuracy: 0.7344\n","Epoch 81, Train Loss: 0.5388, Val Loss: 0.5545, F1 Micro: 0.7156, F1 Macro: 0.7082, Accuracy: 0.7156\n","Epoch 82, Train Loss: 0.5403, Val Loss: 0.5020, F1 Micro: 0.7312, F1 Macro: 0.7304, Accuracy: 0.7312\n","Epoch 83, Train Loss: 0.5414, Val Loss: 0.5079, F1 Micro: 0.7188, F1 Macro: 0.7188, Accuracy: 0.7188\n","Epoch 84, Train Loss: 0.5458, Val Loss: 0.5088, F1 Micro: 0.7375, F1 Macro: 0.7333, Accuracy: 0.7375\n","Epoch 85, Train Loss: 0.5424, Val Loss: 0.5909, F1 Micro: 0.6844, F1 Macro: 0.6748, Accuracy: 0.6844\n","Epoch 86, Train Loss: 0.5493, Val Loss: 0.4983, F1 Micro: 0.7406, F1 Macro: 0.7390, Accuracy: 0.7406\n","Epoch 87, Train Loss: 0.5452, Val Loss: 0.4997, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 88, Train Loss: 0.5474, Val Loss: 0.5093, F1 Micro: 0.7312, F1 Macro: 0.7234, Accuracy: 0.7312\n","Epoch 89, Train Loss: 0.5460, Val Loss: 0.5014, F1 Micro: 0.7469, F1 Macro: 0.7445, Accuracy: 0.7469\n","Epoch 90, Train Loss: 0.5342, Val Loss: 0.5091, F1 Micro: 0.7375, F1 Macro: 0.7373, Accuracy: 0.7375\n","Epoch 91, Train Loss: 0.5443, Val Loss: 0.5234, F1 Micro: 0.7469, F1 Macro: 0.7453, Accuracy: 0.7469\n","Epoch 92, Train Loss: 0.5508, Val Loss: 0.5229, F1 Micro: 0.7156, F1 Macro: 0.7148, Accuracy: 0.7156\n","Epoch 93, Train Loss: 0.5412, Val Loss: 0.5062, F1 Micro: 0.7438, F1 Macro: 0.7438, Accuracy: 0.7438\n","Epoch 94, Train Loss: 0.5371, Val Loss: 0.4994, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 95, Train Loss: 0.5345, Val Loss: 0.5289, F1 Micro: 0.7344, F1 Macro: 0.7206, Accuracy: 0.7344\n","Epoch 96, Train Loss: 0.5424, Val Loss: 0.5261, F1 Micro: 0.7375, F1 Macro: 0.7258, Accuracy: 0.7375\n","Epoch 97, Train Loss: 0.5375, Val Loss: 0.5235, F1 Micro: 0.7469, F1 Macro: 0.7458, Accuracy: 0.7469\n","Epoch 98, Train Loss: 0.5490, Val Loss: 0.5037, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 99, Train Loss: 0.5255, Val Loss: 0.4942, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 100, Train Loss: 0.5311, Val Loss: 0.4924, F1 Micro: 0.7438, F1 Macro: 0.7412, Accuracy: 0.7438\n","Epoch 101, Train Loss: 0.5331, Val Loss: 0.4904, F1 Micro: 0.7406, F1 Macro: 0.7390, Accuracy: 0.7406\n","Epoch 102, Train Loss: 0.5282, Val Loss: 0.4954, F1 Micro: 0.7688, F1 Macro: 0.7683, Accuracy: 0.7688\n","Epoch 103, Train Loss: 0.5362, Val Loss: 0.5176, F1 Micro: 0.7312, F1 Macro: 0.7274, Accuracy: 0.7312\n","Epoch 104, Train Loss: 0.5384, Val Loss: 0.5010, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 105, Train Loss: 0.5361, Val Loss: 0.4900, F1 Micro: 0.7531, F1 Macro: 0.7523, Accuracy: 0.7531\n","Epoch 106, Train Loss: 0.5323, Val Loss: 0.5106, F1 Micro: 0.7188, F1 Macro: 0.7166, Accuracy: 0.7188\n","Epoch 107, Train Loss: 0.5323, Val Loss: 0.4937, F1 Micro: 0.7406, F1 Macro: 0.7382, Accuracy: 0.7406\n","Epoch 108, Train Loss: 0.5425, Val Loss: 0.4907, F1 Micro: 0.7500, F1 Macro: 0.7478, Accuracy: 0.7500\n","Epoch 109, Train Loss: 0.5331, Val Loss: 0.4901, F1 Micro: 0.7531, F1 Macro: 0.7523, Accuracy: 0.7531\n","Epoch 110, Train Loss: 0.5309, Val Loss: 0.5214, F1 Micro: 0.7406, F1 Macro: 0.7280, Accuracy: 0.7406\n","Epoch 111, Train Loss: 0.5360, Val Loss: 0.5017, F1 Micro: 0.7438, F1 Macro: 0.7429, Accuracy: 0.7438\n","Epoch 112, Train Loss: 0.5361, Val Loss: 0.5008, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 113, Train Loss: 0.5328, Val Loss: 0.5048, F1 Micro: 0.7562, F1 Macro: 0.7561, Accuracy: 0.7562\n","Epoch 114, Train Loss: 0.5288, Val Loss: 0.4892, F1 Micro: 0.7719, F1 Macro: 0.7718, Accuracy: 0.7719\n","Epoch 115, Train Loss: 0.5318, Val Loss: 0.4877, F1 Micro: 0.7625, F1 Macro: 0.7616, Accuracy: 0.7625\n","Epoch 116, Train Loss: 0.5168, Val Loss: 0.4845, F1 Micro: 0.7625, F1 Macro: 0.7617, Accuracy: 0.7625\n","Epoch 117, Train Loss: 0.5324, Val Loss: 0.4898, F1 Micro: 0.7469, F1 Macro: 0.7448, Accuracy: 0.7469\n","Epoch 118, Train Loss: 0.5191, Val Loss: 0.5085, F1 Micro: 0.7250, F1 Macro: 0.7206, Accuracy: 0.7250\n","Epoch 119, Train Loss: 0.5342, Val Loss: 0.5037, F1 Micro: 0.7375, F1 Macro: 0.7292, Accuracy: 0.7375\n","Epoch 120, Train Loss: 0.5341, Val Loss: 0.4882, F1 Micro: 0.7531, F1 Macro: 0.7514, Accuracy: 0.7531\n","Epoch 121, Train Loss: 0.5205, Val Loss: 0.4981, F1 Micro: 0.7344, F1 Macro: 0.7327, Accuracy: 0.7344\n","Epoch 122, Train Loss: 0.5227, Val Loss: 0.5179, F1 Micro: 0.7188, F1 Macro: 0.7123, Accuracy: 0.7188\n","Epoch 123, Train Loss: 0.5260, Val Loss: 0.5823, F1 Micro: 0.6687, F1 Macro: 0.6500, Accuracy: 0.6687\n","Epoch 124, Train Loss: 0.5304, Val Loss: 0.4847, F1 Micro: 0.7562, F1 Macro: 0.7520, Accuracy: 0.7562\n","Epoch 125, Train Loss: 0.5208, Val Loss: 0.4872, F1 Micro: 0.7469, F1 Macro: 0.7467, Accuracy: 0.7469\n","Epoch 126, Train Loss: 0.5252, Val Loss: 0.4772, F1 Micro: 0.7719, F1 Macro: 0.7714, Accuracy: 0.7719\n","Epoch 127, Train Loss: 0.5162, Val Loss: 0.5000, F1 Micro: 0.7625, F1 Macro: 0.7544, Accuracy: 0.7625\n","Epoch 128, Train Loss: 0.5183, Val Loss: 0.4801, F1 Micro: 0.7406, F1 Macro: 0.7382, Accuracy: 0.7406\n","Epoch 129, Train Loss: 0.5319, Val Loss: 0.4912, F1 Micro: 0.7625, F1 Macro: 0.7623, Accuracy: 0.7625\n","Epoch 130, Train Loss: 0.5174, Val Loss: 0.4788, F1 Micro: 0.7625, F1 Macro: 0.7591, Accuracy: 0.7625\n","Epoch 131, Train Loss: 0.5299, Val Loss: 0.4812, F1 Micro: 0.7562, F1 Macro: 0.7541, Accuracy: 0.7562\n","Epoch 132, Train Loss: 0.5248, Val Loss: 0.5023, F1 Micro: 0.7281, F1 Macro: 0.7236, Accuracy: 0.7281\n","Epoch 133, Train Loss: 0.5232, Val Loss: 0.4761, F1 Micro: 0.7562, F1 Macro: 0.7555, Accuracy: 0.7562\n","Epoch 134, Train Loss: 0.5165, Val Loss: 0.4872, F1 Micro: 0.7500, F1 Macro: 0.7456, Accuracy: 0.7500\n","Epoch 135, Train Loss: 0.5093, Val Loss: 0.4776, F1 Micro: 0.7500, F1 Macro: 0.7499, Accuracy: 0.7500\n","Epoch 136, Train Loss: 0.5247, Val Loss: 0.4963, F1 Micro: 0.7094, F1 Macro: 0.7063, Accuracy: 0.7094\n","Epoch 137, Train Loss: 0.5183, Val Loss: 0.4990, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 138, Train Loss: 0.5272, Val Loss: 0.4754, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 139, Train Loss: 0.5132, Val Loss: 0.4773, F1 Micro: 0.7531, F1 Macro: 0.7498, Accuracy: 0.7531\n","Epoch 140, Train Loss: 0.5199, Val Loss: 0.5180, F1 Micro: 0.7156, F1 Macro: 0.7076, Accuracy: 0.7156\n","Epoch 141, Train Loss: 0.5125, Val Loss: 0.4751, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 142, Train Loss: 0.5230, Val Loss: 0.4770, F1 Micro: 0.7562, F1 Macro: 0.7559, Accuracy: 0.7562\n","Epoch 143, Train Loss: 0.5193, Val Loss: 0.4821, F1 Micro: 0.7781, F1 Macro: 0.7779, Accuracy: 0.7781\n","Epoch 144, Train Loss: 0.5134, Val Loss: 0.4779, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 145, Train Loss: 0.5222, Val Loss: 0.4710, F1 Micro: 0.7562, F1 Macro: 0.7555, Accuracy: 0.7562\n","Epoch 146, Train Loss: 0.5155, Val Loss: 0.4893, F1 Micro: 0.7125, F1 Macro: 0.7096, Accuracy: 0.7125\n","Epoch 147, Train Loss: 0.5206, Val Loss: 0.4746, F1 Micro: 0.7688, F1 Macro: 0.7686, Accuracy: 0.7688\n","Epoch 148, Train Loss: 0.5196, Val Loss: 0.4752, F1 Micro: 0.7625, F1 Macro: 0.7595, Accuracy: 0.7625\n","Epoch 149, Train Loss: 0.5180, Val Loss: 0.4756, F1 Micro: 0.7562, F1 Macro: 0.7528, Accuracy: 0.7562\n","Epoch 150, Train Loss: 0.5075, Val Loss: 0.4903, F1 Micro: 0.7500, F1 Macro: 0.7488, Accuracy: 0.7500\n","Epoch 151, Train Loss: 0.5057, Val Loss: 0.4712, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 152, Train Loss: 0.5184, Val Loss: 0.4651, F1 Micro: 0.7500, F1 Macro: 0.7486, Accuracy: 0.7500\n","Epoch 153, Train Loss: 0.5135, Val Loss: 0.4743, F1 Micro: 0.7562, F1 Macro: 0.7528, Accuracy: 0.7562\n","Epoch 154, Train Loss: 0.5155, Val Loss: 0.4902, F1 Micro: 0.7594, F1 Macro: 0.7536, Accuracy: 0.7594\n","Epoch 155, Train Loss: 0.5123, Val Loss: 0.4735, F1 Micro: 0.7469, F1 Macro: 0.7448, Accuracy: 0.7469\n","Epoch 156, Train Loss: 0.5144, Val Loss: 0.4683, F1 Micro: 0.7625, F1 Macro: 0.7619, Accuracy: 0.7625\n","Epoch 157, Train Loss: 0.5122, Val Loss: 0.5163, F1 Micro: 0.7156, F1 Macro: 0.7070, Accuracy: 0.7156\n","Epoch 158, Train Loss: 0.5124, Val Loss: 0.4688, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 159, Train Loss: 0.5122, Val Loss: 0.4747, F1 Micro: 0.7688, F1 Macro: 0.7674, Accuracy: 0.7688\n","Epoch 160, Train Loss: 0.5117, Val Loss: 0.4810, F1 Micro: 0.7562, F1 Macro: 0.7491, Accuracy: 0.7562\n","Epoch 161, Train Loss: 0.5270, Val Loss: 0.4803, F1 Micro: 0.7406, F1 Macro: 0.7397, Accuracy: 0.7406\n","Epoch 162, Train Loss: 0.5086, Val Loss: 0.4782, F1 Micro: 0.7812, F1 Macro: 0.7812, Accuracy: 0.7812\n","Epoch 163, Train Loss: 0.5016, Val Loss: 0.4629, F1 Micro: 0.7781, F1 Macro: 0.7779, Accuracy: 0.7781\n","Epoch 164, Train Loss: 0.5163, Val Loss: 0.4651, F1 Micro: 0.7625, F1 Macro: 0.7601, Accuracy: 0.7625\n","Epoch 165, Train Loss: 0.5119, Val Loss: 0.4882, F1 Micro: 0.7594, F1 Macro: 0.7541, Accuracy: 0.7594\n","Epoch 166, Train Loss: 0.5035, Val Loss: 0.4653, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 167, Train Loss: 0.4995, Val Loss: 0.4716, F1 Micro: 0.7812, F1 Macro: 0.7809, Accuracy: 0.7812\n","Epoch 168, Train Loss: 0.5171, Val Loss: 0.4704, F1 Micro: 0.7594, F1 Macro: 0.7593, Accuracy: 0.7594\n","Epoch 169, Train Loss: 0.5168, Val Loss: 0.4708, F1 Micro: 0.7438, F1 Macro: 0.7436, Accuracy: 0.7438\n","Epoch 170, Train Loss: 0.5018, Val Loss: 0.4729, F1 Micro: 0.7562, F1 Macro: 0.7520, Accuracy: 0.7562\n","Epoch 171, Train Loss: 0.5098, Val Loss: 0.4678, F1 Micro: 0.7562, F1 Macro: 0.7531, Accuracy: 0.7562\n","Epoch 172, Train Loss: 0.5025, Val Loss: 0.5216, F1 Micro: 0.7094, F1 Macro: 0.7005, Accuracy: 0.7094\n","Epoch 173, Train Loss: 0.5010, Val Loss: 0.4856, F1 Micro: 0.7375, F1 Macro: 0.7329, Accuracy: 0.7375\n","Epoch 174, Train Loss: 0.5138, Val Loss: 0.4617, F1 Micro: 0.7625, F1 Macro: 0.7623, Accuracy: 0.7625\n","Epoch 175, Train Loss: 0.5058, Val Loss: 0.4769, F1 Micro: 0.7750, F1 Macro: 0.7744, Accuracy: 0.7750\n","Epoch 176, Train Loss: 0.5134, Val Loss: 0.4783, F1 Micro: 0.7625, F1 Macro: 0.7607, Accuracy: 0.7625\n","Epoch 177, Train Loss: 0.5083, Val Loss: 0.4703, F1 Micro: 0.7438, F1 Macro: 0.7438, Accuracy: 0.7438\n","Epoch 178, Train Loss: 0.5055, Val Loss: 0.4566, F1 Micro: 0.7719, F1 Macro: 0.7715, Accuracy: 0.7719\n","Epoch 179, Train Loss: 0.5128, Val Loss: 0.5078, F1 Micro: 0.7250, F1 Macro: 0.7163, Accuracy: 0.7250\n","Epoch 180, Train Loss: 0.5181, Val Loss: 0.4622, F1 Micro: 0.7531, F1 Macro: 0.7521, Accuracy: 0.7531\n","Epoch 181, Train Loss: 0.5103, Val Loss: 0.4653, F1 Micro: 0.7562, F1 Macro: 0.7528, Accuracy: 0.7562\n","Epoch 182, Train Loss: 0.4995, Val Loss: 0.4639, F1 Micro: 0.7625, F1 Macro: 0.7604, Accuracy: 0.7625\n","Epoch 183, Train Loss: 0.5040, Val Loss: 0.4595, F1 Micro: 0.7625, F1 Macro: 0.7617, Accuracy: 0.7625\n","Epoch 184, Train Loss: 0.5115, Val Loss: 0.4624, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 185, Train Loss: 0.5187, Val Loss: 0.4906, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 186, Train Loss: 0.4996, Val Loss: 0.4800, F1 Micro: 0.7469, F1 Macro: 0.7431, Accuracy: 0.7469\n","Epoch 187, Train Loss: 0.5008, Val Loss: 0.4548, F1 Micro: 0.7656, F1 Macro: 0.7650, Accuracy: 0.7656\n","Epoch 188, Train Loss: 0.5066, Val Loss: 0.4806, F1 Micro: 0.7312, F1 Macro: 0.7274, Accuracy: 0.7312\n","Epoch 189, Train Loss: 0.5064, Val Loss: 0.5313, F1 Micro: 0.6813, F1 Macro: 0.6671, Accuracy: 0.6813\n","Epoch 190, Train Loss: 0.5094, Val Loss: 0.5062, F1 Micro: 0.7156, F1 Macro: 0.7088, Accuracy: 0.7156\n","Epoch 191, Train Loss: 0.5080, Val Loss: 0.4782, F1 Micro: 0.7500, F1 Macro: 0.7471, Accuracy: 0.7500\n","Epoch 192, Train Loss: 0.5113, Val Loss: 0.4648, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 193, Train Loss: 0.5114, Val Loss: 0.4782, F1 Micro: 0.7500, F1 Macro: 0.7471, Accuracy: 0.7500\n","Epoch 194, Train Loss: 0.5133, Val Loss: 0.4642, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Epoch 195, Train Loss: 0.5007, Val Loss: 0.4574, F1 Micro: 0.7844, F1 Macro: 0.7834, Accuracy: 0.7844\n","Epoch 196, Train Loss: 0.5096, Val Loss: 0.4669, F1 Micro: 0.7719, F1 Macro: 0.7712, Accuracy: 0.7719\n","Epoch 197, Train Loss: 0.5028, Val Loss: 0.4691, F1 Micro: 0.7531, F1 Macro: 0.7514, Accuracy: 0.7531\n","Epoch 198, Train Loss: 0.5137, Val Loss: 0.4591, F1 Micro: 0.7844, F1 Macro: 0.7838, Accuracy: 0.7844\n","Epoch 199, Train Loss: 0.5000, Val Loss: 0.4738, F1 Micro: 0.7625, F1 Macro: 0.7598, Accuracy: 0.7625\n","Epoch 200, Train Loss: 0.5088, Val Loss: 0.4621, F1 Micro: 0.7719, F1 Macro: 0.7702, Accuracy: 0.7719\n","Average Score for hyperparameters (0.001, 8, 50): 0.7543749999999999\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6144, Val Loss: 0.5804, F1 Micro: 0.6875, F1 Macro: 0.6872, Accuracy: 0.6875\n","Epoch 2, Train Loss: 0.6000, Val Loss: 0.5789, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 3, Train Loss: 0.5683, Val Loss: 0.6326, F1 Micro: 0.6469, F1 Macro: 0.6143, Accuracy: 0.6469\n","Epoch 4, Train Loss: 0.5694, Val Loss: 0.5816, F1 Micro: 0.6406, F1 Macro: 0.6358, Accuracy: 0.6406\n","Epoch 5, Train Loss: 0.5650, Val Loss: 0.5840, F1 Micro: 0.6406, F1 Macro: 0.6340, Accuracy: 0.6406\n","Epoch 6, Train Loss: 0.5745, Val Loss: 0.5944, F1 Micro: 0.6594, F1 Macro: 0.6456, Accuracy: 0.6594\n","Epoch 7, Train Loss: 0.5692, Val Loss: 0.6208, F1 Micro: 0.6969, F1 Macro: 0.6854, Accuracy: 0.6969\n","Epoch 8, Train Loss: 0.5750, Val Loss: 0.6012, F1 Micro: 0.6625, F1 Macro: 0.6591, Accuracy: 0.6625\n","Epoch 9, Train Loss: 0.5760, Val Loss: 0.5962, F1 Micro: 0.6656, F1 Macro: 0.6512, Accuracy: 0.6656\n","Epoch 10, Train Loss: 0.5755, Val Loss: 0.5814, F1 Micro: 0.6719, F1 Macro: 0.6718, Accuracy: 0.6719\n","Epoch 11, Train Loss: 0.5784, Val Loss: 0.5906, F1 Micro: 0.6469, F1 Macro: 0.6353, Accuracy: 0.6469\n","Epoch 12, Train Loss: 0.5710, Val Loss: 0.5833, F1 Micro: 0.6500, F1 Macro: 0.6426, Accuracy: 0.6500\n","Epoch 13, Train Loss: 0.5661, Val Loss: 0.5796, F1 Micro: 0.6406, F1 Macro: 0.6358, Accuracy: 0.6406\n","Epoch 14, Train Loss: 0.5672, Val Loss: 0.5777, F1 Micro: 0.6438, F1 Macro: 0.6392, Accuracy: 0.6438\n","Epoch 15, Train Loss: 0.5650, Val Loss: 0.6208, F1 Micro: 0.6969, F1 Macro: 0.6854, Accuracy: 0.6969\n","Epoch 16, Train Loss: 0.5771, Val Loss: 0.5886, F1 Micro: 0.6531, F1 Macro: 0.6441, Accuracy: 0.6531\n","Epoch 17, Train Loss: 0.5660, Val Loss: 0.5926, F1 Micro: 0.6656, F1 Macro: 0.6512, Accuracy: 0.6656\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6162, Val Loss: 0.5781, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 2, Train Loss: 0.5953, Val Loss: 0.5615, F1 Micro: 0.7312, F1 Macro: 0.7228, Accuracy: 0.7312\n","Epoch 3, Train Loss: 0.5833, Val Loss: 0.5600, F1 Micro: 0.7219, F1 Macro: 0.7152, Accuracy: 0.7219\n","Epoch 4, Train Loss: 0.5756, Val Loss: 0.6936, F1 Micro: 0.5469, F1 Macro: 0.4770, Accuracy: 0.5469\n","Epoch 5, Train Loss: 0.5860, Val Loss: 0.6064, F1 Micro: 0.6906, F1 Macro: 0.6564, Accuracy: 0.6906\n","Epoch 6, Train Loss: 0.5840, Val Loss: 0.5646, F1 Micro: 0.7281, F1 Macro: 0.7164, Accuracy: 0.7281\n","Epoch 7, Train Loss: 0.5866, Val Loss: 0.5765, F1 Micro: 0.7188, F1 Macro: 0.6990, Accuracy: 0.7188\n","Epoch 8, Train Loss: 0.5930, Val Loss: 0.5927, F1 Micro: 0.6719, F1 Macro: 0.6712, Accuracy: 0.6719\n","Epoch 9, Train Loss: 0.5744, Val Loss: 0.5592, F1 Micro: 0.7250, F1 Macro: 0.7175, Accuracy: 0.7250\n","Epoch 10, Train Loss: 0.5804, Val Loss: 0.5573, F1 Micro: 0.7125, F1 Macro: 0.7064, Accuracy: 0.7125\n","Epoch 11, Train Loss: 0.5823, Val Loss: 0.5830, F1 Micro: 0.6813, F1 Macro: 0.6812, Accuracy: 0.6813\n","Epoch 12, Train Loss: 0.5805, Val Loss: 0.5615, F1 Micro: 0.7250, F1 Macro: 0.7150, Accuracy: 0.7250\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6458, Val Loss: 0.6061, F1 Micro: 0.6750, F1 Macro: 0.6745, Accuracy: 0.6750\n","Epoch 2, Train Loss: 0.5705, Val Loss: 0.6056, F1 Micro: 0.6562, F1 Macro: 0.6476, Accuracy: 0.6562\n","Epoch 3, Train Loss: 0.5669, Val Loss: 0.6065, F1 Micro: 0.6625, F1 Macro: 0.6560, Accuracy: 0.6625\n","Epoch 4, Train Loss: 0.5716, Val Loss: 0.6079, F1 Micro: 0.6625, F1 Macro: 0.6510, Accuracy: 0.6625\n","Epoch 5, Train Loss: 0.5728, Val Loss: 0.6322, F1 Micro: 0.6438, F1 Macro: 0.6417, Accuracy: 0.6438\n","Epoch 6, Train Loss: 0.5655, Val Loss: 0.6201, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 7, Train Loss: 0.5694, Val Loss: 0.6506, F1 Micro: 0.6406, F1 Macro: 0.6372, Accuracy: 0.6406\n","Epoch 8, Train Loss: 0.5638, Val Loss: 0.6432, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 9, Train Loss: 0.5619, Val Loss: 0.6456, F1 Micro: 0.6344, F1 Macro: 0.6299, Accuracy: 0.6344\n","Epoch 10, Train Loss: 0.5671, Val Loss: 0.6268, F1 Micro: 0.6531, F1 Macro: 0.6519, Accuracy: 0.6531\n","Epoch 11, Train Loss: 0.5629, Val Loss: 0.6481, F1 Micro: 0.6375, F1 Macro: 0.6329, Accuracy: 0.6375\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6429, Val Loss: 0.5433, F1 Micro: 0.7063, F1 Macro: 0.7053, Accuracy: 0.7063\n","Epoch 2, Train Loss: 0.6024, Val Loss: 0.5682, F1 Micro: 0.6875, F1 Macro: 0.6688, Accuracy: 0.6875\n","Epoch 3, Train Loss: 0.6019, Val Loss: 0.5487, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 4, Train Loss: 0.5826, Val Loss: 0.5455, F1 Micro: 0.7406, F1 Macro: 0.7344, Accuracy: 0.7406\n","Epoch 5, Train Loss: 0.5925, Val Loss: 0.5503, F1 Micro: 0.6937, F1 Macro: 0.6917, Accuracy: 0.6937\n","Epoch 6, Train Loss: 0.5932, Val Loss: 0.5332, F1 Micro: 0.7000, F1 Macro: 0.7000, Accuracy: 0.7000\n","Epoch 7, Train Loss: 0.5852, Val Loss: 0.5312, F1 Micro: 0.7125, F1 Macro: 0.7122, Accuracy: 0.7125\n","Epoch 8, Train Loss: 0.5941, Val Loss: 0.5404, F1 Micro: 0.7031, F1 Macro: 0.7028, Accuracy: 0.7031\n","Epoch 9, Train Loss: 0.5845, Val Loss: 0.5534, F1 Micro: 0.6906, F1 Macro: 0.6884, Accuracy: 0.6906\n","Epoch 10, Train Loss: 0.5814, Val Loss: 0.6040, F1 Micro: 0.6844, F1 Macro: 0.6774, Accuracy: 0.6844\n","Epoch 11, Train Loss: 0.5848, Val Loss: 0.5344, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 12, Train Loss: 0.5835, Val Loss: 0.5960, F1 Micro: 0.6844, F1 Macro: 0.6774, Accuracy: 0.6844\n","Epoch 13, Train Loss: 0.5814, Val Loss: 0.5587, F1 Micro: 0.6937, F1 Macro: 0.6903, Accuracy: 0.6937\n","Epoch 14, Train Loss: 0.5825, Val Loss: 0.5613, F1 Micro: 0.6969, F1 Macro: 0.6932, Accuracy: 0.6969\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.5967, Val Loss: 0.5620, F1 Micro: 0.6906, F1 Macro: 0.6671, Accuracy: 0.6906\n","Epoch 2, Train Loss: 0.6012, Val Loss: 0.5607, F1 Micro: 0.6844, F1 Macro: 0.6616, Accuracy: 0.6844\n","Epoch 3, Train Loss: 0.5995, Val Loss: 0.5672, F1 Micro: 0.6875, F1 Macro: 0.6607, Accuracy: 0.6875\n","Epoch 4, Train Loss: 0.5806, Val Loss: 0.5408, F1 Micro: 0.7250, F1 Macro: 0.7222, Accuracy: 0.7250\n","Epoch 5, Train Loss: 0.5897, Val Loss: 0.5519, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 6, Train Loss: 0.5850, Val Loss: 0.5465, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 7, Train Loss: 0.5844, Val Loss: 0.5443, F1 Micro: 0.7344, F1 Macro: 0.7327, Accuracy: 0.7344\n","Epoch 8, Train Loss: 0.5895, Val Loss: 0.5388, F1 Micro: 0.7250, F1 Macro: 0.7181, Accuracy: 0.7250\n","Epoch 9, Train Loss: 0.5753, Val Loss: 0.5367, F1 Micro: 0.7281, F1 Macro: 0.7252, Accuracy: 0.7281\n","Epoch 10, Train Loss: 0.5725, Val Loss: 0.5453, F1 Micro: 0.7063, F1 Macro: 0.6915, Accuracy: 0.7063\n","Epoch 11, Train Loss: 0.5746, Val Loss: 0.5818, F1 Micro: 0.6813, F1 Macro: 0.6468, Accuracy: 0.6813\n","Epoch 12, Train Loss: 0.5786, Val Loss: 0.5591, F1 Micro: 0.6875, F1 Macro: 0.6644, Accuracy: 0.6875\n","Epoch 13, Train Loss: 0.5724, Val Loss: 0.5367, F1 Micro: 0.7094, F1 Macro: 0.6984, Accuracy: 0.7094\n","Epoch 14, Train Loss: 0.5688, Val Loss: 0.5624, F1 Micro: 0.6906, F1 Macro: 0.6671, Accuracy: 0.6906\n","Epoch 15, Train Loss: 0.5927, Val Loss: 0.5697, F1 Micro: 0.6875, F1 Macro: 0.6865, Accuracy: 0.6875\n","Epoch 16, Train Loss: 0.5753, Val Loss: 0.5439, F1 Micro: 0.7281, F1 Macro: 0.7275, Accuracy: 0.7281\n","Epoch 17, Train Loss: 0.5770, Val Loss: 0.5434, F1 Micro: 0.7219, F1 Macro: 0.7215, Accuracy: 0.7219\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.7156250000000001\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6097, Val Loss: 0.5896, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 2, Train Loss: 0.5875, Val Loss: 0.5802, F1 Micro: 0.6406, F1 Macro: 0.6363, Accuracy: 0.6406\n","Epoch 3, Train Loss: 0.5922, Val Loss: 0.5826, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 4, Train Loss: 0.5746, Val Loss: 0.6048, F1 Micro: 0.6531, F1 Macro: 0.6341, Accuracy: 0.6531\n","Epoch 5, Train Loss: 0.5807, Val Loss: 0.5882, F1 Micro: 0.6687, F1 Macro: 0.6685, Accuracy: 0.6687\n","Epoch 6, Train Loss: 0.5854, Val Loss: 0.5927, F1 Micro: 0.6594, F1 Macro: 0.6456, Accuracy: 0.6594\n","Epoch 7, Train Loss: 0.5847, Val Loss: 0.5910, F1 Micro: 0.6500, F1 Macro: 0.6389, Accuracy: 0.6500\n","Epoch 8, Train Loss: 0.5763, Val Loss: 0.5824, F1 Micro: 0.6375, F1 Macro: 0.6311, Accuracy: 0.6375\n","Epoch 9, Train Loss: 0.5664, Val Loss: 0.5799, F1 Micro: 0.6875, F1 Macro: 0.6873, Accuracy: 0.6875\n","Epoch 10, Train Loss: 0.5694, Val Loss: 0.5774, F1 Micro: 0.6531, F1 Macro: 0.6510, Accuracy: 0.6531\n","Epoch 11, Train Loss: 0.5755, Val Loss: 0.5814, F1 Micro: 0.6375, F1 Macro: 0.6311, Accuracy: 0.6375\n","Epoch 12, Train Loss: 0.5717, Val Loss: 0.5797, F1 Micro: 0.6406, F1 Macro: 0.6358, Accuracy: 0.6406\n","Epoch 13, Train Loss: 0.5682, Val Loss: 0.5765, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 14, Train Loss: 0.5658, Val Loss: 0.5760, F1 Micro: 0.6625, F1 Macro: 0.6609, Accuracy: 0.6625\n","Epoch 15, Train Loss: 0.5700, Val Loss: 0.5755, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 16, Train Loss: 0.5692, Val Loss: 0.5888, F1 Micro: 0.6500, F1 Macro: 0.6381, Accuracy: 0.6500\n","Epoch 17, Train Loss: 0.5712, Val Loss: 0.5754, F1 Micro: 0.6813, F1 Macro: 0.6808, Accuracy: 0.6813\n","Epoch 18, Train Loss: 0.5626, Val Loss: 0.5965, F1 Micro: 0.6594, F1 Macro: 0.6417, Accuracy: 0.6594\n","Epoch 19, Train Loss: 0.5616, Val Loss: 0.5862, F1 Micro: 0.6531, F1 Macro: 0.6433, Accuracy: 0.6531\n","Epoch 20, Train Loss: 0.5665, Val Loss: 0.6122, F1 Micro: 0.6781, F1 Macro: 0.6683, Accuracy: 0.6781\n","Epoch 21, Train Loss: 0.5671, Val Loss: 0.5730, F1 Micro: 0.6781, F1 Macro: 0.6774, Accuracy: 0.6781\n","Epoch 22, Train Loss: 0.5654, Val Loss: 0.5807, F1 Micro: 0.6500, F1 Macro: 0.6419, Accuracy: 0.6500\n","Epoch 23, Train Loss: 0.5615, Val Loss: 0.5735, F1 Micro: 0.6656, F1 Macro: 0.6642, Accuracy: 0.6656\n","Epoch 24, Train Loss: 0.5568, Val Loss: 0.6196, F1 Micro: 0.6469, F1 Macro: 0.6252, Accuracy: 0.6469\n","Epoch 25, Train Loss: 0.5602, Val Loss: 0.6073, F1 Micro: 0.6500, F1 Macro: 0.6254, Accuracy: 0.6500\n","Epoch 26, Train Loss: 0.5569, Val Loss: 0.5720, F1 Micro: 0.6781, F1 Macro: 0.6777, Accuracy: 0.6781\n","Epoch 27, Train Loss: 0.5663, Val Loss: 0.5704, F1 Micro: 0.6781, F1 Macro: 0.6776, Accuracy: 0.6781\n","Epoch 28, Train Loss: 0.5627, Val Loss: 0.5698, F1 Micro: 0.6625, F1 Macro: 0.6609, Accuracy: 0.6625\n","Epoch 29, Train Loss: 0.5634, Val Loss: 0.5935, F1 Micro: 0.6687, F1 Macro: 0.6624, Accuracy: 0.6687\n","Epoch 30, Train Loss: 0.5596, Val Loss: 0.5817, F1 Micro: 0.6500, F1 Macro: 0.6419, Accuracy: 0.6500\n","Epoch 31, Train Loss: 0.5560, Val Loss: 0.5693, F1 Micro: 0.6625, F1 Macro: 0.6603, Accuracy: 0.6625\n","Epoch 32, Train Loss: 0.5564, Val Loss: 0.5734, F1 Micro: 0.6375, F1 Macro: 0.6323, Accuracy: 0.6375\n","Epoch 33, Train Loss: 0.5578, Val Loss: 0.5723, F1 Micro: 0.6687, F1 Macro: 0.6683, Accuracy: 0.6687\n","Epoch 34, Train Loss: 0.5578, Val Loss: 0.5773, F1 Micro: 0.6375, F1 Macro: 0.6311, Accuracy: 0.6375\n","Epoch 35, Train Loss: 0.5662, Val Loss: 0.5870, F1 Micro: 0.6687, F1 Macro: 0.6575, Accuracy: 0.6687\n","Epoch 36, Train Loss: 0.5525, Val Loss: 0.5687, F1 Micro: 0.6687, F1 Macro: 0.6684, Accuracy: 0.6687\n","Epoch 37, Train Loss: 0.5515, Val Loss: 0.5662, F1 Micro: 0.6625, F1 Macro: 0.6609, Accuracy: 0.6625\n","Epoch 38, Train Loss: 0.5584, Val Loss: 0.5765, F1 Micro: 0.6469, F1 Macro: 0.6398, Accuracy: 0.6469\n","Epoch 39, Train Loss: 0.5602, Val Loss: 0.5710, F1 Micro: 0.6469, F1 Macro: 0.6426, Accuracy: 0.6469\n","Epoch 40, Train Loss: 0.5605, Val Loss: 0.5651, F1 Micro: 0.6687, F1 Macro: 0.6672, Accuracy: 0.6687\n","Epoch 41, Train Loss: 0.5516, Val Loss: 0.5659, F1 Micro: 0.6687, F1 Macro: 0.6669, Accuracy: 0.6687\n","Epoch 42, Train Loss: 0.5538, Val Loss: 0.5639, F1 Micro: 0.6687, F1 Macro: 0.6669, Accuracy: 0.6687\n","Epoch 43, Train Loss: 0.5523, Val Loss: 0.5734, F1 Micro: 0.6406, F1 Macro: 0.6346, Accuracy: 0.6406\n","Epoch 44, Train Loss: 0.5556, Val Loss: 0.5817, F1 Micro: 0.6500, F1 Macro: 0.6412, Accuracy: 0.6500\n","Epoch 45, Train Loss: 0.5507, Val Loss: 0.5645, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 46, Train Loss: 0.5512, Val Loss: 0.5627, F1 Micro: 0.6687, F1 Macro: 0.6669, Accuracy: 0.6687\n","Epoch 47, Train Loss: 0.5491, Val Loss: 0.5673, F1 Micro: 0.6719, F1 Macro: 0.6716, Accuracy: 0.6719\n","Epoch 48, Train Loss: 0.5535, Val Loss: 0.5606, F1 Micro: 0.6781, F1 Macro: 0.6776, Accuracy: 0.6781\n","Epoch 49, Train Loss: 0.5486, Val Loss: 0.5720, F1 Micro: 0.6531, F1 Macro: 0.6461, Accuracy: 0.6531\n","Epoch 50, Train Loss: 0.5493, Val Loss: 0.5643, F1 Micro: 0.6531, F1 Macro: 0.6494, Accuracy: 0.6531\n","Epoch 51, Train Loss: 0.5459, Val Loss: 0.5593, F1 Micro: 0.6687, F1 Macro: 0.6675, Accuracy: 0.6687\n","Epoch 52, Train Loss: 0.5479, Val Loss: 0.5616, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 53, Train Loss: 0.5461, Val Loss: 0.5892, F1 Micro: 0.6906, F1 Macro: 0.6805, Accuracy: 0.6906\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6125, Val Loss: 0.5644, F1 Micro: 0.7188, F1 Macro: 0.7054, Accuracy: 0.7188\n","Epoch 2, Train Loss: 0.5971, Val Loss: 0.5752, F1 Micro: 0.7188, F1 Macro: 0.6990, Accuracy: 0.7188\n","Epoch 3, Train Loss: 0.5923, Val Loss: 0.5887, F1 Micro: 0.6875, F1 Macro: 0.6873, Accuracy: 0.6875\n","Epoch 4, Train Loss: 0.5809, Val Loss: 0.5613, F1 Micro: 0.7281, F1 Macro: 0.7192, Accuracy: 0.7281\n","Epoch 5, Train Loss: 0.5861, Val Loss: 0.6185, F1 Micro: 0.6719, F1 Macro: 0.6288, Accuracy: 0.6719\n","Epoch 6, Train Loss: 0.5856, Val Loss: 0.6027, F1 Micro: 0.6562, F1 Macro: 0.6532, Accuracy: 0.6562\n","Epoch 7, Train Loss: 0.5856, Val Loss: 0.5743, F1 Micro: 0.7188, F1 Macro: 0.7000, Accuracy: 0.7188\n","Epoch 8, Train Loss: 0.5851, Val Loss: 0.5690, F1 Micro: 0.7125, F1 Macro: 0.6972, Accuracy: 0.7125\n","Epoch 9, Train Loss: 0.5751, Val Loss: 0.5688, F1 Micro: 0.6875, F1 Macro: 0.6873, Accuracy: 0.6875\n","Epoch 10, Train Loss: 0.5689, Val Loss: 0.5665, F1 Micro: 0.7156, F1 Macro: 0.7009, Accuracy: 0.7156\n","Epoch 11, Train Loss: 0.5663, Val Loss: 0.5884, F1 Micro: 0.6813, F1 Macro: 0.6809, Accuracy: 0.6813\n","Epoch 12, Train Loss: 0.5715, Val Loss: 0.5730, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 13, Train Loss: 0.5852, Val Loss: 0.5630, F1 Micro: 0.7250, F1 Macro: 0.7128, Accuracy: 0.7250\n","Epoch 14, Train Loss: 0.5738, Val Loss: 0.5635, F1 Micro: 0.7250, F1 Macro: 0.7128, Accuracy: 0.7250\n","Epoch 15, Train Loss: 0.5695, Val Loss: 0.5580, F1 Micro: 0.7281, F1 Macro: 0.7198, Accuracy: 0.7281\n","Epoch 16, Train Loss: 0.5745, Val Loss: 0.5753, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 17, Train Loss: 0.5728, Val Loss: 0.5638, F1 Micro: 0.6875, F1 Macro: 0.6872, Accuracy: 0.6875\n","Epoch 18, Train Loss: 0.5755, Val Loss: 0.5735, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 19, Train Loss: 0.5788, Val Loss: 0.5579, F1 Micro: 0.6813, F1 Macro: 0.6791, Accuracy: 0.6813\n","Epoch 20, Train Loss: 0.5718, Val Loss: 0.5537, F1 Micro: 0.6969, F1 Macro: 0.6923, Accuracy: 0.6969\n","Epoch 21, Train Loss: 0.5658, Val Loss: 0.5513, F1 Micro: 0.7000, F1 Macro: 0.6947, Accuracy: 0.7000\n","Epoch 22, Train Loss: 0.5629, Val Loss: 0.5513, F1 Micro: 0.6906, F1 Macro: 0.6864, Accuracy: 0.6906\n","Epoch 23, Train Loss: 0.5666, Val Loss: 0.5531, F1 Micro: 0.6813, F1 Macro: 0.6788, Accuracy: 0.6813\n","Epoch 24, Train Loss: 0.5621, Val Loss: 0.5521, F1 Micro: 0.6906, F1 Macro: 0.6873, Accuracy: 0.6906\n","Epoch 25, Train Loss: 0.5635, Val Loss: 0.5537, F1 Micro: 0.6844, F1 Macro: 0.6827, Accuracy: 0.6844\n","Epoch 26, Train Loss: 0.5620, Val Loss: 0.5505, F1 Micro: 0.7000, F1 Macro: 0.6947, Accuracy: 0.7000\n","Epoch 27, Train Loss: 0.5653, Val Loss: 0.5614, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 28, Train Loss: 0.5609, Val Loss: 0.5497, F1 Micro: 0.6906, F1 Macro: 0.6864, Accuracy: 0.6906\n","Epoch 29, Train Loss: 0.5632, Val Loss: 0.5857, F1 Micro: 0.6719, F1 Macro: 0.6707, Accuracy: 0.6719\n","Epoch 30, Train Loss: 0.5631, Val Loss: 0.5528, F1 Micro: 0.6813, F1 Macro: 0.6800, Accuracy: 0.6813\n","Epoch 31, Train Loss: 0.5611, Val Loss: 0.5464, F1 Micro: 0.6750, F1 Macro: 0.6725, Accuracy: 0.6750\n","Epoch 32, Train Loss: 0.5631, Val Loss: 0.5469, F1 Micro: 0.7063, F1 Macro: 0.7006, Accuracy: 0.7063\n","Epoch 33, Train Loss: 0.5643, Val Loss: 0.5676, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 34, Train Loss: 0.5613, Val Loss: 0.5513, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 35, Train Loss: 0.5645, Val Loss: 0.5514, F1 Micro: 0.6781, F1 Macro: 0.6767, Accuracy: 0.6781\n","Epoch 36, Train Loss: 0.5603, Val Loss: 0.5447, F1 Micro: 0.7063, F1 Macro: 0.7006, Accuracy: 0.7063\n","Epoch 37, Train Loss: 0.5561, Val Loss: 0.5867, F1 Micro: 0.7219, F1 Macro: 0.6974, Accuracy: 0.7219\n","Epoch 38, Train Loss: 0.5608, Val Loss: 0.5461, F1 Micro: 0.6750, F1 Macro: 0.6732, Accuracy: 0.6750\n","Epoch 39, Train Loss: 0.5601, Val Loss: 0.5459, F1 Micro: 0.6813, F1 Macro: 0.6794, Accuracy: 0.6813\n","Epoch 40, Train Loss: 0.5589, Val Loss: 0.5460, F1 Micro: 0.7156, F1 Macro: 0.7088, Accuracy: 0.7156\n","Epoch 41, Train Loss: 0.5592, Val Loss: 0.5437, F1 Micro: 0.7063, F1 Macro: 0.7006, Accuracy: 0.7063\n","Epoch 42, Train Loss: 0.5651, Val Loss: 0.5589, F1 Micro: 0.6656, F1 Macro: 0.6649, Accuracy: 0.6656\n","Epoch 43, Train Loss: 0.5565, Val Loss: 0.5417, F1 Micro: 0.7094, F1 Macro: 0.7035, Accuracy: 0.7094\n","Epoch 44, Train Loss: 0.5618, Val Loss: 0.5544, F1 Micro: 0.7312, F1 Macro: 0.7161, Accuracy: 0.7312\n","Epoch 45, Train Loss: 0.5583, Val Loss: 0.5451, F1 Micro: 0.7000, F1 Macro: 0.6947, Accuracy: 0.7000\n","Epoch 46, Train Loss: 0.5610, Val Loss: 0.5416, F1 Micro: 0.7063, F1 Macro: 0.7006, Accuracy: 0.7063\n","Epoch 47, Train Loss: 0.5589, Val Loss: 0.5419, F1 Micro: 0.6906, F1 Macro: 0.6873, Accuracy: 0.6906\n","Epoch 48, Train Loss: 0.5554, Val Loss: 0.5383, F1 Micro: 0.7000, F1 Macro: 0.6947, Accuracy: 0.7000\n","Epoch 49, Train Loss: 0.5521, Val Loss: 0.5422, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 50, Train Loss: 0.5463, Val Loss: 0.6316, F1 Micro: 0.6562, F1 Macro: 0.6022, Accuracy: 0.6562\n","Epoch 51, Train Loss: 0.5681, Val Loss: 0.5481, F1 Micro: 0.6844, F1 Macro: 0.6840, Accuracy: 0.6844\n","Epoch 52, Train Loss: 0.5533, Val Loss: 0.5462, F1 Micro: 0.6906, F1 Macro: 0.6901, Accuracy: 0.6906\n","Epoch 53, Train Loss: 0.5565, Val Loss: 0.5369, F1 Micro: 0.6906, F1 Macro: 0.6873, Accuracy: 0.6906\n","Epoch 54, Train Loss: 0.5648, Val Loss: 0.5394, F1 Micro: 0.6844, F1 Macro: 0.6818, Accuracy: 0.6844\n","Epoch 55, Train Loss: 0.5529, Val Loss: 0.5486, F1 Micro: 0.7219, F1 Macro: 0.7107, Accuracy: 0.7219\n","Epoch 56, Train Loss: 0.5548, Val Loss: 0.5418, F1 Micro: 0.6844, F1 Macro: 0.6830, Accuracy: 0.6844\n","Epoch 57, Train Loss: 0.5529, Val Loss: 0.5741, F1 Micro: 0.7156, F1 Macro: 0.6962, Accuracy: 0.7156\n","Epoch 58, Train Loss: 0.5526, Val Loss: 0.5382, F1 Micro: 0.6844, F1 Macro: 0.6821, Accuracy: 0.6844\n","Epoch 59, Train Loss: 0.5500, Val Loss: 0.5568, F1 Micro: 0.7250, F1 Macro: 0.7135, Accuracy: 0.7250\n","Epoch 60, Train Loss: 0.5557, Val Loss: 0.5352, F1 Micro: 0.7031, F1 Macro: 0.6971, Accuracy: 0.7031\n","Epoch 61, Train Loss: 0.5526, Val Loss: 0.5409, F1 Micro: 0.6813, F1 Macro: 0.6797, Accuracy: 0.6813\n","Epoch 62, Train Loss: 0.5570, Val Loss: 0.5382, F1 Micro: 0.6875, F1 Macro: 0.6863, Accuracy: 0.6875\n","Epoch 63, Train Loss: 0.5523, Val Loss: 0.5595, F1 Micro: 0.7156, F1 Macro: 0.6951, Accuracy: 0.7156\n","Epoch 64, Train Loss: 0.5531, Val Loss: 0.5399, F1 Micro: 0.6937, F1 Macro: 0.6937, Accuracy: 0.6937\n","Epoch 65, Train Loss: 0.5537, Val Loss: 0.5305, F1 Micro: 0.6844, F1 Macro: 0.6818, Accuracy: 0.6844\n","Epoch 66, Train Loss: 0.5537, Val Loss: 0.5434, F1 Micro: 0.6844, F1 Macro: 0.6840, Accuracy: 0.6844\n","Epoch 67, Train Loss: 0.5491, Val Loss: 0.5352, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 68, Train Loss: 0.5531, Val Loss: 0.5662, F1 Micro: 0.7094, F1 Macro: 0.6862, Accuracy: 0.7094\n","Epoch 69, Train Loss: 0.5553, Val Loss: 0.5380, F1 Micro: 0.6969, F1 Macro: 0.6908, Accuracy: 0.6969\n","Epoch 70, Train Loss: 0.5494, Val Loss: 0.5373, F1 Micro: 0.7094, F1 Macro: 0.7018, Accuracy: 0.7094\n","Epoch 71, Train Loss: 0.5565, Val Loss: 0.5371, F1 Micro: 0.6813, F1 Macro: 0.6802, Accuracy: 0.6813\n","Epoch 72, Train Loss: 0.5456, Val Loss: 0.5278, F1 Micro: 0.6906, F1 Macro: 0.6890, Accuracy: 0.6906\n","Epoch 73, Train Loss: 0.5509, Val Loss: 0.5350, F1 Micro: 0.6969, F1 Macro: 0.6965, Accuracy: 0.6969\n","Epoch 74, Train Loss: 0.5530, Val Loss: 0.5425, F1 Micro: 0.6875, F1 Macro: 0.6874, Accuracy: 0.6875\n","Epoch 75, Train Loss: 0.5509, Val Loss: 0.5362, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 76, Train Loss: 0.5474, Val Loss: 0.5497, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 77, Train Loss: 0.5482, Val Loss: 0.5491, F1 Micro: 0.7094, F1 Macro: 0.7005, Accuracy: 0.7094\n","Epoch 78, Train Loss: 0.5525, Val Loss: 0.5290, F1 Micro: 0.6844, F1 Macro: 0.6821, Accuracy: 0.6844\n","Epoch 79, Train Loss: 0.5560, Val Loss: 0.5287, F1 Micro: 0.6906, F1 Macro: 0.6869, Accuracy: 0.6906\n","Epoch 80, Train Loss: 0.5450, Val Loss: 0.5368, F1 Micro: 0.6969, F1 Macro: 0.6908, Accuracy: 0.6969\n","Epoch 81, Train Loss: 0.5476, Val Loss: 0.5262, F1 Micro: 0.6937, F1 Macro: 0.6884, Accuracy: 0.6937\n","Epoch 82, Train Loss: 0.5388, Val Loss: 0.5221, F1 Micro: 0.6875, F1 Macro: 0.6847, Accuracy: 0.6875\n","Epoch 83, Train Loss: 0.5502, Val Loss: 0.5568, F1 Micro: 0.6781, F1 Macro: 0.6758, Accuracy: 0.6781\n","Epoch 84, Train Loss: 0.5460, Val Loss: 0.5262, F1 Micro: 0.6875, F1 Macro: 0.6843, Accuracy: 0.6875\n","Epoch 85, Train Loss: 0.5548, Val Loss: 0.5418, F1 Micro: 0.7344, F1 Macro: 0.7338, Accuracy: 0.7344\n","Epoch 86, Train Loss: 0.5471, Val Loss: 0.5439, F1 Micro: 0.6969, F1 Macro: 0.6966, Accuracy: 0.6969\n","Epoch 87, Train Loss: 0.5412, Val Loss: 0.5249, F1 Micro: 0.6875, F1 Macro: 0.6851, Accuracy: 0.6875\n","Epoch 88, Train Loss: 0.5428, Val Loss: 0.5725, F1 Micro: 0.7094, F1 Macro: 0.6850, Accuracy: 0.7094\n","Epoch 89, Train Loss: 0.5477, Val Loss: 0.5548, F1 Micro: 0.7156, F1 Macro: 0.7042, Accuracy: 0.7156\n","Epoch 90, Train Loss: 0.5582, Val Loss: 0.5539, F1 Micro: 0.7125, F1 Macro: 0.7027, Accuracy: 0.7125\n","Epoch 91, Train Loss: 0.5451, Val Loss: 0.5308, F1 Micro: 0.7063, F1 Macro: 0.6983, Accuracy: 0.7063\n","Epoch 92, Train Loss: 0.5478, Val Loss: 0.5682, F1 Micro: 0.7250, F1 Macro: 0.7112, Accuracy: 0.7250\n","Epoch 93, Train Loss: 0.5414, Val Loss: 0.5163, F1 Micro: 0.7125, F1 Macro: 0.7088, Accuracy: 0.7125\n","Epoch 94, Train Loss: 0.5409, Val Loss: 0.5226, F1 Micro: 0.6937, F1 Macro: 0.6930, Accuracy: 0.6937\n","Epoch 95, Train Loss: 0.5392, Val Loss: 0.5181, F1 Micro: 0.7000, F1 Macro: 0.6988, Accuracy: 0.7000\n","Epoch 96, Train Loss: 0.5407, Val Loss: 0.5292, F1 Micro: 0.6844, F1 Macro: 0.6844, Accuracy: 0.6844\n","Epoch 97, Train Loss: 0.5404, Val Loss: 0.5425, F1 Micro: 0.7250, F1 Macro: 0.7112, Accuracy: 0.7250\n","Epoch 98, Train Loss: 0.5428, Val Loss: 0.5321, F1 Micro: 0.7250, F1 Macro: 0.7246, Accuracy: 0.7250\n","Epoch 99, Train Loss: 0.5360, Val Loss: 0.5139, F1 Micro: 0.6937, F1 Macro: 0.6903, Accuracy: 0.6937\n","Epoch 100, Train Loss: 0.5472, Val Loss: 0.5202, F1 Micro: 0.6937, F1 Macro: 0.6884, Accuracy: 0.6937\n","Epoch 101, Train Loss: 0.5382, Val Loss: 0.5189, F1 Micro: 0.6937, F1 Macro: 0.6907, Accuracy: 0.6937\n","Epoch 102, Train Loss: 0.5427, Val Loss: 0.5256, F1 Micro: 0.6969, F1 Macro: 0.6908, Accuracy: 0.6969\n","Epoch 103, Train Loss: 0.5427, Val Loss: 0.5406, F1 Micro: 0.7156, F1 Macro: 0.7141, Accuracy: 0.7156\n","Epoch 104, Train Loss: 0.5353, Val Loss: 0.5135, F1 Micro: 0.6969, F1 Macro: 0.6950, Accuracy: 0.6969\n","Epoch 105, Train Loss: 0.5353, Val Loss: 0.5118, F1 Micro: 0.6937, F1 Macro: 0.6903, Accuracy: 0.6937\n","Epoch 106, Train Loss: 0.5369, Val Loss: 0.5635, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 107, Train Loss: 0.5379, Val Loss: 0.5159, F1 Micro: 0.7156, F1 Macro: 0.7154, Accuracy: 0.7156\n","Epoch 108, Train Loss: 0.5346, Val Loss: 0.5238, F1 Micro: 0.7000, F1 Macro: 0.6931, Accuracy: 0.7000\n","Epoch 109, Train Loss: 0.5343, Val Loss: 0.5451, F1 Micro: 0.6906, F1 Macro: 0.6897, Accuracy: 0.6906\n","Epoch 110, Train Loss: 0.5390, Val Loss: 0.5403, F1 Micro: 0.7156, F1 Macro: 0.7049, Accuracy: 0.7156\n","Epoch 111, Train Loss: 0.5414, Val Loss: 0.5135, F1 Micro: 0.7000, F1 Macro: 0.6988, Accuracy: 0.7000\n","Epoch 112, Train Loss: 0.5410, Val Loss: 0.5334, F1 Micro: 0.7125, F1 Macro: 0.7116, Accuracy: 0.7125\n","Epoch 113, Train Loss: 0.5322, Val Loss: 0.5259, F1 Micro: 0.6969, F1 Macro: 0.6913, Accuracy: 0.6969\n","Epoch 114, Train Loss: 0.5544, Val Loss: 0.5651, F1 Micro: 0.7312, F1 Macro: 0.7221, Accuracy: 0.7312\n","Epoch 115, Train Loss: 0.5331, Val Loss: 0.5149, F1 Micro: 0.6969, F1 Macro: 0.6932, Accuracy: 0.6969\n","Epoch 116, Train Loss: 0.5255, Val Loss: 0.5310, F1 Micro: 0.7125, F1 Macro: 0.7013, Accuracy: 0.7125\n","Epoch 117, Train Loss: 0.5294, Val Loss: 0.5445, F1 Micro: 0.7094, F1 Macro: 0.6991, Accuracy: 0.7094\n","Epoch 118, Train Loss: 0.5301, Val Loss: 0.5119, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 119, Train Loss: 0.5239, Val Loss: 0.5085, F1 Micro: 0.7063, F1 Macro: 0.7029, Accuracy: 0.7063\n","Epoch 120, Train Loss: 0.5456, Val Loss: 0.5493, F1 Micro: 0.7063, F1 Macro: 0.6932, Accuracy: 0.7063\n","Epoch 121, Train Loss: 0.5346, Val Loss: 0.5402, F1 Micro: 0.7156, F1 Macro: 0.7009, Accuracy: 0.7156\n","Epoch 122, Train Loss: 0.5335, Val Loss: 0.5482, F1 Micro: 0.7063, F1 Macro: 0.6924, Accuracy: 0.7063\n","Epoch 123, Train Loss: 0.5419, Val Loss: 0.5116, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 124, Train Loss: 0.5323, Val Loss: 0.5226, F1 Micro: 0.6906, F1 Macro: 0.6849, Accuracy: 0.6906\n","Epoch 125, Train Loss: 0.5190, Val Loss: 0.5214, F1 Micro: 0.7406, F1 Macro: 0.7403, Accuracy: 0.7406\n","Epoch 126, Train Loss: 0.5286, Val Loss: 0.5483, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 127, Train Loss: 0.5449, Val Loss: 0.5344, F1 Micro: 0.7094, F1 Macro: 0.6991, Accuracy: 0.7094\n","Epoch 128, Train Loss: 0.5223, Val Loss: 0.5273, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 129, Train Loss: 0.5316, Val Loss: 0.5527, F1 Micro: 0.7094, F1 Macro: 0.6952, Accuracy: 0.7094\n","Epoch 130, Train Loss: 0.5345, Val Loss: 0.5177, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 131, Train Loss: 0.5336, Val Loss: 0.5160, F1 Micro: 0.7156, F1 Macro: 0.7088, Accuracy: 0.7156\n","Epoch 132, Train Loss: 0.5301, Val Loss: 0.5163, F1 Micro: 0.7063, F1 Macro: 0.7058, Accuracy: 0.7063\n","Epoch 133, Train Loss: 0.5275, Val Loss: 0.5038, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 134, Train Loss: 0.5177, Val Loss: 0.5219, F1 Micro: 0.7469, F1 Macro: 0.7448, Accuracy: 0.7469\n","Epoch 135, Train Loss: 0.5227, Val Loss: 0.5094, F1 Micro: 0.7156, F1 Macro: 0.7141, Accuracy: 0.7156\n","Epoch 136, Train Loss: 0.5238, Val Loss: 0.5282, F1 Micro: 0.7125, F1 Macro: 0.7047, Accuracy: 0.7125\n","Epoch 137, Train Loss: 0.5376, Val Loss: 0.5232, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 138, Train Loss: 0.5238, Val Loss: 0.4993, F1 Micro: 0.7156, F1 Macro: 0.7148, Accuracy: 0.7156\n","Epoch 139, Train Loss: 0.5234, Val Loss: 0.5161, F1 Micro: 0.7625, F1 Macro: 0.7616, Accuracy: 0.7625\n","Epoch 140, Train Loss: 0.5098, Val Loss: 0.5027, F1 Micro: 0.7438, F1 Macro: 0.7434, Accuracy: 0.7438\n","Epoch 141, Train Loss: 0.5245, Val Loss: 0.5030, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 142, Train Loss: 0.5245, Val Loss: 0.5138, F1 Micro: 0.7188, F1 Macro: 0.7176, Accuracy: 0.7188\n","Epoch 143, Train Loss: 0.5171, Val Loss: 0.5085, F1 Micro: 0.7188, F1 Macro: 0.7133, Accuracy: 0.7188\n","Epoch 144, Train Loss: 0.5207, Val Loss: 0.5217, F1 Micro: 0.7375, F1 Macro: 0.7348, Accuracy: 0.7375\n","Epoch 145, Train Loss: 0.5156, Val Loss: 0.5092, F1 Micro: 0.7063, F1 Macro: 0.7011, Accuracy: 0.7063\n","Epoch 146, Train Loss: 0.5124, Val Loss: 0.5115, F1 Micro: 0.7344, F1 Macro: 0.7336, Accuracy: 0.7344\n","Epoch 147, Train Loss: 0.5216, Val Loss: 0.5026, F1 Micro: 0.7312, F1 Macro: 0.7306, Accuracy: 0.7312\n","Epoch 148, Train Loss: 0.5105, Val Loss: 0.4947, F1 Micro: 0.7188, F1 Macro: 0.7176, Accuracy: 0.7188\n","Epoch 149, Train Loss: 0.5207, Val Loss: 0.5007, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 150, Train Loss: 0.5180, Val Loss: 0.5058, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 151, Train Loss: 0.5105, Val Loss: 0.5071, F1 Micro: 0.7031, F1 Macro: 0.6986, Accuracy: 0.7031\n","Epoch 152, Train Loss: 0.5222, Val Loss: 0.5243, F1 Micro: 0.6969, F1 Macro: 0.6918, Accuracy: 0.6969\n","Epoch 153, Train Loss: 0.5137, Val Loss: 0.5107, F1 Micro: 0.7063, F1 Macro: 0.7016, Accuracy: 0.7063\n","Epoch 154, Train Loss: 0.5269, Val Loss: 0.5116, F1 Micro: 0.7031, F1 Macro: 0.6995, Accuracy: 0.7031\n","Epoch 155, Train Loss: 0.5309, Val Loss: 0.5089, F1 Micro: 0.7281, F1 Macro: 0.7267, Accuracy: 0.7281\n","Epoch 156, Train Loss: 0.5181, Val Loss: 0.5240, F1 Micro: 0.7625, F1 Macro: 0.7617, Accuracy: 0.7625\n","Epoch 157, Train Loss: 0.5256, Val Loss: 0.5083, F1 Micro: 0.7094, F1 Macro: 0.7087, Accuracy: 0.7094\n","Epoch 158, Train Loss: 0.5127, Val Loss: 0.4986, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 159, Train Loss: 0.5057, Val Loss: 0.4979, F1 Micro: 0.7219, F1 Macro: 0.7192, Accuracy: 0.7219\n","Epoch 160, Train Loss: 0.5126, Val Loss: 0.5078, F1 Micro: 0.7594, F1 Macro: 0.7594, Accuracy: 0.7594\n","Epoch 161, Train Loss: 0.5138, Val Loss: 0.5026, F1 Micro: 0.7219, F1 Macro: 0.7199, Accuracy: 0.7219\n","Epoch 162, Train Loss: 0.5050, Val Loss: 0.5059, F1 Micro: 0.7281, F1 Macro: 0.7272, Accuracy: 0.7281\n","Epoch 163, Train Loss: 0.5148, Val Loss: 0.5004, F1 Micro: 0.7250, F1 Macro: 0.7232, Accuracy: 0.7250\n","Epoch 164, Train Loss: 0.5071, Val Loss: 0.5157, F1 Micro: 0.7156, F1 Macro: 0.7094, Accuracy: 0.7156\n","Epoch 165, Train Loss: 0.5124, Val Loss: 0.5116, F1 Micro: 0.7281, F1 Macro: 0.7262, Accuracy: 0.7281\n","Epoch 166, Train Loss: 0.5066, Val Loss: 0.4975, F1 Micro: 0.7312, F1 Macro: 0.7307, Accuracy: 0.7312\n","Epoch 167, Train Loss: 0.5158, Val Loss: 0.4977, F1 Micro: 0.7438, F1 Macro: 0.7433, Accuracy: 0.7438\n","Epoch 168, Train Loss: 0.4997, Val Loss: 0.5049, F1 Micro: 0.7094, F1 Macro: 0.7059, Accuracy: 0.7094\n","Epoch 169, Train Loss: 0.5118, Val Loss: 0.5040, F1 Micro: 0.7156, F1 Macro: 0.7129, Accuracy: 0.7156\n","Epoch 170, Train Loss: 0.5008, Val Loss: 0.4991, F1 Micro: 0.7188, F1 Macro: 0.7147, Accuracy: 0.7188\n","Epoch 171, Train Loss: 0.5093, Val Loss: 0.5095, F1 Micro: 0.7312, F1 Macro: 0.7295, Accuracy: 0.7312\n","Epoch 172, Train Loss: 0.5038, Val Loss: 0.4980, F1 Micro: 0.7406, F1 Macro: 0.7399, Accuracy: 0.7406\n","Epoch 173, Train Loss: 0.5133, Val Loss: 0.4997, F1 Micro: 0.7500, F1 Macro: 0.7499, Accuracy: 0.7500\n","Epoch 174, Train Loss: 0.5109, Val Loss: 0.5054, F1 Micro: 0.7344, F1 Macro: 0.7299, Accuracy: 0.7344\n","Epoch 175, Train Loss: 0.5062, Val Loss: 0.4947, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 176, Train Loss: 0.5095, Val Loss: 0.5059, F1 Micro: 0.7312, F1 Macro: 0.7295, Accuracy: 0.7312\n","Epoch 177, Train Loss: 0.4997, Val Loss: 0.5004, F1 Micro: 0.7188, F1 Macro: 0.7166, Accuracy: 0.7188\n","Epoch 178, Train Loss: 0.5209, Val Loss: 0.4979, F1 Micro: 0.7375, F1 Macro: 0.7368, Accuracy: 0.7375\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.5841, Val Loss: 0.7356, F1 Micro: 0.6438, F1 Macro: 0.6035, Accuracy: 0.6438\n","Epoch 2, Train Loss: 0.5911, Val Loss: 0.6127, F1 Micro: 0.6500, F1 Macro: 0.6469, Accuracy: 0.6500\n","Epoch 3, Train Loss: 0.5724, Val Loss: 0.6448, F1 Micro: 0.6438, F1 Macro: 0.6417, Accuracy: 0.6438\n","Epoch 4, Train Loss: 0.5734, Val Loss: 0.6089, F1 Micro: 0.6750, F1 Macro: 0.6749, Accuracy: 0.6750\n","Epoch 5, Train Loss: 0.5783, Val Loss: 0.6194, F1 Micro: 0.6781, F1 Macro: 0.6779, Accuracy: 0.6781\n","Epoch 6, Train Loss: 0.5687, Val Loss: 0.6097, F1 Micro: 0.6687, F1 Macro: 0.6686, Accuracy: 0.6687\n","Epoch 7, Train Loss: 0.5641, Val Loss: 0.6293, F1 Micro: 0.6656, F1 Macro: 0.6649, Accuracy: 0.6656\n","Epoch 8, Train Loss: 0.5622, Val Loss: 0.6711, F1 Micro: 0.6250, F1 Macro: 0.6164, Accuracy: 0.6250\n","Epoch 9, Train Loss: 0.5657, Val Loss: 0.6209, F1 Micro: 0.6750, F1 Macro: 0.6747, Accuracy: 0.6750\n","Epoch 10, Train Loss: 0.5603, Val Loss: 0.7199, F1 Micro: 0.6250, F1 Macro: 0.6062, Accuracy: 0.6250\n","Epoch 11, Train Loss: 0.5561, Val Loss: 0.6910, F1 Micro: 0.6250, F1 Macro: 0.6132, Accuracy: 0.6250\n","Epoch 12, Train Loss: 0.5624, Val Loss: 0.6467, F1 Micro: 0.6344, F1 Macro: 0.6309, Accuracy: 0.6344\n","Epoch 13, Train Loss: 0.5593, Val Loss: 0.6251, F1 Micro: 0.6656, F1 Macro: 0.6649, Accuracy: 0.6656\n","Epoch 14, Train Loss: 0.5637, Val Loss: 0.6197, F1 Micro: 0.6656, F1 Macro: 0.6656, Accuracy: 0.6656\n","Epoch 15, Train Loss: 0.5557, Val Loss: 0.6209, F1 Micro: 0.6750, F1 Macro: 0.6750, Accuracy: 0.6750\n","Epoch 16, Train Loss: 0.5594, Val Loss: 0.6093, F1 Micro: 0.6656, F1 Macro: 0.6655, Accuracy: 0.6656\n","Epoch 17, Train Loss: 0.5604, Val Loss: 0.5980, F1 Micro: 0.6562, F1 Macro: 0.6476, Accuracy: 0.6562\n","Epoch 18, Train Loss: 0.5517, Val Loss: 0.6009, F1 Micro: 0.6656, F1 Macro: 0.6642, Accuracy: 0.6656\n","Epoch 19, Train Loss: 0.5652, Val Loss: 0.5949, F1 Micro: 0.6562, F1 Macro: 0.6536, Accuracy: 0.6562\n","Epoch 20, Train Loss: 0.5613, Val Loss: 0.6301, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 21, Train Loss: 0.5614, Val Loss: 0.6164, F1 Micro: 0.6656, F1 Macro: 0.6652, Accuracy: 0.6656\n","Epoch 22, Train Loss: 0.5529, Val Loss: 0.6222, F1 Micro: 0.6500, F1 Macro: 0.6489, Accuracy: 0.6500\n","Epoch 23, Train Loss: 0.5573, Val Loss: 0.5973, F1 Micro: 0.6656, F1 Macro: 0.6649, Accuracy: 0.6656\n","Epoch 24, Train Loss: 0.5468, Val Loss: 0.6543, F1 Micro: 0.6250, F1 Macro: 0.6202, Accuracy: 0.6250\n","Epoch 25, Train Loss: 0.5493, Val Loss: 0.6077, F1 Micro: 0.6656, F1 Macro: 0.6652, Accuracy: 0.6656\n","Epoch 26, Train Loss: 0.5564, Val Loss: 0.6053, F1 Micro: 0.6625, F1 Macro: 0.6620, Accuracy: 0.6625\n","Epoch 27, Train Loss: 0.5497, Val Loss: 0.5937, F1 Micro: 0.6562, F1 Macro: 0.6523, Accuracy: 0.6562\n","Epoch 28, Train Loss: 0.5604, Val Loss: 0.6077, F1 Micro: 0.6469, F1 Macro: 0.6447, Accuracy: 0.6469\n","Epoch 29, Train Loss: 0.5495, Val Loss: 0.6097, F1 Micro: 0.6500, F1 Macro: 0.6491, Accuracy: 0.6500\n","Epoch 30, Train Loss: 0.5428, Val Loss: 0.6224, F1 Micro: 0.6438, F1 Macro: 0.6417, Accuracy: 0.6438\n","Epoch 31, Train Loss: 0.5468, Val Loss: 0.6395, F1 Micro: 0.6281, F1 Macro: 0.6231, Accuracy: 0.6281\n","Epoch 32, Train Loss: 0.5476, Val Loss: 0.6199, F1 Micro: 0.6406, F1 Macro: 0.6376, Accuracy: 0.6406\n","Epoch 33, Train Loss: 0.5597, Val Loss: 0.6014, F1 Micro: 0.6594, F1 Macro: 0.6590, Accuracy: 0.6594\n","Epoch 34, Train Loss: 0.5482, Val Loss: 0.6128, F1 Micro: 0.6500, F1 Macro: 0.6489, Accuracy: 0.6500\n","Epoch 35, Train Loss: 0.5458, Val Loss: 0.5965, F1 Micro: 0.6562, F1 Macro: 0.6536, Accuracy: 0.6562\n","Epoch 36, Train Loss: 0.5606, Val Loss: 0.5977, F1 Micro: 0.6594, F1 Macro: 0.6594, Accuracy: 0.6594\n","Epoch 37, Train Loss: 0.5463, Val Loss: 0.6038, F1 Micro: 0.6406, F1 Macro: 0.6388, Accuracy: 0.6406\n","Epoch 38, Train Loss: 0.5535, Val Loss: 0.6003, F1 Micro: 0.6406, F1 Macro: 0.6391, Accuracy: 0.6406\n","Epoch 39, Train Loss: 0.5533, Val Loss: 0.6076, F1 Micro: 0.6562, F1 Macro: 0.6549, Accuracy: 0.6562\n","Epoch 40, Train Loss: 0.5464, Val Loss: 0.6061, F1 Micro: 0.6344, F1 Macro: 0.6318, Accuracy: 0.6344\n","Epoch 41, Train Loss: 0.5489, Val Loss: 0.5889, F1 Micro: 0.6625, F1 Macro: 0.6603, Accuracy: 0.6625\n","Epoch 42, Train Loss: 0.5445, Val Loss: 0.6074, F1 Micro: 0.6687, F1 Macro: 0.6677, Accuracy: 0.6687\n","Epoch 43, Train Loss: 0.5598, Val Loss: 0.5936, F1 Micro: 0.6625, F1 Macro: 0.6571, Accuracy: 0.6625\n","Epoch 44, Train Loss: 0.5511, Val Loss: 0.6049, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 45, Train Loss: 0.5439, Val Loss: 0.6016, F1 Micro: 0.6438, F1 Macro: 0.6406, Accuracy: 0.6438\n","Epoch 46, Train Loss: 0.5493, Val Loss: 0.6331, F1 Micro: 0.6281, F1 Macro: 0.6231, Accuracy: 0.6281\n","Epoch 47, Train Loss: 0.5534, Val Loss: 0.5865, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 48, Train Loss: 0.5449, Val Loss: 0.5998, F1 Micro: 0.6531, F1 Macro: 0.6527, Accuracy: 0.6531\n","Epoch 49, Train Loss: 0.5445, Val Loss: 0.6339, F1 Micro: 0.6312, F1 Macro: 0.6248, Accuracy: 0.6312\n","Epoch 50, Train Loss: 0.5469, Val Loss: 0.6054, F1 Micro: 0.6562, F1 Macro: 0.6428, Accuracy: 0.6562\n","Epoch 51, Train Loss: 0.5389, Val Loss: 0.6151, F1 Micro: 0.6406, F1 Macro: 0.6352, Accuracy: 0.6406\n","Epoch 52, Train Loss: 0.5428, Val Loss: 0.5972, F1 Micro: 0.6687, F1 Macro: 0.6687, Accuracy: 0.6687\n","Epoch 53, Train Loss: 0.5465, Val Loss: 0.5802, F1 Micro: 0.6656, F1 Macro: 0.6647, Accuracy: 0.6656\n","Epoch 54, Train Loss: 0.5468, Val Loss: 0.5844, F1 Micro: 0.6562, F1 Macro: 0.6556, Accuracy: 0.6562\n","Epoch 55, Train Loss: 0.5472, Val Loss: 0.5940, F1 Micro: 0.6531, F1 Macro: 0.6521, Accuracy: 0.6531\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6024, Val Loss: 0.5445, F1 Micro: 0.7000, F1 Macro: 0.6988, Accuracy: 0.7000\n","Epoch 2, Train Loss: 0.5967, Val Loss: 0.5507, F1 Micro: 0.6906, F1 Macro: 0.6884, Accuracy: 0.6906\n","Epoch 3, Train Loss: 0.5941, Val Loss: 0.5453, F1 Micro: 0.6969, F1 Macro: 0.6953, Accuracy: 0.6969\n","Epoch 4, Train Loss: 0.5872, Val Loss: 0.5325, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 5, Train Loss: 0.5910, Val Loss: 0.5724, F1 Micro: 0.6937, F1 Macro: 0.6722, Accuracy: 0.6937\n","Epoch 6, Train Loss: 0.6152, Val Loss: 0.5390, F1 Micro: 0.7000, F1 Macro: 0.6997, Accuracy: 0.7000\n","Epoch 7, Train Loss: 0.5911, Val Loss: 0.5388, F1 Micro: 0.7000, F1 Macro: 0.6997, Accuracy: 0.7000\n","Epoch 8, Train Loss: 0.5853, Val Loss: 0.5524, F1 Micro: 0.6937, F1 Macro: 0.6917, Accuracy: 0.6937\n","Epoch 9, Train Loss: 0.5900, Val Loss: 0.5402, F1 Micro: 0.7344, F1 Macro: 0.7290, Accuracy: 0.7344\n","Epoch 10, Train Loss: 0.5852, Val Loss: 0.5349, F1 Micro: 0.7344, F1 Macro: 0.7319, Accuracy: 0.7344\n","Epoch 11, Train Loss: 0.5802, Val Loss: 0.5400, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 12, Train Loss: 0.5794, Val Loss: 0.5300, F1 Micro: 0.7406, F1 Macro: 0.7390, Accuracy: 0.7406\n","Epoch 13, Train Loss: 0.5819, Val Loss: 0.5401, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 14, Train Loss: 0.5806, Val Loss: 0.5278, F1 Micro: 0.7094, F1 Macro: 0.7091, Accuracy: 0.7094\n","Epoch 15, Train Loss: 0.5834, Val Loss: 0.5299, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 16, Train Loss: 0.5768, Val Loss: 0.5270, F1 Micro: 0.7063, F1 Macro: 0.7060, Accuracy: 0.7063\n","Epoch 17, Train Loss: 0.5738, Val Loss: 0.5583, F1 Micro: 0.6906, F1 Macro: 0.6884, Accuracy: 0.6906\n","Epoch 18, Train Loss: 0.5754, Val Loss: 0.5754, F1 Micro: 0.6875, F1 Macro: 0.6820, Accuracy: 0.6875\n","Epoch 19, Train Loss: 0.5831, Val Loss: 0.5546, F1 Micro: 0.6906, F1 Macro: 0.6881, Accuracy: 0.6906\n","Epoch 20, Train Loss: 0.5717, Val Loss: 0.5521, F1 Micro: 0.7000, F1 Macro: 0.6858, Accuracy: 0.7000\n","Epoch 21, Train Loss: 0.5858, Val Loss: 0.5291, F1 Micro: 0.7312, F1 Macro: 0.7285, Accuracy: 0.7312\n","Epoch 22, Train Loss: 0.5765, Val Loss: 0.5375, F1 Micro: 0.6906, F1 Macro: 0.6901, Accuracy: 0.6906\n","Epoch 23, Train Loss: 0.5747, Val Loss: 0.5254, F1 Micro: 0.7219, F1 Macro: 0.7209, Accuracy: 0.7219\n","Epoch 24, Train Loss: 0.5766, Val Loss: 0.5278, F1 Micro: 0.7375, F1 Macro: 0.7348, Accuracy: 0.7375\n","Epoch 25, Train Loss: 0.5726, Val Loss: 0.5526, F1 Micro: 0.6969, F1 Macro: 0.6802, Accuracy: 0.6969\n","Epoch 26, Train Loss: 0.5760, Val Loss: 0.5356, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 27, Train Loss: 0.5707, Val Loss: 0.5273, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 28, Train Loss: 0.5738, Val Loss: 0.5254, F1 Micro: 0.7031, F1 Macro: 0.7031, Accuracy: 0.7031\n","Epoch 29, Train Loss: 0.5774, Val Loss: 0.5302, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 30, Train Loss: 0.5729, Val Loss: 0.5371, F1 Micro: 0.6969, F1 Macro: 0.6965, Accuracy: 0.6969\n","Epoch 31, Train Loss: 0.5762, Val Loss: 0.5225, F1 Micro: 0.7375, F1 Macro: 0.7358, Accuracy: 0.7375\n","Epoch 32, Train Loss: 0.5692, Val Loss: 0.5272, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 33, Train Loss: 0.5653, Val Loss: 0.5390, F1 Micro: 0.6969, F1 Macro: 0.6962, Accuracy: 0.6969\n","Epoch 34, Train Loss: 0.5651, Val Loss: 0.5200, F1 Micro: 0.7031, F1 Macro: 0.7029, Accuracy: 0.7031\n","Epoch 35, Train Loss: 0.5665, Val Loss: 0.5277, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 36, Train Loss: 0.5675, Val Loss: 0.5314, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 37, Train Loss: 0.5653, Val Loss: 0.5206, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 38, Train Loss: 0.5639, Val Loss: 0.5496, F1 Micro: 0.7031, F1 Macro: 0.7026, Accuracy: 0.7031\n","Epoch 39, Train Loss: 0.5654, Val Loss: 0.5643, F1 Micro: 0.6906, F1 Macro: 0.6881, Accuracy: 0.6906\n","Epoch 40, Train Loss: 0.5682, Val Loss: 0.5243, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 41, Train Loss: 0.5597, Val Loss: 0.5252, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 42, Train Loss: 0.5619, Val Loss: 0.5207, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 43, Train Loss: 0.5624, Val Loss: 0.5212, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 44, Train Loss: 0.5610, Val Loss: 0.5172, F1 Micro: 0.7375, F1 Macro: 0.7352, Accuracy: 0.7375\n","Epoch 45, Train Loss: 0.5776, Val Loss: 0.5463, F1 Micro: 0.6937, F1 Macro: 0.6920, Accuracy: 0.6937\n","Epoch 46, Train Loss: 0.5702, Val Loss: 0.5179, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 47, Train Loss: 0.5624, Val Loss: 0.5354, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 48, Train Loss: 0.5643, Val Loss: 0.5166, F1 Micro: 0.7344, F1 Macro: 0.7322, Accuracy: 0.7344\n","Epoch 49, Train Loss: 0.5573, Val Loss: 0.5375, F1 Micro: 0.7094, F1 Macro: 0.7083, Accuracy: 0.7094\n","Epoch 50, Train Loss: 0.5616, Val Loss: 0.5142, F1 Micro: 0.7125, F1 Macro: 0.7119, Accuracy: 0.7125\n","Epoch 51, Train Loss: 0.5679, Val Loss: 0.5342, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 52, Train Loss: 0.5608, Val Loss: 0.5137, F1 Micro: 0.7125, F1 Macro: 0.7119, Accuracy: 0.7125\n","Epoch 53, Train Loss: 0.5595, Val Loss: 0.5164, F1 Micro: 0.7063, F1 Macro: 0.7061, Accuracy: 0.7063\n","Epoch 54, Train Loss: 0.5507, Val Loss: 0.5143, F1 Micro: 0.7438, F1 Macro: 0.7401, Accuracy: 0.7438\n","Epoch 55, Train Loss: 0.5624, Val Loss: 0.5212, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 56, Train Loss: 0.5672, Val Loss: 0.5115, F1 Micro: 0.7344, F1 Macro: 0.7327, Accuracy: 0.7344\n","Epoch 57, Train Loss: 0.5592, Val Loss: 0.5229, F1 Micro: 0.7094, F1 Macro: 0.7094, Accuracy: 0.7094\n","Epoch 58, Train Loss: 0.5566, Val Loss: 0.5165, F1 Micro: 0.7031, F1 Macro: 0.7030, Accuracy: 0.7031\n","Epoch 59, Train Loss: 0.5574, Val Loss: 0.5125, F1 Micro: 0.7125, F1 Macro: 0.7121, Accuracy: 0.7125\n","Epoch 60, Train Loss: 0.5586, Val Loss: 0.5122, F1 Micro: 0.7500, F1 Macro: 0.7475, Accuracy: 0.7500\n","Epoch 61, Train Loss: 0.5615, Val Loss: 0.5134, F1 Micro: 0.7469, F1 Macro: 0.7453, Accuracy: 0.7469\n","Epoch 62, Train Loss: 0.5499, Val Loss: 0.5080, F1 Micro: 0.7375, F1 Macro: 0.7363, Accuracy: 0.7375\n","Epoch 63, Train Loss: 0.5502, Val Loss: 0.5150, F1 Micro: 0.7438, F1 Macro: 0.7383, Accuracy: 0.7438\n","Epoch 64, Train Loss: 0.5505, Val Loss: 0.5119, F1 Micro: 0.7312, F1 Macro: 0.7292, Accuracy: 0.7312\n","Epoch 65, Train Loss: 0.5631, Val Loss: 0.5537, F1 Micro: 0.7188, F1 Macro: 0.7182, Accuracy: 0.7188\n","Epoch 66, Train Loss: 0.5619, Val Loss: 0.5095, F1 Micro: 0.7250, F1 Macro: 0.7241, Accuracy: 0.7250\n","Epoch 67, Train Loss: 0.5582, Val Loss: 0.5341, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 68, Train Loss: 0.5590, Val Loss: 0.5096, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 69, Train Loss: 0.5547, Val Loss: 0.5321, F1 Micro: 0.7250, F1 Macro: 0.7247, Accuracy: 0.7250\n","Epoch 70, Train Loss: 0.5533, Val Loss: 0.5123, F1 Micro: 0.7094, F1 Macro: 0.7092, Accuracy: 0.7094\n","Epoch 71, Train Loss: 0.5485, Val Loss: 0.5079, F1 Micro: 0.7469, F1 Macro: 0.7453, Accuracy: 0.7469\n","Epoch 72, Train Loss: 0.5486, Val Loss: 0.5066, F1 Micro: 0.7156, F1 Macro: 0.7150, Accuracy: 0.7156\n","Epoch 73, Train Loss: 0.5498, Val Loss: 0.5046, F1 Micro: 0.7375, F1 Macro: 0.7360, Accuracy: 0.7375\n","Epoch 74, Train Loss: 0.5569, Val Loss: 0.5075, F1 Micro: 0.7531, F1 Macro: 0.7494, Accuracy: 0.7531\n","Epoch 75, Train Loss: 0.5555, Val Loss: 0.5213, F1 Micro: 0.7188, F1 Macro: 0.7188, Accuracy: 0.7188\n","Epoch 76, Train Loss: 0.5494, Val Loss: 0.5084, F1 Micro: 0.7219, F1 Macro: 0.7207, Accuracy: 0.7219\n","Epoch 77, Train Loss: 0.5544, Val Loss: 0.5166, F1 Micro: 0.7625, F1 Macro: 0.7575, Accuracy: 0.7625\n","Epoch 78, Train Loss: 0.5485, Val Loss: 0.5153, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 79, Train Loss: 0.5500, Val Loss: 0.5176, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 80, Train Loss: 0.5499, Val Loss: 0.5193, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 81, Train Loss: 0.5535, Val Loss: 0.5151, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 82, Train Loss: 0.5479, Val Loss: 0.5247, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 83, Train Loss: 0.5538, Val Loss: 0.5031, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 84, Train Loss: 0.5497, Val Loss: 0.5261, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 85, Train Loss: 0.5515, Val Loss: 0.5136, F1 Micro: 0.7375, F1 Macro: 0.7292, Accuracy: 0.7375\n","Epoch 86, Train Loss: 0.5526, Val Loss: 0.5022, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 87, Train Loss: 0.5496, Val Loss: 0.5109, F1 Micro: 0.7469, F1 Macro: 0.7392, Accuracy: 0.7469\n","Epoch 88, Train Loss: 0.5415, Val Loss: 0.5150, F1 Micro: 0.7156, F1 Macro: 0.7156, Accuracy: 0.7156\n","Epoch 89, Train Loss: 0.5464, Val Loss: 0.5080, F1 Micro: 0.7188, F1 Macro: 0.7186, Accuracy: 0.7188\n","Epoch 90, Train Loss: 0.5452, Val Loss: 0.4986, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 91, Train Loss: 0.5494, Val Loss: 0.5080, F1 Micro: 0.7219, F1 Macro: 0.7217, Accuracy: 0.7219\n","Epoch 92, Train Loss: 0.5486, Val Loss: 0.4996, F1 Micro: 0.7438, F1 Macro: 0.7420, Accuracy: 0.7438\n","Epoch 93, Train Loss: 0.5459, Val Loss: 0.5141, F1 Micro: 0.7125, F1 Macro: 0.7124, Accuracy: 0.7125\n","Epoch 94, Train Loss: 0.5398, Val Loss: 0.5123, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 95, Train Loss: 0.5418, Val Loss: 0.4984, F1 Micro: 0.7500, F1 Macro: 0.7460, Accuracy: 0.7500\n","Epoch 96, Train Loss: 0.5406, Val Loss: 0.4940, F1 Micro: 0.7406, F1 Macro: 0.7378, Accuracy: 0.7406\n","Epoch 97, Train Loss: 0.5487, Val Loss: 0.5083, F1 Micro: 0.7312, F1 Macro: 0.7309, Accuracy: 0.7312\n","Epoch 98, Train Loss: 0.5442, Val Loss: 0.5032, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 99, Train Loss: 0.5444, Val Loss: 0.5042, F1 Micro: 0.7250, F1 Macro: 0.7248, Accuracy: 0.7250\n","Epoch 100, Train Loss: 0.5339, Val Loss: 0.5437, F1 Micro: 0.7219, F1 Macro: 0.7209, Accuracy: 0.7219\n","Epoch 101, Train Loss: 0.5450, Val Loss: 0.4993, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 102, Train Loss: 0.5445, Val Loss: 0.4931, F1 Micro: 0.7375, F1 Macro: 0.7363, Accuracy: 0.7375\n","Epoch 103, Train Loss: 0.5430, Val Loss: 0.5024, F1 Micro: 0.7438, F1 Macro: 0.7373, Accuracy: 0.7438\n","Epoch 104, Train Loss: 0.5478, Val Loss: 0.4970, F1 Micro: 0.7656, F1 Macro: 0.7613, Accuracy: 0.7656\n","Epoch 105, Train Loss: 0.5449, Val Loss: 0.5065, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 106, Train Loss: 0.5505, Val Loss: 0.5481, F1 Micro: 0.7156, F1 Macro: 0.7139, Accuracy: 0.7156\n","Epoch 107, Train Loss: 0.5440, Val Loss: 0.4945, F1 Micro: 0.7375, F1 Macro: 0.7358, Accuracy: 0.7375\n","Epoch 108, Train Loss: 0.5384, Val Loss: 0.4996, F1 Micro: 0.7188, F1 Macro: 0.7184, Accuracy: 0.7188\n","Epoch 109, Train Loss: 0.5352, Val Loss: 0.4999, F1 Micro: 0.7375, F1 Macro: 0.7292, Accuracy: 0.7375\n","Epoch 110, Train Loss: 0.5441, Val Loss: 0.5124, F1 Micro: 0.7312, F1 Macro: 0.7177, Accuracy: 0.7312\n","Epoch 111, Train Loss: 0.5413, Val Loss: 0.4937, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 112, Train Loss: 0.5462, Val Loss: 0.5192, F1 Micro: 0.7281, F1 Macro: 0.7281, Accuracy: 0.7281\n","Epoch 113, Train Loss: 0.5307, Val Loss: 0.5007, F1 Micro: 0.7250, F1 Macro: 0.7247, Accuracy: 0.7250\n","Epoch 114, Train Loss: 0.5437, Val Loss: 0.4929, F1 Micro: 0.7312, F1 Macro: 0.7304, Accuracy: 0.7312\n","Epoch 115, Train Loss: 0.5331, Val Loss: 0.4906, F1 Micro: 0.7688, F1 Macro: 0.7643, Accuracy: 0.7688\n","Epoch 116, Train Loss: 0.5368, Val Loss: 0.5005, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 117, Train Loss: 0.5285, Val Loss: 0.4851, F1 Micro: 0.7562, F1 Macro: 0.7531, Accuracy: 0.7562\n","Epoch 118, Train Loss: 0.5405, Val Loss: 0.4895, F1 Micro: 0.7312, F1 Macro: 0.7304, Accuracy: 0.7312\n","Epoch 119, Train Loss: 0.5253, Val Loss: 0.5309, F1 Micro: 0.7312, F1 Macro: 0.7309, Accuracy: 0.7312\n","Epoch 120, Train Loss: 0.5371, Val Loss: 0.4834, F1 Micro: 0.7406, F1 Macro: 0.7382, Accuracy: 0.7406\n","Epoch 121, Train Loss: 0.5341, Val Loss: 0.4838, F1 Micro: 0.7562, F1 Macro: 0.7528, Accuracy: 0.7562\n","Epoch 122, Train Loss: 0.5383, Val Loss: 0.4885, F1 Micro: 0.7500, F1 Macro: 0.7481, Accuracy: 0.7500\n","Epoch 123, Train Loss: 0.5415, Val Loss: 0.4989, F1 Micro: 0.7281, F1 Macro: 0.7279, Accuracy: 0.7281\n","Epoch 124, Train Loss: 0.5346, Val Loss: 0.4865, F1 Micro: 0.7344, F1 Macro: 0.7334, Accuracy: 0.7344\n","Epoch 125, Train Loss: 0.5375, Val Loss: 0.4882, F1 Micro: 0.7625, F1 Macro: 0.7579, Accuracy: 0.7625\n","Epoch 126, Train Loss: 0.5340, Val Loss: 0.5109, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 127, Train Loss: 0.5363, Val Loss: 0.4814, F1 Micro: 0.7375, F1 Macro: 0.7355, Accuracy: 0.7375\n","Epoch 128, Train Loss: 0.5313, Val Loss: 0.4938, F1 Micro: 0.7250, F1 Macro: 0.7247, Accuracy: 0.7250\n","Epoch 129, Train Loss: 0.5373, Val Loss: 0.5017, F1 Micro: 0.7625, F1 Macro: 0.7491, Accuracy: 0.7625\n","Epoch 130, Train Loss: 0.5272, Val Loss: 0.4969, F1 Micro: 0.7344, F1 Macro: 0.7342, Accuracy: 0.7344\n","Epoch 131, Train Loss: 0.5336, Val Loss: 0.4867, F1 Micro: 0.7562, F1 Macro: 0.7538, Accuracy: 0.7562\n","Epoch 132, Train Loss: 0.5341, Val Loss: 0.4811, F1 Micro: 0.7375, F1 Macro: 0.7363, Accuracy: 0.7375\n","Epoch 133, Train Loss: 0.5252, Val Loss: 0.4786, F1 Micro: 0.7406, F1 Macro: 0.7393, Accuracy: 0.7406\n","Epoch 134, Train Loss: 0.5351, Val Loss: 0.4830, F1 Micro: 0.7594, F1 Macro: 0.7526, Accuracy: 0.7594\n","Epoch 135, Train Loss: 0.5280, Val Loss: 0.4952, F1 Micro: 0.7375, F1 Macro: 0.7373, Accuracy: 0.7375\n","Epoch 136, Train Loss: 0.5343, Val Loss: 0.4801, F1 Micro: 0.7375, F1 Macro: 0.7355, Accuracy: 0.7375\n","Epoch 137, Train Loss: 0.5244, Val Loss: 0.4807, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 138, Train Loss: 0.5327, Val Loss: 0.5050, F1 Micro: 0.7438, F1 Macro: 0.7437, Accuracy: 0.7438\n","Epoch 139, Train Loss: 0.5290, Val Loss: 0.4896, F1 Micro: 0.7312, F1 Macro: 0.7208, Accuracy: 0.7312\n","Epoch 140, Train Loss: 0.5283, Val Loss: 0.4781, F1 Micro: 0.7500, F1 Macro: 0.7481, Accuracy: 0.7500\n","Epoch 141, Train Loss: 0.5244, Val Loss: 0.4811, F1 Micro: 0.7469, F1 Macro: 0.7451, Accuracy: 0.7469\n","Epoch 142, Train Loss: 0.5205, Val Loss: 0.5018, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 143, Train Loss: 0.5282, Val Loss: 0.4868, F1 Micro: 0.7375, F1 Macro: 0.7371, Accuracy: 0.7375\n","Epoch 144, Train Loss: 0.5299, Val Loss: 0.4956, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 145, Train Loss: 0.5175, Val Loss: 0.4934, F1 Micro: 0.7781, F1 Macro: 0.7723, Accuracy: 0.7781\n","Epoch 146, Train Loss: 0.5184, Val Loss: 0.4754, F1 Micro: 0.7531, F1 Macro: 0.7498, Accuracy: 0.7531\n","Epoch 147, Train Loss: 0.5391, Val Loss: 0.4717, F1 Micro: 0.7656, F1 Macro: 0.7621, Accuracy: 0.7656\n","Epoch 148, Train Loss: 0.5220, Val Loss: 0.5472, F1 Micro: 0.7344, F1 Macro: 0.7330, Accuracy: 0.7344\n","Epoch 149, Train Loss: 0.5499, Val Loss: 0.4827, F1 Micro: 0.7688, F1 Macro: 0.7647, Accuracy: 0.7688\n","Epoch 150, Train Loss: 0.5298, Val Loss: 0.5080, F1 Micro: 0.7594, F1 Macro: 0.7382, Accuracy: 0.7594\n","Epoch 151, Train Loss: 0.5226, Val Loss: 0.4890, F1 Micro: 0.7375, F1 Macro: 0.7266, Accuracy: 0.7375\n","Epoch 152, Train Loss: 0.5236, Val Loss: 0.4999, F1 Micro: 0.7469, F1 Macro: 0.7469, Accuracy: 0.7469\n","Epoch 153, Train Loss: 0.5206, Val Loss: 0.4825, F1 Micro: 0.7469, F1 Macro: 0.7465, Accuracy: 0.7469\n","Epoch 154, Train Loss: 0.5206, Val Loss: 0.4752, F1 Micro: 0.7531, F1 Macro: 0.7523, Accuracy: 0.7531\n","Epoch 155, Train Loss: 0.5243, Val Loss: 0.4731, F1 Micro: 0.7438, F1 Macro: 0.7420, Accuracy: 0.7438\n","Epoch 156, Train Loss: 0.5263, Val Loss: 0.4824, F1 Micro: 0.7406, F1 Macro: 0.7395, Accuracy: 0.7406\n","Epoch 157, Train Loss: 0.5272, Val Loss: 0.4823, F1 Micro: 0.7406, F1 Macro: 0.7397, Accuracy: 0.7406\n","Epoch 158, Train Loss: 0.5168, Val Loss: 0.4704, F1 Micro: 0.7594, F1 Macro: 0.7557, Accuracy: 0.7594\n","Epoch 159, Train Loss: 0.5135, Val Loss: 0.4845, F1 Micro: 0.7656, F1 Macro: 0.7652, Accuracy: 0.7656\n","Epoch 160, Train Loss: 0.5284, Val Loss: 0.4788, F1 Micro: 0.7875, F1 Macro: 0.7781, Accuracy: 0.7875\n","Epoch 161, Train Loss: 0.5286, Val Loss: 0.4732, F1 Micro: 0.7688, F1 Macro: 0.7670, Accuracy: 0.7688\n","Epoch 162, Train Loss: 0.5150, Val Loss: 0.4781, F1 Micro: 0.7594, F1 Macro: 0.7587, Accuracy: 0.7594\n","Epoch 163, Train Loss: 0.5211, Val Loss: 0.4786, F1 Micro: 0.7500, F1 Macro: 0.7495, Accuracy: 0.7500\n","Epoch 164, Train Loss: 0.5196, Val Loss: 0.4727, F1 Micro: 0.7438, F1 Macro: 0.7427, Accuracy: 0.7438\n","Epoch 165, Train Loss: 0.5227, Val Loss: 0.4729, F1 Micro: 0.7469, F1 Macro: 0.7456, Accuracy: 0.7469\n","Epoch 166, Train Loss: 0.5145, Val Loss: 0.4649, F1 Micro: 0.7625, F1 Macro: 0.7591, Accuracy: 0.7625\n","Epoch 167, Train Loss: 0.5109, Val Loss: 0.4676, F1 Micro: 0.7594, F1 Macro: 0.7536, Accuracy: 0.7594\n","Epoch 168, Train Loss: 0.5085, Val Loss: 0.4688, F1 Micro: 0.7562, F1 Macro: 0.7538, Accuracy: 0.7562\n","Epoch 169, Train Loss: 0.5164, Val Loss: 0.4857, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 170, Train Loss: 0.5200, Val Loss: 0.4657, F1 Micro: 0.7688, F1 Macro: 0.7630, Accuracy: 0.7688\n","Epoch 171, Train Loss: 0.5283, Val Loss: 0.4723, F1 Micro: 0.7469, F1 Macro: 0.7462, Accuracy: 0.7469\n","Epoch 172, Train Loss: 0.5133, Val Loss: 0.4967, F1 Micro: 0.7312, F1 Macro: 0.7312, Accuracy: 0.7312\n","Epoch 173, Train Loss: 0.5080, Val Loss: 0.4698, F1 Micro: 0.7562, F1 Macro: 0.7551, Accuracy: 0.7562\n","Epoch 174, Train Loss: 0.5166, Val Loss: 0.4774, F1 Micro: 0.7594, F1 Macro: 0.7588, Accuracy: 0.7594\n","Epoch 175, Train Loss: 0.5187, Val Loss: 0.4801, F1 Micro: 0.7844, F1 Macro: 0.7711, Accuracy: 0.7844\n","Epoch 176, Train Loss: 0.5153, Val Loss: 0.4650, F1 Micro: 0.7562, F1 Macro: 0.7531, Accuracy: 0.7562\n","Epoch 177, Train Loss: 0.5195, Val Loss: 0.4745, F1 Micro: 0.7656, F1 Macro: 0.7648, Accuracy: 0.7656\n","Epoch 178, Train Loss: 0.5127, Val Loss: 0.4849, F1 Micro: 0.7656, F1 Macro: 0.7656, Accuracy: 0.7656\n","Epoch 179, Train Loss: 0.5105, Val Loss: 0.4684, F1 Micro: 0.7469, F1 Macro: 0.7460, Accuracy: 0.7469\n","Epoch 180, Train Loss: 0.5148, Val Loss: 0.4614, F1 Micro: 0.7531, F1 Macro: 0.7501, Accuracy: 0.7531\n","Epoch 181, Train Loss: 0.5245, Val Loss: 0.4953, F1 Micro: 0.7531, F1 Macro: 0.7531, Accuracy: 0.7531\n","Epoch 182, Train Loss: 0.5305, Val Loss: 0.4707, F1 Micro: 0.7625, F1 Macro: 0.7617, Accuracy: 0.7625\n","Epoch 183, Train Loss: 0.5187, Val Loss: 0.4605, F1 Micro: 0.7656, F1 Macro: 0.7621, Accuracy: 0.7656\n","Epoch 184, Train Loss: 0.5040, Val Loss: 0.4654, F1 Micro: 0.7688, F1 Macro: 0.7643, Accuracy: 0.7688\n","Epoch 185, Train Loss: 0.5246, Val Loss: 0.4893, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 186, Train Loss: 0.5107, Val Loss: 0.4647, F1 Micro: 0.7469, F1 Macro: 0.7458, Accuracy: 0.7469\n","Epoch 187, Train Loss: 0.5203, Val Loss: 0.4710, F1 Micro: 0.7688, F1 Macro: 0.7654, Accuracy: 0.7688\n","Epoch 188, Train Loss: 0.5164, Val Loss: 0.4676, F1 Micro: 0.7719, F1 Macro: 0.7608, Accuracy: 0.7719\n","Epoch 189, Train Loss: 0.5184, Val Loss: 0.5169, F1 Micro: 0.7625, F1 Macro: 0.7623, Accuracy: 0.7625\n","Epoch 190, Train Loss: 0.5242, Val Loss: 0.4699, F1 Micro: 0.7875, F1 Macro: 0.7775, Accuracy: 0.7875\n","Epoch 191, Train Loss: 0.5069, Val Loss: 0.5433, F1 Micro: 0.7000, F1 Macro: 0.6581, Accuracy: 0.7000\n","Epoch 192, Train Loss: 0.5213, Val Loss: 0.4671, F1 Micro: 0.7719, F1 Macro: 0.7709, Accuracy: 0.7719\n","Epoch 193, Train Loss: 0.5166, Val Loss: 0.4584, F1 Micro: 0.7562, F1 Macro: 0.7531, Accuracy: 0.7562\n","Epoch 194, Train Loss: 0.5090, Val Loss: 0.4585, F1 Micro: 0.7594, F1 Macro: 0.7561, Accuracy: 0.7594\n","Epoch 195, Train Loss: 0.5118, Val Loss: 0.4608, F1 Micro: 0.7781, F1 Macro: 0.7736, Accuracy: 0.7781\n","Epoch 196, Train Loss: 0.5133, Val Loss: 0.4599, F1 Micro: 0.7781, F1 Macro: 0.7732, Accuracy: 0.7781\n","Epoch 197, Train Loss: 0.5228, Val Loss: 0.4713, F1 Micro: 0.7562, F1 Macro: 0.7558, Accuracy: 0.7562\n","Epoch 198, Train Loss: 0.5063, Val Loss: 0.4652, F1 Micro: 0.7469, F1 Macro: 0.7453, Accuracy: 0.7469\n","Epoch 199, Train Loss: 0.5030, Val Loss: 0.4652, F1 Micro: 0.7656, F1 Macro: 0.7646, Accuracy: 0.7656\n","Epoch 200, Train Loss: 0.5110, Val Loss: 0.4601, F1 Micro: 0.7500, F1 Macro: 0.7481, Accuracy: 0.7500\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6088, Val Loss: 0.5459, F1 Micro: 0.7312, F1 Macro: 0.7295, Accuracy: 0.7312\n","Epoch 2, Train Loss: 0.5937, Val Loss: 0.5396, F1 Micro: 0.7188, F1 Macro: 0.7105, Accuracy: 0.7188\n","Epoch 3, Train Loss: 0.6109, Val Loss: 0.5899, F1 Micro: 0.6844, F1 Macro: 0.6818, Accuracy: 0.6844\n","Epoch 4, Train Loss: 0.5817, Val Loss: 0.5585, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 5, Train Loss: 0.5849, Val Loss: 0.5493, F1 Micro: 0.7031, F1 Macro: 0.6878, Accuracy: 0.7031\n","Epoch 6, Train Loss: 0.5793, Val Loss: 0.5425, F1 Micro: 0.7281, F1 Macro: 0.7252, Accuracy: 0.7281\n","Epoch 7, Train Loss: 0.5841, Val Loss: 0.5528, F1 Micro: 0.7250, F1 Macro: 0.7246, Accuracy: 0.7250\n","Epoch 8, Train Loss: 0.5780, Val Loss: 0.5453, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 9, Train Loss: 0.5773, Val Loss: 0.5462, F1 Micro: 0.7250, F1 Macro: 0.7245, Accuracy: 0.7250\n","Epoch 10, Train Loss: 0.6015, Val Loss: 0.5429, F1 Micro: 0.7281, F1 Macro: 0.7255, Accuracy: 0.7281\n","Epoch 11, Train Loss: 0.5787, Val Loss: 0.5448, F1 Micro: 0.7031, F1 Macro: 0.6878, Accuracy: 0.7031\n","Epoch 12, Train Loss: 0.5824, Val Loss: 0.5562, F1 Micro: 0.6906, F1 Macro: 0.6694, Accuracy: 0.6906\n","Epoch 13, Train Loss: 0.5763, Val Loss: 0.5927, F1 Micro: 0.6844, F1 Macro: 0.6479, Accuracy: 0.6844\n","Epoch 14, Train Loss: 0.5857, Val Loss: 0.5459, F1 Micro: 0.7063, F1 Macro: 0.6932, Accuracy: 0.7063\n","Epoch 15, Train Loss: 0.5719, Val Loss: 0.5426, F1 Micro: 0.7281, F1 Macro: 0.7277, Accuracy: 0.7281\n","Epoch 16, Train Loss: 0.5800, Val Loss: 0.5787, F1 Micro: 0.6875, F1 Macro: 0.6854, Accuracy: 0.6875\n","Epoch 17, Train Loss: 0.5776, Val Loss: 0.5363, F1 Micro: 0.7312, F1 Macro: 0.7285, Accuracy: 0.7312\n","Epoch 18, Train Loss: 0.5733, Val Loss: 0.5478, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 19, Train Loss: 0.5657, Val Loss: 0.5325, F1 Micro: 0.7219, F1 Macro: 0.7152, Accuracy: 0.7219\n","Epoch 20, Train Loss: 0.5900, Val Loss: 0.5355, F1 Micro: 0.7344, F1 Macro: 0.7304, Accuracy: 0.7344\n","Epoch 21, Train Loss: 0.5730, Val Loss: 0.5399, F1 Micro: 0.7250, F1 Macro: 0.7232, Accuracy: 0.7250\n","Epoch 22, Train Loss: 0.5787, Val Loss: 0.5455, F1 Micro: 0.7250, F1 Macro: 0.7243, Accuracy: 0.7250\n","Epoch 23, Train Loss: 0.5769, Val Loss: 0.5371, F1 Micro: 0.7063, F1 Macro: 0.6955, Accuracy: 0.7063\n","Epoch 24, Train Loss: 0.5711, Val Loss: 0.5311, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 25, Train Loss: 0.5710, Val Loss: 0.5312, F1 Micro: 0.7281, F1 Macro: 0.7252, Accuracy: 0.7281\n","Epoch 26, Train Loss: 0.5701, Val Loss: 0.5298, F1 Micro: 0.7344, F1 Macro: 0.7290, Accuracy: 0.7344\n","Epoch 27, Train Loss: 0.5726, Val Loss: 0.6015, F1 Micro: 0.6469, F1 Macro: 0.6377, Accuracy: 0.6469\n","Epoch 28, Train Loss: 0.5769, Val Loss: 0.5289, F1 Micro: 0.7281, F1 Macro: 0.7244, Accuracy: 0.7281\n","Epoch 29, Train Loss: 0.5694, Val Loss: 0.5297, F1 Micro: 0.7250, F1 Macro: 0.7181, Accuracy: 0.7250\n","Epoch 30, Train Loss: 0.5703, Val Loss: 0.6122, F1 Micro: 0.6687, F1 Macro: 0.6549, Accuracy: 0.6687\n","Epoch 31, Train Loss: 0.5695, Val Loss: 0.5312, F1 Micro: 0.7250, F1 Macro: 0.7229, Accuracy: 0.7250\n","Epoch 32, Train Loss: 0.5643, Val Loss: 0.5393, F1 Micro: 0.7094, F1 Macro: 0.6961, Accuracy: 0.7094\n","Epoch 33, Train Loss: 0.5671, Val Loss: 0.5277, F1 Micro: 0.7312, F1 Macro: 0.7274, Accuracy: 0.7312\n","Epoch 34, Train Loss: 0.5775, Val Loss: 0.5374, F1 Micro: 0.7125, F1 Macro: 0.7041, Accuracy: 0.7125\n","Epoch 35, Train Loss: 0.5649, Val Loss: 0.5433, F1 Micro: 0.7188, F1 Macro: 0.7174, Accuracy: 0.7188\n","Epoch 36, Train Loss: 0.5657, Val Loss: 0.5365, F1 Micro: 0.7063, F1 Macro: 0.6932, Accuracy: 0.7063\n","Epoch 37, Train Loss: 0.5689, Val Loss: 0.5272, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 38, Train Loss: 0.5675, Val Loss: 0.5307, F1 Micro: 0.7125, F1 Macro: 0.7027, Accuracy: 0.7125\n","Epoch 39, Train Loss: 0.5614, Val Loss: 0.5522, F1 Micro: 0.6906, F1 Macro: 0.6905, Accuracy: 0.6906\n","Epoch 40, Train Loss: 0.5684, Val Loss: 0.5296, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 41, Train Loss: 0.5605, Val Loss: 0.5298, F1 Micro: 0.7094, F1 Macro: 0.6999, Accuracy: 0.7094\n","Epoch 42, Train Loss: 0.5594, Val Loss: 0.5396, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 43, Train Loss: 0.5648, Val Loss: 0.5469, F1 Micro: 0.7063, F1 Macro: 0.7063, Accuracy: 0.7063\n","Epoch 44, Train Loss: 0.5644, Val Loss: 0.5274, F1 Micro: 0.7188, F1 Macro: 0.7176, Accuracy: 0.7188\n","Epoch 45, Train Loss: 0.5549, Val Loss: 0.5263, F1 Micro: 0.7125, F1 Macro: 0.7041, Accuracy: 0.7125\n","Epoch 46, Train Loss: 0.5575, Val Loss: 0.5244, F1 Micro: 0.7281, F1 Macro: 0.7262, Accuracy: 0.7281\n","Epoch 47, Train Loss: 0.5567, Val Loss: 0.5238, F1 Micro: 0.7156, F1 Macro: 0.7141, Accuracy: 0.7156\n","Epoch 48, Train Loss: 0.5635, Val Loss: 0.5335, F1 Micro: 0.7188, F1 Macro: 0.7180, Accuracy: 0.7188\n","Epoch 49, Train Loss: 0.5613, Val Loss: 0.5382, F1 Micro: 0.7063, F1 Macro: 0.6915, Accuracy: 0.7063\n","Epoch 50, Train Loss: 0.5578, Val Loss: 0.5220, F1 Micro: 0.7250, F1 Macro: 0.7192, Accuracy: 0.7250\n","Epoch 51, Train Loss: 0.5611, Val Loss: 0.5527, F1 Micro: 0.7000, F1 Macro: 0.6800, Accuracy: 0.7000\n","Epoch 52, Train Loss: 0.5665, Val Loss: 0.5244, F1 Micro: 0.7281, F1 Macro: 0.7216, Accuracy: 0.7281\n","Epoch 53, Train Loss: 0.5568, Val Loss: 0.5214, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 54, Train Loss: 0.5624, Val Loss: 0.5257, F1 Micro: 0.7219, F1 Macro: 0.7152, Accuracy: 0.7219\n","Epoch 55, Train Loss: 0.5688, Val Loss: 0.5286, F1 Micro: 0.7094, F1 Macro: 0.6984, Accuracy: 0.7094\n","Epoch 56, Train Loss: 0.5614, Val Loss: 0.5310, F1 Micro: 0.7125, F1 Macro: 0.7125, Accuracy: 0.7125\n","Epoch 57, Train Loss: 0.5583, Val Loss: 0.5278, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 58, Train Loss: 0.5526, Val Loss: 0.5330, F1 Micro: 0.7063, F1 Macro: 0.7062, Accuracy: 0.7063\n","Epoch 59, Train Loss: 0.5590, Val Loss: 0.5238, F1 Micro: 0.7250, F1 Macro: 0.7237, Accuracy: 0.7250\n","Epoch 60, Train Loss: 0.5525, Val Loss: 0.5657, F1 Micro: 0.7375, F1 Macro: 0.7337, Accuracy: 0.7375\n","Epoch 61, Train Loss: 0.5653, Val Loss: 0.5560, F1 Micro: 0.7063, F1 Macro: 0.7046, Accuracy: 0.7063\n","Epoch 62, Train Loss: 0.5589, Val Loss: 0.5389, F1 Micro: 0.7000, F1 Macro: 0.6994, Accuracy: 0.7000\n","Epoch 63, Train Loss: 0.5531, Val Loss: 0.5175, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 64, Train Loss: 0.5481, Val Loss: 0.5176, F1 Micro: 0.7406, F1 Macro: 0.7371, Accuracy: 0.7406\n","Epoch 65, Train Loss: 0.5518, Val Loss: 0.5237, F1 Micro: 0.7188, F1 Macro: 0.7187, Accuracy: 0.7188\n","Epoch 66, Train Loss: 0.5537, Val Loss: 0.5246, F1 Micro: 0.7125, F1 Macro: 0.7013, Accuracy: 0.7125\n","Epoch 67, Train Loss: 0.5554, Val Loss: 0.5175, F1 Micro: 0.7344, F1 Macro: 0.7285, Accuracy: 0.7344\n","Epoch 68, Train Loss: 0.5524, Val Loss: 0.5143, F1 Micro: 0.7375, F1 Macro: 0.7341, Accuracy: 0.7375\n","Epoch 69, Train Loss: 0.5548, Val Loss: 0.5139, F1 Micro: 0.7406, F1 Macro: 0.7375, Accuracy: 0.7406\n","Epoch 70, Train Loss: 0.5501, Val Loss: 0.5125, F1 Micro: 0.7406, F1 Macro: 0.7378, Accuracy: 0.7406\n","Epoch 71, Train Loss: 0.5437, Val Loss: 0.5123, F1 Micro: 0.7312, F1 Macro: 0.7261, Accuracy: 0.7312\n","Epoch 72, Train Loss: 0.5498, Val Loss: 0.5220, F1 Micro: 0.7094, F1 Macro: 0.7093, Accuracy: 0.7094\n","Epoch 73, Train Loss: 0.5461, Val Loss: 0.5191, F1 Micro: 0.7344, F1 Macro: 0.7319, Accuracy: 0.7344\n","Epoch 74, Train Loss: 0.5458, Val Loss: 0.5207, F1 Micro: 0.7312, F1 Macro: 0.7256, Accuracy: 0.7312\n","Epoch 75, Train Loss: 0.5506, Val Loss: 0.5438, F1 Micro: 0.7156, F1 Macro: 0.7133, Accuracy: 0.7156\n","Epoch 76, Train Loss: 0.5460, Val Loss: 0.5208, F1 Micro: 0.7219, F1 Macro: 0.7146, Accuracy: 0.7219\n","Epoch 77, Train Loss: 0.5530, Val Loss: 0.5158, F1 Micro: 0.7188, F1 Macro: 0.7179, Accuracy: 0.7188\n","Epoch 78, Train Loss: 0.5459, Val Loss: 0.5147, F1 Micro: 0.7375, F1 Macro: 0.7371, Accuracy: 0.7375\n","Epoch 79, Train Loss: 0.5538, Val Loss: 0.5130, F1 Micro: 0.7312, F1 Macro: 0.7297, Accuracy: 0.7312\n","Epoch 80, Train Loss: 0.5513, Val Loss: 0.5173, F1 Micro: 0.7219, F1 Macro: 0.7134, Accuracy: 0.7219\n","Epoch 81, Train Loss: 0.5406, Val Loss: 0.5214, F1 Micro: 0.7125, F1 Macro: 0.7123, Accuracy: 0.7125\n","Epoch 82, Train Loss: 0.5457, Val Loss: 0.5347, F1 Micro: 0.7000, F1 Macro: 0.6988, Accuracy: 0.7000\n","Epoch 83, Train Loss: 0.5480, Val Loss: 0.5121, F1 Micro: 0.7312, F1 Macro: 0.7270, Accuracy: 0.7312\n","Epoch 84, Train Loss: 0.5396, Val Loss: 0.5114, F1 Micro: 0.7406, F1 Macro: 0.7404, Accuracy: 0.7406\n","Epoch 85, Train Loss: 0.5433, Val Loss: 0.5180, F1 Micro: 0.7375, F1 Macro: 0.7371, Accuracy: 0.7375\n","Epoch 86, Train Loss: 0.5488, Val Loss: 0.5499, F1 Micro: 0.7063, F1 Macro: 0.6897, Accuracy: 0.7063\n","Epoch 87, Train Loss: 0.5504, Val Loss: 0.5133, F1 Micro: 0.7438, F1 Macro: 0.7435, Accuracy: 0.7438\n","Epoch 88, Train Loss: 0.5363, Val Loss: 0.5041, F1 Micro: 0.7375, F1 Macro: 0.7348, Accuracy: 0.7375\n","Epoch 89, Train Loss: 0.5370, Val Loss: 0.5115, F1 Micro: 0.7219, F1 Macro: 0.7218, Accuracy: 0.7219\n","Epoch 90, Train Loss: 0.5471, Val Loss: 0.5054, F1 Micro: 0.7406, F1 Macro: 0.7388, Accuracy: 0.7406\n","Epoch 91, Train Loss: 0.5384, Val Loss: 0.5144, F1 Micro: 0.7250, F1 Macro: 0.7249, Accuracy: 0.7250\n","Epoch 92, Train Loss: 0.5465, Val Loss: 0.5070, F1 Micro: 0.7344, F1 Macro: 0.7336, Accuracy: 0.7344\n","Epoch 93, Train Loss: 0.5350, Val Loss: 0.5171, F1 Micro: 0.7250, F1 Macro: 0.7157, Accuracy: 0.7250\n","Epoch 94, Train Loss: 0.5431, Val Loss: 0.5065, F1 Micro: 0.7406, F1 Macro: 0.7405, Accuracy: 0.7406\n","Epoch 95, Train Loss: 0.5462, Val Loss: 0.5068, F1 Micro: 0.7281, F1 Macro: 0.7267, Accuracy: 0.7281\n","Epoch 96, Train Loss: 0.5389, Val Loss: 0.5018, F1 Micro: 0.7312, F1 Macro: 0.7274, Accuracy: 0.7312\n","Epoch 97, Train Loss: 0.5409, Val Loss: 0.5036, F1 Micro: 0.7344, F1 Macro: 0.7338, Accuracy: 0.7344\n","Epoch 98, Train Loss: 0.5411, Val Loss: 0.5159, F1 Micro: 0.7156, F1 Macro: 0.7155, Accuracy: 0.7156\n","Epoch 99, Train Loss: 0.5404, Val Loss: 0.5018, F1 Micro: 0.7344, F1 Macro: 0.7325, Accuracy: 0.7344\n","Epoch 100, Train Loss: 0.5311, Val Loss: 0.4998, F1 Micro: 0.7344, F1 Macro: 0.7308, Accuracy: 0.7344\n","Epoch 101, Train Loss: 0.5356, Val Loss: 0.5137, F1 Micro: 0.7219, F1 Macro: 0.7211, Accuracy: 0.7219\n","Epoch 102, Train Loss: 0.5407, Val Loss: 0.5026, F1 Micro: 0.7500, F1 Macro: 0.7456, Accuracy: 0.7500\n","Epoch 103, Train Loss: 0.5405, Val Loss: 0.5006, F1 Micro: 0.7438, F1 Macro: 0.7408, Accuracy: 0.7438\n","Epoch 104, Train Loss: 0.5379, Val Loss: 0.4961, F1 Micro: 0.7375, F1 Macro: 0.7358, Accuracy: 0.7375\n","Epoch 105, Train Loss: 0.5321, Val Loss: 0.4947, F1 Micro: 0.7500, F1 Macro: 0.7488, Accuracy: 0.7500\n","Epoch 106, Train Loss: 0.5521, Val Loss: 0.5029, F1 Micro: 0.7344, F1 Macro: 0.7315, Accuracy: 0.7344\n","Epoch 107, Train Loss: 0.5382, Val Loss: 0.5247, F1 Micro: 0.7219, F1 Macro: 0.7196, Accuracy: 0.7219\n","Epoch 108, Train Loss: 0.5291, Val Loss: 0.4948, F1 Micro: 0.7469, F1 Macro: 0.7458, Accuracy: 0.7469\n","Epoch 109, Train Loss: 0.5429, Val Loss: 0.4985, F1 Micro: 0.7406, F1 Macro: 0.7401, Accuracy: 0.7406\n","Epoch 110, Train Loss: 0.5356, Val Loss: 0.4976, F1 Micro: 0.7562, F1 Macro: 0.7553, Accuracy: 0.7562\n","Epoch 111, Train Loss: 0.5368, Val Loss: 0.4999, F1 Micro: 0.7562, F1 Macro: 0.7562, Accuracy: 0.7562\n","Epoch 112, Train Loss: 0.5346, Val Loss: 0.4990, F1 Micro: 0.7500, F1 Macro: 0.7500, Accuracy: 0.7500\n","Epoch 113, Train Loss: 0.5400, Val Loss: 0.5153, F1 Micro: 0.7531, F1 Macro: 0.7524, Accuracy: 0.7531\n","Epoch 114, Train Loss: 0.5312, Val Loss: 0.4932, F1 Micro: 0.7438, F1 Macro: 0.7423, Accuracy: 0.7438\n","Epoch 115, Train Loss: 0.5351, Val Loss: 0.5118, F1 Micro: 0.7219, F1 Macro: 0.7121, Accuracy: 0.7219\n","Epoch 116, Train Loss: 0.5248, Val Loss: 0.4981, F1 Micro: 0.7500, F1 Macro: 0.7492, Accuracy: 0.7500\n","Epoch 117, Train Loss: 0.5286, Val Loss: 0.4892, F1 Micro: 0.7531, F1 Macro: 0.7518, Accuracy: 0.7531\n","Epoch 118, Train Loss: 0.5388, Val Loss: 0.5334, F1 Micro: 0.7312, F1 Macro: 0.7282, Accuracy: 0.7312\n","Epoch 119, Train Loss: 0.5376, Val Loss: 0.4952, F1 Micro: 0.7531, F1 Macro: 0.7518, Accuracy: 0.7531\n","Epoch 120, Train Loss: 0.5322, Val Loss: 0.5042, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 121, Train Loss: 0.5325, Val Loss: 0.4884, F1 Micro: 0.7469, F1 Macro: 0.7451, Accuracy: 0.7469\n","Epoch 122, Train Loss: 0.5249, Val Loss: 0.4999, F1 Micro: 0.7719, F1 Macro: 0.7716, Accuracy: 0.7719\n","Epoch 123, Train Loss: 0.5320, Val Loss: 0.5179, F1 Micro: 0.7250, F1 Macro: 0.7202, Accuracy: 0.7250\n","Epoch 124, Train Loss: 0.5227, Val Loss: 0.4954, F1 Micro: 0.7656, F1 Macro: 0.7655, Accuracy: 0.7656\n","Epoch 125, Train Loss: 0.5313, Val Loss: 0.5088, F1 Micro: 0.7344, F1 Macro: 0.7319, Accuracy: 0.7344\n","Epoch 126, Train Loss: 0.5367, Val Loss: 0.5112, F1 Micro: 0.7875, F1 Macro: 0.7874, Accuracy: 0.7875\n","Epoch 127, Train Loss: 0.5270, Val Loss: 0.5028, F1 Micro: 0.7312, F1 Macro: 0.7251, Accuracy: 0.7312\n","Epoch 128, Train Loss: 0.5320, Val Loss: 0.4917, F1 Micro: 0.7688, F1 Macro: 0.7684, Accuracy: 0.7688\n","Epoch 129, Train Loss: 0.5256, Val Loss: 0.4921, F1 Micro: 0.7656, F1 Macro: 0.7652, Accuracy: 0.7656\n","Epoch 130, Train Loss: 0.5295, Val Loss: 0.5076, F1 Micro: 0.7688, F1 Macro: 0.7686, Accuracy: 0.7688\n","Epoch 131, Train Loss: 0.5272, Val Loss: 0.4854, F1 Micro: 0.7438, F1 Macro: 0.7433, Accuracy: 0.7438\n","Epoch 132, Train Loss: 0.5175, Val Loss: 0.4978, F1 Micro: 0.7406, F1 Macro: 0.7344, Accuracy: 0.7406\n","Epoch 133, Train Loss: 0.5249, Val Loss: 0.4968, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 134, Train Loss: 0.5277, Val Loss: 0.4856, F1 Micro: 0.7594, F1 Macro: 0.7593, Accuracy: 0.7594\n","Epoch 135, Train Loss: 0.5282, Val Loss: 0.4911, F1 Micro: 0.7500, F1 Macro: 0.7452, Accuracy: 0.7500\n","Epoch 136, Train Loss: 0.5234, Val Loss: 0.4830, F1 Micro: 0.7719, F1 Macro: 0.7716, Accuracy: 0.7719\n","Epoch 137, Train Loss: 0.5234, Val Loss: 0.4871, F1 Micro: 0.7500, F1 Macro: 0.7475, Accuracy: 0.7500\n","Epoch 138, Train Loss: 0.5251, Val Loss: 0.4935, F1 Micro: 0.7719, F1 Macro: 0.7715, Accuracy: 0.7719\n","Epoch 139, Train Loss: 0.5251, Val Loss: 0.4921, F1 Micro: 0.7375, F1 Macro: 0.7371, Accuracy: 0.7375\n","Epoch 140, Train Loss: 0.5206, Val Loss: 0.5359, F1 Micro: 0.7438, F1 Macro: 0.7324, Accuracy: 0.7438\n","Epoch 141, Train Loss: 0.5274, Val Loss: 0.4821, F1 Micro: 0.7531, F1 Macro: 0.7523, Accuracy: 0.7531\n","Epoch 142, Train Loss: 0.5274, Val Loss: 0.5034, F1 Micro: 0.7344, F1 Macro: 0.7244, Accuracy: 0.7344\n","Epoch 143, Train Loss: 0.5275, Val Loss: 0.4874, F1 Micro: 0.7469, F1 Macro: 0.7418, Accuracy: 0.7469\n","Epoch 144, Train Loss: 0.5228, Val Loss: 0.4795, F1 Micro: 0.7625, F1 Macro: 0.7612, Accuracy: 0.7625\n","Epoch 145, Train Loss: 0.5257, Val Loss: 0.4787, F1 Micro: 0.7562, F1 Macro: 0.7555, Accuracy: 0.7562\n","Epoch 146, Train Loss: 0.5247, Val Loss: 0.4805, F1 Micro: 0.7500, F1 Macro: 0.7471, Accuracy: 0.7500\n","Epoch 147, Train Loss: 0.5200, Val Loss: 0.4813, F1 Micro: 0.7594, F1 Macro: 0.7590, Accuracy: 0.7594\n","Epoch 148, Train Loss: 0.5225, Val Loss: 0.5177, F1 Micro: 0.7344, F1 Macro: 0.7250, Accuracy: 0.7344\n","Epoch 149, Train Loss: 0.5197, Val Loss: 0.4839, F1 Micro: 0.7406, F1 Macro: 0.7406, Accuracy: 0.7406\n","Epoch 150, Train Loss: 0.5249, Val Loss: 0.5000, F1 Micro: 0.7469, F1 Macro: 0.7438, Accuracy: 0.7469\n","Epoch 151, Train Loss: 0.5294, Val Loss: 0.4874, F1 Micro: 0.7438, F1 Macro: 0.7393, Accuracy: 0.7438\n","Epoch 152, Train Loss: 0.5134, Val Loss: 0.4855, F1 Micro: 0.7375, F1 Macro: 0.7375, Accuracy: 0.7375\n","Epoch 153, Train Loss: 0.5093, Val Loss: 0.4776, F1 Micro: 0.7625, F1 Macro: 0.7612, Accuracy: 0.7625\n","Epoch 154, Train Loss: 0.5153, Val Loss: 0.4808, F1 Micro: 0.7562, F1 Macro: 0.7520, Accuracy: 0.7562\n","Epoch 155, Train Loss: 0.5122, Val Loss: 0.4875, F1 Micro: 0.7625, F1 Macro: 0.7625, Accuracy: 0.7625\n","Epoch 156, Train Loss: 0.5230, Val Loss: 0.4741, F1 Micro: 0.7688, F1 Macro: 0.7685, Accuracy: 0.7688\n","Epoch 157, Train Loss: 0.5157, Val Loss: 0.4866, F1 Micro: 0.7719, F1 Macro: 0.7697, Accuracy: 0.7719\n","Epoch 158, Train Loss: 0.5174, Val Loss: 0.4710, F1 Micro: 0.7719, F1 Macro: 0.7715, Accuracy: 0.7719\n","Epoch 159, Train Loss: 0.5221, Val Loss: 0.4757, F1 Micro: 0.7625, F1 Macro: 0.7624, Accuracy: 0.7625\n","Epoch 160, Train Loss: 0.5307, Val Loss: 0.4999, F1 Micro: 0.7500, F1 Macro: 0.7415, Accuracy: 0.7500\n","Epoch 161, Train Loss: 0.5113, Val Loss: 0.4749, F1 Micro: 0.7469, F1 Macro: 0.7431, Accuracy: 0.7469\n","Epoch 162, Train Loss: 0.5110, Val Loss: 0.4782, F1 Micro: 0.7656, F1 Macro: 0.7634, Accuracy: 0.7656\n","Epoch 163, Train Loss: 0.5287, Val Loss: 0.4837, F1 Micro: 0.7531, F1 Macro: 0.7486, Accuracy: 0.7531\n","Epoch 164, Train Loss: 0.5278, Val Loss: 0.4755, F1 Micro: 0.7500, F1 Macro: 0.7475, Accuracy: 0.7500\n","Epoch 165, Train Loss: 0.5266, Val Loss: 0.4918, F1 Micro: 0.7500, F1 Macro: 0.7437, Accuracy: 0.7500\n","Epoch 166, Train Loss: 0.5180, Val Loss: 0.4746, F1 Micro: 0.7531, F1 Macro: 0.7518, Accuracy: 0.7531\n","Epoch 167, Train Loss: 0.5091, Val Loss: 0.5087, F1 Micro: 0.7438, F1 Macro: 0.7418, Accuracy: 0.7438\n","Epoch 168, Train Loss: 0.5241, Val Loss: 0.4778, F1 Micro: 0.7500, F1 Macro: 0.7496, Accuracy: 0.7500\n","Epoch 169, Train Loss: 0.5145, Val Loss: 0.4903, F1 Micro: 0.7375, F1 Macro: 0.7341, Accuracy: 0.7375\n","Epoch 170, Train Loss: 0.5171, Val Loss: 0.4827, F1 Micro: 0.7562, F1 Macro: 0.7555, Accuracy: 0.7562\n","Epoch 171, Train Loss: 0.5123, Val Loss: 0.4817, F1 Micro: 0.7719, F1 Macro: 0.7712, Accuracy: 0.7719\n","Epoch 172, Train Loss: 0.5238, Val Loss: 0.5292, F1 Micro: 0.7188, F1 Macro: 0.7070, Accuracy: 0.7188\n","Epoch 173, Train Loss: 0.5177, Val Loss: 0.5027, F1 Micro: 0.7188, F1 Macro: 0.7128, Accuracy: 0.7188\n","Epoch 174, Train Loss: 0.5201, Val Loss: 0.4722, F1 Micro: 0.7594, F1 Macro: 0.7571, Accuracy: 0.7594\n","Epoch 175, Train Loss: 0.5177, Val Loss: 0.4789, F1 Micro: 0.7469, F1 Macro: 0.7456, Accuracy: 0.7469\n","Epoch 176, Train Loss: 0.5110, Val Loss: 0.4712, F1 Micro: 0.7688, F1 Macro: 0.7687, Accuracy: 0.7688\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7412500000000001\n","Best hyperparameters for Outer FOLD 4: (0.01, 8, 50) with score 0.8150000000000001\n","Epoch 1, Train Loss: 0.7057, Val Loss: 0.6076, F1 Micro: 0.7225, F1 Macro: 0.7163, Accuracy: 0.7225\n","Epoch 2, Train Loss: 0.5996, Val Loss: 0.5519, F1 Micro: 0.6950, F1 Macro: 0.6842, Accuracy: 0.6950\n","Epoch 3, Train Loss: 0.6191, Val Loss: 0.5631, F1 Micro: 0.7250, F1 Macro: 0.7228, Accuracy: 0.7250\n","Epoch 4, Train Loss: 0.6564, Val Loss: 0.6142, F1 Micro: 0.6150, F1 Macro: 0.5539, Accuracy: 0.6150\n","Epoch 5, Train Loss: 0.6141, Val Loss: 0.6623, F1 Micro: 0.6850, F1 Macro: 0.6666, Accuracy: 0.6850\n","Epoch 6, Train Loss: 0.6488, Val Loss: 0.7571, F1 Micro: 0.6450, F1 Macro: 0.6059, Accuracy: 0.6450\n","Epoch 7, Train Loss: 0.6212, Val Loss: 0.5708, F1 Micro: 0.7025, F1 Macro: 0.6884, Accuracy: 0.7025\n","Epoch 8, Train Loss: 0.6013, Val Loss: 0.5551, F1 Micro: 0.7025, F1 Macro: 0.6939, Accuracy: 0.7025\n","Epoch 9, Train Loss: 0.5912, Val Loss: 0.6609, F1 Micro: 0.4975, F1 Macro: 0.3322, Accuracy: 0.4975\n","Epoch 10, Train Loss: 0.6479, Val Loss: 0.6315, F1 Micro: 0.6250, F1 Macro: 0.5692, Accuracy: 0.6250\n","Epoch 11, Train Loss: 0.6105, Val Loss: 0.5646, F1 Micro: 0.7400, F1 Macro: 0.7383, Accuracy: 0.7400\n","Epoch 12, Train Loss: 0.6121, Val Loss: 0.8720, F1 Micro: 0.6275, F1 Macro: 0.5693, Accuracy: 0.6275\n","Epoch 13, Train Loss: 0.5967, Val Loss: 0.5792, F1 Micro: 0.7200, F1 Macro: 0.7136, Accuracy: 0.7200\n","Epoch 14, Train Loss: 0.5964, Val Loss: 0.5295, F1 Micro: 0.7250, F1 Macro: 0.7222, Accuracy: 0.7250\n","Epoch 15, Train Loss: 0.5947, Val Loss: 0.5348, F1 Micro: 0.7225, F1 Macro: 0.7189, Accuracy: 0.7225\n","Epoch 16, Train Loss: 0.6568, Val Loss: 0.7090, F1 Micro: 0.6475, F1 Macro: 0.6094, Accuracy: 0.6475\n","Epoch 17, Train Loss: 0.8009, Val Loss: 0.9052, F1 Micro: 0.3875, F1 Macro: 0.3639, Accuracy: 0.3875\n","Epoch 18, Train Loss: 0.6508, Val Loss: 0.5816, F1 Micro: 0.6700, F1 Macro: 0.6461, Accuracy: 0.6700\n","Epoch 19, Train Loss: 0.6088, Val Loss: 0.5415, F1 Micro: 0.7275, F1 Macro: 0.7274, Accuracy: 0.7275\n","Epoch 20, Train Loss: 0.6006, Val Loss: 0.5262, F1 Micro: 0.7300, F1 Macro: 0.7285, Accuracy: 0.7300\n","Epoch 21, Train Loss: 0.6158, Val Loss: 0.5258, F1 Micro: 0.7425, F1 Macro: 0.7425, Accuracy: 0.7425\n","Epoch 22, Train Loss: 0.6036, Val Loss: 0.5557, F1 Micro: 0.7500, F1 Macro: 0.7494, Accuracy: 0.7500\n","Epoch 23, Train Loss: 0.6247, Val Loss: 0.5637, F1 Micro: 0.7300, F1 Macro: 0.7273, Accuracy: 0.7300\n","Epoch 24, Train Loss: 0.6186, Val Loss: 0.5508, F1 Micro: 0.7350, F1 Macro: 0.7350, Accuracy: 0.7350\n","Epoch 25, Train Loss: 0.6035, Val Loss: 0.5138, F1 Micro: 0.7300, F1 Macro: 0.7298, Accuracy: 0.7300\n","Epoch 26, Train Loss: 0.6135, Val Loss: 0.5971, F1 Micro: 0.6875, F1 Macro: 0.6671, Accuracy: 0.6875\n","Epoch 27, Train Loss: 0.5904, Val Loss: 0.5444, F1 Micro: 0.7275, F1 Macro: 0.7256, Accuracy: 0.7275\n","Epoch 28, Train Loss: 0.6271, Val Loss: 0.6899, F1 Micro: 0.6425, F1 Macro: 0.6024, Accuracy: 0.6425\n","Epoch 29, Train Loss: 0.6428, Val Loss: 0.5192, F1 Micro: 0.7325, F1 Macro: 0.7323, Accuracy: 0.7325\n","Epoch 30, Train Loss: 0.6234, Val Loss: 0.5551, F1 Micro: 0.7400, F1 Macro: 0.7368, Accuracy: 0.7400\n","Epoch 31, Train Loss: 0.5968, Val Loss: 0.5294, F1 Micro: 0.7325, F1 Macro: 0.7323, Accuracy: 0.7325\n","Epoch 32, Train Loss: 0.6194, Val Loss: 0.7661, F1 Micro: 0.7050, F1 Macro: 0.6927, Accuracy: 0.7050\n","Epoch 33, Train Loss: 0.6047, Val Loss: 0.6123, F1 Micro: 0.7075, F1 Macro: 0.6968, Accuracy: 0.7075\n","Epoch 34, Train Loss: 0.6217, Val Loss: 0.6493, F1 Micro: 0.7225, F1 Macro: 0.7163, Accuracy: 0.7225\n","Epoch 35, Train Loss: 0.6458, Val Loss: 0.5488, F1 Micro: 0.7075, F1 Macro: 0.6996, Accuracy: 0.7075\n","Epoch 36, Train Loss: 0.6232, Val Loss: 0.5452, F1 Micro: 0.7025, F1 Macro: 0.6923, Accuracy: 0.7025\n","Epoch 37, Train Loss: 0.6218, Val Loss: 0.5297, F1 Micro: 0.7550, F1 Macro: 0.7545, Accuracy: 0.7550\n","Epoch 38, Train Loss: 0.6090, Val Loss: 0.5549, F1 Micro: 0.7025, F1 Macro: 0.6911, Accuracy: 0.7025\n","Epoch 39, Train Loss: 0.5859, Val Loss: 0.6310, F1 Micro: 0.6825, F1 Macro: 0.6609, Accuracy: 0.6825\n","Epoch 40, Train Loss: 0.6132, Val Loss: 0.6338, F1 Micro: 0.4975, F1 Macro: 0.3366, Accuracy: 0.4975\n","Epoch 41, Train Loss: 0.5738, Val Loss: 0.5271, F1 Micro: 0.7250, F1 Macro: 0.7199, Accuracy: 0.7250\n","Epoch 42, Train Loss: 0.7001, Val Loss: 0.6058, F1 Micro: 0.6925, F1 Macro: 0.6749, Accuracy: 0.6925\n","Epoch 43, Train Loss: 0.6510, Val Loss: 0.5128, F1 Micro: 0.7575, F1 Macro: 0.7572, Accuracy: 0.7575\n","Epoch 44, Train Loss: 0.5979, Val Loss: 0.5569, F1 Micro: 0.7525, F1 Macro: 0.7425, Accuracy: 0.7525\n","Epoch 45, Train Loss: 0.5657, Val Loss: 0.5269, F1 Micro: 0.7250, F1 Macro: 0.7153, Accuracy: 0.7250\n","Epoch 46, Train Loss: 0.5634, Val Loss: 0.5096, F1 Micro: 0.7900, F1 Macro: 0.7897, Accuracy: 0.7900\n","Epoch 47, Train Loss: 0.5717, Val Loss: 0.5695, F1 Micro: 0.7200, F1 Macro: 0.7122, Accuracy: 0.7200\n","Epoch 48, Train Loss: 0.6148, Val Loss: 0.4922, F1 Micro: 0.7350, F1 Macro: 0.7297, Accuracy: 0.7350\n","Epoch 49, Train Loss: 0.5551, Val Loss: 0.5167, F1 Micro: 0.7375, F1 Macro: 0.7338, Accuracy: 0.7375\n","Epoch 50, Train Loss: 0.5551, Val Loss: 0.4924, F1 Micro: 0.7375, F1 Macro: 0.7347, Accuracy: 0.7375\n","Epoch 51, Train Loss: 0.5976, Val Loss: 0.5335, F1 Micro: 0.7400, F1 Macro: 0.7392, Accuracy: 0.7400\n","Epoch 52, Train Loss: 0.5597, Val Loss: 0.4609, F1 Micro: 0.7800, F1 Macro: 0.7800, Accuracy: 0.7800\n","Epoch 53, Train Loss: 0.5528, Val Loss: 0.5366, F1 Micro: 0.7575, F1 Macro: 0.7466, Accuracy: 0.7575\n","Epoch 54, Train Loss: 0.6232, Val Loss: 0.4859, F1 Micro: 0.7450, F1 Macro: 0.7413, Accuracy: 0.7450\n","Epoch 55, Train Loss: 0.5741, Val Loss: 0.5182, F1 Micro: 0.7325, F1 Macro: 0.7243, Accuracy: 0.7325\n","Epoch 56, Train Loss: 0.5653, Val Loss: 0.4815, F1 Micro: 0.8000, F1 Macro: 0.7982, Accuracy: 0.8000\n","Epoch 57, Train Loss: 0.5703, Val Loss: 0.5012, F1 Micro: 0.7600, F1 Macro: 0.7529, Accuracy: 0.7600\n","Epoch 58, Train Loss: 0.5688, Val Loss: 0.4614, F1 Micro: 0.7975, F1 Macro: 0.7975, Accuracy: 0.7975\n","Epoch 59, Train Loss: 0.5738, Val Loss: 0.5076, F1 Micro: 0.7550, F1 Macro: 0.7468, Accuracy: 0.7550\n","Epoch 60, Train Loss: 0.5555, Val Loss: 0.8152, F1 Micro: 0.6875, F1 Macro: 0.6572, Accuracy: 0.6875\n","Epoch 61, Train Loss: 0.5752, Val Loss: 0.8393, F1 Micro: 0.6300, F1 Macro: 0.5731, Accuracy: 0.6300\n","Epoch 62, Train Loss: 0.5659, Val Loss: 0.4966, F1 Micro: 0.7275, F1 Macro: 0.7214, Accuracy: 0.7275\n","Epoch 63, Train Loss: 0.5734, Val Loss: 0.5867, F1 Micro: 0.7400, F1 Macro: 0.7274, Accuracy: 0.7400\n","Epoch 64, Train Loss: 0.5857, Val Loss: 0.5035, F1 Micro: 0.7275, F1 Macro: 0.7259, Accuracy: 0.7275\n","Epoch 65, Train Loss: 0.5614, Val Loss: 0.4593, F1 Micro: 0.8075, F1 Macro: 0.8075, Accuracy: 0.8075\n","Epoch 66, Train Loss: 0.5545, Val Loss: 0.5721, F1 Micro: 0.7475, F1 Macro: 0.7350, Accuracy: 0.7475\n","Epoch 67, Train Loss: 0.6178, Val Loss: 0.5870, F1 Micro: 0.6825, F1 Macro: 0.6550, Accuracy: 0.6825\n","Epoch 68, Train Loss: 0.5723, Val Loss: 0.4475, F1 Micro: 0.8050, F1 Macro: 0.8047, Accuracy: 0.8050\n","Epoch 69, Train Loss: 0.5729, Val Loss: 0.8075, F1 Micro: 0.5225, F1 Macro: 0.3815, Accuracy: 0.5225\n","Epoch 70, Train Loss: 0.5589, Val Loss: 0.4476, F1 Micro: 0.7900, F1 Macro: 0.7895, Accuracy: 0.7900\n","Epoch 71, Train Loss: 0.6008, Val Loss: 0.6617, F1 Micro: 0.6400, F1 Macro: 0.5945, Accuracy: 0.6400\n","Epoch 72, Train Loss: 0.5724, Val Loss: 0.5262, F1 Micro: 0.7950, F1 Macro: 0.7947, Accuracy: 0.7950\n","Epoch 73, Train Loss: 0.5714, Val Loss: 0.6144, F1 Micro: 0.6025, F1 Macro: 0.5323, Accuracy: 0.6025\n","Epoch 74, Train Loss: 0.5685, Val Loss: 0.5264, F1 Micro: 0.7400, F1 Macro: 0.7340, Accuracy: 0.7400\n","Epoch 75, Train Loss: 0.5493, Val Loss: 0.4611, F1 Micro: 0.7825, F1 Macro: 0.7825, Accuracy: 0.7825\n","Epoch 76, Train Loss: 0.5816, Val Loss: 0.6506, F1 Micro: 0.7475, F1 Macro: 0.7470, Accuracy: 0.7475\n","Epoch 77, Train Loss: 0.6018, Val Loss: 0.4701, F1 Micro: 0.7975, F1 Macro: 0.7972, Accuracy: 0.7975\n","Epoch 78, Train Loss: 0.5586, Val Loss: 0.4508, F1 Micro: 0.8100, F1 Macro: 0.8100, Accuracy: 0.8100\n","Epoch 79, Train Loss: 0.5427, Val Loss: 0.4810, F1 Micro: 0.7300, F1 Macro: 0.7234, Accuracy: 0.7300\n","Epoch 80, Train Loss: 0.5554, Val Loss: 0.5047, F1 Micro: 0.7525, F1 Macro: 0.7414, Accuracy: 0.7525\n","Epoch 81, Train Loss: 0.5481, Val Loss: 1.1238, F1 Micro: 0.6425, F1 Macro: 0.5934, Accuracy: 0.6425\n","Epoch 82, Train Loss: 0.5690, Val Loss: 0.4667, F1 Micro: 0.7475, F1 Macro: 0.7398, Accuracy: 0.7475\n","Epoch 83, Train Loss: 0.5433, Val Loss: 0.4524, F1 Micro: 0.7650, F1 Macro: 0.7616, Accuracy: 0.7650\n","Epoch 84, Train Loss: 0.5364, Val Loss: 0.4543, F1 Micro: 0.7725, F1 Macro: 0.7719, Accuracy: 0.7725\n","Epoch 85, Train Loss: 0.5634, Val Loss: 0.5370, F1 Micro: 0.7225, F1 Macro: 0.7036, Accuracy: 0.7225\n","Epoch 86, Train Loss: 0.5528, Val Loss: 0.6062, F1 Micro: 0.7050, F1 Macro: 0.6789, Accuracy: 0.7050\n","Epoch 87, Train Loss: 0.5865, Val Loss: 0.8978, F1 Micro: 0.5250, F1 Macro: 0.3828, Accuracy: 0.5250\n","Epoch 88, Train Loss: 0.5519, Val Loss: 0.4590, F1 Micro: 0.7975, F1 Macro: 0.7971, Accuracy: 0.7975\n","Epoch 89, Train Loss: 0.5488, Val Loss: 0.4597, F1 Micro: 0.7500, F1 Macro: 0.7434, Accuracy: 0.7500\n","Epoch 90, Train Loss: 0.5592, Val Loss: 0.7956, F1 Micro: 0.5050, F1 Macro: 0.3443, Accuracy: 0.5050\n","Epoch 91, Train Loss: 0.5372, Val Loss: 0.5492, F1 Micro: 0.7200, F1 Macro: 0.7029, Accuracy: 0.7200\n","Epoch 92, Train Loss: 0.5594, Val Loss: 0.5464, F1 Micro: 0.6950, F1 Macro: 0.6680, Accuracy: 0.6950\n","Epoch 93, Train Loss: 0.5321, Val Loss: 0.5797, F1 Micro: 0.6975, F1 Macro: 0.6742, Accuracy: 0.6975\n","Epoch 94, Train Loss: 0.5632, Val Loss: 0.4451, F1 Micro: 0.7750, F1 Macro: 0.7708, Accuracy: 0.7750\n","Epoch 95, Train Loss: 0.5897, Val Loss: 0.5240, F1 Micro: 0.7450, F1 Macro: 0.7374, Accuracy: 0.7450\n","Epoch 96, Train Loss: 0.5626, Val Loss: 0.4674, F1 Micro: 0.7600, F1 Macro: 0.7555, Accuracy: 0.7600\n","Epoch 97, Train Loss: 0.5770, Val Loss: 0.5490, F1 Micro: 0.7250, F1 Macro: 0.7059, Accuracy: 0.7250\n","Epoch 98, Train Loss: 0.5292, Val Loss: 0.4736, F1 Micro: 0.7475, F1 Macro: 0.7411, Accuracy: 0.7475\n","Epoch 99, Train Loss: 0.5140, Val Loss: 0.4344, F1 Micro: 0.7975, F1 Macro: 0.7975, Accuracy: 0.7975\n","Epoch 100, Train Loss: 0.5099, Val Loss: 0.4930, F1 Micro: 0.7425, F1 Macro: 0.7331, Accuracy: 0.7425\n","Epoch 101, Train Loss: 0.5115, Val Loss: 0.9377, F1 Micro: 0.5300, F1 Macro: 0.3931, Accuracy: 0.5300\n","Epoch 102, Train Loss: 0.5499, Val Loss: 0.5019, F1 Micro: 0.7825, F1 Macro: 0.7746, Accuracy: 0.7825\n","Epoch 103, Train Loss: 0.5511, Val Loss: 0.5318, F1 Micro: 0.7825, F1 Macro: 0.7825, Accuracy: 0.7825\n","Epoch 104, Train Loss: 0.6206, Val Loss: 0.4484, F1 Micro: 0.8425, F1 Macro: 0.8425, Accuracy: 0.8425\n"]}]},{"cell_type":"code","source":["# Initialize a dictionary to store metrics for different models\n","models_evaluation_metrics_rd = {}\n","\n","# Example model identifiers\n","model_names = ['BasicGraphModel', 'GraphSAGEModel', 'GINModel']\n","\n","# Initialize metric dictionaries for each model\n","for model_name in model_names:\n","    models_evaluation_metrics[model_name] = {'f1_micro': [], 'f1_macro': [], 'accuracy': []}\n","\n","def update_model_metrics(model_name, f1_micro, f1_macro, accuracy):\n","    models_evaluation_metrics[model_name]['f1_micro'].append(f1_micro)\n","    models_evaluation_metrics[model_name]['f1_macro'].append(f1_macro)\n","    models_evaluation_metrics[model_name]['accuracy'].append(accuracy)\n","\n","update_model_metrics('BasicGraphModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMVBXJBfVONO","executionInfo":{"status":"ok","timestamp":1711287832474,"user_tz":-60,"elapsed":237,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"df5b471d-3784-49d5-ce58-ab878c905979"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.6975, 0.8000000000000002, 0.6975, 0.7175, 0.8025]], 'f1_macro': [[0.6892954581929065, 0.7999199679871949, 0.6882226760028085, 0.7162069679979406, 0.8001909567438713]], 'accuracy': [[0.6975, 0.8, 0.6975, 0.7175, 0.8025]]}, 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"markdown","source":["#GraphSAGE model for reddit"],"metadata":{"id":"Q4I0NtBxuKDR"}},{"cell_type":"code","source":["from torch.utils.data import Subset\n","\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_rd)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_subset = Subset(dataset_rd, train_val_idx)\n","    test_subset = Subset(dataset_rd, test_idx)\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_subset = Subset(train_val_subset, inner_train_idx)\n","            inner_val_subset = Subset(train_val_subset, inner_val_idx)\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_subset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_subset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = GraphSAGEModel(\n","                input_size=1,\n","                hidden_size=256,\n","                output_size=dataset_rd.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_subset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_subset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = GraphSAGEModel(\n","        input_size=1,\n","        hidden_size=256,\n","        output_size=dataset_rd.num_classes,\n","        dropout_rate=0.5  # You could also tune the dropout rate if you wanted\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'rd_Basic_model_fold_{fold}.pth')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"1yOAucx4tA0b","executionInfo":{"status":"error","timestamp":1711378197229,"user_tz":-60,"elapsed":489,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"b17c4d28-20c1-4495-a4ee-44a1b297b734"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Outer FOLD 0\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'GraphSAGEModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-ba4cfdc733e2>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Initialize model and optimizer for the current inner fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             model = GraphSAGEModel(\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'GraphSAGEModel' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ca24smYL_8JN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# do the same to dataset proteins"],"metadata":{"id":"ftnzSfuGP71W"}},{"cell_type":"markdown","source":["First is the basic model"],"metadata":{"id":"7xjHeDkZnJbz"}},{"cell_type":"code","source":["\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_pr)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_pr[train_val_idx]\n","    test_dataset = dataset_pr[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = BasicGraphModel(\n","                input_size=dataset_pr.num_node_features,\n","                hidden_size=256,\n","                output_size=dataset_pr.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = BasicGraphModel(\n","        input_size=dataset_pr.num_node_features,\n","        hidden_size=256,\n","        output_size=dataset_pr.num_classes,\n","        dropout_rate=0.5  # You could also tune the dropout rate if you wanted\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'Basic_model_fold_{fold}.pth')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-C1fhny8QBKq","outputId":"8bfb1b5e-35d1-4a36-bf87-81d567a9fa32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 18, Train Loss: 0.6718, Val Loss: 0.7041, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 19, Train Loss: 0.7001, Val Loss: 0.6313, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 20, Train Loss: 0.7277, Val Loss: 0.6248, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 21, Train Loss: 0.7355, Val Loss: 0.6599, F1 Micro: 0.6704, F1 Macro: 0.6287, Accuracy: 0.6704\n","Epoch 22, Train Loss: 0.6875, Val Loss: 0.6288, F1 Micro: 0.6592, F1 Macro: 0.5742, Accuracy: 0.6592\n","Epoch 23, Train Loss: 0.6564, Val Loss: 0.6468, F1 Micro: 0.6648, F1 Macro: 0.5979, Accuracy: 0.6648\n","Epoch 24, Train Loss: 0.6741, Val Loss: 0.6497, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 25, Train Loss: 0.6648, Val Loss: 0.6701, F1 Micro: 0.6257, F1 Macro: 0.5747, Accuracy: 0.6257\n","Epoch 26, Train Loss: 0.6652, Val Loss: 0.6210, F1 Micro: 0.6704, F1 Macro: 0.5449, Accuracy: 0.6704\n","Epoch 27, Train Loss: 0.6645, Val Loss: 0.6626, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 28, Train Loss: 0.6567, Val Loss: 0.6357, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 29, Train Loss: 0.6605, Val Loss: 0.6441, F1 Micro: 0.6648, F1 Macro: 0.6063, Accuracy: 0.6648\n","Epoch 30, Train Loss: 0.6650, Val Loss: 0.6611, F1 Micro: 0.6704, F1 Macro: 0.6346, Accuracy: 0.6704\n","Epoch 31, Train Loss: 0.6531, Val Loss: 0.6161, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 32, Train Loss: 0.6921, Val Loss: 0.6775, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 33, Train Loss: 0.6597, Val Loss: 0.6186, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 34, Train Loss: 0.6797, Val Loss: 0.6238, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 35, Train Loss: 0.6591, Val Loss: 0.6741, F1 Micro: 0.6536, F1 Macro: 0.5799, Accuracy: 0.6536\n","Epoch 36, Train Loss: 0.6971, Val Loss: 0.6811, F1 Micro: 0.6313, F1 Macro: 0.6129, Accuracy: 0.6313\n","Epoch 37, Train Loss: 0.7013, Val Loss: 0.6550, F1 Micro: 0.6536, F1 Macro: 0.6081, Accuracy: 0.6536\n","Epoch 38, Train Loss: 0.6946, Val Loss: 0.6731, F1 Micro: 0.6034, F1 Macro: 0.6026, Accuracy: 0.6034\n","Epoch 39, Train Loss: 0.6745, Val Loss: 0.6254, F1 Micro: 0.6648, F1 Macro: 0.5730, Accuracy: 0.6648\n","Epoch 40, Train Loss: 0.7180, Val Loss: 0.6786, F1 Micro: 0.6034, F1 Macro: 0.5961, Accuracy: 0.6034\n","Epoch 41, Train Loss: 0.6947, Val Loss: 0.6224, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 42, Train Loss: 0.6853, Val Loss: 0.6357, F1 Micro: 0.6480, F1 Macro: 0.6232, Accuracy: 0.6480\n","Epoch 43, Train Loss: 0.6503, Val Loss: 0.6184, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 44, Train Loss: 0.6475, Val Loss: 0.6068, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 45, Train Loss: 0.6372, Val Loss: 0.6432, F1 Micro: 0.6648, F1 Macro: 0.6326, Accuracy: 0.6648\n","Epoch 46, Train Loss: 0.6303, Val Loss: 0.6258, F1 Micro: 0.6648, F1 Macro: 0.5837, Accuracy: 0.6648\n","Epoch 47, Train Loss: 0.6580, Val Loss: 0.6288, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 48, Train Loss: 0.6514, Val Loss: 0.6950, F1 Micro: 0.6760, F1 Macro: 0.5489, Accuracy: 0.6760\n","Epoch 49, Train Loss: 0.6527, Val Loss: 0.6898, F1 Micro: 0.6145, F1 Macro: 0.6001, Accuracy: 0.6145\n","Epoch 50, Train Loss: 0.6736, Val Loss: 0.6188, F1 Micro: 0.7039, F1 Macro: 0.6605, Accuracy: 0.7039\n","Epoch 51, Train Loss: 0.7230, Val Loss: 0.6644, F1 Micro: 0.6760, F1 Macro: 0.5562, Accuracy: 0.6760\n","Epoch 52, Train Loss: 0.7252, Val Loss: 0.8382, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 53, Train Loss: 0.6756, Val Loss: 0.6058, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 54, Train Loss: 0.6909, Val Loss: 0.6278, F1 Micro: 0.6816, F1 Macro: 0.6522, Accuracy: 0.6816\n","Epoch 55, Train Loss: 0.6558, Val Loss: 0.7503, F1 Micro: 0.5251, F1 Macro: 0.5230, Accuracy: 0.5251\n","Epoch 56, Train Loss: 0.6816, Val Loss: 0.6596, F1 Micro: 0.6536, F1 Macro: 0.5750, Accuracy: 0.6536\n","Epoch 57, Train Loss: 0.6823, Val Loss: 0.7510, F1 Micro: 0.5028, F1 Macro: 0.4952, Accuracy: 0.5028\n","Epoch 58, Train Loss: 0.6557, Val Loss: 0.6133, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 59, Train Loss: 0.6382, Val Loss: 0.6179, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 60, Train Loss: 0.6627, Val Loss: 0.6413, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 61, Train Loss: 0.6494, Val Loss: 0.6444, F1 Micro: 0.6480, F1 Macro: 0.6349, Accuracy: 0.6480\n","Epoch 62, Train Loss: 0.6582, Val Loss: 0.6489, F1 Micro: 0.6872, F1 Macro: 0.5781, Accuracy: 0.6872\n","Epoch 63, Train Loss: 0.6687, Val Loss: 0.6098, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 64, Train Loss: 0.6499, Val Loss: 0.6421, F1 Micro: 0.6816, F1 Macro: 0.5738, Accuracy: 0.6816\n","Epoch 65, Train Loss: 0.6374, Val Loss: 0.6289, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 66, Train Loss: 0.6397, Val Loss: 0.5996, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 67, Train Loss: 0.6497, Val Loss: 0.6203, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 68, Train Loss: 0.6575, Val Loss: 0.6334, F1 Micro: 0.6704, F1 Macro: 0.6400, Accuracy: 0.6704\n","Epoch 69, Train Loss: 0.6659, Val Loss: 0.6176, F1 Micro: 0.6704, F1 Macro: 0.5773, Accuracy: 0.6704\n","Epoch 70, Train Loss: 0.6409, Val Loss: 0.6183, F1 Micro: 0.6704, F1 Macro: 0.6185, Accuracy: 0.6704\n","Epoch 71, Train Loss: 0.6474, Val Loss: 0.7217, F1 Micro: 0.4804, F1 Macro: 0.4633, Accuracy: 0.4804\n","Epoch 72, Train Loss: 0.6886, Val Loss: 0.9473, F1 Micro: 0.3631, F1 Macro: 0.2664, Accuracy: 0.3631\n","Epoch 73, Train Loss: 0.7382, Val Loss: 0.6050, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 74, Train Loss: 0.6781, Val Loss: 0.6192, F1 Micro: 0.6816, F1 Macro: 0.6590, Accuracy: 0.6816\n","Epoch 75, Train Loss: 0.6387, Val Loss: 0.6308, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 76, Train Loss: 0.6377, Val Loss: 0.6331, F1 Micro: 0.6592, F1 Macro: 0.5977, Accuracy: 0.6592\n","Epoch 77, Train Loss: 0.6537, Val Loss: 0.6306, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 78, Train Loss: 0.6508, Val Loss: 0.6109, F1 Micro: 0.6872, F1 Macro: 0.6460, Accuracy: 0.6872\n","Epoch 79, Train Loss: 0.6702, Val Loss: 0.6439, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 80, Train Loss: 0.6856, Val Loss: 0.6176, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 81, Train Loss: 0.6665, Val Loss: 0.6274, F1 Micro: 0.6704, F1 Macro: 0.6317, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7351, Val Loss: 0.7539, F1 Micro: 0.3034, F1 Macro: 0.2663, Accuracy: 0.3034\n","Epoch 2, Train Loss: 0.7031, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6829, Val Loss: 0.6600, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6896, Val Loss: 0.6416, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6868, Val Loss: 0.6646, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6669, Val Loss: 0.6358, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6856, Val Loss: 0.6108, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 8, Train Loss: 0.7365, Val Loss: 0.7276, F1 Micro: 0.4438, F1 Macro: 0.4127, Accuracy: 0.4438\n","Epoch 9, Train Loss: 0.6993, Val Loss: 0.6881, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6856, Val Loss: 0.6623, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.7288, Val Loss: 0.9368, F1 Micro: 0.3315, F1 Macro: 0.2900, Accuracy: 0.3315\n","Epoch 12, Train Loss: 0.8011, Val Loss: 0.7068, F1 Micro: 0.5674, F1 Macro: 0.5643, Accuracy: 0.5674\n","Epoch 13, Train Loss: 0.6878, Val Loss: 0.6351, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6681, Val Loss: 0.5982, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 15, Train Loss: 0.6604, Val Loss: 0.6665, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 16, Train Loss: 0.6910, Val Loss: 0.8266, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 17, Train Loss: 0.6716, Val Loss: 0.6060, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 18, Train Loss: 0.6745, Val Loss: 1.1020, F1 Micro: 0.6348, F1 Macro: 0.4025, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.6723, Val Loss: 0.5865, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 20, Train Loss: 0.7104, Val Loss: 0.6053, F1 Micro: 0.7022, F1 Macro: 0.6030, Accuracy: 0.7022\n","Epoch 21, Train Loss: 0.6686, Val Loss: 0.5880, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Epoch 22, Train Loss: 0.6543, Val Loss: 0.5994, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 23, Train Loss: 0.6528, Val Loss: 0.5816, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6460, Val Loss: 0.7459, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6606, Val Loss: 0.5732, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 26, Train Loss: 0.6956, Val Loss: 0.5746, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 27, Train Loss: 0.6671, Val Loss: 0.5978, F1 Micro: 0.6910, F1 Macro: 0.5817, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.6600, Val Loss: 0.5925, F1 Micro: 0.6798, F1 Macro: 0.5277, Accuracy: 0.6798\n","Epoch 29, Train Loss: 0.6495, Val Loss: 0.6028, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 30, Train Loss: 0.6660, Val Loss: 0.7266, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 31, Train Loss: 0.8196, Val Loss: 0.6839, F1 Micro: 0.6011, F1 Macro: 0.5869, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.7143, Val Loss: 0.6207, F1 Micro: 0.6573, F1 Macro: 0.6451, Accuracy: 0.6573\n","Epoch 33, Train Loss: 0.6527, Val Loss: 0.6711, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 34, Train Loss: 0.6722, Val Loss: 0.6045, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 35, Train Loss: 0.6613, Val Loss: 0.5811, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 36, Train Loss: 0.6530, Val Loss: 0.6257, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 37, Train Loss: 0.6604, Val Loss: 0.6377, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 38, Train Loss: 0.6780, Val Loss: 0.7091, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6664, Val Loss: 0.5767, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 40, Train Loss: 0.6667, Val Loss: 0.5955, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 41, Train Loss: 0.6467, Val Loss: 1.0031, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.7154, Val Loss: 0.6167, F1 Micro: 0.6629, F1 Macro: 0.6517, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.7933, Val Loss: 0.6513, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.7142, Val Loss: 0.5858, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.6519, Val Loss: 0.6127, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 46, Train Loss: 0.6503, Val Loss: 0.6967, F1 Micro: 0.5449, F1 Macro: 0.5417, Accuracy: 0.5449\n","Epoch 47, Train Loss: 0.6724, Val Loss: 0.5939, F1 Micro: 0.6966, F1 Macro: 0.5860, Accuracy: 0.6966\n","Epoch 48, Train Loss: 0.6550, Val Loss: 0.5897, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 49, Train Loss: 0.6756, Val Loss: 0.7484, F1 Micro: 0.4157, F1 Macro: 0.3699, Accuracy: 0.4157\n","Epoch 50, Train Loss: 0.6791, Val Loss: 0.6112, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 51, Train Loss: 0.6788, Val Loss: 0.5959, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 52, Train Loss: 0.6666, Val Loss: 0.6535, F1 Micro: 0.5843, F1 Macro: 0.5800, Accuracy: 0.5843\n","Epoch 53, Train Loss: 0.6581, Val Loss: 0.6065, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 54, Train Loss: 0.6505, Val Loss: 0.6316, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 55, Train Loss: 0.6719, Val Loss: 0.5832, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 56, Train Loss: 0.6595, Val Loss: 0.6111, F1 Micro: 0.7022, F1 Macro: 0.6143, Accuracy: 0.7022\n","Epoch 57, Train Loss: 0.6706, Val Loss: 0.6312, F1 Micro: 0.6966, F1 Macro: 0.6097, Accuracy: 0.6966\n","Epoch 58, Train Loss: 0.6488, Val Loss: 1.4405, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 59, Train Loss: 0.7307, Val Loss: 0.9206, F1 Micro: 0.4045, F1 Macro: 0.3871, Accuracy: 0.4045\n","Epoch 60, Train Loss: 0.7134, Val Loss: 0.6035, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 61, Train Loss: 0.6736, Val Loss: 0.6470, F1 Micro: 0.6180, F1 Macro: 0.6083, Accuracy: 0.6180\n","Epoch 62, Train Loss: 0.6606, Val Loss: 0.6451, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.6736, Val Loss: 0.6131, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 64, Train Loss: 0.6614, Val Loss: 0.6057, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 65, Train Loss: 0.6442, Val Loss: 0.6729, F1 Micro: 0.5337, F1 Macro: 0.5294, Accuracy: 0.5337\n","Epoch 66, Train Loss: 0.6500, Val Loss: 0.6325, F1 Micro: 0.6348, F1 Macro: 0.6275, Accuracy: 0.6348\n","Epoch 67, Train Loss: 0.6504, Val Loss: 0.5661, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7269, Val Loss: 0.6949, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.7044, Val Loss: 0.6809, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6863, Val Loss: 0.6786, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6853, Val Loss: 0.6801, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 5, Train Loss: 0.6959, Val Loss: 0.6730, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.7047, Val Loss: 0.7135, F1 Micro: 0.3090, F1 Macro: 0.2361, Accuracy: 0.3090\n","Epoch 7, Train Loss: 0.7016, Val Loss: 0.7033, F1 Micro: 0.5449, F1 Macro: 0.5438, Accuracy: 0.5449\n","Epoch 8, Train Loss: 0.6919, Val Loss: 0.6721, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.7015, Val Loss: 0.6887, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 10, Train Loss: 0.6776, Val Loss: 0.6725, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 11, Train Loss: 0.7371, Val Loss: 0.6659, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.7035, Val Loss: 0.8203, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6945, Val Loss: 0.7573, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.7025, Val Loss: 0.6329, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6778, Val Loss: 0.9490, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.7062, Val Loss: 1.3527, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 17, Train Loss: 0.7336, Val Loss: 0.6609, F1 Micro: 0.7528, F1 Macro: 0.7334, Accuracy: 0.7528\n","Epoch 18, Train Loss: 0.6739, Val Loss: 0.6271, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6640, Val Loss: 0.6184, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.6656, Val Loss: 0.6318, F1 Micro: 0.6461, F1 Macro: 0.5051, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6794, Val Loss: 0.6945, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6908, Val Loss: 0.6270, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6686, Val Loss: 0.6543, F1 Micro: 0.6067, F1 Macro: 0.6065, Accuracy: 0.6067\n","Epoch 24, Train Loss: 0.6793, Val Loss: 0.7157, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 25, Train Loss: 0.7185, Val Loss: 0.6341, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.7026, Val Loss: 0.9627, F1 Micro: 0.6461, F1 Macro: 0.4572, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.7478, Val Loss: 0.6783, F1 Micro: 0.6067, F1 Macro: 0.5900, Accuracy: 0.6067\n","Epoch 28, Train Loss: 0.6869, Val Loss: 0.6169, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 29, Train Loss: 0.6872, Val Loss: 0.6480, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 30, Train Loss: 0.6928, Val Loss: 0.6084, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 31, Train Loss: 0.6661, Val Loss: 0.6886, F1 Micro: 0.6011, F1 Macro: 0.5810, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6925, Val Loss: 0.7142, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6723, Val Loss: 0.6376, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6688, Val Loss: 0.6338, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 35, Train Loss: 0.6871, Val Loss: 0.6187, F1 Micro: 0.7079, F1 Macro: 0.6075, Accuracy: 0.7079\n","Epoch 36, Train Loss: 0.6691, Val Loss: 0.8312, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 37, Train Loss: 0.6698, Val Loss: 0.6093, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.6526, Val Loss: 0.6211, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 39, Train Loss: 0.6889, Val Loss: 0.6024, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 40, Train Loss: 0.7207, Val Loss: 0.6200, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 41, Train Loss: 0.6895, Val Loss: 0.6010, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.6622, Val Loss: 0.6371, F1 Micro: 0.6966, F1 Macro: 0.5722, Accuracy: 0.6966\n","Epoch 43, Train Loss: 0.6795, Val Loss: 0.6020, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6546, Val Loss: 0.6834, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6751, Val Loss: 0.6087, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.6520, Val Loss: 0.5978, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 47, Train Loss: 0.6823, Val Loss: 0.6903, F1 Micro: 0.6011, F1 Macro: 0.5869, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.7035, Val Loss: 0.6521, F1 Micro: 0.5899, F1 Macro: 0.5898, Accuracy: 0.5899\n","Epoch 49, Train Loss: 0.6891, Val Loss: 0.5930, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 50, Train Loss: 0.6697, Val Loss: 0.5932, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 51, Train Loss: 0.6671, Val Loss: 0.5962, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.6515, Val Loss: 0.5865, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 53, Train Loss: 0.6488, Val Loss: 0.5884, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 54, Train Loss: 0.6606, Val Loss: 0.5914, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 55, Train Loss: 0.6492, Val Loss: 0.6190, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 56, Train Loss: 0.6522, Val Loss: 0.5722, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 57, Train Loss: 0.6835, Val Loss: 0.7267, F1 Micro: 0.5449, F1 Macro: 0.5408, Accuracy: 0.5449\n","Epoch 58, Train Loss: 0.6771, Val Loss: 0.7051, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 59, Train Loss: 0.6679, Val Loss: 0.6066, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 60, Train Loss: 0.6702, Val Loss: 0.6057, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 61, Train Loss: 0.6613, Val Loss: 0.6307, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 62, Train Loss: 0.7021, Val Loss: 0.6261, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 63, Train Loss: 0.7009, Val Loss: 0.5982, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 64, Train Loss: 0.6600, Val Loss: 0.5968, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 65, Train Loss: 0.6797, Val Loss: 0.5987, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 66, Train Loss: 0.6484, Val Loss: 0.6798, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 67, Train Loss: 0.7205, Val Loss: 0.6553, F1 Micro: 0.6404, F1 Macro: 0.4541, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7205, Val Loss: 0.7024, F1 Micro: 0.5506, F1 Macro: 0.4504, Accuracy: 0.5506\n","Epoch 2, Train Loss: 0.7057, Val Loss: 0.7241, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 3, Train Loss: 0.6938, Val Loss: 0.7071, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6652, Val Loss: 0.7769, F1 Micro: 0.5562, F1 Macro: 0.5338, Accuracy: 0.5562\n","Epoch 5, Train Loss: 0.6702, Val Loss: 0.7095, F1 Micro: 0.4551, F1 Macro: 0.4402, Accuracy: 0.4551\n","Epoch 6, Train Loss: 0.7154, Val Loss: 0.7294, F1 Micro: 0.5618, F1 Macro: 0.4919, Accuracy: 0.5618\n","Epoch 7, Train Loss: 0.6690, Val Loss: 0.7601, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6698, Val Loss: 0.7546, F1 Micro: 0.5112, F1 Macro: 0.4997, Accuracy: 0.5112\n","Epoch 9, Train Loss: 0.6702, Val Loss: 0.7137, F1 Micro: 0.4775, F1 Macro: 0.3232, Accuracy: 0.4775\n","Epoch 10, Train Loss: 0.7444, Val Loss: 0.6872, F1 Micro: 0.5843, F1 Macro: 0.5800, Accuracy: 0.5843\n","Epoch 11, Train Loss: 0.6670, Val Loss: 0.7617, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6349, Val Loss: 0.7022, F1 Micro: 0.5562, F1 Macro: 0.5165, Accuracy: 0.5562\n","Epoch 13, Train Loss: 0.6494, Val Loss: 0.7602, F1 Micro: 0.5112, F1 Macro: 0.5056, Accuracy: 0.5112\n","Epoch 14, Train Loss: 0.6457, Val Loss: 0.7459, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 15, Train Loss: 0.6517, Val Loss: 0.7123, F1 Micro: 0.6011, F1 Macro: 0.5788, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6657, Val Loss: 0.9098, F1 Micro: 0.4663, F1 Macro: 0.4601, Accuracy: 0.4663\n","Epoch 17, Train Loss: 0.6477, Val Loss: 0.7748, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 18, Train Loss: 0.6498, Val Loss: 0.7904, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6514, Val Loss: 0.7382, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 20, Train Loss: 0.6666, Val Loss: 1.5994, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6868, Val Loss: 0.7219, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 22, Train Loss: 0.6395, Val Loss: 0.7315, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6343, Val Loss: 0.7559, F1 Micro: 0.5337, F1 Macro: 0.5227, Accuracy: 0.5337\n","Epoch 24, Train Loss: 0.6650, Val Loss: 0.7577, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 25, Train Loss: 0.6277, Val Loss: 0.7061, F1 Micro: 0.5955, F1 Macro: 0.5903, Accuracy: 0.5955\n","Epoch 26, Train Loss: 0.6362, Val Loss: 0.7726, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 27, Train Loss: 0.6369, Val Loss: 0.7795, F1 Micro: 0.5843, F1 Macro: 0.5545, Accuracy: 0.5843\n","Epoch 28, Train Loss: 0.6977, Val Loss: 0.7439, F1 Micro: 0.5337, F1 Macro: 0.5330, Accuracy: 0.5337\n","Epoch 29, Train Loss: 0.6547, Val Loss: 0.7573, F1 Micro: 0.5899, F1 Macro: 0.5592, Accuracy: 0.5899\n","Epoch 30, Train Loss: 0.6354, Val Loss: 0.8735, F1 Micro: 0.5618, F1 Macro: 0.4919, Accuracy: 0.5618\n","Epoch 31, Train Loss: 0.6609, Val Loss: 0.7319, F1 Micro: 0.5112, F1 Macro: 0.5077, Accuracy: 0.5112\n","Epoch 32, Train Loss: 0.6823, Val Loss: 0.7132, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6428, Val Loss: 0.7935, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 34, Train Loss: 0.6315, Val Loss: 0.7866, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 35, Train Loss: 0.6365, Val Loss: 0.7459, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6441, Val Loss: 0.8398, F1 Micro: 0.5562, F1 Macro: 0.4604, Accuracy: 0.5562\n","Epoch 37, Train Loss: 0.6846, Val Loss: 0.7584, F1 Micro: 0.5506, F1 Macro: 0.5153, Accuracy: 0.5506\n","Epoch 38, Train Loss: 0.6895, Val Loss: 0.8712, F1 Micro: 0.5730, F1 Macro: 0.5001, Accuracy: 0.5730\n","Epoch 39, Train Loss: 0.6833, Val Loss: 0.7020, F1 Micro: 0.6236, F1 Macro: 0.6172, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6517, Val Loss: 0.7776, F1 Micro: 0.5843, F1 Macro: 0.5487, Accuracy: 0.5843\n","Epoch 41, Train Loss: 0.6295, Val Loss: 0.7767, F1 Micro: 0.5562, F1 Macro: 0.4604, Accuracy: 0.5562\n","Epoch 42, Train Loss: 0.6155, Val Loss: 0.8484, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 43, Train Loss: 0.6384, Val Loss: 0.8033, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 44, Train Loss: 0.6375, Val Loss: 0.9230, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6537, Val Loss: 0.8407, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 46, Train Loss: 0.6628, Val Loss: 0.7337, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6309, Val Loss: 0.7242, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 48, Train Loss: 0.6301, Val Loss: 0.8815, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 49, Train Loss: 0.6211, Val Loss: 0.7701, F1 Micro: 0.5730, F1 Macro: 0.5588, Accuracy: 0.5730\n","Epoch 50, Train Loss: 0.6382, Val Loss: 0.8737, F1 Micro: 0.5787, F1 Macro: 0.4935, Accuracy: 0.5787\n","Epoch 51, Train Loss: 0.6281, Val Loss: 0.7991, F1 Micro: 0.5562, F1 Macro: 0.4604, Accuracy: 0.5562\n","Epoch 52, Train Loss: 0.6314, Val Loss: 0.7410, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 53, Train Loss: 0.6193, Val Loss: 0.7113, F1 Micro: 0.5225, F1 Macro: 0.5217, Accuracy: 0.5225\n","Epoch 54, Train Loss: 0.6227, Val Loss: 0.8048, F1 Micro: 0.5787, F1 Macro: 0.4935, Accuracy: 0.5787\n","Epoch 55, Train Loss: 0.6478, Val Loss: 0.6916, F1 Micro: 0.6011, F1 Macro: 0.5965, Accuracy: 0.6011\n","Epoch 56, Train Loss: 0.6401, Val Loss: 0.6975, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 57, Train Loss: 0.6124, Val Loss: 0.8288, F1 Micro: 0.5449, F1 Macro: 0.4402, Accuracy: 0.5449\n","Epoch 58, Train Loss: 0.6539, Val Loss: 0.7745, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 59, Train Loss: 0.6279, Val Loss: 0.6992, F1 Micro: 0.5955, F1 Macro: 0.5922, Accuracy: 0.5955\n","Epoch 60, Train Loss: 0.6216, Val Loss: 0.7044, F1 Micro: 0.5787, F1 Macro: 0.5764, Accuracy: 0.5787\n","Epoch 61, Train Loss: 0.6259, Val Loss: 0.6926, F1 Micro: 0.5955, F1 Macro: 0.5922, Accuracy: 0.5955\n","Epoch 62, Train Loss: 0.6593, Val Loss: 0.8228, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 63, Train Loss: 0.6824, Val Loss: 0.7529, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 64, Train Loss: 0.6255, Val Loss: 0.7261, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 65, Train Loss: 0.5921, Val Loss: 0.9213, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 66, Train Loss: 0.6511, Val Loss: 0.7326, F1 Micro: 0.5955, F1 Macro: 0.5852, Accuracy: 0.5955\n","Epoch 67, Train Loss: 0.6742, Val Loss: 0.7263, F1 Micro: 0.5843, F1 Macro: 0.5487, Accuracy: 0.5843\n","Epoch 68, Train Loss: 0.7507, Val Loss: 0.9402, F1 Micro: 0.6011, F1 Macro: 0.5353, Accuracy: 0.6011\n","Epoch 69, Train Loss: 0.6443, Val Loss: 0.9315, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 70, Train Loss: 0.6665, Val Loss: 0.7128, F1 Micro: 0.5955, F1 Macro: 0.5762, Accuracy: 0.5955\n","Epoch 71, Train Loss: 0.6448, Val Loss: 0.7120, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 72, Train Loss: 0.6392, Val Loss: 0.8705, F1 Micro: 0.5618, F1 Macro: 0.4919, Accuracy: 0.5618\n","Epoch 73, Train Loss: 0.6357, Val Loss: 0.6958, F1 Micro: 0.5899, F1 Macro: 0.5877, Accuracy: 0.5899\n","Epoch 74, Train Loss: 0.6116, Val Loss: 0.7173, F1 Micro: 0.5393, F1 Macro: 0.5391, Accuracy: 0.5393\n","Epoch 75, Train Loss: 0.6552, Val Loss: 1.0490, F1 Micro: 0.4775, F1 Macro: 0.3232, Accuracy: 0.4775\n","Epoch 76, Train Loss: 0.6986, Val Loss: 0.7731, F1 Micro: 0.5562, F1 Macro: 0.4604, Accuracy: 0.5562\n","Epoch 77, Train Loss: 0.6196, Val Loss: 0.7300, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 78, Train Loss: 0.6108, Val Loss: 0.7410, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 79, Train Loss: 0.6512, Val Loss: 0.7192, F1 Micro: 0.6404, F1 Macro: 0.6299, Accuracy: 0.6404\n","Epoch 80, Train Loss: 0.6257, Val Loss: 0.6871, F1 Micro: 0.6124, F1 Macro: 0.6079, Accuracy: 0.6124\n","Epoch 81, Train Loss: 0.6168, Val Loss: 0.7459, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 82, Train Loss: 0.6113, Val Loss: 0.7119, F1 Micro: 0.5618, F1 Macro: 0.5209, Accuracy: 0.5618\n","Epoch 83, Train Loss: 0.6344, Val Loss: 0.7526, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Epoch 84, Train Loss: 0.7069, Val Loss: 0.7954, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 85, Train Loss: 0.6537, Val Loss: 0.7415, F1 Micro: 0.5562, F1 Macro: 0.5130, Accuracy: 0.5562\n","Epoch 86, Train Loss: 0.6343, Val Loss: 0.7276, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 87, Train Loss: 0.6082, Val Loss: 0.8132, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 88, Train Loss: 0.6075, Val Loss: 0.7533, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 89, Train Loss: 0.6124, Val Loss: 0.8770, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 90, Train Loss: 0.6117, Val Loss: 0.7400, F1 Micro: 0.5056, F1 Macro: 0.5016, Accuracy: 0.5056\n","Epoch 91, Train Loss: 0.6137, Val Loss: 0.7659, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 92, Train Loss: 0.6186, Val Loss: 0.9008, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 93, Train Loss: 0.6126, Val Loss: 0.7531, F1 Micro: 0.5674, F1 Macro: 0.4960, Accuracy: 0.5674\n","Epoch 94, Train Loss: 0.6148, Val Loss: 0.7692, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 95, Train Loss: 0.6222, Val Loss: 0.7538, F1 Micro: 0.5618, F1 Macro: 0.5304, Accuracy: 0.5618\n","Epoch 96, Train Loss: 0.6510, Val Loss: 0.7781, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 97, Train Loss: 0.6233, Val Loss: 0.7190, F1 Micro: 0.5899, F1 Macro: 0.5430, Accuracy: 0.5899\n","Epoch 98, Train Loss: 0.6316, Val Loss: 0.6889, F1 Micro: 0.6124, F1 Macro: 0.6018, Accuracy: 0.6124\n","Epoch 99, Train Loss: 0.6330, Val Loss: 0.7198, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 100, Train Loss: 0.6530, Val Loss: 0.7377, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 101, Train Loss: 0.6310, Val Loss: 0.7276, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 102, Train Loss: 0.6279, Val Loss: 0.7298, F1 Micro: 0.5674, F1 Macro: 0.5601, Accuracy: 0.5674\n","Epoch 103, Train Loss: 0.6433, Val Loss: 0.8070, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Epoch 104, Train Loss: 0.6262, Val Loss: 0.7290, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 105, Train Loss: 0.6372, Val Loss: 0.7099, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 106, Train Loss: 0.6786, Val Loss: 0.7367, F1 Micro: 0.6011, F1 Macro: 0.5810, Accuracy: 0.6011\n","Epoch 107, Train Loss: 0.6192, Val Loss: 0.8225, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 108, Train Loss: 0.6312, Val Loss: 0.8043, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 109, Train Loss: 0.6831, Val Loss: 0.8200, F1 Micro: 0.5506, F1 Macro: 0.4738, Accuracy: 0.5506\n","Epoch 110, Train Loss: 0.6709, Val Loss: 0.6885, F1 Micro: 0.6011, F1 Macro: 0.5931, Accuracy: 0.6011\n","Epoch 111, Train Loss: 0.6217, Val Loss: 0.8977, F1 Micro: 0.5449, F1 Macro: 0.4105, Accuracy: 0.5449\n","Epoch 112, Train Loss: 0.6898, Val Loss: 1.2247, F1 Micro: 0.4775, F1 Macro: 0.3232, Accuracy: 0.4775\n","Epoch 113, Train Loss: 0.6627, Val Loss: 0.7750, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 114, Train Loss: 0.6542, Val Loss: 1.0909, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7234, Val Loss: 0.6975, F1 Micro: 0.4213, F1 Macro: 0.4132, Accuracy: 0.4213\n","Epoch 2, Train Loss: 0.6985, Val Loss: 0.7116, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6943, Val Loss: 0.6852, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6941, Val Loss: 0.6713, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6707, Val Loss: 0.6551, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 6, Train Loss: 0.7101, Val Loss: 0.7496, F1 Micro: 0.3933, F1 Macro: 0.2823, Accuracy: 0.3933\n","Epoch 7, Train Loss: 0.7258, Val Loss: 0.6593, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.7033, Val Loss: 0.6759, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6737, Val Loss: 0.7003, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6590, Val Loss: 0.6665, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6792, Val Loss: 0.6669, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.6538, Val Loss: 0.7255, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.7522, Val Loss: 0.6935, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.7282, Val Loss: 0.6548, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6667, Val Loss: 0.7442, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 16, Train Loss: 0.6611, Val Loss: 0.6765, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6552, Val Loss: 0.6697, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 18, Train Loss: 0.7697, Val Loss: 0.8580, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.7245, Val Loss: 0.7286, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 20, Train Loss: 0.6777, Val Loss: 0.7533, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 21, Train Loss: 0.6551, Val Loss: 0.6550, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 22, Train Loss: 0.6536, Val Loss: 0.6901, F1 Micro: 0.6910, F1 Macro: 0.5817, Accuracy: 0.6910\n","Epoch 23, Train Loss: 0.6631, Val Loss: 0.6629, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 24, Train Loss: 0.6404, Val Loss: 0.6909, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 25, Train Loss: 0.6683, Val Loss: 0.6493, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 26, Train Loss: 0.6644, Val Loss: 0.6610, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6768, Val Loss: 0.6657, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 28, Train Loss: 0.6549, Val Loss: 0.7143, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6459, Val Loss: 0.6472, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 30, Train Loss: 0.6410, Val Loss: 0.6548, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 31, Train Loss: 0.6723, Val Loss: 0.6510, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 32, Train Loss: 0.6423, Val Loss: 0.6623, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 33, Train Loss: 0.6367, Val Loss: 0.6435, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 34, Train Loss: 0.6575, Val Loss: 0.7317, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 35, Train Loss: 0.6817, Val Loss: 0.8166, F1 Micro: 0.6292, F1 Macro: 0.4479, Accuracy: 0.6292\n","Epoch 36, Train Loss: 0.6844, Val Loss: 0.8984, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 37, Train Loss: 0.6953, Val Loss: 0.7554, F1 Micro: 0.6348, F1 Macro: 0.4614, Accuracy: 0.6348\n","Epoch 38, Train Loss: 0.6538, Val Loss: 0.6575, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 39, Train Loss: 0.6445, Val Loss: 0.6581, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 40, Train Loss: 0.6541, Val Loss: 0.6453, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 41, Train Loss: 0.6677, Val Loss: 0.6471, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 42, Train Loss: 0.6553, Val Loss: 0.6731, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 43, Train Loss: 0.6410, Val Loss: 0.6769, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 44, Train Loss: 0.6663, Val Loss: 0.7275, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 45, Train Loss: 0.7601, Val Loss: 0.6437, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 46, Train Loss: 0.6761, Val Loss: 0.7510, F1 Micro: 0.4382, F1 Macro: 0.4051, Accuracy: 0.4382\n","Epoch 47, Train Loss: 0.6583, Val Loss: 0.6970, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 48, Train Loss: 0.6453, Val Loss: 0.6667, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 49, Train Loss: 0.6495, Val Loss: 0.7176, F1 Micro: 0.5730, F1 Macro: 0.5730, Accuracy: 0.5730\n","Epoch 50, Train Loss: 0.6705, Val Loss: 0.6543, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 51, Train Loss: 0.6407, Val Loss: 0.7929, F1 Micro: 0.4101, F1 Macro: 0.3373, Accuracy: 0.4101\n","Epoch 52, Train Loss: 0.6590, Val Loss: 0.6552, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.6346, Val Loss: 0.6764, F1 Micro: 0.6966, F1 Macro: 0.6097, Accuracy: 0.6966\n","Epoch 54, Train Loss: 0.6345, Val Loss: 0.6508, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 55, Train Loss: 0.6258, Val Loss: 0.7884, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 56, Train Loss: 0.6626, Val Loss: 0.6506, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 57, Train Loss: 0.6687, Val Loss: 0.6596, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 58, Train Loss: 0.6536, Val Loss: 0.7135, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 59, Train Loss: 0.6561, Val Loss: 0.6696, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 60, Train Loss: 0.6578, Val Loss: 0.6495, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 61, Train Loss: 0.6688, Val Loss: 0.7932, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 62, Train Loss: 0.6769, Val Loss: 0.7917, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 63, Train Loss: 0.6678, Val Loss: 0.6618, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 64, Train Loss: 0.6413, Val Loss: 0.6806, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 65, Train Loss: 0.6563, Val Loss: 0.6842, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 66, Train Loss: 0.6590, Val Loss: 0.6629, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 67, Train Loss: 0.6328, Val Loss: 0.7680, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 68, Train Loss: 0.6432, Val Loss: 0.6831, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 69, Train Loss: 0.6516, Val Loss: 0.6707, F1 Micro: 0.6236, F1 Macro: 0.6201, Accuracy: 0.6236\n","Epoch 70, Train Loss: 0.6613, Val Loss: 0.6662, F1 Micro: 0.6180, F1 Macro: 0.6140, Accuracy: 0.6180\n","Epoch 71, Train Loss: 0.6549, Val Loss: 0.6438, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 72, Train Loss: 0.6588, Val Loss: 0.6449, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 73, Train Loss: 0.6493, Val Loss: 0.6443, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 74, Train Loss: 0.6546, Val Loss: 0.6887, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 75, Train Loss: 0.6447, Val Loss: 0.7538, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 76, Train Loss: 0.6581, Val Loss: 1.0992, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 77, Train Loss: 0.6784, Val Loss: 0.7703, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 78, Train Loss: 0.7004, Val Loss: 0.6992, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 79, Train Loss: 0.6869, Val Loss: 0.6897, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 80, Train Loss: 0.6726, Val Loss: 0.7410, F1 Micro: 0.6404, F1 Macro: 0.5790, Accuracy: 0.6404\n","Epoch 81, Train Loss: 0.6622, Val Loss: 0.6897, F1 Micro: 0.6236, F1 Macro: 0.6216, Accuracy: 0.6236\n","Epoch 82, Train Loss: 0.6343, Val Loss: 0.7992, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 83, Train Loss: 0.6500, Val Loss: 0.6576, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 84, Train Loss: 0.6660, Val Loss: 0.6499, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 85, Train Loss: 0.6947, Val Loss: 0.6457, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 86, Train Loss: 0.6687, Val Loss: 0.9128, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 87, Train Loss: 0.6563, Val Loss: 0.7580, F1 Micro: 0.4045, F1 Macro: 0.3282, Accuracy: 0.4045\n","Epoch 88, Train Loss: 0.6922, Val Loss: 0.6595, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 89, Train Loss: 0.6440, Val Loss: 0.7160, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 90, Train Loss: 0.6466, Val Loss: 0.6435, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 91, Train Loss: 0.6537, Val Loss: 0.6990, F1 Micro: 0.6067, F1 Macro: 0.5008, Accuracy: 0.6067\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.721662168099931\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7297, Val Loss: 0.6879, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6844, Val Loss: 0.6841, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6690, Val Loss: 0.6704, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 4, Train Loss: 0.6667, Val Loss: 0.6527, F1 Micro: 0.6592, F1 Macro: 0.6304, Accuracy: 0.6592\n","Epoch 5, Train Loss: 0.6685, Val Loss: 0.9123, F1 Micro: 0.3631, F1 Macro: 0.2794, Accuracy: 0.3631\n","Epoch 6, Train Loss: 0.7286, Val Loss: 0.7371, F1 Micro: 0.5028, F1 Macro: 0.4738, Accuracy: 0.5028\n","Epoch 7, Train Loss: 0.6631, Val Loss: 0.6684, F1 Micro: 0.6536, F1 Macro: 0.6203, Accuracy: 0.6536\n","Epoch 8, Train Loss: 0.6472, Val Loss: 0.6544, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 9, Train Loss: 0.6575, Val Loss: 0.6414, F1 Micro: 0.6872, F1 Macro: 0.5844, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.6505, Val Loss: 0.6305, F1 Micro: 0.6760, F1 Macro: 0.6394, Accuracy: 0.6760\n","Epoch 11, Train Loss: 0.6675, Val Loss: 0.6681, F1 Micro: 0.6648, F1 Macro: 0.5171, Accuracy: 0.6648\n","Epoch 12, Train Loss: 0.6548, Val Loss: 0.6355, F1 Micro: 0.6536, F1 Macro: 0.6203, Accuracy: 0.6536\n","Epoch 13, Train Loss: 0.6741, Val Loss: 0.8103, F1 Micro: 0.6536, F1 Macro: 0.4611, Accuracy: 0.6536\n","Epoch 14, Train Loss: 0.6863, Val Loss: 0.6335, F1 Micro: 0.6648, F1 Macro: 0.6063, Accuracy: 0.6648\n","Epoch 15, Train Loss: 0.6403, Val Loss: 0.6202, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 16, Train Loss: 0.6621, Val Loss: 0.6502, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 17, Train Loss: 0.6422, Val Loss: 0.6255, F1 Micro: 0.6927, F1 Macro: 0.6252, Accuracy: 0.6927\n","Epoch 18, Train Loss: 0.6571, Val Loss: 0.6628, F1 Micro: 0.6480, F1 Macro: 0.5546, Accuracy: 0.6480\n","Epoch 19, Train Loss: 0.6469, Val Loss: 0.6337, F1 Micro: 0.6983, F1 Macro: 0.5932, Accuracy: 0.6983\n","Epoch 20, Train Loss: 0.6653, Val Loss: 0.6727, F1 Micro: 0.6592, F1 Macro: 0.6413, Accuracy: 0.6592\n","Epoch 21, Train Loss: 0.6705, Val Loss: 0.6686, F1 Micro: 0.6313, F1 Macro: 0.6271, Accuracy: 0.6313\n","Epoch 22, Train Loss: 0.6556, Val Loss: 0.6667, F1 Micro: 0.6425, F1 Macro: 0.5178, Accuracy: 0.6425\n","Epoch 23, Train Loss: 0.6500, Val Loss: 0.7031, F1 Micro: 0.5642, F1 Macro: 0.5569, Accuracy: 0.5642\n","Epoch 24, Train Loss: 0.6675, Val Loss: 0.6314, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 25, Train Loss: 0.6529, Val Loss: 0.6717, F1 Micro: 0.6480, F1 Macro: 0.6254, Accuracy: 0.6480\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7318, Val Loss: 0.7038, F1 Micro: 0.3258, F1 Macro: 0.2820, Accuracy: 0.3258\n","Epoch 2, Train Loss: 0.6848, Val Loss: 0.6594, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6833, Val Loss: 0.6775, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 4, Train Loss: 0.6575, Val Loss: 0.7132, F1 Micro: 0.6348, F1 Macro: 0.5334, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6781, Val Loss: 0.6233, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 6, Train Loss: 0.7170, Val Loss: 0.6149, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Epoch 7, Train Loss: 0.6775, Val Loss: 0.6110, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 8, Train Loss: 0.6693, Val Loss: 0.6035, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 9, Train Loss: 0.6900, Val Loss: 0.6726, F1 Micro: 0.5899, F1 Macro: 0.5771, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6660, Val Loss: 0.6168, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6696, Val Loss: 0.6498, F1 Micro: 0.5955, F1 Macro: 0.5820, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.6904, Val Loss: 0.7433, F1 Micro: 0.4719, F1 Macro: 0.4305, Accuracy: 0.4719\n","Epoch 13, Train Loss: 0.6555, Val Loss: 0.6804, F1 Micro: 0.5169, F1 Macro: 0.5169, Accuracy: 0.5169\n","Epoch 14, Train Loss: 0.6466, Val Loss: 0.5880, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 15, Train Loss: 0.6915, Val Loss: 0.6644, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6960, Val Loss: 0.6525, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6699, Val Loss: 0.6627, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7069, Val Loss: 0.7045, F1 Micro: 0.4775, F1 Macro: 0.4419, Accuracy: 0.4775\n","Epoch 2, Train Loss: 0.7013, Val Loss: 0.6731, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6797, Val Loss: 0.6842, F1 Micro: 0.6910, F1 Macro: 0.5880, Accuracy: 0.6910\n","Epoch 4, Train Loss: 0.6838, Val Loss: 0.6672, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6752, Val Loss: 0.6826, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6724, Val Loss: 0.6898, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6665, Val Loss: 0.6613, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 8, Train Loss: 0.6602, Val Loss: 0.6255, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6982, Val Loss: 0.6224, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.7151, Val Loss: 0.6539, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.7009, Val Loss: 0.6818, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6911, Val Loss: 0.6614, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 13, Train Loss: 0.6680, Val Loss: 0.6711, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.6731, Val Loss: 0.6502, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6752, Val Loss: 0.6805, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6559, Val Loss: 0.6335, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 17, Train Loss: 0.6762, Val Loss: 0.6271, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6888, Val Loss: 0.7191, F1 Micro: 0.5506, F1 Macro: 0.4567, Accuracy: 0.5506\n","Epoch 2, Train Loss: 0.6888, Val Loss: 0.7834, F1 Micro: 0.5225, F1 Macro: 0.5033, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6994, Val Loss: 0.7312, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6598, Val Loss: 0.7082, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 5, Train Loss: 0.6359, Val Loss: 0.8292, F1 Micro: 0.5449, F1 Macro: 0.4105, Accuracy: 0.5449\n","Epoch 6, Train Loss: 0.6037, Val Loss: 0.8045, F1 Micro: 0.5562, F1 Macro: 0.4540, Accuracy: 0.5562\n","Epoch 7, Train Loss: 0.6533, Val Loss: 0.7097, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6265, Val Loss: 0.9246, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 9, Train Loss: 0.6610, Val Loss: 0.7352, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6334, Val Loss: 0.7202, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6443, Val Loss: 0.7937, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 12, Train Loss: 0.6310, Val Loss: 0.7819, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6254, Val Loss: 0.7936, F1 Micro: 0.5506, F1 Macro: 0.5184, Accuracy: 0.5506\n","Epoch 14, Train Loss: 0.6206, Val Loss: 0.7538, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 15, Train Loss: 0.6251, Val Loss: 0.7254, F1 Micro: 0.6011, F1 Macro: 0.5965, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6231, Val Loss: 0.8191, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6159, Val Loss: 0.8316, F1 Micro: 0.5618, F1 Macro: 0.4577, Accuracy: 0.5618\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7204, Val Loss: 0.6966, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6790, Val Loss: 0.6904, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6813, Val Loss: 0.8304, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6744, Val Loss: 0.6876, F1 Micro: 0.6348, F1 Macro: 0.5270, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6801, Val Loss: 0.8513, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.7039, Val Loss: 0.7177, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.6629, Val Loss: 0.7665, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6790, Val Loss: 0.6739, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 9, Train Loss: 0.6755, Val Loss: 0.7199, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.6644, Val Loss: 0.6941, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 11, Train Loss: 0.6497, Val Loss: 0.6787, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6469, Val Loss: 0.7062, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6406, Val Loss: 0.6751, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6699, Val Loss: 0.6851, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 15, Train Loss: 0.6428, Val Loss: 0.6788, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.6549, Val Loss: 0.6698, F1 Micro: 0.7079, F1 Macro: 0.6189, Accuracy: 0.7079\n","Epoch 17, Train Loss: 0.6459, Val Loss: 0.6761, F1 Micro: 0.6011, F1 Macro: 0.5931, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6762, Val Loss: 0.7107, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 19, Train Loss: 0.6406, Val Loss: 0.6844, F1 Micro: 0.6854, F1 Macro: 0.6720, Accuracy: 0.6854\n","Epoch 20, Train Loss: 0.6643, Val Loss: 0.6837, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6436, Val Loss: 0.6820, F1 Micro: 0.5506, F1 Macro: 0.5503, Accuracy: 0.5506\n","Epoch 22, Train Loss: 0.6440, Val Loss: 0.6787, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 23, Train Loss: 0.6690, Val Loss: 0.7153, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 24, Train Loss: 0.6347, Val Loss: 0.6745, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6481, Val Loss: 0.6854, F1 Micro: 0.7528, F1 Macro: 0.7076, Accuracy: 0.7528\n","Epoch 26, Train Loss: 0.6369, Val Loss: 0.6864, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 27, Train Loss: 0.6346, Val Loss: 0.7030, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 28, Train Loss: 0.6246, Val Loss: 0.7477, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 29, Train Loss: 0.6197, Val Loss: 0.6897, F1 Micro: 0.6742, F1 Macro: 0.6646, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6405, Val Loss: 0.6838, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 31, Train Loss: 0.6391, Val Loss: 0.7369, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 32, Train Loss: 0.6270, Val Loss: 0.7039, F1 Micro: 0.6067, F1 Macro: 0.6049, Accuracy: 0.6067\n","Epoch 33, Train Loss: 0.6488, Val Loss: 0.6783, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6354, Val Loss: 0.6896, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 35, Train Loss: 0.6457, Val Loss: 0.8497, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.7025798757140167\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7178, Val Loss: 0.6675, F1 Micro: 0.6369, F1 Macro: 0.4518, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6754, Val Loss: 0.6875, F1 Micro: 0.6648, F1 Macro: 0.5171, Accuracy: 0.6648\n","Epoch 3, Train Loss: 0.6711, Val Loss: 0.6583, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 4, Train Loss: 0.6566, Val Loss: 0.6335, F1 Micro: 0.6816, F1 Macro: 0.6115, Accuracy: 0.6816\n","Epoch 5, Train Loss: 0.6541, Val Loss: 0.6735, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6688, Val Loss: 0.6500, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 7, Train Loss: 0.6617, Val Loss: 0.6918, F1 Micro: 0.6089, F1 Macro: 0.5998, Accuracy: 0.6089\n","Epoch 8, Train Loss: 0.6481, Val Loss: 0.6640, F1 Micro: 0.6704, F1 Macro: 0.5293, Accuracy: 0.6704\n","Epoch 9, Train Loss: 0.6525, Val Loss: 0.6244, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 10, Train Loss: 0.6905, Val Loss: 0.6638, F1 Micro: 0.6536, F1 Macro: 0.5329, Accuracy: 0.6536\n","Epoch 11, Train Loss: 0.6595, Val Loss: 0.6596, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 12, Train Loss: 0.6585, Val Loss: 0.7064, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 13, Train Loss: 0.6627, Val Loss: 0.6681, F1 Micro: 0.6201, F1 Macro: 0.6167, Accuracy: 0.6201\n","Epoch 14, Train Loss: 0.6794, Val Loss: 0.6932, F1 Micro: 0.6592, F1 Macro: 0.5439, Accuracy: 0.6592\n","Epoch 15, Train Loss: 0.6677, Val Loss: 0.6743, F1 Micro: 0.6536, F1 Macro: 0.6280, Accuracy: 0.6536\n","Epoch 16, Train Loss: 0.6627, Val Loss: 0.6550, F1 Micro: 0.6760, F1 Macro: 0.5696, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.6384, Val Loss: 0.6318, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 18, Train Loss: 0.6511, Val Loss: 0.6441, F1 Micro: 0.6257, F1 Macro: 0.6163, Accuracy: 0.6257\n","Epoch 19, Train Loss: 0.6629, Val Loss: 0.6389, F1 Micro: 0.6648, F1 Macro: 0.6400, Accuracy: 0.6648\n","Epoch 20, Train Loss: 0.6441, Val Loss: 0.6462, F1 Micro: 0.6257, F1 Macro: 0.6080, Accuracy: 0.6257\n","Epoch 21, Train Loss: 0.6779, Val Loss: 0.6397, F1 Micro: 0.6480, F1 Macro: 0.5359, Accuracy: 0.6480\n","Epoch 22, Train Loss: 0.6559, Val Loss: 0.6450, F1 Micro: 0.7039, F1 Macro: 0.6899, Accuracy: 0.7039\n","Epoch 23, Train Loss: 0.6548, Val Loss: 0.6402, F1 Micro: 0.6480, F1 Macro: 0.6275, Accuracy: 0.6480\n","Epoch 24, Train Loss: 0.6442, Val Loss: 0.6248, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 25, Train Loss: 0.6443, Val Loss: 0.6210, F1 Micro: 0.7039, F1 Macro: 0.6605, Accuracy: 0.7039\n","Epoch 26, Train Loss: 0.6338, Val Loss: 0.6266, F1 Micro: 0.6872, F1 Macro: 0.6618, Accuracy: 0.6872\n","Epoch 27, Train Loss: 0.6390, Val Loss: 0.6264, F1 Micro: 0.6760, F1 Macro: 0.6497, Accuracy: 0.6760\n","Epoch 28, Train Loss: 0.6347, Val Loss: 0.7482, F1 Micro: 0.4804, F1 Macro: 0.4674, Accuracy: 0.4804\n","Epoch 29, Train Loss: 0.6383, Val Loss: 0.6747, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 30, Train Loss: 0.6553, Val Loss: 0.6588, F1 Micro: 0.6257, F1 Macro: 0.5581, Accuracy: 0.6257\n","Epoch 31, Train Loss: 0.6358, Val Loss: 0.7149, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 32, Train Loss: 0.6463, Val Loss: 0.6183, F1 Micro: 0.6648, F1 Macro: 0.6400, Accuracy: 0.6648\n","Epoch 33, Train Loss: 0.6472, Val Loss: 0.6244, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 34, Train Loss: 0.6441, Val Loss: 0.6346, F1 Micro: 0.6648, F1 Macro: 0.5611, Accuracy: 0.6648\n","Epoch 35, Train Loss: 0.6475, Val Loss: 0.6181, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 36, Train Loss: 0.6346, Val Loss: 0.6876, F1 Micro: 0.6034, F1 Macro: 0.5961, Accuracy: 0.6034\n","Epoch 37, Train Loss: 0.7480, Val Loss: 0.6111, F1 Micro: 0.7151, F1 Macro: 0.6703, Accuracy: 0.7151\n","Epoch 38, Train Loss: 0.6733, Val Loss: 0.6360, F1 Micro: 0.6816, F1 Macro: 0.5603, Accuracy: 0.6816\n","Epoch 39, Train Loss: 0.6479, Val Loss: 0.6982, F1 Micro: 0.5922, F1 Macro: 0.5897, Accuracy: 0.5922\n","Epoch 40, Train Loss: 0.6528, Val Loss: 0.6715, F1 Micro: 0.6034, F1 Macro: 0.6009, Accuracy: 0.6034\n","Epoch 41, Train Loss: 0.6415, Val Loss: 0.6259, F1 Micro: 0.6536, F1 Macro: 0.6280, Accuracy: 0.6536\n","Epoch 42, Train Loss: 0.6235, Val Loss: 0.6847, F1 Micro: 0.6480, F1 Macro: 0.5359, Accuracy: 0.6480\n","Epoch 43, Train Loss: 0.6369, Val Loss: 0.6201, F1 Micro: 0.6704, F1 Macro: 0.6024, Accuracy: 0.6704\n","Epoch 44, Train Loss: 0.6400, Val Loss: 0.6172, F1 Micro: 0.6704, F1 Macro: 0.6492, Accuracy: 0.6704\n","Epoch 45, Train Loss: 0.6402, Val Loss: 0.6083, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 46, Train Loss: 0.6663, Val Loss: 0.6180, F1 Micro: 0.6704, F1 Macro: 0.5881, Accuracy: 0.6704\n","Epoch 47, Train Loss: 0.6440, Val Loss: 0.6086, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 48, Train Loss: 0.6366, Val Loss: 0.6423, F1 Micro: 0.6313, F1 Macro: 0.6227, Accuracy: 0.6313\n","Epoch 49, Train Loss: 0.6350, Val Loss: 0.6201, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 50, Train Loss: 0.6352, Val Loss: 0.6214, F1 Micro: 0.6536, F1 Macro: 0.6203, Accuracy: 0.6536\n","Epoch 51, Train Loss: 0.6377, Val Loss: 0.6295, F1 Micro: 0.6648, F1 Macro: 0.6139, Accuracy: 0.6648\n","Epoch 52, Train Loss: 0.6332, Val Loss: 0.6392, F1 Micro: 0.6760, F1 Macro: 0.6302, Accuracy: 0.6760\n","Epoch 53, Train Loss: 0.6225, Val Loss: 0.6128, F1 Micro: 0.6760, F1 Macro: 0.6520, Accuracy: 0.6760\n","Epoch 54, Train Loss: 0.6277, Val Loss: 0.6310, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 55, Train Loss: 0.6320, Val Loss: 0.6150, F1 Micro: 0.6536, F1 Macro: 0.6230, Accuracy: 0.6536\n","Epoch 56, Train Loss: 0.6313, Val Loss: 0.6064, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 57, Train Loss: 0.6249, Val Loss: 0.6046, F1 Micro: 0.7318, F1 Macro: 0.6850, Accuracy: 0.7318\n","Epoch 58, Train Loss: 0.6327, Val Loss: 0.6318, F1 Micro: 0.6536, F1 Macro: 0.6364, Accuracy: 0.6536\n","Epoch 59, Train Loss: 0.6514, Val Loss: 0.6031, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 60, Train Loss: 0.6402, Val Loss: 0.6169, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 61, Train Loss: 0.6264, Val Loss: 0.6146, F1 Micro: 0.6760, F1 Macro: 0.6113, Accuracy: 0.6760\n","Epoch 62, Train Loss: 0.6393, Val Loss: 0.6191, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 63, Train Loss: 0.6472, Val Loss: 0.6476, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 64, Train Loss: 0.6473, Val Loss: 0.6292, F1 Micro: 0.6648, F1 Macro: 0.6515, Accuracy: 0.6648\n","Epoch 65, Train Loss: 0.6344, Val Loss: 0.6303, F1 Micro: 0.6592, F1 Macro: 0.6394, Accuracy: 0.6592\n","Epoch 66, Train Loss: 0.6902, Val Loss: 0.6082, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 67, Train Loss: 0.6654, Val Loss: 0.6979, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 68, Train Loss: 0.6523, Val Loss: 0.6814, F1 Micro: 0.6592, F1 Macro: 0.4954, Accuracy: 0.6592\n","Epoch 69, Train Loss: 0.6304, Val Loss: 0.6357, F1 Micro: 0.6592, F1 Macro: 0.5843, Accuracy: 0.6592\n","Epoch 70, Train Loss: 0.6679, Val Loss: 0.6192, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 71, Train Loss: 0.6251, Val Loss: 0.6224, F1 Micro: 0.6704, F1 Macro: 0.6531, Accuracy: 0.6704\n","Epoch 72, Train Loss: 0.6361, Val Loss: 0.6066, F1 Micro: 0.7151, F1 Macro: 0.6790, Accuracy: 0.7151\n","Epoch 73, Train Loss: 0.6306, Val Loss: 0.6504, F1 Micro: 0.6369, F1 Macro: 0.4165, Accuracy: 0.6369\n","Epoch 74, Train Loss: 0.6405, Val Loss: 0.6107, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 75, Train Loss: 0.6340, Val Loss: 0.6061, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 76, Train Loss: 0.6276, Val Loss: 0.6060, F1 Micro: 0.7207, F1 Macro: 0.6612, Accuracy: 0.7207\n","Epoch 77, Train Loss: 0.6250, Val Loss: 0.6127, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 78, Train Loss: 0.6321, Val Loss: 0.6100, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 79, Train Loss: 0.6273, Val Loss: 0.6078, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 80, Train Loss: 0.6428, Val Loss: 0.6239, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 81, Train Loss: 0.6461, Val Loss: 0.6500, F1 Micro: 0.6816, F1 Macro: 0.6569, Accuracy: 0.6816\n","Epoch 82, Train Loss: 0.6597, Val Loss: 0.6260, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 83, Train Loss: 0.6393, Val Loss: 0.6121, F1 Micro: 0.7095, F1 Macro: 0.6741, Accuracy: 0.7095\n","Epoch 84, Train Loss: 0.6352, Val Loss: 0.6383, F1 Micro: 0.6704, F1 Macro: 0.6633, Accuracy: 0.6704\n","Epoch 85, Train Loss: 0.6326, Val Loss: 0.6156, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Epoch 86, Train Loss: 0.6423, Val Loss: 0.6254, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 87, Train Loss: 0.6286, Val Loss: 0.6336, F1 Micro: 0.6816, F1 Macro: 0.6724, Accuracy: 0.6816\n","Epoch 88, Train Loss: 0.6607, Val Loss: 0.6403, F1 Micro: 0.6536, F1 Macro: 0.6429, Accuracy: 0.6536\n","Epoch 89, Train Loss: 0.6610, Val Loss: 0.6832, F1 Micro: 0.6313, F1 Macro: 0.6310, Accuracy: 0.6313\n","Epoch 90, Train Loss: 0.7397, Val Loss: 0.6170, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 91, Train Loss: 0.6894, Val Loss: 0.6180, F1 Micro: 0.6760, F1 Macro: 0.6113, Accuracy: 0.6760\n","Epoch 92, Train Loss: 0.6475, Val Loss: 0.6111, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 93, Train Loss: 0.6613, Val Loss: 0.6647, F1 Micro: 0.6872, F1 Macro: 0.6595, Accuracy: 0.6872\n","Epoch 94, Train Loss: 0.7254, Val Loss: 0.6358, F1 Micro: 0.6648, F1 Macro: 0.6601, Accuracy: 0.6648\n","Epoch 95, Train Loss: 0.6583, Val Loss: 0.6393, F1 Micro: 0.6592, F1 Macro: 0.6480, Accuracy: 0.6592\n","Epoch 96, Train Loss: 0.6342, Val Loss: 0.6087, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 97, Train Loss: 0.6458, Val Loss: 0.6247, F1 Micro: 0.6872, F1 Macro: 0.6571, Accuracy: 0.6872\n","Epoch 98, Train Loss: 0.6394, Val Loss: 0.6287, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 99, Train Loss: 0.6421, Val Loss: 0.6270, F1 Micro: 0.6536, F1 Macro: 0.5932, Accuracy: 0.6536\n","Epoch 100, Train Loss: 0.6218, Val Loss: 0.6432, F1 Micro: 0.6760, F1 Macro: 0.5696, Accuracy: 0.6760\n","Epoch 101, Train Loss: 0.6463, Val Loss: 0.6157, F1 Micro: 0.6704, F1 Macro: 0.5881, Accuracy: 0.6704\n","Epoch 102, Train Loss: 0.6323, Val Loss: 0.6120, F1 Micro: 0.6704, F1 Macro: 0.6425, Accuracy: 0.6704\n","Epoch 103, Train Loss: 0.6481, Val Loss: 0.6102, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 104, Train Loss: 0.6158, Val Loss: 0.6260, F1 Micro: 0.6816, F1 Macro: 0.5738, Accuracy: 0.6816\n","Epoch 105, Train Loss: 0.6215, Val Loss: 0.6385, F1 Micro: 0.6648, F1 Macro: 0.6022, Accuracy: 0.6648\n","Epoch 106, Train Loss: 0.6353, Val Loss: 0.6126, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 107, Train Loss: 0.6339, Val Loss: 0.6203, F1 Micro: 0.6704, F1 Macro: 0.5979, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7297, Val Loss: 0.6812, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6868, Val Loss: 0.6797, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6875, Val Loss: 0.6810, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.6980, Val Loss: 0.6669, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6768, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.4117, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6892, Val Loss: 0.6786, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6906, Val Loss: 0.6673, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6764, Val Loss: 0.6299, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.6644, Val Loss: 0.6320, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6608, Val Loss: 0.6215, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6641, Val Loss: 0.7942, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 12, Train Loss: 0.6860, Val Loss: 0.6145, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6532, Val Loss: 0.6567, F1 Micro: 0.6124, F1 Macro: 0.5986, Accuracy: 0.6124\n","Epoch 14, Train Loss: 0.6524, Val Loss: 0.5752, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 15, Train Loss: 0.6767, Val Loss: 0.5902, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6623, Val Loss: 0.7193, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.7617, Val Loss: 0.6694, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 18, Train Loss: 0.6830, Val Loss: 0.6367, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 19, Train Loss: 0.6556, Val Loss: 0.6895, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 20, Train Loss: 0.6699, Val Loss: 0.6185, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 21, Train Loss: 0.6690, Val Loss: 0.5980, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 22, Train Loss: 0.6494, Val Loss: 0.6590, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 23, Train Loss: 0.6688, Val Loss: 0.6442, F1 Micro: 0.5843, F1 Macro: 0.5838, Accuracy: 0.5843\n","Epoch 24, Train Loss: 0.6657, Val Loss: 0.6054, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 25, Train Loss: 0.6562, Val Loss: 0.6231, F1 Micro: 0.6180, F1 Macro: 0.6096, Accuracy: 0.6180\n","Epoch 26, Train Loss: 0.6586, Val Loss: 0.7179, F1 Micro: 0.5393, F1 Macro: 0.4803, Accuracy: 0.5393\n","Epoch 27, Train Loss: 0.6595, Val Loss: 0.6330, F1 Micro: 0.5899, F1 Macro: 0.5870, Accuracy: 0.5899\n","Epoch 28, Train Loss: 0.6643, Val Loss: 0.5869, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.6480, Val Loss: 0.6333, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6550, Val Loss: 0.6681, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 31, Train Loss: 0.6404, Val Loss: 0.5712, F1 Micro: 0.7584, F1 Macro: 0.7286, Accuracy: 0.7584\n","Epoch 32, Train Loss: 0.6586, Val Loss: 0.5912, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 33, Train Loss: 0.6439, Val Loss: 0.5796, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 34, Train Loss: 0.6524, Val Loss: 0.5873, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 35, Train Loss: 0.6488, Val Loss: 0.5737, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 36, Train Loss: 0.6476, Val Loss: 0.5736, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 37, Train Loss: 0.6856, Val Loss: 0.5755, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 38, Train Loss: 0.6685, Val Loss: 0.6485, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6929, Val Loss: 0.6325, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 40, Train Loss: 0.6479, Val Loss: 0.5976, F1 Micro: 0.6966, F1 Macro: 0.6805, Accuracy: 0.6966\n","Epoch 41, Train Loss: 0.6533, Val Loss: 0.5909, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 42, Train Loss: 0.6499, Val Loss: 0.5842, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 43, Train Loss: 0.6443, Val Loss: 0.5733, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 44, Train Loss: 0.6483, Val Loss: 0.5772, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 45, Train Loss: 0.6500, Val Loss: 0.5802, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 46, Train Loss: 0.6782, Val Loss: 0.6051, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 47, Train Loss: 0.6514, Val Loss: 0.6404, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.6484, Val Loss: 0.6170, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 49, Train Loss: 0.6502, Val Loss: 0.5949, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 50, Train Loss: 0.6453, Val Loss: 0.6477, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6457, Val Loss: 0.5776, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 52, Train Loss: 0.6452, Val Loss: 0.6097, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 53, Train Loss: 0.6586, Val Loss: 0.5963, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 54, Train Loss: 0.6476, Val Loss: 0.6108, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 55, Train Loss: 0.6394, Val Loss: 0.6279, F1 Micro: 0.7022, F1 Macro: 0.6143, Accuracy: 0.7022\n","Epoch 56, Train Loss: 0.6444, Val Loss: 0.6167, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 57, Train Loss: 0.6686, Val Loss: 0.6194, F1 Micro: 0.6236, F1 Macro: 0.6172, Accuracy: 0.6236\n","Epoch 58, Train Loss: 0.6569, Val Loss: 0.6534, F1 Micro: 0.5674, F1 Macro: 0.5667, Accuracy: 0.5674\n","Epoch 59, Train Loss: 0.6516, Val Loss: 0.6158, F1 Micro: 0.6292, F1 Macro: 0.6223, Accuracy: 0.6292\n","Epoch 60, Train Loss: 0.6488, Val Loss: 0.6236, F1 Micro: 0.7022, F1 Macro: 0.6143, Accuracy: 0.7022\n","Epoch 61, Train Loss: 0.6376, Val Loss: 0.5884, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 62, Train Loss: 0.6395, Val Loss: 0.5842, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 63, Train Loss: 0.6510, Val Loss: 0.5870, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 64, Train Loss: 0.6500, Val Loss: 0.5929, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 65, Train Loss: 0.6418, Val Loss: 0.5647, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 66, Train Loss: 0.6384, Val Loss: 0.5599, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 67, Train Loss: 0.6642, Val Loss: 0.6649, F1 Micro: 0.6798, F1 Macro: 0.5522, Accuracy: 0.6798\n","Epoch 68, Train Loss: 0.6590, Val Loss: 0.5929, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 69, Train Loss: 0.6375, Val Loss: 0.5685, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 70, Train Loss: 0.6392, Val Loss: 0.6500, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 71, Train Loss: 0.6495, Val Loss: 0.5677, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 72, Train Loss: 0.6389, Val Loss: 0.5747, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 73, Train Loss: 0.6478, Val Loss: 0.5800, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 74, Train Loss: 0.6482, Val Loss: 0.5712, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 75, Train Loss: 0.6604, Val Loss: 0.6022, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 76, Train Loss: 0.6542, Val Loss: 0.6016, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 77, Train Loss: 0.6327, Val Loss: 0.5633, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 78, Train Loss: 0.6416, Val Loss: 0.5996, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.6432, Val Loss: 0.5788, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.6440, Val Loss: 0.5959, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 81, Train Loss: 0.6738, Val Loss: 0.6738, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7529, Val Loss: 0.7133, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6792, Val Loss: 0.6759, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6747, Val Loss: 0.6630, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 4, Train Loss: 0.6633, Val Loss: 0.6905, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6905, Val Loss: 0.7571, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 6, Train Loss: 0.6794, Val Loss: 0.6455, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 7, Train Loss: 0.6672, Val Loss: 0.6354, F1 Micro: 0.6461, F1 Macro: 0.5051, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6446, Val Loss: 0.7926, F1 Micro: 0.4663, F1 Macro: 0.4496, Accuracy: 0.4663\n","Epoch 9, Train Loss: 0.6778, Val Loss: 0.6823, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 10, Train Loss: 0.6779, Val Loss: 0.6712, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6646, Val Loss: 0.6311, F1 Micro: 0.6854, F1 Macro: 0.5403, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.6852, Val Loss: 0.6804, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.6994, Val Loss: 0.6383, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.6716, Val Loss: 0.6566, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6909, Val Loss: 0.7032, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6738, Val Loss: 0.6288, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6843, Val Loss: 0.6595, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.6638, Val Loss: 0.6663, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6608, Val Loss: 0.5844, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.6485, Val Loss: 0.6290, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.6669, Val Loss: 0.6133, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6823, Val Loss: 0.6521, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 23, Train Loss: 0.6477, Val Loss: 0.5996, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 24, Train Loss: 0.6729, Val Loss: 0.6427, F1 Micro: 0.6966, F1 Macro: 0.5722, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6955, Val Loss: 0.6510, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.6641, Val Loss: 0.6379, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 27, Train Loss: 0.6569, Val Loss: 0.6423, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.6496, Val Loss: 0.5891, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6788, Val Loss: 0.6408, F1 Micro: 0.6854, F1 Macro: 0.6796, Accuracy: 0.6854\n","Epoch 30, Train Loss: 0.6627, Val Loss: 0.6251, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6695, Val Loss: 0.5860, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 32, Train Loss: 0.6646, Val Loss: 0.6302, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.6443, Val Loss: 0.6022, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 34, Train Loss: 0.6641, Val Loss: 0.5772, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 35, Train Loss: 0.6564, Val Loss: 0.6381, F1 Micro: 0.6404, F1 Macro: 0.6382, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6514, Val Loss: 0.6038, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.6517, Val Loss: 0.6503, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 38, Train Loss: 0.6723, Val Loss: 0.6131, F1 Micro: 0.6461, F1 Macro: 0.5051, Accuracy: 0.6461\n","Epoch 39, Train Loss: 0.6490, Val Loss: 0.6052, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 40, Train Loss: 0.6550, Val Loss: 0.6066, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.6666, Val Loss: 0.6496, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 42, Train Loss: 0.6671, Val Loss: 0.5796, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 43, Train Loss: 0.6636, Val Loss: 0.6138, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.6482, Val Loss: 0.6294, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 45, Train Loss: 0.6379, Val Loss: 0.8049, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 46, Train Loss: 0.6734, Val Loss: 0.5827, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 47, Train Loss: 0.6647, Val Loss: 0.6524, F1 Micro: 0.5787, F1 Macro: 0.5776, Accuracy: 0.5787\n","Epoch 48, Train Loss: 0.7002, Val Loss: 0.5868, F1 Micro: 0.7303, F1 Macro: 0.7160, Accuracy: 0.7303\n","Epoch 49, Train Loss: 0.6601, Val Loss: 0.6037, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 50, Train Loss: 0.6443, Val Loss: 0.5725, F1 Micro: 0.7135, F1 Macro: 0.6236, Accuracy: 0.7135\n","Epoch 51, Train Loss: 0.6465, Val Loss: 0.6091, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 52, Train Loss: 0.6562, Val Loss: 0.5821, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 53, Train Loss: 0.6481, Val Loss: 0.5752, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 54, Train Loss: 0.6526, Val Loss: 0.5790, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 55, Train Loss: 0.6635, Val Loss: 0.5795, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 56, Train Loss: 0.6476, Val Loss: 0.5873, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 57, Train Loss: 0.6397, Val Loss: 0.5692, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 58, Train Loss: 0.6408, Val Loss: 0.5849, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 59, Train Loss: 0.6564, Val Loss: 0.5866, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 60, Train Loss: 0.6462, Val Loss: 0.5817, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 61, Train Loss: 0.6489, Val Loss: 0.6092, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.6549, Val Loss: 0.5672, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 63, Train Loss: 0.6419, Val Loss: 0.5718, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 64, Train Loss: 0.6395, Val Loss: 0.5644, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 65, Train Loss: 0.6618, Val Loss: 0.5900, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 66, Train Loss: 0.6519, Val Loss: 0.6018, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 67, Train Loss: 0.6683, Val Loss: 0.5769, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 68, Train Loss: 0.6703, Val Loss: 0.5811, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 69, Train Loss: 0.6639, Val Loss: 0.6426, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 70, Train Loss: 0.6551, Val Loss: 0.5874, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 71, Train Loss: 0.6823, Val Loss: 0.5787, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 72, Train Loss: 0.7361, Val Loss: 0.5669, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 73, Train Loss: 0.6920, Val Loss: 0.7063, F1 Micro: 0.5899, F1 Macro: 0.5893, Accuracy: 0.5899\n","Epoch 74, Train Loss: 0.6663, Val Loss: 0.6095, F1 Micro: 0.6292, F1 Macro: 0.6290, Accuracy: 0.6292\n","Epoch 75, Train Loss: 0.6895, Val Loss: 0.5859, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 76, Train Loss: 0.6781, Val Loss: 1.0647, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 77, Train Loss: 0.7036, Val Loss: 0.6265, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 78, Train Loss: 0.6621, Val Loss: 0.6289, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.6344, Val Loss: 0.5779, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 80, Train Loss: 0.6480, Val Loss: 0.5811, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 81, Train Loss: 0.6573, Val Loss: 0.5863, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 82, Train Loss: 0.6443, Val Loss: 0.5801, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 83, Train Loss: 0.6468, Val Loss: 0.5830, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 84, Train Loss: 0.6437, Val Loss: 0.5641, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 85, Train Loss: 0.6339, Val Loss: 0.5676, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 86, Train Loss: 0.6361, Val Loss: 0.5977, F1 Micro: 0.7303, F1 Macro: 0.7175, Accuracy: 0.7303\n","Epoch 87, Train Loss: 0.6314, Val Loss: 0.6099, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 88, Train Loss: 0.6432, Val Loss: 0.5857, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 89, Train Loss: 0.6350, Val Loss: 0.5472, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 90, Train Loss: 0.6457, Val Loss: 0.5718, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 91, Train Loss: 0.6415, Val Loss: 0.5644, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 92, Train Loss: 0.6384, Val Loss: 0.5681, F1 Micro: 0.7135, F1 Macro: 0.6121, Accuracy: 0.7135\n","Epoch 93, Train Loss: 0.6355, Val Loss: 0.6402, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 94, Train Loss: 0.6411, Val Loss: 0.6000, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 95, Train Loss: 0.6401, Val Loss: 0.5738, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 96, Train Loss: 0.6442, Val Loss: 0.5637, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 97, Train Loss: 0.6415, Val Loss: 0.5678, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 98, Train Loss: 0.6423, Val Loss: 0.5743, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 99, Train Loss: 0.6409, Val Loss: 0.5563, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 100, Train Loss: 0.6518, Val Loss: 0.5486, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 101, Train Loss: 0.6439, Val Loss: 0.6026, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 102, Train Loss: 0.6430, Val Loss: 0.5670, F1 Micro: 0.7472, F1 Macro: 0.7246, Accuracy: 0.7472\n","Epoch 103, Train Loss: 0.6499, Val Loss: 0.5617, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 104, Train Loss: 0.6702, Val Loss: 0.5735, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 105, Train Loss: 0.6383, Val Loss: 0.5634, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 106, Train Loss: 0.6406, Val Loss: 0.5657, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 107, Train Loss: 0.6464, Val Loss: 0.6953, F1 Micro: 0.5169, F1 Macro: 0.5007, Accuracy: 0.5169\n","Epoch 108, Train Loss: 0.6653, Val Loss: 0.6312, F1 Micro: 0.6517, F1 Macro: 0.4603, Accuracy: 0.6517\n","Epoch 109, Train Loss: 0.6420, Val Loss: 0.5658, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7027, Val Loss: 0.7225, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6868, Val Loss: 0.7987, F1 Micro: 0.5393, F1 Macro: 0.4227, Accuracy: 0.5393\n","Epoch 3, Train Loss: 0.6769, Val Loss: 0.7493, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6494, Val Loss: 0.7418, F1 Micro: 0.5562, F1 Macro: 0.5338, Accuracy: 0.5562\n","Epoch 5, Train Loss: 0.6431, Val Loss: 0.7671, F1 Micro: 0.5506, F1 Macro: 0.5267, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.6629, Val Loss: 0.7433, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6466, Val Loss: 0.8056, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.7014, Val Loss: 0.7820, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 9, Train Loss: 0.6440, Val Loss: 0.7481, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6266, Val Loss: 0.8009, F1 Micro: 0.5562, F1 Macro: 0.4540, Accuracy: 0.5562\n","Epoch 11, Train Loss: 0.6312, Val Loss: 0.7637, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6233, Val Loss: 0.7264, F1 Micro: 0.5281, F1 Macro: 0.5178, Accuracy: 0.5281\n","Epoch 13, Train Loss: 0.6233, Val Loss: 0.7878, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 14, Train Loss: 0.6151, Val Loss: 0.7663, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.6174, Val Loss: 0.7288, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 16, Train Loss: 0.6402, Val Loss: 0.8595, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 17, Train Loss: 0.6382, Val Loss: 0.8235, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 18, Train Loss: 0.6220, Val Loss: 0.7550, F1 Micro: 0.5393, F1 Macro: 0.5197, Accuracy: 0.5393\n","Epoch 19, Train Loss: 0.6121, Val Loss: 0.7402, F1 Micro: 0.5337, F1 Macro: 0.5191, Accuracy: 0.5337\n","Epoch 20, Train Loss: 0.6144, Val Loss: 1.0283, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 21, Train Loss: 0.6637, Val Loss: 0.7859, F1 Micro: 0.5674, F1 Macro: 0.5253, Accuracy: 0.5674\n","Epoch 22, Train Loss: 0.6355, Val Loss: 0.8141, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 23, Train Loss: 0.6282, Val Loss: 0.9438, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 24, Train Loss: 0.6234, Val Loss: 0.7793, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 25, Train Loss: 0.6128, Val Loss: 0.7442, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 26, Train Loss: 0.6186, Val Loss: 0.7871, F1 Micro: 0.5787, F1 Macro: 0.5183, Accuracy: 0.5787\n","Epoch 27, Train Loss: 0.6224, Val Loss: 0.7619, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 28, Train Loss: 0.6024, Val Loss: 0.7695, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 29, Train Loss: 0.6117, Val Loss: 0.8243, F1 Micro: 0.6180, F1 Macro: 0.5481, Accuracy: 0.6180\n","Epoch 30, Train Loss: 0.6326, Val Loss: 1.1140, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6358, Val Loss: 0.7329, F1 Micro: 0.5899, F1 Macro: 0.5753, Accuracy: 0.5899\n","Epoch 32, Train Loss: 0.6198, Val Loss: 0.7507, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 33, Train Loss: 0.6311, Val Loss: 0.7332, F1 Micro: 0.4944, F1 Macro: 0.4879, Accuracy: 0.4944\n","Epoch 34, Train Loss: 0.6519, Val Loss: 0.8158, F1 Micro: 0.5618, F1 Macro: 0.4869, Accuracy: 0.5618\n","Epoch 35, Train Loss: 0.6163, Val Loss: 0.8211, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 36, Train Loss: 0.6010, Val Loss: 0.7527, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 37, Train Loss: 0.6077, Val Loss: 0.7982, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 38, Train Loss: 0.6221, Val Loss: 0.9075, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 39, Train Loss: 0.6195, Val Loss: 0.7541, F1 Micro: 0.5843, F1 Macro: 0.5685, Accuracy: 0.5843\n","Epoch 40, Train Loss: 0.6171, Val Loss: 0.7212, F1 Micro: 0.6124, F1 Macro: 0.6069, Accuracy: 0.6124\n","Epoch 41, Train Loss: 0.6278, Val Loss: 0.9028, F1 Micro: 0.4775, F1 Macro: 0.3232, Accuracy: 0.4775\n","Epoch 42, Train Loss: 0.6438, Val Loss: 0.7621, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 43, Train Loss: 0.6182, Val Loss: 0.7869, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 44, Train Loss: 0.6557, Val Loss: 0.7258, F1 Micro: 0.6292, F1 Macro: 0.6198, Accuracy: 0.6292\n","Epoch 45, Train Loss: 0.6124, Val Loss: 0.7831, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 46, Train Loss: 0.6136, Val Loss: 0.8139, F1 Micro: 0.5787, F1 Macro: 0.5226, Accuracy: 0.5787\n","Epoch 47, Train Loss: 0.6225, Val Loss: 0.7097, F1 Micro: 0.5281, F1 Macro: 0.5279, Accuracy: 0.5281\n","Epoch 48, Train Loss: 0.6162, Val Loss: 0.7560, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 49, Train Loss: 0.6078, Val Loss: 0.8251, F1 Micro: 0.5843, F1 Macro: 0.5225, Accuracy: 0.5843\n","Epoch 50, Train Loss: 0.6194, Val Loss: 0.7622, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 51, Train Loss: 0.6074, Val Loss: 0.7721, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 52, Train Loss: 0.6073, Val Loss: 0.7321, F1 Micro: 0.6292, F1 Macro: 0.6168, Accuracy: 0.6292\n","Epoch 53, Train Loss: 0.6251, Val Loss: 1.0846, F1 Micro: 0.5449, F1 Macro: 0.4105, Accuracy: 0.5449\n","Epoch 54, Train Loss: 0.6335, Val Loss: 0.8161, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 55, Train Loss: 0.6169, Val Loss: 0.7245, F1 Micro: 0.6180, F1 Macro: 0.6121, Accuracy: 0.6180\n","Epoch 56, Train Loss: 0.6185, Val Loss: 0.9276, F1 Micro: 0.5449, F1 Macro: 0.4467, Accuracy: 0.5449\n","Epoch 57, Train Loss: 0.6204, Val Loss: 0.7362, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 58, Train Loss: 0.6117, Val Loss: 1.1232, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 59, Train Loss: 0.6766, Val Loss: 0.7236, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 60, Train Loss: 0.6162, Val Loss: 0.7192, F1 Micro: 0.6517, F1 Macro: 0.6452, Accuracy: 0.6517\n","Epoch 61, Train Loss: 0.6101, Val Loss: 0.7275, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 62, Train Loss: 0.5907, Val Loss: 0.8601, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 63, Train Loss: 0.6118, Val Loss: 0.7504, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 64, Train Loss: 0.6245, Val Loss: 0.7778, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 65, Train Loss: 0.6053, Val Loss: 0.7574, F1 Micro: 0.6067, F1 Macro: 0.5700, Accuracy: 0.6067\n","Epoch 66, Train Loss: 0.6051, Val Loss: 0.7960, F1 Micro: 0.5787, F1 Macro: 0.5266, Accuracy: 0.5787\n","Epoch 67, Train Loss: 0.6270, Val Loss: 0.7486, F1 Micro: 0.5730, F1 Macro: 0.5452, Accuracy: 0.5730\n","Epoch 68, Train Loss: 0.6072, Val Loss: 0.7779, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 69, Train Loss: 0.6142, Val Loss: 0.7728, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 70, Train Loss: 0.6133, Val Loss: 0.8401, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 71, Train Loss: 0.6178, Val Loss: 0.7333, F1 Micro: 0.6067, F1 Macro: 0.6017, Accuracy: 0.6067\n","Epoch 72, Train Loss: 0.6249, Val Loss: 0.8010, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 73, Train Loss: 0.6120, Val Loss: 0.7379, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 74, Train Loss: 0.6121, Val Loss: 0.7248, F1 Micro: 0.6067, F1 Macro: 0.5919, Accuracy: 0.6067\n","Epoch 75, Train Loss: 0.6123, Val Loss: 0.7213, F1 Micro: 0.5955, F1 Macro: 0.5692, Accuracy: 0.5955\n","Epoch 76, Train Loss: 0.6150, Val Loss: 0.7321, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 77, Train Loss: 0.6096, Val Loss: 0.7133, F1 Micro: 0.6404, F1 Macro: 0.6349, Accuracy: 0.6404\n","Epoch 78, Train Loss: 0.6050, Val Loss: 0.8725, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 79, Train Loss: 0.6067, Val Loss: 0.7259, F1 Micro: 0.6517, F1 Macro: 0.6428, Accuracy: 0.6517\n","Epoch 80, Train Loss: 0.6011, Val Loss: 0.7659, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 81, Train Loss: 0.6037, Val Loss: 0.8210, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 82, Train Loss: 0.6038, Val Loss: 0.7415, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 83, Train Loss: 0.5996, Val Loss: 0.8779, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 84, Train Loss: 0.6111, Val Loss: 0.7614, F1 Micro: 0.5730, F1 Macro: 0.5548, Accuracy: 0.5730\n","Epoch 85, Train Loss: 0.6127, Val Loss: 0.8213, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 86, Train Loss: 0.6095, Val Loss: 0.7453, F1 Micro: 0.6011, F1 Macro: 0.5831, Accuracy: 0.6011\n","Epoch 87, Train Loss: 0.6151, Val Loss: 0.7484, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 88, Train Loss: 0.5939, Val Loss: 0.8439, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 89, Train Loss: 0.6080, Val Loss: 0.8358, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 90, Train Loss: 0.6194, Val Loss: 0.7030, F1 Micro: 0.5449, F1 Macro: 0.5448, Accuracy: 0.5449\n","Epoch 91, Train Loss: 0.5982, Val Loss: 0.7462, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 92, Train Loss: 0.6157, Val Loss: 0.9305, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 93, Train Loss: 0.6096, Val Loss: 0.8592, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 94, Train Loss: 0.6236, Val Loss: 0.7669, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 95, Train Loss: 0.6114, Val Loss: 0.7579, F1 Micro: 0.5787, F1 Macro: 0.5525, Accuracy: 0.5787\n","Epoch 96, Train Loss: 0.6057, Val Loss: 0.7255, F1 Micro: 0.6124, F1 Macro: 0.5968, Accuracy: 0.6124\n","Epoch 97, Train Loss: 0.6047, Val Loss: 0.8898, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 98, Train Loss: 0.6228, Val Loss: 0.7437, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 99, Train Loss: 0.6211, Val Loss: 0.7573, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 100, Train Loss: 0.6378, Val Loss: 0.7193, F1 Micro: 0.5562, F1 Macro: 0.5558, Accuracy: 0.5562\n","Epoch 101, Train Loss: 0.6125, Val Loss: 0.7814, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 102, Train Loss: 0.5993, Val Loss: 0.8106, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 103, Train Loss: 0.6151, Val Loss: 0.8091, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 104, Train Loss: 0.6103, Val Loss: 0.7542, F1 Micro: 0.6517, F1 Macro: 0.6428, Accuracy: 0.6517\n","Epoch 105, Train Loss: 0.5919, Val Loss: 0.7192, F1 Micro: 0.5562, F1 Macro: 0.5423, Accuracy: 0.5562\n","Epoch 106, Train Loss: 0.5948, Val Loss: 0.9105, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 107, Train Loss: 0.5964, Val Loss: 0.7498, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 108, Train Loss: 0.5961, Val Loss: 0.7304, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 109, Train Loss: 0.5995, Val Loss: 0.7695, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 110, Train Loss: 0.5914, Val Loss: 0.7346, F1 Micro: 0.6180, F1 Macro: 0.6083, Accuracy: 0.6180\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7218, Val Loss: 0.7073, F1 Micro: 0.3596, F1 Macro: 0.2946, Accuracy: 0.3596\n","Epoch 2, Train Loss: 0.6974, Val Loss: 0.7024, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6798, Val Loss: 0.6869, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6760, Val Loss: 0.7059, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6708, Val Loss: 0.6880, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6820, Val Loss: 0.6937, F1 Micro: 0.6011, F1 Macro: 0.4117, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6709, Val Loss: 0.6863, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6877, Val Loss: 0.6853, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.6874, Val Loss: 0.7199, F1 Micro: 0.5899, F1 Macro: 0.3951, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6870, Val Loss: 0.6884, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6849, Val Loss: 0.6899, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6740, Val Loss: 0.7030, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6862, Val Loss: 0.7019, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6865, Val Loss: 0.6846, F1 Micro: 0.6348, F1 Macro: 0.4614, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6897, Val Loss: 0.7724, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6911, Val Loss: 0.7277, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6924, Val Loss: 0.6867, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6721, Val Loss: 0.6744, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6853, Val Loss: 0.7115, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6988, Val Loss: 0.8208, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6837, Val Loss: 0.7110, F1 Micro: 0.6404, F1 Macro: 0.4746, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.7113, Val Loss: 0.8633, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.7750, Val Loss: 0.6986, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 24, Train Loss: 0.6952, Val Loss: 0.6750, F1 Micro: 0.6404, F1 Macro: 0.5977, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6660, Val Loss: 0.7027, F1 Micro: 0.6461, F1 Macro: 0.4875, Accuracy: 0.6461\n","Epoch 26, Train Loss: 0.6530, Val Loss: 0.6756, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 27, Train Loss: 0.6714, Val Loss: 0.6833, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 28, Train Loss: 0.6579, Val Loss: 0.6784, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6520, Val Loss: 0.7311, F1 Micro: 0.6404, F1 Macro: 0.5094, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6446, Val Loss: 0.6856, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 31, Train Loss: 0.6690, Val Loss: 0.6718, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6614, Val Loss: 0.7997, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.6672, Val Loss: 0.7081, F1 Micro: 0.5843, F1 Macro: 0.5737, Accuracy: 0.5843\n","Epoch 34, Train Loss: 0.6605, Val Loss: 0.6770, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 35, Train Loss: 0.6428, Val Loss: 0.6739, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.6435, Val Loss: 0.7090, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 37, Train Loss: 0.6541, Val Loss: 0.7183, F1 Micro: 0.6404, F1 Macro: 0.5790, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6420, Val Loss: 0.6972, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 39, Train Loss: 0.6450, Val Loss: 0.7111, F1 Micro: 0.5955, F1 Macro: 0.5783, Accuracy: 0.5955\n","Epoch 40, Train Loss: 0.6560, Val Loss: 0.6680, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 41, Train Loss: 0.6529, Val Loss: 0.6830, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.6630, Val Loss: 0.7027, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 43, Train Loss: 0.6361, Val Loss: 0.6787, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 44, Train Loss: 0.6221, Val Loss: 0.7521, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6452, Val Loss: 0.7242, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 46, Train Loss: 0.6500, Val Loss: 0.6919, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6437, Val Loss: 0.7013, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 48, Train Loss: 0.6440, Val Loss: 0.6798, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 49, Train Loss: 0.6379, Val Loss: 0.7038, F1 Micro: 0.6124, F1 Macro: 0.6096, Accuracy: 0.6124\n","Epoch 50, Train Loss: 0.6359, Val Loss: 0.6984, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 51, Train Loss: 0.6479, Val Loss: 0.6863, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 52, Train Loss: 0.6644, Val Loss: 0.6910, F1 Micro: 0.5899, F1 Macro: 0.5852, Accuracy: 0.5899\n","Epoch 53, Train Loss: 0.6739, Val Loss: 0.6805, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 54, Train Loss: 0.6760, Val Loss: 0.7211, F1 Micro: 0.6404, F1 Macro: 0.5374, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.6531, Val Loss: 0.7290, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 56, Train Loss: 0.6728, Val Loss: 0.7013, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 57, Train Loss: 0.6506, Val Loss: 0.6906, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 58, Train Loss: 0.6316, Val Loss: 0.6904, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 59, Train Loss: 0.6352, Val Loss: 0.7113, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.6319, Val Loss: 0.6887, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 61, Train Loss: 0.6423, Val Loss: 0.6882, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 62, Train Loss: 0.6288, Val Loss: 0.7072, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 63, Train Loss: 0.6274, Val Loss: 0.6906, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 64, Train Loss: 0.6400, Val Loss: 0.6976, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 65, Train Loss: 0.6262, Val Loss: 0.6856, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 66, Train Loss: 0.6482, Val Loss: 0.7005, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 67, Train Loss: 0.6250, Val Loss: 0.6855, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 68, Train Loss: 0.6320, Val Loss: 0.7130, F1 Micro: 0.7247, F1 Macro: 0.6572, Accuracy: 0.7247\n","Epoch 69, Train Loss: 0.6330, Val Loss: 0.7122, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 70, Train Loss: 0.6238, Val Loss: 0.7130, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 71, Train Loss: 0.6485, Val Loss: 0.6933, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 72, Train Loss: 0.6352, Val Loss: 0.6880, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 73, Train Loss: 0.6389, Val Loss: 0.7772, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.6295, Val Loss: 0.6902, F1 Micro: 0.6236, F1 Macro: 0.6147, Accuracy: 0.6236\n","Epoch 75, Train Loss: 0.6389, Val Loss: 0.7259, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 76, Train Loss: 0.6481, Val Loss: 0.6804, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 77, Train Loss: 0.6346, Val Loss: 0.6777, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 78, Train Loss: 0.6262, Val Loss: 0.6859, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 79, Train Loss: 0.6378, Val Loss: 0.7063, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 80, Train Loss: 0.6282, Val Loss: 0.7107, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 81, Train Loss: 0.6338, Val Loss: 0.6820, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 82, Train Loss: 0.6312, Val Loss: 0.7290, F1 Micro: 0.7191, F1 Macro: 0.6386, Accuracy: 0.7191\n","Epoch 83, Train Loss: 0.6329, Val Loss: 0.6858, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 84, Train Loss: 0.6198, Val Loss: 0.8664, F1 Micro: 0.6404, F1 Macro: 0.4746, Accuracy: 0.6404\n","Epoch 85, Train Loss: 0.6632, Val Loss: 0.6731, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 86, Train Loss: 0.6463, Val Loss: 0.6760, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 87, Train Loss: 0.6525, Val Loss: 0.6936, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 88, Train Loss: 0.6406, Val Loss: 0.6843, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 89, Train Loss: 0.6587, Val Loss: 0.7202, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 90, Train Loss: 0.6278, Val Loss: 0.6827, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 91, Train Loss: 0.6366, Val Loss: 0.7232, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 92, Train Loss: 0.6284, Val Loss: 0.6799, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 93, Train Loss: 0.6349, Val Loss: 0.7372, F1 Micro: 0.6292, F1 Macro: 0.5742, Accuracy: 0.6292\n","Epoch 94, Train Loss: 0.6380, Val Loss: 0.7207, F1 Micro: 0.6461, F1 Macro: 0.6401, Accuracy: 0.6461\n","Epoch 95, Train Loss: 0.6424, Val Loss: 0.7122, F1 Micro: 0.6348, F1 Macro: 0.5202, Accuracy: 0.6348\n","Epoch 96, Train Loss: 0.6346, Val Loss: 0.6765, F1 Micro: 0.5843, F1 Macro: 0.5830, Accuracy: 0.5843\n","Epoch 97, Train Loss: 0.6347, Val Loss: 0.7241, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 98, Train Loss: 0.6268, Val Loss: 0.6987, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 99, Train Loss: 0.6365, Val Loss: 0.6992, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 100, Train Loss: 0.6438, Val Loss: 0.7604, F1 Micro: 0.6910, F1 Macro: 0.5880, Accuracy: 0.6910\n","Epoch 101, Train Loss: 0.6418, Val Loss: 0.7131, F1 Micro: 0.7135, F1 Macro: 0.6236, Accuracy: 0.7135\n","Epoch 102, Train Loss: 0.6186, Val Loss: 0.6776, F1 Micro: 0.6966, F1 Macro: 0.6805, Accuracy: 0.6966\n","Epoch 103, Train Loss: 0.6234, Val Loss: 0.6885, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 104, Train Loss: 0.6116, Val Loss: 0.6780, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 105, Train Loss: 0.6208, Val Loss: 0.6872, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 106, Train Loss: 0.6340, Val Loss: 0.7038, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 107, Train Loss: 0.6286, Val Loss: 0.6789, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 108, Train Loss: 0.6269, Val Loss: 0.6777, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 109, Train Loss: 0.6202, Val Loss: 0.6763, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 110, Train Loss: 0.6387, Val Loss: 0.6878, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 111, Train Loss: 0.6314, Val Loss: 0.7116, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 112, Train Loss: 0.6476, Val Loss: 0.7273, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 113, Train Loss: 0.6789, Val Loss: 0.6972, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 114, Train Loss: 0.6925, Val Loss: 0.6835, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 115, Train Loss: 0.6849, Val Loss: 0.6924, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 116, Train Loss: 0.6588, Val Loss: 0.8474, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 117, Train Loss: 0.7026, Val Loss: 0.6776, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 118, Train Loss: 0.6552, Val Loss: 0.7105, F1 Micro: 0.6292, F1 Macro: 0.5817, Accuracy: 0.6292\n","Epoch 119, Train Loss: 0.6504, Val Loss: 0.7301, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 120, Train Loss: 0.6337, Val Loss: 0.6854, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 121, Train Loss: 0.6367, Val Loss: 0.6877, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 122, Train Loss: 0.6319, Val Loss: 0.7223, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 123, Train Loss: 0.6415, Val Loss: 0.6781, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 124, Train Loss: 0.6387, Val Loss: 0.6872, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 125, Train Loss: 0.6297, Val Loss: 0.8034, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 126, Train Loss: 0.6468, Val Loss: 0.7187, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 127, Train Loss: 0.6268, Val Loss: 0.7373, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 128, Train Loss: 0.6356, Val Loss: 0.6927, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 129, Train Loss: 0.6089, Val Loss: 0.7170, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 130, Train Loss: 0.6313, Val Loss: 0.7020, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 131, Train Loss: 0.6380, Val Loss: 0.6958, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 132, Train Loss: 0.6167, Val Loss: 0.6930, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 133, Train Loss: 0.6297, Val Loss: 0.6765, F1 Micro: 0.7022, F1 Macro: 0.6856, Accuracy: 0.7022\n","Epoch 134, Train Loss: 0.6263, Val Loss: 0.6742, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 135, Train Loss: 0.6284, Val Loss: 0.7498, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 136, Train Loss: 0.6303, Val Loss: 0.6873, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 137, Train Loss: 0.6200, Val Loss: 0.6914, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.7272675914882932\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6865, Val Loss: 0.6627, F1 Micro: 0.6369, F1 Macro: 0.4165, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6801, Val Loss: 0.6839, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 3, Train Loss: 0.6818, Val Loss: 0.6641, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 4, Train Loss: 0.6757, Val Loss: 0.6630, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6647, Val Loss: 0.6836, F1 Micro: 0.6648, F1 Macro: 0.4989, Accuracy: 0.6648\n","Epoch 6, Train Loss: 0.6782, Val Loss: 0.6642, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 7, Train Loss: 0.6739, Val Loss: 0.6575, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.6697, Val Loss: 0.6560, F1 Micro: 0.6369, F1 Macro: 0.4165, Accuracy: 0.6369\n","Epoch 9, Train Loss: 0.6683, Val Loss: 0.6579, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 10, Train Loss: 0.6679, Val Loss: 0.6553, F1 Micro: 0.6369, F1 Macro: 0.4165, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6618, Val Loss: 0.6534, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 12, Train Loss: 0.6559, Val Loss: 0.6392, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 13, Train Loss: 0.6478, Val Loss: 0.6307, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 14, Train Loss: 0.6415, Val Loss: 0.6459, F1 Micro: 0.6592, F1 Macro: 0.6056, Accuracy: 0.6592\n","Epoch 15, Train Loss: 0.6399, Val Loss: 0.6245, F1 Micro: 0.6760, F1 Macro: 0.5816, Accuracy: 0.6760\n","Epoch 16, Train Loss: 0.6292, Val Loss: 0.6230, F1 Micro: 0.6816, F1 Macro: 0.5738, Accuracy: 0.6816\n","Epoch 17, Train Loss: 0.6366, Val Loss: 0.6331, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 18, Train Loss: 0.6347, Val Loss: 0.6242, F1 Micro: 0.6872, F1 Macro: 0.6396, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6425, Val Loss: 0.6213, F1 Micro: 0.6872, F1 Macro: 0.5781, Accuracy: 0.6872\n","Epoch 20, Train Loss: 0.6432, Val Loss: 0.6243, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 21, Train Loss: 0.6304, Val Loss: 0.6373, F1 Micro: 0.6704, F1 Macro: 0.6425, Accuracy: 0.6704\n","Epoch 22, Train Loss: 0.6259, Val Loss: 0.6441, F1 Micro: 0.6536, F1 Macro: 0.5972, Accuracy: 0.6536\n","Epoch 23, Train Loss: 0.6357, Val Loss: 0.6160, F1 Micro: 0.7095, F1 Macro: 0.6622, Accuracy: 0.7095\n","Epoch 24, Train Loss: 0.6298, Val Loss: 0.6145, F1 Micro: 0.7039, F1 Macro: 0.6429, Accuracy: 0.7039\n","Epoch 25, Train Loss: 0.6202, Val Loss: 0.6264, F1 Micro: 0.6816, F1 Macro: 0.6413, Accuracy: 0.6816\n","Epoch 26, Train Loss: 0.6287, Val Loss: 0.6176, F1 Micro: 0.6816, F1 Macro: 0.6382, Accuracy: 0.6816\n","Epoch 27, Train Loss: 0.6250, Val Loss: 0.6276, F1 Micro: 0.6704, F1 Macro: 0.6109, Accuracy: 0.6704\n","Epoch 28, Train Loss: 0.6263, Val Loss: 0.6268, F1 Micro: 0.6704, F1 Macro: 0.6109, Accuracy: 0.6704\n","Epoch 29, Train Loss: 0.6290, Val Loss: 0.6363, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 30, Train Loss: 0.6280, Val Loss: 0.6122, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 31, Train Loss: 0.6292, Val Loss: 0.6131, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 32, Train Loss: 0.6261, Val Loss: 0.6089, F1 Micro: 0.7318, F1 Macro: 0.6747, Accuracy: 0.7318\n","Epoch 33, Train Loss: 0.6209, Val Loss: 0.6152, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 34, Train Loss: 0.6263, Val Loss: 0.6105, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 35, Train Loss: 0.6170, Val Loss: 0.6299, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 36, Train Loss: 0.6274, Val Loss: 0.6094, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 37, Train Loss: 0.6249, Val Loss: 0.6106, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 38, Train Loss: 0.6332, Val Loss: 0.6137, F1 Micro: 0.6760, F1 Macro: 0.6394, Accuracy: 0.6760\n","Epoch 39, Train Loss: 0.6255, Val Loss: 0.6134, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 40, Train Loss: 0.6313, Val Loss: 0.6176, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 41, Train Loss: 0.6218, Val Loss: 0.6091, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 42, Train Loss: 0.6184, Val Loss: 0.6073, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6959, Val Loss: 0.6672, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6777, Val Loss: 0.6523, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6729, Val Loss: 0.6536, F1 Micro: 0.6124, F1 Macro: 0.3930, Accuracy: 0.6124\n","Epoch 4, Train Loss: 0.6761, Val Loss: 0.6648, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6783, Val Loss: 0.6540, F1 Micro: 0.6348, F1 Macro: 0.4510, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6717, Val Loss: 0.6515, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.6767, Val Loss: 0.6626, F1 Micro: 0.6180, F1 Macro: 0.4518, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6695, Val Loss: 0.6561, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 9, Train Loss: 0.6677, Val Loss: 0.6506, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6693, Val Loss: 0.6424, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6762, Val Loss: 0.6497, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6670, Val Loss: 0.6414, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 13, Train Loss: 0.6666, Val Loss: 0.6320, F1 Micro: 0.6461, F1 Macro: 0.4875, Accuracy: 0.6461\n","Epoch 14, Train Loss: 0.6518, Val Loss: 0.6405, F1 Micro: 0.6910, F1 Macro: 0.5880, Accuracy: 0.6910\n","Epoch 15, Train Loss: 0.6509, Val Loss: 0.6103, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.6401, Val Loss: 0.6071, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 17, Train Loss: 0.6303, Val Loss: 0.6078, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 18, Train Loss: 0.6313, Val Loss: 0.6221, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.6427, Val Loss: 0.6035, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 20, Train Loss: 0.6408, Val Loss: 0.5904, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 21, Train Loss: 0.6363, Val Loss: 0.5970, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.6366, Val Loss: 0.5899, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 23, Train Loss: 0.6363, Val Loss: 0.5839, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 24, Train Loss: 0.6322, Val Loss: 0.6044, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 25, Train Loss: 0.6258, Val Loss: 0.5851, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 26, Train Loss: 0.6336, Val Loss: 0.5866, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 27, Train Loss: 0.6320, Val Loss: 0.6089, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 28, Train Loss: 0.6268, Val Loss: 0.5799, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 29, Train Loss: 0.6344, Val Loss: 0.5845, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 30, Train Loss: 0.6372, Val Loss: 0.5820, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 31, Train Loss: 0.6359, Val Loss: 0.5933, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 32, Train Loss: 0.6248, Val Loss: 0.5762, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 33, Train Loss: 0.6470, Val Loss: 0.5802, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 34, Train Loss: 0.6306, Val Loss: 0.5872, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 35, Train Loss: 0.6331, Val Loss: 0.5782, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 36, Train Loss: 0.6266, Val Loss: 0.5770, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6817, Val Loss: 0.6740, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6854, Val Loss: 0.6690, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6812, Val Loss: 0.6733, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6784, Val Loss: 0.6709, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6761, Val Loss: 0.6668, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6725, Val Loss: 0.6632, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6719, Val Loss: 0.6649, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6723, Val Loss: 0.6742, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6715, Val Loss: 0.6645, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6662, Val Loss: 0.6645, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6646, Val Loss: 0.6547, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6662, Val Loss: 0.6516, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6497, Val Loss: 0.6522, F1 Micro: 0.6404, F1 Macro: 0.4541, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6611, Val Loss: 0.6352, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6481, Val Loss: 0.6215, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6442, Val Loss: 0.6124, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 17, Train Loss: 0.6497, Val Loss: 0.6044, F1 Micro: 0.7191, F1 Macro: 0.6336, Accuracy: 0.7191\n","Epoch 18, Train Loss: 0.6431, Val Loss: 0.6131, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.6474, Val Loss: 0.5943, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 20, Train Loss: 0.6492, Val Loss: 0.5935, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 21, Train Loss: 0.6433, Val Loss: 0.5868, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 22, Train Loss: 0.6446, Val Loss: 0.5868, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 23, Train Loss: 0.6453, Val Loss: 0.5854, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 24, Train Loss: 0.6406, Val Loss: 0.5882, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 25, Train Loss: 0.6459, Val Loss: 0.5869, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6367, Val Loss: 0.5818, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 27, Train Loss: 0.6372, Val Loss: 0.6269, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 28, Train Loss: 0.6491, Val Loss: 0.5958, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6377, Val Loss: 0.5971, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6775, Val Loss: 0.7466, F1 Micro: 0.5449, F1 Macro: 0.4402, Accuracy: 0.5449\n","Epoch 2, Train Loss: 0.6639, Val Loss: 0.7234, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6672, Val Loss: 0.7097, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6618, Val Loss: 0.7126, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6633, Val Loss: 0.7162, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6563, Val Loss: 0.7163, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 7, Train Loss: 0.6541, Val Loss: 0.7084, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6553, Val Loss: 0.7111, F1 Micro: 0.5449, F1 Macro: 0.4105, Accuracy: 0.5449\n","Epoch 9, Train Loss: 0.6489, Val Loss: 0.7405, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 10, Train Loss: 0.6443, Val Loss: 0.7234, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 11, Train Loss: 0.6343, Val Loss: 0.7018, F1 Micro: 0.5955, F1 Macro: 0.5264, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.6268, Val Loss: 0.7255, F1 Micro: 0.5449, F1 Macro: 0.4333, Accuracy: 0.5449\n","Epoch 13, Train Loss: 0.6196, Val Loss: 0.7147, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 14, Train Loss: 0.6122, Val Loss: 0.7497, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 15, Train Loss: 0.6145, Val Loss: 0.7197, F1 Micro: 0.6236, F1 Macro: 0.6147, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6126, Val Loss: 0.7480, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6119, Val Loss: 0.7413, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 18, Train Loss: 0.6180, Val Loss: 0.7149, F1 Micro: 0.5787, F1 Macro: 0.5748, Accuracy: 0.5787\n","Epoch 19, Train Loss: 0.6096, Val Loss: 0.7287, F1 Micro: 0.5899, F1 Macro: 0.5619, Accuracy: 0.5899\n","Epoch 20, Train Loss: 0.6016, Val Loss: 0.7291, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 21, Train Loss: 0.6119, Val Loss: 0.7472, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 22, Train Loss: 0.6086, Val Loss: 0.7371, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 23, Train Loss: 0.6098, Val Loss: 0.7327, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.6116, Val Loss: 0.7184, F1 Micro: 0.6180, F1 Macro: 0.6096, Accuracy: 0.6180\n","Epoch 25, Train Loss: 0.5978, Val Loss: 0.7402, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6838, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.4117, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6738, Val Loss: 0.6795, F1 Micro: 0.6236, F1 Macro: 0.4823, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6786, Val Loss: 0.6809, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.6736, Val Loss: 0.6780, F1 Micro: 0.6404, F1 Macro: 0.5014, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6665, Val Loss: 0.6802, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6660, Val Loss: 0.6822, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6670, Val Loss: 0.6742, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6607, Val Loss: 0.6901, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6634, Val Loss: 0.6670, F1 Micro: 0.6348, F1 Macro: 0.4614, Accuracy: 0.6348\n","Epoch 10, Train Loss: 0.6477, Val Loss: 0.6610, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 11, Train Loss: 0.6420, Val Loss: 0.6646, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6343, Val Loss: 0.6850, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6448, Val Loss: 0.6499, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6330, Val Loss: 0.6766, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6498, Val Loss: 0.6501, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6295, Val Loss: 0.6583, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 17, Train Loss: 0.6386, Val Loss: 0.6503, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 18, Train Loss: 0.6323, Val Loss: 0.6577, F1 Micro: 0.7416, F1 Macro: 0.6762, Accuracy: 0.7416\n","Epoch 19, Train Loss: 0.6291, Val Loss: 0.6503, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 20, Train Loss: 0.6291, Val Loss: 0.6520, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 21, Train Loss: 0.6248, Val Loss: 0.6533, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 22, Train Loss: 0.6210, Val Loss: 0.6731, F1 Micro: 0.7303, F1 Macro: 0.6577, Accuracy: 0.7303\n","Epoch 23, Train Loss: 0.6331, Val Loss: 0.6526, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6229, Val Loss: 0.6481, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 25, Train Loss: 0.6284, Val Loss: 0.6512, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.6185, Val Loss: 0.6510, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 27, Train Loss: 0.6200, Val Loss: 0.6514, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 28, Train Loss: 0.6208, Val Loss: 0.6461, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.7149080409264955\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6914, Val Loss: 0.6634, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Epoch 2, Train Loss: 0.6792, Val Loss: 0.6682, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 3, Train Loss: 0.6757, Val Loss: 0.6713, F1 Micro: 0.6536, F1 Macro: 0.4918, Accuracy: 0.6536\n","Epoch 4, Train Loss: 0.6792, Val Loss: 0.6596, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6688, Val Loss: 0.6603, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6677, Val Loss: 0.6645, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.6680, Val Loss: 0.6520, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.6583, Val Loss: 0.6532, F1 Micro: 0.6536, F1 Macro: 0.5845, Accuracy: 0.6536\n","Epoch 9, Train Loss: 0.6589, Val Loss: 0.6417, F1 Micro: 0.6816, F1 Macro: 0.5738, Accuracy: 0.6816\n","Epoch 10, Train Loss: 0.6504, Val Loss: 0.6435, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 11, Train Loss: 0.6369, Val Loss: 0.6328, F1 Micro: 0.6816, F1 Macro: 0.5603, Accuracy: 0.6816\n","Epoch 12, Train Loss: 0.6435, Val Loss: 0.6465, F1 Micro: 0.6536, F1 Macro: 0.5845, Accuracy: 0.6536\n","Epoch 13, Train Loss: 0.6365, Val Loss: 0.6324, F1 Micro: 0.6760, F1 Macro: 0.5489, Accuracy: 0.6760\n","Epoch 14, Train Loss: 0.6431, Val Loss: 0.6267, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 15, Train Loss: 0.6367, Val Loss: 0.6258, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 16, Train Loss: 0.6360, Val Loss: 0.6335, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.6350, Val Loss: 0.6211, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 18, Train Loss: 0.6244, Val Loss: 0.6247, F1 Micro: 0.6480, F1 Macro: 0.5755, Accuracy: 0.6480\n","Epoch 19, Train Loss: 0.6336, Val Loss: 0.6239, F1 Micro: 0.6704, F1 Macro: 0.6317, Accuracy: 0.6704\n","Epoch 20, Train Loss: 0.6291, Val Loss: 0.6173, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6289, Val Loss: 0.6177, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 22, Train Loss: 0.6287, Val Loss: 0.6173, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 23, Train Loss: 0.6324, Val Loss: 0.6169, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 24, Train Loss: 0.6259, Val Loss: 0.6232, F1 Micro: 0.6536, F1 Macro: 0.5845, Accuracy: 0.6536\n","Epoch 25, Train Loss: 0.6239, Val Loss: 0.6140, F1 Micro: 0.7151, F1 Macro: 0.6703, Accuracy: 0.7151\n","Epoch 26, Train Loss: 0.6347, Val Loss: 0.6140, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 27, Train Loss: 0.6351, Val Loss: 0.6177, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 28, Train Loss: 0.6315, Val Loss: 0.6242, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 29, Train Loss: 0.6283, Val Loss: 0.6151, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 30, Train Loss: 0.6264, Val Loss: 0.6207, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 31, Train Loss: 0.6276, Val Loss: 0.6170, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 32, Train Loss: 0.6321, Val Loss: 0.6144, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 33, Train Loss: 0.6201, Val Loss: 0.6163, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 34, Train Loss: 0.6224, Val Loss: 0.6123, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 35, Train Loss: 0.6235, Val Loss: 0.6170, F1 Micro: 0.6480, F1 Macro: 0.5755, Accuracy: 0.6480\n","Epoch 36, Train Loss: 0.6235, Val Loss: 0.6192, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 37, Train Loss: 0.6284, Val Loss: 0.6225, F1 Micro: 0.6760, F1 Macro: 0.5758, Accuracy: 0.6760\n","Epoch 38, Train Loss: 0.6240, Val Loss: 0.6114, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 39, Train Loss: 0.6270, Val Loss: 0.6104, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 40, Train Loss: 0.6211, Val Loss: 0.6127, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 41, Train Loss: 0.6294, Val Loss: 0.6124, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 42, Train Loss: 0.6216, Val Loss: 0.6060, F1 Micro: 0.7263, F1 Macro: 0.6768, Accuracy: 0.7263\n","Epoch 43, Train Loss: 0.6246, Val Loss: 0.6080, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 44, Train Loss: 0.6252, Val Loss: 0.6110, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 45, Train Loss: 0.6147, Val Loss: 0.6091, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 46, Train Loss: 0.6334, Val Loss: 0.6051, F1 Micro: 0.7263, F1 Macro: 0.6801, Accuracy: 0.7263\n","Epoch 47, Train Loss: 0.6188, Val Loss: 0.6185, F1 Micro: 0.6872, F1 Macro: 0.6618, Accuracy: 0.6872\n","Epoch 48, Train Loss: 0.6240, Val Loss: 0.6099, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 49, Train Loss: 0.6250, Val Loss: 0.6068, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 50, Train Loss: 0.6209, Val Loss: 0.6046, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 51, Train Loss: 0.6178, Val Loss: 0.6042, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 52, Train Loss: 0.6178, Val Loss: 0.6063, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 53, Train Loss: 0.6212, Val Loss: 0.6053, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 54, Train Loss: 0.6172, Val Loss: 0.6070, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 55, Train Loss: 0.6218, Val Loss: 0.6042, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 56, Train Loss: 0.6198, Val Loss: 0.6151, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 57, Train Loss: 0.6235, Val Loss: 0.6321, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 58, Train Loss: 0.6252, Val Loss: 0.6168, F1 Micro: 0.6872, F1 Macro: 0.6618, Accuracy: 0.6872\n","Epoch 59, Train Loss: 0.6252, Val Loss: 0.6047, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 60, Train Loss: 0.6189, Val Loss: 0.6079, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 61, Train Loss: 0.6159, Val Loss: 0.6045, F1 Micro: 0.7039, F1 Macro: 0.6605, Accuracy: 0.7039\n","Epoch 62, Train Loss: 0.6157, Val Loss: 0.6110, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 63, Train Loss: 0.6136, Val Loss: 0.6133, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 64, Train Loss: 0.6183, Val Loss: 0.6053, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 65, Train Loss: 0.6319, Val Loss: 0.6025, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 66, Train Loss: 0.6131, Val Loss: 0.6062, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 67, Train Loss: 0.6232, Val Loss: 0.6058, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 68, Train Loss: 0.6178, Val Loss: 0.6034, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 69, Train Loss: 0.6220, Val Loss: 0.6055, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 70, Train Loss: 0.6221, Val Loss: 0.6005, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 71, Train Loss: 0.6132, Val Loss: 0.6011, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 72, Train Loss: 0.6173, Val Loss: 0.5991, F1 Micro: 0.7039, F1 Macro: 0.6605, Accuracy: 0.7039\n","Epoch 73, Train Loss: 0.6176, Val Loss: 0.6092, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 74, Train Loss: 0.6168, Val Loss: 0.5968, F1 Micro: 0.7318, F1 Macro: 0.6850, Accuracy: 0.7318\n","Epoch 75, Train Loss: 0.6283, Val Loss: 0.6177, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 76, Train Loss: 0.6279, Val Loss: 0.6201, F1 Micro: 0.6648, F1 Macro: 0.6443, Accuracy: 0.6648\n","Epoch 77, Train Loss: 0.6180, Val Loss: 0.5979, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 78, Train Loss: 0.6229, Val Loss: 0.6077, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 79, Train Loss: 0.6170, Val Loss: 0.5976, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 80, Train Loss: 0.6183, Val Loss: 0.6274, F1 Micro: 0.6927, F1 Macro: 0.6782, Accuracy: 0.6927\n","Epoch 81, Train Loss: 0.6200, Val Loss: 0.5964, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 82, Train Loss: 0.6177, Val Loss: 0.5990, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 83, Train Loss: 0.6171, Val Loss: 0.5966, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 84, Train Loss: 0.6235, Val Loss: 0.5964, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 85, Train Loss: 0.6175, Val Loss: 0.5954, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 86, Train Loss: 0.6181, Val Loss: 0.5992, F1 Micro: 0.7151, F1 Macro: 0.6703, Accuracy: 0.7151\n","Epoch 87, Train Loss: 0.6219, Val Loss: 0.5964, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 88, Train Loss: 0.6164, Val Loss: 0.6074, F1 Micro: 0.6760, F1 Macro: 0.6474, Accuracy: 0.6760\n","Epoch 89, Train Loss: 0.6182, Val Loss: 0.6087, F1 Micro: 0.6704, F1 Macro: 0.6425, Accuracy: 0.6704\n","Epoch 90, Train Loss: 0.6130, Val Loss: 0.6112, F1 Micro: 0.6927, F1 Macro: 0.6644, Accuracy: 0.6927\n","Epoch 91, Train Loss: 0.6106, Val Loss: 0.6053, F1 Micro: 0.7039, F1 Macro: 0.6692, Accuracy: 0.7039\n","Epoch 92, Train Loss: 0.6165, Val Loss: 0.5997, F1 Micro: 0.7095, F1 Macro: 0.6767, Accuracy: 0.7095\n","Epoch 93, Train Loss: 0.6225, Val Loss: 0.5998, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 94, Train Loss: 0.6125, Val Loss: 0.6178, F1 Micro: 0.6816, F1 Macro: 0.6681, Accuracy: 0.6816\n","Epoch 95, Train Loss: 0.6103, Val Loss: 0.5960, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 96, Train Loss: 0.6166, Val Loss: 0.5972, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 97, Train Loss: 0.6208, Val Loss: 0.6122, F1 Micro: 0.6760, F1 Macro: 0.6541, Accuracy: 0.6760\n","Epoch 98, Train Loss: 0.6155, Val Loss: 0.5980, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 99, Train Loss: 0.6115, Val Loss: 0.6015, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 100, Train Loss: 0.6197, Val Loss: 0.5956, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 101, Train Loss: 0.6166, Val Loss: 0.6050, F1 Micro: 0.6760, F1 Macro: 0.6474, Accuracy: 0.6760\n","Epoch 102, Train Loss: 0.6139, Val Loss: 0.6055, F1 Micro: 0.7095, F1 Macro: 0.6767, Accuracy: 0.7095\n","Epoch 103, Train Loss: 0.6176, Val Loss: 0.5944, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 104, Train Loss: 0.6192, Val Loss: 0.5988, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 105, Train Loss: 0.6122, Val Loss: 0.6010, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 106, Train Loss: 0.6128, Val Loss: 0.6054, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 107, Train Loss: 0.6151, Val Loss: 0.5963, F1 Micro: 0.7039, F1 Macro: 0.6718, Accuracy: 0.7039\n","Epoch 108, Train Loss: 0.6152, Val Loss: 0.5938, F1 Micro: 0.7263, F1 Macro: 0.6768, Accuracy: 0.7263\n","Epoch 109, Train Loss: 0.6149, Val Loss: 0.5931, F1 Micro: 0.7318, F1 Macro: 0.6911, Accuracy: 0.7318\n","Epoch 110, Train Loss: 0.6115, Val Loss: 0.5968, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 111, Train Loss: 0.6153, Val Loss: 0.5992, F1 Micro: 0.7039, F1 Macro: 0.6692, Accuracy: 0.7039\n","Epoch 112, Train Loss: 0.6170, Val Loss: 0.5925, F1 Micro: 0.7151, F1 Macro: 0.6703, Accuracy: 0.7151\n","Epoch 113, Train Loss: 0.6103, Val Loss: 0.6062, F1 Micro: 0.6872, F1 Macro: 0.6545, Accuracy: 0.6872\n","Epoch 114, Train Loss: 0.6160, Val Loss: 0.5950, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 115, Train Loss: 0.6208, Val Loss: 0.5931, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 116, Train Loss: 0.6102, Val Loss: 0.5950, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 117, Train Loss: 0.6146, Val Loss: 0.5943, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 118, Train Loss: 0.6127, Val Loss: 0.5931, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 119, Train Loss: 0.6131, Val Loss: 0.5980, F1 Micro: 0.6927, F1 Macro: 0.6373, Accuracy: 0.6927\n","Epoch 120, Train Loss: 0.6133, Val Loss: 0.5941, F1 Micro: 0.6983, F1 Macro: 0.6457, Accuracy: 0.6983\n","Epoch 121, Train Loss: 0.6077, Val Loss: 0.6023, F1 Micro: 0.6704, F1 Macro: 0.6449, Accuracy: 0.6704\n","Epoch 122, Train Loss: 0.6085, Val Loss: 0.5974, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 123, Train Loss: 0.6107, Val Loss: 0.5949, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 124, Train Loss: 0.6132, Val Loss: 0.5947, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6858, Val Loss: 0.6555, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6787, Val Loss: 0.6637, F1 Micro: 0.6180, F1 Macro: 0.3819, Accuracy: 0.6180\n","Epoch 3, Train Loss: 0.6866, Val Loss: 0.6568, F1 Micro: 0.6124, F1 Macro: 0.3798, Accuracy: 0.6124\n","Epoch 4, Train Loss: 0.6763, Val Loss: 0.6642, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6781, Val Loss: 0.6581, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6724, Val Loss: 0.6574, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6760, Val Loss: 0.6553, F1 Micro: 0.6067, F1 Macro: 0.3776, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6649, Val Loss: 0.6540, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6662, Val Loss: 0.6362, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 10, Train Loss: 0.6581, Val Loss: 0.6437, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6586, Val Loss: 0.6184, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6585, Val Loss: 0.6055, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.6483, Val Loss: 0.6469, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6485, Val Loss: 0.6327, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6448, Val Loss: 0.6065, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.6375, Val Loss: 0.5945, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 17, Train Loss: 0.6336, Val Loss: 0.6115, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 18, Train Loss: 0.6341, Val Loss: 0.5972, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 19, Train Loss: 0.6336, Val Loss: 0.5897, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 20, Train Loss: 0.6536, Val Loss: 0.5956, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 21, Train Loss: 0.6435, Val Loss: 0.5875, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6332, Val Loss: 0.5927, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6360, Val Loss: 0.5945, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 24, Train Loss: 0.6370, Val Loss: 0.5929, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 25, Train Loss: 0.6253, Val Loss: 0.5937, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 26, Train Loss: 0.6368, Val Loss: 0.6084, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 27, Train Loss: 0.6300, Val Loss: 0.5788, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 28, Train Loss: 0.6258, Val Loss: 0.6002, F1 Micro: 0.7022, F1 Macro: 0.6856, Accuracy: 0.7022\n","Epoch 29, Train Loss: 0.6287, Val Loss: 0.5792, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 30, Train Loss: 0.6331, Val Loss: 0.6088, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 31, Train Loss: 0.6380, Val Loss: 0.5817, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 32, Train Loss: 0.6368, Val Loss: 0.5858, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 33, Train Loss: 0.6242, Val Loss: 0.5807, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 34, Train Loss: 0.6353, Val Loss: 0.5760, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 35, Train Loss: 0.6299, Val Loss: 0.5793, F1 Micro: 0.7022, F1 Macro: 0.6088, Accuracy: 0.7022\n","Epoch 36, Train Loss: 0.6424, Val Loss: 0.5830, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6293, Val Loss: 0.5817, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 38, Train Loss: 0.6255, Val Loss: 0.5866, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 39, Train Loss: 0.6355, Val Loss: 0.5932, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 40, Train Loss: 0.6322, Val Loss: 0.5986, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 41, Train Loss: 0.6261, Val Loss: 0.5782, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 42, Train Loss: 0.6280, Val Loss: 0.5869, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 43, Train Loss: 0.6298, Val Loss: 0.5828, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 44, Train Loss: 0.6218, Val Loss: 0.5850, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 45, Train Loss: 0.6222, Val Loss: 0.5773, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 46, Train Loss: 0.6197, Val Loss: 0.6076, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6464, Val Loss: 0.5845, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 48, Train Loss: 0.6217, Val Loss: 0.5828, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 49, Train Loss: 0.6365, Val Loss: 0.5897, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 50, Train Loss: 0.6295, Val Loss: 0.6006, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 51, Train Loss: 0.6355, Val Loss: 0.6042, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 52, Train Loss: 0.6340, Val Loss: 0.5748, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 53, Train Loss: 0.6246, Val Loss: 0.5780, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 54, Train Loss: 0.6230, Val Loss: 0.5756, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 55, Train Loss: 0.6323, Val Loss: 0.5848, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 56, Train Loss: 0.6360, Val Loss: 0.5870, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 57, Train Loss: 0.6195, Val Loss: 0.5828, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 58, Train Loss: 0.6237, Val Loss: 0.5894, F1 Micro: 0.7528, F1 Macro: 0.7297, Accuracy: 0.7528\n","Epoch 59, Train Loss: 0.6300, Val Loss: 0.5762, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 60, Train Loss: 0.6189, Val Loss: 0.5887, F1 Micro: 0.7416, F1 Macro: 0.7194, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.6295, Val Loss: 0.5744, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 62, Train Loss: 0.6204, Val Loss: 0.5923, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 63, Train Loss: 0.6227, Val Loss: 0.5721, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 64, Train Loss: 0.6182, Val Loss: 0.5723, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 65, Train Loss: 0.6242, Val Loss: 0.5726, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 66, Train Loss: 0.6193, Val Loss: 0.5710, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 67, Train Loss: 0.6181, Val Loss: 0.5823, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 68, Train Loss: 0.6179, Val Loss: 0.5805, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 69, Train Loss: 0.6201, Val Loss: 0.5761, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 70, Train Loss: 0.6195, Val Loss: 0.5834, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 71, Train Loss: 0.6181, Val Loss: 0.5794, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 72, Train Loss: 0.6244, Val Loss: 0.5711, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 73, Train Loss: 0.6282, Val Loss: 0.5808, F1 Micro: 0.7528, F1 Macro: 0.7297, Accuracy: 0.7528\n","Epoch 74, Train Loss: 0.6196, Val Loss: 0.5688, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 75, Train Loss: 0.6277, Val Loss: 0.5872, F1 Micro: 0.7022, F1 Macro: 0.6088, Accuracy: 0.7022\n","Epoch 76, Train Loss: 0.6264, Val Loss: 0.5769, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 77, Train Loss: 0.6258, Val Loss: 0.5702, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 78, Train Loss: 0.6221, Val Loss: 0.6062, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 79, Train Loss: 0.6210, Val Loss: 0.5808, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 80, Train Loss: 0.6176, Val Loss: 0.5836, F1 Micro: 0.7528, F1 Macro: 0.7076, Accuracy: 0.7528\n","Epoch 81, Train Loss: 0.6287, Val Loss: 0.5656, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 82, Train Loss: 0.6263, Val Loss: 0.5818, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 83, Train Loss: 0.6283, Val Loss: 0.5677, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 84, Train Loss: 0.6239, Val Loss: 0.5658, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 85, Train Loss: 0.6182, Val Loss: 0.5698, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 86, Train Loss: 0.6213, Val Loss: 0.5685, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 87, Train Loss: 0.6242, Val Loss: 0.5701, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 88, Train Loss: 0.6177, Val Loss: 0.5767, F1 Micro: 0.7303, F1 Macro: 0.6663, Accuracy: 0.7303\n","Epoch 89, Train Loss: 0.6286, Val Loss: 0.5691, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 90, Train Loss: 0.6255, Val Loss: 0.5674, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 91, Train Loss: 0.6188, Val Loss: 0.5727, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 92, Train Loss: 0.6167, Val Loss: 0.5687, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 93, Train Loss: 0.6148, Val Loss: 0.5715, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 94, Train Loss: 0.6211, Val Loss: 0.5668, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 95, Train Loss: 0.6096, Val Loss: 0.5720, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 96, Train Loss: 0.6163, Val Loss: 0.5896, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 97, Train Loss: 0.6202, Val Loss: 0.5713, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 98, Train Loss: 0.6270, Val Loss: 0.5828, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 99, Train Loss: 0.6205, Val Loss: 0.5716, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 100, Train Loss: 0.6185, Val Loss: 0.5681, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 101, Train Loss: 0.6173, Val Loss: 0.5664, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 102, Train Loss: 0.6264, Val Loss: 0.5727, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 103, Train Loss: 0.6395, Val Loss: 0.5714, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 104, Train Loss: 0.6215, Val Loss: 0.5721, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 105, Train Loss: 0.6221, Val Loss: 0.5727, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 106, Train Loss: 0.6193, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 107, Train Loss: 0.6282, Val Loss: 0.5769, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 108, Train Loss: 0.6219, Val Loss: 0.5698, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6945, Val Loss: 0.6937, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.6837, Val Loss: 0.6756, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6753, Val Loss: 0.6727, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 4, Train Loss: 0.6812, Val Loss: 0.6657, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6719, Val Loss: 0.6661, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6761, Val Loss: 0.6656, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6744, Val Loss: 0.6635, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6729, Val Loss: 0.6629, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6692, Val Loss: 0.6634, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6700, Val Loss: 0.6606, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6669, Val Loss: 0.6595, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6643, Val Loss: 0.6626, F1 Micro: 0.6517, F1 Macro: 0.4603, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6663, Val Loss: 0.6499, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6642, Val Loss: 0.6401, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 15, Train Loss: 0.6530, Val Loss: 0.6342, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.6543, Val Loss: 0.6166, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 17, Train Loss: 0.6438, Val Loss: 0.6255, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 18, Train Loss: 0.6444, Val Loss: 0.6070, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.6478, Val Loss: 0.5990, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.6345, Val Loss: 0.5934, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 21, Train Loss: 0.6446, Val Loss: 0.5923, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6412, Val Loss: 0.5882, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 23, Train Loss: 0.6404, Val Loss: 0.5931, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6341, Val Loss: 0.5987, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6409, Val Loss: 0.6034, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.6334, Val Loss: 0.5972, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 27, Train Loss: 0.6399, Val Loss: 0.5861, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 28, Train Loss: 0.6356, Val Loss: 0.5944, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 29, Train Loss: 0.6430, Val Loss: 0.5810, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 30, Train Loss: 0.6413, Val Loss: 0.5860, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 31, Train Loss: 0.6256, Val Loss: 0.5848, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 32, Train Loss: 0.6387, Val Loss: 0.5813, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 33, Train Loss: 0.6344, Val Loss: 0.5821, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 34, Train Loss: 0.6609, Val Loss: 0.5831, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 35, Train Loss: 0.6298, Val Loss: 0.5789, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 36, Train Loss: 0.6399, Val Loss: 0.5870, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 37, Train Loss: 0.6280, Val Loss: 0.5886, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 38, Train Loss: 0.6445, Val Loss: 0.5870, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 39, Train Loss: 0.6329, Val Loss: 0.5725, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 40, Train Loss: 0.6442, Val Loss: 0.5924, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 41, Train Loss: 0.6404, Val Loss: 0.5782, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 42, Train Loss: 0.6384, Val Loss: 0.5811, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 43, Train Loss: 0.6273, Val Loss: 0.6105, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.6301, Val Loss: 0.5759, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 45, Train Loss: 0.6289, Val Loss: 0.5794, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 46, Train Loss: 0.6408, Val Loss: 0.5766, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 47, Train Loss: 0.6267, Val Loss: 0.5986, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.6412, Val Loss: 0.5683, F1 Micro: 0.7135, F1 Macro: 0.6475, Accuracy: 0.7135\n","Epoch 49, Train Loss: 0.6286, Val Loss: 0.5802, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 50, Train Loss: 0.6345, Val Loss: 0.5682, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 51, Train Loss: 0.6297, Val Loss: 0.5775, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.6349, Val Loss: 0.5703, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 53, Train Loss: 0.6272, Val Loss: 0.5804, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 54, Train Loss: 0.6314, Val Loss: 0.5657, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 55, Train Loss: 0.6318, Val Loss: 0.5709, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 56, Train Loss: 0.6234, Val Loss: 0.5685, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 57, Train Loss: 0.6286, Val Loss: 0.5679, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 58, Train Loss: 0.6231, Val Loss: 0.5652, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 59, Train Loss: 0.6272, Val Loss: 0.5625, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 60, Train Loss: 0.6284, Val Loss: 0.5641, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 61, Train Loss: 0.6252, Val Loss: 0.5563, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 62, Train Loss: 0.6297, Val Loss: 0.5729, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 63, Train Loss: 0.6315, Val Loss: 0.5853, F1 Micro: 0.7528, F1 Macro: 0.7316, Accuracy: 0.7528\n","Epoch 64, Train Loss: 0.6388, Val Loss: 0.5670, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 65, Train Loss: 0.6213, Val Loss: 0.5703, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 66, Train Loss: 0.6255, Val Loss: 0.5620, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 67, Train Loss: 0.6339, Val Loss: 0.5624, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 68, Train Loss: 0.6248, Val Loss: 0.5637, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 69, Train Loss: 0.6200, Val Loss: 0.5828, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 70, Train Loss: 0.6453, Val Loss: 0.5592, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 71, Train Loss: 0.6380, Val Loss: 0.5599, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 72, Train Loss: 0.6242, Val Loss: 0.5661, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 73, Train Loss: 0.6200, Val Loss: 0.5615, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 74, Train Loss: 0.6381, Val Loss: 0.5678, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 75, Train Loss: 0.6334, Val Loss: 0.5671, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 76, Train Loss: 0.6220, Val Loss: 0.5710, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 77, Train Loss: 0.6264, Val Loss: 0.5801, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 78, Train Loss: 0.6220, Val Loss: 0.5632, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 79, Train Loss: 0.6165, Val Loss: 0.5583, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 80, Train Loss: 0.6219, Val Loss: 0.5695, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 81, Train Loss: 0.6227, Val Loss: 0.5744, F1 Micro: 0.7416, F1 Macro: 0.7248, Accuracy: 0.7416\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6688, Val Loss: 0.7668, F1 Micro: 0.5449, F1 Macro: 0.4402, Accuracy: 0.5449\n","Epoch 2, Train Loss: 0.6733, Val Loss: 0.7231, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 3, Train Loss: 0.6634, Val Loss: 0.7107, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6591, Val Loss: 0.7110, F1 Micro: 0.5393, F1 Macro: 0.4227, Accuracy: 0.5393\n","Epoch 5, Train Loss: 0.6537, Val Loss: 0.7203, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.6547, Val Loss: 0.7226, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6552, Val Loss: 0.7107, F1 Micro: 0.5787, F1 Macro: 0.4935, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.6531, Val Loss: 0.7458, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 9, Train Loss: 0.6383, Val Loss: 0.7500, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 10, Train Loss: 0.6335, Val Loss: 0.7466, F1 Micro: 0.5449, F1 Macro: 0.4261, Accuracy: 0.5449\n","Epoch 11, Train Loss: 0.6381, Val Loss: 0.7351, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6233, Val Loss: 0.7579, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 13, Train Loss: 0.6131, Val Loss: 0.7371, F1 Micro: 0.5899, F1 Macro: 0.5430, Accuracy: 0.5899\n","Epoch 14, Train Loss: 0.6095, Val Loss: 0.7069, F1 Micro: 0.5899, F1 Macro: 0.5852, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.6326, Val Loss: 0.7315, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 16, Train Loss: 0.6273, Val Loss: 0.7464, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6110, Val Loss: 0.7323, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6182, Val Loss: 0.7516, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 19, Train Loss: 0.6109, Val Loss: 0.7193, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 20, Train Loss: 0.6112, Val Loss: 0.7645, F1 Micro: 0.5843, F1 Macro: 0.5269, Accuracy: 0.5843\n","Epoch 21, Train Loss: 0.6161, Val Loss: 0.7219, F1 Micro: 0.5674, F1 Macro: 0.5406, Accuracy: 0.5674\n","Epoch 22, Train Loss: 0.6067, Val Loss: 0.7271, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.5974, Val Loss: 0.7477, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 24, Train Loss: 0.6026, Val Loss: 0.7647, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 25, Train Loss: 0.5957, Val Loss: 0.7595, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 26, Train Loss: 0.6096, Val Loss: 0.7347, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6084, Val Loss: 0.7282, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6073, Val Loss: 0.7344, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.5917, Val Loss: 0.7342, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6069, Val Loss: 0.7358, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 31, Train Loss: 0.5969, Val Loss: 0.7173, F1 Micro: 0.6236, F1 Macro: 0.6147, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.5937, Val Loss: 0.7494, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.5988, Val Loss: 0.7439, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 34, Train Loss: 0.5961, Val Loss: 0.7244, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 35, Train Loss: 0.5910, Val Loss: 0.7421, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 36, Train Loss: 0.5966, Val Loss: 0.7393, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 37, Train Loss: 0.5901, Val Loss: 0.7210, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.5974, Val Loss: 0.7257, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.5935, Val Loss: 0.7236, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 40, Train Loss: 0.5952, Val Loss: 0.7484, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 41, Train Loss: 0.5923, Val Loss: 0.7427, F1 Micro: 0.5730, F1 Macro: 0.5396, Accuracy: 0.5730\n","Epoch 42, Train Loss: 0.5997, Val Loss: 0.7336, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 43, Train Loss: 0.6092, Val Loss: 0.7339, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 44, Train Loss: 0.5926, Val Loss: 0.7168, F1 Micro: 0.6067, F1 Macro: 0.5995, Accuracy: 0.6067\n","Epoch 45, Train Loss: 0.5899, Val Loss: 0.7330, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.5978, Val Loss: 0.7308, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 47, Train Loss: 0.5993, Val Loss: 0.7290, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 48, Train Loss: 0.5995, Val Loss: 0.7141, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 49, Train Loss: 0.5951, Val Loss: 0.7442, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6140, Val Loss: 0.7339, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 51, Train Loss: 0.5961, Val Loss: 0.7270, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 52, Train Loss: 0.5883, Val Loss: 0.7749, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 53, Train Loss: 0.6003, Val Loss: 0.7638, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 54, Train Loss: 0.5992, Val Loss: 0.7232, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 55, Train Loss: 0.5943, Val Loss: 0.7312, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 56, Train Loss: 0.5858, Val Loss: 0.7366, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 57, Train Loss: 0.5805, Val Loss: 0.7458, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 58, Train Loss: 0.5995, Val Loss: 0.7303, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 59, Train Loss: 0.5873, Val Loss: 0.7538, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 60, Train Loss: 0.5967, Val Loss: 0.7393, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 61, Train Loss: 0.5864, Val Loss: 0.7604, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 62, Train Loss: 0.5908, Val Loss: 0.7329, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 63, Train Loss: 0.5921, Val Loss: 0.7220, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 64, Train Loss: 0.5931, Val Loss: 0.7496, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 65, Train Loss: 0.5880, Val Loss: 0.7191, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 66, Train Loss: 0.5843, Val Loss: 0.7569, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 67, Train Loss: 0.5995, Val Loss: 0.7261, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 68, Train Loss: 0.5908, Val Loss: 0.7328, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 69, Train Loss: 0.5906, Val Loss: 0.7290, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 70, Train Loss: 0.5904, Val Loss: 0.7355, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 71, Train Loss: 0.5844, Val Loss: 0.7613, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 72, Train Loss: 0.5919, Val Loss: 0.7267, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 73, Train Loss: 0.5864, Val Loss: 0.7229, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 74, Train Loss: 0.5893, Val Loss: 0.7522, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 75, Train Loss: 0.5854, Val Loss: 0.7254, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 76, Train Loss: 0.5895, Val Loss: 0.7343, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 77, Train Loss: 0.5942, Val Loss: 0.7441, F1 Micro: 0.6011, F1 Macro: 0.5655, Accuracy: 0.6011\n","Epoch 78, Train Loss: 0.5817, Val Loss: 0.7235, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 79, Train Loss: 0.5876, Val Loss: 0.7301, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6776, Val Loss: 0.7016, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 2, Train Loss: 0.6764, Val Loss: 0.6999, F1 Micro: 0.3989, F1 Macro: 0.2926, Accuracy: 0.3989\n","Epoch 3, Train Loss: 0.6746, Val Loss: 0.6761, F1 Micro: 0.6404, F1 Macro: 0.5014, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6706, Val Loss: 0.6889, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6679, Val Loss: 0.6780, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6707, Val Loss: 0.6761, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6712, Val Loss: 0.6708, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6553, Val Loss: 0.6667, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6518, Val Loss: 0.6782, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 10, Train Loss: 0.6514, Val Loss: 0.6548, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6450, Val Loss: 0.6508, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.6362, Val Loss: 0.6585, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6315, Val Loss: 0.6628, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6362, Val Loss: 0.6552, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 15, Train Loss: 0.6343, Val Loss: 0.6629, F1 Micro: 0.7247, F1 Macro: 0.6572, Accuracy: 0.7247\n","Epoch 16, Train Loss: 0.6308, Val Loss: 0.6485, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.6283, Val Loss: 0.6556, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 18, Train Loss: 0.6250, Val Loss: 0.6486, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 19, Train Loss: 0.6359, Val Loss: 0.6477, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 20, Train Loss: 0.6273, Val Loss: 0.6531, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 21, Train Loss: 0.6280, Val Loss: 0.6542, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 22, Train Loss: 0.6258, Val Loss: 0.6526, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 23, Train Loss: 0.6214, Val Loss: 0.6582, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6241, Val Loss: 0.6668, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6195, Val Loss: 0.6593, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 26, Train Loss: 0.6311, Val Loss: 0.6550, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 27, Train Loss: 0.6207, Val Loss: 0.6482, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 28, Train Loss: 0.6247, Val Loss: 0.6642, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.6203, Val Loss: 0.6517, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 30, Train Loss: 0.6194, Val Loss: 0.6492, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 31, Train Loss: 0.6231, Val Loss: 0.6510, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 32, Train Loss: 0.6183, Val Loss: 0.6521, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 33, Train Loss: 0.6140, Val Loss: 0.6750, F1 Micro: 0.7022, F1 Macro: 0.6195, Accuracy: 0.7022\n","Epoch 34, Train Loss: 0.6237, Val Loss: 0.6614, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 35, Train Loss: 0.6133, Val Loss: 0.6479, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 36, Train Loss: 0.6262, Val Loss: 0.6523, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 37, Train Loss: 0.6215, Val Loss: 0.6542, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 38, Train Loss: 0.6103, Val Loss: 0.6499, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6049, Val Loss: 0.6613, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 40, Train Loss: 0.6216, Val Loss: 0.6554, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 41, Train Loss: 0.6143, Val Loss: 0.6672, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 42, Train Loss: 0.6338, Val Loss: 0.6642, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 43, Train Loss: 0.6200, Val Loss: 0.6576, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 44, Train Loss: 0.6137, Val Loss: 0.6481, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 45, Train Loss: 0.6198, Val Loss: 0.6618, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 46, Train Loss: 0.6143, Val Loss: 0.6515, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 47, Train Loss: 0.6088, Val Loss: 0.6578, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.6157, Val Loss: 0.6560, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 49, Train Loss: 0.6226, Val Loss: 0.6584, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 50, Train Loss: 0.6191, Val Loss: 0.6514, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 51, Train Loss: 0.6167, Val Loss: 0.6541, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 52, Train Loss: 0.6182, Val Loss: 0.6500, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 53, Train Loss: 0.6169, Val Loss: 0.6501, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 54, Train Loss: 0.6158, Val Loss: 0.6513, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 55, Train Loss: 0.6218, Val Loss: 0.6505, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 56, Train Loss: 0.6162, Val Loss: 0.6490, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.6258, Val Loss: 0.6550, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6145, Val Loss: 0.6512, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 59, Train Loss: 0.6036, Val Loss: 0.6762, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 60, Train Loss: 0.6099, Val Loss: 0.6487, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 61, Train Loss: 0.6130, Val Loss: 0.6636, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6175, Val Loss: 0.6563, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 63, Train Loss: 0.6150, Val Loss: 0.6521, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 64, Train Loss: 0.5983, Val Loss: 0.6519, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 65, Train Loss: 0.6070, Val Loss: 0.6649, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 66, Train Loss: 0.6111, Val Loss: 0.6554, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 67, Train Loss: 0.6125, Val Loss: 0.6725, F1 Micro: 0.7135, F1 Macro: 0.6288, Accuracy: 0.7135\n","Epoch 68, Train Loss: 0.6061, Val Loss: 0.6463, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 69, Train Loss: 0.6153, Val Loss: 0.6635, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 70, Train Loss: 0.6260, Val Loss: 0.6548, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7295147824995293\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7015, Val Loss: 0.6775, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6771, Val Loss: 0.6768, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 3, Train Loss: 0.6769, Val Loss: 0.6742, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Epoch 4, Train Loss: 0.6784, Val Loss: 0.6811, F1 Micro: 0.6425, F1 Macro: 0.4317, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6761, Val Loss: 0.6718, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6792, Val Loss: 0.6770, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.6734, Val Loss: 0.6761, F1 Micro: 0.6313, F1 Macro: 0.4009, Accuracy: 0.6313\n","Epoch 8, Train Loss: 0.6739, Val Loss: 0.6713, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 9, Train Loss: 0.6759, Val Loss: 0.6686, F1 Micro: 0.6592, F1 Macro: 0.4856, Accuracy: 0.6592\n","Epoch 10, Train Loss: 0.6711, Val Loss: 0.6708, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6681, Val Loss: 0.6697, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 12, Train Loss: 0.6674, Val Loss: 0.6671, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 13, Train Loss: 0.6642, Val Loss: 0.6632, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6863, Val Loss: 0.6634, F1 Micro: 0.6461, F1 Macro: 0.6024, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.7005, Val Loss: 0.6736, F1 Micro: 0.6180, F1 Macro: 0.3819, Accuracy: 0.6180\n","Epoch 3, Train Loss: 0.6723, Val Loss: 0.6653, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6748, Val Loss: 0.6571, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6804, Val Loss: 0.6866, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6734, Val Loss: 0.6571, F1 Micro: 0.6236, F1 Macro: 0.4550, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6725, Val Loss: 0.6643, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6699, Val Loss: 0.6650, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6707, Val Loss: 0.6625, F1 Micro: 0.6067, F1 Macro: 0.3776, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6704, Val Loss: 0.6679, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 11, Train Loss: 0.6738, Val Loss: 0.6706, F1 Micro: 0.6124, F1 Macro: 0.3798, Accuracy: 0.6124\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6929, Val Loss: 0.6852, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 2, Train Loss: 0.6754, Val Loss: 0.6767, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6704, Val Loss: 0.6906, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 4, Train Loss: 0.6819, Val Loss: 0.6780, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6698, Val Loss: 0.6812, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6770, Val Loss: 0.6873, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 7, Train Loss: 0.6742, Val Loss: 0.6779, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6753, Val Loss: 0.6786, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6725, Val Loss: 0.6859, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6713, Val Loss: 0.6709, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6691, Val Loss: 0.6756, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6681, Val Loss: 0.6709, F1 Micro: 0.6461, F1 Macro: 0.4572, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6669, Val Loss: 0.6779, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6675, Val Loss: 0.7124, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 2, Train Loss: 0.6589, Val Loss: 0.7265, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6634, Val Loss: 0.7842, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6673, Val Loss: 0.7255, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6584, Val Loss: 0.7423, F1 Micro: 0.5506, F1 Macro: 0.4504, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.6622, Val Loss: 0.7507, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6592, Val Loss: 0.7473, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 8, Train Loss: 0.6578, Val Loss: 0.7335, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 9, Train Loss: 0.6560, Val Loss: 0.7696, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6619, Val Loss: 0.7294, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 11, Train Loss: 0.6524, Val Loss: 0.7260, F1 Micro: 0.5449, F1 Macro: 0.4402, Accuracy: 0.5449\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6827, Val Loss: 0.6894, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6764, Val Loss: 0.6875, F1 Micro: 0.5899, F1 Macro: 0.4062, Accuracy: 0.5899\n","Epoch 3, Train Loss: 0.6720, Val Loss: 0.6893, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.6815, Val Loss: 0.7099, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6727, Val Loss: 0.6996, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6751, Val Loss: 0.6896, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6709, Val Loss: 0.6870, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6730, Val Loss: 0.6908, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6662, Val Loss: 0.6886, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6641, Val Loss: 0.6890, F1 Micro: 0.6124, F1 Macro: 0.4387, Accuracy: 0.6124\n","Epoch 11, Train Loss: 0.6670, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6615, Val Loss: 0.6839, F1 Micro: 0.6124, F1 Macro: 0.4387, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6592, Val Loss: 0.6956, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6591, Val Loss: 0.6778, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 15, Train Loss: 0.6486, Val Loss: 0.6867, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6434, Val Loss: 0.6810, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 17, Train Loss: 0.6391, Val Loss: 0.7091, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6305, Val Loss: 0.6765, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.6320, Val Loss: 0.6775, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 20, Train Loss: 0.6219, Val Loss: 0.6848, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 21, Train Loss: 0.6339, Val Loss: 0.6876, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 22, Train Loss: 0.6269, Val Loss: 0.7084, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.6414, Val Loss: 0.6859, F1 Micro: 0.7360, F1 Macro: 0.6712, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6341, Val Loss: 0.6920, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6191, Val Loss: 0.6785, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 26, Train Loss: 0.6281, Val Loss: 0.6888, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 27, Train Loss: 0.6327, Val Loss: 0.6898, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 28, Train Loss: 0.6266, Val Loss: 0.6967, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 29, Train Loss: 0.6305, Val Loss: 0.6898, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 30, Train Loss: 0.6298, Val Loss: 0.6975, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 31, Train Loss: 0.6251, Val Loss: 0.6844, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 32, Train Loss: 0.6230, Val Loss: 0.6911, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 33, Train Loss: 0.6241, Val Loss: 0.6816, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 34, Train Loss: 0.6208, Val Loss: 0.6855, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 35, Train Loss: 0.6192, Val Loss: 0.7088, F1 Micro: 0.7022, F1 Macro: 0.6195, Accuracy: 0.7022\n","Epoch 36, Train Loss: 0.6251, Val Loss: 0.6964, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 37, Train Loss: 0.6283, Val Loss: 0.7016, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.6722679053417865\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6989, Val Loss: 0.6902, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 2, Train Loss: 0.6778, Val Loss: 0.6791, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 3, Train Loss: 0.6800, Val Loss: 0.6707, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 4, Train Loss: 0.6763, Val Loss: 0.6700, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6737, Val Loss: 0.6708, F1 Micro: 0.6480, F1 Macro: 0.4466, Accuracy: 0.6480\n","Epoch 6, Train Loss: 0.6790, Val Loss: 0.6725, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 7, Train Loss: 0.6721, Val Loss: 0.6708, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.6715, Val Loss: 0.6736, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 9, Train Loss: 0.6713, Val Loss: 0.6691, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 10, Train Loss: 0.6695, Val Loss: 0.6674, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6678, Val Loss: 0.6659, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 12, Train Loss: 0.6630, Val Loss: 0.6609, F1 Micro: 0.6760, F1 Macro: 0.5758, Accuracy: 0.6760\n","Epoch 13, Train Loss: 0.6575, Val Loss: 0.6613, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 14, Train Loss: 0.6536, Val Loss: 0.6502, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 15, Train Loss: 0.6474, Val Loss: 0.6518, F1 Micro: 0.6592, F1 Macro: 0.5133, Accuracy: 0.6592\n","Epoch 16, Train Loss: 0.6492, Val Loss: 0.6502, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 17, Train Loss: 0.6389, Val Loss: 0.6421, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 18, Train Loss: 0.6381, Val Loss: 0.6417, F1 Micro: 0.6816, F1 Macro: 0.5916, Accuracy: 0.6816\n","Epoch 19, Train Loss: 0.6331, Val Loss: 0.6372, F1 Micro: 0.6536, F1 Macro: 0.5799, Accuracy: 0.6536\n","Epoch 20, Train Loss: 0.6373, Val Loss: 0.6400, F1 Micro: 0.6927, F1 Macro: 0.6508, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6305, Val Loss: 0.6399, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 22, Train Loss: 0.6337, Val Loss: 0.6332, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 23, Train Loss: 0.6337, Val Loss: 0.6310, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 24, Train Loss: 0.6269, Val Loss: 0.6359, F1 Micro: 0.6648, F1 Macro: 0.6326, Accuracy: 0.6648\n","Epoch 25, Train Loss: 0.6332, Val Loss: 0.6330, F1 Micro: 0.6648, F1 Macro: 0.6326, Accuracy: 0.6648\n","Epoch 26, Train Loss: 0.6352, Val Loss: 0.6342, F1 Micro: 0.6760, F1 Macro: 0.6394, Accuracy: 0.6760\n","Epoch 27, Train Loss: 0.6371, Val Loss: 0.6421, F1 Micro: 0.6648, F1 Macro: 0.6400, Accuracy: 0.6648\n","Epoch 28, Train Loss: 0.6226, Val Loss: 0.6271, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 29, Train Loss: 0.6293, Val Loss: 0.6401, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 30, Train Loss: 0.6295, Val Loss: 0.6274, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 31, Train Loss: 0.6328, Val Loss: 0.6320, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 32, Train Loss: 0.6194, Val Loss: 0.6350, F1 Micro: 0.6927, F1 Macro: 0.6620, Accuracy: 0.6927\n","Epoch 33, Train Loss: 0.6246, Val Loss: 0.6388, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 34, Train Loss: 0.6360, Val Loss: 0.6375, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 35, Train Loss: 0.6244, Val Loss: 0.6281, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 36, Train Loss: 0.6317, Val Loss: 0.6346, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 37, Train Loss: 0.6292, Val Loss: 0.6254, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 38, Train Loss: 0.6214, Val Loss: 0.6365, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 39, Train Loss: 0.6361, Val Loss: 0.6269, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 40, Train Loss: 0.6246, Val Loss: 0.6220, F1 Micro: 0.7151, F1 Macro: 0.6703, Accuracy: 0.7151\n","Epoch 41, Train Loss: 0.6359, Val Loss: 0.6299, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 42, Train Loss: 0.6205, Val Loss: 0.6253, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 43, Train Loss: 0.6260, Val Loss: 0.6214, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 44, Train Loss: 0.6248, Val Loss: 0.6216, F1 Micro: 0.7207, F1 Macro: 0.6719, Accuracy: 0.7207\n","Epoch 45, Train Loss: 0.6301, Val Loss: 0.6208, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 46, Train Loss: 0.6247, Val Loss: 0.6230, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 47, Train Loss: 0.6249, Val Loss: 0.6209, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 48, Train Loss: 0.6232, Val Loss: 0.6245, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 49, Train Loss: 0.6253, Val Loss: 0.6227, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 50, Train Loss: 0.6216, Val Loss: 0.6233, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 51, Train Loss: 0.6244, Val Loss: 0.6209, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 52, Train Loss: 0.6251, Val Loss: 0.6213, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 53, Train Loss: 0.6192, Val Loss: 0.6212, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 54, Train Loss: 0.6235, Val Loss: 0.6419, F1 Micro: 0.6760, F1 Macro: 0.5758, Accuracy: 0.6760\n","Epoch 55, Train Loss: 0.6295, Val Loss: 0.6226, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 56, Train Loss: 0.6236, Val Loss: 0.6210, F1 Micro: 0.7039, F1 Macro: 0.6468, Accuracy: 0.7039\n","Epoch 57, Train Loss: 0.6289, Val Loss: 0.6310, F1 Micro: 0.6536, F1 Macro: 0.6256, Accuracy: 0.6536\n","Epoch 58, Train Loss: 0.6190, Val Loss: 0.6195, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 59, Train Loss: 0.6200, Val Loss: 0.6194, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 60, Train Loss: 0.6290, Val Loss: 0.6192, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 61, Train Loss: 0.6344, Val Loss: 0.6185, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 62, Train Loss: 0.6218, Val Loss: 0.6300, F1 Micro: 0.6816, F1 Macro: 0.6569, Accuracy: 0.6816\n","Epoch 63, Train Loss: 0.6197, Val Loss: 0.6220, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 64, Train Loss: 0.6174, Val Loss: 0.6198, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 65, Train Loss: 0.6207, Val Loss: 0.6222, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 66, Train Loss: 0.6251, Val Loss: 0.6205, F1 Micro: 0.6704, F1 Macro: 0.6400, Accuracy: 0.6704\n","Epoch 67, Train Loss: 0.6223, Val Loss: 0.6156, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 68, Train Loss: 0.6156, Val Loss: 0.6155, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 69, Train Loss: 0.6256, Val Loss: 0.6336, F1 Micro: 0.6704, F1 Macro: 0.5881, Accuracy: 0.6704\n","Epoch 70, Train Loss: 0.6235, Val Loss: 0.6236, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 71, Train Loss: 0.6236, Val Loss: 0.6175, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 72, Train Loss: 0.6240, Val Loss: 0.6204, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 73, Train Loss: 0.6158, Val Loss: 0.6143, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Epoch 74, Train Loss: 0.6171, Val Loss: 0.6212, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 75, Train Loss: 0.6319, Val Loss: 0.6131, F1 Micro: 0.7318, F1 Macro: 0.6911, Accuracy: 0.7318\n","Epoch 76, Train Loss: 0.6192, Val Loss: 0.6139, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 77, Train Loss: 0.6262, Val Loss: 0.6130, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 78, Train Loss: 0.6238, Val Loss: 0.6164, F1 Micro: 0.6704, F1 Macro: 0.6374, Accuracy: 0.6704\n","Epoch 79, Train Loss: 0.6169, Val Loss: 0.6178, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 80, Train Loss: 0.6207, Val Loss: 0.6133, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 81, Train Loss: 0.6246, Val Loss: 0.6125, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 82, Train Loss: 0.6256, Val Loss: 0.6177, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 83, Train Loss: 0.6187, Val Loss: 0.6150, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 84, Train Loss: 0.6193, Val Loss: 0.6151, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 85, Train Loss: 0.6177, Val Loss: 0.6235, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 86, Train Loss: 0.6237, Val Loss: 0.6111, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 87, Train Loss: 0.6280, Val Loss: 0.6128, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 88, Train Loss: 0.6169, Val Loss: 0.6120, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 89, Train Loss: 0.6200, Val Loss: 0.6130, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 90, Train Loss: 0.6211, Val Loss: 0.6188, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 91, Train Loss: 0.6231, Val Loss: 0.6106, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 92, Train Loss: 0.6263, Val Loss: 0.6120, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 93, Train Loss: 0.6227, Val Loss: 0.6136, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 94, Train Loss: 0.6193, Val Loss: 0.6133, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 95, Train Loss: 0.6180, Val Loss: 0.6116, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 96, Train Loss: 0.6179, Val Loss: 0.6233, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 97, Train Loss: 0.6264, Val Loss: 0.6178, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 98, Train Loss: 0.6246, Val Loss: 0.6149, F1 Micro: 0.6927, F1 Macro: 0.6508, Accuracy: 0.6927\n","Epoch 99, Train Loss: 0.6128, Val Loss: 0.6164, F1 Micro: 0.6760, F1 Macro: 0.6520, Accuracy: 0.6760\n","Epoch 100, Train Loss: 0.6182, Val Loss: 0.6113, F1 Micro: 0.7039, F1 Macro: 0.6718, Accuracy: 0.7039\n","Epoch 101, Train Loss: 0.6124, Val Loss: 0.6111, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 102, Train Loss: 0.6201, Val Loss: 0.6112, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 103, Train Loss: 0.6048, Val Loss: 0.6103, F1 Micro: 0.7095, F1 Macro: 0.6515, Accuracy: 0.7095\n","Epoch 104, Train Loss: 0.6186, Val Loss: 0.6091, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 105, Train Loss: 0.6191, Val Loss: 0.6118, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 106, Train Loss: 0.6159, Val Loss: 0.6066, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 107, Train Loss: 0.6148, Val Loss: 0.6080, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 108, Train Loss: 0.6206, Val Loss: 0.6143, F1 Micro: 0.6704, F1 Macro: 0.6374, Accuracy: 0.6704\n","Epoch 109, Train Loss: 0.6211, Val Loss: 0.6065, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 110, Train Loss: 0.6172, Val Loss: 0.6116, F1 Micro: 0.7039, F1 Macro: 0.6743, Accuracy: 0.7039\n","Epoch 111, Train Loss: 0.6129, Val Loss: 0.6063, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 112, Train Loss: 0.6164, Val Loss: 0.6125, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 113, Train Loss: 0.6139, Val Loss: 0.6142, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 114, Train Loss: 0.6159, Val Loss: 0.6081, F1 Micro: 0.6816, F1 Macro: 0.6522, Accuracy: 0.6816\n","Epoch 115, Train Loss: 0.6062, Val Loss: 0.6095, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 116, Train Loss: 0.6159, Val Loss: 0.6041, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 117, Train Loss: 0.6136, Val Loss: 0.6126, F1 Micro: 0.6704, F1 Macro: 0.6471, Accuracy: 0.6704\n","Epoch 118, Train Loss: 0.6058, Val Loss: 0.6081, F1 Micro: 0.7095, F1 Macro: 0.6515, Accuracy: 0.7095\n","Epoch 119, Train Loss: 0.6193, Val Loss: 0.6106, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 120, Train Loss: 0.6112, Val Loss: 0.6081, F1 Micro: 0.6760, F1 Macro: 0.6113, Accuracy: 0.6760\n","Epoch 121, Train Loss: 0.6061, Val Loss: 0.6051, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 122, Train Loss: 0.6162, Val Loss: 0.6036, F1 Micro: 0.7095, F1 Macro: 0.6713, Accuracy: 0.7095\n","Epoch 123, Train Loss: 0.6052, Val Loss: 0.6052, F1 Micro: 0.7263, F1 Macro: 0.6801, Accuracy: 0.7263\n","Epoch 124, Train Loss: 0.6202, Val Loss: 0.6115, F1 Micro: 0.6704, F1 Macro: 0.6471, Accuracy: 0.6704\n","Epoch 125, Train Loss: 0.6154, Val Loss: 0.6069, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6899, Val Loss: 0.6910, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6741, Val Loss: 0.6734, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6764, Val Loss: 0.6555, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6734, Val Loss: 0.6733, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 5, Train Loss: 0.6766, Val Loss: 0.6755, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6781, Val Loss: 0.6609, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6714, Val Loss: 0.6525, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6704, Val Loss: 0.6984, F1 Micro: 0.6348, F1 Macro: 0.4025, Accuracy: 0.6348\n","Epoch 9, Train Loss: 0.6801, Val Loss: 0.6813, F1 Micro: 0.6180, F1 Macro: 0.3954, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.6724, Val Loss: 0.6505, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6742, Val Loss: 0.6508, F1 Micro: 0.6348, F1 Macro: 0.4400, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6710, Val Loss: 0.6483, F1 Micro: 0.6404, F1 Macro: 0.4541, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6668, Val Loss: 0.6315, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 14, Train Loss: 0.6602, Val Loss: 0.6443, F1 Micro: 0.6348, F1 Macro: 0.4510, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6594, Val Loss: 0.6508, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 16, Train Loss: 0.6561, Val Loss: 0.6184, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6460, Val Loss: 0.6090, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6412, Val Loss: 0.5941, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 19, Train Loss: 0.6513, Val Loss: 0.5949, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.6357, Val Loss: 0.5941, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6349, Val Loss: 0.6225, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 22, Train Loss: 0.6338, Val Loss: 0.5927, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 23, Train Loss: 0.6441, Val Loss: 0.5923, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 24, Train Loss: 0.6362, Val Loss: 0.5807, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 25, Train Loss: 0.6387, Val Loss: 0.6023, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.6313, Val Loss: 0.5887, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 27, Train Loss: 0.6407, Val Loss: 0.6191, F1 Micro: 0.7135, F1 Macro: 0.6475, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.6231, Val Loss: 0.5973, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6270, Val Loss: 0.5911, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 30, Train Loss: 0.6359, Val Loss: 0.5984, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 31, Train Loss: 0.6342, Val Loss: 0.5851, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 32, Train Loss: 0.6309, Val Loss: 0.5776, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 33, Train Loss: 0.6408, Val Loss: 0.5749, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 34, Train Loss: 0.6231, Val Loss: 0.5978, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 35, Train Loss: 0.6291, Val Loss: 0.5964, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 36, Train Loss: 0.6360, Val Loss: 0.5782, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 37, Train Loss: 0.6318, Val Loss: 0.5912, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 38, Train Loss: 0.6298, Val Loss: 0.5934, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 39, Train Loss: 0.6290, Val Loss: 0.6019, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 40, Train Loss: 0.6431, Val Loss: 0.6053, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 41, Train Loss: 0.6319, Val Loss: 0.5778, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 42, Train Loss: 0.6299, Val Loss: 0.6286, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 43, Train Loss: 0.6320, Val Loss: 0.5868, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 44, Train Loss: 0.6310, Val Loss: 0.5694, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 45, Train Loss: 0.6186, Val Loss: 0.5915, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.6343, Val Loss: 0.5990, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 47, Train Loss: 0.6363, Val Loss: 0.5805, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 48, Train Loss: 0.6230, Val Loss: 0.5739, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 49, Train Loss: 0.6322, Val Loss: 0.5813, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 50, Train Loss: 0.6316, Val Loss: 0.5802, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 51, Train Loss: 0.6289, Val Loss: 0.5765, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 52, Train Loss: 0.6309, Val Loss: 0.5904, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 53, Train Loss: 0.6281, Val Loss: 0.5765, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 54, Train Loss: 0.6251, Val Loss: 0.5946, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 55, Train Loss: 0.6394, Val Loss: 0.5801, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 56, Train Loss: 0.6249, Val Loss: 0.5719, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 57, Train Loss: 0.6302, Val Loss: 0.5747, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 58, Train Loss: 0.6240, Val Loss: 0.5759, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 59, Train Loss: 0.6218, Val Loss: 0.5828, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 60, Train Loss: 0.6347, Val Loss: 0.5873, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.6316, Val Loss: 0.5898, F1 Micro: 0.7528, F1 Macro: 0.7106, Accuracy: 0.7528\n","Epoch 62, Train Loss: 0.6297, Val Loss: 0.5742, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 63, Train Loss: 0.6267, Val Loss: 0.5860, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 64, Train Loss: 0.6212, Val Loss: 0.5683, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 65, Train Loss: 0.6292, Val Loss: 0.5929, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 66, Train Loss: 0.6330, Val Loss: 0.5671, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 67, Train Loss: 0.6207, Val Loss: 0.5719, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 68, Train Loss: 0.6305, Val Loss: 0.5703, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 69, Train Loss: 0.6313, Val Loss: 0.5718, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 70, Train Loss: 0.6198, Val Loss: 0.5717, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 71, Train Loss: 0.6222, Val Loss: 0.5639, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 72, Train Loss: 0.6212, Val Loss: 0.5790, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 73, Train Loss: 0.6225, Val Loss: 0.5799, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 74, Train Loss: 0.6261, Val Loss: 0.5730, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 75, Train Loss: 0.6208, Val Loss: 0.5832, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 76, Train Loss: 0.6252, Val Loss: 0.5847, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 77, Train Loss: 0.6191, Val Loss: 0.5664, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 78, Train Loss: 0.6303, Val Loss: 0.5741, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 79, Train Loss: 0.6191, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 80, Train Loss: 0.6129, Val Loss: 0.5714, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 81, Train Loss: 0.6226, Val Loss: 0.5755, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 82, Train Loss: 0.6231, Val Loss: 0.5940, F1 Micro: 0.6798, F1 Macro: 0.6684, Accuracy: 0.6798\n","Epoch 83, Train Loss: 0.6239, Val Loss: 0.5674, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 84, Train Loss: 0.6257, Val Loss: 0.5681, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 85, Train Loss: 0.6241, Val Loss: 0.5773, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 86, Train Loss: 0.6212, Val Loss: 0.5688, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 87, Train Loss: 0.6223, Val Loss: 0.5711, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 88, Train Loss: 0.6187, Val Loss: 0.5772, F1 Micro: 0.7584, F1 Macro: 0.7349, Accuracy: 0.7584\n","Epoch 89, Train Loss: 0.6205, Val Loss: 0.5678, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 90, Train Loss: 0.6159, Val Loss: 0.5714, F1 Micro: 0.7584, F1 Macro: 0.7349, Accuracy: 0.7584\n","Epoch 91, Train Loss: 0.6238, Val Loss: 0.5669, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 92, Train Loss: 0.6226, Val Loss: 0.5654, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 93, Train Loss: 0.6239, Val Loss: 0.5668, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 94, Train Loss: 0.6146, Val Loss: 0.5721, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 95, Train Loss: 0.6211, Val Loss: 0.5650, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 96, Train Loss: 0.6162, Val Loss: 0.5709, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 97, Train Loss: 0.6170, Val Loss: 0.5670, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 98, Train Loss: 0.6223, Val Loss: 0.5685, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 99, Train Loss: 0.6188, Val Loss: 0.5665, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 100, Train Loss: 0.6196, Val Loss: 0.5656, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 101, Train Loss: 0.6211, Val Loss: 0.5664, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 102, Train Loss: 0.6179, Val Loss: 0.5727, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 103, Train Loss: 0.6244, Val Loss: 0.5627, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 104, Train Loss: 0.6118, Val Loss: 0.5667, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 105, Train Loss: 0.6257, Val Loss: 0.5620, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 106, Train Loss: 0.6231, Val Loss: 0.5715, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 107, Train Loss: 0.6155, Val Loss: 0.5797, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 108, Train Loss: 0.6240, Val Loss: 0.5685, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 109, Train Loss: 0.6185, Val Loss: 0.5691, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 110, Train Loss: 0.6184, Val Loss: 0.5632, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 111, Train Loss: 0.6193, Val Loss: 0.5699, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 112, Train Loss: 0.6121, Val Loss: 0.5631, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 113, Train Loss: 0.6162, Val Loss: 0.5686, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 114, Train Loss: 0.6214, Val Loss: 0.5642, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 115, Train Loss: 0.6157, Val Loss: 0.5616, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 116, Train Loss: 0.6181, Val Loss: 0.5648, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 117, Train Loss: 0.6186, Val Loss: 0.5593, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 118, Train Loss: 0.6167, Val Loss: 0.5713, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 119, Train Loss: 0.6221, Val Loss: 0.5620, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 120, Train Loss: 0.6264, Val Loss: 0.5620, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 121, Train Loss: 0.6220, Val Loss: 0.5727, F1 Micro: 0.7135, F1 Macro: 0.6957, Accuracy: 0.7135\n","Epoch 122, Train Loss: 0.6203, Val Loss: 0.5701, F1 Micro: 0.7528, F1 Macro: 0.7297, Accuracy: 0.7528\n","Epoch 123, Train Loss: 0.6246, Val Loss: 0.5605, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 124, Train Loss: 0.6161, Val Loss: 0.5606, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 125, Train Loss: 0.6246, Val Loss: 0.5599, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 126, Train Loss: 0.6210, Val Loss: 0.5732, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 127, Train Loss: 0.6184, Val Loss: 0.5632, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 128, Train Loss: 0.6083, Val Loss: 0.5724, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 129, Train Loss: 0.6229, Val Loss: 0.5810, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 130, Train Loss: 0.6210, Val Loss: 0.5638, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 131, Train Loss: 0.6173, Val Loss: 0.5666, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 132, Train Loss: 0.6136, Val Loss: 0.5620, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 133, Train Loss: 0.6178, Val Loss: 0.5641, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 134, Train Loss: 0.6233, Val Loss: 0.5841, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 135, Train Loss: 0.6176, Val Loss: 0.5686, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 136, Train Loss: 0.6144, Val Loss: 0.5794, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 137, Train Loss: 0.6241, Val Loss: 0.5653, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 138, Train Loss: 0.6148, Val Loss: 0.5692, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6845, Val Loss: 0.6849, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 2, Train Loss: 0.6821, Val Loss: 0.6762, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6753, Val Loss: 0.6722, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6793, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6757, Val Loss: 0.6808, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 6, Train Loss: 0.6764, Val Loss: 0.6833, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6807, Val Loss: 0.6782, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6759, Val Loss: 0.6745, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6695, Val Loss: 0.6741, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6711, Val Loss: 0.6760, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6718, Val Loss: 0.6821, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 12, Train Loss: 0.6675, Val Loss: 0.6815, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6673, Val Loss: 0.6721, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 14, Train Loss: 0.6672, Val Loss: 0.6697, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6702, Val Loss: 0.6746, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6691, Val Loss: 0.6577, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6640, Val Loss: 0.6621, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6579, Val Loss: 0.6636, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 19, Train Loss: 0.6529, Val Loss: 0.6504, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 20, Train Loss: 0.6466, Val Loss: 0.6376, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 21, Train Loss: 0.6455, Val Loss: 0.6304, F1 Micro: 0.7191, F1 Macro: 0.6226, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.6509, Val Loss: 0.6272, F1 Micro: 0.7247, F1 Macro: 0.6273, Accuracy: 0.7247\n","Epoch 23, Train Loss: 0.6454, Val Loss: 0.6068, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.6409, Val Loss: 0.6060, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 25, Train Loss: 0.6354, Val Loss: 0.6117, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 26, Train Loss: 0.6412, Val Loss: 0.5959, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 27, Train Loss: 0.6418, Val Loss: 0.5972, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 28, Train Loss: 0.6292, Val Loss: 0.6241, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.6449, Val Loss: 0.5904, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 30, Train Loss: 0.6365, Val Loss: 0.5906, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 31, Train Loss: 0.6359, Val Loss: 0.5985, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.6342, Val Loss: 0.6002, F1 Micro: 0.7247, F1 Macro: 0.7041, Accuracy: 0.7247\n","Epoch 33, Train Loss: 0.6346, Val Loss: 0.5851, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 34, Train Loss: 0.6427, Val Loss: 0.5931, F1 Micro: 0.7191, F1 Macro: 0.6336, Accuracy: 0.7191\n","Epoch 35, Train Loss: 0.6432, Val Loss: 0.5933, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.6415, Val Loss: 0.5846, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6372, Val Loss: 0.5863, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 38, Train Loss: 0.6327, Val Loss: 0.5934, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6440, Val Loss: 0.5912, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 40, Train Loss: 0.6345, Val Loss: 0.5875, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 41, Train Loss: 0.6366, Val Loss: 0.5899, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 42, Train Loss: 0.6388, Val Loss: 0.5827, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 43, Train Loss: 0.6351, Val Loss: 0.5918, F1 Micro: 0.7528, F1 Macro: 0.7297, Accuracy: 0.7528\n","Epoch 44, Train Loss: 0.6404, Val Loss: 0.5796, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 45, Train Loss: 0.6320, Val Loss: 0.5982, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 46, Train Loss: 0.6345, Val Loss: 0.5803, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 47, Train Loss: 0.6302, Val Loss: 0.5845, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 48, Train Loss: 0.6346, Val Loss: 0.5840, F1 Micro: 0.7079, F1 Macro: 0.6189, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.6369, Val Loss: 0.5763, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 50, Train Loss: 0.6285, Val Loss: 0.5788, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 51, Train Loss: 0.6302, Val Loss: 0.5993, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 52, Train Loss: 0.6364, Val Loss: 0.5804, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 53, Train Loss: 0.6302, Val Loss: 0.5895, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 54, Train Loss: 0.6359, Val Loss: 0.5730, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 55, Train Loss: 0.6324, Val Loss: 0.5833, F1 Micro: 0.7584, F1 Macro: 0.7349, Accuracy: 0.7584\n","Epoch 56, Train Loss: 0.6360, Val Loss: 0.5800, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 57, Train Loss: 0.6343, Val Loss: 0.5801, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 58, Train Loss: 0.6237, Val Loss: 0.5761, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 59, Train Loss: 0.6265, Val Loss: 0.5834, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 60, Train Loss: 0.6405, Val Loss: 0.5788, F1 Micro: 0.7079, F1 Macro: 0.6242, Accuracy: 0.7079\n","Epoch 61, Train Loss: 0.6411, Val Loss: 0.5765, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 62, Train Loss: 0.6280, Val Loss: 0.5758, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 63, Train Loss: 0.6308, Val Loss: 0.5751, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 64, Train Loss: 0.6273, Val Loss: 0.5775, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 65, Train Loss: 0.6303, Val Loss: 0.5719, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 66, Train Loss: 0.6452, Val Loss: 0.5826, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 67, Train Loss: 0.6288, Val Loss: 0.5735, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 68, Train Loss: 0.6327, Val Loss: 0.5719, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 69, Train Loss: 0.6309, Val Loss: 0.5748, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 70, Train Loss: 0.6454, Val Loss: 0.6061, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 71, Train Loss: 0.6280, Val Loss: 0.5765, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 72, Train Loss: 0.6326, Val Loss: 0.5756, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 73, Train Loss: 0.6311, Val Loss: 0.5735, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 74, Train Loss: 0.6331, Val Loss: 0.5721, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 75, Train Loss: 0.6283, Val Loss: 0.5819, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 76, Train Loss: 0.6410, Val Loss: 0.5753, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 77, Train Loss: 0.6350, Val Loss: 0.5755, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 78, Train Loss: 0.6278, Val Loss: 0.5744, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 79, Train Loss: 0.6217, Val Loss: 0.5839, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 80, Train Loss: 0.6366, Val Loss: 0.5685, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 81, Train Loss: 0.6191, Val Loss: 0.5632, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 82, Train Loss: 0.6286, Val Loss: 0.5657, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 83, Train Loss: 0.6333, Val Loss: 0.5742, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 84, Train Loss: 0.6323, Val Loss: 0.5888, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 85, Train Loss: 0.6271, Val Loss: 0.5699, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 86, Train Loss: 0.6307, Val Loss: 0.5703, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 87, Train Loss: 0.6279, Val Loss: 0.5652, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 88, Train Loss: 0.6241, Val Loss: 0.5654, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 89, Train Loss: 0.6293, Val Loss: 0.5671, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 90, Train Loss: 0.6236, Val Loss: 0.5661, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 91, Train Loss: 0.6268, Val Loss: 0.5662, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 92, Train Loss: 0.6234, Val Loss: 0.5775, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 93, Train Loss: 0.6339, Val Loss: 0.5707, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 94, Train Loss: 0.6280, Val Loss: 0.5610, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 95, Train Loss: 0.6370, Val Loss: 0.5636, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 96, Train Loss: 0.6317, Val Loss: 0.5688, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 97, Train Loss: 0.6290, Val Loss: 0.5669, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6780, Val Loss: 0.7121, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6637, Val Loss: 0.7342, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 3, Train Loss: 0.6695, Val Loss: 0.7236, F1 Micro: 0.5449, F1 Macro: 0.4105, Accuracy: 0.5449\n","Epoch 4, Train Loss: 0.6621, Val Loss: 0.7127, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6576, Val Loss: 0.7313, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.6603, Val Loss: 0.7939, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 7, Train Loss: 0.6646, Val Loss: 0.7359, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 8, Train Loss: 0.6565, Val Loss: 0.7191, F1 Micro: 0.5449, F1 Macro: 0.4467, Accuracy: 0.5449\n","Epoch 9, Train Loss: 0.6529, Val Loss: 0.7348, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 10, Train Loss: 0.6507, Val Loss: 0.7593, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6576, Val Loss: 0.7339, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 12, Train Loss: 0.6443, Val Loss: 0.7640, F1 Micro: 0.5393, F1 Macro: 0.4227, Accuracy: 0.5393\n","Epoch 13, Train Loss: 0.6476, Val Loss: 0.7206, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 14, Train Loss: 0.6376, Val Loss: 0.7326, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 15, Train Loss: 0.6363, Val Loss: 0.7194, F1 Micro: 0.5393, F1 Macro: 0.4492, Accuracy: 0.5393\n","Epoch 16, Train Loss: 0.6199, Val Loss: 0.7720, F1 Micro: 0.5787, F1 Macro: 0.5226, Accuracy: 0.5787\n","Epoch 17, Train Loss: 0.6145, Val Loss: 0.7547, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 18, Train Loss: 0.6217, Val Loss: 0.7827, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 19, Train Loss: 0.6228, Val Loss: 0.7512, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 20, Train Loss: 0.6108, Val Loss: 0.7751, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 21, Train Loss: 0.6022, Val Loss: 0.8327, F1 Micro: 0.5562, F1 Macro: 0.4473, Accuracy: 0.5562\n","Epoch 22, Train Loss: 0.6037, Val Loss: 0.7376, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 23, Train Loss: 0.6097, Val Loss: 0.7492, F1 Micro: 0.5618, F1 Macro: 0.5333, Accuracy: 0.5618\n","Epoch 24, Train Loss: 0.6056, Val Loss: 0.8223, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 25, Train Loss: 0.6115, Val Loss: 0.7882, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 26, Train Loss: 0.6066, Val Loss: 0.7599, F1 Micro: 0.5787, F1 Macro: 0.5377, Accuracy: 0.5787\n","Epoch 27, Train Loss: 0.5977, Val Loss: 0.8394, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 28, Train Loss: 0.6108, Val Loss: 0.7731, F1 Micro: 0.6067, F1 Macro: 0.5700, Accuracy: 0.6067\n","Epoch 29, Train Loss: 0.6038, Val Loss: 0.7428, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.5987, Val Loss: 0.7591, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 31, Train Loss: 0.6060, Val Loss: 0.7517, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6004, Val Loss: 0.7809, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6055, Val Loss: 0.7597, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6008, Val Loss: 0.7577, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 35, Train Loss: 0.6036, Val Loss: 0.7776, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 36, Train Loss: 0.6005, Val Loss: 0.7559, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 37, Train Loss: 0.5835, Val Loss: 0.7842, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.5991, Val Loss: 0.7836, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 39, Train Loss: 0.6002, Val Loss: 0.7628, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 40, Train Loss: 0.5983, Val Loss: 0.7589, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.5974, Val Loss: 0.8005, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6017, Val Loss: 0.7694, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 43, Train Loss: 0.6054, Val Loss: 0.7894, F1 Micro: 0.5787, F1 Macro: 0.5342, Accuracy: 0.5787\n","Epoch 44, Train Loss: 0.5982, Val Loss: 0.7570, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 45, Train Loss: 0.5996, Val Loss: 0.7542, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 46, Train Loss: 0.5864, Val Loss: 0.7464, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 47, Train Loss: 0.5937, Val Loss: 0.7366, F1 Micro: 0.5955, F1 Macro: 0.5913, Accuracy: 0.5955\n","Epoch 48, Train Loss: 0.5943, Val Loss: 0.7522, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 49, Train Loss: 0.5969, Val Loss: 0.7629, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 50, Train Loss: 0.5898, Val Loss: 0.7842, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 51, Train Loss: 0.5926, Val Loss: 0.7633, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 52, Train Loss: 0.5948, Val Loss: 0.7505, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 53, Train Loss: 0.5937, Val Loss: 0.7655, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 54, Train Loss: 0.5933, Val Loss: 0.7546, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.6002, Val Loss: 0.7771, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 56, Train Loss: 0.5952, Val Loss: 0.7853, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 57, Train Loss: 0.6008, Val Loss: 0.7388, F1 Micro: 0.6236, F1 Macro: 0.6147, Accuracy: 0.6236\n","Epoch 58, Train Loss: 0.5869, Val Loss: 0.7524, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 59, Train Loss: 0.5940, Val Loss: 0.7427, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 60, Train Loss: 0.5994, Val Loss: 0.7467, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 61, Train Loss: 0.5957, Val Loss: 0.7607, F1 Micro: 0.6067, F1 Macro: 0.5836, Accuracy: 0.6067\n","Epoch 62, Train Loss: 0.5948, Val Loss: 0.7409, F1 Micro: 0.6348, F1 Macro: 0.6262, Accuracy: 0.6348\n","Epoch 63, Train Loss: 0.6005, Val Loss: 0.7658, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 64, Train Loss: 0.5957, Val Loss: 0.7638, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 65, Train Loss: 0.5954, Val Loss: 0.8125, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 66, Train Loss: 0.5955, Val Loss: 0.7740, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 67, Train Loss: 0.5933, Val Loss: 0.7594, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 68, Train Loss: 0.5938, Val Loss: 0.7714, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 69, Train Loss: 0.5880, Val Loss: 0.7517, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 70, Train Loss: 0.5970, Val Loss: 0.7482, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 71, Train Loss: 0.5887, Val Loss: 0.7609, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 72, Train Loss: 0.5917, Val Loss: 0.7558, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 73, Train Loss: 0.5910, Val Loss: 0.7575, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 74, Train Loss: 0.5946, Val Loss: 0.7643, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 75, Train Loss: 0.5838, Val Loss: 0.7639, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 76, Train Loss: 0.5935, Val Loss: 0.7808, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 77, Train Loss: 0.5896, Val Loss: 0.7640, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 78, Train Loss: 0.5878, Val Loss: 0.7495, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 79, Train Loss: 0.5861, Val Loss: 0.7660, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 80, Train Loss: 0.5960, Val Loss: 0.7528, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 81, Train Loss: 0.5856, Val Loss: 0.7951, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 82, Train Loss: 0.5809, Val Loss: 0.7572, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 83, Train Loss: 0.5881, Val Loss: 0.7653, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 84, Train Loss: 0.5933, Val Loss: 0.7600, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 85, Train Loss: 0.5841, Val Loss: 0.8308, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 86, Train Loss: 0.5922, Val Loss: 0.7675, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 87, Train Loss: 0.5849, Val Loss: 0.7649, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 88, Train Loss: 0.5912, Val Loss: 0.7619, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Epoch 89, Train Loss: 0.5908, Val Loss: 0.7854, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 90, Train Loss: 0.5965, Val Loss: 0.7395, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 91, Train Loss: 0.5886, Val Loss: 0.7600, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 92, Train Loss: 0.5883, Val Loss: 0.7349, F1 Micro: 0.6180, F1 Macro: 0.6121, Accuracy: 0.6180\n","Epoch 93, Train Loss: 0.5900, Val Loss: 0.7703, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 94, Train Loss: 0.5915, Val Loss: 0.7572, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 95, Train Loss: 0.5831, Val Loss: 0.7680, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 96, Train Loss: 0.5944, Val Loss: 0.7529, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 97, Train Loss: 0.5887, Val Loss: 0.7855, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 98, Train Loss: 0.5899, Val Loss: 0.7679, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 99, Train Loss: 0.5901, Val Loss: 0.7917, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 100, Train Loss: 0.5811, Val Loss: 0.7687, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 101, Train Loss: 0.5867, Val Loss: 0.8146, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 102, Train Loss: 0.5864, Val Loss: 0.7579, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 103, Train Loss: 0.5904, Val Loss: 0.7544, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 104, Train Loss: 0.5779, Val Loss: 0.7644, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 105, Train Loss: 0.5811, Val Loss: 0.7340, F1 Micro: 0.6236, F1 Macro: 0.6160, Accuracy: 0.6236\n","Epoch 106, Train Loss: 0.5900, Val Loss: 0.7345, F1 Micro: 0.6180, F1 Macro: 0.6121, Accuracy: 0.6180\n","Epoch 107, Train Loss: 0.5826, Val Loss: 0.7496, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 108, Train Loss: 0.5889, Val Loss: 0.7667, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 109, Train Loss: 0.5818, Val Loss: 0.7697, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 110, Train Loss: 0.5824, Val Loss: 0.7761, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 111, Train Loss: 0.5901, Val Loss: 0.7454, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 112, Train Loss: 0.5838, Val Loss: 0.7431, F1 Micro: 0.6292, F1 Macro: 0.6168, Accuracy: 0.6292\n","Epoch 113, Train Loss: 0.5836, Val Loss: 0.7616, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 114, Train Loss: 0.5832, Val Loss: 0.7800, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 115, Train Loss: 0.5828, Val Loss: 0.7607, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 116, Train Loss: 0.5823, Val Loss: 0.7522, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 117, Train Loss: 0.5808, Val Loss: 0.7364, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 118, Train Loss: 0.5823, Val Loss: 0.7729, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 119, Train Loss: 0.5827, Val Loss: 0.7972, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6837, Val Loss: 0.7303, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 2, Train Loss: 0.6851, Val Loss: 0.6991, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6752, Val Loss: 0.6928, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6699, Val Loss: 0.6907, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6701, Val Loss: 0.7000, F1 Micro: 0.6067, F1 Macro: 0.4357, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6729, Val Loss: 0.6980, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6709, Val Loss: 0.6872, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6713, Val Loss: 0.6948, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6678, Val Loss: 0.6910, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6677, Val Loss: 0.6997, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6647, Val Loss: 0.6876, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6679, Val Loss: 0.6879, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6665, Val Loss: 0.6843, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6638, Val Loss: 0.6875, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 15, Train Loss: 0.6625, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6543, Val Loss: 0.6775, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 17, Train Loss: 0.6482, Val Loss: 0.6837, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 18, Train Loss: 0.6500, Val Loss: 0.6778, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6319, Val Loss: 0.6928, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.6381, Val Loss: 0.6917, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 21, Train Loss: 0.6282, Val Loss: 0.6815, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 22, Train Loss: 0.6306, Val Loss: 0.6706, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 23, Train Loss: 0.6207, Val Loss: 0.6991, F1 Micro: 0.7360, F1 Macro: 0.6670, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6220, Val Loss: 0.6754, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6319, Val Loss: 0.6891, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 26, Train Loss: 0.6286, Val Loss: 0.6938, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 27, Train Loss: 0.6198, Val Loss: 0.6903, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 28, Train Loss: 0.6283, Val Loss: 0.6826, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6217, Val Loss: 0.6858, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 30, Train Loss: 0.6240, Val Loss: 0.6760, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 31, Train Loss: 0.6238, Val Loss: 0.6873, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6293, Val Loss: 0.6810, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 33, Train Loss: 0.6168, Val Loss: 0.6842, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 34, Train Loss: 0.6274, Val Loss: 0.6833, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 35, Train Loss: 0.6244, Val Loss: 0.6773, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 36, Train Loss: 0.6294, Val Loss: 0.6927, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 37, Train Loss: 0.6244, Val Loss: 0.6758, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 38, Train Loss: 0.6205, Val Loss: 0.6909, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 39, Train Loss: 0.6217, Val Loss: 0.6835, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 40, Train Loss: 0.6191, Val Loss: 0.6789, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 41, Train Loss: 0.6214, Val Loss: 0.6990, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 42, Train Loss: 0.6192, Val Loss: 0.6814, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 43, Train Loss: 0.6215, Val Loss: 0.6866, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6235, Val Loss: 0.6919, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 45, Train Loss: 0.6209, Val Loss: 0.6880, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 46, Train Loss: 0.6191, Val Loss: 0.6950, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 47, Train Loss: 0.6202, Val Loss: 0.6931, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 48, Train Loss: 0.6208, Val Loss: 0.6839, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 49, Train Loss: 0.6176, Val Loss: 0.6996, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 50, Train Loss: 0.6250, Val Loss: 0.6882, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 51, Train Loss: 0.6196, Val Loss: 0.6899, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 52, Train Loss: 0.6210, Val Loss: 0.6937, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 53, Train Loss: 0.6166, Val Loss: 0.7032, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 54, Train Loss: 0.6162, Val Loss: 0.6879, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 55, Train Loss: 0.6121, Val Loss: 0.6981, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 56, Train Loss: 0.6172, Val Loss: 0.6867, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 57, Train Loss: 0.6359, Val Loss: 0.6834, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 58, Train Loss: 0.6197, Val Loss: 0.6949, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 59, Train Loss: 0.6077, Val Loss: 0.6977, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 60, Train Loss: 0.6246, Val Loss: 0.6927, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 61, Train Loss: 0.6194, Val Loss: 0.6980, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 62, Train Loss: 0.6203, Val Loss: 0.6873, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 63, Train Loss: 0.6162, Val Loss: 0.6924, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 64, Train Loss: 0.6179, Val Loss: 0.6898, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 65, Train Loss: 0.6140, Val Loss: 0.7091, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 66, Train Loss: 0.6152, Val Loss: 0.6965, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 67, Train Loss: 0.6161, Val Loss: 0.6873, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 68, Train Loss: 0.6118, Val Loss: 0.7024, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 69, Train Loss: 0.6118, Val Loss: 0.7234, F1 Micro: 0.7022, F1 Macro: 0.6195, Accuracy: 0.7022\n","Epoch 70, Train Loss: 0.6095, Val Loss: 0.7167, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 71, Train Loss: 0.6194, Val Loss: 0.6980, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 72, Train Loss: 0.6155, Val Loss: 0.6899, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 73, Train Loss: 0.6062, Val Loss: 0.6945, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 74, Train Loss: 0.6052, Val Loss: 0.6910, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 75, Train Loss: 0.6145, Val Loss: 0.6911, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 76, Train Loss: 0.6174, Val Loss: 0.6883, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7306383780051472\n","Best hyperparameters for Outer FOLD 3: (0.001, 16, 50) with score 0.7306383780051472\n","Epoch 1, Train Loss: 0.6819, Val Loss: 0.6971, F1 Micro: 0.5856, F1 Macro: 0.4441, Accuracy: 0.5856\n","Epoch 2, Train Loss: 0.6758, Val Loss: 0.7002, F1 Micro: 0.5586, F1 Macro: 0.3584, Accuracy: 0.5586\n","Epoch 3, Train Loss: 0.6807, Val Loss: 0.6865, F1 Micro: 0.5586, F1 Macro: 0.3584, Accuracy: 0.5586\n","Epoch 4, Train Loss: 0.6722, Val Loss: 0.6865, F1 Micro: 0.5586, F1 Macro: 0.3584, Accuracy: 0.5586\n","Epoch 5, Train Loss: 0.6718, Val Loss: 0.6912, F1 Micro: 0.5586, F1 Macro: 0.3584, Accuracy: 0.5586\n","Epoch 6, Train Loss: 0.6654, Val Loss: 0.7006, F1 Micro: 0.5676, F1 Macro: 0.3805, Accuracy: 0.5676\n","Epoch 7, Train Loss: 0.6659, Val Loss: 0.6797, F1 Micro: 0.6306, F1 Macro: 0.5618, Accuracy: 0.6306\n","Epoch 8, Train Loss: 0.6718, Val Loss: 0.6788, F1 Micro: 0.5586, F1 Macro: 0.3584, Accuracy: 0.5586\n","Epoch 9, Train Loss: 0.6662, Val Loss: 0.6916, F1 Micro: 0.5586, F1 Macro: 0.3584, Accuracy: 0.5586\n","Epoch 10, Train Loss: 0.6628, Val Loss: 0.6728, F1 Micro: 0.6532, F1 Macro: 0.5968, Accuracy: 0.6532\n","Epoch 11, Train Loss: 0.6643, Val Loss: 0.6748, F1 Micro: 0.5676, F1 Macro: 0.3805, Accuracy: 0.5676\n","Epoch 12, Train Loss: 0.6517, Val Loss: 0.6613, F1 Micro: 0.5901, F1 Macro: 0.4776, Accuracy: 0.5901\n","Epoch 13, Train Loss: 0.6457, Val Loss: 0.6597, F1 Micro: 0.6216, F1 Macro: 0.5204, Accuracy: 0.6216\n","Epoch 14, Train Loss: 0.6360, Val Loss: 0.6424, F1 Micro: 0.6532, F1 Macro: 0.5968, Accuracy: 0.6532\n","Epoch 15, Train Loss: 0.6366, Val Loss: 0.6436, F1 Micro: 0.6622, F1 Macro: 0.6009, Accuracy: 0.6622\n","Epoch 16, Train Loss: 0.6306, Val Loss: 0.6394, F1 Micro: 0.6622, F1 Macro: 0.6073, Accuracy: 0.6622\n","Epoch 17, Train Loss: 0.6274, Val Loss: 0.6382, F1 Micro: 0.6532, F1 Macro: 0.6184, Accuracy: 0.6532\n","Epoch 18, Train Loss: 0.6249, Val Loss: 0.6802, F1 Micro: 0.6396, F1 Macro: 0.5524, Accuracy: 0.6396\n","Epoch 19, Train Loss: 0.6357, Val Loss: 0.6479, F1 Micro: 0.6306, F1 Macro: 0.5654, Accuracy: 0.6306\n","Epoch 20, Train Loss: 0.6273, Val Loss: 0.6347, F1 Micro: 0.7117, F1 Macro: 0.6873, Accuracy: 0.7117\n","Epoch 21, Train Loss: 0.6292, Val Loss: 0.6302, F1 Micro: 0.7027, F1 Macro: 0.6825, Accuracy: 0.7027\n","Epoch 22, Train Loss: 0.6337, Val Loss: 0.6344, F1 Micro: 0.6712, F1 Macro: 0.6337, Accuracy: 0.6712\n","Epoch 23, Train Loss: 0.6331, Val Loss: 0.6387, F1 Micro: 0.6667, F1 Macro: 0.6140, Accuracy: 0.6667\n","Epoch 24, Train Loss: 0.6315, Val Loss: 0.6615, F1 Micro: 0.6351, F1 Macro: 0.5490, Accuracy: 0.6351\n","Epoch 25, Train Loss: 0.6265, Val Loss: 0.6359, F1 Micro: 0.6667, F1 Macro: 0.6140, Accuracy: 0.6667\n","Epoch 26, Train Loss: 0.6183, Val Loss: 0.6321, F1 Micro: 0.7117, F1 Macro: 0.6856, Accuracy: 0.7117\n","Epoch 27, Train Loss: 0.6225, Val Loss: 0.6292, F1 Micro: 0.7072, F1 Macro: 0.6865, Accuracy: 0.7072\n","Epoch 28, Train Loss: 0.6367, Val Loss: 0.6299, F1 Micro: 0.7072, F1 Macro: 0.6881, Accuracy: 0.7072\n","Epoch 29, Train Loss: 0.6246, Val Loss: 0.6636, F1 Micro: 0.6216, F1 Macro: 0.5300, Accuracy: 0.6216\n","Epoch 30, Train Loss: 0.6313, Val Loss: 0.6368, F1 Micro: 0.6577, F1 Macro: 0.6005, Accuracy: 0.6577\n","Epoch 31, Train Loss: 0.6253, Val Loss: 0.6427, F1 Micro: 0.6486, F1 Macro: 0.5931, Accuracy: 0.6486\n","Epoch 32, Train Loss: 0.6199, Val Loss: 0.6411, F1 Micro: 0.6667, F1 Macro: 0.6110, Accuracy: 0.6667\n","Epoch 33, Train Loss: 0.6275, Val Loss: 0.6347, F1 Micro: 0.7027, F1 Macro: 0.6739, Accuracy: 0.7027\n","Epoch 34, Train Loss: 0.6253, Val Loss: 0.6359, F1 Micro: 0.6667, F1 Macro: 0.6110, Accuracy: 0.6667\n","Epoch 35, Train Loss: 0.6228, Val Loss: 0.6307, F1 Micro: 0.6802, F1 Macro: 0.6437, Accuracy: 0.6802\n","Epoch 36, Train Loss: 0.6217, Val Loss: 0.6320, F1 Micro: 0.6802, F1 Macro: 0.6437, Accuracy: 0.6802\n","Epoch 37, Train Loss: 0.6283, Val Loss: 0.6418, F1 Micro: 0.6532, F1 Macro: 0.5902, Accuracy: 0.6532\n","Epoch 38, Train Loss: 0.6169, Val Loss: 0.6519, F1 Micro: 0.6486, F1 Macro: 0.5795, Accuracy: 0.6486\n","Epoch 39, Train Loss: 0.6199, Val Loss: 0.6365, F1 Micro: 0.6802, F1 Macro: 0.6390, Accuracy: 0.6802\n","Epoch 40, Train Loss: 0.6298, Val Loss: 0.6435, F1 Micro: 0.6577, F1 Macro: 0.5972, Accuracy: 0.6577\n","Epoch 41, Train Loss: 0.6187, Val Loss: 0.6236, F1 Micro: 0.7027, F1 Macro: 0.6758, Accuracy: 0.7027\n","Epoch 42, Train Loss: 0.6178, Val Loss: 0.6273, F1 Micro: 0.6757, F1 Macro: 0.6351, Accuracy: 0.6757\n","Epoch 43, Train Loss: 0.6251, Val Loss: 0.6324, F1 Micro: 0.7117, F1 Macro: 0.6856, Accuracy: 0.7117\n","Epoch 44, Train Loss: 0.6243, Val Loss: 0.6407, F1 Micro: 0.6622, F1 Macro: 0.6041, Accuracy: 0.6622\n","Epoch 45, Train Loss: 0.6206, Val Loss: 0.6408, F1 Micro: 0.6667, F1 Macro: 0.6169, Accuracy: 0.6667\n","Epoch 46, Train Loss: 0.6161, Val Loss: 0.6296, F1 Micro: 0.6667, F1 Macro: 0.6197, Accuracy: 0.6667\n","Epoch 47, Train Loss: 0.6118, Val Loss: 0.6253, F1 Micro: 0.6847, F1 Macro: 0.6520, Accuracy: 0.6847\n","Epoch 48, Train Loss: 0.6207, Val Loss: 0.6345, F1 Micro: 0.6577, F1 Macro: 0.6005, Accuracy: 0.6577\n","Epoch 49, Train Loss: 0.6188, Val Loss: 0.6311, F1 Micro: 0.6577, F1 Macro: 0.6066, Accuracy: 0.6577\n","Epoch 50, Train Loss: 0.6261, Val Loss: 0.6231, F1 Micro: 0.7117, F1 Macro: 0.6921, Accuracy: 0.7117\n","Epoch 51, Train Loss: 0.6157, Val Loss: 0.6335, F1 Micro: 0.6937, F1 Macro: 0.6599, Accuracy: 0.6937\n","Epoch 52, Train Loss: 0.6146, Val Loss: 0.6372, F1 Micro: 0.6577, F1 Macro: 0.6005, Accuracy: 0.6577\n","Epoch 53, Train Loss: 0.6264, Val Loss: 0.6249, F1 Micro: 0.6982, F1 Macro: 0.6680, Accuracy: 0.6982\n","Epoch 54, Train Loss: 0.6166, Val Loss: 0.6224, F1 Micro: 0.6757, F1 Macro: 0.6442, Accuracy: 0.6757\n","Epoch 55, Train Loss: 0.6205, Val Loss: 0.6249, F1 Micro: 0.6892, F1 Macro: 0.6560, Accuracy: 0.6892\n","Epoch 56, Train Loss: 0.6151, Val Loss: 0.6656, F1 Micro: 0.6441, F1 Macro: 0.5684, Accuracy: 0.6441\n","Epoch 57, Train Loss: 0.6211, Val Loss: 0.6368, F1 Micro: 0.6622, F1 Macro: 0.6041, Accuracy: 0.6622\n","Epoch 58, Train Loss: 0.6244, Val Loss: 0.6257, F1 Micro: 0.6937, F1 Macro: 0.6620, Accuracy: 0.6937\n","Epoch 59, Train Loss: 0.6136, Val Loss: 0.6406, F1 Micro: 0.6532, F1 Macro: 0.5902, Accuracy: 0.6532\n","Epoch 60, Train Loss: 0.6133, Val Loss: 0.6446, F1 Micro: 0.6577, F1 Macro: 0.5972, Accuracy: 0.6577\n","Epoch 61, Train Loss: 0.6161, Val Loss: 0.6436, F1 Micro: 0.6577, F1 Macro: 0.5972, Accuracy: 0.6577\n","Epoch 62, Train Loss: 0.6163, Val Loss: 0.6191, F1 Micro: 0.6937, F1 Macro: 0.6659, Accuracy: 0.6937\n","Epoch 63, Train Loss: 0.6174, Val Loss: 0.6187, F1 Micro: 0.7117, F1 Macro: 0.6890, Accuracy: 0.7117\n","Epoch 64, Train Loss: 0.6179, Val Loss: 0.6231, F1 Micro: 0.6847, F1 Macro: 0.6476, Accuracy: 0.6847\n","Epoch 65, Train Loss: 0.6114, Val Loss: 0.6161, F1 Micro: 0.7027, F1 Macro: 0.6840, Accuracy: 0.7027\n","Epoch 66, Train Loss: 0.6196, Val Loss: 0.6234, F1 Micro: 0.6802, F1 Macro: 0.6414, Accuracy: 0.6802\n","Epoch 67, Train Loss: 0.6170, Val Loss: 0.6262, F1 Micro: 0.6532, F1 Macro: 0.5999, Accuracy: 0.6532\n","Epoch 68, Train Loss: 0.6167, Val Loss: 0.6448, F1 Micro: 0.6441, F1 Macro: 0.5760, Accuracy: 0.6441\n","Epoch 69, Train Loss: 0.6105, Val Loss: 0.6219, F1 Micro: 0.7252, F1 Macro: 0.7073, Accuracy: 0.7252\n","Epoch 70, Train Loss: 0.6096, Val Loss: 0.6249, F1 Micro: 0.7072, F1 Macro: 0.6798, Accuracy: 0.7072\n","Epoch 71, Train Loss: 0.6159, Val Loss: 0.6164, F1 Micro: 0.7027, F1 Macro: 0.6776, Accuracy: 0.7027\n","Epoch 72, Train Loss: 0.6155, Val Loss: 0.6176, F1 Micro: 0.7027, F1 Macro: 0.6776, Accuracy: 0.7027\n","Epoch 73, Train Loss: 0.6092, Val Loss: 0.6286, F1 Micro: 0.6937, F1 Macro: 0.6577, Accuracy: 0.6937\n","Epoch 74, Train Loss: 0.6177, Val Loss: 0.6371, F1 Micro: 0.6577, F1 Macro: 0.5972, Accuracy: 0.6577\n","Epoch 75, Train Loss: 0.6226, Val Loss: 0.6430, F1 Micro: 0.6577, F1 Macro: 0.5903, Accuracy: 0.6577\n","Epoch 76, Train Loss: 0.6141, Val Loss: 0.6285, F1 Micro: 0.6532, F1 Macro: 0.5968, Accuracy: 0.6532\n","Epoch 77, Train Loss: 0.6101, Val Loss: 0.6291, F1 Micro: 0.7252, F1 Macro: 0.7058, Accuracy: 0.7252\n","Epoch 78, Train Loss: 0.6110, Val Loss: 0.6321, F1 Micro: 0.6532, F1 Macro: 0.5936, Accuracy: 0.6532\n","Epoch 79, Train Loss: 0.6186, Val Loss: 0.6217, F1 Micro: 0.7027, F1 Macro: 0.6881, Accuracy: 0.7027\n","Epoch 80, Train Loss: 0.6134, Val Loss: 0.6220, F1 Micro: 0.7027, F1 Macro: 0.6739, Accuracy: 0.7027\n","Epoch 81, Train Loss: 0.6085, Val Loss: 0.6280, F1 Micro: 0.6441, F1 Macro: 0.5863, Accuracy: 0.6441\n","Epoch 82, Train Loss: 0.6159, Val Loss: 0.6214, F1 Micro: 0.7072, F1 Macro: 0.6798, Accuracy: 0.7072\n","Epoch 83, Train Loss: 0.6053, Val Loss: 0.6154, F1 Micro: 0.7117, F1 Macro: 0.6921, Accuracy: 0.7117\n","Epoch 84, Train Loss: 0.6124, Val Loss: 0.6453, F1 Micro: 0.6532, F1 Macro: 0.5831, Accuracy: 0.6532\n","Epoch 85, Train Loss: 0.6072, Val Loss: 0.6195, F1 Micro: 0.6937, F1 Macro: 0.6640, Accuracy: 0.6937\n","Epoch 86, Train Loss: 0.6160, Val Loss: 0.6313, F1 Micro: 0.6712, F1 Macro: 0.6235, Accuracy: 0.6712\n","Epoch 87, Train Loss: 0.6043, Val Loss: 0.6234, F1 Micro: 0.6667, F1 Macro: 0.6224, Accuracy: 0.6667\n","Epoch 88, Train Loss: 0.6077, Val Loss: 0.6174, F1 Micro: 0.7027, F1 Macro: 0.6776, Accuracy: 0.7027\n","Epoch 89, Train Loss: 0.6158, Val Loss: 0.6123, F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Epoch 90, Train Loss: 0.6157, Val Loss: 0.6221, F1 Micro: 0.6847, F1 Macro: 0.6476, Accuracy: 0.6847\n","Epoch 91, Train Loss: 0.6108, Val Loss: 0.6227, F1 Micro: 0.6532, F1 Macro: 0.6029, Accuracy: 0.6532\n","Epoch 92, Train Loss: 0.6096, Val Loss: 0.6146, F1 Micro: 0.7207, F1 Macro: 0.7032, Accuracy: 0.7207\n","Epoch 93, Train Loss: 0.6081, Val Loss: 0.6351, F1 Micro: 0.6351, F1 Macro: 0.5689, Accuracy: 0.6351\n","Epoch 94, Train Loss: 0.6099, Val Loss: 0.6222, F1 Micro: 0.6802, F1 Macro: 0.6414, Accuracy: 0.6802\n","Epoch 95, Train Loss: 0.6077, Val Loss: 0.6227, F1 Micro: 0.7117, F1 Macro: 0.7020, Accuracy: 0.7117\n","Epoch 96, Train Loss: 0.6065, Val Loss: 0.6181, F1 Micro: 0.7117, F1 Macro: 0.6856, Accuracy: 0.7117\n","Epoch 97, Train Loss: 0.6113, Val Loss: 0.6160, F1 Micro: 0.7027, F1 Macro: 0.6776, Accuracy: 0.7027\n","Epoch 98, Train Loss: 0.6072, Val Loss: 0.6172, F1 Micro: 0.7207, F1 Macro: 0.7017, Accuracy: 0.7207\n","Epoch 99, Train Loss: 0.6130, Val Loss: 0.6206, F1 Micro: 0.7162, F1 Macro: 0.6930, Accuracy: 0.7162\n","Epoch 100, Train Loss: 0.6078, Val Loss: 0.6213, F1 Micro: 0.7027, F1 Macro: 0.6739, Accuracy: 0.7027\n","Epoch 101, Train Loss: 0.6033, Val Loss: 0.6283, F1 Micro: 0.7162, F1 Macro: 0.6914, Accuracy: 0.7162\n","Epoch 102, Train Loss: 0.6071, Val Loss: 0.6127, F1 Micro: 0.7072, F1 Macro: 0.6881, Accuracy: 0.7072\n","Epoch 103, Train Loss: 0.6089, Val Loss: 0.6112, F1 Micro: 0.6937, F1 Macro: 0.6759, Accuracy: 0.6937\n","Epoch 104, Train Loss: 0.6125, Val Loss: 0.6495, F1 Micro: 0.6441, F1 Macro: 0.5723, Accuracy: 0.6441\n","Epoch 105, Train Loss: 0.6175, Val Loss: 0.6214, F1 Micro: 0.6757, F1 Macro: 0.6376, Accuracy: 0.6757\n","Epoch 106, Train Loss: 0.6153, Val Loss: 0.6185, F1 Micro: 0.7162, F1 Macro: 0.6977, Accuracy: 0.7162\n","Epoch 107, Train Loss: 0.6108, Val Loss: 0.6236, F1 Micro: 0.6396, F1 Macro: 0.5827, Accuracy: 0.6396\n","Epoch 108, Train Loss: 0.6148, Val Loss: 0.6165, F1 Micro: 0.6982, F1 Macro: 0.6718, Accuracy: 0.6982\n","Epoch 109, Train Loss: 0.6069, Val Loss: 0.6634, F1 Micro: 0.6306, F1 Macro: 0.5366, Accuracy: 0.6306\n","Epoch 110, Train Loss: 0.6091, Val Loss: 0.6348, F1 Micro: 0.6441, F1 Macro: 0.5760, Accuracy: 0.6441\n","Epoch 111, Train Loss: 0.6082, Val Loss: 0.6137, F1 Micro: 0.7117, F1 Macro: 0.6936, Accuracy: 0.7117\n","Epoch 112, Train Loss: 0.6044, Val Loss: 0.6282, F1 Micro: 0.7117, F1 Macro: 0.6988, Accuracy: 0.7117\n","Epoch 113, Train Loss: 0.6105, Val Loss: 0.6167, F1 Micro: 0.7207, F1 Macro: 0.6987, Accuracy: 0.7207\n","Epoch 114, Train Loss: 0.6125, Val Loss: 0.6205, F1 Micro: 0.6757, F1 Macro: 0.6376, Accuracy: 0.6757\n","Epoch 115, Train Loss: 0.6092, Val Loss: 0.6293, F1 Micro: 0.6577, F1 Macro: 0.6005, Accuracy: 0.6577\n","Epoch 116, Train Loss: 0.6064, Val Loss: 0.6308, F1 Micro: 0.7027, F1 Macro: 0.6927, Accuracy: 0.7027\n","Epoch 117, Train Loss: 0.6083, Val Loss: 0.6222, F1 Micro: 0.6712, F1 Macro: 0.6288, Accuracy: 0.6712\n","Epoch 118, Train Loss: 0.6087, Val Loss: 0.6130, F1 Micro: 0.7027, F1 Macro: 0.6809, Accuracy: 0.7027\n","Epoch 119, Train Loss: 0.6089, Val Loss: 0.6275, F1 Micro: 0.6441, F1 Macro: 0.5863, Accuracy: 0.6441\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6441, F1 Macro: 0.5863, Accuracy: 0.6441\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7304, Val Loss: 0.6660, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6890, Val Loss: 0.6936, F1 Micro: 0.5419, F1 Macro: 0.5048, Accuracy: 0.5419\n","Epoch 3, Train Loss: 0.6815, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6702, Val Loss: 0.6511, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 5, Train Loss: 0.6912, Val Loss: 0.6543, F1 Micro: 0.6592, F1 Macro: 0.5843, Accuracy: 0.6592\n","Epoch 6, Train Loss: 0.7069, Val Loss: 0.7998, F1 Micro: 0.6369, F1 Macro: 0.5874, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.7013, Val Loss: 0.6721, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 8, Train Loss: 0.6722, Val Loss: 0.6836, F1 Micro: 0.6089, F1 Macro: 0.5495, Accuracy: 0.6089\n","Epoch 9, Train Loss: 0.6872, Val Loss: 0.6755, F1 Micro: 0.6872, F1 Macro: 0.5323, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.6675, Val Loss: 0.6423, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Epoch 11, Train Loss: 0.6458, Val Loss: 1.0088, F1 Micro: 0.6592, F1 Macro: 0.4954, Accuracy: 0.6592\n","Epoch 12, Train Loss: 0.8091, Val Loss: 0.6689, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 13, Train Loss: 0.6762, Val Loss: 0.6937, F1 Micro: 0.6034, F1 Macro: 0.5919, Accuracy: 0.6034\n","Epoch 14, Train Loss: 0.6524, Val Loss: 0.7128, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 15, Train Loss: 0.6700, Val Loss: 0.6461, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 16, Train Loss: 0.6431, Val Loss: 0.6456, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 17, Train Loss: 0.6549, Val Loss: 0.6476, F1 Micro: 0.6760, F1 Macro: 0.5413, Accuracy: 0.6760\n","Epoch 18, Train Loss: 0.6870, Val Loss: 0.6933, F1 Micro: 0.6536, F1 Macro: 0.4495, Accuracy: 0.6536\n","Epoch 19, Train Loss: 0.6744, Val Loss: 0.6678, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 20, Train Loss: 0.6605, Val Loss: 0.6548, F1 Micro: 0.6927, F1 Macro: 0.5533, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6676, Val Loss: 0.6461, F1 Micro: 0.6592, F1 Macro: 0.5843, Accuracy: 0.6592\n","Epoch 22, Train Loss: 0.6410, Val Loss: 0.6647, F1 Micro: 0.6313, F1 Macro: 0.5863, Accuracy: 0.6313\n","Epoch 23, Train Loss: 0.6461, Val Loss: 0.6417, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 24, Train Loss: 0.6797, Val Loss: 0.6411, F1 Micro: 0.7039, F1 Macro: 0.6151, Accuracy: 0.7039\n","Epoch 25, Train Loss: 0.6434, Val Loss: 0.6357, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 26, Train Loss: 0.6406, Val Loss: 0.6368, F1 Micro: 0.6760, F1 Macro: 0.5562, Accuracy: 0.6760\n","Epoch 27, Train Loss: 0.6652, Val Loss: 0.6364, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 28, Train Loss: 0.6479, Val Loss: 0.7013, F1 Micro: 0.6480, F1 Macro: 0.6001, Accuracy: 0.6480\n","Epoch 29, Train Loss: 0.6844, Val Loss: 0.6500, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 30, Train Loss: 0.6852, Val Loss: 0.7002, F1 Micro: 0.6201, F1 Macro: 0.5223, Accuracy: 0.6201\n","Epoch 31, Train Loss: 0.6792, Val Loss: 0.6679, F1 Micro: 0.6257, F1 Macro: 0.6099, Accuracy: 0.6257\n","Epoch 32, Train Loss: 0.6544, Val Loss: 0.6571, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 33, Train Loss: 0.6602, Val Loss: 0.6476, F1 Micro: 0.6704, F1 Macro: 0.5589, Accuracy: 0.6704\n","Epoch 34, Train Loss: 0.6502, Val Loss: 0.6576, F1 Micro: 0.6313, F1 Macro: 0.5987, Accuracy: 0.6313\n","Epoch 35, Train Loss: 0.6565, Val Loss: 0.6390, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7346, Val Loss: 0.6711, F1 Micro: 0.6348, F1 Macro: 0.4510, Accuracy: 0.6348\n","Epoch 2, Train Loss: 0.7005, Val Loss: 0.6653, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.7019, Val Loss: 0.6672, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6906, Val Loss: 0.7214, F1 Micro: 0.3764, F1 Macro: 0.3762, Accuracy: 0.3764\n","Epoch 5, Train Loss: 0.7030, Val Loss: 0.6696, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6941, Val Loss: 0.6825, F1 Micro: 0.6966, F1 Macro: 0.5793, Accuracy: 0.6966\n","Epoch 7, Train Loss: 0.6803, Val Loss: 0.7829, F1 Micro: 0.4045, F1 Macro: 0.4045, Accuracy: 0.4045\n","Epoch 8, Train Loss: 0.6843, Val Loss: 0.6688, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 9, Train Loss: 0.6825, Val Loss: 0.7781, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 10, Train Loss: 0.7008, Val Loss: 0.6549, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 11, Train Loss: 0.6712, Val Loss: 0.6354, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.7079, Val Loss: 0.6285, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.7724, Val Loss: 0.6626, F1 Micro: 0.6348, F1 Macro: 0.5862, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.8236, Val Loss: 0.7216, F1 Micro: 0.5000, F1 Macro: 0.4899, Accuracy: 0.5000\n","Epoch 15, Train Loss: 0.7317, Val Loss: 0.7910, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.7114, Val Loss: 0.6288, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7156, Val Loss: 0.6636, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6891, Val Loss: 0.8408, F1 Micro: 0.3652, F1 Macro: 0.3627, Accuracy: 0.3652\n","Epoch 3, Train Loss: 0.6911, Val Loss: 0.6701, F1 Micro: 0.6292, F1 Macro: 0.5411, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6838, Val Loss: 0.7153, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.7058, Val Loss: 1.1245, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 6, Train Loss: 0.7401, Val Loss: 0.6789, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.7198, Val Loss: 0.6817, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6801, Val Loss: 0.6548, F1 Micro: 0.6292, F1 Macro: 0.5019, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6771, Val Loss: 0.6563, F1 Micro: 0.6348, F1 Macro: 0.5334, Accuracy: 0.6348\n","Epoch 10, Train Loss: 0.6637, Val Loss: 0.6334, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6661, Val Loss: 0.6541, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6692, Val Loss: 0.6871, F1 Micro: 0.6124, F1 Macro: 0.5111, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6545, Val Loss: 0.6994, F1 Micro: 0.6404, F1 Macro: 0.6382, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6464, Val Loss: 0.7086, F1 Micro: 0.6124, F1 Macro: 0.4283, Accuracy: 0.6124\n","Epoch 15, Train Loss: 0.6650, Val Loss: 0.6389, F1 Micro: 0.6404, F1 Macro: 0.5094, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6687, Val Loss: 0.6617, F1 Micro: 0.6236, F1 Macro: 0.4904, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6588, Val Loss: 0.6232, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6627, Val Loss: 0.6446, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.7210, Val Loss: 0.6396, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6845, Val Loss: 1.0559, F1 Micro: 0.3708, F1 Macro: 0.2705, Accuracy: 0.3708\n","Epoch 21, Train Loss: 0.7166, Val Loss: 0.7172, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 22, Train Loss: 0.6642, Val Loss: 0.6572, F1 Micro: 0.6292, F1 Macro: 0.4370, Accuracy: 0.6292\n","Epoch 23, Train Loss: 0.6593, Val Loss: 0.6724, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.6742, Val Loss: 0.8699, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 25, Train Loss: 0.6572, Val Loss: 0.6613, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 26, Train Loss: 0.6544, Val Loss: 0.6662, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 27, Train Loss: 0.6836, Val Loss: 1.0532, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 28, Train Loss: 0.7314, Val Loss: 0.6309, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6590, Val Loss: 0.6370, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 30, Train Loss: 0.6803, Val Loss: 0.6652, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6645, Val Loss: 0.6504, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 32, Train Loss: 0.6489, Val Loss: 0.6486, F1 Micro: 0.6292, F1 Macro: 0.4771, Accuracy: 0.6292\n","Epoch 33, Train Loss: 0.6414, Val Loss: 0.7092, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 34, Train Loss: 0.6406, Val Loss: 0.6529, F1 Micro: 0.6629, F1 Macro: 0.6468, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6624, Val Loss: 0.6349, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7089, Val Loss: 0.8684, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6797, Val Loss: 0.7211, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 3, Train Loss: 0.6719, Val Loss: 0.7311, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6785, Val Loss: 0.6991, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6756, Val Loss: 0.7760, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6678, Val Loss: 0.7124, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6679, Val Loss: 0.7204, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6774, Val Loss: 1.0884, F1 Micro: 0.4157, F1 Macro: 0.3463, Accuracy: 0.4157\n","Epoch 9, Train Loss: 0.7244, Val Loss: 0.7356, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 10, Train Loss: 0.6823, Val Loss: 0.8617, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.7015, Val Loss: 0.6958, F1 Micro: 0.4775, F1 Macro: 0.3232, Accuracy: 0.4775\n","Epoch 12, Train Loss: 0.7586, Val Loss: 0.9033, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7117, Val Loss: 0.7372, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6884, Val Loss: 0.6852, F1 Micro: 0.6067, F1 Macro: 0.4357, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6956, Val Loss: 0.6671, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6782, Val Loss: 0.7596, F1 Micro: 0.6292, F1 Macro: 0.5163, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.7016, Val Loss: 0.9175, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6966, Val Loss: 0.6726, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6957, Val Loss: 0.7883, F1 Micro: 0.4888, F1 Macro: 0.4868, Accuracy: 0.4888\n","Epoch 8, Train Loss: 0.7677, Val Loss: 0.6644, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6678, Val Loss: 0.6390, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6482, Val Loss: 0.6808, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6674, Val Loss: 0.6601, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6668, Val Loss: 0.6423, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6875, Val Loss: 0.6439, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6538, Val Loss: 0.6312, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6660, Val Loss: 0.6357, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6526, Val Loss: 0.6478, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6555, Val Loss: 0.6309, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6676, Val Loss: 0.7867, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6617, Val Loss: 0.7098, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 20, Train Loss: 0.6946, Val Loss: 0.6634, F1 Micro: 0.6067, F1 Macro: 0.4634, Accuracy: 0.6067\n","Epoch 21, Train Loss: 0.6646, Val Loss: 0.7250, F1 Micro: 0.4888, F1 Macro: 0.4841, Accuracy: 0.4888\n","Epoch 22, Train Loss: 0.6786, Val Loss: 0.6387, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.7658, Val Loss: 0.6883, F1 Micro: 0.6292, F1 Macro: 0.6285, Accuracy: 0.6292\n","Epoch 24, Train Loss: 0.6834, Val Loss: 0.7533, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6532, Val Loss: 0.6738, F1 Micro: 0.5674, F1 Macro: 0.5673, Accuracy: 0.5674\n","Epoch 26, Train Loss: 0.6749, Val Loss: 0.7292, F1 Micro: 0.6180, F1 Macro: 0.5085, Accuracy: 0.6180\n","Epoch 27, Train Loss: 0.6680, Val Loss: 0.6302, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.6800891343920659\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7154, Val Loss: 0.7901, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 2, Train Loss: 0.6934, Val Loss: 0.6617, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6882, Val Loss: 0.6596, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6892, Val Loss: 0.6534, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.7038, Val Loss: 0.6644, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 6, Train Loss: 0.6969, Val Loss: 0.6492, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 7, Train Loss: 0.6943, Val Loss: 0.6647, F1 Micro: 0.6369, F1 Macro: 0.5713, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.6803, Val Loss: 0.6526, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 9, Train Loss: 0.6640, Val Loss: 0.6527, F1 Micro: 0.6592, F1 Macro: 0.5843, Accuracy: 0.6592\n","Epoch 10, Train Loss: 0.6664, Val Loss: 0.7709, F1 Micro: 0.3575, F1 Macro: 0.3414, Accuracy: 0.3575\n","Epoch 11, Train Loss: 0.6670, Val Loss: 0.6899, F1 Micro: 0.6145, F1 Macro: 0.5351, Accuracy: 0.6145\n","Epoch 12, Train Loss: 0.6651, Val Loss: 0.6531, F1 Micro: 0.6648, F1 Macro: 0.5409, Accuracy: 0.6648\n","Epoch 13, Train Loss: 0.6673, Val Loss: 0.8032, F1 Micro: 0.4749, F1 Macro: 0.4564, Accuracy: 0.4749\n","Epoch 14, Train Loss: 0.6856, Val Loss: 0.6599, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 15, Train Loss: 0.7259, Val Loss: 0.7229, F1 Micro: 0.3743, F1 Macro: 0.3431, Accuracy: 0.3743\n","Epoch 16, Train Loss: 0.7264, Val Loss: 0.7132, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 17, Train Loss: 0.7101, Val Loss: 0.6631, F1 Micro: 0.6760, F1 Macro: 0.5816, Accuracy: 0.6760\n","Epoch 18, Train Loss: 0.6821, Val Loss: 0.6884, F1 Micro: 0.5922, F1 Macro: 0.5633, Accuracy: 0.5922\n","Epoch 19, Train Loss: 0.6639, Val Loss: 0.6610, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 20, Train Loss: 0.6717, Val Loss: 0.6601, F1 Micro: 0.6536, F1 Macro: 0.6047, Accuracy: 0.6536\n","Epoch 21, Train Loss: 0.6702, Val Loss: 0.6629, F1 Micro: 0.6872, F1 Macro: 0.5571, Accuracy: 0.6872\n","Epoch 22, Train Loss: 0.6464, Val Loss: 0.6548, F1 Micro: 0.6704, F1 Macro: 0.5293, Accuracy: 0.6704\n","Epoch 23, Train Loss: 0.6421, Val Loss: 0.6472, F1 Micro: 0.7039, F1 Macro: 0.6151, Accuracy: 0.7039\n","Epoch 24, Train Loss: 0.6531, Val Loss: 0.8126, F1 Micro: 0.4916, F1 Macro: 0.4620, Accuracy: 0.4916\n","Epoch 25, Train Loss: 0.7109, Val Loss: 0.6403, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 26, Train Loss: 0.6551, Val Loss: 0.6571, F1 Micro: 0.6927, F1 Macro: 0.5533, Accuracy: 0.6927\n","Epoch 27, Train Loss: 0.6425, Val Loss: 0.6528, F1 Micro: 0.6760, F1 Macro: 0.6474, Accuracy: 0.6760\n","Epoch 28, Train Loss: 0.6772, Val Loss: 0.6470, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 29, Train Loss: 0.6726, Val Loss: 0.6520, F1 Micro: 0.6536, F1 Macro: 0.6010, Accuracy: 0.6536\n","Epoch 30, Train Loss: 0.6633, Val Loss: 0.6378, F1 Micro: 0.7095, F1 Macro: 0.6622, Accuracy: 0.7095\n","Epoch 31, Train Loss: 0.6491, Val Loss: 0.6502, F1 Micro: 0.6704, F1 Macro: 0.6221, Accuracy: 0.6704\n","Epoch 32, Train Loss: 0.6569, Val Loss: 0.6776, F1 Micro: 0.6648, F1 Macro: 0.5409, Accuracy: 0.6648\n","Epoch 33, Train Loss: 0.6495, Val Loss: 0.7139, F1 Micro: 0.6872, F1 Macro: 0.5410, Accuracy: 0.6872\n","Epoch 34, Train Loss: 0.6656, Val Loss: 0.6377, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 35, Train Loss: 0.6667, Val Loss: 0.6463, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 36, Train Loss: 0.6487, Val Loss: 0.7197, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 37, Train Loss: 0.6603, Val Loss: 0.6386, F1 Micro: 0.7263, F1 Macro: 0.6579, Accuracy: 0.7263\n","Epoch 38, Train Loss: 0.6674, Val Loss: 0.6432, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 39, Train Loss: 0.6474, Val Loss: 0.6806, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 40, Train Loss: 0.6651, Val Loss: 0.6757, F1 Micro: 0.6145, F1 Macro: 0.5693, Accuracy: 0.6145\n","Epoch 41, Train Loss: 0.6691, Val Loss: 0.6713, F1 Micro: 0.6816, F1 Macro: 0.5530, Accuracy: 0.6816\n","Epoch 42, Train Loss: 0.6758, Val Loss: 0.8545, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 43, Train Loss: 0.6620, Val Loss: 0.6503, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 44, Train Loss: 0.6735, Val Loss: 0.6479, F1 Micro: 0.6927, F1 Macro: 0.6252, Accuracy: 0.6927\n","Epoch 45, Train Loss: 0.6597, Val Loss: 0.6462, F1 Micro: 0.6816, F1 Macro: 0.5530, Accuracy: 0.6816\n","Epoch 46, Train Loss: 0.6629, Val Loss: 0.6769, F1 Micro: 0.6089, F1 Macro: 0.5744, Accuracy: 0.6089\n","Epoch 47, Train Loss: 0.6844, Val Loss: 0.6399, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 48, Train Loss: 0.6755, Val Loss: 0.6329, F1 Micro: 0.7151, F1 Macro: 0.6564, Accuracy: 0.7151\n","Epoch 49, Train Loss: 0.6515, Val Loss: 0.6926, F1 Micro: 0.6034, F1 Macro: 0.5753, Accuracy: 0.6034\n","Epoch 50, Train Loss: 0.6509, Val Loss: 0.6384, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 51, Train Loss: 0.7139, Val Loss: 0.6889, F1 Micro: 0.6034, F1 Macro: 0.5866, Accuracy: 0.6034\n","Epoch 52, Train Loss: 0.6760, Val Loss: 0.6573, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 53, Train Loss: 0.6563, Val Loss: 0.6554, F1 Micro: 0.6872, F1 Macro: 0.5493, Accuracy: 0.6872\n","Epoch 54, Train Loss: 0.6701, Val Loss: 0.6413, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 55, Train Loss: 0.6483, Val Loss: 0.6397, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 56, Train Loss: 0.6396, Val Loss: 0.6818, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 57, Train Loss: 0.6458, Val Loss: 0.6299, F1 Micro: 0.7207, F1 Macro: 0.6393, Accuracy: 0.7207\n","Epoch 58, Train Loss: 0.6606, Val Loss: 0.6549, F1 Micro: 0.6648, F1 Macro: 0.6174, Accuracy: 0.6648\n","Epoch 59, Train Loss: 0.6590, Val Loss: 0.6617, F1 Micro: 0.6034, F1 Macro: 0.5802, Accuracy: 0.6034\n","Epoch 60, Train Loss: 0.6579, Val Loss: 0.6447, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 61, Train Loss: 0.6546, Val Loss: 0.6348, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 62, Train Loss: 0.6477, Val Loss: 0.6394, F1 Micro: 0.6760, F1 Macro: 0.5630, Accuracy: 0.6760\n","Epoch 63, Train Loss: 0.6619, Val Loss: 0.6387, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 64, Train Loss: 0.6547, Val Loss: 0.6518, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 65, Train Loss: 0.6670, Val Loss: 0.6472, F1 Micro: 0.6480, F1 Macro: 0.6208, Accuracy: 0.6480\n","Epoch 66, Train Loss: 0.6759, Val Loss: 0.6652, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 67, Train Loss: 0.7233, Val Loss: 0.7035, F1 Micro: 0.6034, F1 Macro: 0.5753, Accuracy: 0.6034\n","Epoch 68, Train Loss: 0.7262, Val Loss: 0.6399, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 69, Train Loss: 0.6596, Val Loss: 0.6569, F1 Micro: 0.6536, F1 Macro: 0.6256, Accuracy: 0.6536\n","Epoch 70, Train Loss: 0.6584, Val Loss: 0.6545, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 71, Train Loss: 0.6460, Val Loss: 0.6371, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 72, Train Loss: 0.6675, Val Loss: 0.6422, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 73, Train Loss: 0.6517, Val Loss: 0.6303, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 74, Train Loss: 0.6585, Val Loss: 0.6651, F1 Micro: 0.6480, F1 Macro: 0.6275, Accuracy: 0.6480\n","Epoch 75, Train Loss: 0.6490, Val Loss: 0.6416, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 76, Train Loss: 0.6485, Val Loss: 0.6780, F1 Micro: 0.6872, F1 Macro: 0.5493, Accuracy: 0.6872\n","Epoch 77, Train Loss: 0.6932, Val Loss: 0.8957, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 78, Train Loss: 0.7402, Val Loss: 0.6505, F1 Micro: 0.6927, F1 Macro: 0.5612, Accuracy: 0.6927\n","Epoch 79, Train Loss: 0.6645, Val Loss: 0.6466, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 80, Train Loss: 0.6685, Val Loss: 0.6495, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 81, Train Loss: 0.6354, Val Loss: 0.6373, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 82, Train Loss: 0.6555, Val Loss: 0.6607, F1 Micro: 0.6145, F1 Macro: 0.5943, Accuracy: 0.6145\n","Epoch 83, Train Loss: 0.6397, Val Loss: 0.7232, F1 Micro: 0.5810, F1 Macro: 0.5566, Accuracy: 0.5810\n","Epoch 84, Train Loss: 0.6664, Val Loss: 0.6506, F1 Micro: 0.6425, F1 Macro: 0.6160, Accuracy: 0.6425\n","Epoch 85, Train Loss: 0.6462, Val Loss: 0.6789, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 86, Train Loss: 0.6617, Val Loss: 0.7073, F1 Micro: 0.6536, F1 Macro: 0.4495, Accuracy: 0.6536\n","Epoch 87, Train Loss: 0.7379, Val Loss: 0.6523, F1 Micro: 0.6425, F1 Macro: 0.6183, Accuracy: 0.6425\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7730, Val Loss: 0.6700, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6759, Val Loss: 0.6563, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6753, Val Loss: 0.6581, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 4, Train Loss: 0.6843, Val Loss: 0.6381, F1 Micro: 0.6629, F1 Macro: 0.4665, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6920, Val Loss: 0.6481, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.7007, Val Loss: 0.8256, F1 Micro: 0.2921, F1 Macro: 0.2653, Accuracy: 0.2921\n","Epoch 7, Train Loss: 0.6927, Val Loss: 0.6417, F1 Micro: 0.6404, F1 Macro: 0.4048, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6851, Val Loss: 0.6508, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6907, Val Loss: 0.6009, F1 Micro: 0.7360, F1 Macro: 0.6368, Accuracy: 0.7360\n","Epoch 10, Train Loss: 0.6789, Val Loss: 0.6859, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.7287, Val Loss: 0.7137, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.6776, Val Loss: 0.6908, F1 Micro: 0.5056, F1 Macro: 0.5025, Accuracy: 0.5056\n","Epoch 13, Train Loss: 0.6741, Val Loss: 0.6199, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6758, Val Loss: 0.6007, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 15, Train Loss: 0.6765, Val Loss: 0.6086, F1 Micro: 0.7079, F1 Macro: 0.6384, Accuracy: 0.7079\n","Epoch 16, Train Loss: 0.6846, Val Loss: 0.6037, F1 Micro: 0.7079, F1 Macro: 0.6014, Accuracy: 0.7079\n","Epoch 17, Train Loss: 0.6640, Val Loss: 0.6099, F1 Micro: 0.6798, F1 Macro: 0.5277, Accuracy: 0.6798\n","Epoch 18, Train Loss: 0.6649, Val Loss: 0.5866, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 19, Train Loss: 0.6909, Val Loss: 0.6723, F1 Micro: 0.5562, F1 Macro: 0.5561, Accuracy: 0.5562\n","Epoch 20, Train Loss: 0.7356, Val Loss: 0.6320, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 21, Train Loss: 0.7011, Val Loss: 0.7243, F1 Micro: 0.5056, F1 Macro: 0.4912, Accuracy: 0.5056\n","Epoch 22, Train Loss: 0.6861, Val Loss: 0.5847, F1 Micro: 0.7191, F1 Macro: 0.6336, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6478, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 24, Train Loss: 0.6708, Val Loss: 0.6320, F1 Micro: 0.7079, F1 Macro: 0.5880, Accuracy: 0.7079\n","Epoch 25, Train Loss: 0.6782, Val Loss: 0.5956, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 26, Train Loss: 0.6537, Val Loss: 0.6720, F1 Micro: 0.5281, F1 Macro: 0.5102, Accuracy: 0.5281\n","Epoch 27, Train Loss: 0.6533, Val Loss: 0.5737, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 28, Train Loss: 0.6547, Val Loss: 0.5997, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 29, Train Loss: 0.6567, Val Loss: 0.6380, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6584, Val Loss: 0.6260, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 31, Train Loss: 0.6646, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6890, Val Loss: 0.6248, F1 Micro: 0.6854, F1 Macro: 0.5486, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.7555, Val Loss: 0.5802, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 34, Train Loss: 0.7581, Val Loss: 0.6901, F1 Micro: 0.5112, F1 Macro: 0.4892, Accuracy: 0.5112\n","Epoch 35, Train Loss: 0.7168, Val Loss: 0.6102, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 36, Train Loss: 0.6685, Val Loss: 0.6202, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6515, Val Loss: 0.5766, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 38, Train Loss: 0.6424, Val Loss: 0.6287, F1 Micro: 0.6742, F1 Macro: 0.5053, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6556, Val Loss: 0.5801, F1 Micro: 0.7135, F1 Macro: 0.6288, Accuracy: 0.7135\n","Epoch 40, Train Loss: 0.6414, Val Loss: 0.5969, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 41, Train Loss: 0.6496, Val Loss: 0.6070, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 42, Train Loss: 0.6624, Val Loss: 0.5687, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 43, Train Loss: 0.6798, Val Loss: 0.5822, F1 Micro: 0.7360, F1 Macro: 0.6626, Accuracy: 0.7360\n","Epoch 44, Train Loss: 0.6577, Val Loss: 0.6125, F1 Micro: 0.6685, F1 Macro: 0.4917, Accuracy: 0.6685\n","Epoch 45, Train Loss: 0.7175, Val Loss: 0.7480, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.7862, Val Loss: 0.5714, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 47, Train Loss: 0.6928, Val Loss: 0.6313, F1 Micro: 0.6685, F1 Macro: 0.6629, Accuracy: 0.6685\n","Epoch 48, Train Loss: 0.7045, Val Loss: 0.6425, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.7186, Val Loss: 0.7076, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 50, Train Loss: 0.6943, Val Loss: 0.5890, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 51, Train Loss: 0.6500, Val Loss: 0.5904, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 52, Train Loss: 0.6496, Val Loss: 0.5870, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 53, Train Loss: 0.6485, Val Loss: 0.5844, F1 Micro: 0.7360, F1 Macro: 0.6425, Accuracy: 0.7360\n","Epoch 54, Train Loss: 0.6607, Val Loss: 0.6052, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 55, Train Loss: 0.6554, Val Loss: 0.5714, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 56, Train Loss: 0.6497, Val Loss: 0.6022, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 57, Train Loss: 0.6448, Val Loss: 0.6767, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 58, Train Loss: 0.6494, Val Loss: 0.6041, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 59, Train Loss: 0.6352, Val Loss: 0.5632, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 60, Train Loss: 0.6459, Val Loss: 0.5827, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 61, Train Loss: 0.6547, Val Loss: 0.6158, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 62, Train Loss: 0.6835, Val Loss: 0.5898, F1 Micro: 0.7416, F1 Macro: 0.6675, Accuracy: 0.7416\n","Epoch 63, Train Loss: 0.6466, Val Loss: 0.6074, F1 Micro: 0.6966, F1 Macro: 0.6837, Accuracy: 0.6966\n","Epoch 64, Train Loss: 0.6461, Val Loss: 0.6075, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 65, Train Loss: 0.6517, Val Loss: 0.5692, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 66, Train Loss: 0.6678, Val Loss: 0.5825, F1 Micro: 0.6910, F1 Macro: 0.5817, Accuracy: 0.6910\n","Epoch 67, Train Loss: 0.6739, Val Loss: 0.6079, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 68, Train Loss: 0.6906, Val Loss: 0.5649, F1 Micro: 0.7416, F1 Macro: 0.6762, Accuracy: 0.7416\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7219, Val Loss: 0.7297, F1 Micro: 0.3427, F1 Macro: 0.2733, Accuracy: 0.3427\n","Epoch 2, Train Loss: 0.6916, Val Loss: 0.6673, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6951, Val Loss: 0.6755, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6808, Val Loss: 0.6843, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6865, Val Loss: 0.6961, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.7453, Val Loss: 0.6743, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6972, Val Loss: 0.6730, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6799, Val Loss: 0.6963, F1 Micro: 0.5056, F1 Macro: 0.5056, Accuracy: 0.5056\n","Epoch 9, Train Loss: 0.6748, Val Loss: 0.7197, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.7080, Val Loss: 0.6573, F1 Micro: 0.6011, F1 Macro: 0.5353, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6829, Val Loss: 0.7327, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6993, Val Loss: 0.6566, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.7239, Val Loss: 0.6883, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6975, Val Loss: 0.6734, F1 Micro: 0.6124, F1 Macro: 0.5231, Accuracy: 0.6124\n","Epoch 15, Train Loss: 0.6969, Val Loss: 0.9305, F1 Micro: 0.4607, F1 Macro: 0.4523, Accuracy: 0.4607\n","Epoch 16, Train Loss: 0.6915, Val Loss: 0.6491, F1 Micro: 0.6236, F1 Macro: 0.4550, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6756, Val Loss: 0.6433, F1 Micro: 0.6124, F1 Macro: 0.5047, Accuracy: 0.6124\n","Epoch 18, Train Loss: 0.6537, Val Loss: 0.6343, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.7283, Val Loss: 0.6276, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6860, Val Loss: 0.6655, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 21, Train Loss: 0.6658, Val Loss: 0.6696, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.6661, Val Loss: 0.6843, F1 Micro: 0.6404, F1 Macro: 0.4429, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6618, Val Loss: 0.7267, F1 Micro: 0.6404, F1 Macro: 0.6123, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.7224, Val Loss: 0.6734, F1 Micro: 0.6461, F1 Macro: 0.5876, Accuracy: 0.6461\n","Epoch 25, Train Loss: 0.6783, Val Loss: 0.7549, F1 Micro: 0.6404, F1 Macro: 0.4310, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.7401, Val Loss: 0.6501, F1 Micro: 0.6180, F1 Macro: 0.4787, Accuracy: 0.6180\n","Epoch 27, Train Loss: 0.7059, Val Loss: 0.6422, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 28, Train Loss: 0.6777, Val Loss: 0.6593, F1 Micro: 0.6292, F1 Macro: 0.5465, Accuracy: 0.6292\n","Epoch 29, Train Loss: 0.6678, Val Loss: 0.8755, F1 Micro: 0.4270, F1 Macro: 0.4102, Accuracy: 0.4270\n","Epoch 30, Train Loss: 0.7271, Val Loss: 0.7476, F1 Micro: 0.3764, F1 Macro: 0.3052, Accuracy: 0.3764\n","Epoch 31, Train Loss: 0.6960, Val Loss: 0.6260, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 32, Train Loss: 0.6579, Val Loss: 0.6234, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.6481, Val Loss: 0.6534, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 34, Train Loss: 0.6522, Val Loss: 0.6738, F1 Micro: 0.6573, F1 Macro: 0.6525, Accuracy: 0.6573\n","Epoch 35, Train Loss: 0.6782, Val Loss: 0.6432, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 36, Train Loss: 0.6438, Val Loss: 0.6543, F1 Micro: 0.6236, F1 Macro: 0.5369, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6885, Val Loss: 0.6761, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 38, Train Loss: 0.6699, Val Loss: 0.7440, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6687, Val Loss: 0.6418, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.7424, Val Loss: 0.6479, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 41, Train Loss: 0.6639, Val Loss: 0.6440, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6625, Val Loss: 0.6436, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.6600, Val Loss: 0.6302, F1 Micro: 0.6236, F1 Macro: 0.5253, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6468, Val Loss: 0.6389, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 45, Train Loss: 0.6669, Val Loss: 0.6643, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.6632, Val Loss: 0.6612, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6482, Val Loss: 0.6276, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 48, Train Loss: 0.6788, Val Loss: 0.6403, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 49, Train Loss: 0.7423, Val Loss: 0.6540, F1 Micro: 0.6292, F1 Macro: 0.4771, Accuracy: 0.6292\n","Epoch 50, Train Loss: 0.7612, Val Loss: 0.6574, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 51, Train Loss: 0.6582, Val Loss: 0.6529, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 52, Train Loss: 0.6490, Val Loss: 0.6275, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 53, Train Loss: 0.6469, Val Loss: 0.6708, F1 Micro: 0.6517, F1 Macro: 0.6463, Accuracy: 0.6517\n","Epoch 54, Train Loss: 0.6573, Val Loss: 0.6522, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 55, Train Loss: 0.6443, Val Loss: 0.8362, F1 Micro: 0.6348, F1 Macro: 0.4282, Accuracy: 0.6348\n","Epoch 56, Train Loss: 0.6724, Val Loss: 0.6805, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 57, Train Loss: 0.6537, Val Loss: 0.6484, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 58, Train Loss: 0.6647, Val Loss: 0.6260, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 59, Train Loss: 0.6537, Val Loss: 0.6494, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 60, Train Loss: 0.7287, Val Loss: 0.6858, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 61, Train Loss: 0.6527, Val Loss: 0.6248, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.6392, Val Loss: 0.7397, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 63, Train Loss: 0.6594, Val Loss: 0.7347, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 64, Train Loss: 0.6720, Val Loss: 0.6794, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 65, Train Loss: 0.7040, Val Loss: 0.6504, F1 Micro: 0.6966, F1 Macro: 0.6805, Accuracy: 0.6966\n","Epoch 66, Train Loss: 0.6565, Val Loss: 0.6424, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 67, Train Loss: 0.6447, Val Loss: 0.6483, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 68, Train Loss: 0.6450, Val Loss: 0.6684, F1 Micro: 0.6517, F1 Macro: 0.6452, Accuracy: 0.6517\n","Epoch 69, Train Loss: 0.7228, Val Loss: 0.6721, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 70, Train Loss: 0.7090, Val Loss: 0.6560, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 71, Train Loss: 0.6519, Val Loss: 0.6326, F1 Micro: 0.6404, F1 Macro: 0.5747, Accuracy: 0.6404\n","Epoch 72, Train Loss: 0.6598, Val Loss: 0.8426, F1 Micro: 0.4888, F1 Macro: 0.4785, Accuracy: 0.4888\n","Epoch 73, Train Loss: 0.6722, Val Loss: 0.7076, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 74, Train Loss: 0.6966, Val Loss: 0.6561, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.6956, Val Loss: 0.6368, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 76, Train Loss: 0.6320, Val Loss: 0.6493, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 77, Train Loss: 0.6650, Val Loss: 0.6248, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 78, Train Loss: 0.6654, Val Loss: 0.6539, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 79, Train Loss: 0.6450, Val Loss: 0.6284, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.6470, Val Loss: 0.6293, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 81, Train Loss: 0.6357, Val Loss: 0.6869, F1 Micro: 0.6348, F1 Macro: 0.4282, Accuracy: 0.6348\n","Epoch 82, Train Loss: 0.6550, Val Loss: 0.6225, F1 Micro: 0.6404, F1 Macro: 0.5908, Accuracy: 0.6404\n","Epoch 83, Train Loss: 0.6538, Val Loss: 0.6629, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 84, Train Loss: 0.6589, Val Loss: 0.6446, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Epoch 85, Train Loss: 0.7172, Val Loss: 0.8811, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 86, Train Loss: 0.6763, Val Loss: 0.8692, F1 Micro: 0.4213, F1 Macro: 0.4077, Accuracy: 0.4213\n","Epoch 87, Train Loss: 0.7189, Val Loss: 0.6469, F1 Micro: 0.6404, F1 Macro: 0.5747, Accuracy: 0.6404\n","Epoch 88, Train Loss: 0.6684, Val Loss: 0.6809, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 89, Train Loss: 0.6462, Val Loss: 0.6198, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 90, Train Loss: 0.6261, Val Loss: 0.6873, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 91, Train Loss: 0.6420, Val Loss: 0.6635, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 92, Train Loss: 0.6591, Val Loss: 0.6688, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 93, Train Loss: 0.6715, Val Loss: 0.8505, F1 Micro: 0.3708, F1 Macro: 0.2705, Accuracy: 0.3708\n","Epoch 94, Train Loss: 0.6532, Val Loss: 0.6340, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 95, Train Loss: 0.6485, Val Loss: 0.6227, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 96, Train Loss: 0.6719, Val Loss: 0.6289, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 97, Train Loss: 0.6682, Val Loss: 0.6599, F1 Micro: 0.6180, F1 Macro: 0.5016, Accuracy: 0.6180\n","Epoch 98, Train Loss: 0.6562, Val Loss: 0.6331, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 99, Train Loss: 0.6561, Val Loss: 0.6621, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 100, Train Loss: 0.6992, Val Loss: 0.8535, F1 Micro: 0.4888, F1 Macro: 0.4887, Accuracy: 0.4888\n","Epoch 101, Train Loss: 0.6680, Val Loss: 0.6568, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 102, Train Loss: 0.6448, Val Loss: 0.7652, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 103, Train Loss: 0.6921, Val Loss: 0.6753, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 104, Train Loss: 0.6552, Val Loss: 0.6746, F1 Micro: 0.6517, F1 Macro: 0.6488, Accuracy: 0.6517\n","Epoch 105, Train Loss: 0.6693, Val Loss: 0.6277, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 106, Train Loss: 0.6330, Val Loss: 0.6966, F1 Micro: 0.6124, F1 Macro: 0.4831, Accuracy: 0.6124\n","Epoch 107, Train Loss: 0.6771, Val Loss: 0.6509, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 108, Train Loss: 0.6438, Val Loss: 0.6450, F1 Micro: 0.6292, F1 Macro: 0.4679, Accuracy: 0.6292\n","Epoch 109, Train Loss: 0.6614, Val Loss: 0.7366, F1 Micro: 0.5169, F1 Macro: 0.5129, Accuracy: 0.5169\n","Epoch 110, Train Loss: 0.6515, Val Loss: 0.6182, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 111, Train Loss: 0.6456, Val Loss: 0.6259, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 112, Train Loss: 0.6365, Val Loss: 0.6773, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 113, Train Loss: 0.6616, Val Loss: 0.6588, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 114, Train Loss: 0.6593, Val Loss: 0.6359, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 115, Train Loss: 0.6516, Val Loss: 0.6492, F1 Micro: 0.6742, F1 Macro: 0.6646, Accuracy: 0.6742\n","Epoch 116, Train Loss: 0.6693, Val Loss: 0.6363, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 117, Train Loss: 0.6654, Val Loss: 0.6289, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 118, Train Loss: 0.6845, Val Loss: 0.6596, F1 Micro: 0.6742, F1 Macro: 0.6633, Accuracy: 0.6742\n","Epoch 119, Train Loss: 0.6868, Val Loss: 0.6600, F1 Micro: 0.6798, F1 Macro: 0.6710, Accuracy: 0.6798\n","Epoch 120, Train Loss: 0.6916, Val Loss: 0.6770, F1 Micro: 0.6292, F1 Macro: 0.6245, Accuracy: 0.6292\n","Epoch 121, Train Loss: 0.6720, Val Loss: 0.6323, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 122, Train Loss: 0.6452, Val Loss: 0.6414, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 123, Train Loss: 0.6296, Val Loss: 0.8087, F1 Micro: 0.4775, F1 Macro: 0.4512, Accuracy: 0.4775\n","Epoch 124, Train Loss: 0.6480, Val Loss: 0.9656, F1 Micro: 0.3933, F1 Macro: 0.3318, Accuracy: 0.3933\n","Epoch 125, Train Loss: 0.6551, Val Loss: 0.7389, F1 Micro: 0.5562, F1 Macro: 0.5562, Accuracy: 0.5562\n","Epoch 126, Train Loss: 0.6594, Val Loss: 0.6391, F1 Micro: 0.6292, F1 Macro: 0.5742, Accuracy: 0.6292\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7044, Val Loss: 0.7072, F1 Micro: 0.4213, F1 Macro: 0.4132, Accuracy: 0.4213\n","Epoch 2, Train Loss: 0.6868, Val Loss: 0.7887, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6922, Val Loss: 0.7057, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 4, Train Loss: 0.6888, Val Loss: 0.7557, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6907, Val Loss: 1.2657, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.7408, Val Loss: 0.7196, F1 Micro: 0.5449, F1 Macro: 0.4333, Accuracy: 0.5449\n","Epoch 7, Train Loss: 0.7017, Val Loss: 0.6880, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 8, Train Loss: 0.6763, Val Loss: 0.7212, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6656, Val Loss: 0.8023, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6803, Val Loss: 0.7303, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6842, Val Loss: 0.7682, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6837, Val Loss: 0.7522, F1 Micro: 0.5506, F1 Macro: 0.5497, Accuracy: 0.5506\n","Epoch 13, Train Loss: 0.7394, Val Loss: 0.7503, F1 Micro: 0.4719, F1 Macro: 0.3542, Accuracy: 0.4719\n","Epoch 14, Train Loss: 0.7207, Val Loss: 0.7105, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6738, Val Loss: 0.7005, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6749, Val Loss: 0.7431, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6708, Val Loss: 0.7376, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6777, Val Loss: 0.7182, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 19, Train Loss: 0.6824, Val Loss: 0.7215, F1 Micro: 0.5618, F1 Macro: 0.5360, Accuracy: 0.5618\n","Epoch 20, Train Loss: 0.6783, Val Loss: 0.6946, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6713, Val Loss: 0.6810, F1 Micro: 0.6124, F1 Macro: 0.6114, Accuracy: 0.6124\n","Epoch 22, Train Loss: 0.7089, Val Loss: 0.7507, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 23, Train Loss: 0.6873, Val Loss: 0.7585, F1 Micro: 0.4494, F1 Macro: 0.4424, Accuracy: 0.4494\n","Epoch 24, Train Loss: 0.6968, Val Loss: 0.7626, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.7057, Val Loss: 0.7581, F1 Micro: 0.5618, F1 Macro: 0.4363, Accuracy: 0.5618\n","Epoch 26, Train Loss: 0.7298, Val Loss: 0.6947, F1 Micro: 0.5506, F1 Macro: 0.5459, Accuracy: 0.5506\n","Epoch 27, Train Loss: 0.7156, Val Loss: 0.7878, F1 Micro: 0.4382, F1 Macro: 0.3487, Accuracy: 0.4382\n","Epoch 28, Train Loss: 0.7326, Val Loss: 0.8082, F1 Micro: 0.4719, F1 Macro: 0.3206, Accuracy: 0.4719\n","Epoch 29, Train Loss: 0.7339, Val Loss: 0.8509, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 30, Train Loss: 0.7523, Val Loss: 0.7892, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6825, Val Loss: 0.7325, F1 Micro: 0.4157, F1 Macro: 0.3290, Accuracy: 0.4157\n","Epoch 32, Train Loss: 0.7006, Val Loss: 0.7328, F1 Micro: 0.5618, F1 Macro: 0.4363, Accuracy: 0.5618\n","Epoch 33, Train Loss: 0.6793, Val Loss: 0.7676, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 34, Train Loss: 0.7101, Val Loss: 0.7848, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6785, Val Loss: 0.6788, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 36, Train Loss: 0.6722, Val Loss: 0.7751, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6750, Val Loss: 0.6938, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 38, Train Loss: 0.6786, Val Loss: 0.7025, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 39, Train Loss: 0.6599, Val Loss: 0.8649, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6967, Val Loss: 0.7767, F1 Micro: 0.3933, F1 Macro: 0.3457, Accuracy: 0.3933\n","Epoch 41, Train Loss: 0.7228, Val Loss: 0.8632, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 42, Train Loss: 0.6603, Val Loss: 0.7992, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 43, Train Loss: 0.6718, Val Loss: 0.6765, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 44, Train Loss: 0.6807, Val Loss: 0.9069, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 45, Train Loss: 0.6746, Val Loss: 0.7620, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 46, Train Loss: 0.6721, Val Loss: 0.6677, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6651, Val Loss: 0.7094, F1 Micro: 0.5674, F1 Macro: 0.4909, Accuracy: 0.5674\n","Epoch 48, Train Loss: 0.6771, Val Loss: 0.6924, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6553, Val Loss: 0.6764, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 50, Train Loss: 0.7007, Val Loss: 0.7682, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 51, Train Loss: 0.6833, Val Loss: 0.6765, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 52, Train Loss: 0.6521, Val Loss: 0.7834, F1 Micro: 0.5674, F1 Macro: 0.4740, Accuracy: 0.5674\n","Epoch 53, Train Loss: 0.6525, Val Loss: 0.7314, F1 Micro: 0.5955, F1 Macro: 0.5545, Accuracy: 0.5955\n","Epoch 54, Train Loss: 0.6490, Val Loss: 0.6494, F1 Micro: 0.6742, F1 Macro: 0.6568, Accuracy: 0.6742\n","Epoch 55, Train Loss: 0.6483, Val Loss: 0.6501, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 56, Train Loss: 0.6499, Val Loss: 0.7102, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 57, Train Loss: 0.6506, Val Loss: 0.7089, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 58, Train Loss: 0.6705, Val Loss: 0.9050, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 59, Train Loss: 0.6426, Val Loss: 0.6526, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 60, Train Loss: 0.6200, Val Loss: 0.7202, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 61, Train Loss: 0.6282, Val Loss: 0.7374, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 62, Train Loss: 0.6492, Val Loss: 0.7582, F1 Micro: 0.5562, F1 Macro: 0.4251, Accuracy: 0.5562\n","Epoch 63, Train Loss: 0.6445, Val Loss: 0.6546, F1 Micro: 0.6573, F1 Macro: 0.6504, Accuracy: 0.6573\n","Epoch 64, Train Loss: 0.6425, Val Loss: 0.6954, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 65, Train Loss: 0.7186, Val Loss: 0.7248, F1 Micro: 0.4944, F1 Macro: 0.3955, Accuracy: 0.4944\n","Epoch 66, Train Loss: 0.6427, Val Loss: 0.6600, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 67, Train Loss: 0.6674, Val Loss: 0.7181, F1 Micro: 0.5787, F1 Macro: 0.4753, Accuracy: 0.5787\n","Epoch 68, Train Loss: 0.6712, Val Loss: 0.6679, F1 Micro: 0.6180, F1 Macro: 0.6121, Accuracy: 0.6180\n","Epoch 69, Train Loss: 0.6407, Val Loss: 0.6758, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 70, Train Loss: 0.6516, Val Loss: 0.8642, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 71, Train Loss: 0.6422, Val Loss: 0.6604, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 72, Train Loss: 0.6486, Val Loss: 0.7139, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 73, Train Loss: 0.6668, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 74, Train Loss: 0.6797, Val Loss: 0.7561, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 75, Train Loss: 0.6613, Val Loss: 0.6890, F1 Micro: 0.5449, F1 Macro: 0.5372, Accuracy: 0.5449\n","Epoch 76, Train Loss: 0.6494, Val Loss: 0.7874, F1 Micro: 0.5730, F1 Macro: 0.5141, Accuracy: 0.5730\n","Epoch 77, Train Loss: 0.6901, Val Loss: 0.6760, F1 Micro: 0.5618, F1 Macro: 0.5550, Accuracy: 0.5618\n","Epoch 78, Train Loss: 0.6701, Val Loss: 0.7478, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 79, Train Loss: 0.6610, Val Loss: 0.7703, F1 Micro: 0.4719, F1 Macro: 0.3686, Accuracy: 0.4719\n","Epoch 80, Train Loss: 0.6682, Val Loss: 0.7447, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 81, Train Loss: 0.6328, Val Loss: 0.8531, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 82, Train Loss: 0.6381, Val Loss: 0.7464, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 83, Train Loss: 0.6372, Val Loss: 0.6465, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 84, Train Loss: 0.6252, Val Loss: 0.6765, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 85, Train Loss: 0.6519, Val Loss: 0.6791, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 86, Train Loss: 0.6632, Val Loss: 0.6559, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 87, Train Loss: 0.6615, Val Loss: 0.6553, F1 Micro: 0.6067, F1 Macro: 0.5982, Accuracy: 0.6067\n","Epoch 88, Train Loss: 0.6700, Val Loss: 0.6466, F1 Micro: 0.6348, F1 Macro: 0.6262, Accuracy: 0.6348\n","Epoch 89, Train Loss: 0.6674, Val Loss: 0.6378, F1 Micro: 0.6348, F1 Macro: 0.6347, Accuracy: 0.6348\n","Epoch 90, Train Loss: 0.6525, Val Loss: 0.7163, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 91, Train Loss: 0.6459, Val Loss: 0.6640, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 92, Train Loss: 0.6454, Val Loss: 0.6546, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 93, Train Loss: 0.6642, Val Loss: 0.6752, F1 Micro: 0.5730, F1 Macro: 0.5332, Accuracy: 0.5730\n","Epoch 94, Train Loss: 0.6519, Val Loss: 0.6998, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 95, Train Loss: 0.6567, Val Loss: 0.6352, F1 Micro: 0.6966, F1 Macro: 0.6878, Accuracy: 0.6966\n","Epoch 96, Train Loss: 0.6747, Val Loss: 0.7805, F1 Micro: 0.5787, F1 Macro: 0.5266, Accuracy: 0.5787\n","Epoch 97, Train Loss: 0.7294, Val Loss: 0.6500, F1 Micro: 0.6517, F1 Macro: 0.6481, Accuracy: 0.6517\n","Epoch 98, Train Loss: 0.6789, Val Loss: 0.6502, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 99, Train Loss: 0.6485, Val Loss: 0.6880, F1 Micro: 0.6292, F1 Macro: 0.5780, Accuracy: 0.6292\n","Epoch 100, Train Loss: 0.6497, Val Loss: 0.6557, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 101, Train Loss: 0.6345, Val Loss: 0.7026, F1 Micro: 0.5787, F1 Macro: 0.5183, Accuracy: 0.5787\n","Epoch 102, Train Loss: 0.6475, Val Loss: 0.6407, F1 Micro: 0.6573, F1 Macro: 0.6480, Accuracy: 0.6573\n","Epoch 103, Train Loss: 0.6363, Val Loss: 0.7724, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 104, Train Loss: 0.6339, Val Loss: 0.6704, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 105, Train Loss: 0.6287, Val Loss: 0.9199, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 106, Train Loss: 0.6416, Val Loss: 0.6766, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 107, Train Loss: 0.6505, Val Loss: 0.6765, F1 Micro: 0.5618, F1 Macro: 0.5522, Accuracy: 0.5618\n","Epoch 108, Train Loss: 0.6680, Val Loss: 0.7371, F1 Micro: 0.5674, F1 Macro: 0.5009, Accuracy: 0.5674\n","Epoch 109, Train Loss: 0.6282, Val Loss: 0.8660, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 110, Train Loss: 0.6515, Val Loss: 0.7916, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 111, Train Loss: 0.6443, Val Loss: 0.7744, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 112, Train Loss: 0.6429, Val Loss: 0.7236, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 113, Train Loss: 0.6399, Val Loss: 0.9665, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 114, Train Loss: 0.6358, Val Loss: 0.6517, F1 Micro: 0.6067, F1 Macro: 0.6027, Accuracy: 0.6067\n","Epoch 115, Train Loss: 0.6458, Val Loss: 0.6815, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 116, Train Loss: 0.6409, Val Loss: 0.6886, F1 Micro: 0.6180, F1 Macro: 0.6121, Accuracy: 0.6180\n","Epoch 117, Train Loss: 0.6539, Val Loss: 0.6450, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 118, Train Loss: 0.6852, Val Loss: 0.6478, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 119, Train Loss: 0.6799, Val Loss: 1.0451, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 120, Train Loss: 0.6454, Val Loss: 0.8435, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 121, Train Loss: 0.6460, Val Loss: 0.6664, F1 Micro: 0.6236, F1 Macro: 0.6209, Accuracy: 0.6236\n","Epoch 122, Train Loss: 0.6867, Val Loss: 0.6482, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 123, Train Loss: 0.6423, Val Loss: 0.6428, F1 Micro: 0.6629, F1 Macro: 0.6586, Accuracy: 0.6629\n","Epoch 124, Train Loss: 0.6338, Val Loss: 0.7751, F1 Micro: 0.5674, F1 Macro: 0.5055, Accuracy: 0.5674\n","Epoch 125, Train Loss: 0.6322, Val Loss: 0.6734, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 126, Train Loss: 0.7059, Val Loss: 0.7102, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 127, Train Loss: 0.6976, Val Loss: 0.8214, F1 Micro: 0.4831, F1 Macro: 0.3439, Accuracy: 0.4831\n","Epoch 128, Train Loss: 0.7556, Val Loss: 0.8634, F1 Micro: 0.5506, F1 Macro: 0.4137, Accuracy: 0.5506\n","Epoch 129, Train Loss: 0.6759, Val Loss: 0.7216, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 130, Train Loss: 0.6309, Val Loss: 0.6881, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 131, Train Loss: 0.6404, Val Loss: 0.6390, F1 Micro: 0.6348, F1 Macro: 0.6339, Accuracy: 0.6348\n","Epoch 132, Train Loss: 0.6394, Val Loss: 0.6902, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 133, Train Loss: 0.6233, Val Loss: 0.6483, F1 Micro: 0.6180, F1 Macro: 0.6068, Accuracy: 0.6180\n","Epoch 134, Train Loss: 0.6345, Val Loss: 0.6862, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 135, Train Loss: 0.6205, Val Loss: 0.8155, F1 Micro: 0.5562, F1 Macro: 0.4777, Accuracy: 0.5562\n","Epoch 136, Train Loss: 0.6409, Val Loss: 0.7303, F1 Micro: 0.5843, F1 Macro: 0.5082, Accuracy: 0.5843\n","Epoch 137, Train Loss: 0.6491, Val Loss: 0.7357, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 138, Train Loss: 0.6329, Val Loss: 0.6686, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 139, Train Loss: 0.6417, Val Loss: 0.6593, F1 Micro: 0.6011, F1 Macro: 0.5983, Accuracy: 0.6011\n","Epoch 140, Train Loss: 0.7033, Val Loss: 0.8180, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 141, Train Loss: 0.6491, Val Loss: 0.6658, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 142, Train Loss: 0.6375, Val Loss: 0.6357, F1 Micro: 0.6798, F1 Macro: 0.6698, Accuracy: 0.6798\n","Epoch 143, Train Loss: 0.6321, Val Loss: 0.6618, F1 Micro: 0.6124, F1 Macro: 0.5859, Accuracy: 0.6124\n","Epoch 144, Train Loss: 0.6359, Val Loss: 0.7032, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 145, Train Loss: 0.6510, Val Loss: 0.6305, F1 Micro: 0.6629, F1 Macro: 0.6619, Accuracy: 0.6629\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7316, Val Loss: 0.6878, F1 Micro: 0.5506, F1 Macro: 0.5485, Accuracy: 0.5506\n","Epoch 2, Train Loss: 0.7072, Val Loss: 0.6995, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6845, Val Loss: 0.6881, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6748, Val Loss: 0.6727, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6776, Val Loss: 0.6907, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6963, Val Loss: 0.6984, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.7004, Val Loss: 0.8905, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.7030, Val Loss: 0.6745, F1 Micro: 0.6067, F1 Macro: 0.5246, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6841, Val Loss: 0.7416, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6872, Val Loss: 0.8494, F1 Micro: 0.5674, F1 Macro: 0.4960, Accuracy: 0.5674\n","Epoch 11, Train Loss: 0.6856, Val Loss: 0.7038, F1 Micro: 0.5562, F1 Macro: 0.4777, Accuracy: 0.5562\n","Epoch 12, Train Loss: 0.6882, Val Loss: 0.7247, F1 Micro: 0.6180, F1 Macro: 0.4312, Accuracy: 0.6180\n","Epoch 13, Train Loss: 0.7009, Val Loss: 0.7076, F1 Micro: 0.5393, F1 Macro: 0.4803, Accuracy: 0.5393\n","Epoch 14, Train Loss: 0.7212, Val Loss: 0.6603, F1 Micro: 0.6348, F1 Macro: 0.5270, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6535, Val Loss: 0.7770, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6426, Val Loss: 0.7346, F1 Micro: 0.4438, F1 Macro: 0.4240, Accuracy: 0.4438\n","Epoch 17, Train Loss: 0.6705, Val Loss: 0.6482, F1 Micro: 0.6124, F1 Macro: 0.4752, Accuracy: 0.6124\n","Epoch 18, Train Loss: 0.6551, Val Loss: 0.9688, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 19, Train Loss: 0.6736, Val Loss: 0.6703, F1 Micro: 0.5899, F1 Macro: 0.5883, Accuracy: 0.5899\n","Epoch 20, Train Loss: 0.6754, Val Loss: 0.6857, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6739, Val Loss: 0.6711, F1 Micro: 0.6292, F1 Macro: 0.5567, Accuracy: 0.6292\n","Epoch 22, Train Loss: 0.6486, Val Loss: 0.6907, F1 Micro: 0.6124, F1 Macro: 0.5047, Accuracy: 0.6124\n","Epoch 23, Train Loss: 0.6500, Val Loss: 0.6491, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 24, Train Loss: 0.6820, Val Loss: 0.6390, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.7580, Val Loss: 0.7080, F1 Micro: 0.5449, F1 Macro: 0.5408, Accuracy: 0.5449\n","Epoch 26, Train Loss: 0.6929, Val Loss: 0.8975, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.7224, Val Loss: 1.0974, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 28, Train Loss: 0.6897, Val Loss: 0.6469, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6462, Val Loss: 0.7263, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 30, Train Loss: 0.6635, Val Loss: 0.6321, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 31, Train Loss: 0.6409, Val Loss: 0.6250, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 32, Train Loss: 0.6402, Val Loss: 0.6453, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 33, Train Loss: 0.6456, Val Loss: 0.6366, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6475, Val Loss: 0.6487, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 35, Train Loss: 0.6748, Val Loss: 0.6265, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 36, Train Loss: 0.6970, Val Loss: 0.7387, F1 Micro: 0.5281, F1 Macro: 0.4943, Accuracy: 0.5281\n","Epoch 37, Train Loss: 0.6773, Val Loss: 0.6395, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 38, Train Loss: 0.6876, Val Loss: 0.6279, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 39, Train Loss: 0.6493, Val Loss: 0.6679, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 40, Train Loss: 0.7083, Val Loss: 0.6257, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 41, Train Loss: 0.6897, Val Loss: 0.6275, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 42, Train Loss: 0.6550, Val Loss: 0.6563, F1 Micro: 0.6461, F1 Macro: 0.5835, Accuracy: 0.6461\n","Epoch 43, Train Loss: 0.6466, Val Loss: 0.7204, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 44, Train Loss: 0.6638, Val Loss: 0.6496, F1 Micro: 0.6180, F1 Macro: 0.6156, Accuracy: 0.6180\n","Epoch 45, Train Loss: 0.6358, Val Loss: 0.7027, F1 Micro: 0.6348, F1 Macro: 0.5202, Accuracy: 0.6348\n","Epoch 46, Train Loss: 0.6429, Val Loss: 0.6349, F1 Micro: 0.6854, F1 Macro: 0.6762, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6373, Val Loss: 0.6424, F1 Micro: 0.6629, F1 Macro: 0.6586, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6758, Val Loss: 0.6459, F1 Micro: 0.6742, F1 Macro: 0.6691, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.6842, Val Loss: 0.8564, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 50, Train Loss: 0.6963, Val Loss: 0.6641, F1 Micro: 0.6404, F1 Macro: 0.5374, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6860, Val Loss: 0.6935, F1 Micro: 0.5056, F1 Macro: 0.5016, Accuracy: 0.5056\n","Epoch 52, Train Loss: 0.6816, Val Loss: 0.7330, F1 Micro: 0.6180, F1 Macro: 0.4312, Accuracy: 0.6180\n","Epoch 53, Train Loss: 0.6602, Val Loss: 0.6321, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6291, Val Loss: 0.6305, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 55, Train Loss: 0.6545, Val Loss: 0.6263, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 56, Train Loss: 0.6503, Val Loss: 0.6272, F1 Micro: 0.7303, F1 Macro: 0.7110, Accuracy: 0.7303\n","Epoch 57, Train Loss: 0.6503, Val Loss: 0.7788, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 58, Train Loss: 0.6572, Val Loss: 1.0112, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 59, Train Loss: 0.7138, Val Loss: 0.6622, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.7653, Val Loss: 0.7975, F1 Micro: 0.5955, F1 Macro: 0.4090, Accuracy: 0.5955\n","Epoch 61, Train Loss: 0.6827, Val Loss: 0.6578, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 62, Train Loss: 0.6567, Val Loss: 0.6259, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 63, Train Loss: 0.6586, Val Loss: 0.6301, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.6447, Val Loss: 0.6699, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 65, Train Loss: 0.6643, Val Loss: 0.6613, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 66, Train Loss: 0.6469, Val Loss: 0.6297, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 67, Train Loss: 0.6610, Val Loss: 0.6384, F1 Micro: 0.6798, F1 Macro: 0.6733, Accuracy: 0.6798\n","Epoch 68, Train Loss: 0.6323, Val Loss: 0.6861, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 69, Train Loss: 0.6207, Val Loss: 0.6653, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 70, Train Loss: 0.6429, Val Loss: 0.6230, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.6456, Val Loss: 0.6371, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 72, Train Loss: 0.6457, Val Loss: 0.6652, F1 Micro: 0.5843, F1 Macro: 0.5824, Accuracy: 0.5843\n","Epoch 73, Train Loss: 0.6810, Val Loss: 0.7915, F1 Micro: 0.4157, F1 Macro: 0.3226, Accuracy: 0.4157\n","Epoch 74, Train Loss: 0.6641, Val Loss: 0.6338, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 75, Train Loss: 0.6812, Val Loss: 0.9755, F1 Micro: 0.4213, F1 Macro: 0.3258, Accuracy: 0.4213\n","Epoch 76, Train Loss: 0.7151, Val Loss: 0.6926, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 77, Train Loss: 0.6889, Val Loss: 0.6956, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 78, Train Loss: 0.6617, Val Loss: 0.6880, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 79, Train Loss: 0.6424, Val Loss: 0.6570, F1 Micro: 0.6236, F1 Macro: 0.5524, Accuracy: 0.6236\n","Epoch 80, Train Loss: 0.6440, Val Loss: 0.6249, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 81, Train Loss: 0.6694, Val Loss: 0.6213, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 82, Train Loss: 0.6700, Val Loss: 0.6269, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 83, Train Loss: 0.6452, Val Loss: 0.6262, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 84, Train Loss: 0.6292, Val Loss: 0.7063, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 85, Train Loss: 0.6748, Val Loss: 0.6898, F1 Micro: 0.5787, F1 Macro: 0.5785, Accuracy: 0.5787\n","Epoch 86, Train Loss: 0.6334, Val Loss: 0.6276, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 87, Train Loss: 0.6725, Val Loss: 0.6203, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 88, Train Loss: 0.6416, Val Loss: 0.6597, F1 Micro: 0.5899, F1 Macro: 0.5899, Accuracy: 0.5899\n","Epoch 89, Train Loss: 0.6503, Val Loss: 0.6379, F1 Micro: 0.6629, F1 Macro: 0.6594, Accuracy: 0.6629\n","Epoch 90, Train Loss: 0.6366, Val Loss: 0.6994, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 91, Train Loss: 0.6672, Val Loss: 0.6444, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 92, Train Loss: 0.6511, Val Loss: 0.6196, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 93, Train Loss: 0.6476, Val Loss: 0.6181, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 94, Train Loss: 0.6711, Val Loss: 0.6401, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 95, Train Loss: 0.7438, Val Loss: 0.7091, F1 Micro: 0.5281, F1 Macro: 0.5266, Accuracy: 0.5281\n","Epoch 96, Train Loss: 0.7120, Val Loss: 0.8739, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 97, Train Loss: 0.6887, Val Loss: 0.9427, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 98, Train Loss: 0.6739, Val Loss: 0.7565, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 99, Train Loss: 0.6671, Val Loss: 0.6366, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 100, Train Loss: 0.6489, Val Loss: 0.6217, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 101, Train Loss: 0.6490, Val Loss: 0.6287, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 102, Train Loss: 0.6557, Val Loss: 0.6379, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 103, Train Loss: 0.6491, Val Loss: 0.6614, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 104, Train Loss: 0.6550, Val Loss: 0.6499, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 105, Train Loss: 0.6391, Val Loss: 0.6185, F1 Micro: 0.7247, F1 Macro: 0.7093, Accuracy: 0.7247\n","Epoch 106, Train Loss: 0.6409, Val Loss: 0.6506, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 107, Train Loss: 0.6264, Val Loss: 0.6632, F1 Micro: 0.6236, F1 Macro: 0.5423, Accuracy: 0.6236\n","Epoch 108, Train Loss: 0.6382, Val Loss: 0.6517, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 109, Train Loss: 0.6431, Val Loss: 0.7232, F1 Micro: 0.5112, F1 Macro: 0.5067, Accuracy: 0.5112\n","Epoch 110, Train Loss: 0.6651, Val Loss: 0.6333, F1 Micro: 0.6685, F1 Macro: 0.6607, Accuracy: 0.6685\n","Epoch 111, Train Loss: 0.6400, Val Loss: 0.8072, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 112, Train Loss: 0.6641, Val Loss: 0.6665, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 113, Train Loss: 0.6651, Val Loss: 0.6327, F1 Micro: 0.6854, F1 Macro: 0.6796, Accuracy: 0.6854\n","Epoch 114, Train Loss: 0.6311, Val Loss: 0.6799, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 115, Train Loss: 0.6748, Val Loss: 1.0487, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 116, Train Loss: 0.6481, Val Loss: 0.6300, F1 Micro: 0.6742, F1 Macro: 0.6659, Accuracy: 0.6742\n","Epoch 117, Train Loss: 0.6497, Val Loss: 0.7629, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 118, Train Loss: 0.7441, Val Loss: 0.6663, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 119, Train Loss: 0.6690, Val Loss: 0.7180, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 120, Train Loss: 0.6772, Val Loss: 0.6293, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 121, Train Loss: 0.6729, Val Loss: 0.6425, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 122, Train Loss: 0.6493, Val Loss: 0.6531, F1 Micro: 0.6404, F1 Macro: 0.5374, Accuracy: 0.6404\n","Epoch 123, Train Loss: 0.6621, Val Loss: 0.6507, F1 Micro: 0.6124, F1 Macro: 0.6114, Accuracy: 0.6124\n","Epoch 124, Train Loss: 0.6442, Val Loss: 0.6272, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 125, Train Loss: 0.6945, Val Loss: 0.6417, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 126, Train Loss: 0.6949, Val Loss: 0.6497, F1 Micro: 0.6124, F1 Macro: 0.6103, Accuracy: 0.6124\n","Epoch 127, Train Loss: 0.7037, Val Loss: 0.6939, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 128, Train Loss: 0.6371, Val Loss: 0.6518, F1 Micro: 0.6292, F1 Macro: 0.5163, Accuracy: 0.6292\n","Epoch 129, Train Loss: 0.6486, Val Loss: 0.6194, F1 Micro: 0.7303, F1 Macro: 0.7110, Accuracy: 0.7303\n","Epoch 130, Train Loss: 0.6395, Val Loss: 0.6542, F1 Micro: 0.6180, F1 Macro: 0.6156, Accuracy: 0.6180\n","Epoch 131, Train Loss: 0.6485, Val Loss: 0.6842, F1 Micro: 0.6124, F1 Macro: 0.4387, Accuracy: 0.6124\n","Epoch 132, Train Loss: 0.6721, Val Loss: 0.6395, F1 Micro: 0.6742, F1 Macro: 0.6700, Accuracy: 0.6742\n","Epoch 133, Train Loss: 0.6418, Val Loss: 0.6789, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 134, Train Loss: 0.6714, Val Loss: 0.6146, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 135, Train Loss: 0.6950, Val Loss: 0.6425, F1 Micro: 0.6517, F1 Macro: 0.6441, Accuracy: 0.6517\n","Epoch 136, Train Loss: 0.6702, Val Loss: 0.7761, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 137, Train Loss: 0.6438, Val Loss: 0.6582, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 138, Train Loss: 0.6509, Val Loss: 0.6286, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 139, Train Loss: 0.6324, Val Loss: 0.6422, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 140, Train Loss: 0.6420, Val Loss: 0.7664, F1 Micro: 0.4326, F1 Macro: 0.3974, Accuracy: 0.4326\n","Epoch 141, Train Loss: 0.7137, Val Loss: 0.6251, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 142, Train Loss: 0.7234, Val Loss: 0.6249, F1 Micro: 0.6854, F1 Macro: 0.6762, Accuracy: 0.6854\n","Epoch 143, Train Loss: 0.6718, Val Loss: 0.6213, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.7250266775469211\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7430, Val Loss: 0.6715, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 2, Train Loss: 0.6709, Val Loss: 0.6898, F1 Micro: 0.6313, F1 Macro: 0.5792, Accuracy: 0.6313\n","Epoch 3, Train Loss: 0.6680, Val Loss: 0.6741, F1 Micro: 0.6592, F1 Macro: 0.5843, Accuracy: 0.6592\n","Epoch 4, Train Loss: 0.6650, Val Loss: 0.6944, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 5, Train Loss: 0.6808, Val Loss: 0.6712, F1 Micro: 0.6480, F1 Macro: 0.5845, Accuracy: 0.6480\n","Epoch 6, Train Loss: 0.6464, Val Loss: 0.6899, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 7, Train Loss: 0.6734, Val Loss: 0.6997, F1 Micro: 0.6369, F1 Macro: 0.5279, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.7048, Val Loss: 0.7920, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6907, Val Loss: 0.6729, F1 Micro: 0.6648, F1 Macro: 0.5672, Accuracy: 0.6648\n","Epoch 10, Train Loss: 0.6699, Val Loss: 0.6786, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 11, Train Loss: 0.6721, Val Loss: 0.6742, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 12, Train Loss: 0.6261, Val Loss: 0.6990, F1 Micro: 0.7039, F1 Macro: 0.6095, Accuracy: 0.7039\n","Epoch 13, Train Loss: 0.6461, Val Loss: 0.7313, F1 Micro: 0.6089, F1 Macro: 0.5407, Accuracy: 0.6089\n","Epoch 14, Train Loss: 0.6472, Val Loss: 0.6865, F1 Micro: 0.6872, F1 Macro: 0.6247, Accuracy: 0.6872\n","Epoch 15, Train Loss: 0.6446, Val Loss: 0.7116, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 16, Train Loss: 0.6463, Val Loss: 0.6721, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7329, Val Loss: 0.6857, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 2, Train Loss: 0.6789, Val Loss: 0.6748, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6812, Val Loss: 0.6624, F1 Micro: 0.6461, F1 Macro: 0.4337, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6761, Val Loss: 0.6572, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6725, Val Loss: 0.6761, F1 Micro: 0.4551, F1 Macro: 0.4488, Accuracy: 0.4551\n","Epoch 6, Train Loss: 0.6686, Val Loss: 0.6386, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6671, Val Loss: 0.6828, F1 Micro: 0.4719, F1 Macro: 0.4637, Accuracy: 0.4719\n","Epoch 8, Train Loss: 0.6734, Val Loss: 0.6050, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6558, Val Loss: 0.6779, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6865, Val Loss: 0.6350, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6788, Val Loss: 0.6273, F1 Micro: 0.7135, F1 Macro: 0.6236, Accuracy: 0.7135\n","Epoch 12, Train Loss: 0.6741, Val Loss: 0.6013, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 13, Train Loss: 0.6636, Val Loss: 0.6408, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 14, Train Loss: 0.6646, Val Loss: 0.6113, F1 Micro: 0.6742, F1 Macro: 0.4951, Accuracy: 0.6742\n","Epoch 15, Train Loss: 0.6657, Val Loss: 0.6683, F1 Micro: 0.5843, F1 Macro: 0.5778, Accuracy: 0.5843\n","Epoch 16, Train Loss: 0.6983, Val Loss: 0.6301, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 17, Train Loss: 0.6984, Val Loss: 0.6279, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 18, Train Loss: 0.7444, Val Loss: 0.6337, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 19, Train Loss: 0.6712, Val Loss: 0.6066, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 20, Train Loss: 0.6695, Val Loss: 0.6052, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 21, Train Loss: 0.6571, Val Loss: 0.5871, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 22, Train Loss: 0.6398, Val Loss: 0.6702, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6886, Val Loss: 0.6264, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 24, Train Loss: 0.6726, Val Loss: 0.6017, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Epoch 25, Train Loss: 0.6554, Val Loss: 0.6057, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6378, Val Loss: 0.5943, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 27, Train Loss: 0.6451, Val Loss: 0.5942, F1 Micro: 0.7472, F1 Macro: 0.6629, Accuracy: 0.7472\n","Epoch 28, Train Loss: 0.6349, Val Loss: 0.6090, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 29, Train Loss: 0.6435, Val Loss: 0.6817, F1 Micro: 0.4944, F1 Macro: 0.4816, Accuracy: 0.4944\n","Epoch 30, Train Loss: 0.6603, Val Loss: 0.5926, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 31, Train Loss: 0.6494, Val Loss: 0.6902, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.6583, Val Loss: 0.5899, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 33, Train Loss: 0.6676, Val Loss: 0.5864, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 34, Train Loss: 0.6587, Val Loss: 0.6086, F1 Micro: 0.7079, F1 Macro: 0.6384, Accuracy: 0.7079\n","Epoch 35, Train Loss: 0.6624, Val Loss: 0.6687, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 36, Train Loss: 0.6697, Val Loss: 0.5879, F1 Micro: 0.7416, F1 Macro: 0.6629, Accuracy: 0.7416\n","Epoch 37, Train Loss: 0.6849, Val Loss: 0.5910, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 38, Train Loss: 0.6573, Val Loss: 0.5887, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 39, Train Loss: 0.6606, Val Loss: 0.5991, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 40, Train Loss: 0.6539, Val Loss: 0.5900, F1 Micro: 0.6742, F1 Macro: 0.5405, Accuracy: 0.6742\n","Epoch 41, Train Loss: 0.6406, Val Loss: 0.6165, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.6621, Val Loss: 0.5902, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7196, Val Loss: 0.6809, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.6810, Val Loss: 0.7141, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6711, Val Loss: 0.6988, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6832, Val Loss: 0.6787, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 5, Train Loss: 0.6510, Val Loss: 0.7072, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6971, Val Loss: 0.7684, F1 Micro: 0.5562, F1 Macro: 0.5530, Accuracy: 0.5562\n","Epoch 7, Train Loss: 0.6854, Val Loss: 0.6861, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6663, Val Loss: 0.6764, F1 Micro: 0.4888, F1 Macro: 0.4829, Accuracy: 0.4888\n","Epoch 9, Train Loss: 0.6738, Val Loss: 0.6335, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6513, Val Loss: 0.6605, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6534, Val Loss: 0.6495, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6711, Val Loss: 0.6493, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 13, Train Loss: 0.6490, Val Loss: 0.6319, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 14, Train Loss: 0.6800, Val Loss: 0.7240, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6755, Val Loss: 0.6559, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6337, Val Loss: 0.6392, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6415, Val Loss: 0.6886, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6491, Val Loss: 0.6465, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 19, Train Loss: 0.6502, Val Loss: 0.6517, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.6496, Val Loss: 0.7031, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.6408, Val Loss: 0.6796, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6458, Val Loss: 0.6901, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 23, Train Loss: 0.6486, Val Loss: 0.6734, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.6529, Val Loss: 0.6662, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 25, Train Loss: 0.6338, Val Loss: 0.6352, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 26, Train Loss: 0.6298, Val Loss: 0.6559, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 27, Train Loss: 0.6297, Val Loss: 0.7526, F1 Micro: 0.5899, F1 Macro: 0.5899, Accuracy: 0.5899\n","Epoch 28, Train Loss: 0.6469, Val Loss: 0.6757, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.6369, Val Loss: 0.6433, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7012, Val Loss: 0.8669, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.7031, Val Loss: 0.6862, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6708, Val Loss: 0.8011, F1 Micro: 0.5674, F1 Macro: 0.4740, Accuracy: 0.5674\n","Epoch 4, Train Loss: 0.6794, Val Loss: 0.7073, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6739, Val Loss: 0.7458, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6654, Val Loss: 0.6892, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6643, Val Loss: 0.7085, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.6763, Val Loss: 0.7432, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6650, Val Loss: 0.8221, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6531, Val Loss: 0.7486, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6815, Val Loss: 0.6796, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6598, Val Loss: 0.7210, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7455, Val Loss: 0.6761, F1 Micro: 0.5899, F1 Macro: 0.3834, Accuracy: 0.5899\n","Epoch 2, Train Loss: 0.6801, Val Loss: 0.6719, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6772, Val Loss: 0.6653, F1 Micro: 0.6124, F1 Macro: 0.4283, Accuracy: 0.6124\n","Epoch 4, Train Loss: 0.6732, Val Loss: 0.6770, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6586, Val Loss: 0.6403, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 6, Train Loss: 0.6542, Val Loss: 0.8296, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 7, Train Loss: 0.6824, Val Loss: 0.6967, F1 Micro: 0.5843, F1 Macro: 0.4916, Accuracy: 0.5843\n","Epoch 8, Train Loss: 0.6517, Val Loss: 0.6383, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.7295, Val Loss: 0.8480, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 10, Train Loss: 0.6726, Val Loss: 0.6501, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6511, Val Loss: 0.6438, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6262, Val Loss: 0.6284, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.6553, Val Loss: 0.6348, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6449, Val Loss: 0.7368, F1 Micro: 0.6067, F1 Macro: 0.5008, Accuracy: 0.6067\n","Epoch 15, Train Loss: 0.6474, Val Loss: 0.7065, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6412, Val Loss: 0.6497, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6368, Val Loss: 0.7719, F1 Micro: 0.4719, F1 Macro: 0.4494, Accuracy: 0.4719\n","Epoch 18, Train Loss: 0.6403, Val Loss: 0.6966, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6425, Val Loss: 0.6506, F1 Micro: 0.5955, F1 Macro: 0.5867, Accuracy: 0.5955\n","Epoch 20, Train Loss: 0.6388, Val Loss: 0.6428, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6312, Val Loss: 0.6348, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6260, Val Loss: 0.6375, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.7059381080911431\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7422, Val Loss: 0.6711, F1 Micro: 0.6425, F1 Macro: 0.4191, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6824, Val Loss: 0.6732, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6845, Val Loss: 0.6767, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 4, Train Loss: 0.6751, Val Loss: 0.6729, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 5, Train Loss: 0.6612, Val Loss: 0.6887, F1 Micro: 0.6145, F1 Macro: 0.5759, Accuracy: 0.6145\n","Epoch 6, Train Loss: 0.6531, Val Loss: 0.6894, F1 Micro: 0.6760, F1 Macro: 0.5246, Accuracy: 0.6760\n","Epoch 7, Train Loss: 0.6551, Val Loss: 0.6859, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 8, Train Loss: 0.6578, Val Loss: 0.6774, F1 Micro: 0.6760, F1 Macro: 0.6365, Accuracy: 0.6760\n","Epoch 9, Train Loss: 0.6411, Val Loss: 0.6651, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.6518, Val Loss: 0.6593, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 11, Train Loss: 0.6576, Val Loss: 0.6987, F1 Micro: 0.6704, F1 Macro: 0.5589, Accuracy: 0.6704\n","Epoch 12, Train Loss: 0.6455, Val Loss: 0.7144, F1 Micro: 0.6089, F1 Macro: 0.5826, Accuracy: 0.6089\n","Epoch 13, Train Loss: 0.6566, Val Loss: 0.6716, F1 Micro: 0.6704, F1 Macro: 0.6255, Accuracy: 0.6704\n","Epoch 14, Train Loss: 0.6479, Val Loss: 0.6815, F1 Micro: 0.6760, F1 Macro: 0.5816, Accuracy: 0.6760\n","Epoch 15, Train Loss: 0.6372, Val Loss: 0.6636, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 16, Train Loss: 0.6378, Val Loss: 0.6655, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.6612, Val Loss: 0.6796, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 18, Train Loss: 0.6585, Val Loss: 0.6805, F1 Micro: 0.6648, F1 Macro: 0.5934, Accuracy: 0.6648\n","Epoch 19, Train Loss: 0.6726, Val Loss: 0.7151, F1 Micro: 0.6536, F1 Macro: 0.5329, Accuracy: 0.6536\n","Epoch 20, Train Loss: 0.7119, Val Loss: 0.6993, F1 Micro: 0.5978, F1 Macro: 0.5798, Accuracy: 0.5978\n","Epoch 21, Train Loss: 0.6787, Val Loss: 0.6558, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 22, Train Loss: 0.6941, Val Loss: 0.8901, F1 Micro: 0.3575, F1 Macro: 0.2762, Accuracy: 0.3575\n","Epoch 23, Train Loss: 0.6827, Val Loss: 0.6704, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 24, Train Loss: 0.6433, Val Loss: 0.7212, F1 Micro: 0.6034, F1 Macro: 0.5161, Accuracy: 0.6034\n","Epoch 25, Train Loss: 0.6533, Val Loss: 0.6976, F1 Micro: 0.6983, F1 Macro: 0.5729, Accuracy: 0.6983\n","Epoch 26, Train Loss: 0.6350, Val Loss: 0.6641, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 27, Train Loss: 0.6299, Val Loss: 0.6598, F1 Micro: 0.7318, F1 Macro: 0.6850, Accuracy: 0.7318\n","Epoch 28, Train Loss: 0.6423, Val Loss: 0.7240, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 29, Train Loss: 0.6346, Val Loss: 0.6563, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 30, Train Loss: 0.6493, Val Loss: 0.7494, F1 Micro: 0.6927, F1 Macro: 0.5612, Accuracy: 0.6927\n","Epoch 31, Train Loss: 0.6687, Val Loss: 0.6723, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 32, Train Loss: 0.6382, Val Loss: 0.6689, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 33, Train Loss: 0.6464, Val Loss: 0.6760, F1 Micro: 0.6648, F1 Macro: 0.5934, Accuracy: 0.6648\n","Epoch 34, Train Loss: 0.6400, Val Loss: 0.6620, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 35, Train Loss: 0.6236, Val Loss: 0.6658, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 36, Train Loss: 0.6154, Val Loss: 0.6684, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 37, Train Loss: 0.6314, Val Loss: 0.6670, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 38, Train Loss: 0.6245, Val Loss: 0.7951, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 39, Train Loss: 0.6351, Val Loss: 0.6839, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 40, Train Loss: 0.6559, Val Loss: 0.6993, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 41, Train Loss: 0.6473, Val Loss: 0.6609, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 42, Train Loss: 0.6589, Val Loss: 0.6763, F1 Micro: 0.6760, F1 Macro: 0.5562, Accuracy: 0.6760\n","Epoch 43, Train Loss: 0.6470, Val Loss: 0.6604, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 44, Train Loss: 0.6552, Val Loss: 0.6536, F1 Micro: 0.6983, F1 Macro: 0.6457, Accuracy: 0.6983\n","Epoch 45, Train Loss: 0.6233, Val Loss: 0.7361, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 46, Train Loss: 0.6369, Val Loss: 0.6624, F1 Micro: 0.6480, F1 Macro: 0.5927, Accuracy: 0.6480\n","Epoch 47, Train Loss: 0.6210, Val Loss: 0.6660, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 48, Train Loss: 0.6273, Val Loss: 0.6644, F1 Micro: 0.6480, F1 Macro: 0.6183, Accuracy: 0.6480\n","Epoch 49, Train Loss: 0.6330, Val Loss: 0.6738, F1 Micro: 0.6313, F1 Macro: 0.6064, Accuracy: 0.6313\n","Epoch 50, Train Loss: 0.6553, Val Loss: 0.6632, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 51, Train Loss: 0.6290, Val Loss: 0.6624, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 52, Train Loss: 0.6338, Val Loss: 0.6549, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 53, Train Loss: 0.6240, Val Loss: 0.6560, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 54, Train Loss: 0.6278, Val Loss: 0.6579, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 55, Train Loss: 0.6350, Val Loss: 0.6588, F1 Micro: 0.6927, F1 Macro: 0.6594, Accuracy: 0.6927\n","Epoch 56, Train Loss: 0.6338, Val Loss: 0.6658, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Epoch 57, Train Loss: 0.6818, Val Loss: 0.6782, F1 Micro: 0.6648, F1 Macro: 0.5255, Accuracy: 0.6648\n","Epoch 58, Train Loss: 0.6670, Val Loss: 0.7150, F1 Micro: 0.5810, F1 Macro: 0.5784, Accuracy: 0.5810\n","Epoch 59, Train Loss: 0.6526, Val Loss: 0.6850, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 60, Train Loss: 0.6505, Val Loss: 0.6625, F1 Micro: 0.6816, F1 Macro: 0.5603, Accuracy: 0.6816\n","Epoch 61, Train Loss: 0.6482, Val Loss: 0.6482, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 62, Train Loss: 0.6317, Val Loss: 0.6757, F1 Micro: 0.6536, F1 Macro: 0.6203, Accuracy: 0.6536\n","Epoch 63, Train Loss: 0.6531, Val Loss: 0.6550, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 64, Train Loss: 0.6290, Val Loss: 0.6699, F1 Micro: 0.6648, F1 Macro: 0.5547, Accuracy: 0.6648\n","Epoch 65, Train Loss: 0.6377, Val Loss: 0.6551, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 66, Train Loss: 0.6465, Val Loss: 0.6550, F1 Micro: 0.6760, F1 Macro: 0.5696, Accuracy: 0.6760\n","Epoch 67, Train Loss: 0.6247, Val Loss: 0.7042, F1 Micro: 0.6592, F1 Macro: 0.5369, Accuracy: 0.6592\n","Epoch 68, Train Loss: 0.6278, Val Loss: 0.6516, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 69, Train Loss: 0.6362, Val Loss: 0.6697, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 70, Train Loss: 0.6409, Val Loss: 0.7201, F1 Micro: 0.6816, F1 Macro: 0.5453, Accuracy: 0.6816\n","Epoch 71, Train Loss: 0.6382, Val Loss: 0.6665, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 72, Train Loss: 0.6327, Val Loss: 0.6627, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 73, Train Loss: 0.6592, Val Loss: 0.6728, F1 Micro: 0.6425, F1 Macro: 0.5801, Accuracy: 0.6425\n","Epoch 74, Train Loss: 0.6443, Val Loss: 0.6737, F1 Micro: 0.6257, F1 Macro: 0.6039, Accuracy: 0.6257\n","Epoch 75, Train Loss: 0.6406, Val Loss: 0.6659, F1 Micro: 0.6704, F1 Macro: 0.5715, Accuracy: 0.6704\n","Epoch 76, Train Loss: 0.6288, Val Loss: 0.6636, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 77, Train Loss: 0.6301, Val Loss: 0.6792, F1 Micro: 0.7095, F1 Macro: 0.6141, Accuracy: 0.7095\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7239, Val Loss: 0.6741, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.7020, Val Loss: 0.6659, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Epoch 3, Train Loss: 0.6813, Val Loss: 0.6782, F1 Micro: 0.6854, F1 Macro: 0.5316, Accuracy: 0.6854\n","Epoch 4, Train Loss: 0.6802, Val Loss: 0.6857, F1 Micro: 0.4831, F1 Macro: 0.4719, Accuracy: 0.4831\n","Epoch 5, Train Loss: 0.6800, Val Loss: 0.6852, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6757, Val Loss: 0.6503, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 7, Train Loss: 0.6732, Val Loss: 0.6444, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 8, Train Loss: 0.6471, Val Loss: 0.6362, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6865, Val Loss: 0.6638, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 10, Train Loss: 0.7023, Val Loss: 0.7020, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.7118, Val Loss: 0.6563, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6751, Val Loss: 0.6312, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6735, Val Loss: 0.6369, F1 Micro: 0.6348, F1 Macro: 0.5657, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.6664, Val Loss: 0.6281, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 15, Train Loss: 0.6759, Val Loss: 0.6286, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6598, Val Loss: 0.6179, F1 Micro: 0.7416, F1 Macro: 0.6802, Accuracy: 0.7416\n","Epoch 17, Train Loss: 0.6667, Val Loss: 0.6289, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.6520, Val Loss: 0.6065, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 19, Train Loss: 0.6609, Val Loss: 0.6867, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.6799, Val Loss: 0.6144, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.6503, Val Loss: 0.6042, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 22, Train Loss: 0.6601, Val Loss: 0.6005, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.6524, Val Loss: 0.6391, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 24, Train Loss: 0.6791, Val Loss: 0.6847, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.6938, Val Loss: 0.6241, F1 Micro: 0.7022, F1 Macro: 0.5904, Accuracy: 0.7022\n","Epoch 26, Train Loss: 0.6627, Val Loss: 0.5940, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 27, Train Loss: 0.6447, Val Loss: 0.6027, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 28, Train Loss: 0.6628, Val Loss: 0.5996, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.6796, Val Loss: 0.6036, F1 Micro: 0.6854, F1 Macro: 0.5316, Accuracy: 0.6854\n","Epoch 30, Train Loss: 0.6498, Val Loss: 0.6567, F1 Micro: 0.5618, F1 Macro: 0.5613, Accuracy: 0.5618\n","Epoch 31, Train Loss: 0.6665, Val Loss: 0.5983, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 32, Train Loss: 0.6519, Val Loss: 0.5913, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 33, Train Loss: 0.7234, Val Loss: 0.6917, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.6593, Val Loss: 0.6061, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6599, Val Loss: 0.5896, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 36, Train Loss: 0.6627, Val Loss: 0.5982, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 37, Train Loss: 0.6650, Val Loss: 0.6078, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 38, Train Loss: 0.6533, Val Loss: 0.5861, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 39, Train Loss: 0.6451, Val Loss: 0.5858, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 40, Train Loss: 0.6401, Val Loss: 0.5828, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 41, Train Loss: 0.6740, Val Loss: 0.7057, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 42, Train Loss: 0.7102, Val Loss: 0.5990, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 43, Train Loss: 0.6520, Val Loss: 0.6042, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 44, Train Loss: 0.6622, Val Loss: 0.6004, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6460, Val Loss: 0.5952, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.6372, Val Loss: 0.6022, F1 Micro: 0.7191, F1 Macro: 0.6226, Accuracy: 0.7191\n","Epoch 47, Train Loss: 0.6783, Val Loss: 0.6098, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6800, Val Loss: 0.5910, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 49, Train Loss: 0.6523, Val Loss: 0.5747, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 50, Train Loss: 0.6466, Val Loss: 0.5753, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 51, Train Loss: 0.6553, Val Loss: 0.5862, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 52, Train Loss: 0.6360, Val Loss: 0.6088, F1 Micro: 0.6742, F1 Macro: 0.4951, Accuracy: 0.6742\n","Epoch 53, Train Loss: 0.6406, Val Loss: 0.5734, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 54, Train Loss: 0.6457, Val Loss: 0.5816, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 55, Train Loss: 0.6542, Val Loss: 0.6042, F1 Micro: 0.7191, F1 Macro: 0.6336, Accuracy: 0.7191\n","Epoch 56, Train Loss: 0.6462, Val Loss: 0.5889, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 57, Train Loss: 0.6363, Val Loss: 0.5810, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 58, Train Loss: 0.6333, Val Loss: 0.5975, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 59, Train Loss: 0.6367, Val Loss: 0.5759, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 60, Train Loss: 0.6579, Val Loss: 0.5776, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 61, Train Loss: 0.6666, Val Loss: 0.5814, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 62, Train Loss: 0.6498, Val Loss: 0.5920, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 63, Train Loss: 0.6507, Val Loss: 0.5779, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 64, Train Loss: 0.6413, Val Loss: 0.5861, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 65, Train Loss: 0.6351, Val Loss: 0.5880, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 66, Train Loss: 0.6551, Val Loss: 0.6593, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.6548, Val Loss: 0.5960, F1 Micro: 0.6798, F1 Macro: 0.5277, Accuracy: 0.6798\n","Epoch 68, Train Loss: 0.6416, Val Loss: 0.5781, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 69, Train Loss: 0.6384, Val Loss: 0.5802, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 70, Train Loss: 0.6638, Val Loss: 0.5767, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 71, Train Loss: 0.6761, Val Loss: 0.5957, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 72, Train Loss: 0.6492, Val Loss: 0.5920, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 73, Train Loss: 0.6574, Val Loss: 0.5729, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 74, Train Loss: 0.6322, Val Loss: 0.5923, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 75, Train Loss: 0.6504, Val Loss: 0.5785, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 76, Train Loss: 0.6459, Val Loss: 0.5707, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 77, Train Loss: 0.6549, Val Loss: 0.5868, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 78, Train Loss: 0.6674, Val Loss: 0.5943, F1 Micro: 0.6966, F1 Macro: 0.5860, Accuracy: 0.6966\n","Epoch 79, Train Loss: 0.6425, Val Loss: 0.5926, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 80, Train Loss: 0.6661, Val Loss: 0.6214, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 81, Train Loss: 0.6737, Val Loss: 0.6409, F1 Micro: 0.5674, F1 Macro: 0.5674, Accuracy: 0.5674\n","Epoch 82, Train Loss: 0.6796, Val Loss: 0.6160, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 83, Train Loss: 0.6510, Val Loss: 0.6089, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 84, Train Loss: 0.6532, Val Loss: 0.5813, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 85, Train Loss: 0.6513, Val Loss: 0.6474, F1 Micro: 0.6685, F1 Macro: 0.5017, Accuracy: 0.6685\n","Epoch 86, Train Loss: 0.6529, Val Loss: 0.5649, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 87, Train Loss: 0.6707, Val Loss: 0.6292, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 88, Train Loss: 0.6770, Val Loss: 0.6413, F1 Micro: 0.7303, F1 Macro: 0.6261, Accuracy: 0.7303\n","Epoch 89, Train Loss: 0.6514, Val Loss: 0.6170, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7227, Val Loss: 0.6767, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 2, Train Loss: 0.6840, Val Loss: 0.6809, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6682, Val Loss: 0.7713, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6656, Val Loss: 0.6725, F1 Micro: 0.6236, F1 Macro: 0.5190, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6951, Val Loss: 0.6663, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6687, Val Loss: 0.6484, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6516, Val Loss: 0.7090, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6546, Val Loss: 0.6969, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6767, Val Loss: 0.6680, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6706, Val Loss: 0.6440, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6534, Val Loss: 0.6794, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 12, Train Loss: 0.6721, Val Loss: 0.6566, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6521, Val Loss: 0.6553, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6392, Val Loss: 0.6871, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 15, Train Loss: 0.6493, Val Loss: 0.6681, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6718, Val Loss: 0.6325, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6434, Val Loss: 0.6916, F1 Micro: 0.6292, F1 Macro: 0.4858, Accuracy: 0.6292\n","Epoch 18, Train Loss: 0.6473, Val Loss: 0.6813, F1 Micro: 0.6180, F1 Macro: 0.4312, Accuracy: 0.6180\n","Epoch 19, Train Loss: 0.6560, Val Loss: 0.6858, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6408, Val Loss: 0.7062, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6364, Val Loss: 0.6802, F1 Micro: 0.6461, F1 Macro: 0.6420, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.6508, Val Loss: 0.6608, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6484, Val Loss: 0.6724, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6475, Val Loss: 0.6704, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 25, Train Loss: 0.6328, Val Loss: 0.6606, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6323, Val Loss: 0.6403, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 27, Train Loss: 0.6387, Val Loss: 0.6421, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.6550, Val Loss: 0.6978, F1 Micro: 0.6461, F1 Macro: 0.6420, Accuracy: 0.6461\n","Epoch 29, Train Loss: 0.6439, Val Loss: 0.6626, F1 Micro: 0.6742, F1 Macro: 0.5405, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6357, Val Loss: 0.6825, F1 Micro: 0.6124, F1 Macro: 0.4907, Accuracy: 0.6124\n","Epoch 31, Train Loss: 0.6474, Val Loss: 0.6620, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 32, Train Loss: 0.6469, Val Loss: 0.6960, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 33, Train Loss: 0.6773, Val Loss: 0.6593, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.6667, Val Loss: 0.6516, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6367, Val Loss: 0.6483, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 36, Train Loss: 0.6430, Val Loss: 0.6474, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6627, Val Loss: 0.6683, F1 Micro: 0.6236, F1 Macro: 0.4981, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6373, Val Loss: 0.6537, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 39, Train Loss: 0.6320, Val Loss: 0.7594, F1 Micro: 0.6236, F1 Macro: 0.5253, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6623, Val Loss: 0.8299, F1 Micro: 0.3708, F1 Macro: 0.2705, Accuracy: 0.3708\n","Epoch 41, Train Loss: 0.6522, Val Loss: 0.6465, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.6469, Val Loss: 0.7165, F1 Micro: 0.5730, F1 Macro: 0.5730, Accuracy: 0.5730\n","Epoch 43, Train Loss: 0.6498, Val Loss: 0.6843, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 44, Train Loss: 0.6532, Val Loss: 0.6568, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 45, Train Loss: 0.6312, Val Loss: 0.6391, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.6285, Val Loss: 0.6527, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 47, Train Loss: 0.6450, Val Loss: 0.6537, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6367, Val Loss: 0.6590, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.6313, Val Loss: 0.6527, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 50, Train Loss: 0.6454, Val Loss: 0.6514, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6503, Val Loss: 0.6450, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 52, Train Loss: 0.6615, Val Loss: 0.7609, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 53, Train Loss: 0.6881, Val Loss: 0.6266, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 54, Train Loss: 0.6425, Val Loss: 0.6747, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 55, Train Loss: 0.6263, Val Loss: 0.6441, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 56, Train Loss: 0.6226, Val Loss: 0.7257, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 57, Train Loss: 0.6406, Val Loss: 0.6401, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 58, Train Loss: 0.6811, Val Loss: 0.6668, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 59, Train Loss: 0.6402, Val Loss: 0.6847, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 60, Train Loss: 0.6364, Val Loss: 0.6524, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 61, Train Loss: 0.6379, Val Loss: 0.6959, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 62, Train Loss: 0.6384, Val Loss: 0.6520, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 63, Train Loss: 0.6363, Val Loss: 0.6649, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 64, Train Loss: 0.6373, Val Loss: 0.6677, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 65, Train Loss: 0.6260, Val Loss: 0.6432, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 66, Train Loss: 0.6588, Val Loss: 0.6533, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 67, Train Loss: 0.6339, Val Loss: 0.6425, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 68, Train Loss: 0.6375, Val Loss: 0.6523, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 69, Train Loss: 0.6300, Val Loss: 0.6944, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 70, Train Loss: 0.6387, Val Loss: 0.6449, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 71, Train Loss: 0.6255, Val Loss: 0.6671, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 72, Train Loss: 0.6280, Val Loss: 0.6453, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 73, Train Loss: 0.6374, Val Loss: 0.6405, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 74, Train Loss: 0.6244, Val Loss: 0.6474, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.6265, Val Loss: 0.6659, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 76, Train Loss: 0.6289, Val Loss: 0.7091, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 77, Train Loss: 0.6286, Val Loss: 0.6638, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 78, Train Loss: 0.6371, Val Loss: 0.6421, F1 Micro: 0.6461, F1 Macro: 0.5697, Accuracy: 0.6461\n","Epoch 79, Train Loss: 0.6480, Val Loss: 0.6442, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.6776, Val Loss: 0.6938, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 81, Train Loss: 0.6591, Val Loss: 0.6607, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7160, Val Loss: 0.7597, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6835, Val Loss: 0.7214, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6761, Val Loss: 0.7186, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6704, Val Loss: 0.6878, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 5, Train Loss: 0.6847, Val Loss: 0.7459, F1 Micro: 0.5337, F1 Macro: 0.3687, Accuracy: 0.5337\n","Epoch 6, Train Loss: 0.7011, Val Loss: 0.7302, F1 Micro: 0.4775, F1 Macro: 0.3232, Accuracy: 0.4775\n","Epoch 7, Train Loss: 0.6893, Val Loss: 0.7142, F1 Micro: 0.5787, F1 Macro: 0.4989, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.6617, Val Loss: 0.7461, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6640, Val Loss: 0.7214, F1 Micro: 0.5618, F1 Macro: 0.4363, Accuracy: 0.5618\n","Epoch 10, Train Loss: 0.6530, Val Loss: 0.6730, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 11, Train Loss: 0.6595, Val Loss: 0.8966, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 12, Train Loss: 0.6547, Val Loss: 0.6875, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 13, Train Loss: 0.6338, Val Loss: 0.7787, F1 Micro: 0.5787, F1 Macro: 0.4935, Accuracy: 0.5787\n","Epoch 14, Train Loss: 0.6361, Val Loss: 0.7194, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 15, Train Loss: 0.6344, Val Loss: 0.6729, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6336, Val Loss: 0.7638, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 17, Train Loss: 0.6379, Val Loss: 0.7317, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 18, Train Loss: 0.6299, Val Loss: 0.6699, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.6463, Val Loss: 0.7686, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 20, Train Loss: 0.6479, Val Loss: 0.6739, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6414, Val Loss: 0.7329, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6579, Val Loss: 0.7246, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 23, Train Loss: 0.6401, Val Loss: 0.6940, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6471, Val Loss: 0.6622, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 25, Train Loss: 0.6375, Val Loss: 0.7200, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 26, Train Loss: 0.6600, Val Loss: 0.6990, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 27, Train Loss: 0.6229, Val Loss: 0.8282, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 28, Train Loss: 0.6400, Val Loss: 0.7935, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 29, Train Loss: 0.6510, Val Loss: 0.6693, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6337, Val Loss: 0.6527, F1 Micro: 0.6742, F1 Macro: 0.6721, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.6466, Val Loss: 0.7129, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 32, Train Loss: 0.6409, Val Loss: 0.6837, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 33, Train Loss: 0.6430, Val Loss: 0.7161, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 34, Train Loss: 0.6248, Val Loss: 0.9132, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 35, Train Loss: 0.6477, Val Loss: 0.6646, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6578, Val Loss: 0.6379, F1 Micro: 0.6573, F1 Macro: 0.6568, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.6294, Val Loss: 0.6732, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 38, Train Loss: 0.6275, Val Loss: 0.6641, F1 Micro: 0.6854, F1 Macro: 0.6720, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6332, Val Loss: 0.7978, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 40, Train Loss: 0.6393, Val Loss: 0.7619, F1 Micro: 0.5899, F1 Macro: 0.5174, Accuracy: 0.5899\n","Epoch 41, Train Loss: 0.6443, Val Loss: 0.7316, F1 Micro: 0.6124, F1 Macro: 0.5681, Accuracy: 0.6124\n","Epoch 42, Train Loss: 0.6322, Val Loss: 0.7934, F1 Micro: 0.5787, F1 Macro: 0.5266, Accuracy: 0.5787\n","Epoch 43, Train Loss: 0.6284, Val Loss: 0.6558, F1 Micro: 0.6517, F1 Macro: 0.6452, Accuracy: 0.6517\n","Epoch 44, Train Loss: 0.6441, Val Loss: 0.7498, F1 Micro: 0.5787, F1 Macro: 0.5266, Accuracy: 0.5787\n","Epoch 45, Train Loss: 0.6196, Val Loss: 0.6956, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6221, Val Loss: 0.6438, F1 Micro: 0.6910, F1 Macro: 0.6837, Accuracy: 0.6910\n","Epoch 47, Train Loss: 0.6356, Val Loss: 0.7217, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 48, Train Loss: 0.6442, Val Loss: 0.6657, F1 Micro: 0.5955, F1 Macro: 0.5950, Accuracy: 0.5955\n","Epoch 49, Train Loss: 0.6429, Val Loss: 0.7677, F1 Micro: 0.5787, F1 Macro: 0.5305, Accuracy: 0.5787\n","Epoch 50, Train Loss: 0.6609, Val Loss: 0.7332, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6600, Val Loss: 0.8688, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 52, Train Loss: 0.6349, Val Loss: 0.7192, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 53, Train Loss: 0.6394, Val Loss: 0.6926, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 54, Train Loss: 0.6594, Val Loss: 0.7164, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 55, Train Loss: 0.6475, Val Loss: 0.7619, F1 Micro: 0.5730, F1 Macro: 0.5001, Accuracy: 0.5730\n","Epoch 56, Train Loss: 0.6235, Val Loss: 0.7652, F1 Micro: 0.5843, F1 Macro: 0.5132, Accuracy: 0.5843\n","Epoch 57, Train Loss: 0.6359, Val Loss: 0.7442, F1 Micro: 0.5787, F1 Macro: 0.5138, Accuracy: 0.5787\n","Epoch 58, Train Loss: 0.6223, Val Loss: 0.7259, F1 Micro: 0.6124, F1 Macro: 0.5681, Accuracy: 0.6124\n","Epoch 59, Train Loss: 0.6184, Val Loss: 0.8386, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 60, Train Loss: 0.6412, Val Loss: 0.7511, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 61, Train Loss: 0.6304, Val Loss: 0.6769, F1 Micro: 0.6348, F1 Macro: 0.6306, Accuracy: 0.6348\n","Epoch 62, Train Loss: 0.6155, Val Loss: 0.6628, F1 Micro: 0.6629, F1 Macro: 0.6502, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.6294, Val Loss: 0.7060, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 64, Train Loss: 0.6349, Val Loss: 0.6329, F1 Micro: 0.6404, F1 Macro: 0.6400, Accuracy: 0.6404\n","Epoch 65, Train Loss: 0.6271, Val Loss: 0.6557, F1 Micro: 0.6348, F1 Macro: 0.6347, Accuracy: 0.6348\n","Epoch 66, Train Loss: 0.6483, Val Loss: 0.6628, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 67, Train Loss: 0.6282, Val Loss: 0.6563, F1 Micro: 0.6629, F1 Macro: 0.6502, Accuracy: 0.6629\n","Epoch 68, Train Loss: 0.6151, Val Loss: 0.7442, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 69, Train Loss: 0.6433, Val Loss: 0.7445, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 70, Train Loss: 0.6370, Val Loss: 0.6585, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 71, Train Loss: 0.6235, Val Loss: 0.8011, F1 Micro: 0.5730, F1 Macro: 0.5141, Accuracy: 0.5730\n","Epoch 72, Train Loss: 0.6299, Val Loss: 0.7387, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 73, Train Loss: 0.6311, Val Loss: 0.8669, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 74, Train Loss: 0.6093, Val Loss: 0.6864, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 75, Train Loss: 0.6154, Val Loss: 0.7100, F1 Micro: 0.6067, F1 Macro: 0.5635, Accuracy: 0.6067\n","Epoch 76, Train Loss: 0.6194, Val Loss: 0.6484, F1 Micro: 0.6798, F1 Macro: 0.6684, Accuracy: 0.6798\n","Epoch 77, Train Loss: 0.6289, Val Loss: 0.7031, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 78, Train Loss: 0.6263, Val Loss: 0.7007, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 79, Train Loss: 0.6155, Val Loss: 0.7738, F1 Micro: 0.5787, F1 Macro: 0.5041, Accuracy: 0.5787\n","Epoch 80, Train Loss: 0.6545, Val Loss: 1.0039, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 81, Train Loss: 0.6414, Val Loss: 0.7768, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 82, Train Loss: 0.7117, Val Loss: 0.7207, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 83, Train Loss: 0.6474, Val Loss: 0.7135, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 84, Train Loss: 0.6497, Val Loss: 0.6710, F1 Micro: 0.6011, F1 Macro: 0.5990, Accuracy: 0.6011\n","Epoch 85, Train Loss: 0.6475, Val Loss: 0.6543, F1 Micro: 0.6798, F1 Macro: 0.6743, Accuracy: 0.6798\n","Epoch 86, Train Loss: 0.6074, Val Loss: 0.6775, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 87, Train Loss: 0.6246, Val Loss: 0.6905, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 88, Train Loss: 0.6150, Val Loss: 0.7072, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 89, Train Loss: 0.6182, Val Loss: 0.6499, F1 Micro: 0.6348, F1 Macro: 0.6348, Accuracy: 0.6348\n","Epoch 90, Train Loss: 0.6153, Val Loss: 0.7099, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 91, Train Loss: 0.6114, Val Loss: 0.7541, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 92, Train Loss: 0.6349, Val Loss: 0.8515, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 93, Train Loss: 0.6263, Val Loss: 0.6772, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 94, Train Loss: 0.6295, Val Loss: 0.6430, F1 Micro: 0.6573, F1 Macro: 0.6560, Accuracy: 0.6573\n","Epoch 95, Train Loss: 0.6463, Val Loss: 0.6933, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 96, Train Loss: 0.6313, Val Loss: 0.6767, F1 Micro: 0.6404, F1 Macro: 0.6367, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7480, Val Loss: 0.6949, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6767, Val Loss: 0.6642, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6644, Val Loss: 0.6608, F1 Micro: 0.6348, F1 Macro: 0.5270, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6440, Val Loss: 0.6680, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6371, Val Loss: 0.6908, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6503, Val Loss: 0.6777, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6740, Val Loss: 0.7873, F1 Micro: 0.4326, F1 Macro: 0.4070, Accuracy: 0.4326\n","Epoch 8, Train Loss: 0.6811, Val Loss: 0.6391, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6468, Val Loss: 0.6326, F1 Micro: 0.6854, F1 Macro: 0.6749, Accuracy: 0.6854\n","Epoch 10, Train Loss: 0.6493, Val Loss: 0.6435, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6510, Val Loss: 0.6516, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6434, Val Loss: 0.6443, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 13, Train Loss: 0.6568, Val Loss: 0.6502, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6365, Val Loss: 0.6846, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 15, Train Loss: 0.6641, Val Loss: 0.6467, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 16, Train Loss: 0.6336, Val Loss: 0.6617, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6512, Val Loss: 0.7329, F1 Micro: 0.6517, F1 Macro: 0.5170, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.6345, Val Loss: 0.7137, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6358, Val Loss: 0.6393, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.6458, Val Loss: 0.6642, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.6288, Val Loss: 0.6627, F1 Micro: 0.5674, F1 Macro: 0.5663, Accuracy: 0.5674\n","Epoch 22, Train Loss: 0.6418, Val Loss: 0.6710, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6437, Val Loss: 0.6354, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 24, Train Loss: 0.6543, Val Loss: 0.6244, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 25, Train Loss: 0.6349, Val Loss: 0.7236, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 26, Train Loss: 0.6259, Val Loss: 0.6310, F1 Micro: 0.7079, F1 Macro: 0.6954, Accuracy: 0.7079\n","Epoch 27, Train Loss: 0.6428, Val Loss: 0.7493, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6264, Val Loss: 0.6618, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 29, Train Loss: 0.6411, Val Loss: 0.6332, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 30, Train Loss: 0.6218, Val Loss: 0.6413, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 31, Train Loss: 0.6363, Val Loss: 0.6978, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 32, Train Loss: 0.6329, Val Loss: 0.6436, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.6311, Val Loss: 0.6323, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 34, Train Loss: 0.6252, Val Loss: 0.6311, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 35, Train Loss: 0.6330, Val Loss: 0.6293, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 36, Train Loss: 0.6287, Val Loss: 0.6281, F1 Micro: 0.7079, F1 Macro: 0.6939, Accuracy: 0.7079\n","Epoch 37, Train Loss: 0.6500, Val Loss: 0.6185, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 38, Train Loss: 0.6307, Val Loss: 0.6407, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6509, Val Loss: 0.6285, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 40, Train Loss: 0.6934, Val Loss: 0.6649, F1 Micro: 0.5787, F1 Macro: 0.5780, Accuracy: 0.5787\n","Epoch 41, Train Loss: 0.6520, Val Loss: 0.6209, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 42, Train Loss: 0.6274, Val Loss: 0.6331, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 43, Train Loss: 0.6427, Val Loss: 0.6349, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 44, Train Loss: 0.6298, Val Loss: 0.6289, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 45, Train Loss: 0.6453, Val Loss: 0.6623, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.6379, Val Loss: 0.6658, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 47, Train Loss: 0.6430, Val Loss: 0.6630, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 48, Train Loss: 0.6421, Val Loss: 0.7789, F1 Micro: 0.4607, F1 Macro: 0.4256, Accuracy: 0.4607\n","Epoch 49, Train Loss: 0.7263, Val Loss: 0.7728, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 50, Train Loss: 0.7526, Val Loss: 0.6956, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6750, Val Loss: 0.6355, F1 Micro: 0.6685, F1 Macro: 0.6607, Accuracy: 0.6685\n","Epoch 52, Train Loss: 0.6383, Val Loss: 0.6466, F1 Micro: 0.6573, F1 Macro: 0.6525, Accuracy: 0.6573\n","Epoch 53, Train Loss: 0.6429, Val Loss: 0.6653, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 54, Train Loss: 0.6239, Val Loss: 0.6472, F1 Micro: 0.6180, F1 Macro: 0.6175, Accuracy: 0.6180\n","Epoch 55, Train Loss: 0.6315, Val Loss: 0.6778, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 56, Train Loss: 0.6471, Val Loss: 0.6476, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 57, Train Loss: 0.6330, Val Loss: 0.6488, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6204, Val Loss: 0.6181, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 59, Train Loss: 0.6129, Val Loss: 0.6360, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 60, Train Loss: 0.6265, Val Loss: 0.6953, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 61, Train Loss: 0.6394, Val Loss: 0.6462, F1 Micro: 0.6124, F1 Macro: 0.6103, Accuracy: 0.6124\n","Epoch 62, Train Loss: 0.6143, Val Loss: 0.6245, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 63, Train Loss: 0.6267, Val Loss: 0.6200, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 64, Train Loss: 0.6337, Val Loss: 0.6518, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 65, Train Loss: 0.6272, Val Loss: 0.6193, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 66, Train Loss: 0.6306, Val Loss: 0.6317, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 67, Train Loss: 0.6387, Val Loss: 0.6244, F1 Micro: 0.6854, F1 Macro: 0.6762, Accuracy: 0.6854\n","Epoch 68, Train Loss: 0.6442, Val Loss: 0.6195, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 69, Train Loss: 0.6360, Val Loss: 0.6645, F1 Micro: 0.6404, F1 Macro: 0.5374, Accuracy: 0.6404\n","Epoch 70, Train Loss: 0.6347, Val Loss: 0.6793, F1 Micro: 0.6236, F1 Macro: 0.5369, Accuracy: 0.6236\n","Epoch 71, Train Loss: 0.6241, Val Loss: 0.7846, F1 Micro: 0.6124, F1 Macro: 0.5047, Accuracy: 0.6124\n","Epoch 72, Train Loss: 0.6270, Val Loss: 0.6433, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 73, Train Loss: 0.6292, Val Loss: 0.6778, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 74, Train Loss: 0.6286, Val Loss: 0.6352, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 75, Train Loss: 0.6375, Val Loss: 0.6573, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 76, Train Loss: 0.6361, Val Loss: 0.6367, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 77, Train Loss: 0.6462, Val Loss: 0.7251, F1 Micro: 0.6124, F1 Macro: 0.5047, Accuracy: 0.6124\n","Epoch 78, Train Loss: 0.6295, Val Loss: 0.6143, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 79, Train Loss: 0.6419, Val Loss: 0.6634, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 80, Train Loss: 0.6417, Val Loss: 0.6161, F1 Micro: 0.6910, F1 Macro: 0.6813, Accuracy: 0.6910\n","Epoch 81, Train Loss: 0.6430, Val Loss: 0.6307, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 82, Train Loss: 0.6452, Val Loss: 0.6191, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 83, Train Loss: 0.6378, Val Loss: 0.6494, F1 Micro: 0.6011, F1 Macro: 0.5996, Accuracy: 0.6011\n","Epoch 84, Train Loss: 0.6294, Val Loss: 0.6271, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 85, Train Loss: 0.6400, Val Loss: 0.7746, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 86, Train Loss: 0.6362, Val Loss: 0.6123, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 87, Train Loss: 0.6361, Val Loss: 0.6689, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 88, Train Loss: 0.6191, Val Loss: 0.6284, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 89, Train Loss: 0.6283, Val Loss: 0.6201, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 90, Train Loss: 0.6370, Val Loss: 0.6574, F1 Micro: 0.6348, F1 Macro: 0.5334, Accuracy: 0.6348\n","Epoch 91, Train Loss: 0.6762, Val Loss: 0.8119, F1 Micro: 0.6011, F1 Macro: 0.4970, Accuracy: 0.6011\n","Epoch 92, Train Loss: 0.6748, Val Loss: 0.6169, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 93, Train Loss: 0.6638, Val Loss: 0.6591, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 94, Train Loss: 0.6335, Val Loss: 0.6157, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 95, Train Loss: 0.6599, Val Loss: 0.6527, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 96, Train Loss: 0.6363, Val Loss: 0.6366, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 97, Train Loss: 0.6373, Val Loss: 0.6392, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 98, Train Loss: 0.6244, Val Loss: 0.6421, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 99, Train Loss: 0.6384, Val Loss: 0.7066, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 100, Train Loss: 0.6380, Val Loss: 0.6191, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 101, Train Loss: 0.6184, Val Loss: 0.6239, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 102, Train Loss: 0.6403, Val Loss: 0.6471, F1 Micro: 0.6067, F1 Macro: 0.6063, Accuracy: 0.6067\n","Epoch 103, Train Loss: 0.6386, Val Loss: 0.6119, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 104, Train Loss: 0.6387, Val Loss: 0.6187, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 105, Train Loss: 0.6220, Val Loss: 0.6273, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 106, Train Loss: 0.6236, Val Loss: 0.6256, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 107, Train Loss: 0.6275, Val Loss: 0.6994, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 108, Train Loss: 0.6419, Val Loss: 0.6683, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 109, Train Loss: 0.6303, Val Loss: 0.6291, F1 Micro: 0.6461, F1 Macro: 0.6401, Accuracy: 0.6461\n","Epoch 110, Train Loss: 0.6271, Val Loss: 0.6217, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 111, Train Loss: 0.6297, Val Loss: 0.6258, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 112, Train Loss: 0.6225, Val Loss: 0.6139, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 113, Train Loss: 0.6273, Val Loss: 0.6126, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 114, Train Loss: 0.6256, Val Loss: 0.6352, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 115, Train Loss: 0.6118, Val Loss: 0.6272, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 116, Train Loss: 0.6196, Val Loss: 0.6151, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 117, Train Loss: 0.6401, Val Loss: 0.6581, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 118, Train Loss: 0.6285, Val Loss: 0.6482, F1 Micro: 0.6348, F1 Macro: 0.6339, Accuracy: 0.6348\n","Epoch 119, Train Loss: 0.6533, Val Loss: 0.8181, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 120, Train Loss: 0.6519, Val Loss: 0.6527, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 121, Train Loss: 0.6379, Val Loss: 0.7304, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 122, Train Loss: 0.6290, Val Loss: 0.6384, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 123, Train Loss: 0.6605, Val Loss: 0.6396, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 124, Train Loss: 0.6673, Val Loss: 0.6322, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 125, Train Loss: 0.6303, Val Loss: 0.6222, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 126, Train Loss: 0.6396, Val Loss: 0.6178, F1 Micro: 0.7416, F1 Macro: 0.7213, Accuracy: 0.7416\n","Epoch 127, Train Loss: 0.6401, Val Loss: 0.6659, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 128, Train Loss: 0.6231, Val Loss: 0.6641, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 129, Train Loss: 0.6304, Val Loss: 0.6431, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 130, Train Loss: 0.6267, Val Loss: 0.6158, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 131, Train Loss: 0.6278, Val Loss: 0.6371, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 132, Train Loss: 0.6258, Val Loss: 0.6204, F1 Micro: 0.6966, F1 Macro: 0.6821, Accuracy: 0.6966\n","Epoch 133, Train Loss: 0.6321, Val Loss: 0.6368, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 134, Train Loss: 0.6281, Val Loss: 0.7094, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 135, Train Loss: 0.6419, Val Loss: 0.6514, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 136, Train Loss: 0.6203, Val Loss: 0.6703, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 137, Train Loss: 0.6389, Val Loss: 0.6134, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Epoch 138, Train Loss: 0.6329, Val Loss: 0.6147, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 139, Train Loss: 0.6389, Val Loss: 0.6180, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 140, Train Loss: 0.6285, Val Loss: 0.6323, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 141, Train Loss: 0.6382, Val Loss: 0.6447, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 142, Train Loss: 0.6341, Val Loss: 0.6210, F1 Micro: 0.6854, F1 Macro: 0.6735, Accuracy: 0.6854\n","Epoch 143, Train Loss: 0.6221, Val Loss: 0.6254, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 144, Train Loss: 0.6265, Val Loss: 0.6270, F1 Micro: 0.6854, F1 Macro: 0.6735, Accuracy: 0.6854\n","Epoch 145, Train Loss: 0.6275, Val Loss: 0.6185, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 146, Train Loss: 0.6237, Val Loss: 0.6621, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 147, Train Loss: 0.6449, Val Loss: 0.6180, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 148, Train Loss: 0.6422, Val Loss: 0.7412, F1 Micro: 0.5000, F1 Macro: 0.4929, Accuracy: 0.5000\n","Epoch 149, Train Loss: 0.6505, Val Loss: 0.6168, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 150, Train Loss: 0.6534, Val Loss: 0.6686, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 151, Train Loss: 0.7060, Val Loss: 0.6159, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.7272675914882933\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6858, Val Loss: 0.7062, F1 Micro: 0.4581, F1 Macro: 0.4581, Accuracy: 0.4581\n","Epoch 2, Train Loss: 0.6876, Val Loss: 0.6587, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6800, Val Loss: 0.6603, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6810, Val Loss: 0.6989, F1 Micro: 0.4860, F1 Macro: 0.4856, Accuracy: 0.4860\n","Epoch 5, Train Loss: 0.6789, Val Loss: 0.6588, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6748, Val Loss: 0.6597, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 7, Train Loss: 0.6735, Val Loss: 0.6644, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6676, Val Loss: 0.6643, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6707, Val Loss: 0.6600, F1 Micro: 0.6648, F1 Macro: 0.5547, Accuracy: 0.6648\n","Epoch 10, Train Loss: 0.6635, Val Loss: 0.6505, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 11, Train Loss: 0.6475, Val Loss: 0.6520, F1 Micro: 0.6648, F1 Macro: 0.5785, Accuracy: 0.6648\n","Epoch 12, Train Loss: 0.6474, Val Loss: 0.6438, F1 Micro: 0.7095, F1 Macro: 0.5956, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.6337, Val Loss: 0.6478, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 14, Train Loss: 0.6295, Val Loss: 0.6478, F1 Micro: 0.7095, F1 Macro: 0.6249, Accuracy: 0.7095\n","Epoch 15, Train Loss: 0.6319, Val Loss: 0.6630, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 16, Train Loss: 0.6303, Val Loss: 0.6434, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 17, Train Loss: 0.6246, Val Loss: 0.6468, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 18, Train Loss: 0.6243, Val Loss: 0.6490, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6318, Val Loss: 0.6509, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 20, Train Loss: 0.6186, Val Loss: 0.6402, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 21, Train Loss: 0.6222, Val Loss: 0.6483, F1 Micro: 0.6927, F1 Macro: 0.5888, Accuracy: 0.6927\n","Epoch 22, Train Loss: 0.6249, Val Loss: 0.6400, F1 Micro: 0.7207, F1 Macro: 0.6612, Accuracy: 0.7207\n","Epoch 23, Train Loss: 0.6214, Val Loss: 0.6449, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 24, Train Loss: 0.6188, Val Loss: 0.6446, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 25, Train Loss: 0.6354, Val Loss: 0.6390, F1 Micro: 0.7151, F1 Macro: 0.6440, Accuracy: 0.7151\n","Epoch 26, Train Loss: 0.6207, Val Loss: 0.6409, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6913, Val Loss: 0.6785, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6822, Val Loss: 0.6836, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 3, Train Loss: 0.6843, Val Loss: 0.6819, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 4, Train Loss: 0.6758, Val Loss: 0.6700, F1 Micro: 0.6461, F1 Macro: 0.4337, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6726, Val Loss: 0.6702, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6706, Val Loss: 0.6671, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6757, Val Loss: 0.6660, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6685, Val Loss: 0.6614, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6775, Val Loss: 0.6626, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6683, Val Loss: 0.6649, F1 Micro: 0.6742, F1 Macro: 0.5239, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6685, Val Loss: 0.6548, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6717, Val Loss: 0.6546, F1 Micro: 0.6910, F1 Macro: 0.5750, Accuracy: 0.6910\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6926, Val Loss: 0.6699, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6886, Val Loss: 0.6781, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6802, Val Loss: 0.6720, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6804, Val Loss: 0.6675, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6715, Val Loss: 0.6678, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6729, Val Loss: 0.6644, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.6742, Val Loss: 0.6638, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6732, Val Loss: 0.6627, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6681, Val Loss: 0.6610, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6657, Val Loss: 0.6592, F1 Micro: 0.6292, F1 Macro: 0.5019, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6610, Val Loss: 0.6499, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6466, Val Loss: 0.6470, F1 Micro: 0.6236, F1 Macro: 0.5055, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6834, Val Loss: 0.6900, F1 Micro: 0.5618, F1 Macro: 0.4363, Accuracy: 0.5618\n","Epoch 2, Train Loss: 0.6682, Val Loss: 0.7519, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6694, Val Loss: 0.6995, F1 Micro: 0.5787, F1 Macro: 0.4817, Accuracy: 0.5787\n","Epoch 4, Train Loss: 0.6628, Val Loss: 0.6925, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6592, Val Loss: 0.7225, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 6, Train Loss: 0.6612, Val Loss: 0.6936, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6679, Val Loss: 0.6988, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 8, Train Loss: 0.6632, Val Loss: 0.7021, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6630, Val Loss: 0.6947, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6533, Val Loss: 0.7286, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6477, Val Loss: 0.6981, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 12, Train Loss: 0.6507, Val Loss: 0.6708, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6289, Val Loss: 0.6575, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6208, Val Loss: 0.6641, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 15, Train Loss: 0.6297, Val Loss: 0.6571, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6254, Val Loss: 0.7027, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6229, Val Loss: 0.6575, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6178, Val Loss: 0.7022, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.6227, Val Loss: 0.6801, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 20, Train Loss: 0.6286, Val Loss: 0.6603, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 21, Train Loss: 0.6340, Val Loss: 0.7025, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 22, Train Loss: 0.6188, Val Loss: 0.6568, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 23, Train Loss: 0.6139, Val Loss: 0.6990, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.6230, Val Loss: 0.6790, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 25, Train Loss: 0.6284, Val Loss: 0.6755, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6862, Val Loss: 0.6705, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6777, Val Loss: 0.6881, F1 Micro: 0.6124, F1 Macro: 0.4283, Accuracy: 0.6124\n","Epoch 3, Train Loss: 0.6840, Val Loss: 0.6709, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6792, Val Loss: 0.6804, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 5, Train Loss: 0.6738, Val Loss: 0.6767, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6704, Val Loss: 0.6762, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6716, Val Loss: 0.6719, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.6708, Val Loss: 0.6680, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6690, Val Loss: 0.6741, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6632, Val Loss: 0.6679, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6585, Val Loss: 0.6708, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.685700834850292\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6898, Val Loss: 0.7044, F1 Micro: 0.3743, F1 Macro: 0.3743, Accuracy: 0.3743\n","Epoch 2, Train Loss: 0.6835, Val Loss: 0.6630, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6801, Val Loss: 0.6684, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 4, Train Loss: 0.6777, Val Loss: 0.6581, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6755, Val Loss: 0.6609, F1 Micro: 0.6480, F1 Macro: 0.4345, Accuracy: 0.6480\n","Epoch 6, Train Loss: 0.6730, Val Loss: 0.6668, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 7, Train Loss: 0.6735, Val Loss: 0.6593, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 8, Train Loss: 0.6672, Val Loss: 0.6547, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 9, Train Loss: 0.6638, Val Loss: 0.6574, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 10, Train Loss: 0.6590, Val Loss: 0.6523, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 11, Train Loss: 0.6446, Val Loss: 0.6555, F1 Micro: 0.6872, F1 Macro: 0.5571, Accuracy: 0.6872\n","Epoch 12, Train Loss: 0.6415, Val Loss: 0.6555, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 13, Train Loss: 0.6249, Val Loss: 0.6499, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 14, Train Loss: 0.6321, Val Loss: 0.6490, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 15, Train Loss: 0.6349, Val Loss: 0.6503, F1 Micro: 0.6592, F1 Macro: 0.4954, Accuracy: 0.6592\n","Epoch 16, Train Loss: 0.6290, Val Loss: 0.6485, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 17, Train Loss: 0.6251, Val Loss: 0.6512, F1 Micro: 0.7095, F1 Macro: 0.6082, Accuracy: 0.7095\n","Epoch 18, Train Loss: 0.6237, Val Loss: 0.6655, F1 Micro: 0.6872, F1 Macro: 0.5571, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6314, Val Loss: 0.6423, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 20, Train Loss: 0.6279, Val Loss: 0.6469, F1 Micro: 0.7039, F1 Macro: 0.6151, Accuracy: 0.7039\n","Epoch 21, Train Loss: 0.6289, Val Loss: 0.6503, F1 Micro: 0.6816, F1 Macro: 0.6349, Accuracy: 0.6816\n","Epoch 22, Train Loss: 0.6249, Val Loss: 0.6404, F1 Micro: 0.7151, F1 Macro: 0.6440, Accuracy: 0.7151\n","Epoch 23, Train Loss: 0.6196, Val Loss: 0.6586, F1 Micro: 0.6760, F1 Macro: 0.6232, Accuracy: 0.6760\n","Epoch 24, Train Loss: 0.6268, Val Loss: 0.6454, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 25, Train Loss: 0.6358, Val Loss: 0.6394, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 26, Train Loss: 0.6205, Val Loss: 0.6414, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 27, Train Loss: 0.6258, Val Loss: 0.6442, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 28, Train Loss: 0.6165, Val Loss: 0.6644, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 29, Train Loss: 0.6205, Val Loss: 0.6374, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 30, Train Loss: 0.6225, Val Loss: 0.6369, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 31, Train Loss: 0.6191, Val Loss: 0.6392, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 32, Train Loss: 0.6196, Val Loss: 0.6390, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 33, Train Loss: 0.6220, Val Loss: 0.6390, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 34, Train Loss: 0.6235, Val Loss: 0.6362, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 35, Train Loss: 0.6194, Val Loss: 0.6548, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Epoch 36, Train Loss: 0.6307, Val Loss: 0.6384, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 37, Train Loss: 0.6239, Val Loss: 0.6381, F1 Micro: 0.7207, F1 Macro: 0.6393, Accuracy: 0.7207\n","Epoch 38, Train Loss: 0.6212, Val Loss: 0.6423, F1 Micro: 0.6816, F1 Macro: 0.6413, Accuracy: 0.6816\n","Epoch 39, Train Loss: 0.6142, Val Loss: 0.6449, F1 Micro: 0.6760, F1 Macro: 0.6268, Accuracy: 0.6760\n","Epoch 40, Train Loss: 0.6224, Val Loss: 0.6549, F1 Micro: 0.6760, F1 Macro: 0.6365, Accuracy: 0.6760\n","Epoch 41, Train Loss: 0.6315, Val Loss: 0.6341, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 42, Train Loss: 0.6208, Val Loss: 0.6406, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 43, Train Loss: 0.6255, Val Loss: 0.6506, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 44, Train Loss: 0.6183, Val Loss: 0.6370, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 45, Train Loss: 0.6221, Val Loss: 0.6346, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 46, Train Loss: 0.6176, Val Loss: 0.6367, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 47, Train Loss: 0.6122, Val Loss: 0.6369, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 48, Train Loss: 0.6204, Val Loss: 0.6349, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 49, Train Loss: 0.6179, Val Loss: 0.6343, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 50, Train Loss: 0.6129, Val Loss: 0.6344, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 51, Train Loss: 0.6221, Val Loss: 0.6415, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 52, Train Loss: 0.6287, Val Loss: 0.6371, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 53, Train Loss: 0.6193, Val Loss: 0.6314, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 54, Train Loss: 0.6200, Val Loss: 0.6299, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 55, Train Loss: 0.6175, Val Loss: 0.6323, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 56, Train Loss: 0.6157, Val Loss: 0.6368, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 57, Train Loss: 0.6232, Val Loss: 0.6293, F1 Micro: 0.7318, F1 Macro: 0.6710, Accuracy: 0.7318\n","Epoch 58, Train Loss: 0.6215, Val Loss: 0.6392, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 59, Train Loss: 0.6178, Val Loss: 0.6331, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 60, Train Loss: 0.6178, Val Loss: 0.6340, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 61, Train Loss: 0.6268, Val Loss: 0.6323, F1 Micro: 0.7151, F1 Macro: 0.6440, Accuracy: 0.7151\n","Epoch 62, Train Loss: 0.6163, Val Loss: 0.6300, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 63, Train Loss: 0.6197, Val Loss: 0.6315, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 64, Train Loss: 0.6201, Val Loss: 0.6298, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 65, Train Loss: 0.6129, Val Loss: 0.6454, F1 Micro: 0.6927, F1 Macro: 0.6508, Accuracy: 0.6927\n","Epoch 66, Train Loss: 0.6197, Val Loss: 0.6290, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 67, Train Loss: 0.6224, Val Loss: 0.6343, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 68, Train Loss: 0.6122, Val Loss: 0.6308, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 69, Train Loss: 0.6123, Val Loss: 0.6389, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 70, Train Loss: 0.6158, Val Loss: 0.6345, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 71, Train Loss: 0.6189, Val Loss: 0.6338, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 72, Train Loss: 0.6136, Val Loss: 0.6377, F1 Micro: 0.6872, F1 Macro: 0.6460, Accuracy: 0.6872\n","Epoch 73, Train Loss: 0.6184, Val Loss: 0.6302, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 74, Train Loss: 0.6168, Val Loss: 0.6321, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 75, Train Loss: 0.6174, Val Loss: 0.6278, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 76, Train Loss: 0.6175, Val Loss: 0.6354, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 77, Train Loss: 0.6164, Val Loss: 0.6312, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 78, Train Loss: 0.6149, Val Loss: 0.6316, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 79, Train Loss: 0.6100, Val Loss: 0.6308, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 80, Train Loss: 0.6135, Val Loss: 0.6348, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 81, Train Loss: 0.6230, Val Loss: 0.6281, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 82, Train Loss: 0.6149, Val Loss: 0.6282, F1 Micro: 0.7263, F1 Macro: 0.6801, Accuracy: 0.7263\n","Epoch 83, Train Loss: 0.6190, Val Loss: 0.6272, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 84, Train Loss: 0.6181, Val Loss: 0.6274, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 85, Train Loss: 0.6147, Val Loss: 0.6303, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 86, Train Loss: 0.6236, Val Loss: 0.6302, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 87, Train Loss: 0.6131, Val Loss: 0.6310, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 88, Train Loss: 0.6167, Val Loss: 0.6293, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 89, Train Loss: 0.6195, Val Loss: 0.6331, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 90, Train Loss: 0.6123, Val Loss: 0.6350, F1 Micro: 0.6704, F1 Macro: 0.6346, Accuracy: 0.6704\n","Epoch 91, Train Loss: 0.6144, Val Loss: 0.6316, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 92, Train Loss: 0.6183, Val Loss: 0.6263, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 93, Train Loss: 0.6106, Val Loss: 0.6335, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 94, Train Loss: 0.6102, Val Loss: 0.6269, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 95, Train Loss: 0.6137, Val Loss: 0.6418, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 96, Train Loss: 0.6175, Val Loss: 0.6273, F1 Micro: 0.7263, F1 Macro: 0.6734, Accuracy: 0.7263\n","Epoch 97, Train Loss: 0.6121, Val Loss: 0.6353, F1 Micro: 0.6983, F1 Macro: 0.5993, Accuracy: 0.6983\n","Epoch 98, Train Loss: 0.6129, Val Loss: 0.6267, F1 Micro: 0.7207, F1 Macro: 0.6752, Accuracy: 0.7207\n","Epoch 99, Train Loss: 0.6148, Val Loss: 0.6288, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 100, Train Loss: 0.6134, Val Loss: 0.6266, F1 Micro: 0.7318, F1 Macro: 0.6882, Accuracy: 0.7318\n","Epoch 101, Train Loss: 0.6141, Val Loss: 0.6258, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 102, Train Loss: 0.6182, Val Loss: 0.6301, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 103, Train Loss: 0.6072, Val Loss: 0.6293, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 104, Train Loss: 0.6159, Val Loss: 0.6272, F1 Micro: 0.7207, F1 Macro: 0.6752, Accuracy: 0.7207\n","Epoch 105, Train Loss: 0.6143, Val Loss: 0.6276, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 106, Train Loss: 0.6119, Val Loss: 0.6287, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 107, Train Loss: 0.6148, Val Loss: 0.6275, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6868, Val Loss: 0.6761, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6785, Val Loss: 0.6659, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6809, Val Loss: 0.6848, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 4, Train Loss: 0.6822, Val Loss: 0.6652, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6709, Val Loss: 0.6697, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6743, Val Loss: 0.6771, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 7, Train Loss: 0.6780, Val Loss: 0.6662, F1 Micro: 0.6404, F1 Macro: 0.4310, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6657, Val Loss: 0.6638, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6734, Val Loss: 0.6611, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 10, Train Loss: 0.6684, Val Loss: 0.6619, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6743, Val Loss: 0.6555, F1 Micro: 0.6461, F1 Macro: 0.4337, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6715, Val Loss: 0.6528, F1 Micro: 0.6798, F1 Macro: 0.5364, Accuracy: 0.6798\n","Epoch 13, Train Loss: 0.6602, Val Loss: 0.6389, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6536, Val Loss: 0.6389, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 15, Train Loss: 0.6582, Val Loss: 0.6197, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6523, Val Loss: 0.6043, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 17, Train Loss: 0.6381, Val Loss: 0.6251, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6446, Val Loss: 0.6023, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 19, Train Loss: 0.6530, Val Loss: 0.6005, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6454, Val Loss: 0.5892, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 21, Train Loss: 0.6394, Val Loss: 0.6108, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 22, Train Loss: 0.6367, Val Loss: 0.6049, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.6458, Val Loss: 0.5884, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 24, Train Loss: 0.6405, Val Loss: 0.5822, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 25, Train Loss: 0.6432, Val Loss: 0.5807, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 26, Train Loss: 0.6403, Val Loss: 0.5867, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 27, Train Loss: 0.6352, Val Loss: 0.5944, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 28, Train Loss: 0.6411, Val Loss: 0.5807, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 29, Train Loss: 0.6324, Val Loss: 0.5868, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 30, Train Loss: 0.6290, Val Loss: 0.5767, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 31, Train Loss: 0.6327, Val Loss: 0.5796, F1 Micro: 0.7528, F1 Macro: 0.6862, Accuracy: 0.7528\n","Epoch 32, Train Loss: 0.6295, Val Loss: 0.5792, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 33, Train Loss: 0.6469, Val Loss: 0.5783, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 34, Train Loss: 0.6324, Val Loss: 0.5782, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 35, Train Loss: 0.6410, Val Loss: 0.5833, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 36, Train Loss: 0.6500, Val Loss: 0.5886, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 37, Train Loss: 0.6289, Val Loss: 0.5847, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 38, Train Loss: 0.6397, Val Loss: 0.5757, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 39, Train Loss: 0.6324, Val Loss: 0.6179, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 40, Train Loss: 0.6445, Val Loss: 0.5849, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 41, Train Loss: 0.6389, Val Loss: 0.5757, F1 Micro: 0.7360, F1 Macro: 0.6626, Accuracy: 0.7360\n","Epoch 42, Train Loss: 0.6304, Val Loss: 0.5733, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 43, Train Loss: 0.6245, Val Loss: 0.5763, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 44, Train Loss: 0.6346, Val Loss: 0.5741, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6394, Val Loss: 0.5760, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 46, Train Loss: 0.6345, Val Loss: 0.5747, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 47, Train Loss: 0.6281, Val Loss: 0.5776, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 48, Train Loss: 0.6324, Val Loss: 0.5727, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 49, Train Loss: 0.6297, Val Loss: 0.5791, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 50, Train Loss: 0.6319, Val Loss: 0.5752, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 51, Train Loss: 0.6398, Val Loss: 0.5756, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 52, Train Loss: 0.6349, Val Loss: 0.5759, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 53, Train Loss: 0.6285, Val Loss: 0.5793, F1 Micro: 0.7584, F1 Macro: 0.7186, Accuracy: 0.7584\n","Epoch 54, Train Loss: 0.6275, Val Loss: 0.5722, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 55, Train Loss: 0.6204, Val Loss: 0.5781, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 56, Train Loss: 0.6324, Val Loss: 0.5701, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 57, Train Loss: 0.6270, Val Loss: 0.5858, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 58, Train Loss: 0.6281, Val Loss: 0.5754, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 59, Train Loss: 0.6377, Val Loss: 0.5823, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 60, Train Loss: 0.6264, Val Loss: 0.5717, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.6290, Val Loss: 0.5780, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 62, Train Loss: 0.6238, Val Loss: 0.5710, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 63, Train Loss: 0.6281, Val Loss: 0.5780, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 64, Train Loss: 0.6315, Val Loss: 0.5745, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 65, Train Loss: 0.6343, Val Loss: 0.5865, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 66, Train Loss: 0.6200, Val Loss: 0.5715, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 67, Train Loss: 0.6308, Val Loss: 0.5689, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 68, Train Loss: 0.6256, Val Loss: 0.5779, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 69, Train Loss: 0.6368, Val Loss: 0.5807, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 70, Train Loss: 0.6349, Val Loss: 0.5753, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 71, Train Loss: 0.6268, Val Loss: 0.5783, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 72, Train Loss: 0.6271, Val Loss: 0.5710, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 73, Train Loss: 0.6196, Val Loss: 0.5795, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 74, Train Loss: 0.6183, Val Loss: 0.5753, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 75, Train Loss: 0.6361, Val Loss: 0.5673, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 76, Train Loss: 0.6193, Val Loss: 0.5851, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 77, Train Loss: 0.6229, Val Loss: 0.5698, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 78, Train Loss: 0.6334, Val Loss: 0.5775, F1 Micro: 0.7640, F1 Macro: 0.7237, Accuracy: 0.7640\n","Epoch 79, Train Loss: 0.6282, Val Loss: 0.5742, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 80, Train Loss: 0.6250, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 81, Train Loss: 0.6303, Val Loss: 0.5713, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 82, Train Loss: 0.6348, Val Loss: 0.5747, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 83, Train Loss: 0.6341, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 84, Train Loss: 0.6255, Val Loss: 0.5702, F1 Micro: 0.7528, F1 Macro: 0.7076, Accuracy: 0.7528\n","Epoch 85, Train Loss: 0.6353, Val Loss: 0.5755, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 86, Train Loss: 0.6202, Val Loss: 0.5755, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 87, Train Loss: 0.6225, Val Loss: 0.5686, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 88, Train Loss: 0.6128, Val Loss: 0.5916, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 89, Train Loss: 0.6279, Val Loss: 0.5770, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 90, Train Loss: 0.6298, Val Loss: 0.5723, F1 Micro: 0.7584, F1 Macro: 0.6913, Accuracy: 0.7584\n","Epoch 91, Train Loss: 0.6266, Val Loss: 0.5732, F1 Micro: 0.7584, F1 Macro: 0.6913, Accuracy: 0.7584\n","Epoch 92, Train Loss: 0.6330, Val Loss: 0.5771, F1 Micro: 0.7697, F1 Macro: 0.7316, Accuracy: 0.7697\n","Epoch 93, Train Loss: 0.6192, Val Loss: 0.5685, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 94, Train Loss: 0.6292, Val Loss: 0.5821, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 95, Train Loss: 0.6280, Val Loss: 0.5788, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 96, Train Loss: 0.6156, Val Loss: 0.5689, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 97, Train Loss: 0.6292, Val Loss: 0.5642, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 98, Train Loss: 0.6300, Val Loss: 0.5672, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 99, Train Loss: 0.6245, Val Loss: 0.5765, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 100, Train Loss: 0.6210, Val Loss: 0.5722, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 101, Train Loss: 0.6148, Val Loss: 0.5672, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 102, Train Loss: 0.6257, Val Loss: 0.5716, F1 Micro: 0.7697, F1 Macro: 0.7231, Accuracy: 0.7697\n","Epoch 103, Train Loss: 0.6274, Val Loss: 0.5683, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 104, Train Loss: 0.6209, Val Loss: 0.5652, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 105, Train Loss: 0.6220, Val Loss: 0.5673, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 106, Train Loss: 0.6220, Val Loss: 0.5771, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 107, Train Loss: 0.6269, Val Loss: 0.5875, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Epoch 108, Train Loss: 0.6232, Val Loss: 0.5740, F1 Micro: 0.7753, F1 Macro: 0.7283, Accuracy: 0.7753\n","Epoch 109, Train Loss: 0.6310, Val Loss: 0.5727, F1 Micro: 0.7697, F1 Macro: 0.7316, Accuracy: 0.7697\n","Epoch 110, Train Loss: 0.6299, Val Loss: 0.5688, F1 Micro: 0.7416, F1 Macro: 0.6762, Accuracy: 0.7416\n","Epoch 111, Train Loss: 0.6275, Val Loss: 0.5758, F1 Micro: 0.7247, F1 Macro: 0.6330, Accuracy: 0.7247\n","Epoch 112, Train Loss: 0.6267, Val Loss: 0.5807, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 113, Train Loss: 0.6205, Val Loss: 0.5659, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 114, Train Loss: 0.6198, Val Loss: 0.5643, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 115, Train Loss: 0.6208, Val Loss: 0.5706, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 116, Train Loss: 0.6238, Val Loss: 0.5715, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 117, Train Loss: 0.6277, Val Loss: 0.5728, F1 Micro: 0.7640, F1 Macro: 0.7237, Accuracy: 0.7640\n","Epoch 118, Train Loss: 0.6198, Val Loss: 0.5646, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 119, Train Loss: 0.6234, Val Loss: 0.5721, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 120, Train Loss: 0.6242, Val Loss: 0.5765, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 121, Train Loss: 0.6150, Val Loss: 0.5639, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 122, Train Loss: 0.6267, Val Loss: 0.5770, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 123, Train Loss: 0.6284, Val Loss: 0.5636, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 124, Train Loss: 0.6270, Val Loss: 0.5638, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 125, Train Loss: 0.6179, Val Loss: 0.5724, F1 Micro: 0.7753, F1 Macro: 0.7283, Accuracy: 0.7753\n","Epoch 126, Train Loss: 0.6178, Val Loss: 0.5874, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Epoch 127, Train Loss: 0.6285, Val Loss: 0.5642, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 128, Train Loss: 0.6195, Val Loss: 0.5671, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 129, Train Loss: 0.6187, Val Loss: 0.5624, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 130, Train Loss: 0.6225, Val Loss: 0.5761, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 131, Train Loss: 0.6246, Val Loss: 0.5752, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 132, Train Loss: 0.6211, Val Loss: 0.5664, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 133, Train Loss: 0.6232, Val Loss: 0.5711, F1 Micro: 0.7640, F1 Macro: 0.7237, Accuracy: 0.7640\n","Epoch 134, Train Loss: 0.6255, Val Loss: 0.5760, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 135, Train Loss: 0.6320, Val Loss: 0.5715, F1 Micro: 0.7697, F1 Macro: 0.7316, Accuracy: 0.7697\n","Epoch 136, Train Loss: 0.6209, Val Loss: 0.5742, F1 Micro: 0.7584, F1 Macro: 0.6913, Accuracy: 0.7584\n","Epoch 137, Train Loss: 0.6254, Val Loss: 0.5833, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Epoch 138, Train Loss: 0.6243, Val Loss: 0.5642, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 139, Train Loss: 0.6180, Val Loss: 0.5698, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 140, Train Loss: 0.6232, Val Loss: 0.5661, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 141, Train Loss: 0.6185, Val Loss: 0.5650, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 142, Train Loss: 0.6231, Val Loss: 0.5678, F1 Micro: 0.7360, F1 Macro: 0.6580, Accuracy: 0.7360\n","Epoch 143, Train Loss: 0.6201, Val Loss: 0.5782, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 144, Train Loss: 0.6237, Val Loss: 0.5634, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 145, Train Loss: 0.6191, Val Loss: 0.5660, F1 Micro: 0.7528, F1 Macro: 0.6902, Accuracy: 0.7528\n","Epoch 146, Train Loss: 0.6218, Val Loss: 0.5643, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 147, Train Loss: 0.6074, Val Loss: 0.5685, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 148, Train Loss: 0.6239, Val Loss: 0.5647, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 149, Train Loss: 0.6260, Val Loss: 0.5646, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 150, Train Loss: 0.6197, Val Loss: 0.5661, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 151, Train Loss: 0.6192, Val Loss: 0.5662, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 152, Train Loss: 0.6256, Val Loss: 0.5652, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 153, Train Loss: 0.6194, Val Loss: 0.5627, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 154, Train Loss: 0.6269, Val Loss: 0.5745, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 155, Train Loss: 0.6211, Val Loss: 0.5789, F1 Micro: 0.7809, F1 Macro: 0.7394, Accuracy: 0.7809\n","Epoch 156, Train Loss: 0.6330, Val Loss: 0.5640, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 157, Train Loss: 0.6265, Val Loss: 0.5843, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 158, Train Loss: 0.6279, Val Loss: 0.5819, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Epoch 159, Train Loss: 0.6293, Val Loss: 0.5648, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 160, Train Loss: 0.6217, Val Loss: 0.5634, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 161, Train Loss: 0.6204, Val Loss: 0.5733, F1 Micro: 0.7697, F1 Macro: 0.7316, Accuracy: 0.7697\n","Epoch 162, Train Loss: 0.6312, Val Loss: 0.5720, F1 Micro: 0.7753, F1 Macro: 0.7342, Accuracy: 0.7753\n","Epoch 163, Train Loss: 0.6249, Val Loss: 0.5621, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 164, Train Loss: 0.6222, Val Loss: 0.5702, F1 Micro: 0.7528, F1 Macro: 0.6862, Accuracy: 0.7528\n","Epoch 165, Train Loss: 0.6178, Val Loss: 0.5619, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 166, Train Loss: 0.6226, Val Loss: 0.5674, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 167, Train Loss: 0.6214, Val Loss: 0.5701, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 168, Train Loss: 0.6328, Val Loss: 0.5634, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 169, Train Loss: 0.6270, Val Loss: 0.5680, F1 Micro: 0.7584, F1 Macro: 0.7186, Accuracy: 0.7584\n","Epoch 170, Train Loss: 0.6204, Val Loss: 0.5677, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 171, Train Loss: 0.6151, Val Loss: 0.5653, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 172, Train Loss: 0.6202, Val Loss: 0.5899, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 173, Train Loss: 0.6173, Val Loss: 0.5764, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 174, Train Loss: 0.6236, Val Loss: 0.5647, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 175, Train Loss: 0.6171, Val Loss: 0.5625, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 176, Train Loss: 0.6260, Val Loss: 0.5643, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 177, Train Loss: 0.6188, Val Loss: 0.5746, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 178, Train Loss: 0.6156, Val Loss: 0.5655, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 179, Train Loss: 0.6334, Val Loss: 0.5686, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 180, Train Loss: 0.6136, Val Loss: 0.5629, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 181, Train Loss: 0.6251, Val Loss: 0.5658, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 182, Train Loss: 0.6214, Val Loss: 0.5722, F1 Micro: 0.7697, F1 Macro: 0.7199, Accuracy: 0.7697\n","Epoch 183, Train Loss: 0.6226, Val Loss: 0.5660, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 184, Train Loss: 0.6134, Val Loss: 0.5662, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 185, Train Loss: 0.6300, Val Loss: 0.5693, F1 Micro: 0.7640, F1 Macro: 0.7080, Accuracy: 0.7640\n","Epoch 186, Train Loss: 0.6285, Val Loss: 0.5652, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 187, Train Loss: 0.6173, Val Loss: 0.5899, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 188, Train Loss: 0.6184, Val Loss: 0.5640, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 189, Train Loss: 0.6142, Val Loss: 0.5787, F1 Micro: 0.7191, F1 Macro: 0.6226, Accuracy: 0.7191\n","Epoch 190, Train Loss: 0.6335, Val Loss: 0.5623, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 191, Train Loss: 0.6266, Val Loss: 0.5620, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 192, Train Loss: 0.6202, Val Loss: 0.5963, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 193, Train Loss: 0.6168, Val Loss: 0.5700, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 194, Train Loss: 0.6166, Val Loss: 0.5637, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 195, Train Loss: 0.6250, Val Loss: 0.5640, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 196, Train Loss: 0.6194, Val Loss: 0.5632, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 197, Train Loss: 0.6208, Val Loss: 0.5638, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 198, Train Loss: 0.6244, Val Loss: 0.5640, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 199, Train Loss: 0.6217, Val Loss: 0.5672, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 200, Train Loss: 0.6204, Val Loss: 0.5798, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6902, Val Loss: 0.6904, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6845, Val Loss: 0.6655, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6735, Val Loss: 0.6716, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6828, Val Loss: 0.6659, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6808, Val Loss: 0.6628, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6724, Val Loss: 0.6685, F1 Micro: 0.6236, F1 Macro: 0.4981, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6720, Val Loss: 0.6602, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6734, Val Loss: 0.6568, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6704, Val Loss: 0.6542, F1 Micro: 0.6348, F1 Macro: 0.4400, Accuracy: 0.6348\n","Epoch 10, Train Loss: 0.6602, Val Loss: 0.6507, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6495, Val Loss: 0.6456, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6463, Val Loss: 0.6368, F1 Micro: 0.6124, F1 Macro: 0.5047, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6361, Val Loss: 0.6449, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6417, Val Loss: 0.6287, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 15, Train Loss: 0.6307, Val Loss: 0.6586, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6384, Val Loss: 0.6271, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 17, Train Loss: 0.6321, Val Loss: 0.6230, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6200, Val Loss: 0.6345, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 19, Train Loss: 0.6311, Val Loss: 0.6267, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6328, Val Loss: 0.6280, F1 Micro: 0.6461, F1 Macro: 0.5697, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6381, Val Loss: 0.6250, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6310, Val Loss: 0.6305, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6236, Val Loss: 0.6383, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6437, Val Loss: 0.6550, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6326, Val Loss: 0.6240, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6346, Val Loss: 0.6309, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 27, Train Loss: 0.6196, Val Loss: 0.6288, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 28, Train Loss: 0.6263, Val Loss: 0.6335, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 29, Train Loss: 0.6297, Val Loss: 0.6342, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.6333, Val Loss: 0.6196, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6242, Val Loss: 0.6246, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 32, Train Loss: 0.6234, Val Loss: 0.6340, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 33, Train Loss: 0.6303, Val Loss: 0.6327, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6300, Val Loss: 0.6287, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 35, Train Loss: 0.6286, Val Loss: 0.6275, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.6213, Val Loss: 0.6220, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6221, Val Loss: 0.6301, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.6148, Val Loss: 0.6271, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 39, Train Loss: 0.6192, Val Loss: 0.6302, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 40, Train Loss: 0.6297, Val Loss: 0.6307, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.6227, Val Loss: 0.6243, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.6162, Val Loss: 0.6261, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6302, Val Loss: 0.6314, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 44, Train Loss: 0.6285, Val Loss: 0.6230, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 45, Train Loss: 0.6202, Val Loss: 0.6364, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 46, Train Loss: 0.6191, Val Loss: 0.6295, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6242, Val Loss: 0.6420, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.6193, Val Loss: 0.6268, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 49, Train Loss: 0.6116, Val Loss: 0.6248, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 50, Train Loss: 0.6197, Val Loss: 0.6298, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6250, Val Loss: 0.6293, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.6110, Val Loss: 0.6243, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 53, Train Loss: 0.6153, Val Loss: 0.6264, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6357, Val Loss: 0.6266, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 55, Train Loss: 0.6206, Val Loss: 0.6311, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 56, Train Loss: 0.6317, Val Loss: 0.6275, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 57, Train Loss: 0.6145, Val Loss: 0.6283, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 58, Train Loss: 0.6209, Val Loss: 0.6280, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.6069, Val Loss: 0.6243, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.6122, Val Loss: 0.6295, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.6334, Val Loss: 0.6255, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.6168, Val Loss: 0.6246, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.6210, Val Loss: 0.6356, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 64, Train Loss: 0.6219, Val Loss: 0.6263, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 65, Train Loss: 0.6172, Val Loss: 0.6239, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 66, Train Loss: 0.6211, Val Loss: 0.6309, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 67, Train Loss: 0.6084, Val Loss: 0.6530, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 68, Train Loss: 0.6080, Val Loss: 0.6321, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 69, Train Loss: 0.6188, Val Loss: 0.6341, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.6217, Val Loss: 0.6306, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 71, Train Loss: 0.6147, Val Loss: 0.6251, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 72, Train Loss: 0.6073, Val Loss: 0.6349, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 73, Train Loss: 0.6406, Val Loss: 0.6261, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.6209, Val Loss: 0.6248, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.6101, Val Loss: 0.6292, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 76, Train Loss: 0.6071, Val Loss: 0.6273, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 77, Train Loss: 0.6194, Val Loss: 0.6246, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 78, Train Loss: 0.6229, Val Loss: 0.6238, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.6206, Val Loss: 0.6235, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 80, Train Loss: 0.6273, Val Loss: 0.6258, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 81, Train Loss: 0.6217, Val Loss: 0.6466, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 82, Train Loss: 0.6161, Val Loss: 0.6325, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 83, Train Loss: 0.6176, Val Loss: 0.6379, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 84, Train Loss: 0.6175, Val Loss: 0.6344, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 85, Train Loss: 0.6097, Val Loss: 0.6295, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 86, Train Loss: 0.6175, Val Loss: 0.6260, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 87, Train Loss: 0.6148, Val Loss: 0.6267, F1 Micro: 0.6573, F1 Macro: 0.6082, Accuracy: 0.6573\n","Epoch 88, Train Loss: 0.6091, Val Loss: 0.6270, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 89, Train Loss: 0.6132, Val Loss: 0.6269, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 90, Train Loss: 0.6103, Val Loss: 0.6285, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 91, Train Loss: 0.6146, Val Loss: 0.6309, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 92, Train Loss: 0.6075, Val Loss: 0.6318, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 93, Train Loss: 0.6171, Val Loss: 0.6297, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 94, Train Loss: 0.6225, Val Loss: 0.6278, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 95, Train Loss: 0.6100, Val Loss: 0.6283, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 96, Train Loss: 0.6152, Val Loss: 0.6292, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 97, Train Loss: 0.6190, Val Loss: 0.6253, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 98, Train Loss: 0.6227, Val Loss: 0.6230, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 99, Train Loss: 0.6206, Val Loss: 0.6386, F1 Micro: 0.6798, F1 Macro: 0.5522, Accuracy: 0.6798\n","Epoch 100, Train Loss: 0.6365, Val Loss: 0.6345, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 101, Train Loss: 0.6156, Val Loss: 0.6363, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 102, Train Loss: 0.6120, Val Loss: 0.6244, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 103, Train Loss: 0.6111, Val Loss: 0.6280, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 104, Train Loss: 0.6092, Val Loss: 0.6272, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 105, Train Loss: 0.6163, Val Loss: 0.6262, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 106, Train Loss: 0.6101, Val Loss: 0.6289, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 107, Train Loss: 0.6059, Val Loss: 0.6280, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 108, Train Loss: 0.6185, Val Loss: 0.6266, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 109, Train Loss: 0.6112, Val Loss: 0.6262, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 110, Train Loss: 0.6054, Val Loss: 0.6288, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 111, Train Loss: 0.6097, Val Loss: 0.6332, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 112, Train Loss: 0.6165, Val Loss: 0.6266, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 113, Train Loss: 0.6082, Val Loss: 0.6307, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 114, Train Loss: 0.6198, Val Loss: 0.6236, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 115, Train Loss: 0.6127, Val Loss: 0.6283, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 116, Train Loss: 0.6104, Val Loss: 0.6291, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 117, Train Loss: 0.6135, Val Loss: 0.6270, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 118, Train Loss: 0.6184, Val Loss: 0.6290, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 119, Train Loss: 0.6131, Val Loss: 0.6225, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 120, Train Loss: 0.6107, Val Loss: 0.6360, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 121, Train Loss: 0.6140, Val Loss: 0.6240, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 122, Train Loss: 0.6213, Val Loss: 0.6268, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 123, Train Loss: 0.6181, Val Loss: 0.6225, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 124, Train Loss: 0.6098, Val Loss: 0.6384, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 125, Train Loss: 0.6197, Val Loss: 0.6226, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 126, Train Loss: 0.6269, Val Loss: 0.6236, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 127, Train Loss: 0.6051, Val Loss: 0.6270, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 128, Train Loss: 0.6136, Val Loss: 0.6271, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 129, Train Loss: 0.6188, Val Loss: 0.6230, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 130, Train Loss: 0.6139, Val Loss: 0.6317, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 131, Train Loss: 0.6152, Val Loss: 0.6443, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6738, Val Loss: 0.7221, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 2, Train Loss: 0.6649, Val Loss: 0.7650, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6659, Val Loss: 0.7724, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6640, Val Loss: 0.7178, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 5, Train Loss: 0.6668, Val Loss: 0.6957, F1 Micro: 0.5787, F1 Macro: 0.4753, Accuracy: 0.5787\n","Epoch 6, Train Loss: 0.6699, Val Loss: 0.7033, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6590, Val Loss: 0.6972, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6523, Val Loss: 0.7264, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6615, Val Loss: 0.6999, F1 Micro: 0.5674, F1 Macro: 0.4544, Accuracy: 0.5674\n","Epoch 10, Train Loss: 0.6560, Val Loss: 0.6864, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6493, Val Loss: 0.6859, F1 Micro: 0.5843, F1 Macro: 0.4916, Accuracy: 0.5843\n","Epoch 12, Train Loss: 0.6392, Val Loss: 0.6730, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6377, Val Loss: 0.6858, F1 Micro: 0.5843, F1 Macro: 0.4916, Accuracy: 0.5843\n","Epoch 14, Train Loss: 0.6264, Val Loss: 0.6819, F1 Micro: 0.5899, F1 Macro: 0.5222, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.6195, Val Loss: 0.6667, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 16, Train Loss: 0.6246, Val Loss: 0.7082, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 17, Train Loss: 0.6195, Val Loss: 0.6587, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6152, Val Loss: 0.7045, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 19, Train Loss: 0.6177, Val Loss: 0.7044, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6173, Val Loss: 0.6715, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 21, Train Loss: 0.6139, Val Loss: 0.6570, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 22, Train Loss: 0.6163, Val Loss: 0.6760, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 23, Train Loss: 0.6074, Val Loss: 0.6884, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.6213, Val Loss: 0.6714, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 25, Train Loss: 0.6082, Val Loss: 0.6861, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 26, Train Loss: 0.6303, Val Loss: 0.6743, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 27, Train Loss: 0.6209, Val Loss: 0.6692, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6061, Val Loss: 0.7546, F1 Micro: 0.5899, F1 Macro: 0.5174, Accuracy: 0.5899\n","Epoch 29, Train Loss: 0.6144, Val Loss: 0.6631, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 30, Train Loss: 0.6235, Val Loss: 0.6585, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6134, Val Loss: 0.6855, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 32, Train Loss: 0.6107, Val Loss: 0.6886, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 33, Train Loss: 0.6124, Val Loss: 0.6667, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 34, Train Loss: 0.6115, Val Loss: 0.6871, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 35, Train Loss: 0.6129, Val Loss: 0.6726, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Epoch 36, Train Loss: 0.6102, Val Loss: 0.6879, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 37, Train Loss: 0.6011, Val Loss: 0.7519, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 38, Train Loss: 0.6112, Val Loss: 0.6520, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 39, Train Loss: 0.6172, Val Loss: 0.6782, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6152, Val Loss: 0.6812, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 41, Train Loss: 0.6158, Val Loss: 0.6526, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.6124, Val Loss: 0.6828, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 43, Train Loss: 0.6163, Val Loss: 0.6529, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 44, Train Loss: 0.6121, Val Loss: 0.6664, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 45, Train Loss: 0.6059, Val Loss: 0.6936, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6042, Val Loss: 0.7306, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 47, Train Loss: 0.6154, Val Loss: 0.6488, F1 Micro: 0.6854, F1 Macro: 0.6720, Accuracy: 0.6854\n","Epoch 48, Train Loss: 0.6223, Val Loss: 0.7106, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 49, Train Loss: 0.6204, Val Loss: 0.6514, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 50, Train Loss: 0.6115, Val Loss: 0.7005, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 51, Train Loss: 0.6184, Val Loss: 0.6986, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 52, Train Loss: 0.6136, Val Loss: 0.6688, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 53, Train Loss: 0.6213, Val Loss: 0.6561, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 54, Train Loss: 0.6189, Val Loss: 0.6846, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 55, Train Loss: 0.6020, Val Loss: 0.6821, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 56, Train Loss: 0.6073, Val Loss: 0.6672, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 57, Train Loss: 0.6141, Val Loss: 0.6830, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 58, Train Loss: 0.6068, Val Loss: 0.6890, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Epoch 59, Train Loss: 0.6100, Val Loss: 0.6783, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 60, Train Loss: 0.6062, Val Loss: 0.6774, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 61, Train Loss: 0.6150, Val Loss: 0.6567, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 62, Train Loss: 0.6187, Val Loss: 0.6410, F1 Micro: 0.6629, F1 Macro: 0.6577, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.6122, Val Loss: 0.7054, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 64, Train Loss: 0.6047, Val Loss: 0.6420, F1 Micro: 0.6685, F1 Macro: 0.6607, Accuracy: 0.6685\n","Epoch 65, Train Loss: 0.6048, Val Loss: 0.6910, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 66, Train Loss: 0.6086, Val Loss: 0.6804, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 67, Train Loss: 0.6092, Val Loss: 0.6453, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 68, Train Loss: 0.6166, Val Loss: 0.6601, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 69, Train Loss: 0.6071, Val Loss: 0.6739, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 70, Train Loss: 0.6110, Val Loss: 0.6473, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 71, Train Loss: 0.6095, Val Loss: 0.6769, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 72, Train Loss: 0.6125, Val Loss: 0.6732, F1 Micro: 0.6404, F1 Macro: 0.6123, Accuracy: 0.6404\n","Epoch 73, Train Loss: 0.6095, Val Loss: 0.6548, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.6058, Val Loss: 0.6478, F1 Micro: 0.6798, F1 Macro: 0.6698, Accuracy: 0.6798\n","Epoch 75, Train Loss: 0.5984, Val Loss: 0.6622, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 76, Train Loss: 0.6007, Val Loss: 0.7029, F1 Micro: 0.6292, F1 Macro: 0.5780, Accuracy: 0.6292\n","Epoch 77, Train Loss: 0.6232, Val Loss: 0.6628, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 78, Train Loss: 0.6065, Val Loss: 0.6551, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 79, Train Loss: 0.6034, Val Loss: 0.7073, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 80, Train Loss: 0.6144, Val Loss: 0.6461, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 81, Train Loss: 0.6192, Val Loss: 0.6475, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 82, Train Loss: 0.6029, Val Loss: 0.6699, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 83, Train Loss: 0.6163, Val Loss: 0.6601, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 84, Train Loss: 0.5974, Val Loss: 0.6538, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 85, Train Loss: 0.5976, Val Loss: 0.6577, F1 Micro: 0.6629, F1 Macro: 0.6430, Accuracy: 0.6629\n","Epoch 86, Train Loss: 0.6070, Val Loss: 0.6537, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 87, Train Loss: 0.6038, Val Loss: 0.6778, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 88, Train Loss: 0.6234, Val Loss: 0.6879, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6931, Val Loss: 0.6796, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 2, Train Loss: 0.6780, Val Loss: 0.6840, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.6812, Val Loss: 0.6900, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6760, Val Loss: 0.6746, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6666, Val Loss: 0.6830, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6763, Val Loss: 0.6737, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6724, Val Loss: 0.6684, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6661, Val Loss: 0.6754, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 9, Train Loss: 0.6690, Val Loss: 0.6627, F1 Micro: 0.6180, F1 Macro: 0.4868, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.6655, Val Loss: 0.6599, F1 Micro: 0.6180, F1 Macro: 0.4868, Accuracy: 0.6180\n","Epoch 11, Train Loss: 0.6632, Val Loss: 0.6623, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6526, Val Loss: 0.6589, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6508, Val Loss: 0.6397, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 14, Train Loss: 0.6320, Val Loss: 0.6391, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6283, Val Loss: 0.6419, F1 Micro: 0.6404, F1 Macro: 0.6123, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6320, Val Loss: 0.6396, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6265, Val Loss: 0.6341, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6441, Val Loss: 0.6424, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.6263, Val Loss: 0.6437, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 20, Train Loss: 0.6338, Val Loss: 0.6334, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 21, Train Loss: 0.6321, Val Loss: 0.6553, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6286, Val Loss: 0.6472, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 23, Train Loss: 0.6163, Val Loss: 0.6297, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 24, Train Loss: 0.6210, Val Loss: 0.6365, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6215, Val Loss: 0.6404, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 26, Train Loss: 0.6207, Val Loss: 0.6374, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 27, Train Loss: 0.6277, Val Loss: 0.6355, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.6214, Val Loss: 0.6365, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 29, Train Loss: 0.6218, Val Loss: 0.6413, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 30, Train Loss: 0.6301, Val Loss: 0.6396, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 31, Train Loss: 0.6215, Val Loss: 0.6299, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 32, Train Loss: 0.6212, Val Loss: 0.6300, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 33, Train Loss: 0.6201, Val Loss: 0.6477, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6264, Val Loss: 0.6372, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.6188, Val Loss: 0.6346, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 36, Train Loss: 0.6292, Val Loss: 0.6371, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 37, Train Loss: 0.6194, Val Loss: 0.6311, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 38, Train Loss: 0.6130, Val Loss: 0.6438, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 39, Train Loss: 0.6302, Val Loss: 0.6389, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 40, Train Loss: 0.6165, Val Loss: 0.6332, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 41, Train Loss: 0.6232, Val Loss: 0.6287, F1 Micro: 0.7022, F1 Macro: 0.6872, Accuracy: 0.7022\n","Epoch 42, Train Loss: 0.6314, Val Loss: 0.6295, F1 Micro: 0.6966, F1 Macro: 0.6821, Accuracy: 0.6966\n","Epoch 43, Train Loss: 0.6192, Val Loss: 0.6286, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6298, Val Loss: 0.6274, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 45, Train Loss: 0.6182, Val Loss: 0.6257, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.6175, Val Loss: 0.6422, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6261, Val Loss: 0.6275, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 48, Train Loss: 0.6151, Val Loss: 0.6292, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 49, Train Loss: 0.6105, Val Loss: 0.6540, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 50, Train Loss: 0.6158, Val Loss: 0.6378, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6220, Val Loss: 0.6588, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 52, Train Loss: 0.6202, Val Loss: 0.6256, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 53, Train Loss: 0.6189, Val Loss: 0.6238, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 54, Train Loss: 0.6131, Val Loss: 0.6236, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 55, Train Loss: 0.6317, Val Loss: 0.6446, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 56, Train Loss: 0.6202, Val Loss: 0.6303, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 57, Train Loss: 0.6191, Val Loss: 0.6302, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 58, Train Loss: 0.6204, Val Loss: 0.6333, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 59, Train Loss: 0.6109, Val Loss: 0.6459, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 60, Train Loss: 0.6237, Val Loss: 0.6400, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.6122, Val Loss: 0.6355, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.6242, Val Loss: 0.6291, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 63, Train Loss: 0.6116, Val Loss: 0.6387, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 64, Train Loss: 0.6225, Val Loss: 0.6252, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 65, Train Loss: 0.6114, Val Loss: 0.6359, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 66, Train Loss: 0.6163, Val Loss: 0.6314, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 67, Train Loss: 0.6201, Val Loss: 0.6245, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 68, Train Loss: 0.6062, Val Loss: 0.6290, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 69, Train Loss: 0.6150, Val Loss: 0.6289, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 70, Train Loss: 0.6199, Val Loss: 0.6338, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 71, Train Loss: 0.6116, Val Loss: 0.6354, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 72, Train Loss: 0.6192, Val Loss: 0.6330, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 73, Train Loss: 0.6154, Val Loss: 0.6243, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7272675914882932\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6837, Val Loss: 0.6907, F1 Micro: 0.5419, F1 Macro: 0.5342, Accuracy: 0.5419\n","Epoch 2, Train Loss: 0.6870, Val Loss: 0.6744, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6768, Val Loss: 0.6865, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 4, Train Loss: 0.6827, Val Loss: 0.6731, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6773, Val Loss: 0.6745, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6782, Val Loss: 0.6715, F1 Micro: 0.6648, F1 Macro: 0.5547, Accuracy: 0.6648\n","Epoch 7, Train Loss: 0.6728, Val Loss: 0.6711, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6724, Val Loss: 0.6728, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6738, Val Loss: 0.6705, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6763, Val Loss: 0.6691, F1 Micro: 0.6480, F1 Macro: 0.4466, Accuracy: 0.6480\n","Epoch 11, Train Loss: 0.6710, Val Loss: 0.6743, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 12, Train Loss: 0.6646, Val Loss: 0.6698, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 13, Train Loss: 0.6571, Val Loss: 0.6652, F1 Micro: 0.6536, F1 Macro: 0.4822, Accuracy: 0.6536\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6983, Val Loss: 0.6788, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6776, Val Loss: 0.6731, F1 Micro: 0.6517, F1 Macro: 0.4712, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6793, Val Loss: 0.6750, F1 Micro: 0.6742, F1 Macro: 0.5239, Accuracy: 0.6742\n","Epoch 4, Train Loss: 0.6720, Val Loss: 0.6763, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6723, Val Loss: 0.6727, F1 Micro: 0.6742, F1 Macro: 0.5239, Accuracy: 0.6742\n","Epoch 6, Train Loss: 0.6759, Val Loss: 0.6731, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6751, Val Loss: 0.6707, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6765, Val Loss: 0.6800, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6728, Val Loss: 0.6737, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6755, Val Loss: 0.6708, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6704, Val Loss: 0.6725, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6699, Val Loss: 0.6664, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6667, Val Loss: 0.6649, F1 Micro: 0.6404, F1 Macro: 0.4310, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6816, Val Loss: 0.6784, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6780, Val Loss: 0.6775, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6764, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6794, Val Loss: 0.6777, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6765, Val Loss: 0.6773, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6832, Val Loss: 0.6771, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6738, Val Loss: 0.6781, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6767, Val Loss: 0.6806, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6720, Val Loss: 0.6844, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6670, Val Loss: 0.6712, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6690, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6693, Val Loss: 0.6723, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6641, Val Loss: 0.6669, F1 Micro: 0.6292, F1 Macro: 0.4255, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6561, Val Loss: 0.6716, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6563, Val Loss: 0.6611, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6493, Val Loss: 0.6504, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 17, Train Loss: 0.6340, Val Loss: 0.6586, F1 Micro: 0.6180, F1 Macro: 0.5151, Accuracy: 0.6180\n","Epoch 18, Train Loss: 0.6369, Val Loss: 0.6398, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6376, Val Loss: 0.6506, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 20, Train Loss: 0.6365, Val Loss: 0.6609, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 21, Train Loss: 0.6325, Val Loss: 0.6394, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.6418, Val Loss: 0.6467, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.6267, Val Loss: 0.6492, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 24, Train Loss: 0.6226, Val Loss: 0.6373, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6312, Val Loss: 0.6416, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6267, Val Loss: 0.6670, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6294, Val Loss: 0.6707, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6338, Val Loss: 0.6783, F1 Micro: 0.6573, F1 Macro: 0.6082, Accuracy: 0.6573\n","Epoch 29, Train Loss: 0.6340, Val Loss: 0.6551, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 30, Train Loss: 0.6273, Val Loss: 0.6599, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 31, Train Loss: 0.6286, Val Loss: 0.6489, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 32, Train Loss: 0.6275, Val Loss: 0.6462, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 33, Train Loss: 0.6253, Val Loss: 0.6610, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 34, Train Loss: 0.6364, Val Loss: 0.6449, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.6209, Val Loss: 0.6404, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.6207, Val Loss: 0.6476, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6204, Val Loss: 0.6554, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 38, Train Loss: 0.6191, Val Loss: 0.6460, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6274, Val Loss: 0.6449, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 40, Train Loss: 0.6203, Val Loss: 0.6623, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6773, Val Loss: 0.7066, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 2, Train Loss: 0.6700, Val Loss: 0.6907, F1 Micro: 0.6067, F1 Macro: 0.5836, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6723, Val Loss: 0.7359, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6624, Val Loss: 0.7068, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 5, Train Loss: 0.6661, Val Loss: 0.7450, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6640, Val Loss: 0.7328, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6606, Val Loss: 0.7223, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6654, Val Loss: 0.7435, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6620, Val Loss: 0.7134, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6606, Val Loss: 0.7070, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6686, Val Loss: 0.7105, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6570, Val Loss: 0.7270, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6869, Val Loss: 0.6697, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6906, Val Loss: 0.7281, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6772, Val Loss: 0.6711, F1 Micro: 0.6180, F1 Macro: 0.5272, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.6746, Val Loss: 0.7041, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6705, Val Loss: 0.6794, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6722, Val Loss: 0.6763, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6667, Val Loss: 0.6962, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6702, Val Loss: 0.6905, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6705, Val Loss: 0.6742, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6721, Val Loss: 0.6865, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6643, Val Loss: 0.6636, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.6643964597325969\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6887, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6815, Val Loss: 0.6724, F1 Micro: 0.6536, F1 Macro: 0.4611, Accuracy: 0.6536\n","Epoch 3, Train Loss: 0.6770, Val Loss: 0.6807, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6738, Val Loss: 0.6787, F1 Micro: 0.6536, F1 Macro: 0.5932, Accuracy: 0.6536\n","Epoch 5, Train Loss: 0.6786, Val Loss: 0.6708, F1 Micro: 0.6425, F1 Macro: 0.4317, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6856, Val Loss: 0.6752, F1 Micro: 0.6816, F1 Macro: 0.6115, Accuracy: 0.6816\n","Epoch 7, Train Loss: 0.6798, Val Loss: 0.6704, F1 Micro: 0.6480, F1 Macro: 0.4974, Accuracy: 0.6480\n","Epoch 8, Train Loss: 0.6752, Val Loss: 0.6703, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6761, Val Loss: 0.6708, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6727, Val Loss: 0.6696, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 11, Train Loss: 0.6713, Val Loss: 0.6689, F1 Micro: 0.6536, F1 Macro: 0.4495, Accuracy: 0.6536\n","Epoch 12, Train Loss: 0.6701, Val Loss: 0.6697, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 13, Train Loss: 0.6598, Val Loss: 0.6677, F1 Micro: 0.6592, F1 Macro: 0.4752, Accuracy: 0.6592\n","Epoch 14, Train Loss: 0.6566, Val Loss: 0.6703, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 15, Train Loss: 0.6463, Val Loss: 0.6655, F1 Micro: 0.6536, F1 Macro: 0.4918, Accuracy: 0.6536\n","Epoch 16, Train Loss: 0.6432, Val Loss: 0.6676, F1 Micro: 0.6648, F1 Macro: 0.5730, Accuracy: 0.6648\n","Epoch 17, Train Loss: 0.6413, Val Loss: 0.6802, F1 Micro: 0.7095, F1 Macro: 0.5956, Accuracy: 0.7095\n","Epoch 18, Train Loss: 0.6276, Val Loss: 0.6760, F1 Micro: 0.6872, F1 Macro: 0.6326, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6376, Val Loss: 0.6868, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 20, Train Loss: 0.6215, Val Loss: 0.6838, F1 Micro: 0.6648, F1 Macro: 0.6063, Accuracy: 0.6648\n","Epoch 21, Train Loss: 0.6256, Val Loss: 0.6925, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 22, Train Loss: 0.6331, Val Loss: 0.6807, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 23, Train Loss: 0.6290, Val Loss: 0.6954, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 24, Train Loss: 0.6234, Val Loss: 0.6818, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Epoch 25, Train Loss: 0.6241, Val Loss: 0.6837, F1 Micro: 0.7039, F1 Macro: 0.6151, Accuracy: 0.7039\n","Epoch 26, Train Loss: 0.6350, Val Loss: 0.6885, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 27, Train Loss: 0.6213, Val Loss: 0.6768, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 28, Train Loss: 0.6214, Val Loss: 0.6863, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 29, Train Loss: 0.6235, Val Loss: 0.6725, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 30, Train Loss: 0.6274, Val Loss: 0.6817, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 31, Train Loss: 0.6236, Val Loss: 0.6798, F1 Micro: 0.6927, F1 Macro: 0.6252, Accuracy: 0.6927\n","Epoch 32, Train Loss: 0.6214, Val Loss: 0.6953, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 33, Train Loss: 0.6262, Val Loss: 0.6730, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 34, Train Loss: 0.6203, Val Loss: 0.6739, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 35, Train Loss: 0.6274, Val Loss: 0.6825, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 36, Train Loss: 0.6228, Val Loss: 0.6686, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 37, Train Loss: 0.6169, Val Loss: 0.6737, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 38, Train Loss: 0.6206, Val Loss: 0.6706, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 39, Train Loss: 0.6179, Val Loss: 0.6980, F1 Micro: 0.6927, F1 Macro: 0.5888, Accuracy: 0.6927\n","Epoch 40, Train Loss: 0.6244, Val Loss: 0.6907, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 41, Train Loss: 0.6266, Val Loss: 0.6867, F1 Micro: 0.6536, F1 Macro: 0.6114, Accuracy: 0.6536\n","Epoch 42, Train Loss: 0.6251, Val Loss: 0.6716, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 43, Train Loss: 0.6192, Val Loss: 0.6870, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 44, Train Loss: 0.6304, Val Loss: 0.6959, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 45, Train Loss: 0.6299, Val Loss: 0.6752, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 46, Train Loss: 0.6216, Val Loss: 0.6710, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 47, Train Loss: 0.6192, Val Loss: 0.6693, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 48, Train Loss: 0.6185, Val Loss: 0.6813, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 49, Train Loss: 0.6202, Val Loss: 0.6726, F1 Micro: 0.6872, F1 Macro: 0.6396, Accuracy: 0.6872\n","Epoch 50, Train Loss: 0.6208, Val Loss: 0.6736, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 51, Train Loss: 0.6184, Val Loss: 0.6691, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 52, Train Loss: 0.6252, Val Loss: 0.6714, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 53, Train Loss: 0.6184, Val Loss: 0.6776, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 54, Train Loss: 0.6161, Val Loss: 0.6693, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 55, Train Loss: 0.6194, Val Loss: 0.6749, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 56, Train Loss: 0.6111, Val Loss: 0.6841, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 57, Train Loss: 0.6170, Val Loss: 0.6785, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 58, Train Loss: 0.6199, Val Loss: 0.6756, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 59, Train Loss: 0.6256, Val Loss: 0.6636, F1 Micro: 0.7095, F1 Macro: 0.6622, Accuracy: 0.7095\n","Epoch 60, Train Loss: 0.6242, Val Loss: 0.6747, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 61, Train Loss: 0.6153, Val Loss: 0.6648, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 62, Train Loss: 0.6190, Val Loss: 0.6650, F1 Micro: 0.7095, F1 Macro: 0.6622, Accuracy: 0.7095\n","Epoch 63, Train Loss: 0.6167, Val Loss: 0.6718, F1 Micro: 0.6648, F1 Macro: 0.6299, Accuracy: 0.6648\n","Epoch 64, Train Loss: 0.6227, Val Loss: 0.6687, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 65, Train Loss: 0.6236, Val Loss: 0.6648, F1 Micro: 0.7207, F1 Macro: 0.6612, Accuracy: 0.7207\n","Epoch 66, Train Loss: 0.6185, Val Loss: 0.6719, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 67, Train Loss: 0.6176, Val Loss: 0.6863, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 68, Train Loss: 0.6235, Val Loss: 0.6683, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 69, Train Loss: 0.6191, Val Loss: 0.6650, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 70, Train Loss: 0.6166, Val Loss: 0.6684, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 71, Train Loss: 0.6243, Val Loss: 0.6715, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 72, Train Loss: 0.6256, Val Loss: 0.6775, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 73, Train Loss: 0.6136, Val Loss: 0.6684, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 74, Train Loss: 0.6281, Val Loss: 0.6761, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 75, Train Loss: 0.6261, Val Loss: 0.6695, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 76, Train Loss: 0.6120, Val Loss: 0.6703, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 77, Train Loss: 0.6200, Val Loss: 0.6674, F1 Micro: 0.7039, F1 Macro: 0.6429, Accuracy: 0.7039\n","Epoch 78, Train Loss: 0.6190, Val Loss: 0.6658, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 79, Train Loss: 0.6178, Val Loss: 0.6648, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 80, Train Loss: 0.6189, Val Loss: 0.6671, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 81, Train Loss: 0.6160, Val Loss: 0.6765, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 82, Train Loss: 0.6051, Val Loss: 0.6627, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 83, Train Loss: 0.6214, Val Loss: 0.6696, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 84, Train Loss: 0.6146, Val Loss: 0.6707, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 85, Train Loss: 0.6178, Val Loss: 0.6621, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 86, Train Loss: 0.6187, Val Loss: 0.6695, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 87, Train Loss: 0.6162, Val Loss: 0.6691, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 88, Train Loss: 0.6160, Val Loss: 0.6720, F1 Micro: 0.7207, F1 Macro: 0.6393, Accuracy: 0.7207\n","Epoch 89, Train Loss: 0.6203, Val Loss: 0.6628, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 90, Train Loss: 0.6187, Val Loss: 0.6641, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 91, Train Loss: 0.6139, Val Loss: 0.6620, F1 Micro: 0.7318, F1 Macro: 0.6710, Accuracy: 0.7318\n","Epoch 92, Train Loss: 0.6281, Val Loss: 0.6606, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 93, Train Loss: 0.6209, Val Loss: 0.6595, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 94, Train Loss: 0.6123, Val Loss: 0.6639, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 95, Train Loss: 0.6130, Val Loss: 0.6599, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 96, Train Loss: 0.6109, Val Loss: 0.6621, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 97, Train Loss: 0.6140, Val Loss: 0.6605, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 98, Train Loss: 0.6126, Val Loss: 0.6650, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 99, Train Loss: 0.6131, Val Loss: 0.6647, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 100, Train Loss: 0.6171, Val Loss: 0.6593, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 101, Train Loss: 0.6205, Val Loss: 0.6604, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 102, Train Loss: 0.6172, Val Loss: 0.6606, F1 Micro: 0.7318, F1 Macro: 0.6670, Accuracy: 0.7318\n","Epoch 103, Train Loss: 0.6130, Val Loss: 0.6582, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 104, Train Loss: 0.6055, Val Loss: 0.6753, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 105, Train Loss: 0.6181, Val Loss: 0.6571, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 106, Train Loss: 0.6101, Val Loss: 0.6643, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 107, Train Loss: 0.6158, Val Loss: 0.6704, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 108, Train Loss: 0.6122, Val Loss: 0.6577, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 109, Train Loss: 0.6136, Val Loss: 0.6642, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 110, Train Loss: 0.6093, Val Loss: 0.6697, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 111, Train Loss: 0.6171, Val Loss: 0.6562, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Epoch 112, Train Loss: 0.6163, Val Loss: 0.6589, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 113, Train Loss: 0.6144, Val Loss: 0.6554, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 114, Train Loss: 0.6133, Val Loss: 0.6552, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 115, Train Loss: 0.6172, Val Loss: 0.6563, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 116, Train Loss: 0.6144, Val Loss: 0.6551, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 117, Train Loss: 0.6149, Val Loss: 0.6549, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 118, Train Loss: 0.6137, Val Loss: 0.6649, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 119, Train Loss: 0.6174, Val Loss: 0.6546, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 120, Train Loss: 0.6101, Val Loss: 0.6707, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 121, Train Loss: 0.6064, Val Loss: 0.6595, F1 Micro: 0.7263, F1 Macro: 0.6621, Accuracy: 0.7263\n","Epoch 122, Train Loss: 0.6170, Val Loss: 0.6603, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 123, Train Loss: 0.6154, Val Loss: 0.6548, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 124, Train Loss: 0.6133, Val Loss: 0.6538, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 125, Train Loss: 0.6110, Val Loss: 0.6525, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 126, Train Loss: 0.6246, Val Loss: 0.6546, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 127, Train Loss: 0.6188, Val Loss: 0.6552, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 128, Train Loss: 0.6184, Val Loss: 0.6552, F1 Micro: 0.6704, F1 Macro: 0.6346, Accuracy: 0.6704\n","Epoch 129, Train Loss: 0.6176, Val Loss: 0.6562, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 130, Train Loss: 0.6104, Val Loss: 0.6536, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Epoch 131, Train Loss: 0.6138, Val Loss: 0.6606, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 132, Train Loss: 0.6138, Val Loss: 0.6597, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 133, Train Loss: 0.6117, Val Loss: 0.6668, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 134, Train Loss: 0.6109, Val Loss: 0.6571, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 135, Train Loss: 0.6028, Val Loss: 0.6598, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 136, Train Loss: 0.6152, Val Loss: 0.6554, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 137, Train Loss: 0.6191, Val Loss: 0.6571, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 138, Train Loss: 0.6174, Val Loss: 0.6545, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 139, Train Loss: 0.6105, Val Loss: 0.6563, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 140, Train Loss: 0.6099, Val Loss: 0.6522, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 141, Train Loss: 0.6171, Val Loss: 0.6535, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6964, Val Loss: 0.6757, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6734, Val Loss: 0.6844, F1 Micro: 0.6685, F1 Macro: 0.5111, Accuracy: 0.6685\n","Epoch 3, Train Loss: 0.6832, Val Loss: 0.6728, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6775, Val Loss: 0.6762, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6719, Val Loss: 0.6734, F1 Micro: 0.6910, F1 Macro: 0.5817, Accuracy: 0.6910\n","Epoch 6, Train Loss: 0.6705, Val Loss: 0.6743, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6735, Val Loss: 0.6711, F1 Micro: 0.6854, F1 Macro: 0.5637, Accuracy: 0.6854\n","Epoch 8, Train Loss: 0.6720, Val Loss: 0.6688, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6689, Val Loss: 0.6688, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6730, Val Loss: 0.6666, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.6715, Val Loss: 0.6637, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.6687, Val Loss: 0.6617, F1 Micro: 0.6573, F1 Macro: 0.4848, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6666, Val Loss: 0.6584, F1 Micro: 0.6517, F1 Macro: 0.4365, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6636, Val Loss: 0.6530, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6633, Val Loss: 0.6479, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6581, Val Loss: 0.6340, F1 Micro: 0.6742, F1 Macro: 0.5239, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6613, Val Loss: 0.6422, F1 Micro: 0.7079, F1 Macro: 0.6075, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6562, Val Loss: 0.6180, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 19, Train Loss: 0.6429, Val Loss: 0.6129, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 20, Train Loss: 0.6482, Val Loss: 0.6109, F1 Micro: 0.7303, F1 Macro: 0.6531, Accuracy: 0.7303\n","Epoch 21, Train Loss: 0.6436, Val Loss: 0.6111, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 22, Train Loss: 0.6450, Val Loss: 0.5940, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 23, Train Loss: 0.6369, Val Loss: 0.5943, F1 Micro: 0.7416, F1 Macro: 0.6762, Accuracy: 0.7416\n","Epoch 24, Train Loss: 0.6432, Val Loss: 0.5866, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 25, Train Loss: 0.6463, Val Loss: 0.5900, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 26, Train Loss: 0.6487, Val Loss: 0.5876, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 27, Train Loss: 0.6458, Val Loss: 0.5907, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.6306, Val Loss: 0.5898, F1 Micro: 0.7528, F1 Macro: 0.6862, Accuracy: 0.7528\n","Epoch 29, Train Loss: 0.6452, Val Loss: 0.5855, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 30, Train Loss: 0.6348, Val Loss: 0.5848, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 31, Train Loss: 0.6391, Val Loss: 0.5848, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 32, Train Loss: 0.6373, Val Loss: 0.5866, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 33, Train Loss: 0.6388, Val Loss: 0.5958, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 34, Train Loss: 0.6329, Val Loss: 0.5849, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 35, Train Loss: 0.6324, Val Loss: 0.5832, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 36, Train Loss: 0.6332, Val Loss: 0.5815, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 37, Train Loss: 0.6460, Val Loss: 0.5847, F1 Micro: 0.7528, F1 Macro: 0.6902, Accuracy: 0.7528\n","Epoch 38, Train Loss: 0.6453, Val Loss: 0.5823, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 39, Train Loss: 0.6383, Val Loss: 0.5843, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 40, Train Loss: 0.6315, Val Loss: 0.5833, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 41, Train Loss: 0.6305, Val Loss: 0.5826, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 42, Train Loss: 0.6360, Val Loss: 0.5895, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 43, Train Loss: 0.6322, Val Loss: 0.6047, F1 Micro: 0.6404, F1 Macro: 0.5747, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6383, Val Loss: 0.5778, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6359, Val Loss: 0.5894, F1 Micro: 0.7360, F1 Macro: 0.6580, Accuracy: 0.7360\n","Epoch 46, Train Loss: 0.6276, Val Loss: 0.5793, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 47, Train Loss: 0.6369, Val Loss: 0.5786, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 48, Train Loss: 0.6295, Val Loss: 0.5857, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 49, Train Loss: 0.6353, Val Loss: 0.5766, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 50, Train Loss: 0.6331, Val Loss: 0.5773, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 51, Train Loss: 0.6332, Val Loss: 0.5900, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 52, Train Loss: 0.6375, Val Loss: 0.5816, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 53, Train Loss: 0.6315, Val Loss: 0.5803, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 54, Train Loss: 0.6385, Val Loss: 0.5774, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 55, Train Loss: 0.6316, Val Loss: 0.5831, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 56, Train Loss: 0.6319, Val Loss: 0.5913, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 57, Train Loss: 0.6363, Val Loss: 0.5823, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 58, Train Loss: 0.6275, Val Loss: 0.5830, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 59, Train Loss: 0.6344, Val Loss: 0.5823, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 60, Train Loss: 0.6390, Val Loss: 0.5802, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 61, Train Loss: 0.6280, Val Loss: 0.5760, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 62, Train Loss: 0.6413, Val Loss: 0.5767, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 63, Train Loss: 0.6328, Val Loss: 0.5809, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 64, Train Loss: 0.6248, Val Loss: 0.5745, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 65, Train Loss: 0.6317, Val Loss: 0.5761, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 66, Train Loss: 0.6238, Val Loss: 0.5817, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 67, Train Loss: 0.6268, Val Loss: 0.6066, F1 Micro: 0.7360, F1 Macro: 0.6425, Accuracy: 0.7360\n","Epoch 68, Train Loss: 0.6339, Val Loss: 0.5772, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 69, Train Loss: 0.6326, Val Loss: 0.5729, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 70, Train Loss: 0.6274, Val Loss: 0.5724, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 71, Train Loss: 0.6373, Val Loss: 0.5752, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 72, Train Loss: 0.6369, Val Loss: 0.5770, F1 Micro: 0.7528, F1 Macro: 0.7106, Accuracy: 0.7528\n","Epoch 73, Train Loss: 0.6309, Val Loss: 0.5726, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 74, Train Loss: 0.6308, Val Loss: 0.5742, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 75, Train Loss: 0.6320, Val Loss: 0.5758, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 76, Train Loss: 0.6277, Val Loss: 0.5770, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 77, Train Loss: 0.6319, Val Loss: 0.5758, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 78, Train Loss: 0.6343, Val Loss: 0.5894, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 79, Train Loss: 0.6299, Val Loss: 0.5758, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 80, Train Loss: 0.6330, Val Loss: 0.5765, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6937, Val Loss: 0.6868, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.6758, Val Loss: 0.6799, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6743, Val Loss: 0.6979, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6780, Val Loss: 0.6876, F1 Micro: 0.6292, F1 Macro: 0.4771, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6759, Val Loss: 0.6779, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6726, Val Loss: 0.6814, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 7, Train Loss: 0.6696, Val Loss: 0.6788, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6737, Val Loss: 0.6764, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6708, Val Loss: 0.6781, F1 Micro: 0.6292, F1 Macro: 0.4370, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6719, Val Loss: 0.6830, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.6689, Val Loss: 0.6776, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 12, Train Loss: 0.6691, Val Loss: 0.6741, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 13, Train Loss: 0.6690, Val Loss: 0.6771, F1 Micro: 0.6292, F1 Macro: 0.5163, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6610, Val Loss: 0.6659, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6617, Val Loss: 0.6624, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 16, Train Loss: 0.6462, Val Loss: 0.6577, F1 Micro: 0.6180, F1 Macro: 0.4944, Accuracy: 0.6180\n","Epoch 17, Train Loss: 0.6448, Val Loss: 0.6503, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 18, Train Loss: 0.6373, Val Loss: 0.6550, F1 Micro: 0.6124, F1 Macro: 0.4668, Accuracy: 0.6124\n","Epoch 19, Train Loss: 0.6329, Val Loss: 0.6412, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6433, Val Loss: 0.6484, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.6365, Val Loss: 0.6468, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 22, Train Loss: 0.6352, Val Loss: 0.6557, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6275, Val Loss: 0.6459, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n"]}]},{"cell_type":"code","source":["# Initialize a dictionary to store metrics for different models\n","models_evaluation_metrics_pr = {}\n","\n","# Example model identifiers\n","model_names = ['BasicGraphModel', 'GraphSAGEModel', 'GINModel']\n","\n","# Initialize metric dictionaries for each model\n","for model_name in model_names:\n","    models_evaluation_metrics_pr[model_name] = {'f1_micro': [], 'f1_macro': [], 'accuracy': []}\n","\n","def update_model_metrics_pr(model_name, f1_micro, f1_macro, accuracy):\n","    models_evaluation_metrics_pr[model_name]['f1_micro'].append(f1_micro)\n","    models_evaluation_metrics_pr[model_name]['f1_macro'].append(f1_macro)\n","    models_evaluation_metrics_pr[model_name]['accuracy'].append(accuracy)\n","\n","update_model_metrics_pr('BasicGraphModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics_pr)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cl8TlshsKHh","executionInfo":{"status":"ok","timestamp":1711378126262,"user_tz":-60,"elapsed":437,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"c83fe1b4-f2e6-4e08-fca8-d16c3c350ef4"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]], 'f1_macro': [[0.6368645296571416, 0.7291175419792784, 0.5760113268608413, 0.586319141408185, 0.6266265380189431]], 'accuracy': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]]}, 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"markdown","source":["GraphSAGE model for protein"],"metadata":{"id":"DEBtx6VRFge6"}},{"cell_type":"code","source":["\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_pr)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_pr[train_val_idx]\n","    test_dataset = dataset_pr[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = GraphSAGEModel(\n","                input_dim=dataset_pr.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_pr.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = GraphSAGEModel(\n","        input_dim=dataset_pr.num_node_features,\n","        hidden_dim=256,\n","        output_dim=dataset_pr.num_classes,\n","        dropout_rate=0.5  # You could also tune the dropout rate if you wanted\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'Basic_model_fold_{fold}.pth')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5SDCp7Ohn2S","executionInfo":{"status":"ok","timestamp":1711382967098,"user_tz":-60,"elapsed":2606863,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"0533ed68-0465-43f9-ba77-0f73d3c13b3f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 21, Train Loss: 0.6243, Val Loss: 0.6680, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 22, Train Loss: 0.6374, Val Loss: 0.7012, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6557, Val Loss: 0.6565, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 24, Train Loss: 0.6335, Val Loss: 0.6724, F1 Micro: 0.6180, F1 Macro: 0.6131, Accuracy: 0.6180\n","Epoch 25, Train Loss: 0.6190, Val Loss: 0.6737, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6250, Val Loss: 0.7082, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6323, Val Loss: 0.6705, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.6234, Val Loss: 0.6620, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.6289, Val Loss: 0.6616, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6472, Val Loss: 0.6801, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 31, Train Loss: 0.6274, Val Loss: 0.6625, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.6169, Val Loss: 0.6655, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 33, Train Loss: 0.6418, Val Loss: 0.7066, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 34, Train Loss: 0.6343, Val Loss: 0.6727, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 35, Train Loss: 0.6189, Val Loss: 0.6583, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.6293, Val Loss: 0.6740, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 37, Train Loss: 0.6278, Val Loss: 0.6642, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 38, Train Loss: 0.6285, Val Loss: 0.6626, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 39, Train Loss: 0.6281, Val Loss: 0.6653, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 40, Train Loss: 0.6217, Val Loss: 0.6928, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6390, Val Loss: 0.6741, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 42, Train Loss: 0.6335, Val Loss: 0.6617, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 43, Train Loss: 0.6228, Val Loss: 0.6495, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6279, Val Loss: 0.6489, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 45, Train Loss: 0.6379, Val Loss: 0.6855, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.6296, Val Loss: 0.6759, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 47, Train Loss: 0.6253, Val Loss: 0.6799, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 48, Train Loss: 0.6295, Val Loss: 0.6839, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 49, Train Loss: 0.6355, Val Loss: 0.6715, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 50, Train Loss: 0.6225, Val Loss: 0.6843, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 51, Train Loss: 0.6213, Val Loss: 0.6583, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 52, Train Loss: 0.6342, Val Loss: 0.6549, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 53, Train Loss: 0.6199, Val Loss: 0.6740, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 54, Train Loss: 0.6247, Val Loss: 0.7100, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.6481, Val Loss: 0.6903, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7224719101123596\n","Best hyperparameters for Outer FOLD 2: (0.01, 8, 50) with score 0.7258426966292135\n","Epoch 1, Train Loss: 0.8394, Val Loss: 0.7608, F1 Micro: 0.5336, F1 Macro: 0.5286, Accuracy: 0.5336\n","Epoch 2, Train Loss: 0.7049, Val Loss: 0.6796, F1 Micro: 0.6143, F1 Macro: 0.5894, Accuracy: 0.6143\n","Epoch 3, Train Loss: 0.6711, Val Loss: 0.8404, F1 Micro: 0.6099, F1 Macro: 0.5489, Accuracy: 0.6099\n","Epoch 4, Train Loss: 0.7150, Val Loss: 0.6424, F1 Micro: 0.6502, F1 Macro: 0.6029, Accuracy: 0.6502\n","Epoch 5, Train Loss: 0.6503, Val Loss: 0.6468, F1 Micro: 0.6682, F1 Macro: 0.6483, Accuracy: 0.6682\n","Epoch 6, Train Loss: 0.6552, Val Loss: 0.6527, F1 Micro: 0.6143, F1 Macro: 0.5590, Accuracy: 0.6143\n","Epoch 7, Train Loss: 0.6337, Val Loss: 0.6442, F1 Micro: 0.6592, F1 Macro: 0.6074, Accuracy: 0.6592\n","Epoch 8, Train Loss: 0.6330, Val Loss: 0.6446, F1 Micro: 0.6592, F1 Macro: 0.6447, Accuracy: 0.6592\n","Epoch 9, Train Loss: 0.6500, Val Loss: 0.6521, F1 Micro: 0.6547, F1 Macro: 0.6492, Accuracy: 0.6547\n","Epoch 10, Train Loss: 0.6329, Val Loss: 0.6424, F1 Micro: 0.6413, F1 Macro: 0.5867, Accuracy: 0.6413\n","Epoch 11, Train Loss: 0.6365, Val Loss: 0.6725, F1 Micro: 0.6637, F1 Macro: 0.6410, Accuracy: 0.6637\n","Epoch 12, Train Loss: 0.6304, Val Loss: 0.6952, F1 Micro: 0.6054, F1 Macro: 0.6050, Accuracy: 0.6054\n","Epoch 13, Train Loss: 0.6285, Val Loss: 0.6731, F1 Micro: 0.6816, F1 Macro: 0.6721, Accuracy: 0.6816\n","Epoch 14, Train Loss: 0.6312, Val Loss: 0.6380, F1 Micro: 0.6682, F1 Macro: 0.6374, Accuracy: 0.6682\n","Epoch 15, Train Loss: 0.6341, Val Loss: 0.6466, F1 Micro: 0.6547, F1 Macro: 0.6237, Accuracy: 0.6547\n","Epoch 16, Train Loss: 0.6356, Val Loss: 0.6489, F1 Micro: 0.6726, F1 Macro: 0.6538, Accuracy: 0.6726\n","Epoch 17, Train Loss: 0.6369, Val Loss: 0.6537, F1 Micro: 0.6143, F1 Macro: 0.5451, Accuracy: 0.6143\n","Epoch 18, Train Loss: 0.6196, Val Loss: 0.6563, F1 Micro: 0.6188, F1 Macro: 0.6098, Accuracy: 0.6188\n","Epoch 19, Train Loss: 0.6499, Val Loss: 0.6412, F1 Micro: 0.6547, F1 Macro: 0.6120, Accuracy: 0.6547\n","Epoch 20, Train Loss: 0.6451, Val Loss: 0.6424, F1 Micro: 0.6592, F1 Macro: 0.6404, Accuracy: 0.6592\n","Epoch 21, Train Loss: 0.6270, Val Loss: 0.6413, F1 Micro: 0.6547, F1 Macro: 0.6216, Accuracy: 0.6547\n","Epoch 22, Train Loss: 0.6307, Val Loss: 0.6757, F1 Micro: 0.5919, F1 Macro: 0.5914, Accuracy: 0.5919\n","Epoch 23, Train Loss: 0.6431, Val Loss: 0.6435, F1 Micro: 0.6547, F1 Macro: 0.6315, Accuracy: 0.6547\n","Epoch 24, Train Loss: 0.6314, Val Loss: 0.6476, F1 Micro: 0.6547, F1 Macro: 0.5762, Accuracy: 0.6547\n","Epoch 25, Train Loss: 0.6319, Val Loss: 0.6420, F1 Micro: 0.6726, F1 Macro: 0.6489, Accuracy: 0.6726\n","Epoch 26, Train Loss: 0.6339, Val Loss: 0.6424, F1 Micro: 0.6592, F1 Macro: 0.6335, Accuracy: 0.6592\n","Epoch 27, Train Loss: 0.6266, Val Loss: 0.6567, F1 Micro: 0.6637, F1 Macro: 0.6525, Accuracy: 0.6637\n","Epoch 28, Train Loss: 0.6325, Val Loss: 0.6477, F1 Micro: 0.6457, F1 Macro: 0.5964, Accuracy: 0.6457\n","Epoch 29, Train Loss: 0.6273, Val Loss: 0.6429, F1 Micro: 0.6592, F1 Macro: 0.6335, Accuracy: 0.6592\n","Epoch 30, Train Loss: 0.6314, Val Loss: 0.6421, F1 Micro: 0.6682, F1 Macro: 0.6232, Accuracy: 0.6682\n","Epoch 31, Train Loss: 0.6275, Val Loss: 0.6537, F1 Micro: 0.6457, F1 Macro: 0.5964, Accuracy: 0.6457\n","Epoch 32, Train Loss: 0.6410, Val Loss: 0.6635, F1 Micro: 0.6547, F1 Macro: 0.6483, Accuracy: 0.6547\n","Epoch 33, Train Loss: 0.6240, Val Loss: 0.6428, F1 Micro: 0.6547, F1 Macro: 0.6278, Accuracy: 0.6547\n","Epoch 34, Train Loss: 0.6357, Val Loss: 0.6841, F1 Micro: 0.6413, F1 Macro: 0.6392, Accuracy: 0.6413\n","Epoch 35, Train Loss: 0.6230, Val Loss: 0.6469, F1 Micro: 0.6637, F1 Macro: 0.6374, Accuracy: 0.6637\n","Epoch 36, Train Loss: 0.6316, Val Loss: 0.6493, F1 Micro: 0.6457, F1 Macro: 0.5768, Accuracy: 0.6457\n","Epoch 37, Train Loss: 0.6277, Val Loss: 0.6569, F1 Micro: 0.6099, F1 Macro: 0.5454, Accuracy: 0.6099\n","Epoch 38, Train Loss: 0.6372, Val Loss: 0.6457, F1 Micro: 0.6502, F1 Macro: 0.6108, Accuracy: 0.6502\n","Epoch 39, Train Loss: 0.6320, Val Loss: 0.6533, F1 Micro: 0.6592, F1 Macro: 0.6013, Accuracy: 0.6592\n","Epoch 40, Train Loss: 0.6228, Val Loss: 0.6597, F1 Micro: 0.6143, F1 Macro: 0.5523, Accuracy: 0.6143\n","Epoch 41, Train Loss: 0.6442, Val Loss: 0.6615, F1 Micro: 0.6637, F1 Macro: 0.6335, Accuracy: 0.6637\n","Epoch 42, Train Loss: 0.6337, Val Loss: 0.6476, F1 Micro: 0.6771, F1 Macro: 0.6608, Accuracy: 0.6771\n","Epoch 43, Train Loss: 0.6281, Val Loss: 0.6548, F1 Micro: 0.5964, F1 Macro: 0.5114, Accuracy: 0.5964\n","Epoch 44, Train Loss: 0.6357, Val Loss: 0.6478, F1 Micro: 0.6502, F1 Macro: 0.6276, Accuracy: 0.6502\n","Epoch 45, Train Loss: 0.6401, Val Loss: 0.6498, F1 Micro: 0.6502, F1 Macro: 0.6293, Accuracy: 0.6502\n","Epoch 46, Train Loss: 0.6279, Val Loss: 0.6591, F1 Micro: 0.6054, F1 Macro: 0.5265, Accuracy: 0.6054\n","Epoch 47, Train Loss: 0.6286, Val Loss: 0.6495, F1 Micro: 0.6592, F1 Macro: 0.6419, Accuracy: 0.6592\n","Epoch 48, Train Loss: 0.6282, Val Loss: 0.6951, F1 Micro: 0.6009, F1 Macro: 0.5626, Accuracy: 0.6009\n","Epoch 49, Train Loss: 0.6360, Val Loss: 0.6578, F1 Micro: 0.6323, F1 Macro: 0.6120, Accuracy: 0.6323\n","Epoch 50, Train Loss: 0.6334, Val Loss: 0.6506, F1 Micro: 0.5964, F1 Macro: 0.5022, Accuracy: 0.5964\n","Epoch 51, Train Loss: 0.6369, Val Loss: 0.6543, F1 Micro: 0.6502, F1 Macro: 0.5840, Accuracy: 0.6502\n","Epoch 52, Train Loss: 0.6328, Val Loss: 0.6561, F1 Micro: 0.6054, F1 Macro: 0.5901, Accuracy: 0.6054\n","Epoch 53, Train Loss: 0.6412, Val Loss: 0.6436, F1 Micro: 0.6682, F1 Macro: 0.6330, Accuracy: 0.6682\n","Epoch 54, Train Loss: 0.6385, Val Loss: 0.6523, F1 Micro: 0.6368, F1 Macro: 0.6123, Accuracy: 0.6368\n","Epoch 55, Train Loss: 0.6431, Val Loss: 0.6489, F1 Micro: 0.6682, F1 Macro: 0.5946, Accuracy: 0.6682\n","Epoch 56, Train Loss: 0.6345, Val Loss: 0.6654, F1 Micro: 0.6054, F1 Macro: 0.5085, Accuracy: 0.6054\n","Epoch 57, Train Loss: 0.6357, Val Loss: 0.6726, F1 Micro: 0.6547, F1 Macro: 0.6500, Accuracy: 0.6547\n","Epoch 58, Train Loss: 0.6230, Val Loss: 0.6634, F1 Micro: 0.6502, F1 Macro: 0.6293, Accuracy: 0.6502\n","Epoch 59, Train Loss: 0.6399, Val Loss: 0.6695, F1 Micro: 0.6054, F1 Macro: 0.5419, Accuracy: 0.6054\n","Epoch 60, Train Loss: 0.6400, Val Loss: 0.6612, F1 Micro: 0.6502, F1 Macro: 0.6309, Accuracy: 0.6502\n","Epoch 61, Train Loss: 0.6423, Val Loss: 0.6455, F1 Micro: 0.6592, F1 Macro: 0.6316, Accuracy: 0.6592\n","Epoch 62, Train Loss: 0.6318, Val Loss: 0.6687, F1 Micro: 0.6547, F1 Macro: 0.6379, Accuracy: 0.6547\n","Epoch 63, Train Loss: 0.6445, Val Loss: 0.7012, F1 Micro: 0.6682, F1 Macro: 0.6639, Accuracy: 0.6682\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6682, F1 Macro: 0.6639, Accuracy: 0.6682\n","Outer FOLD 3\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.9255, Val Loss: 0.6237, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 2, Train Loss: 0.6888, Val Loss: 0.6480, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6848, Val Loss: 0.6605, F1 Micro: 0.6480, F1 Macro: 0.5290, Accuracy: 0.6480\n","Epoch 4, Train Loss: 0.6996, Val Loss: 0.6290, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 5, Train Loss: 0.6549, Val Loss: 0.6258, F1 Micro: 0.6536, F1 Macro: 0.5845, Accuracy: 0.6536\n","Epoch 6, Train Loss: 0.6616, Val Loss: 0.6163, F1 Micro: 0.7039, F1 Macro: 0.6718, Accuracy: 0.7039\n","Epoch 7, Train Loss: 0.6573, Val Loss: 0.6401, F1 Micro: 0.6592, F1 Macro: 0.6351, Accuracy: 0.6592\n","Epoch 8, Train Loss: 0.6496, Val Loss: 0.6264, F1 Micro: 0.6648, F1 Macro: 0.5887, Accuracy: 0.6648\n","Epoch 9, Train Loss: 0.6548, Val Loss: 0.6196, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 10, Train Loss: 0.6438, Val Loss: 0.6088, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 11, Train Loss: 0.6544, Val Loss: 0.6267, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 12, Train Loss: 0.6479, Val Loss: 0.6134, F1 Micro: 0.6983, F1 Macro: 0.6717, Accuracy: 0.6983\n","Epoch 13, Train Loss: 0.6484, Val Loss: 0.6177, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 14, Train Loss: 0.6322, Val Loss: 0.6164, F1 Micro: 0.6536, F1 Macro: 0.6081, Accuracy: 0.6536\n","Epoch 15, Train Loss: 0.6432, Val Loss: 0.6207, F1 Micro: 0.6816, F1 Macro: 0.6349, Accuracy: 0.6816\n","Epoch 16, Train Loss: 0.6354, Val Loss: 0.6186, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.8308, Val Loss: 0.6563, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.7469, Val Loss: 0.6429, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6955, Val Loss: 0.6637, F1 Micro: 0.6236, F1 Macro: 0.4550, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6852, Val Loss: 0.6273, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6815, Val Loss: 0.6780, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6491, Val Loss: 0.6861, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6650, Val Loss: 0.6383, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6685, Val Loss: 0.6496, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6409, Val Loss: 0.6090, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6338, Val Loss: 0.6124, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6376, Val Loss: 0.6641, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6503, Val Loss: 0.6662, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6385, Val Loss: 0.7287, F1 Micro: 0.6404, F1 Macro: 0.6367, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6451, Val Loss: 0.5860, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 15, Train Loss: 0.6453, Val Loss: 0.5917, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.6440, Val Loss: 0.6644, F1 Micro: 0.6067, F1 Macro: 0.5246, Accuracy: 0.6067\n","Epoch 17, Train Loss: 0.6582, Val Loss: 0.6366, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 18, Train Loss: 0.6376, Val Loss: 0.6370, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 19, Train Loss: 0.6438, Val Loss: 0.5993, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 20, Train Loss: 0.6399, Val Loss: 0.6441, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 21, Train Loss: 0.6431, Val Loss: 0.7101, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 22, Train Loss: 0.6318, Val Loss: 0.6656, F1 Micro: 0.6461, F1 Macro: 0.5916, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6516, Val Loss: 0.6326, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 24, Train Loss: 0.6562, Val Loss: 0.6053, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 25, Train Loss: 0.6361, Val Loss: 0.6499, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6454, Val Loss: 0.6944, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.6507, Val Loss: 0.6121, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 28, Train Loss: 0.6479, Val Loss: 0.6141, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 29, Train Loss: 0.6474, Val Loss: 0.6126, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.9133, Val Loss: 0.7701, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 2, Train Loss: 0.7061, Val Loss: 0.8067, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 3, Train Loss: 0.6879, Val Loss: 0.5980, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 4, Train Loss: 0.7475, Val Loss: 0.6588, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 5, Train Loss: 0.6489, Val Loss: 0.6589, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6546, Val Loss: 0.6105, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 7, Train Loss: 0.6397, Val Loss: 0.6217, F1 Micro: 0.7247, F1 Macro: 0.6273, Accuracy: 0.7247\n","Epoch 8, Train Loss: 0.6782, Val Loss: 0.6099, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6454, Val Loss: 0.6024, F1 Micro: 0.7022, F1 Macro: 0.6888, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.6593, Val Loss: 0.6046, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 11, Train Loss: 0.6462, Val Loss: 0.6214, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6563, Val Loss: 0.5979, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 13, Train Loss: 0.6408, Val Loss: 0.6040, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 14, Train Loss: 0.6485, Val Loss: 0.6135, F1 Micro: 0.7079, F1 Macro: 0.6939, Accuracy: 0.7079\n","Epoch 15, Train Loss: 0.6532, Val Loss: 0.5844, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6318, Val Loss: 0.5843, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 17, Train Loss: 0.6459, Val Loss: 0.5878, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.8993, Val Loss: 0.9414, F1 Micro: 0.5674, F1 Macro: 0.5319, Accuracy: 0.5674\n","Epoch 2, Train Loss: 0.6810, Val Loss: 0.7235, F1 Micro: 0.5337, F1 Macro: 0.5019, Accuracy: 0.5337\n","Epoch 3, Train Loss: 0.6850, Val Loss: 0.9676, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 4, Train Loss: 0.6447, Val Loss: 0.7663, F1 Micro: 0.5562, F1 Macro: 0.5545, Accuracy: 0.5562\n","Epoch 5, Train Loss: 0.6329, Val Loss: 0.7170, F1 Micro: 0.5618, F1 Macro: 0.5598, Accuracy: 0.5618\n","Epoch 6, Train Loss: 0.6224, Val Loss: 0.8607, F1 Micro: 0.5618, F1 Macro: 0.5174, Accuracy: 0.5618\n","Epoch 7, Train Loss: 0.6499, Val Loss: 0.7789, F1 Micro: 0.5337, F1 Macro: 0.4042, Accuracy: 0.5337\n","Epoch 8, Train Loss: 0.6029, Val Loss: 0.7449, F1 Micro: 0.5955, F1 Macro: 0.5762, Accuracy: 0.5955\n","Epoch 9, Train Loss: 0.6221, Val Loss: 0.7568, F1 Micro: 0.5674, F1 Macro: 0.5379, Accuracy: 0.5674\n","Epoch 10, Train Loss: 0.6273, Val Loss: 0.7363, F1 Micro: 0.5843, F1 Macro: 0.5704, Accuracy: 0.5843\n","Epoch 11, Train Loss: 0.6235, Val Loss: 0.7305, F1 Micro: 0.5674, F1 Macro: 0.5287, Accuracy: 0.5674\n","Epoch 12, Train Loss: 0.6360, Val Loss: 0.7447, F1 Micro: 0.5674, F1 Macro: 0.5140, Accuracy: 0.5674\n","Epoch 13, Train Loss: 0.6196, Val Loss: 0.7747, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6092, Val Loss: 0.8125, F1 Micro: 0.5449, F1 Macro: 0.4261, Accuracy: 0.5449\n","Epoch 15, Train Loss: 0.6086, Val Loss: 0.7129, F1 Micro: 0.6124, F1 Macro: 0.6088, Accuracy: 0.6124\n","Epoch 16, Train Loss: 0.5979, Val Loss: 0.7418, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 17, Train Loss: 0.5976, Val Loss: 0.7808, F1 Micro: 0.5787, F1 Macro: 0.5226, Accuracy: 0.5787\n","Epoch 18, Train Loss: 0.6259, Val Loss: 0.7818, F1 Micro: 0.5618, F1 Macro: 0.4967, Accuracy: 0.5618\n","Epoch 19, Train Loss: 0.6255, Val Loss: 0.7458, F1 Micro: 0.5843, F1 Macro: 0.5598, Accuracy: 0.5843\n","Epoch 20, Train Loss: 0.6200, Val Loss: 0.7562, F1 Micro: 0.5843, F1 Macro: 0.5517, Accuracy: 0.5843\n","Epoch 21, Train Loss: 0.6184, Val Loss: 0.7709, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 22, Train Loss: 0.6297, Val Loss: 0.7207, F1 Micro: 0.6292, F1 Macro: 0.6262, Accuracy: 0.6292\n","Epoch 23, Train Loss: 0.6180, Val Loss: 0.6989, F1 Micro: 0.5674, F1 Macro: 0.5613, Accuracy: 0.5674\n","Epoch 24, Train Loss: 0.6107, Val Loss: 0.7148, F1 Micro: 0.5674, F1 Macro: 0.5601, Accuracy: 0.5674\n","Epoch 25, Train Loss: 0.5806, Val Loss: 0.7290, F1 Micro: 0.5787, F1 Macro: 0.5637, Accuracy: 0.5787\n","Epoch 26, Train Loss: 0.6132, Val Loss: 0.7078, F1 Micro: 0.5843, F1 Macro: 0.5752, Accuracy: 0.5843\n","Epoch 27, Train Loss: 0.5978, Val Loss: 0.7386, F1 Micro: 0.6124, F1 Macro: 0.5986, Accuracy: 0.6124\n","Epoch 28, Train Loss: 0.6183, Val Loss: 0.7105, F1 Micro: 0.5787, F1 Macro: 0.5637, Accuracy: 0.5787\n","Epoch 29, Train Loss: 0.6089, Val Loss: 0.7555, F1 Micro: 0.5843, F1 Macro: 0.5269, Accuracy: 0.5843\n","Epoch 30, Train Loss: 0.6189, Val Loss: 0.7582, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 31, Train Loss: 0.6159, Val Loss: 0.7274, F1 Micro: 0.5843, F1 Macro: 0.5685, Accuracy: 0.5843\n","Epoch 32, Train Loss: 0.6052, Val Loss: 0.7442, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.8318, Val Loss: 1.1045, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.7520, Val Loss: 0.8592, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6667, Val Loss: 0.8058, F1 Micro: 0.7191, F1 Macro: 0.6386, Accuracy: 0.7191\n","Epoch 4, Train Loss: 0.6781, Val Loss: 0.6709, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6818, Val Loss: 0.6906, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6521, Val Loss: 0.6824, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 7, Train Loss: 0.6434, Val Loss: 0.6924, F1 Micro: 0.6236, F1 Macro: 0.5190, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6532, Val Loss: 0.7316, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Epoch 9, Train Loss: 0.6230, Val Loss: 0.6707, F1 Micro: 0.6461, F1 Macro: 0.5990, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6363, Val Loss: 0.7429, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6315, Val Loss: 0.7160, F1 Micro: 0.6011, F1 Macro: 0.4759, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6622, Val Loss: 0.6657, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6323, Val Loss: 0.7097, F1 Micro: 0.6011, F1 Macro: 0.4225, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.7048270667252527\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8400, Val Loss: 0.8711, F1 Micro: 0.6872, F1 Macro: 0.5645, Accuracy: 0.6872\n","Epoch 2, Train Loss: 0.7840, Val Loss: 0.6580, F1 Micro: 0.6480, F1 Macro: 0.4466, Accuracy: 0.6480\n","Epoch 3, Train Loss: 0.7236, Val Loss: 1.0055, F1 Micro: 0.3631, F1 Macro: 0.2664, Accuracy: 0.3631\n","Epoch 4, Train Loss: 0.7046, Val Loss: 0.6626, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 5, Train Loss: 0.6519, Val Loss: 0.6238, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 6, Train Loss: 0.6453, Val Loss: 0.6347, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 7, Train Loss: 0.6457, Val Loss: 0.6099, F1 Micro: 0.6704, F1 Macro: 0.6317, Accuracy: 0.6704\n","Epoch 8, Train Loss: 0.6727, Val Loss: 0.6296, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 9, Train Loss: 0.6446, Val Loss: 0.6389, F1 Micro: 0.6816, F1 Macro: 0.6711, Accuracy: 0.6816\n","Epoch 10, Train Loss: 0.6441, Val Loss: 0.7151, F1 Micro: 0.5531, F1 Macro: 0.5514, Accuracy: 0.5531\n","Epoch 11, Train Loss: 0.6614, Val Loss: 0.6403, F1 Micro: 0.6927, F1 Macro: 0.6812, Accuracy: 0.6927\n","Epoch 12, Train Loss: 0.6348, Val Loss: 0.6587, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 13, Train Loss: 0.6535, Val Loss: 0.6392, F1 Micro: 0.6536, F1 Macro: 0.6456, Accuracy: 0.6536\n","Epoch 14, Train Loss: 0.6362, Val Loss: 0.6267, F1 Micro: 0.6760, F1 Macro: 0.6302, Accuracy: 0.6760\n","Epoch 15, Train Loss: 0.6417, Val Loss: 0.6225, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 16, Train Loss: 0.6523, Val Loss: 0.6480, F1 Micro: 0.6592, F1 Macro: 0.6328, Accuracy: 0.6592\n","Epoch 17, Train Loss: 0.6478, Val Loss: 0.6408, F1 Micro: 0.6760, F1 Macro: 0.6520, Accuracy: 0.6760\n","Epoch 18, Train Loss: 0.6342, Val Loss: 0.6333, F1 Micro: 0.6927, F1 Macro: 0.6730, Accuracy: 0.6927\n","Epoch 19, Train Loss: 0.6568, Val Loss: 0.6352, F1 Micro: 0.6592, F1 Macro: 0.5630, Accuracy: 0.6592\n","Epoch 20, Train Loss: 0.6239, Val Loss: 0.6267, F1 Micro: 0.6816, F1 Macro: 0.5970, Accuracy: 0.6816\n","Epoch 21, Train Loss: 0.6403, Val Loss: 0.6801, F1 Micro: 0.6425, F1 Macro: 0.6206, Accuracy: 0.6425\n","Epoch 22, Train Loss: 0.6424, Val Loss: 0.6220, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 23, Train Loss: 0.6457, Val Loss: 0.6358, F1 Micro: 0.6536, F1 Macro: 0.5465, Accuracy: 0.6536\n","Epoch 24, Train Loss: 0.6394, Val Loss: 0.6293, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 25, Train Loss: 0.6431, Val Loss: 0.6457, F1 Micro: 0.6536, F1 Macro: 0.6010, Accuracy: 0.6536\n","Epoch 26, Train Loss: 0.6414, Val Loss: 0.6096, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 27, Train Loss: 0.6434, Val Loss: 0.6235, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 28, Train Loss: 0.6385, Val Loss: 0.6351, F1 Micro: 0.6592, F1 Macro: 0.5569, Accuracy: 0.6592\n","Epoch 29, Train Loss: 0.6452, Val Loss: 0.6251, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Epoch 30, Train Loss: 0.6294, Val Loss: 0.6246, F1 Micro: 0.6816, F1 Macro: 0.6315, Accuracy: 0.6816\n","Epoch 31, Train Loss: 0.6376, Val Loss: 0.6295, F1 Micro: 0.6536, F1 Macro: 0.5465, Accuracy: 0.6536\n","Epoch 32, Train Loss: 0.6446, Val Loss: 0.6439, F1 Micro: 0.6648, F1 Macro: 0.6530, Accuracy: 0.6648\n","Epoch 33, Train Loss: 0.6466, Val Loss: 0.6434, F1 Micro: 0.6648, F1 Macro: 0.5979, Accuracy: 0.6648\n","Epoch 34, Train Loss: 0.6345, Val Loss: 0.6348, F1 Micro: 0.6983, F1 Macro: 0.6780, Accuracy: 0.6983\n","Epoch 35, Train Loss: 0.6419, Val Loss: 0.6243, F1 Micro: 0.6480, F1 Macro: 0.5140, Accuracy: 0.6480\n","Epoch 36, Train Loss: 0.6348, Val Loss: 0.6435, F1 Micro: 0.6425, F1 Macro: 0.6375, Accuracy: 0.6425\n","Epoch 37, Train Loss: 0.6635, Val Loss: 0.6357, F1 Micro: 0.6592, F1 Macro: 0.6251, Accuracy: 0.6592\n","Epoch 38, Train Loss: 0.6314, Val Loss: 0.6612, F1 Micro: 0.6704, F1 Macro: 0.6255, Accuracy: 0.6704\n","Epoch 39, Train Loss: 0.6390, Val Loss: 0.6642, F1 Micro: 0.6704, F1 Macro: 0.6548, Accuracy: 0.6704\n","Epoch 40, Train Loss: 0.6396, Val Loss: 0.6551, F1 Micro: 0.6704, F1 Macro: 0.6548, Accuracy: 0.6704\n","Epoch 41, Train Loss: 0.6510, Val Loss: 0.6189, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 42, Train Loss: 0.6444, Val Loss: 0.6162, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 43, Train Loss: 0.6387, Val Loss: 0.6223, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 44, Train Loss: 0.6409, Val Loss: 0.6437, F1 Micro: 0.6480, F1 Macro: 0.5290, Accuracy: 0.6480\n","Epoch 45, Train Loss: 0.6400, Val Loss: 0.6280, F1 Micro: 0.6648, F1 Macro: 0.5837, Accuracy: 0.6648\n","Epoch 46, Train Loss: 0.6501, Val Loss: 0.6263, F1 Micro: 0.6816, F1 Macro: 0.5916, Accuracy: 0.6816\n","Epoch 47, Train Loss: 0.6448, Val Loss: 0.6295, F1 Micro: 0.7151, F1 Macro: 0.6842, Accuracy: 0.7151\n","Epoch 48, Train Loss: 0.6521, Val Loss: 0.6354, F1 Micro: 0.6872, F1 Macro: 0.6660, Accuracy: 0.6872\n","Epoch 49, Train Loss: 0.6390, Val Loss: 0.6147, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 50, Train Loss: 0.6378, Val Loss: 0.6223, F1 Micro: 0.6872, F1 Macro: 0.6618, Accuracy: 0.6872\n","Epoch 51, Train Loss: 0.6418, Val Loss: 0.6350, F1 Micro: 0.6704, F1 Macro: 0.6400, Accuracy: 0.6704\n","Epoch 52, Train Loss: 0.6453, Val Loss: 0.6344, F1 Micro: 0.6816, F1 Macro: 0.6681, Accuracy: 0.6816\n","Epoch 53, Train Loss: 0.6386, Val Loss: 0.6355, F1 Micro: 0.6704, F1 Macro: 0.6449, Accuracy: 0.6704\n","Epoch 54, Train Loss: 0.6375, Val Loss: 0.6569, F1 Micro: 0.6872, F1 Macro: 0.6660, Accuracy: 0.6872\n","Epoch 55, Train Loss: 0.6457, Val Loss: 0.6347, F1 Micro: 0.6760, F1 Macro: 0.6302, Accuracy: 0.6760\n","Epoch 56, Train Loss: 0.6410, Val Loss: 0.6285, F1 Micro: 0.6425, F1 Macro: 0.4755, Accuracy: 0.6425\n","Epoch 57, Train Loss: 0.6465, Val Loss: 0.6191, F1 Micro: 0.6648, F1 Macro: 0.5837, Accuracy: 0.6648\n","Epoch 58, Train Loss: 0.6427, Val Loss: 0.6331, F1 Micro: 0.6760, F1 Macro: 0.5562, Accuracy: 0.6760\n","Epoch 59, Train Loss: 0.6389, Val Loss: 0.6362, F1 Micro: 0.6592, F1 Macro: 0.5977, Accuracy: 0.6592\n","Epoch 60, Train Loss: 0.6350, Val Loss: 0.6427, F1 Micro: 0.7039, F1 Macro: 0.6928, Accuracy: 0.7039\n","Epoch 61, Train Loss: 0.6314, Val Loss: 0.6126, F1 Micro: 0.6760, F1 Macro: 0.5758, Accuracy: 0.6760\n","Epoch 62, Train Loss: 0.6301, Val Loss: 0.6920, F1 Micro: 0.6369, F1 Macro: 0.6346, Accuracy: 0.6369\n","Epoch 63, Train Loss: 0.6520, Val Loss: 0.6317, F1 Micro: 0.6983, F1 Macro: 0.6760, Accuracy: 0.6983\n","Epoch 64, Train Loss: 0.6376, Val Loss: 0.6275, F1 Micro: 0.6480, F1 Macro: 0.4974, Accuracy: 0.6480\n","Epoch 65, Train Loss: 0.6414, Val Loss: 0.6601, F1 Micro: 0.6704, F1 Macro: 0.6581, Accuracy: 0.6704\n","Epoch 66, Train Loss: 0.6337, Val Loss: 0.6259, F1 Micro: 0.6816, F1 Macro: 0.6522, Accuracy: 0.6816\n","Epoch 67, Train Loss: 0.6428, Val Loss: 0.6125, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 68, Train Loss: 0.6345, Val Loss: 0.6114, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 69, Train Loss: 0.6485, Val Loss: 0.6265, F1 Micro: 0.6760, F1 Macro: 0.6497, Accuracy: 0.6760\n","Epoch 70, Train Loss: 0.6568, Val Loss: 0.6339, F1 Micro: 0.6648, F1 Macro: 0.5547, Accuracy: 0.6648\n","Epoch 71, Train Loss: 0.6397, Val Loss: 0.6419, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 72, Train Loss: 0.6429, Val Loss: 0.6260, F1 Micro: 0.6592, F1 Macro: 0.5439, Accuracy: 0.6592\n","Epoch 73, Train Loss: 0.6460, Val Loss: 0.6165, F1 Micro: 0.6983, F1 Macro: 0.6643, Accuracy: 0.6983\n","Epoch 74, Train Loss: 0.6393, Val Loss: 0.6132, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 75, Train Loss: 0.6338, Val Loss: 0.6221, F1 Micro: 0.7207, F1 Macro: 0.6891, Accuracy: 0.7207\n","Epoch 76, Train Loss: 0.6469, Val Loss: 0.6323, F1 Micro: 0.6425, F1 Macro: 0.4755, Accuracy: 0.6425\n","Epoch 77, Train Loss: 0.6423, Val Loss: 0.6239, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 78, Train Loss: 0.6414, Val Loss: 0.6178, F1 Micro: 0.6983, F1 Macro: 0.6669, Accuracy: 0.6983\n","Epoch 79, Train Loss: 0.6397, Val Loss: 0.6246, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 80, Train Loss: 0.6451, Val Loss: 0.6586, F1 Micro: 0.6369, F1 Macro: 0.4408, Accuracy: 0.6369\n","Epoch 81, Train Loss: 0.6552, Val Loss: 0.6319, F1 Micro: 0.6313, F1 Macro: 0.4488, Accuracy: 0.6313\n","Epoch 82, Train Loss: 0.6444, Val Loss: 0.6650, F1 Micro: 0.6648, F1 Macro: 0.6443, Accuracy: 0.6648\n","Epoch 83, Train Loss: 0.6482, Val Loss: 0.6263, F1 Micro: 0.6704, F1 Macro: 0.6255, Accuracy: 0.6704\n","Epoch 84, Train Loss: 0.6482, Val Loss: 0.6243, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 85, Train Loss: 0.6384, Val Loss: 0.6179, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 86, Train Loss: 0.6391, Val Loss: 0.6193, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 87, Train Loss: 0.6261, Val Loss: 0.6252, F1 Micro: 0.6648, F1 Macro: 0.6208, Accuracy: 0.6648\n","Epoch 88, Train Loss: 0.6527, Val Loss: 0.6220, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 89, Train Loss: 0.6366, Val Loss: 0.6153, F1 Micro: 0.6816, F1 Macro: 0.6115, Accuracy: 0.6816\n","Epoch 90, Train Loss: 0.6389, Val Loss: 0.6213, F1 Micro: 0.6648, F1 Macro: 0.5611, Accuracy: 0.6648\n","Epoch 91, Train Loss: 0.6512, Val Loss: 0.6213, F1 Micro: 0.6983, F1 Macro: 0.6693, Accuracy: 0.6983\n","Epoch 92, Train Loss: 0.6370, Val Loss: 0.6485, F1 Micro: 0.6592, F1 Macro: 0.6413, Accuracy: 0.6592\n","Epoch 93, Train Loss: 0.6389, Val Loss: 0.7084, F1 Micro: 0.5978, F1 Macro: 0.5680, Accuracy: 0.5978\n","Epoch 94, Train Loss: 0.6414, Val Loss: 0.6298, F1 Micro: 0.6816, F1 Macro: 0.6590, Accuracy: 0.6816\n","Epoch 95, Train Loss: 0.6284, Val Loss: 0.6495, F1 Micro: 0.6369, F1 Macro: 0.4623, Accuracy: 0.6369\n","Epoch 96, Train Loss: 0.6556, Val Loss: 0.6278, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 97, Train Loss: 0.6415, Val Loss: 0.6514, F1 Micro: 0.6592, F1 Macro: 0.5569, Accuracy: 0.6592\n","Epoch 98, Train Loss: 0.6451, Val Loss: 0.6486, F1 Micro: 0.6704, F1 Macro: 0.6287, Accuracy: 0.6704\n","Epoch 99, Train Loss: 0.6374, Val Loss: 0.6359, F1 Micro: 0.6648, F1 Macro: 0.6139, Accuracy: 0.6648\n","Epoch 100, Train Loss: 0.6302, Val Loss: 0.6543, F1 Micro: 0.6425, F1 Macro: 0.6384, Accuracy: 0.6425\n","Epoch 101, Train Loss: 0.6401, Val Loss: 0.6307, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 102, Train Loss: 0.6372, Val Loss: 0.6280, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 103, Train Loss: 0.6338, Val Loss: 0.6373, F1 Micro: 0.6760, F1 Macro: 0.6615, Accuracy: 0.6760\n","Epoch 104, Train Loss: 0.6459, Val Loss: 0.6346, F1 Micro: 0.6592, F1 Macro: 0.6304, Accuracy: 0.6592\n","Epoch 105, Train Loss: 0.6362, Val Loss: 0.6187, F1 Micro: 0.6927, F1 Macro: 0.6594, Accuracy: 0.6927\n","Epoch 106, Train Loss: 0.6411, Val Loss: 0.6365, F1 Micro: 0.6927, F1 Macro: 0.6826, Accuracy: 0.6927\n","Epoch 107, Train Loss: 0.6358, Val Loss: 0.6431, F1 Micro: 0.6536, F1 Macro: 0.6203, Accuracy: 0.6536\n","Epoch 108, Train Loss: 0.6332, Val Loss: 0.6360, F1 Micro: 0.6592, F1 Macro: 0.5439, Accuracy: 0.6592\n","Epoch 109, Train Loss: 0.6411, Val Loss: 0.6208, F1 Micro: 0.6648, F1 Macro: 0.5785, Accuracy: 0.6648\n","Epoch 110, Train Loss: 0.6337, Val Loss: 0.6249, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 111, Train Loss: 0.6330, Val Loss: 0.6476, F1 Micro: 0.6704, F1 Macro: 0.6185, Accuracy: 0.6704\n","Epoch 112, Train Loss: 0.6361, Val Loss: 0.6638, F1 Micro: 0.6369, F1 Macro: 0.6361, Accuracy: 0.6369\n","Epoch 113, Train Loss: 0.6421, Val Loss: 0.6222, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 114, Train Loss: 0.6420, Val Loss: 0.6158, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 115, Train Loss: 0.6525, Val Loss: 0.6447, F1 Micro: 0.7095, F1 Macro: 0.6880, Accuracy: 0.7095\n","Epoch 116, Train Loss: 0.6220, Val Loss: 0.6301, F1 Micro: 0.6704, F1 Macro: 0.6449, Accuracy: 0.6704\n","Epoch 117, Train Loss: 0.6390, Val Loss: 0.6137, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 118, Train Loss: 0.6250, Val Loss: 0.6284, F1 Micro: 0.6983, F1 Macro: 0.6760, Accuracy: 0.6983\n","Epoch 119, Train Loss: 0.6243, Val Loss: 0.6115, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 120, Train Loss: 0.6388, Val Loss: 0.6182, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 121, Train Loss: 0.6441, Val Loss: 0.6209, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 122, Train Loss: 0.6366, Val Loss: 0.6267, F1 Micro: 0.6927, F1 Macro: 0.6689, Accuracy: 0.6927\n","Epoch 123, Train Loss: 0.6264, Val Loss: 0.6272, F1 Micro: 0.6760, F1 Macro: 0.6268, Accuracy: 0.6760\n","Epoch 124, Train Loss: 0.6411, Val Loss: 0.6252, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 125, Train Loss: 0.6294, Val Loss: 0.6238, F1 Micro: 0.6872, F1 Macro: 0.6595, Accuracy: 0.6872\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7918, Val Loss: 0.8011, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.7604, Val Loss: 0.5951, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 3, Train Loss: 0.6960, Val Loss: 0.6514, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 4, Train Loss: 0.6696, Val Loss: 0.6314, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 5, Train Loss: 0.6821, Val Loss: 0.5871, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.6698, Val Loss: 0.6116, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.6593, Val Loss: 0.6062, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 8, Train Loss: 0.6615, Val Loss: 0.6355, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6417, Val Loss: 0.6304, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6410, Val Loss: 0.6063, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6420, Val Loss: 0.6206, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6564, Val Loss: 0.6292, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6472, Val Loss: 0.6007, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 14, Train Loss: 0.6497, Val Loss: 0.6003, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6494, Val Loss: 0.6359, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6439, Val Loss: 0.6276, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.6416, Val Loss: 0.6187, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 18, Train Loss: 0.6610, Val Loss: 0.6389, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.6436, Val Loss: 0.6048, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.6340, Val Loss: 0.6606, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 21, Train Loss: 0.6379, Val Loss: 0.6048, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6373, Val Loss: 0.6242, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.6545, Val Loss: 0.6471, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.6477, Val Loss: 0.6824, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 25, Train Loss: 0.6607, Val Loss: 0.5922, F1 Micro: 0.7584, F1 Macro: 0.7286, Accuracy: 0.7584\n","Epoch 26, Train Loss: 0.6386, Val Loss: 0.6339, F1 Micro: 0.6798, F1 Macro: 0.6653, Accuracy: 0.6798\n","Epoch 27, Train Loss: 0.6362, Val Loss: 0.5915, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 28, Train Loss: 0.6557, Val Loss: 0.6533, F1 Micro: 0.6629, F1 Macro: 0.6517, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6283, Val Loss: 0.6348, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 30, Train Loss: 0.6435, Val Loss: 0.6233, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6467, Val Loss: 0.6390, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 32, Train Loss: 0.6358, Val Loss: 0.6042, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 33, Train Loss: 0.6437, Val Loss: 0.6304, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 34, Train Loss: 0.6437, Val Loss: 0.6333, F1 Micro: 0.6292, F1 Macro: 0.4582, Accuracy: 0.6292\n","Epoch 35, Train Loss: 0.6396, Val Loss: 0.6344, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.6499, Val Loss: 0.6272, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6425, Val Loss: 0.6229, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 38, Train Loss: 0.6488, Val Loss: 0.5925, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 39, Train Loss: 0.6292, Val Loss: 0.6018, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 40, Train Loss: 0.6310, Val Loss: 0.6264, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 41, Train Loss: 0.6266, Val Loss: 0.6686, F1 Micro: 0.6236, F1 Macro: 0.4106, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6629, Val Loss: 0.6207, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 43, Train Loss: 0.6453, Val Loss: 0.6099, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 44, Train Loss: 0.6427, Val Loss: 0.6085, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 45, Train Loss: 0.6264, Val Loss: 0.7088, F1 Micro: 0.5506, F1 Macro: 0.5505, Accuracy: 0.5506\n","Epoch 46, Train Loss: 0.6490, Val Loss: 0.6059, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 47, Train Loss: 0.6396, Val Loss: 0.6184, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 48, Train Loss: 0.6404, Val Loss: 0.6304, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 49, Train Loss: 0.6408, Val Loss: 0.6143, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 50, Train Loss: 0.6525, Val Loss: 0.6743, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 51, Train Loss: 0.6524, Val Loss: 0.6038, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 52, Train Loss: 0.6322, Val Loss: 0.5998, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 53, Train Loss: 0.6391, Val Loss: 0.6427, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 54, Train Loss: 0.6436, Val Loss: 0.6696, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 55, Train Loss: 0.6358, Val Loss: 0.6402, F1 Micro: 0.6236, F1 Macro: 0.4823, Accuracy: 0.6236\n","Epoch 56, Train Loss: 0.6315, Val Loss: 0.6400, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.6278, Val Loss: 0.6843, F1 Micro: 0.6742, F1 Macro: 0.6633, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.6301, Val Loss: 0.6249, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 59, Train Loss: 0.6449, Val Loss: 0.6084, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 60, Train Loss: 0.6346, Val Loss: 0.6092, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 61, Train Loss: 0.6395, Val Loss: 0.6468, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6334, Val Loss: 0.7176, F1 Micro: 0.5056, F1 Macro: 0.5016, Accuracy: 0.5056\n","Epoch 63, Train Loss: 0.6439, Val Loss: 0.6740, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.6401, Val Loss: 0.6444, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 65, Train Loss: 0.6408, Val Loss: 0.6402, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 66, Train Loss: 0.6406, Val Loss: 0.6210, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 67, Train Loss: 0.6397, Val Loss: 0.6373, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 68, Train Loss: 0.6434, Val Loss: 0.6277, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 69, Train Loss: 0.6436, Val Loss: 0.6651, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 70, Train Loss: 0.6377, Val Loss: 0.6161, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.6329, Val Loss: 0.6054, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 72, Train Loss: 0.6465, Val Loss: 0.6396, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 73, Train Loss: 0.6336, Val Loss: 0.6379, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 74, Train Loss: 0.6319, Val Loss: 0.6476, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 75, Train Loss: 0.6470, Val Loss: 0.6148, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.9542, Val Loss: 0.7161, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.7225, Val Loss: 0.7677, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 3, Train Loss: 0.6980, Val Loss: 0.6312, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6697, Val Loss: 0.6238, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 5, Train Loss: 0.6534, Val Loss: 0.6172, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6702, Val Loss: 0.6220, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.6489, Val Loss: 0.6102, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6567, Val Loss: 0.6114, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6662, Val Loss: 0.5779, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6635, Val Loss: 0.5872, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 11, Train Loss: 0.6333, Val Loss: 0.5966, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 12, Train Loss: 0.6454, Val Loss: 0.6095, F1 Micro: 0.6742, F1 Macro: 0.6568, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6414, Val Loss: 0.6365, F1 Micro: 0.5730, F1 Macro: 0.5548, Accuracy: 0.5730\n","Epoch 14, Train Loss: 0.6388, Val Loss: 0.6210, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6490, Val Loss: 0.5845, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 16, Train Loss: 0.6532, Val Loss: 0.5992, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6501, Val Loss: 0.5906, F1 Micro: 0.6404, F1 Macro: 0.5310, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6331, Val Loss: 0.5877, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 19, Train Loss: 0.6363, Val Loss: 0.6047, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6313, Val Loss: 0.5744, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 21, Train Loss: 0.6773, Val Loss: 0.6037, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 22, Train Loss: 0.6418, Val Loss: 0.5921, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 23, Train Loss: 0.6458, Val Loss: 0.6125, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 24, Train Loss: 0.6362, Val Loss: 0.6271, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 25, Train Loss: 0.6388, Val Loss: 0.5773, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 26, Train Loss: 0.6292, Val Loss: 0.5795, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 27, Train Loss: 0.6485, Val Loss: 0.6212, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6431, Val Loss: 0.6012, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6376, Val Loss: 0.5799, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 30, Train Loss: 0.6476, Val Loss: 0.6143, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 31, Train Loss: 0.6307, Val Loss: 0.5975, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 32, Train Loss: 0.6439, Val Loss: 0.5936, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 33, Train Loss: 0.6448, Val Loss: 0.5930, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.6477, Val Loss: 0.5940, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 35, Train Loss: 0.6475, Val Loss: 0.5984, F1 Micro: 0.6461, F1 Macro: 0.4780, Accuracy: 0.6461\n","Epoch 36, Train Loss: 0.6412, Val Loss: 0.6313, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.6457, Val Loss: 0.5829, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 38, Train Loss: 0.6475, Val Loss: 0.5848, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6360, Val Loss: 0.5767, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 40, Train Loss: 0.6467, Val Loss: 0.5811, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 41, Train Loss: 0.6388, Val Loss: 0.5837, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 42, Train Loss: 0.6541, Val Loss: 0.5827, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 43, Train Loss: 0.6402, Val Loss: 0.5888, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 44, Train Loss: 0.6417, Val Loss: 0.5828, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 45, Train Loss: 0.6426, Val Loss: 0.5984, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.6391, Val Loss: 0.5989, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 47, Train Loss: 0.6365, Val Loss: 0.5820, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 48, Train Loss: 0.6303, Val Loss: 0.5940, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 49, Train Loss: 0.6486, Val Loss: 0.5908, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 50, Train Loss: 0.6314, Val Loss: 0.5878, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 51, Train Loss: 0.6366, Val Loss: 0.5911, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 52, Train Loss: 0.6218, Val Loss: 0.6390, F1 Micro: 0.6011, F1 Macro: 0.6005, Accuracy: 0.6011\n","Epoch 53, Train Loss: 0.6618, Val Loss: 0.6081, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 54, Train Loss: 0.6409, Val Loss: 0.5961, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 55, Train Loss: 0.6450, Val Loss: 0.5965, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 56, Train Loss: 0.6353, Val Loss: 0.5974, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 57, Train Loss: 0.6363, Val Loss: 0.5730, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 58, Train Loss: 0.6514, Val Loss: 0.5934, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 59, Train Loss: 0.6312, Val Loss: 0.5930, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 60, Train Loss: 0.6332, Val Loss: 0.5864, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 61, Train Loss: 0.6262, Val Loss: 0.5652, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6459, Val Loss: 0.6096, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 63, Train Loss: 0.6362, Val Loss: 0.6186, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 64, Train Loss: 0.6388, Val Loss: 0.5879, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 65, Train Loss: 0.6473, Val Loss: 0.5999, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 66, Train Loss: 0.6420, Val Loss: 0.6353, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 67, Train Loss: 0.6500, Val Loss: 0.5829, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 68, Train Loss: 0.6317, Val Loss: 0.5910, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 69, Train Loss: 0.6546, Val Loss: 0.5888, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.6437, Val Loss: 0.5859, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 71, Train Loss: 0.6467, Val Loss: 0.5782, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 72, Train Loss: 0.6380, Val Loss: 0.5893, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Epoch 73, Train Loss: 0.6222, Val Loss: 0.5962, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 74, Train Loss: 0.6475, Val Loss: 0.5847, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 75, Train Loss: 0.6360, Val Loss: 0.6580, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 76, Train Loss: 0.6622, Val Loss: 0.5993, F1 Micro: 0.7079, F1 Macro: 0.6014, Accuracy: 0.7079\n","Epoch 77, Train Loss: 0.6495, Val Loss: 0.5826, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 78, Train Loss: 0.6394, Val Loss: 0.5819, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 79, Train Loss: 0.6314, Val Loss: 0.5821, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 80, Train Loss: 0.6304, Val Loss: 0.5781, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 81, Train Loss: 0.6474, Val Loss: 0.5872, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 82, Train Loss: 0.6492, Val Loss: 0.6088, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 83, Train Loss: 0.6362, Val Loss: 0.5921, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 84, Train Loss: 0.6281, Val Loss: 0.5924, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 85, Train Loss: 0.6424, Val Loss: 0.6110, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 86, Train Loss: 0.6361, Val Loss: 0.6055, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 87, Train Loss: 0.6553, Val Loss: 0.5952, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 88, Train Loss: 0.6367, Val Loss: 0.5847, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 89, Train Loss: 0.6394, Val Loss: 0.6262, F1 Micro: 0.6404, F1 Macro: 0.6299, Accuracy: 0.6404\n","Epoch 90, Train Loss: 0.6421, Val Loss: 0.6049, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 91, Train Loss: 0.6411, Val Loss: 0.5837, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 92, Train Loss: 0.6339, Val Loss: 0.5905, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 93, Train Loss: 0.6212, Val Loss: 0.5715, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 94, Train Loss: 0.6404, Val Loss: 0.5710, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 95, Train Loss: 0.6326, Val Loss: 0.5714, F1 Micro: 0.7360, F1 Macro: 0.6712, Accuracy: 0.7360\n","Epoch 96, Train Loss: 0.6444, Val Loss: 0.5986, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 97, Train Loss: 0.6462, Val Loss: 0.5880, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 98, Train Loss: 0.6289, Val Loss: 0.6145, F1 Micro: 0.7191, F1 Macro: 0.7025, Accuracy: 0.7191\n","Epoch 99, Train Loss: 0.6369, Val Loss: 0.6076, F1 Micro: 0.6461, F1 Macro: 0.5916, Accuracy: 0.6461\n","Epoch 100, Train Loss: 0.6445, Val Loss: 0.6115, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 101, Train Loss: 0.6198, Val Loss: 0.5751, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 102, Train Loss: 0.6487, Val Loss: 0.5787, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 103, Train Loss: 0.6364, Val Loss: 0.5729, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 104, Train Loss: 0.6320, Val Loss: 0.5937, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 105, Train Loss: 0.6478, Val Loss: 0.5807, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 106, Train Loss: 0.6373, Val Loss: 0.5858, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 107, Train Loss: 0.6368, Val Loss: 0.6127, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 108, Train Loss: 0.6283, Val Loss: 0.5810, F1 Micro: 0.7303, F1 Macro: 0.6663, Accuracy: 0.7303\n","Epoch 109, Train Loss: 0.6403, Val Loss: 0.5805, F1 Micro: 0.7303, F1 Macro: 0.6621, Accuracy: 0.7303\n","Epoch 110, Train Loss: 0.6370, Val Loss: 0.6152, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 111, Train Loss: 0.6331, Val Loss: 0.5802, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 112, Train Loss: 0.6371, Val Loss: 0.5900, F1 Micro: 0.7360, F1 Macro: 0.6580, Accuracy: 0.7360\n","Epoch 113, Train Loss: 0.6406, Val Loss: 0.6084, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 114, Train Loss: 0.6311, Val Loss: 0.5944, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 115, Train Loss: 0.6382, Val Loss: 0.6621, F1 Micro: 0.5899, F1 Macro: 0.5893, Accuracy: 0.5899\n","Epoch 116, Train Loss: 0.6515, Val Loss: 0.5839, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 117, Train Loss: 0.6471, Val Loss: 0.5865, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 118, Train Loss: 0.6502, Val Loss: 0.6389, F1 Micro: 0.5730, F1 Macro: 0.5704, Accuracy: 0.5730\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8980, Val Loss: 0.7914, F1 Micro: 0.5449, F1 Macro: 0.5446, Accuracy: 0.5449\n","Epoch 2, Train Loss: 0.6907, Val Loss: 0.9106, F1 Micro: 0.5618, F1 Macro: 0.5274, Accuracy: 0.5618\n","Epoch 3, Train Loss: 0.6909, Val Loss: 0.8596, F1 Micro: 0.5449, F1 Macro: 0.4588, Accuracy: 0.5449\n","Epoch 4, Train Loss: 0.6524, Val Loss: 0.7898, F1 Micro: 0.5562, F1 Macro: 0.5093, Accuracy: 0.5562\n","Epoch 5, Train Loss: 0.6404, Val Loss: 0.7165, F1 Micro: 0.5955, F1 Macro: 0.5930, Accuracy: 0.5955\n","Epoch 6, Train Loss: 0.6437, Val Loss: 0.7247, F1 Micro: 0.5955, F1 Macro: 0.5955, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6303, Val Loss: 0.7390, F1 Micro: 0.6180, F1 Macro: 0.5997, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6044, Val Loss: 0.7926, F1 Micro: 0.5562, F1 Macro: 0.4329, Accuracy: 0.5562\n","Epoch 9, Train Loss: 0.6148, Val Loss: 0.7049, F1 Micro: 0.6067, F1 Macro: 0.5952, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6178, Val Loss: 0.7349, F1 Micro: 0.5787, F1 Macro: 0.5525, Accuracy: 0.5787\n","Epoch 11, Train Loss: 0.6061, Val Loss: 0.7843, F1 Micro: 0.6011, F1 Macro: 0.5655, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6177, Val Loss: 0.6994, F1 Micro: 0.5169, F1 Macro: 0.5163, Accuracy: 0.5169\n","Epoch 13, Train Loss: 0.6130, Val Loss: 0.9277, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 14, Train Loss: 0.6032, Val Loss: 0.7452, F1 Micro: 0.6011, F1 Macro: 0.5655, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6190, Val Loss: 0.7970, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6024, Val Loss: 0.7130, F1 Micro: 0.5899, F1 Macro: 0.5787, Accuracy: 0.5899\n","Epoch 17, Train Loss: 0.6067, Val Loss: 0.7649, F1 Micro: 0.5506, F1 Macro: 0.4683, Accuracy: 0.5506\n","Epoch 18, Train Loss: 0.6044, Val Loss: 1.0299, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6406, Val Loss: 0.7117, F1 Micro: 0.5899, F1 Macro: 0.5870, Accuracy: 0.5899\n","Epoch 20, Train Loss: 0.6318, Val Loss: 0.7258, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 21, Train Loss: 0.6153, Val Loss: 0.7372, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 22, Train Loss: 0.6043, Val Loss: 0.7350, F1 Micro: 0.5843, F1 Macro: 0.5721, Accuracy: 0.5843\n","Epoch 23, Train Loss: 0.6033, Val Loss: 0.7033, F1 Micro: 0.5506, F1 Macro: 0.5478, Accuracy: 0.5506\n","Epoch 24, Train Loss: 0.6133, Val Loss: 0.7564, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 25, Train Loss: 0.6218, Val Loss: 0.7129, F1 Micro: 0.5899, F1 Macro: 0.5734, Accuracy: 0.5899\n","Epoch 26, Train Loss: 0.6225, Val Loss: 0.7189, F1 Micro: 0.5955, F1 Macro: 0.5820, Accuracy: 0.5955\n","Epoch 27, Train Loss: 0.6025, Val Loss: 0.8227, F1 Micro: 0.6011, F1 Macro: 0.5205, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6040, Val Loss: 0.7321, F1 Micro: 0.6011, F1 Macro: 0.5831, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6210, Val Loss: 0.7321, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 30, Train Loss: 0.6021, Val Loss: 0.7281, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 31, Train Loss: 0.6119, Val Loss: 0.8059, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6105, Val Loss: 0.7551, F1 Micro: 0.5730, F1 Macro: 0.5223, Accuracy: 0.5730\n","Epoch 33, Train Loss: 0.6136, Val Loss: 0.7461, F1 Micro: 0.5787, F1 Macro: 0.5617, Accuracy: 0.5787\n","Epoch 34, Train Loss: 0.5986, Val Loss: 0.7916, F1 Micro: 0.6180, F1 Macro: 0.6162, Accuracy: 0.6180\n","Epoch 35, Train Loss: 0.6326, Val Loss: 0.7359, F1 Micro: 0.6124, F1 Macro: 0.5859, Accuracy: 0.6124\n","Epoch 36, Train Loss: 0.6122, Val Loss: 0.7057, F1 Micro: 0.5787, F1 Macro: 0.5764, Accuracy: 0.5787\n","Epoch 37, Train Loss: 0.6284, Val Loss: 0.8585, F1 Micro: 0.5506, F1 Macro: 0.4789, Accuracy: 0.5506\n","Epoch 38, Train Loss: 0.6143, Val Loss: 0.7654, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6347, Val Loss: 0.7428, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 40, Train Loss: 0.6295, Val Loss: 0.7209, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6070, Val Loss: 0.7508, F1 Micro: 0.6180, F1 Macro: 0.6052, Accuracy: 0.6180\n","Epoch 42, Train Loss: 0.6169, Val Loss: 0.7214, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 43, Train Loss: 0.6085, Val Loss: 0.7290, F1 Micro: 0.5674, F1 Macro: 0.5456, Accuracy: 0.5674\n","Epoch 44, Train Loss: 0.6099, Val Loss: 0.7709, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 45, Train Loss: 0.6044, Val Loss: 0.7154, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6064, Val Loss: 0.7163, F1 Micro: 0.5843, F1 Macro: 0.5766, Accuracy: 0.5843\n","Epoch 47, Train Loss: 0.6146, Val Loss: 0.7713, F1 Micro: 0.5730, F1 Macro: 0.5261, Accuracy: 0.5730\n","Epoch 48, Train Loss: 0.5945, Val Loss: 0.7865, F1 Micro: 0.5506, F1 Macro: 0.4626, Accuracy: 0.5506\n","Epoch 49, Train Loss: 0.6137, Val Loss: 0.7407, F1 Micro: 0.5674, F1 Macro: 0.5350, Accuracy: 0.5674\n","Epoch 50, Train Loss: 0.6222, Val Loss: 0.7350, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 51, Train Loss: 0.5957, Val Loss: 0.9353, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 52, Train Loss: 0.6246, Val Loss: 0.7299, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 53, Train Loss: 0.6101, Val Loss: 0.7386, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 54, Train Loss: 0.6240, Val Loss: 0.7375, F1 Micro: 0.6011, F1 Macro: 0.5788, Accuracy: 0.6011\n","Epoch 55, Train Loss: 0.6086, Val Loss: 0.7538, F1 Micro: 0.5562, F1 Macro: 0.4722, Accuracy: 0.5562\n","Epoch 56, Train Loss: 0.6070, Val Loss: 0.7428, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 57, Train Loss: 0.5898, Val Loss: 0.7297, F1 Micro: 0.5955, F1 Macro: 0.5762, Accuracy: 0.5955\n","Epoch 58, Train Loss: 0.6203, Val Loss: 0.7700, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 59, Train Loss: 0.5993, Val Loss: 0.7584, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 60, Train Loss: 0.5917, Val Loss: 0.7802, F1 Micro: 0.5787, F1 Macro: 0.5550, Accuracy: 0.5787\n","Epoch 61, Train Loss: 0.6088, Val Loss: 0.7293, F1 Micro: 0.6180, F1 Macro: 0.6052, Accuracy: 0.6180\n","Epoch 62, Train Loss: 0.6037, Val Loss: 0.7267, F1 Micro: 0.6011, F1 Macro: 0.5869, Accuracy: 0.6011\n","Epoch 63, Train Loss: 0.6055, Val Loss: 0.7593, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 64, Train Loss: 0.6131, Val Loss: 0.7771, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 65, Train Loss: 0.6165, Val Loss: 0.7098, F1 Micro: 0.6180, F1 Macro: 0.6168, Accuracy: 0.6180\n","Epoch 66, Train Loss: 0.6224, Val Loss: 0.7204, F1 Micro: 0.5787, F1 Macro: 0.5672, Accuracy: 0.5787\n","Epoch 67, Train Loss: 0.6050, Val Loss: 0.7351, F1 Micro: 0.5955, F1 Macro: 0.5820, Accuracy: 0.5955\n","Epoch 68, Train Loss: 0.6111, Val Loss: 0.7249, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 69, Train Loss: 0.6159, Val Loss: 0.7319, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 70, Train Loss: 0.6019, Val Loss: 0.7481, F1 Micro: 0.5449, F1 Macro: 0.4929, Accuracy: 0.5449\n","Epoch 71, Train Loss: 0.5910, Val Loss: 0.7339, F1 Micro: 0.5674, F1 Macro: 0.5587, Accuracy: 0.5674\n","Epoch 72, Train Loss: 0.5917, Val Loss: 0.7549, F1 Micro: 0.6011, F1 Macro: 0.5788, Accuracy: 0.6011\n","Epoch 73, Train Loss: 0.6136, Val Loss: 0.7649, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 74, Train Loss: 0.6009, Val Loss: 0.7774, F1 Micro: 0.5337, F1 Macro: 0.4567, Accuracy: 0.5337\n","Epoch 75, Train Loss: 0.6130, Val Loss: 0.7361, F1 Micro: 0.5674, F1 Macro: 0.5379, Accuracy: 0.5674\n","Epoch 76, Train Loss: 0.6216, Val Loss: 0.7622, F1 Micro: 0.6067, F1 Macro: 0.5811, Accuracy: 0.6067\n","Epoch 77, Train Loss: 0.6178, Val Loss: 0.7171, F1 Micro: 0.5787, F1 Macro: 0.5672, Accuracy: 0.5787\n","Epoch 78, Train Loss: 0.6117, Val Loss: 0.7150, F1 Micro: 0.5955, F1 Macro: 0.5867, Accuracy: 0.5955\n","Epoch 79, Train Loss: 0.6144, Val Loss: 0.7482, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 80, Train Loss: 0.6077, Val Loss: 0.8141, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 81, Train Loss: 0.5916, Val Loss: 0.7436, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 82, Train Loss: 0.5982, Val Loss: 0.7520, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 83, Train Loss: 0.6299, Val Loss: 0.7384, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 84, Train Loss: 0.6026, Val Loss: 0.7540, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 85, Train Loss: 0.5992, Val Loss: 0.7240, F1 Micro: 0.5899, F1 Macro: 0.5896, Accuracy: 0.5899\n","Epoch 86, Train Loss: 0.6120, Val Loss: 0.7342, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 87, Train Loss: 0.6187, Val Loss: 0.7803, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 88, Train Loss: 0.6063, Val Loss: 0.7566, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 89, Train Loss: 0.6267, Val Loss: 0.7437, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 90, Train Loss: 0.6048, Val Loss: 0.7264, F1 Micro: 0.5899, F1 Macro: 0.5714, Accuracy: 0.5899\n","Epoch 91, Train Loss: 0.6018, Val Loss: 0.7328, F1 Micro: 0.5787, F1 Macro: 0.5617, Accuracy: 0.5787\n","Epoch 92, Train Loss: 0.5922, Val Loss: 0.7780, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 93, Train Loss: 0.6071, Val Loss: 0.7589, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 94, Train Loss: 0.6080, Val Loss: 0.7667, F1 Micro: 0.5674, F1 Macro: 0.5287, Accuracy: 0.5674\n","Epoch 95, Train Loss: 0.6018, Val Loss: 0.7545, F1 Micro: 0.5899, F1 Macro: 0.5734, Accuracy: 0.5899\n","Epoch 96, Train Loss: 0.6035, Val Loss: 0.7324, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 97, Train Loss: 0.6122, Val Loss: 0.7267, F1 Micro: 0.5843, F1 Macro: 0.5665, Accuracy: 0.5843\n","Epoch 98, Train Loss: 0.6134, Val Loss: 0.8038, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 99, Train Loss: 0.6248, Val Loss: 0.7407, F1 Micro: 0.6067, F1 Macro: 0.5919, Accuracy: 0.6067\n","Epoch 100, Train Loss: 0.6098, Val Loss: 0.7330, F1 Micro: 0.5955, F1 Macro: 0.5802, Accuracy: 0.5955\n","Epoch 101, Train Loss: 0.6126, Val Loss: 0.7295, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 102, Train Loss: 0.5890, Val Loss: 0.7986, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 103, Train Loss: 0.5994, Val Loss: 0.7639, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 104, Train Loss: 0.6161, Val Loss: 0.7809, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 105, Train Loss: 0.6120, Val Loss: 0.7219, F1 Micro: 0.5843, F1 Macro: 0.5685, Accuracy: 0.5843\n","Epoch 106, Train Loss: 0.6038, Val Loss: 0.7391, F1 Micro: 0.5169, F1 Macro: 0.5119, Accuracy: 0.5169\n","Epoch 107, Train Loss: 0.6112, Val Loss: 0.8056, F1 Micro: 0.5393, F1 Macro: 0.4366, Accuracy: 0.5393\n","Epoch 108, Train Loss: 0.6090, Val Loss: 0.7514, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 109, Train Loss: 0.6074, Val Loss: 0.7310, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 110, Train Loss: 0.6201, Val Loss: 0.7648, F1 Micro: 0.6067, F1 Macro: 0.5635, Accuracy: 0.6067\n","Epoch 111, Train Loss: 0.5998, Val Loss: 0.7630, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 112, Train Loss: 0.5817, Val Loss: 0.7540, F1 Micro: 0.5899, F1 Macro: 0.5645, Accuracy: 0.5899\n","Epoch 113, Train Loss: 0.6152, Val Loss: 0.7296, F1 Micro: 0.6067, F1 Macro: 0.5900, Accuracy: 0.6067\n","Epoch 114, Train Loss: 0.6123, Val Loss: 0.7474, F1 Micro: 0.5787, F1 Macro: 0.5499, Accuracy: 0.5787\n","Epoch 115, Train Loss: 0.5989, Val Loss: 0.7313, F1 Micro: 0.5674, F1 Macro: 0.5613, Accuracy: 0.5674\n","Epoch 116, Train Loss: 0.6062, Val Loss: 0.7628, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 117, Train Loss: 0.6029, Val Loss: 0.7399, F1 Micro: 0.6067, F1 Macro: 0.5900, Accuracy: 0.6067\n","Epoch 118, Train Loss: 0.6062, Val Loss: 0.7190, F1 Micro: 0.5899, F1 Macro: 0.5841, Accuracy: 0.5899\n","Epoch 119, Train Loss: 0.5991, Val Loss: 0.7863, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.9297, Val Loss: 0.7623, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 2, Train Loss: 0.6757, Val Loss: 0.6645, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6904, Val Loss: 0.6867, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6973, Val Loss: 0.7524, F1 Micro: 0.5393, F1 Macro: 0.5379, Accuracy: 0.5393\n","Epoch 5, Train Loss: 0.6740, Val Loss: 0.6681, F1 Micro: 0.6236, F1 Macro: 0.6118, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6364, Val Loss: 0.7120, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 7, Train Loss: 0.6357, Val Loss: 0.6969, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 8, Train Loss: 0.6386, Val Loss: 0.6699, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.6612, Val Loss: 0.6970, F1 Micro: 0.5730, F1 Macro: 0.5588, Accuracy: 0.5730\n","Epoch 10, Train Loss: 0.6525, Val Loss: 0.6830, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6373, Val Loss: 0.6551, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 12, Train Loss: 0.6395, Val Loss: 0.6728, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.6318, Val Loss: 0.6761, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 14, Train Loss: 0.6376, Val Loss: 0.6823, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6446, Val Loss: 0.6696, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.6319, Val Loss: 0.6785, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6424, Val Loss: 0.6832, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 18, Train Loss: 0.6277, Val Loss: 0.7370, F1 Micro: 0.6124, F1 Macro: 0.5231, Accuracy: 0.6124\n","Epoch 19, Train Loss: 0.6366, Val Loss: 0.7075, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 20, Train Loss: 0.6389, Val Loss: 0.6775, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6467, Val Loss: 0.6652, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 22, Train Loss: 0.6323, Val Loss: 0.6795, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.6219, Val Loss: 0.7139, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 24, Train Loss: 0.6252, Val Loss: 0.6729, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 25, Train Loss: 0.6436, Val Loss: 0.6737, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6354, Val Loss: 0.6729, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 27, Train Loss: 0.6302, Val Loss: 0.6959, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6181, Val Loss: 0.7407, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 29, Train Loss: 0.6357, Val Loss: 0.7503, F1 Micro: 0.6404, F1 Macro: 0.4746, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6377, Val Loss: 0.6866, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 31, Train Loss: 0.6334, Val Loss: 0.6749, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.6401, Val Loss: 0.6615, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 33, Train Loss: 0.6282, Val Loss: 0.7383, F1 Micro: 0.7022, F1 Macro: 0.6088, Accuracy: 0.7022\n","Epoch 34, Train Loss: 0.6416, Val Loss: 0.6966, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 35, Train Loss: 0.6238, Val Loss: 0.6835, F1 Micro: 0.6348, F1 Macro: 0.5270, Accuracy: 0.6348\n","Epoch 36, Train Loss: 0.6341, Val Loss: 0.7104, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 37, Train Loss: 0.6204, Val Loss: 0.7659, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.6302, Val Loss: 0.6753, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6301, Val Loss: 0.6815, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 40, Train Loss: 0.6530, Val Loss: 0.6810, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 41, Train Loss: 0.6309, Val Loss: 0.6709, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 42, Train Loss: 0.6290, Val Loss: 0.6874, F1 Micro: 0.6236, F1 Macro: 0.5190, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6327, Val Loss: 0.6936, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.6349, Val Loss: 0.6636, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 45, Train Loss: 0.6301, Val Loss: 0.6773, F1 Micro: 0.6742, F1 Macro: 0.6508, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.6428, Val Loss: 0.7007, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 47, Train Loss: 0.6512, Val Loss: 0.6706, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 48, Train Loss: 0.6378, Val Loss: 0.6966, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.6241, Val Loss: 0.6704, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 50, Train Loss: 0.6283, Val Loss: 0.6713, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 51, Train Loss: 0.6327, Val Loss: 0.6715, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 52, Train Loss: 0.6355, Val Loss: 0.6691, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 53, Train Loss: 0.6452, Val Loss: 0.7231, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.6412, Val Loss: 0.6741, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 55, Train Loss: 0.6300, Val Loss: 0.6972, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 56, Train Loss: 0.6260, Val Loss: 0.6939, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 57, Train Loss: 0.6202, Val Loss: 0.6713, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 58, Train Loss: 0.6365, Val Loss: 0.7366, F1 Micro: 0.6404, F1 Macro: 0.5014, Accuracy: 0.6404\n","Epoch 59, Train Loss: 0.6303, Val Loss: 0.6750, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 60, Train Loss: 0.6287, Val Loss: 0.6849, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 61, Train Loss: 0.6242, Val Loss: 0.7188, F1 Micro: 0.6236, F1 Macro: 0.4981, Accuracy: 0.6236\n","Epoch 62, Train Loss: 0.6287, Val Loss: 0.7159, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.6291, Val Loss: 0.7075, F1 Micro: 0.6966, F1 Macro: 0.6245, Accuracy: 0.6966\n","Epoch 64, Train Loss: 0.6340, Val Loss: 0.6793, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 65, Train Loss: 0.6242, Val Loss: 0.6899, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.7137969995606052\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8082, Val Loss: 0.6346, F1 Micro: 0.7486, F1 Macro: 0.7254, Accuracy: 0.7486\n","Epoch 2, Train Loss: 0.6846, Val Loss: 0.7109, F1 Micro: 0.6760, F1 Macro: 0.5489, Accuracy: 0.6760\n","Epoch 3, Train Loss: 0.6883, Val Loss: 0.6698, F1 Micro: 0.6257, F1 Macro: 0.6163, Accuracy: 0.6257\n","Epoch 4, Train Loss: 0.6750, Val Loss: 0.7366, F1 Micro: 0.6480, F1 Macro: 0.5217, Accuracy: 0.6480\n","Epoch 5, Train Loss: 0.7271, Val Loss: 0.6806, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 6, Train Loss: 0.6694, Val Loss: 0.6424, F1 Micro: 0.6369, F1 Macro: 0.5404, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.6688, Val Loss: 0.6401, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.6579, Val Loss: 0.6414, F1 Micro: 0.6592, F1 Macro: 0.6373, Accuracy: 0.6592\n","Epoch 9, Train Loss: 0.6545, Val Loss: 0.6055, F1 Micro: 0.6704, F1 Macro: 0.5589, Accuracy: 0.6704\n","Epoch 10, Train Loss: 0.6769, Val Loss: 0.7125, F1 Micro: 0.6369, F1 Macro: 0.4408, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6577, Val Loss: 0.6637, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8971, Val Loss: 0.5964, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 2, Train Loss: 0.7239, Val Loss: 0.6754, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6904, Val Loss: 0.6044, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 4, Train Loss: 0.6766, Val Loss: 0.5851, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 5, Train Loss: 0.6547, Val Loss: 0.5852, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 6, Train Loss: 0.6825, Val Loss: 0.7206, F1 Micro: 0.5955, F1 Macro: 0.5950, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6805, Val Loss: 0.6120, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6505, Val Loss: 0.6139, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.6713, Val Loss: 0.5903, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 10, Train Loss: 0.6586, Val Loss: 0.5722, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 11, Train Loss: 0.6489, Val Loss: 0.5830, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 12, Train Loss: 0.6506, Val Loss: 0.6210, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.6374, Val Loss: 0.5801, F1 Micro: 0.7753, F1 Macro: 0.7443, Accuracy: 0.7753\n","Epoch 14, Train Loss: 0.6324, Val Loss: 0.6020, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 15, Train Loss: 0.6375, Val Loss: 0.6090, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 16, Train Loss: 0.6417, Val Loss: 0.6759, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6231, Val Loss: 0.6087, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6282, Val Loss: 0.6080, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 19, Train Loss: 0.6534, Val Loss: 0.6078, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 20, Train Loss: 0.6493, Val Loss: 0.6136, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.6468, Val Loss: 0.5995, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6395, Val Loss: 0.5903, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 23, Train Loss: 0.6485, Val Loss: 0.6038, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8202, Val Loss: 0.7907, F1 Micro: 0.4775, F1 Macro: 0.4670, Accuracy: 0.4775\n","Epoch 2, Train Loss: 0.7471, Val Loss: 0.6166, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 3, Train Loss: 0.7223, Val Loss: 0.5827, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 4, Train Loss: 0.6770, Val Loss: 0.8757, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 5, Train Loss: 0.7022, Val Loss: 0.6649, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 6, Train Loss: 0.6560, Val Loss: 0.5830, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6458, Val Loss: 0.6152, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 8, Train Loss: 0.6516, Val Loss: 0.7032, F1 Micro: 0.5337, F1 Macro: 0.5333, Accuracy: 0.5337\n","Epoch 9, Train Loss: 0.6545, Val Loss: 0.5814, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 10, Train Loss: 0.6396, Val Loss: 0.6087, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.6363, Val Loss: 0.6352, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.6517, Val Loss: 0.5823, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 13, Train Loss: 0.6303, Val Loss: 0.6905, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6689, Val Loss: 0.5826, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 15, Train Loss: 0.6473, Val Loss: 0.5920, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.6307, Val Loss: 0.5888, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 17, Train Loss: 0.6376, Val Loss: 0.5981, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6602, Val Loss: 0.6031, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 19, Train Loss: 0.6326, Val Loss: 0.5914, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8137, Val Loss: 1.2067, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 2, Train Loss: 0.6614, Val Loss: 0.7080, F1 Micro: 0.5506, F1 Macro: 0.5374, Accuracy: 0.5506\n","Epoch 3, Train Loss: 0.7467, Val Loss: 0.8961, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 4, Train Loss: 0.6349, Val Loss: 0.8117, F1 Micro: 0.5225, F1 Macro: 0.5157, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6584, Val Loss: 0.7685, F1 Micro: 0.5562, F1 Macro: 0.5165, Accuracy: 0.5562\n","Epoch 6, Train Loss: 0.6537, Val Loss: 0.7431, F1 Micro: 0.5449, F1 Macro: 0.5448, Accuracy: 0.5449\n","Epoch 7, Train Loss: 0.6326, Val Loss: 0.8026, F1 Micro: 0.5899, F1 Macro: 0.5592, Accuracy: 0.5899\n","Epoch 8, Train Loss: 0.6252, Val Loss: 0.7891, F1 Micro: 0.6124, F1 Macro: 0.5681, Accuracy: 0.6124\n","Epoch 9, Train Loss: 0.6188, Val Loss: 0.7505, F1 Micro: 0.5674, F1 Macro: 0.5406, Accuracy: 0.5674\n","Epoch 10, Train Loss: 0.6101, Val Loss: 0.7854, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6113, Val Loss: 0.8372, F1 Micro: 0.5562, F1 Macro: 0.4971, Accuracy: 0.5562\n","Epoch 12, Train Loss: 0.6303, Val Loss: 0.7298, F1 Micro: 0.6067, F1 Macro: 0.5952, Accuracy: 0.6067\n","Epoch 13, Train Loss: 0.6084, Val Loss: 0.8586, F1 Micro: 0.5787, F1 Macro: 0.5410, Accuracy: 0.5787\n","Epoch 14, Train Loss: 0.6127, Val Loss: 0.7524, F1 Micro: 0.5506, F1 Macro: 0.5267, Accuracy: 0.5506\n","Epoch 15, Train Loss: 0.6195, Val Loss: 0.8626, F1 Micro: 0.5506, F1 Macro: 0.4504, Accuracy: 0.5506\n","Epoch 16, Train Loss: 0.6040, Val Loss: 0.8910, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6219, Val Loss: 0.7864, F1 Micro: 0.5618, F1 Macro: 0.4919, Accuracy: 0.5618\n","Epoch 18, Train Loss: 0.5983, Val Loss: 0.7776, F1 Micro: 0.6067, F1 Macro: 0.5811, Accuracy: 0.6067\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8468, Val Loss: 0.6842, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.6946, Val Loss: 0.7428, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.7066, Val Loss: 0.7311, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 4, Train Loss: 0.6575, Val Loss: 0.8775, F1 Micro: 0.6404, F1 Macro: 0.4746, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.7075, Val Loss: 0.7307, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6697, Val Loss: 0.7078, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 7, Train Loss: 0.6590, Val Loss: 0.6815, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 8, Train Loss: 0.6328, Val Loss: 0.7894, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 9, Train Loss: 0.6377, Val Loss: 0.7062, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 10, Train Loss: 0.6337, Val Loss: 0.7206, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6316, Val Loss: 0.7155, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6194, Val Loss: 0.7833, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6355, Val Loss: 0.7000, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 14, Train Loss: 0.6135, Val Loss: 0.6849, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 15, Train Loss: 0.6325, Val Loss: 0.6927, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 16, Train Loss: 0.6204, Val Loss: 0.7418, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 17, Train Loss: 0.6333, Val Loss: 0.7103, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.6264, Val Loss: 0.7580, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6270, Val Loss: 0.7334, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.7148892097169042\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8441, Val Loss: 0.8252, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.7349, Val Loss: 0.6510, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6705, Val Loss: 0.6758, F1 Micro: 0.6536, F1 Macro: 0.5399, Accuracy: 0.6536\n","Epoch 4, Train Loss: 0.7009, Val Loss: 0.6514, F1 Micro: 0.6592, F1 Macro: 0.6192, Accuracy: 0.6592\n","Epoch 5, Train Loss: 0.6895, Val Loss: 0.6626, F1 Micro: 0.6760, F1 Macro: 0.5489, Accuracy: 0.6760\n","Epoch 6, Train Loss: 0.6775, Val Loss: 0.6687, F1 Micro: 0.6480, F1 Macro: 0.6332, Accuracy: 0.6480\n","Epoch 7, Train Loss: 0.6456, Val Loss: 0.6102, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.6479, Val Loss: 0.6137, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 9, Train Loss: 0.6562, Val Loss: 0.6200, F1 Micro: 0.6648, F1 Macro: 0.6443, Accuracy: 0.6648\n","Epoch 10, Train Loss: 0.6787, Val Loss: 0.6390, F1 Micro: 0.6816, F1 Macro: 0.5916, Accuracy: 0.6816\n","Epoch 11, Train Loss: 0.6320, Val Loss: 0.6202, F1 Micro: 0.6872, F1 Macro: 0.6775, Accuracy: 0.6872\n","Epoch 12, Train Loss: 0.6506, Val Loss: 0.6136, F1 Micro: 0.6872, F1 Macro: 0.6698, Accuracy: 0.6872\n","Epoch 13, Train Loss: 0.6435, Val Loss: 0.6503, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 14, Train Loss: 0.6398, Val Loss: 0.6236, F1 Micro: 0.6592, F1 Macro: 0.4954, Accuracy: 0.6592\n","Epoch 15, Train Loss: 0.6389, Val Loss: 0.6131, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 16, Train Loss: 0.6700, Val Loss: 0.6292, F1 Micro: 0.6648, F1 Macro: 0.6544, Accuracy: 0.6648\n","Epoch 17, Train Loss: 0.6901, Val Loss: 0.6423, F1 Micro: 0.6872, F1 Macro: 0.6761, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.6314, Val Loss: 0.6257, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 19, Train Loss: 0.6452, Val Loss: 0.6439, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 20, Train Loss: 0.6587, Val Loss: 0.6130, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 21, Train Loss: 0.6217, Val Loss: 0.6238, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 22, Train Loss: 0.6438, Val Loss: 0.6208, F1 Micro: 0.6704, F1 Macro: 0.6374, Accuracy: 0.6704\n","Epoch 23, Train Loss: 0.6367, Val Loss: 0.6050, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 24, Train Loss: 0.6306, Val Loss: 0.6268, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 25, Train Loss: 0.6398, Val Loss: 0.6252, F1 Micro: 0.6592, F1 Macro: 0.4954, Accuracy: 0.6592\n","Epoch 26, Train Loss: 0.6309, Val Loss: 0.6173, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 27, Train Loss: 0.6307, Val Loss: 0.6170, F1 Micro: 0.6816, F1 Macro: 0.6665, Accuracy: 0.6816\n","Epoch 28, Train Loss: 0.6353, Val Loss: 0.6004, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 29, Train Loss: 0.6295, Val Loss: 0.6029, F1 Micro: 0.6816, F1 Macro: 0.6413, Accuracy: 0.6816\n","Epoch 30, Train Loss: 0.6318, Val Loss: 0.6398, F1 Micro: 0.6369, F1 Macro: 0.6339, Accuracy: 0.6369\n","Epoch 31, Train Loss: 0.6361, Val Loss: 0.6113, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 32, Train Loss: 0.6261, Val Loss: 0.6066, F1 Micro: 0.6704, F1 Macro: 0.6400, Accuracy: 0.6704\n","Epoch 33, Train Loss: 0.6273, Val Loss: 0.6164, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 34, Train Loss: 0.6532, Val Loss: 0.6731, F1 Micro: 0.6034, F1 Macro: 0.6009, Accuracy: 0.6034\n","Epoch 35, Train Loss: 0.6384, Val Loss: 0.6118, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 36, Train Loss: 0.6392, Val Loss: 0.6217, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 37, Train Loss: 0.6386, Val Loss: 0.6165, F1 Micro: 0.6983, F1 Macro: 0.6669, Accuracy: 0.6983\n","Epoch 38, Train Loss: 0.6320, Val Loss: 0.6107, F1 Micro: 0.7151, F1 Macro: 0.6842, Accuracy: 0.7151\n","Epoch 39, Train Loss: 0.6281, Val Loss: 0.6168, F1 Micro: 0.6592, F1 Macro: 0.5439, Accuracy: 0.6592\n","Epoch 40, Train Loss: 0.6413, Val Loss: 0.6281, F1 Micro: 0.6648, F1 Macro: 0.6581, Accuracy: 0.6648\n","Epoch 41, Train Loss: 0.6550, Val Loss: 0.6125, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 42, Train Loss: 0.6375, Val Loss: 0.6083, F1 Micro: 0.6704, F1 Macro: 0.6346, Accuracy: 0.6704\n","Epoch 43, Train Loss: 0.6415, Val Loss: 0.6123, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 44, Train Loss: 0.6398, Val Loss: 0.6100, F1 Micro: 0.7039, F1 Macro: 0.6692, Accuracy: 0.7039\n","Epoch 45, Train Loss: 0.6410, Val Loss: 0.6109, F1 Micro: 0.6872, F1 Macro: 0.6326, Accuracy: 0.6872\n","Epoch 46, Train Loss: 0.6390, Val Loss: 0.6179, F1 Micro: 0.6648, F1 Macro: 0.6270, Accuracy: 0.6648\n","Epoch 47, Train Loss: 0.6220, Val Loss: 0.6074, F1 Micro: 0.7207, F1 Macro: 0.6866, Accuracy: 0.7207\n","Epoch 48, Train Loss: 0.6304, Val Loss: 0.6172, F1 Micro: 0.6872, F1 Macro: 0.6775, Accuracy: 0.6872\n","Epoch 49, Train Loss: 0.6232, Val Loss: 0.6033, F1 Micro: 0.7039, F1 Macro: 0.6830, Accuracy: 0.7039\n","Epoch 50, Train Loss: 0.6383, Val Loss: 0.6032, F1 Micro: 0.6704, F1 Macro: 0.6255, Accuracy: 0.6704\n","Epoch 51, Train Loss: 0.6317, Val Loss: 0.6091, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 52, Train Loss: 0.6358, Val Loss: 0.6108, F1 Micro: 0.6592, F1 Macro: 0.5977, Accuracy: 0.6592\n","Epoch 53, Train Loss: 0.6370, Val Loss: 0.6061, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 54, Train Loss: 0.6385, Val Loss: 0.6258, F1 Micro: 0.6760, F1 Macro: 0.6660, Accuracy: 0.6760\n","Epoch 55, Train Loss: 0.6224, Val Loss: 0.6305, F1 Micro: 0.6592, F1 Macro: 0.6557, Accuracy: 0.6592\n","Epoch 56, Train Loss: 0.6296, Val Loss: 0.6126, F1 Micro: 0.6760, F1 Macro: 0.6598, Accuracy: 0.6760\n","Epoch 57, Train Loss: 0.6265, Val Loss: 0.6238, F1 Micro: 0.6592, F1 Macro: 0.5742, Accuracy: 0.6592\n","Epoch 58, Train Loss: 0.6292, Val Loss: 0.6107, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 59, Train Loss: 0.6303, Val Loss: 0.6049, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 60, Train Loss: 0.6418, Val Loss: 0.6297, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 61, Train Loss: 0.6460, Val Loss: 0.6119, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 62, Train Loss: 0.6258, Val Loss: 0.6225, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 63, Train Loss: 0.6257, Val Loss: 0.6068, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 64, Train Loss: 0.6263, Val Loss: 0.6018, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 65, Train Loss: 0.6456, Val Loss: 0.6091, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 66, Train Loss: 0.6281, Val Loss: 0.6025, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 67, Train Loss: 0.6372, Val Loss: 0.6183, F1 Micro: 0.6872, F1 Macro: 0.6698, Accuracy: 0.6872\n","Epoch 68, Train Loss: 0.6292, Val Loss: 0.6154, F1 Micro: 0.6704, F1 Macro: 0.6609, Accuracy: 0.6704\n","Epoch 69, Train Loss: 0.6359, Val Loss: 0.6117, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 70, Train Loss: 0.6288, Val Loss: 0.6339, F1 Micro: 0.6648, F1 Macro: 0.6618, Accuracy: 0.6648\n","Epoch 71, Train Loss: 0.6245, Val Loss: 0.6109, F1 Micro: 0.7151, F1 Macro: 0.6817, Accuracy: 0.7151\n","Epoch 72, Train Loss: 0.6330, Val Loss: 0.6089, F1 Micro: 0.6592, F1 Macro: 0.6017, Accuracy: 0.6592\n","Epoch 73, Train Loss: 0.6233, Val Loss: 0.6162, F1 Micro: 0.6648, F1 Macro: 0.5730, Accuracy: 0.6648\n","Epoch 74, Train Loss: 0.6179, Val Loss: 0.6034, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 75, Train Loss: 0.6195, Val Loss: 0.6057, F1 Micro: 0.6648, F1 Macro: 0.5887, Accuracy: 0.6648\n","Epoch 76, Train Loss: 0.6537, Val Loss: 0.6084, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 77, Train Loss: 0.6263, Val Loss: 0.6116, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 78, Train Loss: 0.6384, Val Loss: 0.6055, F1 Micro: 0.6927, F1 Macro: 0.6373, Accuracy: 0.6927\n","Epoch 79, Train Loss: 0.6239, Val Loss: 0.6277, F1 Micro: 0.6704, F1 Macro: 0.5881, Accuracy: 0.6704\n","Epoch 80, Train Loss: 0.6322, Val Loss: 0.6111, F1 Micro: 0.6927, F1 Macro: 0.6644, Accuracy: 0.6927\n","Epoch 81, Train Loss: 0.6307, Val Loss: 0.6105, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 82, Train Loss: 0.6574, Val Loss: 0.6153, F1 Micro: 0.7095, F1 Macro: 0.6899, Accuracy: 0.7095\n","Epoch 83, Train Loss: 0.6244, Val Loss: 0.6294, F1 Micro: 0.6648, F1 Macro: 0.5785, Accuracy: 0.6648\n","Epoch 84, Train Loss: 0.6330, Val Loss: 0.6180, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 85, Train Loss: 0.6282, Val Loss: 0.6184, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 86, Train Loss: 0.6325, Val Loss: 0.6272, F1 Micro: 0.6816, F1 Macro: 0.6724, Accuracy: 0.6816\n","Epoch 87, Train Loss: 0.6254, Val Loss: 0.6223, F1 Micro: 0.6983, F1 Macro: 0.6739, Accuracy: 0.6983\n","Epoch 88, Train Loss: 0.6372, Val Loss: 0.6155, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 89, Train Loss: 0.6462, Val Loss: 0.6063, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 90, Train Loss: 0.6209, Val Loss: 0.6133, F1 Micro: 0.6648, F1 Macro: 0.5409, Accuracy: 0.6648\n","Epoch 91, Train Loss: 0.6277, Val Loss: 0.6148, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 92, Train Loss: 0.6235, Val Loss: 0.6089, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 93, Train Loss: 0.6385, Val Loss: 0.6485, F1 Micro: 0.6425, F1 Macro: 0.5801, Accuracy: 0.6425\n","Epoch 94, Train Loss: 0.6218, Val Loss: 0.6142, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 95, Train Loss: 0.6395, Val Loss: 0.6061, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 96, Train Loss: 0.6401, Val Loss: 0.6060, F1 Micro: 0.6927, F1 Macro: 0.6373, Accuracy: 0.6927\n","Epoch 97, Train Loss: 0.6236, Val Loss: 0.6258, F1 Micro: 0.6927, F1 Macro: 0.6766, Accuracy: 0.6927\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8779, Val Loss: 0.7484, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 2, Train Loss: 0.7419, Val Loss: 0.7470, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6653, Val Loss: 0.6247, F1 Micro: 0.6629, F1 Macro: 0.6430, Accuracy: 0.6629\n","Epoch 4, Train Loss: 0.6703, Val Loss: 0.6347, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6817, Val Loss: 0.7511, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6807, Val Loss: 0.5883, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 7, Train Loss: 0.6615, Val Loss: 0.6234, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6564, Val Loss: 0.5945, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 9, Train Loss: 0.6691, Val Loss: 0.6495, F1 Micro: 0.6629, F1 Macro: 0.4882, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6390, Val Loss: 0.6088, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.6581, Val Loss: 0.5757, F1 Micro: 0.7247, F1 Macro: 0.6572, Accuracy: 0.7247\n","Epoch 12, Train Loss: 0.6436, Val Loss: 0.5768, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 13, Train Loss: 0.6460, Val Loss: 0.6034, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6234, Val Loss: 0.5751, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 15, Train Loss: 0.6388, Val Loss: 0.6249, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 16, Train Loss: 0.6377, Val Loss: 0.6512, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6456, Val Loss: 0.5690, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Epoch 18, Train Loss: 0.6434, Val Loss: 0.6177, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 19, Train Loss: 0.6341, Val Loss: 0.5907, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 20, Train Loss: 0.6425, Val Loss: 0.5798, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 21, Train Loss: 0.6388, Val Loss: 0.5923, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 22, Train Loss: 0.6395, Val Loss: 0.6114, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6344, Val Loss: 0.5907, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 24, Train Loss: 0.6343, Val Loss: 0.5926, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6305, Val Loss: 0.5976, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.6325, Val Loss: 0.6974, F1 Micro: 0.5449, F1 Macro: 0.5408, Accuracy: 0.5449\n","Epoch 27, Train Loss: 0.6523, Val Loss: 0.6252, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 28, Train Loss: 0.6358, Val Loss: 0.6165, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 29, Train Loss: 0.6313, Val Loss: 0.6220, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6351, Val Loss: 0.5824, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 31, Train Loss: 0.6337, Val Loss: 0.6047, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 32, Train Loss: 0.6370, Val Loss: 0.6028, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 33, Train Loss: 0.6373, Val Loss: 0.6136, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 34, Train Loss: 0.6275, Val Loss: 0.6322, F1 Micro: 0.6404, F1 Macro: 0.4647, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6237, Val Loss: 0.5769, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 36, Train Loss: 0.6405, Val Loss: 0.6111, F1 Micro: 0.6798, F1 Macro: 0.6722, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.6279, Val Loss: 0.5875, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 38, Train Loss: 0.6319, Val Loss: 0.6376, F1 Micro: 0.6180, F1 Macro: 0.6172, Accuracy: 0.6180\n","Epoch 39, Train Loss: 0.6402, Val Loss: 0.6341, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 40, Train Loss: 0.6389, Val Loss: 0.6022, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 41, Train Loss: 0.6229, Val Loss: 0.6061, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 42, Train Loss: 0.6295, Val Loss: 0.6033, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 43, Train Loss: 0.6349, Val Loss: 0.6184, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.6382, Val Loss: 0.6013, F1 Micro: 0.6685, F1 Macro: 0.5111, Accuracy: 0.6685\n","Epoch 45, Train Loss: 0.6236, Val Loss: 0.5826, F1 Micro: 0.7247, F1 Macro: 0.7041, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.6321, Val Loss: 0.5811, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 47, Train Loss: 0.6262, Val Loss: 0.6252, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 48, Train Loss: 0.6270, Val Loss: 0.5825, F1 Micro: 0.7135, F1 Macro: 0.6974, Accuracy: 0.7135\n","Epoch 49, Train Loss: 0.6306, Val Loss: 0.5920, F1 Micro: 0.6966, F1 Macro: 0.6837, Accuracy: 0.6966\n","Epoch 50, Train Loss: 0.6392, Val Loss: 0.5979, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 51, Train Loss: 0.6435, Val Loss: 0.5975, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 52, Train Loss: 0.6336, Val Loss: 0.6035, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 53, Train Loss: 0.6413, Val Loss: 0.6198, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.6253, Val Loss: 0.5895, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 55, Train Loss: 0.6312, Val Loss: 0.5881, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 56, Train Loss: 0.6247, Val Loss: 0.6109, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 57, Train Loss: 0.6269, Val Loss: 0.6156, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 58, Train Loss: 0.6304, Val Loss: 0.6116, F1 Micro: 0.6854, F1 Macro: 0.6720, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.6426, Val Loss: 0.5844, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 60, Train Loss: 0.6291, Val Loss: 0.6035, F1 Micro: 0.6854, F1 Macro: 0.6735, Accuracy: 0.6854\n","Epoch 61, Train Loss: 0.6392, Val Loss: 0.5854, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 62, Train Loss: 0.6391, Val Loss: 0.5886, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 63, Train Loss: 0.6240, Val Loss: 0.6036, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 64, Train Loss: 0.6297, Val Loss: 0.6112, F1 Micro: 0.6742, F1 Macro: 0.6681, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.6458, Val Loss: 0.5908, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 66, Train Loss: 0.6226, Val Loss: 0.6296, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 67, Train Loss: 0.6386, Val Loss: 0.6051, F1 Micro: 0.6685, F1 Macro: 0.6595, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8676, Val Loss: 0.6481, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.7137, Val Loss: 0.6292, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 3, Train Loss: 0.7204, Val Loss: 0.7350, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6942, Val Loss: 0.6546, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6966, Val Loss: 0.5744, F1 Micro: 0.7303, F1 Macro: 0.7110, Accuracy: 0.7303\n","Epoch 6, Train Loss: 0.6600, Val Loss: 0.6431, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.6619, Val Loss: 0.6675, F1 Micro: 0.6348, F1 Macro: 0.5560, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6358, Val Loss: 0.6160, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.6575, Val Loss: 0.6233, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6576, Val Loss: 0.6251, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 11, Train Loss: 0.6671, Val Loss: 0.6229, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.6428, Val Loss: 0.5934, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6354, Val Loss: 0.6268, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6446, Val Loss: 0.5886, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6530, Val Loss: 0.6017, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 16, Train Loss: 0.6297, Val Loss: 0.6038, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 17, Train Loss: 0.6393, Val Loss: 0.6098, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 18, Train Loss: 0.6380, Val Loss: 0.6178, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 19, Train Loss: 0.6436, Val Loss: 0.6136, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 20, Train Loss: 0.6504, Val Loss: 0.5992, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 21, Train Loss: 0.6357, Val Loss: 0.6148, F1 Micro: 0.7360, F1 Macro: 0.6531, Accuracy: 0.7360\n","Epoch 22, Train Loss: 0.6422, Val Loss: 0.6051, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6438, Val Loss: 0.6472, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6367, Val Loss: 0.5993, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6426, Val Loss: 0.6375, F1 Micro: 0.6180, F1 Macro: 0.5432, Accuracy: 0.6180\n","Epoch 26, Train Loss: 0.6417, Val Loss: 0.5815, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 27, Train Loss: 0.6545, Val Loss: 0.6170, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 28, Train Loss: 0.6286, Val Loss: 0.6065, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 29, Train Loss: 0.6328, Val Loss: 0.6369, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6366, Val Loss: 0.6621, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 31, Train Loss: 0.6443, Val Loss: 0.5826, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 32, Train Loss: 0.6483, Val Loss: 0.5956, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.6388, Val Loss: 0.6454, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 34, Train Loss: 0.6466, Val Loss: 0.5964, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 35, Train Loss: 0.6335, Val Loss: 0.6102, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 36, Train Loss: 0.6468, Val Loss: 0.6044, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6354, Val Loss: 0.6026, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 38, Train Loss: 0.6388, Val Loss: 0.6223, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 39, Train Loss: 0.6357, Val Loss: 0.5747, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 40, Train Loss: 0.6371, Val Loss: 0.6154, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 41, Train Loss: 0.6286, Val Loss: 0.5961, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 42, Train Loss: 0.6357, Val Loss: 0.5810, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 43, Train Loss: 0.6302, Val Loss: 0.5748, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 44, Train Loss: 0.6277, Val Loss: 0.5719, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.6305, Val Loss: 0.5899, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 46, Train Loss: 0.6360, Val Loss: 0.6151, F1 Micro: 0.7135, F1 Macro: 0.6180, Accuracy: 0.7135\n","Epoch 47, Train Loss: 0.6316, Val Loss: 0.5816, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 48, Train Loss: 0.6367, Val Loss: 0.6232, F1 Micro: 0.7303, F1 Macro: 0.6320, Accuracy: 0.7303\n","Epoch 49, Train Loss: 0.6439, Val Loss: 0.6022, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 50, Train Loss: 0.6298, Val Loss: 0.6012, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6330, Val Loss: 0.6298, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 52, Train Loss: 0.6486, Val Loss: 0.6111, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 53, Train Loss: 0.6441, Val Loss: 0.6022, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6241, Val Loss: 0.5843, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 55, Train Loss: 0.6303, Val Loss: 0.5981, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 56, Train Loss: 0.6491, Val Loss: 0.6294, F1 Micro: 0.7079, F1 Macro: 0.6014, Accuracy: 0.7079\n","Epoch 57, Train Loss: 0.6400, Val Loss: 0.6062, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 58, Train Loss: 0.6360, Val Loss: 0.6430, F1 Micro: 0.7135, F1 Macro: 0.6121, Accuracy: 0.7135\n","Epoch 59, Train Loss: 0.6285, Val Loss: 0.5815, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 60, Train Loss: 0.6256, Val Loss: 0.6127, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 61, Train Loss: 0.6549, Val Loss: 0.6017, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6291, Val Loss: 0.6124, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 63, Train Loss: 0.6459, Val Loss: 0.5971, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 64, Train Loss: 0.6265, Val Loss: 0.6052, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 65, Train Loss: 0.6290, Val Loss: 0.6116, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 66, Train Loss: 0.6495, Val Loss: 0.5973, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 67, Train Loss: 0.6391, Val Loss: 0.6019, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 68, Train Loss: 0.6317, Val Loss: 0.5886, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 69, Train Loss: 0.6188, Val Loss: 0.5846, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 70, Train Loss: 0.6382, Val Loss: 0.6137, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 71, Train Loss: 0.6501, Val Loss: 0.5867, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 72, Train Loss: 0.6392, Val Loss: 0.6029, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 73, Train Loss: 0.6342, Val Loss: 0.6042, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 74, Train Loss: 0.6314, Val Loss: 0.5960, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.6358, Val Loss: 0.5931, F1 Micro: 0.7416, F1 Macro: 0.6802, Accuracy: 0.7416\n","Epoch 76, Train Loss: 0.6300, Val Loss: 0.5826, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.6302, Val Loss: 0.5777, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 78, Train Loss: 0.6337, Val Loss: 0.6233, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.6381, Val Loss: 0.5890, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 80, Train Loss: 0.6387, Val Loss: 0.5998, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 81, Train Loss: 0.6388, Val Loss: 0.6069, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 82, Train Loss: 0.6330, Val Loss: 0.5845, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 83, Train Loss: 0.6304, Val Loss: 0.6110, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 84, Train Loss: 0.6245, Val Loss: 0.5990, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 85, Train Loss: 0.6414, Val Loss: 0.6075, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 86, Train Loss: 0.6369, Val Loss: 0.6324, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 87, Train Loss: 0.6361, Val Loss: 0.5863, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 88, Train Loss: 0.6310, Val Loss: 0.5852, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 89, Train Loss: 0.6386, Val Loss: 0.6114, F1 Micro: 0.6292, F1 Macro: 0.5465, Accuracy: 0.6292\n","Epoch 90, Train Loss: 0.6334, Val Loss: 0.5787, F1 Micro: 0.7303, F1 Macro: 0.6621, Accuracy: 0.7303\n","Epoch 91, Train Loss: 0.6307, Val Loss: 0.5880, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 92, Train Loss: 0.6296, Val Loss: 0.5744, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 93, Train Loss: 0.6335, Val Loss: 0.6128, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 94, Train Loss: 0.6325, Val Loss: 0.6079, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 95, Train Loss: 0.6479, Val Loss: 0.6070, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 96, Train Loss: 0.6338, Val Loss: 0.5894, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 97, Train Loss: 0.6195, Val Loss: 0.6039, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 98, Train Loss: 0.6392, Val Loss: 0.5991, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 99, Train Loss: 0.6330, Val Loss: 0.5823, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 100, Train Loss: 0.6550, Val Loss: 0.6239, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 101, Train Loss: 0.6370, Val Loss: 0.5883, F1 Micro: 0.7416, F1 Macro: 0.6629, Accuracy: 0.7416\n","Epoch 102, Train Loss: 0.6344, Val Loss: 0.6110, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 103, Train Loss: 0.6300, Val Loss: 0.5711, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 104, Train Loss: 0.6285, Val Loss: 0.5742, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 105, Train Loss: 0.6441, Val Loss: 0.6118, F1 Micro: 0.7303, F1 Macro: 0.6431, Accuracy: 0.7303\n","Epoch 106, Train Loss: 0.6322, Val Loss: 0.5983, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 107, Train Loss: 0.6401, Val Loss: 0.6329, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 108, Train Loss: 0.6277, Val Loss: 0.5992, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 109, Train Loss: 0.6248, Val Loss: 0.6138, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.0072, Val Loss: 0.8044, F1 Micro: 0.4888, F1 Macro: 0.4728, Accuracy: 0.4888\n","Epoch 2, Train Loss: 0.7074, Val Loss: 0.8604, F1 Micro: 0.5955, F1 Macro: 0.5740, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.6243, Val Loss: 0.7712, F1 Micro: 0.5393, F1 Macro: 0.4659, Accuracy: 0.5393\n","Epoch 4, Train Loss: 0.6601, Val Loss: 0.7695, F1 Micro: 0.5787, F1 Macro: 0.5786, Accuracy: 0.5787\n","Epoch 5, Train Loss: 0.6453, Val Loss: 0.8943, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 6, Train Loss: 0.6140, Val Loss: 0.7388, F1 Micro: 0.5112, F1 Macro: 0.5029, Accuracy: 0.5112\n","Epoch 7, Train Loss: 0.6293, Val Loss: 0.7850, F1 Micro: 0.5618, F1 Macro: 0.5209, Accuracy: 0.5618\n","Epoch 8, Train Loss: 0.6383, Val Loss: 0.8655, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 9, Train Loss: 0.6252, Val Loss: 0.7221, F1 Micro: 0.5225, F1 Macro: 0.5095, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6282, Val Loss: 0.8188, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6179, Val Loss: 0.7344, F1 Micro: 0.5955, F1 Macro: 0.5892, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.6086, Val Loss: 0.7223, F1 Micro: 0.5337, F1 Macro: 0.5330, Accuracy: 0.5337\n","Epoch 13, Train Loss: 0.6167, Val Loss: 0.8133, F1 Micro: 0.5674, F1 Macro: 0.5009, Accuracy: 0.5674\n","Epoch 14, Train Loss: 0.6070, Val Loss: 0.7697, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.5991, Val Loss: 0.7676, F1 Micro: 0.5787, F1 Macro: 0.5672, Accuracy: 0.5787\n","Epoch 16, Train Loss: 0.6064, Val Loss: 0.7962, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6063, Val Loss: 0.7498, F1 Micro: 0.6124, F1 Macro: 0.5986, Accuracy: 0.6124\n","Epoch 18, Train Loss: 0.6118, Val Loss: 0.7788, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6096, Val Loss: 0.8464, F1 Micro: 0.5449, F1 Macro: 0.4529, Accuracy: 0.5449\n","Epoch 20, Train Loss: 0.6087, Val Loss: 0.7322, F1 Micro: 0.5955, F1 Macro: 0.5820, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.6034, Val Loss: 0.8230, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 22, Train Loss: 0.6079, Val Loss: 0.8199, F1 Micro: 0.5730, F1 Macro: 0.5261, Accuracy: 0.5730\n","Epoch 23, Train Loss: 0.6148, Val Loss: 0.7663, F1 Micro: 0.6067, F1 Macro: 0.5811, Accuracy: 0.6067\n","Epoch 24, Train Loss: 0.6098, Val Loss: 0.7697, F1 Micro: 0.5562, F1 Macro: 0.5093, Accuracy: 0.5562\n","Epoch 25, Train Loss: 0.6059, Val Loss: 0.8306, F1 Micro: 0.5899, F1 Macro: 0.5430, Accuracy: 0.5899\n","Epoch 26, Train Loss: 0.5966, Val Loss: 0.8166, F1 Micro: 0.5562, F1 Macro: 0.4829, Accuracy: 0.5562\n","Epoch 27, Train Loss: 0.6145, Val Loss: 0.8014, F1 Micro: 0.5506, F1 Macro: 0.4929, Accuracy: 0.5506\n","Epoch 28, Train Loss: 0.6152, Val Loss: 0.7970, F1 Micro: 0.5618, F1 Macro: 0.5209, Accuracy: 0.5618\n","Epoch 29, Train Loss: 0.5984, Val Loss: 0.7830, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6013, Val Loss: 0.8625, F1 Micro: 0.5843, F1 Macro: 0.5225, Accuracy: 0.5843\n","Epoch 31, Train Loss: 0.5994, Val Loss: 0.7510, F1 Micro: 0.5787, F1 Macro: 0.5617, Accuracy: 0.5787\n","Epoch 32, Train Loss: 0.6011, Val Loss: 0.7479, F1 Micro: 0.5899, F1 Macro: 0.5877, Accuracy: 0.5899\n","Epoch 33, Train Loss: 0.5891, Val Loss: 0.8014, F1 Micro: 0.5843, F1 Macro: 0.5517, Accuracy: 0.5843\n","Epoch 34, Train Loss: 0.5904, Val Loss: 0.8144, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 35, Train Loss: 0.6004, Val Loss: 0.8017, F1 Micro: 0.6067, F1 Macro: 0.5635, Accuracy: 0.6067\n","Epoch 36, Train Loss: 0.6027, Val Loss: 0.8053, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 37, Train Loss: 0.6043, Val Loss: 0.7576, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 38, Train Loss: 0.5975, Val Loss: 0.7149, F1 Micro: 0.5506, F1 Macro: 0.5491, Accuracy: 0.5506\n","Epoch 39, Train Loss: 0.5984, Val Loss: 0.8075, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 40, Train Loss: 0.5993, Val Loss: 0.7976, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 41, Train Loss: 0.5992, Val Loss: 0.7510, F1 Micro: 0.5899, F1 Macro: 0.5787, Accuracy: 0.5899\n","Epoch 42, Train Loss: 0.6122, Val Loss: 0.8045, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 43, Train Loss: 0.6108, Val Loss: 0.7510, F1 Micro: 0.6067, F1 Macro: 0.5700, Accuracy: 0.6067\n","Epoch 44, Train Loss: 0.6031, Val Loss: 0.7724, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 45, Train Loss: 0.5963, Val Loss: 0.8026, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 46, Train Loss: 0.5961, Val Loss: 0.7853, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6035, Val Loss: 0.7737, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6043, Val Loss: 0.7379, F1 Micro: 0.5618, F1 Macro: 0.5431, Accuracy: 0.5618\n","Epoch 49, Train Loss: 0.5919, Val Loss: 0.7847, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 50, Train Loss: 0.6201, Val Loss: 0.7311, F1 Micro: 0.5730, F1 Macro: 0.5526, Accuracy: 0.5730\n","Epoch 51, Train Loss: 0.6062, Val Loss: 0.8285, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 52, Train Loss: 0.5812, Val Loss: 0.8489, F1 Micro: 0.5787, F1 Macro: 0.5226, Accuracy: 0.5787\n","Epoch 53, Train Loss: 0.5974, Val Loss: 0.8332, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 54, Train Loss: 0.6003, Val Loss: 0.7843, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.5974, Val Loss: 0.7701, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 56, Train Loss: 0.5998, Val Loss: 0.7681, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Epoch 57, Train Loss: 0.5963, Val Loss: 0.8636, F1 Micro: 0.5393, F1 Macro: 0.4227, Accuracy: 0.5393\n","Epoch 58, Train Loss: 0.6086, Val Loss: 0.7367, F1 Micro: 0.6180, F1 Macro: 0.6035, Accuracy: 0.6180\n","Epoch 59, Train Loss: 0.6000, Val Loss: 0.8277, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 60, Train Loss: 0.6069, Val Loss: 0.8431, F1 Micro: 0.5730, F1 Macro: 0.5261, Accuracy: 0.5730\n","Epoch 61, Train Loss: 0.5948, Val Loss: 0.7772, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 62, Train Loss: 0.5906, Val Loss: 0.7599, F1 Micro: 0.6180, F1 Macro: 0.5997, Accuracy: 0.6180\n","Epoch 63, Train Loss: 0.6043, Val Loss: 0.7585, F1 Micro: 0.5730, F1 Macro: 0.5637, Accuracy: 0.5730\n","Epoch 64, Train Loss: 0.5928, Val Loss: 0.7280, F1 Micro: 0.5787, F1 Macro: 0.5727, Accuracy: 0.5787\n","Epoch 65, Train Loss: 0.6049, Val Loss: 0.7750, F1 Micro: 0.5787, F1 Macro: 0.5377, Accuracy: 0.5787\n","Epoch 66, Train Loss: 0.6106, Val Loss: 0.7421, F1 Micro: 0.5618, F1 Macro: 0.5562, Accuracy: 0.5618\n","Epoch 67, Train Loss: 0.6015, Val Loss: 0.8046, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 68, Train Loss: 0.6130, Val Loss: 0.7337, F1 Micro: 0.5955, F1 Macro: 0.5852, Accuracy: 0.5955\n","Epoch 69, Train Loss: 0.5939, Val Loss: 0.8264, F1 Micro: 0.5787, F1 Macro: 0.5266, Accuracy: 0.5787\n","Epoch 70, Train Loss: 0.5973, Val Loss: 0.8289, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 71, Train Loss: 0.5907, Val Loss: 0.7428, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 72, Train Loss: 0.6001, Val Loss: 0.7707, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 73, Train Loss: 0.6000, Val Loss: 0.7404, F1 Micro: 0.5787, F1 Macro: 0.5617, Accuracy: 0.5787\n","Epoch 74, Train Loss: 0.5956, Val Loss: 0.7639, F1 Micro: 0.5618, F1 Macro: 0.5174, Accuracy: 0.5618\n","Epoch 75, Train Loss: 0.6076, Val Loss: 0.7005, F1 Micro: 0.6067, F1 Macro: 0.6059, Accuracy: 0.6067\n","Epoch 76, Train Loss: 0.6068, Val Loss: 0.7798, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 77, Train Loss: 0.6075, Val Loss: 0.7277, F1 Micro: 0.6011, F1 Macro: 0.5851, Accuracy: 0.6011\n","Epoch 78, Train Loss: 0.6090, Val Loss: 0.8047, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 79, Train Loss: 0.6046, Val Loss: 0.7701, F1 Micro: 0.5730, F1 Macro: 0.5298, Accuracy: 0.5730\n","Epoch 80, Train Loss: 0.5919, Val Loss: 0.8313, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 81, Train Loss: 0.6018, Val Loss: 0.8349, F1 Micro: 0.5562, F1 Macro: 0.4664, Accuracy: 0.5562\n","Epoch 82, Train Loss: 0.6043, Val Loss: 0.7537, F1 Micro: 0.6011, F1 Macro: 0.5655, Accuracy: 0.6011\n","Epoch 83, Train Loss: 0.5965, Val Loss: 0.7798, F1 Micro: 0.5618, F1 Macro: 0.5209, Accuracy: 0.5618\n","Epoch 84, Train Loss: 0.6111, Val Loss: 0.7706, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 85, Train Loss: 0.6066, Val Loss: 0.7517, F1 Micro: 0.5730, F1 Macro: 0.5396, Accuracy: 0.5730\n","Epoch 86, Train Loss: 0.5920, Val Loss: 0.7602, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 87, Train Loss: 0.6069, Val Loss: 0.7402, F1 Micro: 0.5843, F1 Macro: 0.5752, Accuracy: 0.5843\n","Epoch 88, Train Loss: 0.5948, Val Loss: 0.8136, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 89, Train Loss: 0.6187, Val Loss: 0.7227, F1 Micro: 0.5730, F1 Macro: 0.5664, Accuracy: 0.5730\n","Epoch 90, Train Loss: 0.5948, Val Loss: 0.8147, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 91, Train Loss: 0.6161, Val Loss: 0.7782, F1 Micro: 0.5562, F1 Macro: 0.4971, Accuracy: 0.5562\n","Epoch 92, Train Loss: 0.6097, Val Loss: 0.8018, F1 Micro: 0.5843, F1 Macro: 0.5269, Accuracy: 0.5843\n","Epoch 93, Train Loss: 0.5813, Val Loss: 0.7556, F1 Micro: 0.6236, F1 Macro: 0.6118, Accuracy: 0.6236\n","Epoch 94, Train Loss: 0.6037, Val Loss: 0.7359, F1 Micro: 0.5562, F1 Macro: 0.5130, Accuracy: 0.5562\n","Epoch 95, Train Loss: 0.5964, Val Loss: 0.8276, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 96, Train Loss: 0.6048, Val Loss: 0.8398, F1 Micro: 0.5787, F1 Macro: 0.5183, Accuracy: 0.5787\n","Epoch 97, Train Loss: 0.6058, Val Loss: 0.7937, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 98, Train Loss: 0.6082, Val Loss: 0.7865, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 99, Train Loss: 0.6075, Val Loss: 0.7780, F1 Micro: 0.5674, F1 Macro: 0.5055, Accuracy: 0.5674\n","Epoch 100, Train Loss: 0.5850, Val Loss: 0.7377, F1 Micro: 0.5787, F1 Macro: 0.5637, Accuracy: 0.5787\n","Epoch 101, Train Loss: 0.6047, Val Loss: 0.7645, F1 Micro: 0.6011, F1 Macro: 0.5810, Accuracy: 0.6011\n","Epoch 102, Train Loss: 0.5910, Val Loss: 0.7268, F1 Micro: 0.5674, F1 Macro: 0.5587, Accuracy: 0.5674\n","Epoch 103, Train Loss: 0.5994, Val Loss: 0.8368, F1 Micro: 0.5337, F1 Macro: 0.4193, Accuracy: 0.5337\n","Epoch 104, Train Loss: 0.6047, Val Loss: 0.7431, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.0908, Val Loss: 0.7823, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.7439, Val Loss: 0.7040, F1 Micro: 0.6180, F1 Macro: 0.6068, Accuracy: 0.6180\n","Epoch 3, Train Loss: 0.6808, Val Loss: 0.7476, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 4, Train Loss: 0.7074, Val Loss: 0.6796, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6476, Val Loss: 0.8224, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 6, Train Loss: 0.6449, Val Loss: 0.7909, F1 Micro: 0.7022, F1 Macro: 0.6195, Accuracy: 0.7022\n","Epoch 7, Train Loss: 0.6577, Val Loss: 0.7473, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6525, Val Loss: 0.7040, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6524, Val Loss: 0.7573, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6375, Val Loss: 0.8048, F1 Micro: 0.6124, F1 Macro: 0.4979, Accuracy: 0.6124\n","Epoch 11, Train Loss: 0.6284, Val Loss: 0.7068, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 12, Train Loss: 0.6339, Val Loss: 0.7736, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6404, Val Loss: 0.8112, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6287, Val Loss: 0.7102, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 15, Train Loss: 0.6456, Val Loss: 0.7317, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.6268, Val Loss: 0.7209, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.6462, Val Loss: 0.6992, F1 Micro: 0.6124, F1 Macro: 0.6002, Accuracy: 0.6124\n","Epoch 18, Train Loss: 0.6291, Val Loss: 0.6982, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6190, Val Loss: 0.7163, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.6264, Val Loss: 0.7056, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 21, Train Loss: 0.6269, Val Loss: 0.7121, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6288, Val Loss: 0.7371, F1 Micro: 0.6854, F1 Macro: 0.6197, Accuracy: 0.6854\n","Epoch 23, Train Loss: 0.6282, Val Loss: 0.7354, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 24, Train Loss: 0.6225, Val Loss: 0.7887, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 25, Train Loss: 0.6429, Val Loss: 0.7270, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 26, Train Loss: 0.6024, Val Loss: 0.7105, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6581, Val Loss: 0.6985, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.6312, Val Loss: 0.7281, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 29, Train Loss: 0.6336, Val Loss: 0.7237, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.6228, Val Loss: 0.7083, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 31, Train Loss: 0.6318, Val Loss: 0.7270, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 32, Train Loss: 0.6188, Val Loss: 0.7449, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 33, Train Loss: 0.6346, Val Loss: 0.7674, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 34, Train Loss: 0.6251, Val Loss: 0.7350, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 35, Train Loss: 0.6129, Val Loss: 0.7264, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 36, Train Loss: 0.6181, Val Loss: 0.8053, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 37, Train Loss: 0.6311, Val Loss: 0.7827, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 38, Train Loss: 0.6354, Val Loss: 0.7322, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 39, Train Loss: 0.6239, Val Loss: 0.7083, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 40, Train Loss: 0.6175, Val Loss: 0.7104, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 41, Train Loss: 0.6279, Val Loss: 0.7173, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 42, Train Loss: 0.6134, Val Loss: 0.7120, F1 Micro: 0.6067, F1 Macro: 0.5982, Accuracy: 0.6067\n","Epoch 43, Train Loss: 0.6165, Val Loss: 0.7435, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 44, Train Loss: 0.6181, Val Loss: 0.7305, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 45, Train Loss: 0.6202, Val Loss: 0.7304, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.6253, Val Loss: 0.7241, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 47, Train Loss: 0.6203, Val Loss: 0.7012, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 48, Train Loss: 0.6218, Val Loss: 0.7448, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.6146, Val Loss: 0.7460, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 50, Train Loss: 0.6315, Val Loss: 0.7310, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 51, Train Loss: 0.6163, Val Loss: 0.6959, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 52, Train Loss: 0.6074, Val Loss: 0.7279, F1 Micro: 0.6404, F1 Macro: 0.5550, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.6372, Val Loss: 0.7317, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 54, Train Loss: 0.6293, Val Loss: 0.7237, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 55, Train Loss: 0.6232, Val Loss: 0.7044, F1 Micro: 0.6404, F1 Macro: 0.6359, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.6331, Val Loss: 0.7157, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 57, Train Loss: 0.6132, Val Loss: 0.7302, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 58, Train Loss: 0.6104, Val Loss: 0.7345, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 59, Train Loss: 0.6190, Val Loss: 0.7565, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 60, Train Loss: 0.6300, Val Loss: 0.7381, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.6232, Val Loss: 0.7339, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 62, Train Loss: 0.6116, Val Loss: 0.7351, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 63, Train Loss: 0.6263, Val Loss: 0.7457, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 64, Train Loss: 0.6155, Val Loss: 0.7122, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 65, Train Loss: 0.6226, Val Loss: 0.7057, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 66, Train Loss: 0.6263, Val Loss: 0.7510, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 67, Train Loss: 0.6158, Val Loss: 0.7431, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 68, Train Loss: 0.6232, Val Loss: 0.7030, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 69, Train Loss: 0.6261, Val Loss: 0.7234, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 70, Train Loss: 0.6209, Val Loss: 0.7332, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.6228, Val Loss: 0.7061, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 72, Train Loss: 0.6182, Val Loss: 0.7308, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 73, Train Loss: 0.6215, Val Loss: 0.7589, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 74, Train Loss: 0.6316, Val Loss: 0.7197, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 75, Train Loss: 0.6304, Val Loss: 0.7629, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 76, Train Loss: 0.6184, Val Loss: 0.7517, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 77, Train Loss: 0.6302, Val Loss: 0.7143, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 78, Train Loss: 0.6340, Val Loss: 0.7008, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 79, Train Loss: 0.6166, Val Loss: 0.7119, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 80, Train Loss: 0.6123, Val Loss: 0.7195, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 81, Train Loss: 0.6176, Val Loss: 0.7507, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 82, Train Loss: 0.6271, Val Loss: 0.7773, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 83, Train Loss: 0.6290, Val Loss: 0.7326, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 84, Train Loss: 0.6196, Val Loss: 0.7335, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 85, Train Loss: 0.6352, Val Loss: 0.7186, F1 Micro: 0.6966, F1 Macro: 0.6245, Accuracy: 0.6966\n","Epoch 86, Train Loss: 0.6248, Val Loss: 0.7529, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 87, Train Loss: 0.6280, Val Loss: 0.7856, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 88, Train Loss: 0.6182, Val Loss: 0.8004, F1 Micro: 0.6348, F1 Macro: 0.4614, Accuracy: 0.6348\n","Epoch 89, Train Loss: 0.6174, Val Loss: 0.7630, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 90, Train Loss: 0.6226, Val Loss: 0.7073, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.6221, Val Loss: 0.7405, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 92, Train Loss: 0.6280, Val Loss: 0.7108, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 93, Train Loss: 0.6229, Val Loss: 0.7229, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 94, Train Loss: 0.6110, Val Loss: 0.7274, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 95, Train Loss: 0.6408, Val Loss: 0.6958, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.7182913815830771\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6798, Val Loss: 0.6433, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 2, Train Loss: 0.6508, Val Loss: 0.6300, F1 Micro: 0.6592, F1 Macro: 0.5843, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6553, Val Loss: 0.6337, F1 Micro: 0.6704, F1 Macro: 0.5024, Accuracy: 0.6704\n","Epoch 4, Train Loss: 0.6816, Val Loss: 0.6362, F1 Micro: 0.6648, F1 Macro: 0.4989, Accuracy: 0.6648\n","Epoch 5, Train Loss: 0.6512, Val Loss: 0.6956, F1 Micro: 0.6369, F1 Macro: 0.4165, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6389, Val Loss: 0.6176, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 7, Train Loss: 0.6573, Val Loss: 0.6256, F1 Micro: 0.6816, F1 Macro: 0.6611, Accuracy: 0.6816\n","Epoch 8, Train Loss: 0.6565, Val Loss: 0.6135, F1 Micro: 0.6592, F1 Macro: 0.5977, Accuracy: 0.6592\n","Epoch 9, Train Loss: 0.6524, Val Loss: 0.6157, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.6456, Val Loss: 0.6173, F1 Micro: 0.6927, F1 Macro: 0.5888, Accuracy: 0.6927\n","Epoch 11, Train Loss: 0.6418, Val Loss: 0.6064, F1 Micro: 0.6760, F1 Macro: 0.6268, Accuracy: 0.6760\n","Epoch 12, Train Loss: 0.6543, Val Loss: 0.6074, F1 Micro: 0.6648, F1 Macro: 0.6102, Accuracy: 0.6648\n","Epoch 13, Train Loss: 0.6597, Val Loss: 0.6221, F1 Micro: 0.6648, F1 Macro: 0.6139, Accuracy: 0.6648\n","Epoch 14, Train Loss: 0.6647, Val Loss: 0.6255, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 15, Train Loss: 0.6490, Val Loss: 0.6164, F1 Micro: 0.6872, F1 Macro: 0.6326, Accuracy: 0.6872\n","Epoch 16, Train Loss: 0.6624, Val Loss: 0.6239, F1 Micro: 0.6480, F1 Macro: 0.6128, Accuracy: 0.6480\n","Epoch 17, Train Loss: 0.6426, Val Loss: 0.6030, F1 Micro: 0.6648, F1 Macro: 0.5611, Accuracy: 0.6648\n","Epoch 18, Train Loss: 0.6352, Val Loss: 0.6067, F1 Micro: 0.6536, F1 Macro: 0.5465, Accuracy: 0.6536\n","Epoch 19, Train Loss: 0.6433, Val Loss: 0.6781, F1 Micro: 0.6201, F1 Macro: 0.6113, Accuracy: 0.6201\n","Epoch 20, Train Loss: 0.6642, Val Loss: 0.6566, F1 Micro: 0.6369, F1 Macro: 0.6313, Accuracy: 0.6369\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7082, Val Loss: 0.6477, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.6695, Val Loss: 0.6334, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 3, Train Loss: 0.6560, Val Loss: 0.6321, F1 Micro: 0.7079, F1 Macro: 0.6384, Accuracy: 0.7079\n","Epoch 4, Train Loss: 0.6395, Val Loss: 0.6332, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 5, Train Loss: 0.6552, Val Loss: 0.6358, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 6, Train Loss: 0.6338, Val Loss: 0.6220, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.6457, Val Loss: 0.6379, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 8, Train Loss: 0.6491, Val Loss: 0.6015, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.6470, Val Loss: 0.6345, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 10, Train Loss: 0.6533, Val Loss: 0.6360, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 11, Train Loss: 0.6599, Val Loss: 0.6239, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6434, Val Loss: 0.6004, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 13, Train Loss: 0.6587, Val Loss: 0.6620, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6766, Val Loss: 0.6389, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 2, Train Loss: 0.6734, Val Loss: 0.6048, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 3, Train Loss: 0.6603, Val Loss: 0.6175, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 4, Train Loss: 0.6707, Val Loss: 0.6385, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 5, Train Loss: 0.6627, Val Loss: 0.5946, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 6, Train Loss: 0.6748, Val Loss: 0.5849, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.6516, Val Loss: 0.6031, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 8, Train Loss: 0.6411, Val Loss: 0.6602, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6371, Val Loss: 0.6092, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 10, Train Loss: 0.6565, Val Loss: 0.6115, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 11, Train Loss: 0.6413, Val Loss: 0.5830, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 12, Train Loss: 0.6528, Val Loss: 0.6247, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6540, Val Loss: 0.6196, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6457, Val Loss: 0.5926, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6559, Val Loss: 0.6025, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6614, Val Loss: 0.7549, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 2, Train Loss: 0.6331, Val Loss: 0.8324, F1 Micro: 0.5787, F1 Macro: 0.4753, Accuracy: 0.5787\n","Epoch 3, Train Loss: 0.6352, Val Loss: 0.7238, F1 Micro: 0.5843, F1 Macro: 0.5545, Accuracy: 0.5843\n","Epoch 4, Train Loss: 0.6208, Val Loss: 0.7645, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6290, Val Loss: 0.7326, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 6, Train Loss: 0.6205, Val Loss: 0.8172, F1 Micro: 0.5506, F1 Macro: 0.4683, Accuracy: 0.5506\n","Epoch 7, Train Loss: 0.6233, Val Loss: 0.7147, F1 Micro: 0.6236, F1 Macro: 0.6172, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6263, Val Loss: 0.8066, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6653, Val Loss: 0.7399, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 10, Train Loss: 0.6105, Val Loss: 0.7923, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6295, Val Loss: 0.7048, F1 Micro: 0.6011, F1 Macro: 0.5931, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6198, Val Loss: 0.7119, F1 Micro: 0.5449, F1 Macro: 0.5342, Accuracy: 0.5449\n","Epoch 13, Train Loss: 0.6088, Val Loss: 0.8794, F1 Micro: 0.5506, F1 Macro: 0.4567, Accuracy: 0.5506\n","Epoch 14, Train Loss: 0.6199, Val Loss: 0.9146, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 15, Train Loss: 0.6252, Val Loss: 0.7235, F1 Micro: 0.5562, F1 Macro: 0.5558, Accuracy: 0.5562\n","Epoch 16, Train Loss: 0.6163, Val Loss: 0.8176, F1 Micro: 0.5618, F1 Macro: 0.4967, Accuracy: 0.5618\n","Epoch 17, Train Loss: 0.6151, Val Loss: 0.7933, F1 Micro: 0.5506, F1 Macro: 0.4504, Accuracy: 0.5506\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6739, Val Loss: 0.6724, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 2, Train Loss: 0.6732, Val Loss: 0.7302, F1 Micro: 0.6461, F1 Macro: 0.4966, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6594, Val Loss: 0.7236, F1 Micro: 0.6404, F1 Macro: 0.4841, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6466, Val Loss: 0.6991, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6439, Val Loss: 0.6501, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 6, Train Loss: 0.6439, Val Loss: 0.6910, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.6506, Val Loss: 0.6568, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6698, Val Loss: 0.6716, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 9, Train Loss: 0.6586, Val Loss: 0.6662, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 10, Train Loss: 0.6424, Val Loss: 0.6882, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 11, Train Loss: 0.6256, Val Loss: 0.7009, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.6980980478312725\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6975, Val Loss: 0.6630, F1 Micro: 0.6648, F1 Macro: 0.6063, Accuracy: 0.6648\n","Epoch 2, Train Loss: 0.6659, Val Loss: 0.6438, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 3, Train Loss: 0.6611, Val Loss: 0.6465, F1 Micro: 0.6480, F1 Macro: 0.4687, Accuracy: 0.6480\n","Epoch 4, Train Loss: 0.6534, Val Loss: 0.6489, F1 Micro: 0.6872, F1 Macro: 0.5715, Accuracy: 0.6872\n","Epoch 5, Train Loss: 0.6724, Val Loss: 0.6435, F1 Micro: 0.6704, F1 Macro: 0.6317, Accuracy: 0.6704\n","Epoch 6, Train Loss: 0.6467, Val Loss: 0.6802, F1 Micro: 0.6704, F1 Macro: 0.5293, Accuracy: 0.6704\n","Epoch 7, Train Loss: 0.6437, Val Loss: 0.6235, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 8, Train Loss: 0.6617, Val Loss: 0.6325, F1 Micro: 0.6704, F1 Macro: 0.5881, Accuracy: 0.6704\n","Epoch 9, Train Loss: 0.6436, Val Loss: 0.6619, F1 Micro: 0.6760, F1 Macro: 0.5413, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.6646, Val Loss: 0.6198, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 11, Train Loss: 0.6523, Val Loss: 0.6349, F1 Micro: 0.6536, F1 Macro: 0.6203, Accuracy: 0.6536\n","Epoch 12, Train Loss: 0.6685, Val Loss: 0.6221, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 13, Train Loss: 0.6509, Val Loss: 0.6456, F1 Micro: 0.6704, F1 Macro: 0.6548, Accuracy: 0.6704\n","Epoch 14, Train Loss: 0.6558, Val Loss: 0.6320, F1 Micro: 0.6872, F1 Macro: 0.6680, Accuracy: 0.6872\n","Epoch 15, Train Loss: 0.6288, Val Loss: 0.6396, F1 Micro: 0.6704, F1 Macro: 0.5653, Accuracy: 0.6704\n","Epoch 16, Train Loss: 0.6475, Val Loss: 0.6238, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.6285, Val Loss: 0.6221, F1 Micro: 0.6983, F1 Macro: 0.6643, Accuracy: 0.6983\n","Epoch 18, Train Loss: 0.6387, Val Loss: 0.6293, F1 Micro: 0.6816, F1 Macro: 0.5738, Accuracy: 0.6816\n","Epoch 19, Train Loss: 0.6669, Val Loss: 0.6243, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 20, Train Loss: 0.6391, Val Loss: 0.7323, F1 Micro: 0.5363, F1 Macro: 0.5326, Accuracy: 0.5363\n","Epoch 21, Train Loss: 0.6441, Val Loss: 0.6160, F1 Micro: 0.6648, F1 Macro: 0.5409, Accuracy: 0.6648\n","Epoch 22, Train Loss: 0.6327, Val Loss: 0.6245, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 23, Train Loss: 0.6633, Val Loss: 0.6285, F1 Micro: 0.6536, F1 Macro: 0.5399, Accuracy: 0.6536\n","Epoch 24, Train Loss: 0.6341, Val Loss: 0.6391, F1 Micro: 0.6760, F1 Macro: 0.5630, Accuracy: 0.6760\n","Epoch 25, Train Loss: 0.6468, Val Loss: 0.6204, F1 Micro: 0.6592, F1 Macro: 0.6093, Accuracy: 0.6592\n","Epoch 26, Train Loss: 0.6459, Val Loss: 0.6110, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 27, Train Loss: 0.6408, Val Loss: 0.6293, F1 Micro: 0.6592, F1 Macro: 0.6251, Accuracy: 0.6592\n","Epoch 28, Train Loss: 0.6613, Val Loss: 0.6129, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 29, Train Loss: 0.6531, Val Loss: 0.6341, F1 Micro: 0.6648, F1 Macro: 0.6462, Accuracy: 0.6648\n","Epoch 30, Train Loss: 0.6375, Val Loss: 0.6181, F1 Micro: 0.6648, F1 Macro: 0.5887, Accuracy: 0.6648\n","Epoch 31, Train Loss: 0.6273, Val Loss: 0.6176, F1 Micro: 0.6760, F1 Macro: 0.5816, Accuracy: 0.6760\n","Epoch 32, Train Loss: 0.6523, Val Loss: 0.6062, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 33, Train Loss: 0.6298, Val Loss: 0.6777, F1 Micro: 0.6480, F1 Macro: 0.6254, Accuracy: 0.6480\n","Epoch 34, Train Loss: 0.6587, Val Loss: 0.6130, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 35, Train Loss: 0.6368, Val Loss: 0.6304, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 36, Train Loss: 0.6463, Val Loss: 0.6235, F1 Micro: 0.6536, F1 Macro: 0.6114, Accuracy: 0.6536\n","Epoch 37, Train Loss: 0.6364, Val Loss: 0.6174, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 38, Train Loss: 0.6416, Val Loss: 0.6169, F1 Micro: 0.6872, F1 Macro: 0.6571, Accuracy: 0.6872\n","Epoch 39, Train Loss: 0.6276, Val Loss: 0.6396, F1 Micro: 0.6816, F1 Macro: 0.6241, Accuracy: 0.6816\n","Epoch 40, Train Loss: 0.6249, Val Loss: 0.6143, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 41, Train Loss: 0.6220, Val Loss: 0.6123, F1 Micro: 0.6704, F1 Macro: 0.5979, Accuracy: 0.6704\n","Epoch 42, Train Loss: 0.6298, Val Loss: 0.6193, F1 Micro: 0.6704, F1 Macro: 0.5653, Accuracy: 0.6704\n","Epoch 43, Train Loss: 0.6423, Val Loss: 0.6199, F1 Micro: 0.6536, F1 Macro: 0.5750, Accuracy: 0.6536\n","Epoch 44, Train Loss: 0.6194, Val Loss: 0.6224, F1 Micro: 0.6704, F1 Macro: 0.6185, Accuracy: 0.6704\n","Epoch 45, Train Loss: 0.6508, Val Loss: 0.6202, F1 Micro: 0.6760, F1 Macro: 0.6268, Accuracy: 0.6760\n","Epoch 46, Train Loss: 0.6330, Val Loss: 0.6100, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 47, Train Loss: 0.6357, Val Loss: 0.6078, F1 Micro: 0.6872, F1 Macro: 0.6362, Accuracy: 0.6872\n","Epoch 48, Train Loss: 0.6374, Val Loss: 0.6452, F1 Micro: 0.7263, F1 Macro: 0.7087, Accuracy: 0.7263\n","Epoch 49, Train Loss: 0.6528, Val Loss: 0.6248, F1 Micro: 0.6425, F1 Macro: 0.4849, Accuracy: 0.6425\n","Epoch 50, Train Loss: 0.6208, Val Loss: 0.6075, F1 Micro: 0.6927, F1 Macro: 0.6373, Accuracy: 0.6927\n","Epoch 51, Train Loss: 0.6494, Val Loss: 0.6360, F1 Micro: 0.6592, F1 Macro: 0.6351, Accuracy: 0.6592\n","Epoch 52, Train Loss: 0.6475, Val Loss: 0.6066, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 53, Train Loss: 0.6442, Val Loss: 0.6152, F1 Micro: 0.6648, F1 Macro: 0.6022, Accuracy: 0.6648\n","Epoch 54, Train Loss: 0.6258, Val Loss: 0.6138, F1 Micro: 0.6760, F1 Macro: 0.6268, Accuracy: 0.6760\n","Epoch 55, Train Loss: 0.6386, Val Loss: 0.6387, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 56, Train Loss: 0.6356, Val Loss: 0.6387, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 57, Train Loss: 0.6331, Val Loss: 0.6096, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 58, Train Loss: 0.6361, Val Loss: 0.6209, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 59, Train Loss: 0.6365, Val Loss: 0.6181, F1 Micro: 0.6592, F1 Macro: 0.5687, Accuracy: 0.6592\n","Epoch 60, Train Loss: 0.6329, Val Loss: 0.6057, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 61, Train Loss: 0.6344, Val Loss: 0.6083, F1 Micro: 0.6927, F1 Macro: 0.6594, Accuracy: 0.6927\n","Epoch 62, Train Loss: 0.6460, Val Loss: 0.6275, F1 Micro: 0.6480, F1 Macro: 0.5546, Accuracy: 0.6480\n","Epoch 63, Train Loss: 0.6245, Val Loss: 0.6312, F1 Micro: 0.6927, F1 Macro: 0.6798, Accuracy: 0.6927\n","Epoch 64, Train Loss: 0.6429, Val Loss: 0.6153, F1 Micro: 0.6536, F1 Macro: 0.5890, Accuracy: 0.6536\n","Epoch 65, Train Loss: 0.6348, Val Loss: 0.6153, F1 Micro: 0.6983, F1 Macro: 0.6760, Accuracy: 0.6983\n","Epoch 66, Train Loss: 0.6230, Val Loss: 0.6083, F1 Micro: 0.6648, F1 Macro: 0.5979, Accuracy: 0.6648\n","Epoch 67, Train Loss: 0.6324, Val Loss: 0.6328, F1 Micro: 0.6425, F1 Macro: 0.4317, Accuracy: 0.6425\n","Epoch 68, Train Loss: 0.6295, Val Loss: 0.6062, F1 Micro: 0.6704, F1 Macro: 0.5293, Accuracy: 0.6704\n","Epoch 69, Train Loss: 0.6332, Val Loss: 0.6069, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 70, Train Loss: 0.6337, Val Loss: 0.6003, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 71, Train Loss: 0.6309, Val Loss: 0.6156, F1 Micro: 0.6760, F1 Macro: 0.6232, Accuracy: 0.6760\n","Epoch 72, Train Loss: 0.6306, Val Loss: 0.6102, F1 Micro: 0.6927, F1 Macro: 0.6620, Accuracy: 0.6927\n","Epoch 73, Train Loss: 0.6321, Val Loss: 0.6016, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 74, Train Loss: 0.6401, Val Loss: 0.6277, F1 Micro: 0.7151, F1 Macro: 0.7001, Accuracy: 0.7151\n","Epoch 75, Train Loss: 0.6246, Val Loss: 0.6191, F1 Micro: 0.6983, F1 Macro: 0.6760, Accuracy: 0.6983\n","Epoch 76, Train Loss: 0.6277, Val Loss: 0.5980, F1 Micro: 0.6648, F1 Macro: 0.5730, Accuracy: 0.6648\n","Epoch 77, Train Loss: 0.6340, Val Loss: 0.5978, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 78, Train Loss: 0.6248, Val Loss: 0.6093, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 79, Train Loss: 0.6489, Val Loss: 0.6186, F1 Micro: 0.7151, F1 Macro: 0.7001, Accuracy: 0.7151\n","Epoch 80, Train Loss: 0.6285, Val Loss: 0.6049, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 81, Train Loss: 0.6230, Val Loss: 0.6427, F1 Micro: 0.6592, F1 Macro: 0.6431, Accuracy: 0.6592\n","Epoch 82, Train Loss: 0.6230, Val Loss: 0.6087, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 83, Train Loss: 0.6193, Val Loss: 0.6052, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 84, Train Loss: 0.6172, Val Loss: 0.6192, F1 Micro: 0.6704, F1 Macro: 0.6109, Accuracy: 0.6704\n","Epoch 85, Train Loss: 0.6251, Val Loss: 0.6057, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 86, Train Loss: 0.6323, Val Loss: 0.6444, F1 Micro: 0.6704, F1 Macro: 0.6565, Accuracy: 0.6704\n","Epoch 87, Train Loss: 0.6260, Val Loss: 0.6064, F1 Micro: 0.6816, F1 Macro: 0.6115, Accuracy: 0.6816\n","Epoch 88, Train Loss: 0.6165, Val Loss: 0.6270, F1 Micro: 0.6760, F1 Macro: 0.6232, Accuracy: 0.6760\n","Epoch 89, Train Loss: 0.6209, Val Loss: 0.6042, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 90, Train Loss: 0.6243, Val Loss: 0.6161, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 91, Train Loss: 0.6264, Val Loss: 0.6022, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 92, Train Loss: 0.6199, Val Loss: 0.6078, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 93, Train Loss: 0.6267, Val Loss: 0.6066, F1 Micro: 0.6816, F1 Macro: 0.5970, Accuracy: 0.6816\n","Epoch 94, Train Loss: 0.6223, Val Loss: 0.6464, F1 Micro: 0.6760, F1 Macro: 0.6580, Accuracy: 0.6760\n","Epoch 95, Train Loss: 0.6303, Val Loss: 0.6024, F1 Micro: 0.6816, F1 Macro: 0.6382, Accuracy: 0.6816\n","Epoch 96, Train Loss: 0.6280, Val Loss: 0.6223, F1 Micro: 0.6648, F1 Macro: 0.5785, Accuracy: 0.6648\n","Epoch 97, Train Loss: 0.6256, Val Loss: 0.6225, F1 Micro: 0.6648, F1 Macro: 0.6174, Accuracy: 0.6648\n","Epoch 98, Train Loss: 0.6242, Val Loss: 0.6169, F1 Micro: 0.6760, F1 Macro: 0.6520, Accuracy: 0.6760\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6866, Val Loss: 0.6116, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6635, Val Loss: 0.7424, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 3, Train Loss: 0.6584, Val Loss: 0.6413, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 4, Train Loss: 0.6421, Val Loss: 0.6726, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6553, Val Loss: 0.6727, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 6, Train Loss: 0.6602, Val Loss: 0.6335, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.6471, Val Loss: 0.6206, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 8, Train Loss: 0.6559, Val Loss: 0.6805, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6706, Val Loss: 0.6540, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 10, Train Loss: 0.6440, Val Loss: 0.6051, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 11, Train Loss: 0.6595, Val Loss: 0.6174, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6649, Val Loss: 0.6461, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 13, Train Loss: 0.6484, Val Loss: 0.6532, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6448, Val Loss: 0.6132, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6365, Val Loss: 0.6223, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.6433, Val Loss: 0.5847, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 17, Train Loss: 0.6353, Val Loss: 0.6103, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 18, Train Loss: 0.6358, Val Loss: 0.6251, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 19, Train Loss: 0.6609, Val Loss: 0.5874, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 20, Train Loss: 0.6322, Val Loss: 0.6530, F1 Micro: 0.6798, F1 Macro: 0.6698, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6435, Val Loss: 0.6160, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 22, Train Loss: 0.6490, Val Loss: 0.6133, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 23, Train Loss: 0.6372, Val Loss: 0.6035, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 24, Train Loss: 0.6273, Val Loss: 0.6103, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 25, Train Loss: 0.6391, Val Loss: 0.6271, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 26, Train Loss: 0.6379, Val Loss: 0.6731, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 27, Train Loss: 0.6465, Val Loss: 0.6330, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.6416, Val Loss: 0.5909, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6236, Val Loss: 0.6606, F1 Micro: 0.6292, F1 Macro: 0.5019, Accuracy: 0.6292\n","Epoch 30, Train Loss: 0.6423, Val Loss: 0.6197, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 31, Train Loss: 0.6382, Val Loss: 0.6115, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 32, Train Loss: 0.6579, Val Loss: 0.6367, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 33, Train Loss: 0.6579, Val Loss: 0.6193, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6601, Val Loss: 0.6692, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 35, Train Loss: 0.6309, Val Loss: 0.7431, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6453, Val Loss: 0.6540, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 37, Train Loss: 0.6455, Val Loss: 0.6336, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.6311, Val Loss: 0.6117, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6291, Val Loss: 0.5957, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 40, Train Loss: 0.6281, Val Loss: 0.6597, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 41, Train Loss: 0.6416, Val Loss: 0.6080, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 42, Train Loss: 0.6242, Val Loss: 0.6891, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 43, Train Loss: 0.6480, Val Loss: 0.6170, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 44, Train Loss: 0.6560, Val Loss: 0.5890, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 45, Train Loss: 0.6455, Val Loss: 0.6895, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6325, Val Loss: 0.6313, F1 Micro: 0.6348, F1 Macro: 0.4977, Accuracy: 0.6348\n","Epoch 47, Train Loss: 0.6265, Val Loss: 0.6117, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.6419, Val Loss: 0.5844, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.6236, Val Loss: 0.6544, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 50, Train Loss: 0.6349, Val Loss: 0.6085, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 51, Train Loss: 0.6483, Val Loss: 0.6108, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 52, Train Loss: 0.6315, Val Loss: 0.6264, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 53, Train Loss: 0.6271, Val Loss: 0.5887, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 54, Train Loss: 0.6289, Val Loss: 0.6079, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 55, Train Loss: 0.6320, Val Loss: 0.6577, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 56, Train Loss: 0.6363, Val Loss: 0.6420, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 57, Train Loss: 0.6294, Val Loss: 0.6099, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.6192, Val Loss: 0.6414, F1 Micro: 0.6461, F1 Macro: 0.5835, Accuracy: 0.6461\n","Epoch 59, Train Loss: 0.6518, Val Loss: 0.6302, F1 Micro: 0.6629, F1 Macro: 0.6577, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.6313, Val Loss: 0.6499, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 61, Train Loss: 0.6352, Val Loss: 0.6361, F1 Micro: 0.6966, F1 Macro: 0.6805, Accuracy: 0.6966\n","Epoch 62, Train Loss: 0.6206, Val Loss: 0.6648, F1 Micro: 0.6629, F1 Macro: 0.6517, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.6345, Val Loss: 0.6648, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 64, Train Loss: 0.6300, Val Loss: 0.6329, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 65, Train Loss: 0.6306, Val Loss: 0.6627, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 66, Train Loss: 0.6329, Val Loss: 0.5832, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6904, Val Loss: 0.6323, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 2, Train Loss: 0.6713, Val Loss: 0.6874, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6617, Val Loss: 0.6456, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6701, Val Loss: 0.6297, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6648, Val Loss: 0.6515, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6545, Val Loss: 0.6116, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 7, Train Loss: 0.6610, Val Loss: 0.5996, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6519, Val Loss: 0.6184, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 9, Train Loss: 0.6432, Val Loss: 0.5890, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 10, Train Loss: 0.6510, Val Loss: 0.6470, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6511, Val Loss: 0.6262, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.6557, Val Loss: 0.6020, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 13, Train Loss: 0.6446, Val Loss: 0.5925, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 14, Train Loss: 0.6327, Val Loss: 0.6721, F1 Micro: 0.6461, F1 Macro: 0.4780, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6355, Val Loss: 0.6928, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6631, Val Loss: 0.6172, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 17, Train Loss: 0.6263, Val Loss: 0.7095, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 18, Train Loss: 0.6452, Val Loss: 0.5923, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 19, Train Loss: 0.6485, Val Loss: 0.6124, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.6503, Val Loss: 0.6414, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.6586, Val Loss: 0.6178, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 22, Train Loss: 0.6620, Val Loss: 0.5803, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 23, Train Loss: 0.6342, Val Loss: 0.6487, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 24, Train Loss: 0.6467, Val Loss: 0.6069, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 25, Train Loss: 0.6395, Val Loss: 0.5993, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 26, Train Loss: 0.6634, Val Loss: 0.5854, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 27, Train Loss: 0.6421, Val Loss: 0.6026, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 28, Train Loss: 0.6256, Val Loss: 0.5823, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6462, Val Loss: 0.6065, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6575, Val Loss: 0.7021, F1 Micro: 0.7135, F1 Macro: 0.6121, Accuracy: 0.7135\n","Epoch 31, Train Loss: 0.6586, Val Loss: 0.6438, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 32, Train Loss: 0.6430, Val Loss: 0.5886, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 33, Train Loss: 0.6423, Val Loss: 0.5989, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 34, Train Loss: 0.6348, Val Loss: 0.5955, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6518, Val Loss: 0.5920, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.6315, Val Loss: 0.5925, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 37, Train Loss: 0.6338, Val Loss: 0.6028, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 38, Train Loss: 0.6554, Val Loss: 0.6160, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 39, Train Loss: 0.6350, Val Loss: 0.5867, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 40, Train Loss: 0.6554, Val Loss: 0.6400, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 41, Train Loss: 0.6475, Val Loss: 0.5938, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 42, Train Loss: 0.6534, Val Loss: 0.5860, F1 Micro: 0.6461, F1 Macro: 0.5697, Accuracy: 0.6461\n","Epoch 43, Train Loss: 0.6410, Val Loss: 0.6439, F1 Micro: 0.5955, F1 Macro: 0.5867, Accuracy: 0.5955\n","Epoch 44, Train Loss: 0.6269, Val Loss: 0.5994, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 45, Train Loss: 0.6536, Val Loss: 0.6087, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.6481, Val Loss: 0.5894, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 47, Train Loss: 0.6473, Val Loss: 0.5864, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 48, Train Loss: 0.6299, Val Loss: 0.6002, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.6295, Val Loss: 0.5957, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 50, Train Loss: 0.6419, Val Loss: 0.6237, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6503, Val Loss: 0.6035, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 52, Train Loss: 0.6473, Val Loss: 0.5922, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 53, Train Loss: 0.6356, Val Loss: 0.6004, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 54, Train Loss: 0.6423, Val Loss: 0.6033, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 55, Train Loss: 0.6360, Val Loss: 0.5831, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 56, Train Loss: 0.6297, Val Loss: 0.5924, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 57, Train Loss: 0.6333, Val Loss: 0.6116, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 58, Train Loss: 0.6423, Val Loss: 0.5855, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 59, Train Loss: 0.6254, Val Loss: 0.5851, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6566, Val Loss: 0.7425, F1 Micro: 0.5843, F1 Macro: 0.5545, Accuracy: 0.5843\n","Epoch 2, Train Loss: 0.6408, Val Loss: 0.7478, F1 Micro: 0.5393, F1 Macro: 0.4431, Accuracy: 0.5393\n","Epoch 3, Train Loss: 0.6284, Val Loss: 0.7956, F1 Micro: 0.5449, F1 Macro: 0.4749, Accuracy: 0.5449\n","Epoch 4, Train Loss: 0.6235, Val Loss: 0.7518, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.6235, Val Loss: 0.8253, F1 Micro: 0.5449, F1 Macro: 0.4261, Accuracy: 0.5449\n","Epoch 6, Train Loss: 0.6217, Val Loss: 0.7354, F1 Micro: 0.5899, F1 Macro: 0.5619, Accuracy: 0.5899\n","Epoch 7, Train Loss: 0.6035, Val Loss: 0.7943, F1 Micro: 0.5337, F1 Macro: 0.4394, Accuracy: 0.5337\n","Epoch 8, Train Loss: 0.6244, Val Loss: 0.7422, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 9, Train Loss: 0.6224, Val Loss: 0.8566, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 10, Train Loss: 0.6189, Val Loss: 0.8594, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 11, Train Loss: 0.5996, Val Loss: 0.7445, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6087, Val Loss: 0.8075, F1 Micro: 0.5506, F1 Macro: 0.4626, Accuracy: 0.5506\n","Epoch 13, Train Loss: 0.6055, Val Loss: 0.7705, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6229, Val Loss: 0.7899, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 15, Train Loss: 0.6118, Val Loss: 0.7334, F1 Micro: 0.5674, F1 Macro: 0.5456, Accuracy: 0.5674\n","Epoch 16, Train Loss: 0.6294, Val Loss: 0.7233, F1 Micro: 0.5618, F1 Macro: 0.5598, Accuracy: 0.5618\n","Epoch 17, Train Loss: 0.6176, Val Loss: 0.7279, F1 Micro: 0.5899, F1 Macro: 0.5619, Accuracy: 0.5899\n","Epoch 18, Train Loss: 0.6128, Val Loss: 0.7175, F1 Micro: 0.5562, F1 Macro: 0.5441, Accuracy: 0.5562\n","Epoch 19, Train Loss: 0.6193, Val Loss: 0.7043, F1 Micro: 0.5730, F1 Macro: 0.5548, Accuracy: 0.5730\n","Epoch 20, Train Loss: 0.6117, Val Loss: 0.7509, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 21, Train Loss: 0.5983, Val Loss: 0.7806, F1 Micro: 0.5562, F1 Macro: 0.5055, Accuracy: 0.5562\n","Epoch 22, Train Loss: 0.6065, Val Loss: 0.6976, F1 Micro: 0.5899, F1 Macro: 0.5883, Accuracy: 0.5899\n","Epoch 23, Train Loss: 0.6104, Val Loss: 0.7194, F1 Micro: 0.5674, F1 Macro: 0.5456, Accuracy: 0.5674\n","Epoch 24, Train Loss: 0.6058, Val Loss: 0.9195, F1 Micro: 0.5506, F1 Macro: 0.4567, Accuracy: 0.5506\n","Epoch 25, Train Loss: 0.6263, Val Loss: 0.7666, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.5993, Val Loss: 0.7634, F1 Micro: 0.5618, F1 Macro: 0.5209, Accuracy: 0.5618\n","Epoch 27, Train Loss: 0.6111, Val Loss: 0.8213, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.5935, Val Loss: 0.7688, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.5977, Val Loss: 0.7300, F1 Micro: 0.5955, F1 Macro: 0.5837, Accuracy: 0.5955\n","Epoch 30, Train Loss: 0.6058, Val Loss: 0.7522, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6148, Val Loss: 0.7881, F1 Micro: 0.5843, F1 Macro: 0.5225, Accuracy: 0.5843\n","Epoch 32, Train Loss: 0.6019, Val Loss: 0.8136, F1 Micro: 0.5618, F1 Macro: 0.5013, Accuracy: 0.5618\n","Epoch 33, Train Loss: 0.6011, Val Loss: 0.7356, F1 Micro: 0.5899, F1 Macro: 0.5714, Accuracy: 0.5899\n","Epoch 34, Train Loss: 0.6135, Val Loss: 0.7811, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6144, Val Loss: 0.7141, F1 Micro: 0.6067, F1 Macro: 0.5968, Accuracy: 0.6067\n","Epoch 36, Train Loss: 0.6086, Val Loss: 0.7444, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6103, Val Loss: 0.7475, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 38, Train Loss: 0.5978, Val Loss: 0.7486, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 39, Train Loss: 0.5931, Val Loss: 0.7180, F1 Micro: 0.5843, F1 Macro: 0.5622, Accuracy: 0.5843\n","Epoch 40, Train Loss: 0.6111, Val Loss: 0.7903, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 41, Train Loss: 0.6140, Val Loss: 0.8522, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 42, Train Loss: 0.6168, Val Loss: 0.7471, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 43, Train Loss: 0.5925, Val Loss: 0.7642, F1 Micro: 0.5843, F1 Macro: 0.5572, Accuracy: 0.5843\n","Epoch 44, Train Loss: 0.6137, Val Loss: 0.7703, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 45, Train Loss: 0.5966, Val Loss: 0.8536, F1 Micro: 0.5449, F1 Macro: 0.4402, Accuracy: 0.5449\n","Epoch 46, Train Loss: 0.6036, Val Loss: 0.7022, F1 Micro: 0.5169, F1 Macro: 0.5168, Accuracy: 0.5169\n","Epoch 47, Train Loss: 0.6190, Val Loss: 0.7476, F1 Micro: 0.6124, F1 Macro: 0.5859, Accuracy: 0.6124\n","Epoch 48, Train Loss: 0.5995, Val Loss: 0.7739, F1 Micro: 0.5562, F1 Macro: 0.5165, Accuracy: 0.5562\n","Epoch 49, Train Loss: 0.6166, Val Loss: 0.7861, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 50, Train Loss: 0.5938, Val Loss: 0.7560, F1 Micro: 0.5843, F1 Macro: 0.5598, Accuracy: 0.5843\n","Epoch 51, Train Loss: 0.6026, Val Loss: 0.7242, F1 Micro: 0.6124, F1 Macro: 0.6032, Accuracy: 0.6124\n","Epoch 52, Train Loss: 0.5889, Val Loss: 0.7164, F1 Micro: 0.5955, F1 Macro: 0.5837, Accuracy: 0.5955\n","Epoch 53, Train Loss: 0.6070, Val Loss: 0.7325, F1 Micro: 0.5787, F1 Macro: 0.5715, Accuracy: 0.5787\n","Epoch 54, Train Loss: 0.6043, Val Loss: 0.7069, F1 Micro: 0.6011, F1 Macro: 0.5955, Accuracy: 0.6011\n","Epoch 55, Train Loss: 0.6069, Val Loss: 0.7222, F1 Micro: 0.5562, F1 Macro: 0.5383, Accuracy: 0.5562\n","Epoch 56, Train Loss: 0.5942, Val Loss: 0.7152, F1 Micro: 0.6124, F1 Macro: 0.6109, Accuracy: 0.6124\n","Epoch 57, Train Loss: 0.6064, Val Loss: 0.7460, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 58, Train Loss: 0.5910, Val Loss: 0.7703, F1 Micro: 0.5843, F1 Macro: 0.5421, Accuracy: 0.5843\n","Epoch 59, Train Loss: 0.6057, Val Loss: 0.7954, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 60, Train Loss: 0.5980, Val Loss: 0.7418, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 61, Train Loss: 0.6096, Val Loss: 0.7964, F1 Micro: 0.5562, F1 Macro: 0.4829, Accuracy: 0.5562\n","Epoch 62, Train Loss: 0.6041, Val Loss: 0.7744, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 63, Train Loss: 0.6010, Val Loss: 0.7482, F1 Micro: 0.5899, F1 Macro: 0.5714, Accuracy: 0.5899\n","Epoch 64, Train Loss: 0.6035, Val Loss: 0.7917, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6776, Val Loss: 0.6936, F1 Micro: 0.6067, F1 Macro: 0.5072, Accuracy: 0.6067\n","Epoch 2, Train Loss: 0.6588, Val Loss: 0.6595, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 3, Train Loss: 0.6534, Val Loss: 0.6522, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 4, Train Loss: 0.6492, Val Loss: 0.6680, F1 Micro: 0.6292, F1 Macro: 0.5465, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6425, Val Loss: 0.6831, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6407, Val Loss: 0.6916, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6287, Val Loss: 0.6676, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 8, Train Loss: 0.6535, Val Loss: 0.6845, F1 Micro: 0.6067, F1 Macro: 0.4547, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6477, Val Loss: 0.6533, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6407, Val Loss: 0.6581, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 11, Train Loss: 0.6355, Val Loss: 0.8117, F1 Micro: 0.6011, F1 Macro: 0.4682, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6460, Val Loss: 0.7061, F1 Micro: 0.6292, F1 Macro: 0.4479, Accuracy: 0.6292\n","Epoch 13, Train Loss: 0.6731, Val Loss: 0.6557, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 14, Train Loss: 0.6511, Val Loss: 0.6804, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6494, Val Loss: 0.6938, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 16, Train Loss: 0.6423, Val Loss: 0.6631, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 17, Train Loss: 0.6274, Val Loss: 0.7088, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 18, Train Loss: 0.6583, Val Loss: 0.6581, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 19, Train Loss: 0.6428, Val Loss: 0.7161, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 20, Train Loss: 0.6420, Val Loss: 0.7065, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.6287, Val Loss: 0.7230, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 22, Train Loss: 0.6611, Val Loss: 0.7028, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 23, Train Loss: 0.6447, Val Loss: 0.6703, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 24, Train Loss: 0.6383, Val Loss: 0.6871, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 25, Train Loss: 0.6318, Val Loss: 0.7191, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 26, Train Loss: 0.6402, Val Loss: 0.6630, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 27, Train Loss: 0.6328, Val Loss: 0.6905, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 28, Train Loss: 0.6343, Val Loss: 0.6902, F1 Micro: 0.7022, F1 Macro: 0.6143, Accuracy: 0.7022\n","Epoch 29, Train Loss: 0.6249, Val Loss: 0.6887, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.6367, Val Loss: 0.6543, F1 Micro: 0.6573, F1 Macro: 0.6082, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6317, Val Loss: 0.6591, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.6319, Val Loss: 0.6851, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 33, Train Loss: 0.6376, Val Loss: 0.6707, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 34, Train Loss: 0.6416, Val Loss: 0.6506, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6460, Val Loss: 0.6688, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6355, Val Loss: 0.7011, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6292, Val Loss: 0.6632, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 38, Train Loss: 0.6266, Val Loss: 0.6990, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 39, Train Loss: 0.6354, Val Loss: 0.6864, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 40, Train Loss: 0.6258, Val Loss: 0.7370, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 41, Train Loss: 0.6307, Val Loss: 0.6831, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 42, Train Loss: 0.6314, Val Loss: 0.7249, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6290, Val Loss: 0.6724, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.6192, Val Loss: 0.6859, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 45, Train Loss: 0.6272, Val Loss: 0.7122, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 46, Train Loss: 0.6275, Val Loss: 0.7233, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6313, Val Loss: 0.6671, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 48, Train Loss: 0.6087, Val Loss: 0.6706, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.6212, Val Loss: 0.6844, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 50, Train Loss: 0.6109, Val Loss: 0.6883, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6262, Val Loss: 0.6636, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 52, Train Loss: 0.6286, Val Loss: 0.6785, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7081727449626515\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6768, Val Loss: 0.6542, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 2, Train Loss: 0.6530, Val Loss: 0.6457, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 3, Train Loss: 0.6586, Val Loss: 0.6374, F1 Micro: 0.6704, F1 Macro: 0.6346, Accuracy: 0.6704\n","Epoch 4, Train Loss: 0.6442, Val Loss: 0.6385, F1 Micro: 0.6816, F1 Macro: 0.6241, Accuracy: 0.6816\n","Epoch 5, Train Loss: 0.6468, Val Loss: 0.6698, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 6, Train Loss: 0.6554, Val Loss: 0.6339, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 7, Train Loss: 0.6390, Val Loss: 0.6323, F1 Micro: 0.6648, F1 Macro: 0.5979, Accuracy: 0.6648\n","Epoch 8, Train Loss: 0.6457, Val Loss: 0.6423, F1 Micro: 0.6760, F1 Macro: 0.6365, Accuracy: 0.6760\n","Epoch 9, Train Loss: 0.6400, Val Loss: 0.6263, F1 Micro: 0.6704, F1 Macro: 0.6255, Accuracy: 0.6704\n","Epoch 10, Train Loss: 0.6437, Val Loss: 0.6622, F1 Micro: 0.6648, F1 Macro: 0.5255, Accuracy: 0.6648\n","Epoch 11, Train Loss: 0.6666, Val Loss: 0.6486, F1 Micro: 0.6648, F1 Macro: 0.5672, Accuracy: 0.6648\n","Epoch 12, Train Loss: 0.6415, Val Loss: 0.6677, F1 Micro: 0.5978, F1 Macro: 0.5956, Accuracy: 0.5978\n","Epoch 13, Train Loss: 0.6383, Val Loss: 0.6487, F1 Micro: 0.6648, F1 Macro: 0.6174, Accuracy: 0.6648\n","Epoch 14, Train Loss: 0.6374, Val Loss: 0.6378, F1 Micro: 0.6648, F1 Macro: 0.6208, Accuracy: 0.6648\n","Epoch 15, Train Loss: 0.6381, Val Loss: 0.6378, F1 Micro: 0.6704, F1 Macro: 0.6531, Accuracy: 0.6704\n","Epoch 16, Train Loss: 0.6379, Val Loss: 0.6221, F1 Micro: 0.7039, F1 Macro: 0.6605, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6848, Val Loss: 0.6272, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 2, Train Loss: 0.6538, Val Loss: 0.6158, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 3, Train Loss: 0.6483, Val Loss: 0.5971, F1 Micro: 0.7022, F1 Macro: 0.6195, Accuracy: 0.7022\n","Epoch 4, Train Loss: 0.6450, Val Loss: 0.6371, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6352, Val Loss: 0.6021, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 6, Train Loss: 0.6565, Val Loss: 0.6026, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 7, Train Loss: 0.6346, Val Loss: 0.6828, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6396, Val Loss: 0.5870, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 9, Train Loss: 0.6452, Val Loss: 0.6085, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 10, Train Loss: 0.6514, Val Loss: 0.6405, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6454, Val Loss: 0.5992, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 12, Train Loss: 0.6334, Val Loss: 0.6156, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6853, Val Loss: 0.6364, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6732, Val Loss: 0.6249, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 3, Train Loss: 0.6575, Val Loss: 0.6209, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6489, Val Loss: 0.5956, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6502, Val Loss: 0.6259, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6419, Val Loss: 0.6317, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.6540, Val Loss: 0.6324, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6408, Val Loss: 0.6053, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.6454, Val Loss: 0.6300, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6352, Val Loss: 0.5928, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6290, Val Loss: 0.6099, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 12, Train Loss: 0.6533, Val Loss: 0.6417, F1 Micro: 0.6461, F1 Macro: 0.4679, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6637, Val Loss: 0.6522, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 14, Train Loss: 0.6543, Val Loss: 0.6022, F1 Micro: 0.7079, F1 Macro: 0.6242, Accuracy: 0.7079\n","Epoch 15, Train Loss: 0.6325, Val Loss: 0.6319, F1 Micro: 0.6517, F1 Macro: 0.4911, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6414, Val Loss: 0.6058, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 17, Train Loss: 0.6410, Val Loss: 0.6035, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6473, Val Loss: 0.7297, F1 Micro: 0.6404, F1 Macro: 0.4429, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6401, Val Loss: 0.6666, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 20, Train Loss: 0.6420, Val Loss: 0.5985, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 21, Train Loss: 0.6524, Val Loss: 0.6137, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.6395, Val Loss: 0.6201, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 23, Train Loss: 0.6367, Val Loss: 0.6262, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 24, Train Loss: 0.6372, Val Loss: 0.6192, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6482, Val Loss: 0.6153, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6511, Val Loss: 0.6056, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 27, Train Loss: 0.6293, Val Loss: 0.5858, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 28, Train Loss: 0.6306, Val Loss: 0.6175, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6559, Val Loss: 0.6715, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.6465, Val Loss: 0.6610, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 31, Train Loss: 0.6462, Val Loss: 0.5819, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 32, Train Loss: 0.6408, Val Loss: 0.6198, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.6288, Val Loss: 0.6432, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 34, Train Loss: 0.6327, Val Loss: 0.6221, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 35, Train Loss: 0.6601, Val Loss: 0.6267, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6595, Val Loss: 0.6041, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6308, Val Loss: 0.6385, F1 Micro: 0.7191, F1 Macro: 0.6336, Accuracy: 0.7191\n","Epoch 38, Train Loss: 0.6245, Val Loss: 0.6400, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 39, Train Loss: 0.6342, Val Loss: 0.6245, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.6607, Val Loss: 0.5982, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 41, Train Loss: 0.6356, Val Loss: 0.6260, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6616, Val Loss: 0.8194, F1 Micro: 0.5899, F1 Macro: 0.5174, Accuracy: 0.5899\n","Epoch 2, Train Loss: 0.6375, Val Loss: 0.7613, F1 Micro: 0.5281, F1 Macro: 0.4877, Accuracy: 0.5281\n","Epoch 3, Train Loss: 0.6382, Val Loss: 0.8062, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6193, Val Loss: 0.7361, F1 Micro: 0.5843, F1 Macro: 0.5704, Accuracy: 0.5843\n","Epoch 5, Train Loss: 0.6169, Val Loss: 0.7905, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 6, Train Loss: 0.6182, Val Loss: 0.7933, F1 Micro: 0.5674, F1 Macro: 0.5140, Accuracy: 0.5674\n","Epoch 7, Train Loss: 0.6191, Val Loss: 0.8819, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 8, Train Loss: 0.6108, Val Loss: 0.7420, F1 Micro: 0.5787, F1 Macro: 0.5596, Accuracy: 0.5787\n","Epoch 9, Train Loss: 0.6223, Val Loss: 0.8606, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 10, Train Loss: 0.6145, Val Loss: 0.7853, F1 Micro: 0.5449, F1 Macro: 0.4529, Accuracy: 0.5449\n","Epoch 11, Train Loss: 0.6204, Val Loss: 0.7633, F1 Micro: 0.5899, F1 Macro: 0.5592, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6215, Val Loss: 0.7931, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 13, Train Loss: 0.6133, Val Loss: 0.7471, F1 Micro: 0.5730, F1 Macro: 0.5332, Accuracy: 0.5730\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6751, Val Loss: 0.6900, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 2, Train Loss: 0.6541, Val Loss: 0.7172, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6572, Val Loss: 0.7664, F1 Micro: 0.6180, F1 Macro: 0.4200, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.6469, Val Loss: 0.6768, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6478, Val Loss: 0.6891, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 6, Train Loss: 0.6509, Val Loss: 0.7579, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 7, Train Loss: 0.6398, Val Loss: 0.6931, F1 Micro: 0.7360, F1 Macro: 0.6752, Accuracy: 0.7360\n","Epoch 8, Train Loss: 0.6473, Val Loss: 0.6817, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 9, Train Loss: 0.6319, Val Loss: 0.6979, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 10, Train Loss: 0.6391, Val Loss: 0.7200, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6469, Val Loss: 0.7149, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 12, Train Loss: 0.6400, Val Loss: 0.7050, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6427, Val Loss: 0.7026, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6279, Val Loss: 0.6825, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 15, Train Loss: 0.6332, Val Loss: 0.6941, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 16, Train Loss: 0.6291, Val Loss: 0.7259, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6359, Val Loss: 0.6769, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.7003326847027808\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6696, Val Loss: 0.6631, F1 Micro: 0.6816, F1 Macro: 0.5603, Accuracy: 0.6816\n","Epoch 2, Train Loss: 0.6627, Val Loss: 0.6460, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 3, Train Loss: 0.6650, Val Loss: 0.6377, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 4, Train Loss: 0.6388, Val Loss: 0.6303, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 5, Train Loss: 0.6422, Val Loss: 0.6312, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 6, Train Loss: 0.6400, Val Loss: 0.6970, F1 Micro: 0.6313, F1 Macro: 0.4009, Accuracy: 0.6313\n","Epoch 7, Train Loss: 0.6532, Val Loss: 0.6194, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.6421, Val Loss: 0.6192, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 9, Train Loss: 0.6344, Val Loss: 0.6235, F1 Micro: 0.6760, F1 Macro: 0.6334, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.6442, Val Loss: 0.6219, F1 Micro: 0.6760, F1 Macro: 0.5976, Accuracy: 0.6760\n","Epoch 11, Train Loss: 0.6341, Val Loss: 0.6191, F1 Micro: 0.6760, F1 Macro: 0.6334, Accuracy: 0.6760\n","Epoch 12, Train Loss: 0.6467, Val Loss: 0.6213, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 13, Train Loss: 0.6411, Val Loss: 0.6344, F1 Micro: 0.6760, F1 Macro: 0.6394, Accuracy: 0.6760\n","Epoch 14, Train Loss: 0.6472, Val Loss: 0.6125, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 15, Train Loss: 0.6653, Val Loss: 0.6326, F1 Micro: 0.6592, F1 Macro: 0.6328, Accuracy: 0.6592\n","Epoch 16, Train Loss: 0.6486, Val Loss: 0.6231, F1 Micro: 0.6592, F1 Macro: 0.6192, Accuracy: 0.6592\n","Epoch 17, Train Loss: 0.6313, Val Loss: 0.6233, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.6355, Val Loss: 0.6269, F1 Micro: 0.6648, F1 Macro: 0.6400, Accuracy: 0.6648\n","Epoch 19, Train Loss: 0.6405, Val Loss: 0.6243, F1 Micro: 0.6704, F1 Macro: 0.5653, Accuracy: 0.6704\n","Epoch 20, Train Loss: 0.6490, Val Loss: 0.6240, F1 Micro: 0.6313, F1 Macro: 0.5959, Accuracy: 0.6313\n","Epoch 21, Train Loss: 0.6324, Val Loss: 0.6139, F1 Micro: 0.6816, F1 Macro: 0.6241, Accuracy: 0.6816\n","Epoch 22, Train Loss: 0.6327, Val Loss: 0.6166, F1 Micro: 0.6872, F1 Macro: 0.6595, Accuracy: 0.6872\n","Epoch 23, Train Loss: 0.6305, Val Loss: 0.6153, F1 Micro: 0.6927, F1 Macro: 0.6252, Accuracy: 0.6927\n","Epoch 24, Train Loss: 0.6411, Val Loss: 0.6420, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 25, Train Loss: 0.6337, Val Loss: 0.6220, F1 Micro: 0.6704, F1 Macro: 0.6148, Accuracy: 0.6704\n","Epoch 26, Train Loss: 0.6370, Val Loss: 0.6274, F1 Micro: 0.6648, F1 Macro: 0.6208, Accuracy: 0.6648\n","Epoch 27, Train Loss: 0.6301, Val Loss: 0.6174, F1 Micro: 0.6816, F1 Macro: 0.6522, Accuracy: 0.6816\n","Epoch 28, Train Loss: 0.6410, Val Loss: 0.6170, F1 Micro: 0.6592, F1 Macro: 0.5569, Accuracy: 0.6592\n","Epoch 29, Train Loss: 0.6273, Val Loss: 0.6203, F1 Micro: 0.6536, F1 Macro: 0.5329, Accuracy: 0.6536\n","Epoch 30, Train Loss: 0.6303, Val Loss: 0.6307, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 31, Train Loss: 0.6369, Val Loss: 0.6122, F1 Micro: 0.6983, F1 Macro: 0.6643, Accuracy: 0.6983\n","Epoch 32, Train Loss: 0.6289, Val Loss: 0.6137, F1 Micro: 0.6872, F1 Macro: 0.6460, Accuracy: 0.6872\n","Epoch 33, Train Loss: 0.6119, Val Loss: 0.6445, F1 Micro: 0.6648, F1 Macro: 0.4989, Accuracy: 0.6648\n","Epoch 34, Train Loss: 0.6218, Val Loss: 0.6185, F1 Micro: 0.6872, F1 Macro: 0.6660, Accuracy: 0.6872\n","Epoch 35, Train Loss: 0.6259, Val Loss: 0.6290, F1 Micro: 0.6927, F1 Macro: 0.5948, Accuracy: 0.6927\n","Epoch 36, Train Loss: 0.6459, Val Loss: 0.6177, F1 Micro: 0.6648, F1 Macro: 0.6299, Accuracy: 0.6648\n","Epoch 37, Train Loss: 0.6391, Val Loss: 0.6102, F1 Micro: 0.6816, F1 Macro: 0.6382, Accuracy: 0.6816\n","Epoch 38, Train Loss: 0.6382, Val Loss: 0.6126, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 39, Train Loss: 0.6456, Val Loss: 0.6369, F1 Micro: 0.6592, F1 Macro: 0.5369, Accuracy: 0.6592\n","Epoch 40, Train Loss: 0.6285, Val Loss: 0.6126, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 41, Train Loss: 0.6257, Val Loss: 0.6138, F1 Micro: 0.6536, F1 Macro: 0.6047, Accuracy: 0.6536\n","Epoch 42, Train Loss: 0.6153, Val Loss: 0.6245, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 43, Train Loss: 0.6210, Val Loss: 0.6189, F1 Micro: 0.6872, F1 Macro: 0.6618, Accuracy: 0.6872\n","Epoch 44, Train Loss: 0.6395, Val Loss: 0.6128, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 45, Train Loss: 0.6407, Val Loss: 0.6116, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 46, Train Loss: 0.6282, Val Loss: 0.6280, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Epoch 47, Train Loss: 0.6258, Val Loss: 0.6186, F1 Micro: 0.6927, F1 Macro: 0.6667, Accuracy: 0.6927\n","Epoch 48, Train Loss: 0.6410, Val Loss: 0.6319, F1 Micro: 0.6760, F1 Macro: 0.6615, Accuracy: 0.6760\n","Epoch 49, Train Loss: 0.6320, Val Loss: 0.6183, F1 Micro: 0.6536, F1 Macro: 0.6114, Accuracy: 0.6536\n","Epoch 50, Train Loss: 0.6218, Val Loss: 0.6432, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 51, Train Loss: 0.6242, Val Loss: 0.6224, F1 Micro: 0.6648, F1 Macro: 0.6299, Accuracy: 0.6648\n","Epoch 52, Train Loss: 0.6202, Val Loss: 0.6242, F1 Micro: 0.6816, F1 Macro: 0.6681, Accuracy: 0.6816\n","Epoch 53, Train Loss: 0.6358, Val Loss: 0.6367, F1 Micro: 0.6480, F1 Macro: 0.6128, Accuracy: 0.6480\n","Epoch 54, Train Loss: 0.6373, Val Loss: 0.6120, F1 Micro: 0.6648, F1 Macro: 0.6063, Accuracy: 0.6648\n","Epoch 55, Train Loss: 0.6295, Val Loss: 0.6103, F1 Micro: 0.6704, F1 Macro: 0.6185, Accuracy: 0.6704\n","Epoch 56, Train Loss: 0.6311, Val Loss: 0.6100, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 57, Train Loss: 0.6265, Val Loss: 0.6543, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 58, Train Loss: 0.6288, Val Loss: 0.6217, F1 Micro: 0.6816, F1 Macro: 0.6611, Accuracy: 0.6816\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6753, Val Loss: 0.6289, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 2, Train Loss: 0.6804, Val Loss: 0.6227, F1 Micro: 0.6629, F1 Macro: 0.4882, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6602, Val Loss: 0.6341, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6653, Val Loss: 0.6479, F1 Micro: 0.6517, F1 Macro: 0.6463, Accuracy: 0.6517\n","Epoch 5, Train Loss: 0.6438, Val Loss: 0.6013, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 6, Train Loss: 0.6303, Val Loss: 0.5965, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 7, Train Loss: 0.6352, Val Loss: 0.6061, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 8, Train Loss: 0.6389, Val Loss: 0.6004, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.6522, Val Loss: 0.6208, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 10, Train Loss: 0.6355, Val Loss: 0.6461, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6424, Val Loss: 0.5899, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 12, Train Loss: 0.6436, Val Loss: 0.6086, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.6291, Val Loss: 0.5757, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 14, Train Loss: 0.6401, Val Loss: 0.6195, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6461, Val Loss: 0.6306, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 16, Train Loss: 0.6415, Val Loss: 0.6021, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.6541, Val Loss: 0.5926, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.6353, Val Loss: 0.6347, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 19, Train Loss: 0.6414, Val Loss: 0.6086, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 20, Train Loss: 0.6397, Val Loss: 0.5964, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 21, Train Loss: 0.6526, Val Loss: 0.5927, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 22, Train Loss: 0.6592, Val Loss: 0.6187, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 23, Train Loss: 0.6334, Val Loss: 0.5926, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 24, Train Loss: 0.6376, Val Loss: 0.5938, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 25, Train Loss: 0.6244, Val Loss: 0.5887, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 26, Train Loss: 0.6308, Val Loss: 0.5968, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 27, Train Loss: 0.6248, Val Loss: 0.6111, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.6393, Val Loss: 0.6726, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 29, Train Loss: 0.6307, Val Loss: 0.6245, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6377, Val Loss: 0.6130, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 31, Train Loss: 0.6249, Val Loss: 0.5779, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 32, Train Loss: 0.6369, Val Loss: 0.5896, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 33, Train Loss: 0.6252, Val Loss: 0.6515, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.6328, Val Loss: 0.6413, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 35, Train Loss: 0.6294, Val Loss: 0.5935, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6363, Val Loss: 0.6382, F1 Micro: 0.6798, F1 Macro: 0.6653, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.6258, Val Loss: 0.6113, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 38, Train Loss: 0.6347, Val Loss: 0.6083, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6304, Val Loss: 0.5790, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 40, Train Loss: 0.6288, Val Loss: 0.6090, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 41, Train Loss: 0.6193, Val Loss: 0.5902, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.6205, Val Loss: 0.6238, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.6264, Val Loss: 0.6029, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 44, Train Loss: 0.6333, Val Loss: 0.6077, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.6303, Val Loss: 0.6091, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 46, Train Loss: 0.6188, Val Loss: 0.6306, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 47, Train Loss: 0.6336, Val Loss: 0.5796, F1 Micro: 0.7022, F1 Macro: 0.6030, Accuracy: 0.7022\n","Epoch 48, Train Loss: 0.6438, Val Loss: 0.5920, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 49, Train Loss: 0.6332, Val Loss: 0.5897, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 50, Train Loss: 0.6304, Val Loss: 0.6722, F1 Micro: 0.5730, F1 Macro: 0.5717, Accuracy: 0.5730\n","Epoch 51, Train Loss: 0.6260, Val Loss: 0.5876, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 52, Train Loss: 0.6181, Val Loss: 0.5910, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 53, Train Loss: 0.6369, Val Loss: 0.6146, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.6264, Val Loss: 0.5974, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 55, Train Loss: 0.6305, Val Loss: 0.6068, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 56, Train Loss: 0.6287, Val Loss: 0.6077, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 57, Train Loss: 0.6364, Val Loss: 0.6240, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 58, Train Loss: 0.6277, Val Loss: 0.6294, F1 Micro: 0.6461, F1 Macro: 0.6350, Accuracy: 0.6461\n","Epoch 59, Train Loss: 0.6227, Val Loss: 0.5743, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 60, Train Loss: 0.6313, Val Loss: 0.5959, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.6290, Val Loss: 0.6070, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 62, Train Loss: 0.6320, Val Loss: 0.5844, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 63, Train Loss: 0.6152, Val Loss: 0.6034, F1 Micro: 0.7079, F1 Macro: 0.6384, Accuracy: 0.7079\n","Epoch 64, Train Loss: 0.6334, Val Loss: 0.6025, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 65, Train Loss: 0.6335, Val Loss: 0.6160, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 66, Train Loss: 0.6299, Val Loss: 0.5981, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 67, Train Loss: 0.6225, Val Loss: 0.5993, F1 Micro: 0.7360, F1 Macro: 0.6752, Accuracy: 0.7360\n","Epoch 68, Train Loss: 0.6351, Val Loss: 0.6040, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 69, Train Loss: 0.6241, Val Loss: 0.6195, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 70, Train Loss: 0.6161, Val Loss: 0.5985, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 71, Train Loss: 0.6256, Val Loss: 0.5705, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 72, Train Loss: 0.6182, Val Loss: 0.6096, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 73, Train Loss: 0.6286, Val Loss: 0.5862, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 74, Train Loss: 0.6332, Val Loss: 0.5828, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 75, Train Loss: 0.6296, Val Loss: 0.5791, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 76, Train Loss: 0.6278, Val Loss: 0.5670, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 77, Train Loss: 0.6241, Val Loss: 0.5986, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 78, Train Loss: 0.6369, Val Loss: 0.5992, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 79, Train Loss: 0.6233, Val Loss: 0.5983, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 80, Train Loss: 0.6338, Val Loss: 0.6216, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 81, Train Loss: 0.6198, Val Loss: 0.5895, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 82, Train Loss: 0.6338, Val Loss: 0.6346, F1 Micro: 0.6292, F1 Macro: 0.6262, Accuracy: 0.6292\n","Epoch 83, Train Loss: 0.6234, Val Loss: 0.6124, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 84, Train Loss: 0.6286, Val Loss: 0.5701, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 85, Train Loss: 0.6196, Val Loss: 0.5793, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 86, Train Loss: 0.6192, Val Loss: 0.6094, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 87, Train Loss: 0.6274, Val Loss: 0.6004, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 88, Train Loss: 0.6300, Val Loss: 0.5735, F1 Micro: 0.7022, F1 Macro: 0.6195, Accuracy: 0.7022\n","Epoch 89, Train Loss: 0.6198, Val Loss: 0.5911, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6932, Val Loss: 0.6606, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6658, Val Loss: 0.6094, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 3, Train Loss: 0.6573, Val Loss: 0.6065, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 4, Train Loss: 0.6589, Val Loss: 0.6076, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6518, Val Loss: 0.6520, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6521, Val Loss: 0.6385, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6524, Val Loss: 0.6290, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 8, Train Loss: 0.6511, Val Loss: 0.6101, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 9, Train Loss: 0.6388, Val Loss: 0.5866, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 10, Train Loss: 0.6313, Val Loss: 0.6040, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6458, Val Loss: 0.6095, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 12, Train Loss: 0.6483, Val Loss: 0.6519, F1 Micro: 0.7247, F1 Macro: 0.6330, Accuracy: 0.7247\n","Epoch 13, Train Loss: 0.6355, Val Loss: 0.6346, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 14, Train Loss: 0.6477, Val Loss: 0.6009, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6447, Val Loss: 0.6234, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6299, Val Loss: 0.5988, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 17, Train Loss: 0.6297, Val Loss: 0.6266, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6498, Val Loss: 0.6383, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 19, Train Loss: 0.6460, Val Loss: 0.6550, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.6574, Val Loss: 0.6040, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.6348, Val Loss: 0.6436, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 22, Train Loss: 0.6368, Val Loss: 0.6074, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6414, Val Loss: 0.6141, F1 Micro: 0.7360, F1 Macro: 0.6712, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6299, Val Loss: 0.5875, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 25, Train Loss: 0.6317, Val Loss: 0.6419, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.6350, Val Loss: 0.6022, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 27, Train Loss: 0.6333, Val Loss: 0.5837, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 28, Train Loss: 0.6386, Val Loss: 0.6252, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6417, Val Loss: 0.5891, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 30, Train Loss: 0.6398, Val Loss: 0.6260, F1 Micro: 0.6180, F1 Macro: 0.6140, Accuracy: 0.6180\n","Epoch 31, Train Loss: 0.6431, Val Loss: 0.6629, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.6244, Val Loss: 0.6014, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 33, Train Loss: 0.6236, Val Loss: 0.6087, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6359, Val Loss: 0.6114, F1 Micro: 0.7360, F1 Macro: 0.6712, Accuracy: 0.7360\n","Epoch 35, Train Loss: 0.6314, Val Loss: 0.6067, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 36, Train Loss: 0.6476, Val Loss: 0.5887, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 37, Train Loss: 0.6265, Val Loss: 0.5938, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.6419, Val Loss: 0.6065, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 39, Train Loss: 0.6329, Val Loss: 0.5967, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.6384, Val Loss: 0.6055, F1 Micro: 0.7303, F1 Macro: 0.6577, Accuracy: 0.7303\n","Epoch 41, Train Loss: 0.6456, Val Loss: 0.6231, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 42, Train Loss: 0.6499, Val Loss: 0.6268, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 43, Train Loss: 0.6431, Val Loss: 0.6001, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6375, Val Loss: 0.6081, F1 Micro: 0.7303, F1 Macro: 0.6663, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6247, Val Loss: 0.6196, F1 Micro: 0.7303, F1 Macro: 0.6621, Accuracy: 0.7303\n","Epoch 46, Train Loss: 0.6384, Val Loss: 0.6153, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 47, Train Loss: 0.6429, Val Loss: 0.6683, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6392, Val Loss: 0.5967, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.6389, Val Loss: 0.6025, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 50, Train Loss: 0.6315, Val Loss: 0.6066, F1 Micro: 0.7191, F1 Macro: 0.6565, Accuracy: 0.7191\n","Epoch 51, Train Loss: 0.6201, Val Loss: 0.6172, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 52, Train Loss: 0.6486, Val Loss: 0.6038, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 53, Train Loss: 0.6340, Val Loss: 0.6377, F1 Micro: 0.7303, F1 Macro: 0.6577, Accuracy: 0.7303\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6673, Val Loss: 0.7726, F1 Micro: 0.5674, F1 Macro: 0.4472, Accuracy: 0.5674\n","Epoch 2, Train Loss: 0.6523, Val Loss: 0.7826, F1 Micro: 0.5393, F1 Macro: 0.4366, Accuracy: 0.5393\n","Epoch 3, Train Loss: 0.6513, Val Loss: 0.7743, F1 Micro: 0.5393, F1 Macro: 0.4606, Accuracy: 0.5393\n","Epoch 4, Train Loss: 0.6303, Val Loss: 0.8272, F1 Micro: 0.5562, F1 Macro: 0.4879, Accuracy: 0.5562\n","Epoch 5, Train Loss: 0.6269, Val Loss: 0.7677, F1 Micro: 0.5618, F1 Macro: 0.5137, Accuracy: 0.5618\n","Epoch 6, Train Loss: 0.6149, Val Loss: 0.8177, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 7, Train Loss: 0.6093, Val Loss: 0.7183, F1 Micro: 0.5506, F1 Macro: 0.5501, Accuracy: 0.5506\n","Epoch 8, Train Loss: 0.6093, Val Loss: 0.7900, F1 Micro: 0.5730, F1 Macro: 0.5141, Accuracy: 0.5730\n","Epoch 9, Train Loss: 0.6176, Val Loss: 0.7711, F1 Micro: 0.5225, F1 Macro: 0.4380, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6161, Val Loss: 0.8007, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6090, Val Loss: 0.7443, F1 Micro: 0.6011, F1 Macro: 0.5831, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6180, Val Loss: 0.7893, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 13, Train Loss: 0.6145, Val Loss: 0.7777, F1 Micro: 0.5787, F1 Macro: 0.5342, Accuracy: 0.5787\n","Epoch 14, Train Loss: 0.6157, Val Loss: 0.7901, F1 Micro: 0.5730, F1 Macro: 0.5223, Accuracy: 0.5730\n","Epoch 15, Train Loss: 0.6094, Val Loss: 0.8023, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.6085, Val Loss: 0.7278, F1 Micro: 0.5618, F1 Macro: 0.5616, Accuracy: 0.5618\n","Epoch 17, Train Loss: 0.6148, Val Loss: 0.7841, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 18, Train Loss: 0.6082, Val Loss: 0.8441, F1 Micro: 0.5337, F1 Macro: 0.4394, Accuracy: 0.5337\n","Epoch 19, Train Loss: 0.5996, Val Loss: 0.7844, F1 Micro: 0.5562, F1 Macro: 0.5093, Accuracy: 0.5562\n","Epoch 20, Train Loss: 0.6196, Val Loss: 0.7899, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 21, Train Loss: 0.6017, Val Loss: 0.8141, F1 Micro: 0.5449, F1 Macro: 0.4529, Accuracy: 0.5449\n","Epoch 22, Train Loss: 0.6126, Val Loss: 0.8027, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 23, Train Loss: 0.6050, Val Loss: 0.8731, F1 Micro: 0.5449, F1 Macro: 0.4333, Accuracy: 0.5449\n","Epoch 24, Train Loss: 0.6156, Val Loss: 0.7816, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 25, Train Loss: 0.6067, Val Loss: 0.7879, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 26, Train Loss: 0.6029, Val Loss: 0.7822, F1 Micro: 0.5787, F1 Macro: 0.5441, Accuracy: 0.5787\n","Epoch 27, Train Loss: 0.5944, Val Loss: 0.8076, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 28, Train Loss: 0.6098, Val Loss: 0.7478, F1 Micro: 0.6180, F1 Macro: 0.6068, Accuracy: 0.6180\n","Epoch 29, Train Loss: 0.6083, Val Loss: 0.7613, F1 Micro: 0.6011, F1 Macro: 0.5902, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6028, Val Loss: 0.7656, F1 Micro: 0.5787, F1 Macro: 0.5441, Accuracy: 0.5787\n","Epoch 31, Train Loss: 0.6006, Val Loss: 0.8353, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 32, Train Loss: 0.6132, Val Loss: 0.8065, F1 Micro: 0.5506, F1 Macro: 0.4738, Accuracy: 0.5506\n","Epoch 33, Train Loss: 0.6100, Val Loss: 0.7904, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6002, Val Loss: 0.7638, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 35, Train Loss: 0.6026, Val Loss: 0.7703, F1 Micro: 0.5899, F1 Macro: 0.5592, Accuracy: 0.5899\n","Epoch 36, Train Loss: 0.6109, Val Loss: 0.7676, F1 Micro: 0.5843, F1 Macro: 0.5517, Accuracy: 0.5843\n","Epoch 37, Train Loss: 0.5941, Val Loss: 0.8091, F1 Micro: 0.5787, F1 Macro: 0.5305, Accuracy: 0.5787\n","Epoch 38, Train Loss: 0.5963, Val Loss: 0.7958, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.5990, Val Loss: 0.7828, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 40, Train Loss: 0.6082, Val Loss: 0.7821, F1 Micro: 0.5393, F1 Macro: 0.4846, Accuracy: 0.5393\n","Epoch 41, Train Loss: 0.5943, Val Loss: 0.7531, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 42, Train Loss: 0.5975, Val Loss: 0.7461, F1 Micro: 0.5506, F1 Macro: 0.5267, Accuracy: 0.5506\n","Epoch 43, Train Loss: 0.6019, Val Loss: 0.8650, F1 Micro: 0.5449, F1 Macro: 0.4333, Accuracy: 0.5449\n","Epoch 44, Train Loss: 0.5930, Val Loss: 0.7477, F1 Micro: 0.5506, F1 Macro: 0.5356, Accuracy: 0.5506\n","Epoch 45, Train Loss: 0.5900, Val Loss: 0.7775, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 46, Train Loss: 0.5963, Val Loss: 0.7882, F1 Micro: 0.5674, F1 Macro: 0.5350, Accuracy: 0.5674\n","Epoch 47, Train Loss: 0.6117, Val Loss: 0.7939, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.5958, Val Loss: 0.8150, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 49, Train Loss: 0.6062, Val Loss: 0.7380, F1 Micro: 0.5449, F1 Macro: 0.5244, Accuracy: 0.5449\n","Epoch 50, Train Loss: 0.5895, Val Loss: 0.7450, F1 Micro: 0.5562, F1 Macro: 0.5338, Accuracy: 0.5562\n","Epoch 51, Train Loss: 0.5920, Val Loss: 0.7480, F1 Micro: 0.5618, F1 Macro: 0.5385, Accuracy: 0.5618\n","Epoch 52, Train Loss: 0.5936, Val Loss: 0.7466, F1 Micro: 0.5843, F1 Macro: 0.5704, Accuracy: 0.5843\n","Epoch 53, Train Loss: 0.6101, Val Loss: 0.7293, F1 Micro: 0.5955, F1 Macro: 0.5820, Accuracy: 0.5955\n","Epoch 54, Train Loss: 0.5981, Val Loss: 0.8427, F1 Micro: 0.5787, F1 Macro: 0.5183, Accuracy: 0.5787\n","Epoch 55, Train Loss: 0.6010, Val Loss: 0.7808, F1 Micro: 0.5899, F1 Macro: 0.5669, Accuracy: 0.5899\n","Epoch 56, Train Loss: 0.6013, Val Loss: 0.7460, F1 Micro: 0.5449, F1 Macro: 0.5244, Accuracy: 0.5449\n","Epoch 57, Train Loss: 0.6086, Val Loss: 0.7822, F1 Micro: 0.5899, F1 Macro: 0.5430, Accuracy: 0.5899\n","Epoch 58, Train Loss: 0.6014, Val Loss: 0.7847, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 59, Train Loss: 0.5925, Val Loss: 0.7265, F1 Micro: 0.5506, F1 Macro: 0.5491, Accuracy: 0.5506\n","Epoch 60, Train Loss: 0.6090, Val Loss: 0.7473, F1 Micro: 0.5562, F1 Macro: 0.5338, Accuracy: 0.5562\n","Epoch 61, Train Loss: 0.5865, Val Loss: 0.7374, F1 Micro: 0.6236, F1 Macro: 0.6160, Accuracy: 0.6236\n","Epoch 62, Train Loss: 0.5967, Val Loss: 0.7365, F1 Micro: 0.6011, F1 Macro: 0.5975, Accuracy: 0.6011\n","Epoch 63, Train Loss: 0.6100, Val Loss: 0.7586, F1 Micro: 0.5843, F1 Macro: 0.5598, Accuracy: 0.5843\n","Epoch 64, Train Loss: 0.5919, Val Loss: 0.8388, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 65, Train Loss: 0.5910, Val Loss: 0.8099, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 66, Train Loss: 0.5990, Val Loss: 0.7492, F1 Micro: 0.5337, F1 Macro: 0.5210, Accuracy: 0.5337\n","Epoch 67, Train Loss: 0.5983, Val Loss: 0.7988, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 68, Train Loss: 0.5999, Val Loss: 0.7553, F1 Micro: 0.5843, F1 Macro: 0.5665, Accuracy: 0.5843\n","Epoch 69, Train Loss: 0.6018, Val Loss: 0.7623, F1 Micro: 0.5843, F1 Macro: 0.5545, Accuracy: 0.5843\n","Epoch 70, Train Loss: 0.5919, Val Loss: 0.7849, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 71, Train Loss: 0.6035, Val Loss: 0.8242, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 72, Train Loss: 0.5924, Val Loss: 0.7673, F1 Micro: 0.5787, F1 Macro: 0.5377, Accuracy: 0.5787\n","Epoch 73, Train Loss: 0.6189, Val Loss: 0.7379, F1 Micro: 0.5674, F1 Macro: 0.5587, Accuracy: 0.5674\n","Epoch 74, Train Loss: 0.5925, Val Loss: 0.7323, F1 Micro: 0.6011, F1 Macro: 0.5955, Accuracy: 0.6011\n","Epoch 75, Train Loss: 0.5970, Val Loss: 0.7551, F1 Micro: 0.5787, F1 Macro: 0.5596, Accuracy: 0.5787\n","Epoch 76, Train Loss: 0.6025, Val Loss: 0.7863, F1 Micro: 0.5955, F1 Macro: 0.5545, Accuracy: 0.5955\n","Epoch 77, Train Loss: 0.5926, Val Loss: 0.8563, F1 Micro: 0.5562, F1 Macro: 0.4664, Accuracy: 0.5562\n","Epoch 78, Train Loss: 0.6008, Val Loss: 0.7904, F1 Micro: 0.5955, F1 Macro: 0.5717, Accuracy: 0.5955\n","Epoch 79, Train Loss: 0.6001, Val Loss: 0.8133, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 80, Train Loss: 0.5972, Val Loss: 0.7758, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 81, Train Loss: 0.5954, Val Loss: 0.7612, F1 Micro: 0.5730, F1 Macro: 0.5548, Accuracy: 0.5730\n","Epoch 82, Train Loss: 0.5955, Val Loss: 0.8228, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 83, Train Loss: 0.6017, Val Loss: 0.7547, F1 Micro: 0.5674, F1 Macro: 0.5456, Accuracy: 0.5674\n","Epoch 84, Train Loss: 0.5970, Val Loss: 0.7639, F1 Micro: 0.5787, F1 Macro: 0.5596, Accuracy: 0.5787\n","Epoch 85, Train Loss: 0.5964, Val Loss: 0.8061, F1 Micro: 0.5899, F1 Macro: 0.5430, Accuracy: 0.5899\n","Epoch 86, Train Loss: 0.6107, Val Loss: 0.7371, F1 Micro: 0.5618, F1 Macro: 0.5573, Accuracy: 0.5618\n","Epoch 87, Train Loss: 0.6028, Val Loss: 0.7809, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 88, Train Loss: 0.5935, Val Loss: 0.7445, F1 Micro: 0.5730, F1 Macro: 0.5569, Accuracy: 0.5730\n","Epoch 89, Train Loss: 0.5867, Val Loss: 0.7788, F1 Micro: 0.5618, F1 Macro: 0.5243, Accuracy: 0.5618\n","Epoch 90, Train Loss: 0.5913, Val Loss: 0.7776, F1 Micro: 0.5955, F1 Macro: 0.5740, Accuracy: 0.5955\n","Epoch 91, Train Loss: 0.5882, Val Loss: 0.8199, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 92, Train Loss: 0.5889, Val Loss: 0.7626, F1 Micro: 0.5449, F1 Macro: 0.5042, Accuracy: 0.5449\n","Epoch 93, Train Loss: 0.6000, Val Loss: 0.7777, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 94, Train Loss: 0.5947, Val Loss: 0.8081, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 95, Train Loss: 0.5911, Val Loss: 0.7542, F1 Micro: 0.5562, F1 Macro: 0.5457, Accuracy: 0.5562\n","Epoch 96, Train Loss: 0.5954, Val Loss: 0.7520, F1 Micro: 0.5449, F1 Macro: 0.5108, Accuracy: 0.5449\n","Epoch 97, Train Loss: 0.5847, Val Loss: 0.7612, F1 Micro: 0.6011, F1 Macro: 0.5831, Accuracy: 0.6011\n","Epoch 98, Train Loss: 0.5986, Val Loss: 0.8222, F1 Micro: 0.5449, F1 Macro: 0.4588, Accuracy: 0.5449\n","Epoch 99, Train Loss: 0.5915, Val Loss: 0.8177, F1 Micro: 0.5337, F1 Macro: 0.4567, Accuracy: 0.5337\n","Epoch 100, Train Loss: 0.5823, Val Loss: 0.7543, F1 Micro: 0.5674, F1 Macro: 0.5456, Accuracy: 0.5674\n","Epoch 101, Train Loss: 0.5985, Val Loss: 0.7677, F1 Micro: 0.6011, F1 Macro: 0.5831, Accuracy: 0.6011\n","Epoch 102, Train Loss: 0.5913, Val Loss: 0.7822, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 103, Train Loss: 0.5969, Val Loss: 0.7793, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 104, Train Loss: 0.5947, Val Loss: 0.8024, F1 Micro: 0.5899, F1 Macro: 0.5430, Accuracy: 0.5899\n","Epoch 105, Train Loss: 0.5971, Val Loss: 0.8372, F1 Micro: 0.5337, F1 Macro: 0.4331, Accuracy: 0.5337\n","Epoch 106, Train Loss: 0.5917, Val Loss: 0.7994, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 107, Train Loss: 0.6115, Val Loss: 0.7793, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Epoch 108, Train Loss: 0.5869, Val Loss: 0.8471, F1 Micro: 0.5955, F1 Macro: 0.5545, Accuracy: 0.5955\n","Epoch 109, Train Loss: 0.5956, Val Loss: 0.7442, F1 Micro: 0.5899, F1 Macro: 0.5753, Accuracy: 0.5899\n","Epoch 110, Train Loss: 0.6062, Val Loss: 0.7314, F1 Micro: 0.5730, F1 Macro: 0.5606, Accuracy: 0.5730\n","Epoch 111, Train Loss: 0.5998, Val Loss: 0.7663, F1 Micro: 0.5843, F1 Macro: 0.5685, Accuracy: 0.5843\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6959, Val Loss: 0.6976, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6491, Val Loss: 0.7530, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 3, Train Loss: 0.6554, Val Loss: 0.7372, F1 Micro: 0.6404, F1 Macro: 0.4746, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6414, Val Loss: 0.7261, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6372, Val Loss: 0.7206, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6341, Val Loss: 0.7081, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.6381, Val Loss: 0.6836, F1 Micro: 0.6629, F1 Macro: 0.6468, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6438, Val Loss: 0.6931, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6393, Val Loss: 0.6822, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6355, Val Loss: 0.6924, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6266, Val Loss: 0.6837, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6449, Val Loss: 0.6925, F1 Micro: 0.6461, F1 Macro: 0.5697, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6262, Val Loss: 0.7064, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6234, Val Loss: 0.7142, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6275, Val Loss: 0.6950, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6245, Val Loss: 0.6966, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6322, Val Loss: 0.7064, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6363, Val Loss: 0.6861, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 19, Train Loss: 0.6337, Val Loss: 0.6814, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 20, Train Loss: 0.6369, Val Loss: 0.7246, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 21, Train Loss: 0.6370, Val Loss: 0.7057, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 22, Train Loss: 0.6320, Val Loss: 0.7335, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.6427, Val Loss: 0.6958, F1 Micro: 0.7135, F1 Macro: 0.6475, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.6338, Val Loss: 0.7811, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.6416, Val Loss: 0.6757, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 26, Train Loss: 0.6318, Val Loss: 0.6871, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 27, Train Loss: 0.6258, Val Loss: 0.7327, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 28, Train Loss: 0.6333, Val Loss: 0.6995, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6237, Val Loss: 0.6878, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6392, Val Loss: 0.6857, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 31, Train Loss: 0.6289, Val Loss: 0.6877, F1 Micro: 0.6292, F1 Macro: 0.6095, Accuracy: 0.6292\n","Epoch 32, Train Loss: 0.6304, Val Loss: 0.7166, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 33, Train Loss: 0.6366, Val Loss: 0.6985, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 34, Train Loss: 0.6287, Val Loss: 0.7193, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.6315, Val Loss: 0.7036, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 36, Train Loss: 0.6249, Val Loss: 0.6980, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 37, Train Loss: 0.6540, Val Loss: 0.6943, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 38, Train Loss: 0.6295, Val Loss: 0.6883, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 39, Train Loss: 0.6253, Val Loss: 0.6859, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 40, Train Loss: 0.6285, Val Loss: 0.7069, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 41, Train Loss: 0.6168, Val Loss: 0.6926, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 42, Train Loss: 0.6207, Val Loss: 0.7182, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 43, Train Loss: 0.6210, Val Loss: 0.7196, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 44, Train Loss: 0.6203, Val Loss: 0.6980, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 45, Train Loss: 0.6207, Val Loss: 0.6868, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 46, Train Loss: 0.6135, Val Loss: 0.6854, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6278, Val Loss: 0.7029, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.6296, Val Loss: 0.7676, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 49, Train Loss: 0.6356, Val Loss: 0.6995, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 50, Train Loss: 0.6196, Val Loss: 0.7223, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6295, Val Loss: 0.6890, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 52, Train Loss: 0.6316, Val Loss: 0.7328, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 53, Train Loss: 0.6211, Val Loss: 0.7416, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 54, Train Loss: 0.6247, Val Loss: 0.7758, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 55, Train Loss: 0.6370, Val Loss: 0.6883, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.6172, Val Loss: 0.7136, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 57, Train Loss: 0.6207, Val Loss: 0.7020, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 58, Train Loss: 0.6262, Val Loss: 0.6874, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.6268, Val Loss: 0.7233, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 60, Train Loss: 0.6288, Val Loss: 0.6903, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 61, Train Loss: 0.6231, Val Loss: 0.7142, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 62, Train Loss: 0.6146, Val Loss: 0.7309, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 63, Train Loss: 0.6186, Val Loss: 0.7668, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 64, Train Loss: 0.6457, Val Loss: 0.7147, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 65, Train Loss: 0.6082, Val Loss: 0.7041, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 66, Train Loss: 0.6216, Val Loss: 0.7484, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.6117, Val Loss: 0.7295, F1 Micro: 0.7079, F1 Macro: 0.6339, Accuracy: 0.7079\n","Epoch 68, Train Loss: 0.6304, Val Loss: 0.7328, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 69, Train Loss: 0.6250, Val Loss: 0.7282, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7059569393007344\n","Best hyperparameters for Outer FOLD 3: (0.01, 16, 50) with score 0.7182913815830771\n","Epoch 1, Train Loss: 0.7816, Val Loss: 0.7509, F1 Micro: 0.6351, F1 Macro: 0.5909, Accuracy: 0.6351\n","Epoch 2, Train Loss: 0.6899, Val Loss: 0.7196, F1 Micro: 0.5090, F1 Macro: 0.4717, Accuracy: 0.5090\n","Epoch 3, Train Loss: 0.7388, Val Loss: 0.8070, F1 Micro: 0.6081, F1 Macro: 0.4895, Accuracy: 0.6081\n","Epoch 4, Train Loss: 0.6751, Val Loss: 0.6586, F1 Micro: 0.6261, F1 Macro: 0.5583, Accuracy: 0.6261\n","Epoch 5, Train Loss: 0.6624, Val Loss: 0.6752, F1 Micro: 0.6126, F1 Macro: 0.5235, Accuracy: 0.6126\n","Epoch 6, Train Loss: 0.6627, Val Loss: 0.6277, F1 Micro: 0.6712, F1 Macro: 0.6513, Accuracy: 0.6712\n","Epoch 7, Train Loss: 0.6488, Val Loss: 0.6326, F1 Micro: 0.6667, F1 Macro: 0.6613, Accuracy: 0.6667\n","Epoch 8, Train Loss: 0.6561, Val Loss: 0.6353, F1 Micro: 0.6622, F1 Macro: 0.6103, Accuracy: 0.6622\n","Epoch 9, Train Loss: 0.6474, Val Loss: 0.6737, F1 Micro: 0.5946, F1 Macro: 0.4806, Accuracy: 0.5946\n","Epoch 10, Train Loss: 0.6331, Val Loss: 0.6310, F1 Micro: 0.6982, F1 Macro: 0.6769, Accuracy: 0.6982\n","Epoch 11, Train Loss: 0.6242, Val Loss: 0.6389, F1 Micro: 0.6486, F1 Macro: 0.6047, Accuracy: 0.6486\n","Epoch 12, Train Loss: 0.6395, Val Loss: 0.6821, F1 Micro: 0.6126, F1 Macro: 0.4925, Accuracy: 0.6126\n","Epoch 13, Train Loss: 0.6296, Val Loss: 0.6901, F1 Micro: 0.6126, F1 Macro: 0.5189, Accuracy: 0.6126\n","Epoch 14, Train Loss: 0.6345, Val Loss: 0.6695, F1 Micro: 0.6351, F1 Macro: 0.5399, Accuracy: 0.6351\n","Epoch 15, Train Loss: 0.6464, Val Loss: 0.6425, F1 Micro: 0.6802, F1 Macro: 0.6390, Accuracy: 0.6802\n","Epoch 16, Train Loss: 0.6246, Val Loss: 0.6331, F1 Micro: 0.6667, F1 Macro: 0.6299, Accuracy: 0.6667\n","Epoch 17, Train Loss: 0.6280, Val Loss: 0.6312, F1 Micro: 0.6982, F1 Macro: 0.6659, Accuracy: 0.6982\n","Epoch 18, Train Loss: 0.6182, Val Loss: 0.6472, F1 Micro: 0.6622, F1 Macro: 0.6073, Accuracy: 0.6622\n","Epoch 19, Train Loss: 0.6411, Val Loss: 0.6513, F1 Micro: 0.6486, F1 Macro: 0.6189, Accuracy: 0.6486\n","Epoch 20, Train Loss: 0.6295, Val Loss: 0.6848, F1 Micro: 0.6036, F1 Macro: 0.5077, Accuracy: 0.6036\n","Epoch 21, Train Loss: 0.6302, Val Loss: 0.6372, F1 Micro: 0.6441, F1 Macro: 0.6010, Accuracy: 0.6441\n","Epoch 22, Train Loss: 0.6193, Val Loss: 0.6305, F1 Micro: 0.6937, F1 Macro: 0.6787, Accuracy: 0.6937\n","Epoch 23, Train Loss: 0.6533, Val Loss: 0.6408, F1 Micro: 0.6847, F1 Macro: 0.6476, Accuracy: 0.6847\n","Epoch 24, Train Loss: 0.6344, Val Loss: 0.6633, F1 Micro: 0.6216, F1 Macro: 0.5099, Accuracy: 0.6216\n","Epoch 25, Train Loss: 0.6223, Val Loss: 0.6322, F1 Micro: 0.6757, F1 Macro: 0.6696, Accuracy: 0.6757\n","Epoch 26, Train Loss: 0.6372, Val Loss: 0.6409, F1 Micro: 0.6757, F1 Macro: 0.6704, Accuracy: 0.6757\n","Epoch 27, Train Loss: 0.6322, Val Loss: 0.6516, F1 Micro: 0.6577, F1 Macro: 0.6094, Accuracy: 0.6577\n","Epoch 28, Train Loss: 0.6210, Val Loss: 0.6264, F1 Micro: 0.6892, F1 Macro: 0.6746, Accuracy: 0.6892\n","Epoch 29, Train Loss: 0.6390, Val Loss: 0.6422, F1 Micro: 0.6396, F1 Macro: 0.6386, Accuracy: 0.6396\n","Epoch 30, Train Loss: 0.6354, Val Loss: 0.6422, F1 Micro: 0.6622, F1 Macro: 0.6160, Accuracy: 0.6622\n","Epoch 31, Train Loss: 0.6253, Val Loss: 0.6371, F1 Micro: 0.6667, F1 Macro: 0.6365, Accuracy: 0.6667\n","Epoch 32, Train Loss: 0.6327, Val Loss: 0.6318, F1 Micro: 0.6757, F1 Macro: 0.6688, Accuracy: 0.6757\n","Epoch 33, Train Loss: 0.6172, Val Loss: 0.6413, F1 Micro: 0.6441, F1 Macro: 0.6420, Accuracy: 0.6441\n","Epoch 34, Train Loss: 0.6407, Val Loss: 0.6520, F1 Micro: 0.6441, F1 Macro: 0.6085, Accuracy: 0.6441\n","Epoch 35, Train Loss: 0.6282, Val Loss: 0.6259, F1 Micro: 0.6847, F1 Macro: 0.6692, Accuracy: 0.6847\n","Epoch 36, Train Loss: 0.6368, Val Loss: 0.6321, F1 Micro: 0.6892, F1 Macro: 0.6746, Accuracy: 0.6892\n","Epoch 37, Train Loss: 0.6381, Val Loss: 0.6462, F1 Micro: 0.6667, F1 Macro: 0.6110, Accuracy: 0.6667\n","Epoch 38, Train Loss: 0.6289, Val Loss: 0.6304, F1 Micro: 0.7027, F1 Macro: 0.6793, Accuracy: 0.7027\n","Epoch 39, Train Loss: 0.6219, Val Loss: 0.6484, F1 Micro: 0.6622, F1 Macro: 0.6073, Accuracy: 0.6622\n","Epoch 40, Train Loss: 0.6381, Val Loss: 0.6457, F1 Micro: 0.6577, F1 Macro: 0.6005, Accuracy: 0.6577\n","Epoch 41, Train Loss: 0.6297, Val Loss: 0.6365, F1 Micro: 0.6892, F1 Macro: 0.6538, Accuracy: 0.6892\n","Epoch 42, Train Loss: 0.6304, Val Loss: 0.6843, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 43, Train Loss: 0.6369, Val Loss: 0.6372, F1 Micro: 0.6577, F1 Macro: 0.6066, Accuracy: 0.6577\n","Epoch 44, Train Loss: 0.6242, Val Loss: 0.6251, F1 Micro: 0.6892, F1 Macro: 0.6793, Accuracy: 0.6892\n","Epoch 45, Train Loss: 0.6348, Val Loss: 0.6691, F1 Micro: 0.6261, F1 Macro: 0.5423, Accuracy: 0.6261\n","Epoch 46, Train Loss: 0.6359, Val Loss: 0.6490, F1 Micro: 0.6441, F1 Macro: 0.5760, Accuracy: 0.6441\n","Epoch 47, Train Loss: 0.6372, Val Loss: 0.6371, F1 Micro: 0.6486, F1 Macro: 0.6468, Accuracy: 0.6486\n","Epoch 48, Train Loss: 0.6270, Val Loss: 0.6425, F1 Micro: 0.6622, F1 Macro: 0.6073, Accuracy: 0.6622\n","Epoch 49, Train Loss: 0.6193, Val Loss: 0.6310, F1 Micro: 0.6712, F1 Macro: 0.6337, Accuracy: 0.6712\n","Epoch 50, Train Loss: 0.6272, Val Loss: 0.6353, F1 Micro: 0.6802, F1 Macro: 0.6414, Accuracy: 0.6802\n","Epoch 51, Train Loss: 0.6349, Val Loss: 0.6737, F1 Micro: 0.5901, F1 Macro: 0.4467, Accuracy: 0.5901\n","Epoch 52, Train Loss: 0.6387, Val Loss: 0.6379, F1 Micro: 0.6847, F1 Macro: 0.6428, Accuracy: 0.6847\n","Epoch 53, Train Loss: 0.6208, Val Loss: 0.6388, F1 Micro: 0.6396, F1 Macro: 0.5918, Accuracy: 0.6396\n","Epoch 54, Train Loss: 0.6249, Val Loss: 0.6496, F1 Micro: 0.6441, F1 Macro: 0.5760, Accuracy: 0.6441\n","Epoch 55, Train Loss: 0.6284, Val Loss: 0.6344, F1 Micro: 0.7162, F1 Macro: 0.7041, Accuracy: 0.7162\n","Epoch 56, Train Loss: 0.6231, Val Loss: 0.6379, F1 Micro: 0.7027, F1 Macro: 0.6758, Accuracy: 0.7027\n","Epoch 57, Train Loss: 0.6182, Val Loss: 0.6519, F1 Micro: 0.6667, F1 Macro: 0.6422, Accuracy: 0.6667\n","Epoch 58, Train Loss: 0.6298, Val Loss: 0.6326, F1 Micro: 0.6757, F1 Macro: 0.6696, Accuracy: 0.6757\n","Epoch 59, Train Loss: 0.6222, Val Loss: 0.6542, F1 Micro: 0.6351, F1 Macro: 0.5533, Accuracy: 0.6351\n","Epoch 60, Train Loss: 0.6107, Val Loss: 0.6274, F1 Micro: 0.6667, F1 Macro: 0.6343, Accuracy: 0.6667\n","Epoch 61, Train Loss: 0.6280, Val Loss: 0.6312, F1 Micro: 0.6892, F1 Macro: 0.6771, Accuracy: 0.6892\n","Epoch 62, Train Loss: 0.6240, Val Loss: 0.6305, F1 Micro: 0.7027, F1 Macro: 0.6758, Accuracy: 0.7027\n","Epoch 63, Train Loss: 0.6187, Val Loss: 0.6360, F1 Micro: 0.6486, F1 Macro: 0.5931, Accuracy: 0.6486\n","Epoch 64, Train Loss: 0.6245, Val Loss: 0.6627, F1 Micro: 0.6081, F1 Macro: 0.5203, Accuracy: 0.6081\n","Epoch 65, Train Loss: 0.6335, Val Loss: 0.6507, F1 Micro: 0.6396, F1 Macro: 0.5524, Accuracy: 0.6396\n","Epoch 66, Train Loss: 0.6328, Val Loss: 0.6265, F1 Micro: 0.6937, F1 Macro: 0.6812, Accuracy: 0.6937\n","Epoch 67, Train Loss: 0.6267, Val Loss: 0.6543, F1 Micro: 0.6486, F1 Macro: 0.5831, Accuracy: 0.6486\n","Epoch 68, Train Loss: 0.6259, Val Loss: 0.6331, F1 Micro: 0.6757, F1 Macro: 0.6598, Accuracy: 0.6757\n","Epoch 69, Train Loss: 0.6307, Val Loss: 0.6311, F1 Micro: 0.6622, F1 Macro: 0.6260, Accuracy: 0.6622\n","Epoch 70, Train Loss: 0.6336, Val Loss: 0.6249, F1 Micro: 0.6982, F1 Macro: 0.6769, Accuracy: 0.6982\n","Epoch 71, Train Loss: 0.6205, Val Loss: 0.6441, F1 Micro: 0.6486, F1 Macro: 0.5831, Accuracy: 0.6486\n","Epoch 72, Train Loss: 0.6299, Val Loss: 0.6396, F1 Micro: 0.6532, F1 Macro: 0.5999, Accuracy: 0.6532\n","Epoch 73, Train Loss: 0.6312, Val Loss: 0.6265, F1 Micro: 0.6982, F1 Macro: 0.6736, Accuracy: 0.6982\n","Epoch 74, Train Loss: 0.6253, Val Loss: 0.6530, F1 Micro: 0.6486, F1 Macro: 0.5831, Accuracy: 0.6486\n","Epoch 75, Train Loss: 0.6217, Val Loss: 0.6286, F1 Micro: 0.6802, F1 Macro: 0.6481, Accuracy: 0.6802\n","Epoch 76, Train Loss: 0.6339, Val Loss: 0.6245, F1 Micro: 0.6847, F1 Macro: 0.6580, Accuracy: 0.6847\n","Epoch 77, Train Loss: 0.6308, Val Loss: 0.7282, F1 Micro: 0.5676, F1 Macro: 0.3805, Accuracy: 0.5676\n","Epoch 78, Train Loss: 0.6212, Val Loss: 0.6334, F1 Micro: 0.6532, F1 Macro: 0.6029, Accuracy: 0.6532\n","Epoch 79, Train Loss: 0.6195, Val Loss: 0.6604, F1 Micro: 0.6577, F1 Macro: 0.5938, Accuracy: 0.6577\n","Epoch 80, Train Loss: 0.6336, Val Loss: 0.6663, F1 Micro: 0.6351, F1 Macro: 0.5575, Accuracy: 0.6351\n","Epoch 81, Train Loss: 0.6217, Val Loss: 0.6440, F1 Micro: 0.6757, F1 Macro: 0.6244, Accuracy: 0.6757\n","Epoch 82, Train Loss: 0.6201, Val Loss: 0.6423, F1 Micro: 0.6396, F1 Macro: 0.5889, Accuracy: 0.6396\n","Epoch 83, Train Loss: 0.6264, Val Loss: 0.6292, F1 Micro: 0.6892, F1 Macro: 0.6560, Accuracy: 0.6892\n","Epoch 84, Train Loss: 0.6221, Val Loss: 0.6425, F1 Micro: 0.6622, F1 Macro: 0.6132, Accuracy: 0.6622\n","Epoch 85, Train Loss: 0.6208, Val Loss: 0.6287, F1 Micro: 0.6712, F1 Macro: 0.6337, Accuracy: 0.6712\n","Epoch 86, Train Loss: 0.6250, Val Loss: 0.6452, F1 Micro: 0.6532, F1 Macro: 0.5902, Accuracy: 0.6532\n","Epoch 87, Train Loss: 0.6393, Val Loss: 0.6436, F1 Micro: 0.6306, F1 Macro: 0.5580, Accuracy: 0.6306\n","Epoch 88, Train Loss: 0.6343, Val Loss: 0.6318, F1 Micro: 0.6667, F1 Macro: 0.6299, Accuracy: 0.6667\n","Epoch 89, Train Loss: 0.6307, Val Loss: 0.6327, F1 Micro: 0.6802, F1 Macro: 0.6522, Accuracy: 0.6802\n","Epoch 90, Train Loss: 0.6274, Val Loss: 0.6327, F1 Micro: 0.6667, F1 Macro: 0.6250, Accuracy: 0.6667\n","Epoch 91, Train Loss: 0.6209, Val Loss: 0.6260, F1 Micro: 0.6937, F1 Macro: 0.6834, Accuracy: 0.6937\n","Epoch 92, Train Loss: 0.6346, Val Loss: 0.6306, F1 Micro: 0.6892, F1 Macro: 0.6538, Accuracy: 0.6892\n","Epoch 93, Train Loss: 0.6266, Val Loss: 0.6459, F1 Micro: 0.6577, F1 Macro: 0.6005, Accuracy: 0.6577\n","Epoch 94, Train Loss: 0.6322, Val Loss: 0.6480, F1 Micro: 0.6441, F1 Macro: 0.5760, Accuracy: 0.6441\n","Epoch 95, Train Loss: 0.6238, Val Loss: 0.6247, F1 Micro: 0.7072, F1 Macro: 0.6909, Accuracy: 0.7072\n","Epoch 96, Train Loss: 0.6164, Val Loss: 0.6462, F1 Micro: 0.6802, F1 Macro: 0.6778, Accuracy: 0.6802\n","Epoch 97, Train Loss: 0.6420, Val Loss: 0.6558, F1 Micro: 0.6081, F1 Macro: 0.5108, Accuracy: 0.6081\n","Epoch 98, Train Loss: 0.6271, Val Loss: 0.6587, F1 Micro: 0.5991, F1 Macro: 0.4891, Accuracy: 0.5991\n","Epoch 99, Train Loss: 0.6252, Val Loss: 0.6353, F1 Micro: 0.6577, F1 Macro: 0.6122, Accuracy: 0.6577\n","Epoch 100, Train Loss: 0.6218, Val Loss: 0.6332, F1 Micro: 0.6667, F1 Macro: 0.6343, Accuracy: 0.6667\n","Epoch 101, Train Loss: 0.6238, Val Loss: 0.6388, F1 Micro: 0.6532, F1 Macro: 0.5936, Accuracy: 0.6532\n","Epoch 102, Train Loss: 0.6203, Val Loss: 0.6261, F1 Micro: 0.6937, F1 Macro: 0.6894, Accuracy: 0.6937\n","Epoch 103, Train Loss: 0.6289, Val Loss: 0.6339, F1 Micro: 0.6622, F1 Macro: 0.6132, Accuracy: 0.6622\n","Epoch 104, Train Loss: 0.6073, Val Loss: 0.6555, F1 Micro: 0.6351, F1 Macro: 0.5575, Accuracy: 0.6351\n","Epoch 105, Train Loss: 0.6288, Val Loss: 0.6250, F1 Micro: 0.6847, F1 Macro: 0.6616, Accuracy: 0.6847\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6847, F1 Macro: 0.6616, Accuracy: 0.6847\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.9829, Val Loss: 0.9101, F1 Micro: 0.4413, F1 Macro: 0.4135, Accuracy: 0.4413\n","Epoch 2, Train Loss: 0.7180, Val Loss: 0.7622, F1 Micro: 0.5140, F1 Macro: 0.5137, Accuracy: 0.5140\n","Epoch 3, Train Loss: 0.6783, Val Loss: 0.7571, F1 Micro: 0.5475, F1 Macro: 0.5058, Accuracy: 0.5475\n","Epoch 4, Train Loss: 0.6800, Val Loss: 0.6682, F1 Micro: 0.6257, F1 Macro: 0.5992, Accuracy: 0.6257\n","Epoch 5, Train Loss: 0.6489, Val Loss: 0.6651, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 6, Train Loss: 0.6616, Val Loss: 0.6959, F1 Micro: 0.6201, F1 Macro: 0.5865, Accuracy: 0.6201\n","Epoch 7, Train Loss: 0.6561, Val Loss: 0.6866, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.6370, Val Loss: 0.6524, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 9, Train Loss: 0.6619, Val Loss: 0.6885, F1 Micro: 0.6760, F1 Macro: 0.5413, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.6389, Val Loss: 0.6472, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 11, Train Loss: 0.6455, Val Loss: 0.6498, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 12, Train Loss: 0.6501, Val Loss: 0.6456, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 13, Train Loss: 0.6605, Val Loss: 0.6418, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 14, Train Loss: 0.6389, Val Loss: 0.6539, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 15, Train Loss: 0.6472, Val Loss: 0.6454, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 16, Train Loss: 0.6321, Val Loss: 0.6545, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 17, Train Loss: 0.6374, Val Loss: 0.6652, F1 Micro: 0.6927, F1 Macro: 0.5888, Accuracy: 0.6927\n","Epoch 18, Train Loss: 0.6451, Val Loss: 0.6503, F1 Micro: 0.7151, F1 Macro: 0.6817, Accuracy: 0.7151\n","Epoch 19, Train Loss: 0.6343, Val Loss: 0.6615, F1 Micro: 0.6648, F1 Macro: 0.6400, Accuracy: 0.6648\n","Epoch 20, Train Loss: 0.6409, Val Loss: 0.6314, F1 Micro: 0.7374, F1 Macro: 0.6797, Accuracy: 0.7374\n","Epoch 21, Train Loss: 0.6450, Val Loss: 0.6596, F1 Micro: 0.6536, F1 Macro: 0.6081, Accuracy: 0.6536\n","Epoch 22, Train Loss: 0.6342, Val Loss: 0.6624, F1 Micro: 0.6257, F1 Macro: 0.6080, Accuracy: 0.6257\n","Epoch 23, Train Loss: 0.6384, Val Loss: 0.6519, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Epoch 24, Train Loss: 0.6365, Val Loss: 0.6623, F1 Micro: 0.6983, F1 Macro: 0.6717, Accuracy: 0.6983\n","Epoch 25, Train Loss: 0.6429, Val Loss: 0.6491, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 26, Train Loss: 0.6383, Val Loss: 0.6244, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 27, Train Loss: 0.6373, Val Loss: 0.6460, F1 Micro: 0.7263, F1 Macro: 0.6801, Accuracy: 0.7263\n","Epoch 28, Train Loss: 0.6302, Val Loss: 0.6882, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 29, Train Loss: 0.6387, Val Loss: 0.6576, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 30, Train Loss: 0.6368, Val Loss: 0.6466, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.8828, Val Loss: 0.8218, F1 Micro: 0.4101, F1 Macro: 0.4086, Accuracy: 0.4101\n","Epoch 2, Train Loss: 0.7619, Val Loss: 0.6385, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.7327, Val Loss: 0.6114, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 4, Train Loss: 0.6592, Val Loss: 0.6271, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6687, Val Loss: 0.6131, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 6, Train Loss: 0.6544, Val Loss: 0.6476, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 7, Train Loss: 0.6639, Val Loss: 0.6491, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 8, Train Loss: 0.6683, Val Loss: 0.6425, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6647, Val Loss: 0.6235, F1 Micro: 0.6798, F1 Macro: 0.5364, Accuracy: 0.6798\n","Epoch 10, Train Loss: 0.6442, Val Loss: 0.5953, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 11, Train Loss: 0.6392, Val Loss: 0.6031, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 12, Train Loss: 0.6329, Val Loss: 0.6082, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.6497, Val Loss: 0.6035, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 14, Train Loss: 0.6504, Val Loss: 0.6335, F1 Micro: 0.6966, F1 Macro: 0.6821, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6473, Val Loss: 0.6190, F1 Micro: 0.6573, F1 Macro: 0.4634, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6442, Val Loss: 0.6206, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 17, Train Loss: 0.6486, Val Loss: 0.6163, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 18, Train Loss: 0.6577, Val Loss: 0.6100, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 19, Train Loss: 0.6325, Val Loss: 0.5984, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 20, Train Loss: 0.6576, Val Loss: 0.6131, F1 Micro: 0.6573, F1 Macro: 0.4848, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.8476, Val Loss: 0.8696, F1 Micro: 0.4101, F1 Macro: 0.3659, Accuracy: 0.4101\n","Epoch 2, Train Loss: 0.7458, Val Loss: 1.0484, F1 Micro: 0.3427, F1 Macro: 0.2888, Accuracy: 0.3427\n","Epoch 3, Train Loss: 0.7329, Val Loss: 0.7048, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6688, Val Loss: 0.6387, F1 Micro: 0.6067, F1 Macro: 0.4795, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.6507, Val Loss: 0.6867, F1 Micro: 0.6180, F1 Macro: 0.6156, Accuracy: 0.6180\n","Epoch 6, Train Loss: 0.6705, Val Loss: 0.6491, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6532, Val Loss: 0.6414, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6428, Val Loss: 0.6835, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6381, Val Loss: 0.6865, F1 Micro: 0.6348, F1 Macro: 0.6345, Accuracy: 0.6348\n","Epoch 10, Train Loss: 0.6247, Val Loss: 0.7882, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6423, Val Loss: 0.6875, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6367, Val Loss: 0.6549, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 13, Train Loss: 0.6532, Val Loss: 0.6678, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6360, Val Loss: 0.6279, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6470, Val Loss: 0.6330, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6356, Val Loss: 0.6605, F1 Micro: 0.5899, F1 Macro: 0.5692, Accuracy: 0.5899\n","Epoch 17, Train Loss: 0.6440, Val Loss: 0.6428, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7936, Val Loss: 1.2860, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 2, Train Loss: 0.7684, Val Loss: 0.7875, F1 Micro: 0.5337, F1 Macro: 0.5076, Accuracy: 0.5337\n","Epoch 3, Train Loss: 0.7047, Val Loss: 0.7331, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 4, Train Loss: 0.6621, Val Loss: 0.8256, F1 Micro: 0.5562, F1 Macro: 0.5165, Accuracy: 0.5562\n","Epoch 5, Train Loss: 0.6629, Val Loss: 0.7162, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6735, Val Loss: 0.8225, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 7, Train Loss: 0.6338, Val Loss: 0.7063, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6422, Val Loss: 0.6666, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6474, Val Loss: 0.7044, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6341, Val Loss: 0.7087, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6358, Val Loss: 0.7170, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6475, Val Loss: 0.6828, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 13, Train Loss: 0.6459, Val Loss: 0.6610, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6316, Val Loss: 0.7066, F1 Micro: 0.5787, F1 Macro: 0.5138, Accuracy: 0.5787\n","Epoch 15, Train Loss: 0.6422, Val Loss: 0.6715, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6319, Val Loss: 0.6861, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6417, Val Loss: 0.6601, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.6355, Val Loss: 0.7072, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.9856, Val Loss: 0.9015, F1 Micro: 0.4270, F1 Macro: 0.4267, Accuracy: 0.4270\n","Epoch 2, Train Loss: 0.7261, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.5902, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6784, Val Loss: 0.7066, F1 Micro: 0.6236, F1 Macro: 0.5423, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6723, Val Loss: 0.7237, F1 Micro: 0.5955, F1 Macro: 0.3977, Accuracy: 0.5955\n","Epoch 5, Train Loss: 0.6578, Val Loss: 0.6807, F1 Micro: 0.6404, F1 Macro: 0.5550, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6345, Val Loss: 0.6708, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 7, Train Loss: 0.6565, Val Loss: 0.6674, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 8, Train Loss: 0.6496, Val Loss: 0.6835, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6465, Val Loss: 0.6494, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6432, Val Loss: 0.6596, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6320, Val Loss: 0.6706, F1 Micro: 0.6124, F1 Macro: 0.6002, Accuracy: 0.6124\n","Epoch 12, Train Loss: 0.6417, Val Loss: 0.6639, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.6303, Val Loss: 0.7212, F1 Micro: 0.5562, F1 Macro: 0.5555, Accuracy: 0.5562\n","Epoch 14, Train Loss: 0.6492, Val Loss: 0.6825, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6399, Val Loss: 0.7051, F1 Micro: 0.5787, F1 Macro: 0.5776, Accuracy: 0.5787\n","Epoch 16, Train Loss: 0.6328, Val Loss: 0.6907, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6450, Val Loss: 0.6966, F1 Micro: 0.5506, F1 Macro: 0.5503, Accuracy: 0.5506\n","Epoch 18, Train Loss: 0.6398, Val Loss: 0.6545, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 19, Train Loss: 0.6291, Val Loss: 0.6636, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 20, Train Loss: 0.6406, Val Loss: 0.6489, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 21, Train Loss: 0.6396, Val Loss: 0.6938, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 22, Train Loss: 0.6416, Val Loss: 0.6903, F1 Micro: 0.6180, F1 Macro: 0.6083, Accuracy: 0.6180\n","Epoch 23, Train Loss: 0.6310, Val Loss: 0.6917, F1 Micro: 0.6124, F1 Macro: 0.4979, Accuracy: 0.6124\n","Epoch 24, Train Loss: 0.6320, Val Loss: 0.6928, F1 Micro: 0.6180, F1 Macro: 0.6096, Accuracy: 0.6180\n","Epoch 25, Train Loss: 0.6417, Val Loss: 0.6714, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6458, Val Loss: 0.6667, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6388, Val Loss: 0.6652, F1 Micro: 0.6573, F1 Macro: 0.6492, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.6342, Val Loss: 0.6821, F1 Micro: 0.5955, F1 Macro: 0.5802, Accuracy: 0.5955\n","Epoch 29, Train Loss: 0.6353, Val Loss: 0.6660, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6426, Val Loss: 0.6641, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.7025422132948339\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.9611, Val Loss: 0.7293, F1 Micro: 0.6369, F1 Macro: 0.5943, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6982, Val Loss: 0.6614, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 3, Train Loss: 0.6675, Val Loss: 0.6714, F1 Micro: 0.6760, F1 Macro: 0.5413, Accuracy: 0.6760\n","Epoch 4, Train Loss: 0.6852, Val Loss: 0.6526, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 5, Train Loss: 0.6690, Val Loss: 0.6544, F1 Micro: 0.6872, F1 Macro: 0.5410, Accuracy: 0.6872\n","Epoch 6, Train Loss: 0.6468, Val Loss: 0.6878, F1 Micro: 0.5978, F1 Macro: 0.5884, Accuracy: 0.5978\n","Epoch 7, Train Loss: 0.6480, Val Loss: 0.6589, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.6483, Val Loss: 0.6419, F1 Micro: 0.7095, F1 Macro: 0.6767, Accuracy: 0.7095\n","Epoch 9, Train Loss: 0.6604, Val Loss: 0.6397, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 10, Train Loss: 0.6493, Val Loss: 0.6460, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 11, Train Loss: 0.6454, Val Loss: 0.6682, F1 Micro: 0.6816, F1 Macro: 0.5371, Accuracy: 0.6816\n","Epoch 12, Train Loss: 0.6373, Val Loss: 0.6569, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 13, Train Loss: 0.6348, Val Loss: 0.6606, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 14, Train Loss: 0.6429, Val Loss: 0.6358, F1 Micro: 0.7207, F1 Macro: 0.6612, Accuracy: 0.7207\n","Epoch 15, Train Loss: 0.6380, Val Loss: 0.6551, F1 Micro: 0.6313, F1 Macro: 0.6109, Accuracy: 0.6313\n","Epoch 16, Train Loss: 0.6459, Val Loss: 0.6740, F1 Micro: 0.6089, F1 Macro: 0.5984, Accuracy: 0.6089\n","Epoch 17, Train Loss: 0.6442, Val Loss: 0.6531, F1 Micro: 0.6872, F1 Macro: 0.6205, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.6398, Val Loss: 0.6350, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 19, Train Loss: 0.6561, Val Loss: 0.6479, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 20, Train Loss: 0.6539, Val Loss: 0.6662, F1 Micro: 0.6927, F1 Macro: 0.5533, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6422, Val Loss: 0.6367, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 22, Train Loss: 0.6417, Val Loss: 0.6440, F1 Micro: 0.6872, F1 Macro: 0.6571, Accuracy: 0.6872\n","Epoch 23, Train Loss: 0.6526, Val Loss: 0.6516, F1 Micro: 0.6872, F1 Macro: 0.5715, Accuracy: 0.6872\n","Epoch 24, Train Loss: 0.6310, Val Loss: 0.6465, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 25, Train Loss: 0.6448, Val Loss: 0.6787, F1 Micro: 0.6927, F1 Macro: 0.5612, Accuracy: 0.6927\n","Epoch 26, Train Loss: 0.6370, Val Loss: 0.6507, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 27, Train Loss: 0.6467, Val Loss: 0.6360, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 28, Train Loss: 0.6362, Val Loss: 0.6480, F1 Micro: 0.6816, F1 Macro: 0.5603, Accuracy: 0.6816\n","Epoch 29, Train Loss: 0.6309, Val Loss: 0.6787, F1 Micro: 0.6872, F1 Macro: 0.5645, Accuracy: 0.6872\n","Epoch 30, Train Loss: 0.6476, Val Loss: 0.6377, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 31, Train Loss: 0.6479, Val Loss: 0.6630, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 32, Train Loss: 0.6488, Val Loss: 0.6549, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 33, Train Loss: 0.6487, Val Loss: 0.6879, F1 Micro: 0.6313, F1 Macro: 0.6109, Accuracy: 0.6313\n","Epoch 34, Train Loss: 0.6409, Val Loss: 0.6607, F1 Micro: 0.7039, F1 Macro: 0.6429, Accuracy: 0.7039\n","Epoch 35, Train Loss: 0.6298, Val Loss: 0.6897, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 36, Train Loss: 0.6530, Val Loss: 0.6461, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 37, Train Loss: 0.6458, Val Loss: 0.6512, F1 Micro: 0.6704, F1 Macro: 0.5119, Accuracy: 0.6704\n","Epoch 38, Train Loss: 0.6407, Val Loss: 0.6499, F1 Micro: 0.6704, F1 Macro: 0.5715, Accuracy: 0.6704\n","Epoch 39, Train Loss: 0.6351, Val Loss: 0.6544, F1 Micro: 0.6760, F1 Macro: 0.5630, Accuracy: 0.6760\n","Epoch 40, Train Loss: 0.6322, Val Loss: 0.6490, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 41, Train Loss: 0.6314, Val Loss: 0.7186, F1 Micro: 0.6592, F1 Macro: 0.6017, Accuracy: 0.6592\n","Epoch 42, Train Loss: 0.6450, Val Loss: 0.6451, F1 Micro: 0.7151, F1 Macro: 0.6790, Accuracy: 0.7151\n","Epoch 43, Train Loss: 0.6507, Val Loss: 0.6351, F1 Micro: 0.7542, F1 Macro: 0.7113, Accuracy: 0.7542\n","Epoch 44, Train Loss: 0.6371, Val Loss: 0.6359, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 45, Train Loss: 0.6301, Val Loss: 0.6482, F1 Micro: 0.6760, F1 Macro: 0.6474, Accuracy: 0.6760\n","Epoch 46, Train Loss: 0.6457, Val Loss: 0.6606, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 47, Train Loss: 0.6426, Val Loss: 0.6480, F1 Micro: 0.6872, F1 Macro: 0.6247, Accuracy: 0.6872\n","Epoch 48, Train Loss: 0.6436, Val Loss: 0.6586, F1 Micro: 0.6257, F1 Macro: 0.6080, Accuracy: 0.6257\n","Epoch 49, Train Loss: 0.6268, Val Loss: 0.6361, F1 Micro: 0.7318, F1 Macro: 0.6670, Accuracy: 0.7318\n","Epoch 50, Train Loss: 0.6309, Val Loss: 0.6601, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 51, Train Loss: 0.6400, Val Loss: 0.6422, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 52, Train Loss: 0.6489, Val Loss: 0.6534, F1 Micro: 0.6983, F1 Macro: 0.6616, Accuracy: 0.6983\n","Epoch 53, Train Loss: 0.6407, Val Loss: 0.6628, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 54, Train Loss: 0.6384, Val Loss: 0.6430, F1 Micro: 0.7095, F1 Macro: 0.6249, Accuracy: 0.7095\n","Epoch 55, Train Loss: 0.6408, Val Loss: 0.6367, F1 Micro: 0.7374, F1 Macro: 0.6797, Accuracy: 0.7374\n","Epoch 56, Train Loss: 0.6472, Val Loss: 0.6472, F1 Micro: 0.7207, F1 Macro: 0.6891, Accuracy: 0.7207\n","Epoch 57, Train Loss: 0.6359, Val Loss: 0.6414, F1 Micro: 0.7318, F1 Macro: 0.6818, Accuracy: 0.7318\n","Epoch 58, Train Loss: 0.6414, Val Loss: 0.6403, F1 Micro: 0.6927, F1 Macro: 0.6620, Accuracy: 0.6927\n","Epoch 59, Train Loss: 0.6392, Val Loss: 0.6438, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 60, Train Loss: 0.6309, Val Loss: 0.6649, F1 Micro: 0.6872, F1 Macro: 0.5844, Accuracy: 0.6872\n","Epoch 61, Train Loss: 0.6375, Val Loss: 0.6541, F1 Micro: 0.6480, F1 Macro: 0.6254, Accuracy: 0.6480\n","Epoch 62, Train Loss: 0.6457, Val Loss: 0.6361, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 63, Train Loss: 0.6467, Val Loss: 0.6757, F1 Micro: 0.6983, F1 Macro: 0.5868, Accuracy: 0.6983\n","Epoch 64, Train Loss: 0.6356, Val Loss: 0.6411, F1 Micro: 0.7374, F1 Macro: 0.6961, Accuracy: 0.7374\n","Epoch 65, Train Loss: 0.6341, Val Loss: 0.6400, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 66, Train Loss: 0.6307, Val Loss: 0.6741, F1 Micro: 0.6034, F1 Macro: 0.5903, Accuracy: 0.6034\n","Epoch 67, Train Loss: 0.6342, Val Loss: 0.6469, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 68, Train Loss: 0.6534, Val Loss: 0.6607, F1 Micro: 0.6592, F1 Macro: 0.4752, Accuracy: 0.6592\n","Epoch 69, Train Loss: 0.6431, Val Loss: 0.6333, F1 Micro: 0.7430, F1 Macro: 0.6883, Accuracy: 0.7430\n","Epoch 70, Train Loss: 0.6381, Val Loss: 0.6714, F1 Micro: 0.6648, F1 Macro: 0.5611, Accuracy: 0.6648\n","Epoch 71, Train Loss: 0.6419, Val Loss: 0.6862, F1 Micro: 0.6257, F1 Macro: 0.6099, Accuracy: 0.6257\n","Epoch 72, Train Loss: 0.6418, Val Loss: 0.6357, F1 Micro: 0.7318, F1 Macro: 0.6939, Accuracy: 0.7318\n","Epoch 73, Train Loss: 0.6507, Val Loss: 0.6645, F1 Micro: 0.6480, F1 Macro: 0.6001, Accuracy: 0.6480\n","Epoch 74, Train Loss: 0.6389, Val Loss: 0.6439, F1 Micro: 0.6816, F1 Macro: 0.6413, Accuracy: 0.6816\n","Epoch 75, Train Loss: 0.6388, Val Loss: 0.6911, F1 Micro: 0.6872, F1 Macro: 0.5715, Accuracy: 0.6872\n","Epoch 76, Train Loss: 0.6424, Val Loss: 0.6734, F1 Micro: 0.6704, F1 Macro: 0.5589, Accuracy: 0.6704\n","Epoch 77, Train Loss: 0.6389, Val Loss: 0.6564, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 78, Train Loss: 0.6532, Val Loss: 0.6389, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 79, Train Loss: 0.6352, Val Loss: 0.6642, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 80, Train Loss: 0.6409, Val Loss: 0.6445, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 81, Train Loss: 0.6363, Val Loss: 0.6533, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 82, Train Loss: 0.6302, Val Loss: 0.6461, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 83, Train Loss: 0.6523, Val Loss: 0.6413, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 84, Train Loss: 0.6372, Val Loss: 0.6407, F1 Micro: 0.7263, F1 Macro: 0.6916, Accuracy: 0.7263\n","Epoch 85, Train Loss: 0.6367, Val Loss: 0.6540, F1 Micro: 0.6257, F1 Macro: 0.6080, Accuracy: 0.6257\n","Epoch 86, Train Loss: 0.6362, Val Loss: 0.6540, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 87, Train Loss: 0.6307, Val Loss: 0.6711, F1 Micro: 0.6592, F1 Macro: 0.6161, Accuracy: 0.6592\n","Epoch 88, Train Loss: 0.6343, Val Loss: 0.6459, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 89, Train Loss: 0.6324, Val Loss: 0.6409, F1 Micro: 0.6704, F1 Macro: 0.5208, Accuracy: 0.6704\n","Epoch 90, Train Loss: 0.6455, Val Loss: 0.6547, F1 Micro: 0.6760, F1 Macro: 0.6497, Accuracy: 0.6760\n","Epoch 91, Train Loss: 0.6417, Val Loss: 0.6456, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 92, Train Loss: 0.6306, Val Loss: 0.6521, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 93, Train Loss: 0.6428, Val Loss: 0.6439, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.9476, Val Loss: 0.6871, F1 Micro: 0.6461, F1 Macro: 0.4875, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.7700, Val Loss: 0.6527, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 3, Train Loss: 0.7078, Val Loss: 0.6526, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6955, Val Loss: 0.6150, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 5, Train Loss: 0.6655, Val Loss: 0.6213, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6505, Val Loss: 0.5994, F1 Micro: 0.7079, F1 Macro: 0.5880, Accuracy: 0.7079\n","Epoch 7, Train Loss: 0.6625, Val Loss: 0.6263, F1 Micro: 0.6629, F1 Macro: 0.4981, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6372, Val Loss: 0.6052, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 9, Train Loss: 0.6510, Val Loss: 0.6420, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 10, Train Loss: 0.6732, Val Loss: 0.6231, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 11, Train Loss: 0.6460, Val Loss: 0.6168, F1 Micro: 0.6742, F1 Macro: 0.5239, Accuracy: 0.6742\n","Epoch 12, Train Loss: 0.6539, Val Loss: 0.5884, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 13, Train Loss: 0.6562, Val Loss: 0.6182, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6623, Val Loss: 0.6179, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6473, Val Loss: 0.6128, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.6582, Val Loss: 0.6296, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6470, Val Loss: 0.6161, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 18, Train Loss: 0.6363, Val Loss: 0.5855, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 19, Train Loss: 0.6468, Val Loss: 0.6146, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.6299, Val Loss: 0.5924, F1 Micro: 0.7360, F1 Macro: 0.6670, Accuracy: 0.7360\n","Epoch 21, Train Loss: 0.6583, Val Loss: 0.6010, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 22, Train Loss: 0.6539, Val Loss: 0.5991, F1 Micro: 0.7191, F1 Macro: 0.6434, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6376, Val Loss: 0.5987, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 24, Train Loss: 0.6551, Val Loss: 0.6079, F1 Micro: 0.6798, F1 Macro: 0.5364, Accuracy: 0.6798\n","Epoch 25, Train Loss: 0.6628, Val Loss: 0.6241, F1 Micro: 0.6517, F1 Macro: 0.4488, Accuracy: 0.6517\n","Epoch 26, Train Loss: 0.6459, Val Loss: 0.6120, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 27, Train Loss: 0.6477, Val Loss: 0.6274, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 28, Train Loss: 0.6511, Val Loss: 0.6168, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 29, Train Loss: 0.6361, Val Loss: 0.6098, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 30, Train Loss: 0.6463, Val Loss: 0.6149, F1 Micro: 0.7360, F1 Macro: 0.6712, Accuracy: 0.7360\n","Epoch 31, Train Loss: 0.6331, Val Loss: 0.6076, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 32, Train Loss: 0.6464, Val Loss: 0.6404, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 33, Train Loss: 0.6542, Val Loss: 0.6102, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 34, Train Loss: 0.6438, Val Loss: 0.6157, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 35, Train Loss: 0.6488, Val Loss: 0.6336, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.6343, Val Loss: 0.6338, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6544, Val Loss: 0.5998, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 38, Train Loss: 0.6428, Val Loss: 0.6658, F1 Micro: 0.6854, F1 Macro: 0.6720, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6563, Val Loss: 0.6874, F1 Micro: 0.6461, F1 Macro: 0.5876, Accuracy: 0.6461\n","Epoch 40, Train Loss: 0.6246, Val Loss: 0.5981, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 41, Train Loss: 0.6510, Val Loss: 0.6048, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 42, Train Loss: 0.6510, Val Loss: 0.6241, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 43, Train Loss: 0.6493, Val Loss: 0.6179, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6493, Val Loss: 0.6130, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 45, Train Loss: 0.6584, Val Loss: 0.6002, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 46, Train Loss: 0.6447, Val Loss: 0.6093, F1 Micro: 0.6461, F1 Macro: 0.4572, Accuracy: 0.6461\n","Epoch 47, Train Loss: 0.6398, Val Loss: 0.6114, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 48, Train Loss: 0.6515, Val Loss: 0.6027, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 49, Train Loss: 0.6387, Val Loss: 0.5988, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 50, Train Loss: 0.6379, Val Loss: 0.5963, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 51, Train Loss: 0.6429, Val Loss: 0.6265, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 52, Train Loss: 0.6469, Val Loss: 0.6086, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 53, Train Loss: 0.6371, Val Loss: 0.5853, F1 Micro: 0.7360, F1 Macro: 0.6752, Accuracy: 0.7360\n","Epoch 54, Train Loss: 0.6609, Val Loss: 0.6146, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 55, Train Loss: 0.6507, Val Loss: 0.6510, F1 Micro: 0.7247, F1 Macro: 0.6653, Accuracy: 0.7247\n","Epoch 56, Train Loss: 0.6486, Val Loss: 0.6001, F1 Micro: 0.7528, F1 Macro: 0.7106, Accuracy: 0.7528\n","Epoch 57, Train Loss: 0.6497, Val Loss: 0.6044, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 58, Train Loss: 0.6429, Val Loss: 0.6065, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 59, Train Loss: 0.6572, Val Loss: 0.6099, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 60, Train Loss: 0.6580, Val Loss: 0.6052, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 61, Train Loss: 0.6445, Val Loss: 0.6148, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6458, Val Loss: 0.6038, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 63, Train Loss: 0.6395, Val Loss: 0.6377, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 64, Train Loss: 0.6450, Val Loss: 0.6073, F1 Micro: 0.7247, F1 Macro: 0.6528, Accuracy: 0.7247\n","Epoch 65, Train Loss: 0.6360, Val Loss: 0.6204, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 66, Train Loss: 0.6484, Val Loss: 0.6108, F1 Micro: 0.6517, F1 Macro: 0.4488, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.6397, Val Loss: 0.6230, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 68, Train Loss: 0.6491, Val Loss: 0.6014, F1 Micro: 0.7584, F1 Macro: 0.7157, Accuracy: 0.7584\n","Epoch 69, Train Loss: 0.6469, Val Loss: 0.5992, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 70, Train Loss: 0.6408, Val Loss: 0.6481, F1 Micro: 0.5674, F1 Macro: 0.5658, Accuracy: 0.5674\n","Epoch 71, Train Loss: 0.6394, Val Loss: 0.6016, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 72, Train Loss: 0.6421, Val Loss: 0.6193, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 73, Train Loss: 0.6453, Val Loss: 0.6193, F1 Micro: 0.6742, F1 Macro: 0.5239, Accuracy: 0.6742\n","Epoch 74, Train Loss: 0.6420, Val Loss: 0.5977, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 75, Train Loss: 0.6299, Val Loss: 0.6051, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 76, Train Loss: 0.6422, Val Loss: 0.6332, F1 Micro: 0.7079, F1 Macro: 0.6339, Accuracy: 0.7079\n","Epoch 77, Train Loss: 0.6488, Val Loss: 0.5988, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 78, Train Loss: 0.6371, Val Loss: 0.6171, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 79, Train Loss: 0.6480, Val Loss: 0.5994, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 80, Train Loss: 0.6372, Val Loss: 0.6080, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 81, Train Loss: 0.6577, Val Loss: 0.6146, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 82, Train Loss: 0.6439, Val Loss: 0.6120, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 83, Train Loss: 0.6520, Val Loss: 0.6095, F1 Micro: 0.7247, F1 Macro: 0.6330, Accuracy: 0.7247\n","Epoch 84, Train Loss: 0.6425, Val Loss: 0.6096, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 85, Train Loss: 0.6404, Val Loss: 0.6081, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 86, Train Loss: 0.6566, Val Loss: 0.5949, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 87, Train Loss: 0.6558, Val Loss: 0.6020, F1 Micro: 0.7640, F1 Macro: 0.7080, Accuracy: 0.7640\n","Epoch 88, Train Loss: 0.6449, Val Loss: 0.6000, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 89, Train Loss: 0.6520, Val Loss: 0.6059, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 90, Train Loss: 0.6493, Val Loss: 0.5911, F1 Micro: 0.7640, F1 Macro: 0.7080, Accuracy: 0.7640\n","Epoch 91, Train Loss: 0.6595, Val Loss: 0.6180, F1 Micro: 0.6910, F1 Macro: 0.5817, Accuracy: 0.6910\n","Epoch 92, Train Loss: 0.6308, Val Loss: 0.6275, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 93, Train Loss: 0.6482, Val Loss: 0.6084, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 94, Train Loss: 0.6542, Val Loss: 0.6119, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 95, Train Loss: 0.6467, Val Loss: 0.6205, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 96, Train Loss: 0.6447, Val Loss: 0.6033, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 97, Train Loss: 0.6447, Val Loss: 0.6282, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 98, Train Loss: 0.6468, Val Loss: 0.6480, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 99, Train Loss: 0.6446, Val Loss: 0.6020, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 100, Train Loss: 0.6440, Val Loss: 0.6016, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 101, Train Loss: 0.6479, Val Loss: 0.6013, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 102, Train Loss: 0.6344, Val Loss: 0.6279, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 103, Train Loss: 0.6306, Val Loss: 0.6038, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 104, Train Loss: 0.6348, Val Loss: 0.5972, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 105, Train Loss: 0.6496, Val Loss: 0.6866, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 106, Train Loss: 0.6385, Val Loss: 0.5976, F1 Micro: 0.7416, F1 Macro: 0.6802, Accuracy: 0.7416\n","Epoch 107, Train Loss: 0.6306, Val Loss: 0.6166, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 108, Train Loss: 0.6470, Val Loss: 0.6093, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 109, Train Loss: 0.6407, Val Loss: 0.5952, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 110, Train Loss: 0.6640, Val Loss: 0.5993, F1 Micro: 0.7472, F1 Macro: 0.6725, Accuracy: 0.7472\n","Epoch 111, Train Loss: 0.6417, Val Loss: 0.6121, F1 Micro: 0.7697, F1 Macro: 0.7367, Accuracy: 0.7697\n","Epoch 112, Train Loss: 0.6411, Val Loss: 0.6067, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 113, Train Loss: 0.6542, Val Loss: 0.5965, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 114, Train Loss: 0.6393, Val Loss: 0.6293, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 115, Train Loss: 0.6412, Val Loss: 0.5906, F1 Micro: 0.7360, F1 Macro: 0.6626, Accuracy: 0.7360\n","Epoch 116, Train Loss: 0.6379, Val Loss: 0.6040, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 117, Train Loss: 0.6495, Val Loss: 0.6108, F1 Micro: 0.6685, F1 Macro: 0.5111, Accuracy: 0.6685\n","Epoch 118, Train Loss: 0.6351, Val Loss: 0.6029, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 119, Train Loss: 0.6477, Val Loss: 0.6161, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 120, Train Loss: 0.6406, Val Loss: 0.5993, F1 Micro: 0.6854, F1 Macro: 0.5486, Accuracy: 0.6854\n","Epoch 121, Train Loss: 0.6398, Val Loss: 0.6337, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 122, Train Loss: 0.6500, Val Loss: 0.6007, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 123, Train Loss: 0.6535, Val Loss: 0.6195, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 124, Train Loss: 0.6296, Val Loss: 0.6263, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 125, Train Loss: 0.6497, Val Loss: 0.6421, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 126, Train Loss: 0.6342, Val Loss: 0.6043, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 127, Train Loss: 0.6389, Val Loss: 0.6193, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 128, Train Loss: 0.6583, Val Loss: 0.6019, F1 Micro: 0.7416, F1 Macro: 0.6802, Accuracy: 0.7416\n","Epoch 129, Train Loss: 0.6503, Val Loss: 0.6159, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 130, Train Loss: 0.6434, Val Loss: 0.5990, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 131, Train Loss: 0.6289, Val Loss: 0.6108, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 132, Train Loss: 0.6373, Val Loss: 0.6221, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 133, Train Loss: 0.6585, Val Loss: 0.6173, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 134, Train Loss: 0.6579, Val Loss: 0.6106, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 135, Train Loss: 0.6508, Val Loss: 0.6237, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 136, Train Loss: 0.6459, Val Loss: 0.5943, F1 Micro: 0.7528, F1 Macro: 0.6902, Accuracy: 0.7528\n","Epoch 137, Train Loss: 0.6343, Val Loss: 0.6059, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 138, Train Loss: 0.6340, Val Loss: 0.6024, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 139, Train Loss: 0.6512, Val Loss: 0.6051, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 140, Train Loss: 0.6415, Val Loss: 0.5939, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 141, Train Loss: 0.6505, Val Loss: 0.6134, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 142, Train Loss: 0.6426, Val Loss: 0.6230, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 143, Train Loss: 0.6336, Val Loss: 0.6089, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 144, Train Loss: 0.6306, Val Loss: 0.6158, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 145, Train Loss: 0.6582, Val Loss: 0.6216, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 146, Train Loss: 0.6353, Val Loss: 0.5941, F1 Micro: 0.7416, F1 Macro: 0.6802, Accuracy: 0.7416\n","Epoch 147, Train Loss: 0.6407, Val Loss: 0.6134, F1 Micro: 0.6966, F1 Macro: 0.5793, Accuracy: 0.6966\n","Epoch 148, Train Loss: 0.6311, Val Loss: 0.6016, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 149, Train Loss: 0.6259, Val Loss: 0.6043, F1 Micro: 0.7079, F1 Macro: 0.6189, Accuracy: 0.7079\n","Epoch 150, Train Loss: 0.6479, Val Loss: 0.6268, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 151, Train Loss: 0.6458, Val Loss: 0.6258, F1 Micro: 0.7191, F1 Macro: 0.7008, Accuracy: 0.7191\n","Epoch 152, Train Loss: 0.6445, Val Loss: 0.6332, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 153, Train Loss: 0.6513, Val Loss: 0.6180, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 154, Train Loss: 0.6413, Val Loss: 0.6093, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 155, Train Loss: 0.6433, Val Loss: 0.5946, F1 Micro: 0.7697, F1 Macro: 0.7095, Accuracy: 0.7697\n","Epoch 156, Train Loss: 0.6304, Val Loss: 0.6127, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 157, Train Loss: 0.6507, Val Loss: 0.6148, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 158, Train Loss: 0.6425, Val Loss: 0.5977, F1 Micro: 0.7809, F1 Macro: 0.7305, Accuracy: 0.7809\n","Epoch 159, Train Loss: 0.6439, Val Loss: 0.6007, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 160, Train Loss: 0.6541, Val Loss: 0.6100, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 161, Train Loss: 0.6510, Val Loss: 0.6032, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 162, Train Loss: 0.6375, Val Loss: 0.6030, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 163, Train Loss: 0.6536, Val Loss: 0.6106, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 164, Train Loss: 0.6564, Val Loss: 0.6167, F1 Micro: 0.6798, F1 Macro: 0.5364, Accuracy: 0.6798\n","Epoch 165, Train Loss: 0.6354, Val Loss: 0.6125, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 166, Train Loss: 0.6312, Val Loss: 0.5978, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 167, Train Loss: 0.6379, Val Loss: 0.6162, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 168, Train Loss: 0.6455, Val Loss: 0.6093, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 169, Train Loss: 0.6446, Val Loss: 0.6156, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 170, Train Loss: 0.6450, Val Loss: 0.6256, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 171, Train Loss: 0.6275, Val Loss: 0.6192, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 172, Train Loss: 0.6380, Val Loss: 0.5915, F1 Micro: 0.7640, F1 Macro: 0.7080, Accuracy: 0.7640\n","Epoch 173, Train Loss: 0.6384, Val Loss: 0.6264, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 174, Train Loss: 0.6559, Val Loss: 0.6234, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 175, Train Loss: 0.6383, Val Loss: 0.6004, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 176, Train Loss: 0.6362, Val Loss: 0.6107, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 177, Train Loss: 0.6316, Val Loss: 0.6024, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 178, Train Loss: 0.6488, Val Loss: 0.5966, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 179, Train Loss: 0.6298, Val Loss: 0.6087, F1 Micro: 0.7360, F1 Macro: 0.6670, Accuracy: 0.7360\n","Epoch 180, Train Loss: 0.6445, Val Loss: 0.6114, F1 Micro: 0.7135, F1 Macro: 0.6180, Accuracy: 0.7135\n","Epoch 181, Train Loss: 0.6469, Val Loss: 0.5976, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 182, Train Loss: 0.6487, Val Loss: 0.6088, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 183, Train Loss: 0.6543, Val Loss: 0.6222, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 184, Train Loss: 0.6435, Val Loss: 0.6035, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 185, Train Loss: 0.6438, Val Loss: 0.5981, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 186, Train Loss: 0.6374, Val Loss: 0.6261, F1 Micro: 0.6742, F1 Macro: 0.5405, Accuracy: 0.6742\n","Epoch 187, Train Loss: 0.6393, Val Loss: 0.6063, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 188, Train Loss: 0.6475, Val Loss: 0.6064, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 189, Train Loss: 0.6368, Val Loss: 0.5951, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 190, Train Loss: 0.6485, Val Loss: 0.6070, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 191, Train Loss: 0.6507, Val Loss: 0.6131, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 192, Train Loss: 0.6482, Val Loss: 0.6019, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 193, Train Loss: 0.6465, Val Loss: 0.6064, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 194, Train Loss: 0.6410, Val Loss: 0.5996, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 195, Train Loss: 0.6505, Val Loss: 0.5938, F1 Micro: 0.7303, F1 Macro: 0.6531, Accuracy: 0.7303\n","Epoch 196, Train Loss: 0.6454, Val Loss: 0.6221, F1 Micro: 0.7247, F1 Macro: 0.7041, Accuracy: 0.7247\n","Epoch 197, Train Loss: 0.6507, Val Loss: 0.6034, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 198, Train Loss: 0.6460, Val Loss: 0.6074, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 199, Train Loss: 0.6381, Val Loss: 0.6176, F1 Micro: 0.6517, F1 Macro: 0.4603, Accuracy: 0.6517\n","Epoch 200, Train Loss: 0.6359, Val Loss: 0.6037, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8803, Val Loss: 0.7344, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.7277, Val Loss: 0.7157, F1 Micro: 0.5899, F1 Macro: 0.5898, Accuracy: 0.5899\n","Epoch 3, Train Loss: 0.6979, Val Loss: 0.6938, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6893, Val Loss: 0.6686, F1 Micro: 0.6180, F1 Macro: 0.4787, Accuracy: 0.6180\n","Epoch 5, Train Loss: 0.6722, Val Loss: 0.6542, F1 Micro: 0.6067, F1 Macro: 0.5133, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6538, Val Loss: 0.6498, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 7, Train Loss: 0.6642, Val Loss: 0.6350, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6435, Val Loss: 0.6601, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6467, Val Loss: 0.6532, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 10, Train Loss: 0.6316, Val Loss: 0.6548, F1 Micro: 0.6404, F1 Macro: 0.5550, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6473, Val Loss: 0.6464, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6472, Val Loss: 0.6837, F1 Micro: 0.6124, F1 Macro: 0.6032, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6405, Val Loss: 0.6451, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6383, Val Loss: 0.7132, F1 Micro: 0.5787, F1 Macro: 0.5780, Accuracy: 0.5787\n","Epoch 15, Train Loss: 0.6387, Val Loss: 0.6474, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6487, Val Loss: 0.6616, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 17, Train Loss: 0.6512, Val Loss: 0.6476, F1 Micro: 0.6124, F1 Macro: 0.5173, Accuracy: 0.6124\n","Epoch 18, Train Loss: 0.6303, Val Loss: 0.6369, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6265, Val Loss: 0.6840, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6374, Val Loss: 0.6591, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 21, Train Loss: 0.6414, Val Loss: 0.6790, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6596, Val Loss: 0.6644, F1 Micro: 0.6461, F1 Macro: 0.6350, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6480, Val Loss: 0.6649, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 24, Train Loss: 0.6422, Val Loss: 0.6734, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 25, Train Loss: 0.6457, Val Loss: 0.6597, F1 Micro: 0.6124, F1 Macro: 0.5111, Accuracy: 0.6124\n","Epoch 26, Train Loss: 0.6255, Val Loss: 0.6414, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6334, Val Loss: 0.6355, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 28, Train Loss: 0.6381, Val Loss: 0.6741, F1 Micro: 0.5955, F1 Macro: 0.4723, Accuracy: 0.5955\n","Epoch 29, Train Loss: 0.6406, Val Loss: 0.6341, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 30, Train Loss: 0.6320, Val Loss: 0.6376, F1 Micro: 0.6854, F1 Macro: 0.5637, Accuracy: 0.6854\n","Epoch 31, Train Loss: 0.6490, Val Loss: 0.6386, F1 Micro: 0.6404, F1 Macro: 0.5977, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6461, Val Loss: 0.6308, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.6307, Val Loss: 0.6531, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 34, Train Loss: 0.6498, Val Loss: 0.6781, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 35, Train Loss: 0.6412, Val Loss: 0.6502, F1 Micro: 0.6180, F1 Macro: 0.5085, Accuracy: 0.6180\n","Epoch 36, Train Loss: 0.6425, Val Loss: 0.6426, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 37, Train Loss: 0.6417, Val Loss: 0.6364, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 38, Train Loss: 0.6431, Val Loss: 0.6327, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 39, Train Loss: 0.6340, Val Loss: 0.6345, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6442, Val Loss: 0.6538, F1 Micro: 0.6011, F1 Macro: 0.4682, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6351, Val Loss: 0.6648, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 42, Train Loss: 0.6418, Val Loss: 0.6380, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 43, Train Loss: 0.6418, Val Loss: 0.6327, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 44, Train Loss: 0.6351, Val Loss: 0.6512, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 45, Train Loss: 0.6388, Val Loss: 0.6548, F1 Micro: 0.6292, F1 Macro: 0.5465, Accuracy: 0.6292\n","Epoch 46, Train Loss: 0.6207, Val Loss: 0.6794, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6398, Val Loss: 0.7137, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6379, Val Loss: 0.6363, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 49, Train Loss: 0.6504, Val Loss: 0.6347, F1 Micro: 0.6573, F1 Macro: 0.6082, Accuracy: 0.6573\n","Epoch 50, Train Loss: 0.6322, Val Loss: 0.6376, F1 Micro: 0.6180, F1 Macro: 0.5328, Accuracy: 0.6180\n","Epoch 51, Train Loss: 0.6422, Val Loss: 0.6558, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 52, Train Loss: 0.6261, Val Loss: 0.6424, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 53, Train Loss: 0.6351, Val Loss: 0.6569, F1 Micro: 0.6124, F1 Macro: 0.5231, Accuracy: 0.6124\n","Epoch 54, Train Loss: 0.6367, Val Loss: 0.6688, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.6343, Val Loss: 0.6351, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.6370, Val Loss: 0.6472, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 57, Train Loss: 0.6277, Val Loss: 0.6318, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 58, Train Loss: 0.6230, Val Loss: 0.6546, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 59, Train Loss: 0.6430, Val Loss: 0.7633, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 60, Train Loss: 0.6267, Val Loss: 0.6476, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 61, Train Loss: 0.6443, Val Loss: 0.6633, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 62, Train Loss: 0.6380, Val Loss: 0.6977, F1 Micro: 0.6461, F1 Macro: 0.5990, Accuracy: 0.6461\n","Epoch 63, Train Loss: 0.6313, Val Loss: 0.6298, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Epoch 64, Train Loss: 0.6330, Val Loss: 0.6485, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 65, Train Loss: 0.6431, Val Loss: 0.6473, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 66, Train Loss: 0.6382, Val Loss: 0.6454, F1 Micro: 0.6124, F1 Macro: 0.4907, Accuracy: 0.6124\n","Epoch 67, Train Loss: 0.6574, Val Loss: 0.6490, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 68, Train Loss: 0.6269, Val Loss: 0.6316, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 69, Train Loss: 0.6378, Val Loss: 0.6382, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 70, Train Loss: 0.6468, Val Loss: 0.6384, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 71, Train Loss: 0.6425, Val Loss: 0.6451, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 72, Train Loss: 0.6238, Val Loss: 0.7132, F1 Micro: 0.5449, F1 Macro: 0.5442, Accuracy: 0.5449\n","Epoch 73, Train Loss: 0.6436, Val Loss: 0.6618, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 74, Train Loss: 0.6331, Val Loss: 0.7232, F1 Micro: 0.5899, F1 Macro: 0.4893, Accuracy: 0.5899\n","Epoch 75, Train Loss: 0.6529, Val Loss: 0.6485, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 76, Train Loss: 0.6291, Val Loss: 0.6370, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.6328, Val Loss: 0.6550, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 78, Train Loss: 0.6376, Val Loss: 0.6458, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 79, Train Loss: 0.6299, Val Loss: 0.6487, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 80, Train Loss: 0.6293, Val Loss: 0.6464, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8784, Val Loss: 0.8682, F1 Micro: 0.5843, F1 Macro: 0.5269, Accuracy: 0.5843\n","Epoch 2, Train Loss: 0.7273, Val Loss: 0.6961, F1 Micro: 0.6236, F1 Macro: 0.6233, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.7194, Val Loss: 0.7377, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6847, Val Loss: 0.7395, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 5, Train Loss: 0.6707, Val Loss: 0.6753, F1 Micro: 0.5843, F1 Macro: 0.5517, Accuracy: 0.5843\n","Epoch 6, Train Loss: 0.6470, Val Loss: 0.7049, F1 Micro: 0.5730, F1 Macro: 0.5001, Accuracy: 0.5730\n","Epoch 7, Train Loss: 0.6330, Val Loss: 0.6984, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6492, Val Loss: 0.7359, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6284, Val Loss: 0.6840, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6365, Val Loss: 0.6724, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6268, Val Loss: 0.7098, F1 Micro: 0.5955, F1 Macro: 0.5545, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.6433, Val Loss: 0.6741, F1 Micro: 0.6011, F1 Macro: 0.5975, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6414, Val Loss: 0.6932, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 14, Train Loss: 0.6254, Val Loss: 0.6539, F1 Micro: 0.6573, F1 Macro: 0.6570, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6195, Val Loss: 0.6940, F1 Micro: 0.5955, F1 Macro: 0.5802, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.6375, Val Loss: 0.6729, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6319, Val Loss: 0.6668, F1 Micro: 0.6067, F1 Macro: 0.5836, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6283, Val Loss: 0.6987, F1 Micro: 0.5843, F1 Macro: 0.5455, Accuracy: 0.5843\n","Epoch 19, Train Loss: 0.6396, Val Loss: 0.6800, F1 Micro: 0.5955, F1 Macro: 0.5545, Accuracy: 0.5955\n","Epoch 20, Train Loss: 0.6489, Val Loss: 0.7534, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 21, Train Loss: 0.6355, Val Loss: 0.7076, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 22, Train Loss: 0.6310, Val Loss: 0.6847, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6257, Val Loss: 0.7310, F1 Micro: 0.5562, F1 Macro: 0.4473, Accuracy: 0.5562\n","Epoch 24, Train Loss: 0.6370, Val Loss: 0.6704, F1 Micro: 0.6124, F1 Macro: 0.5949, Accuracy: 0.6124\n","Epoch 25, Train Loss: 0.6270, Val Loss: 0.6745, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6369, Val Loss: 0.6866, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6358, Val Loss: 0.6902, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 28, Train Loss: 0.6442, Val Loss: 0.7466, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6307, Val Loss: 0.6967, F1 Micro: 0.5787, F1 Macro: 0.5226, Accuracy: 0.5787\n","Epoch 30, Train Loss: 0.6269, Val Loss: 0.7164, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 31, Train Loss: 0.6356, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 32, Train Loss: 0.6274, Val Loss: 0.6875, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6304, Val Loss: 0.6612, F1 Micro: 0.6461, F1 Macro: 0.6447, Accuracy: 0.6461\n","Epoch 34, Train Loss: 0.6343, Val Loss: 0.6774, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6251, Val Loss: 0.6715, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 36, Train Loss: 0.6371, Val Loss: 0.6680, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 37, Train Loss: 0.6234, Val Loss: 0.7012, F1 Micro: 0.5506, F1 Macro: 0.4838, Accuracy: 0.5506\n","Epoch 38, Train Loss: 0.6360, Val Loss: 0.7074, F1 Micro: 0.5674, F1 Macro: 0.4613, Accuracy: 0.5674\n","Epoch 39, Train Loss: 0.6282, Val Loss: 0.6822, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 40, Train Loss: 0.6185, Val Loss: 0.7139, F1 Micro: 0.6067, F1 Macro: 0.5836, Accuracy: 0.6067\n","Epoch 41, Train Loss: 0.6289, Val Loss: 0.6746, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 42, Train Loss: 0.6249, Val Loss: 0.7362, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 43, Train Loss: 0.6230, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.6209, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6410, Val Loss: 0.6995, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 45, Train Loss: 0.6258, Val Loss: 0.6843, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.6123, Val Loss: 0.6588, F1 Micro: 0.6685, F1 Macro: 0.6619, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6157, Val Loss: 0.7505, F1 Micro: 0.5787, F1 Macro: 0.5138, Accuracy: 0.5787\n","Epoch 48, Train Loss: 0.6322, Val Loss: 0.7228, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6170, Val Loss: 0.6981, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 50, Train Loss: 0.6349, Val Loss: 0.6702, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6302, Val Loss: 0.6660, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 52, Train Loss: 0.6375, Val Loss: 0.6638, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 53, Train Loss: 0.6286, Val Loss: 0.6945, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 54, Train Loss: 0.6231, Val Loss: 0.6704, F1 Micro: 0.6348, F1 Macro: 0.6286, Accuracy: 0.6348\n","Epoch 55, Train Loss: 0.6253, Val Loss: 0.6647, F1 Micro: 0.6404, F1 Macro: 0.6349, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.6213, Val Loss: 0.6613, F1 Micro: 0.6685, F1 Macro: 0.6619, Accuracy: 0.6685\n","Epoch 57, Train Loss: 0.6209, Val Loss: 0.6616, F1 Micro: 0.6517, F1 Macro: 0.6452, Accuracy: 0.6517\n","Epoch 58, Train Loss: 0.6392, Val Loss: 0.6748, F1 Micro: 0.6404, F1 Macro: 0.6397, Accuracy: 0.6404\n","Epoch 59, Train Loss: 0.6239, Val Loss: 0.6775, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 60, Train Loss: 0.6301, Val Loss: 0.6792, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 61, Train Loss: 0.6225, Val Loss: 0.6689, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 62, Train Loss: 0.6207, Val Loss: 0.6688, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 63, Train Loss: 0.6168, Val Loss: 0.6873, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 64, Train Loss: 0.6138, Val Loss: 0.7102, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Epoch 65, Train Loss: 0.6376, Val Loss: 0.6615, F1 Micro: 0.6292, F1 Macro: 0.6223, Accuracy: 0.6292\n","Epoch 66, Train Loss: 0.6225, Val Loss: 0.6836, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 67, Train Loss: 0.6233, Val Loss: 0.6929, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 68, Train Loss: 0.6141, Val Loss: 0.6850, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 69, Train Loss: 0.6177, Val Loss: 0.6913, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 70, Train Loss: 0.6157, Val Loss: 0.6917, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 71, Train Loss: 0.6267, Val Loss: 0.6858, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 72, Train Loss: 0.6241, Val Loss: 0.7060, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 73, Train Loss: 0.6285, Val Loss: 0.7059, F1 Micro: 0.5787, F1 Macro: 0.5041, Accuracy: 0.5787\n","Epoch 74, Train Loss: 0.6324, Val Loss: 0.6806, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 75, Train Loss: 0.6338, Val Loss: 0.6662, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 76, Train Loss: 0.6229, Val Loss: 0.7142, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 77, Train Loss: 0.6303, Val Loss: 0.6942, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 78, Train Loss: 0.6281, Val Loss: 0.7290, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 79, Train Loss: 0.6164, Val Loss: 0.6966, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 80, Train Loss: 0.6262, Val Loss: 0.6651, F1 Micro: 0.6348, F1 Macro: 0.6334, Accuracy: 0.6348\n","Epoch 81, Train Loss: 0.6254, Val Loss: 0.6819, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 82, Train Loss: 0.6141, Val Loss: 0.6842, F1 Micro: 0.6629, F1 Macro: 0.6544, Accuracy: 0.6629\n","Epoch 83, Train Loss: 0.6279, Val Loss: 0.7232, F1 Micro: 0.6124, F1 Macro: 0.5681, Accuracy: 0.6124\n","Epoch 84, Train Loss: 0.6389, Val Loss: 0.6940, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 85, Train Loss: 0.6221, Val Loss: 0.7190, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 86, Train Loss: 0.6201, Val Loss: 0.6801, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 87, Train Loss: 0.6169, Val Loss: 0.6710, F1 Micro: 0.5899, F1 Macro: 0.5898, Accuracy: 0.5899\n","Epoch 88, Train Loss: 0.6280, Val Loss: 0.6853, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 89, Train Loss: 0.6309, Val Loss: 0.6845, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 90, Train Loss: 0.6180, Val Loss: 0.6979, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 91, Train Loss: 0.6340, Val Loss: 0.6887, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 92, Train Loss: 0.6243, Val Loss: 0.7413, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 93, Train Loss: 0.6455, Val Loss: 0.6788, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 94, Train Loss: 0.6259, Val Loss: 0.6907, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 95, Train Loss: 0.6305, Val Loss: 0.6794, F1 Micro: 0.6629, F1 Macro: 0.6531, Accuracy: 0.6629\n","Epoch 96, Train Loss: 0.6327, Val Loss: 0.6669, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.9130, Val Loss: 0.9123, F1 Micro: 0.3989, F1 Macro: 0.3451, Accuracy: 0.3989\n","Epoch 2, Train Loss: 0.7362, Val Loss: 0.8237, F1 Micro: 0.5787, F1 Macro: 0.4817, Accuracy: 0.5787\n","Epoch 3, Train Loss: 0.7010, Val Loss: 0.8091, F1 Micro: 0.4663, F1 Macro: 0.4537, Accuracy: 0.4663\n","Epoch 4, Train Loss: 0.6900, Val Loss: 1.0066, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6983, Val Loss: 0.6648, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.6583, Val Loss: 0.6772, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.6535, Val Loss: 0.6616, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6483, Val Loss: 0.6636, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6537, Val Loss: 0.6599, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6311, Val Loss: 0.6745, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6478, Val Loss: 0.6672, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6372, Val Loss: 0.6714, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 13, Train Loss: 0.6434, Val Loss: 0.6668, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6573, Val Loss: 0.6692, F1 Micro: 0.6011, F1 Macro: 0.5886, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6350, Val Loss: 0.6964, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 16, Train Loss: 0.6294, Val Loss: 0.7006, F1 Micro: 0.5393, F1 Macro: 0.5391, Accuracy: 0.5393\n","Epoch 17, Train Loss: 0.6285, Val Loss: 0.6720, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6241, Val Loss: 0.6498, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 19, Train Loss: 0.6293, Val Loss: 0.6681, F1 Micro: 0.6067, F1 Macro: 0.5936, Accuracy: 0.6067\n","Epoch 20, Train Loss: 0.6296, Val Loss: 0.6940, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6348, Val Loss: 0.6510, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6461, Val Loss: 0.6800, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6443, Val Loss: 0.6580, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6551, Val Loss: 0.6610, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.6305, Val Loss: 0.6602, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6325, Val Loss: 0.7219, F1 Micro: 0.5899, F1 Macro: 0.3834, Accuracy: 0.5899\n","Epoch 27, Train Loss: 0.6509, Val Loss: 0.6743, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6378, Val Loss: 0.6653, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 29, Train Loss: 0.6326, Val Loss: 0.6637, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 30, Train Loss: 0.6461, Val Loss: 0.6631, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.6224, Val Loss: 0.6867, F1 Micro: 0.6854, F1 Macro: 0.6735, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.6613, Val Loss: 0.6520, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 33, Train Loss: 0.6443, Val Loss: 0.6516, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 34, Train Loss: 0.6367, Val Loss: 0.6618, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 35, Train Loss: 0.6352, Val Loss: 0.7177, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6396, Val Loss: 0.6680, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6365, Val Loss: 0.6565, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 38, Train Loss: 0.6459, Val Loss: 0.6591, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 39, Train Loss: 0.6579, Val Loss: 0.6706, F1 Micro: 0.5955, F1 Macro: 0.4796, Accuracy: 0.5955\n","Epoch 40, Train Loss: 0.6398, Val Loss: 0.6565, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 41, Train Loss: 0.6412, Val Loss: 0.6613, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 42, Train Loss: 0.6274, Val Loss: 0.6818, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 43, Train Loss: 0.6353, Val Loss: 0.6636, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.6297, Val Loss: 0.6707, F1 Micro: 0.6124, F1 Macro: 0.4979, Accuracy: 0.6124\n","Epoch 45, Train Loss: 0.6122, Val Loss: 0.6838, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.6422, Val Loss: 0.6536, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6342, Val Loss: 0.6535, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.6381, Val Loss: 0.6766, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.6367, Val Loss: 0.6890, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 50, Train Loss: 0.6405, Val Loss: 0.6576, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6330, Val Loss: 0.6507, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 52, Train Loss: 0.6279, Val Loss: 0.6614, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 53, Train Loss: 0.6409, Val Loss: 0.6851, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 54, Train Loss: 0.6281, Val Loss: 0.6943, F1 Micro: 0.6348, F1 Macro: 0.5862, Accuracy: 0.6348\n","Epoch 55, Train Loss: 0.6463, Val Loss: 0.6854, F1 Micro: 0.6461, F1 Macro: 0.5835, Accuracy: 0.6461\n","Epoch 56, Train Loss: 0.6286, Val Loss: 0.6607, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 57, Train Loss: 0.6490, Val Loss: 0.6821, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6239, Val Loss: 0.6709, F1 Micro: 0.6461, F1 Macro: 0.5697, Accuracy: 0.6461\n","Epoch 59, Train Loss: 0.6230, Val Loss: 0.7112, F1 Micro: 0.6292, F1 Macro: 0.5293, Accuracy: 0.6292\n","Epoch 60, Train Loss: 0.6373, Val Loss: 0.6535, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 61, Train Loss: 0.6431, Val Loss: 0.6545, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 62, Train Loss: 0.6396, Val Loss: 0.6607, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.6288, Val Loss: 0.6891, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 64, Train Loss: 0.6441, Val Loss: 0.6562, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 65, Train Loss: 0.6489, Val Loss: 0.6673, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 66, Train Loss: 0.6233, Val Loss: 0.6883, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.6341, Val Loss: 0.6609, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 68, Train Loss: 0.6353, Val Loss: 0.6980, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 69, Train Loss: 0.6401, Val Loss: 0.6550, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 70, Train Loss: 0.6404, Val Loss: 0.6622, F1 Micro: 0.6404, F1 Macro: 0.5871, Accuracy: 0.6404\n","Epoch 71, Train Loss: 0.6293, Val Loss: 0.6630, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 72, Train Loss: 0.6374, Val Loss: 0.6529, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 73, Train Loss: 0.6287, Val Loss: 0.6895, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 74, Train Loss: 0.6393, Val Loss: 0.6694, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 75, Train Loss: 0.6298, Val Loss: 0.7196, F1 Micro: 0.6011, F1 Macro: 0.5764, Accuracy: 0.6011\n","Epoch 76, Train Loss: 0.6314, Val Loss: 0.6769, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.6230, Val Loss: 0.6610, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 78, Train Loss: 0.6384, Val Loss: 0.6812, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 79, Train Loss: 0.6373, Val Loss: 0.6852, F1 Micro: 0.6348, F1 Macro: 0.5703, Accuracy: 0.6348\n","Epoch 80, Train Loss: 0.6313, Val Loss: 0.6551, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 81, Train Loss: 0.6294, Val Loss: 0.6607, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 82, Train Loss: 0.6326, Val Loss: 0.7139, F1 Micro: 0.6067, F1 Macro: 0.6055, Accuracy: 0.6067\n","Epoch 83, Train Loss: 0.6279, Val Loss: 0.7135, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 84, Train Loss: 0.6359, Val Loss: 0.6735, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 85, Train Loss: 0.6263, Val Loss: 0.6594, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 86, Train Loss: 0.6210, Val Loss: 0.6698, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 87, Train Loss: 0.6418, Val Loss: 0.6536, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 88, Train Loss: 0.6294, Val Loss: 0.7570, F1 Micro: 0.6011, F1 Macro: 0.5831, Accuracy: 0.6011\n","Epoch 89, Train Loss: 0.6553, Val Loss: 0.6605, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 90, Train Loss: 0.6300, Val Loss: 0.6715, F1 Micro: 0.6011, F1 Macro: 0.4682, Accuracy: 0.6011\n","Epoch 91, Train Loss: 0.6313, Val Loss: 0.6888, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 92, Train Loss: 0.6352, Val Loss: 0.6512, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.6479, Val Loss: 0.6608, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 94, Train Loss: 0.6278, Val Loss: 0.6904, F1 Micro: 0.5899, F1 Macro: 0.5174, Accuracy: 0.5899\n","Epoch 95, Train Loss: 0.6529, Val Loss: 0.6610, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 96, Train Loss: 0.6280, Val Loss: 0.6474, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 97, Train Loss: 0.6317, Val Loss: 0.6845, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 98, Train Loss: 0.6189, Val Loss: 0.6607, F1 Micro: 0.6742, F1 Macro: 0.6633, Accuracy: 0.6742\n","Epoch 99, Train Loss: 0.6375, Val Loss: 0.6529, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 100, Train Loss: 0.6290, Val Loss: 0.6636, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 101, Train Loss: 0.6325, Val Loss: 0.6646, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 102, Train Loss: 0.6366, Val Loss: 0.6602, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 103, Train Loss: 0.6354, Val Loss: 0.6649, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 104, Train Loss: 0.6286, Val Loss: 0.6724, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 105, Train Loss: 0.6383, Val Loss: 0.6615, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 106, Train Loss: 0.6325, Val Loss: 0.7036, F1 Micro: 0.5674, F1 Macro: 0.5673, Accuracy: 0.5674\n","Epoch 107, Train Loss: 0.6397, Val Loss: 0.6895, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 108, Train Loss: 0.6345, Val Loss: 0.6900, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 109, Train Loss: 0.6469, Val Loss: 0.6620, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 110, Train Loss: 0.6376, Val Loss: 0.6749, F1 Micro: 0.6404, F1 Macro: 0.6367, Accuracy: 0.6404\n","Epoch 111, Train Loss: 0.6276, Val Loss: 0.7108, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 112, Train Loss: 0.6332, Val Loss: 0.6600, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 113, Train Loss: 0.6193, Val Loss: 0.6991, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 114, Train Loss: 0.6438, Val Loss: 0.6667, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 115, Train Loss: 0.6295, Val Loss: 0.6668, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 116, Train Loss: 0.6443, Val Loss: 0.6713, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 117, Train Loss: 0.6359, Val Loss: 0.6759, F1 Micro: 0.5843, F1 Macro: 0.5721, Accuracy: 0.5843\n","Epoch 118, Train Loss: 0.6375, Val Loss: 0.7136, F1 Micro: 0.6348, F1 Macro: 0.5657, Accuracy: 0.6348\n","Epoch 119, Train Loss: 0.6316, Val Loss: 0.6555, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 120, Train Loss: 0.6341, Val Loss: 0.6667, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 121, Train Loss: 0.6444, Val Loss: 0.6657, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 122, Train Loss: 0.6257, Val Loss: 0.6547, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 123, Train Loss: 0.6315, Val Loss: 0.6573, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 124, Train Loss: 0.6226, Val Loss: 0.6849, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 125, Train Loss: 0.6294, Val Loss: 0.7063, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 126, Train Loss: 0.6419, Val Loss: 0.6702, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 127, Train Loss: 0.6325, Val Loss: 0.6564, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 128, Train Loss: 0.6362, Val Loss: 0.6597, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 129, Train Loss: 0.6420, Val Loss: 0.6651, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 130, Train Loss: 0.6226, Val Loss: 0.6644, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 131, Train Loss: 0.6476, Val Loss: 0.6574, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 132, Train Loss: 0.6302, Val Loss: 0.6702, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 133, Train Loss: 0.6358, Val Loss: 0.6707, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 134, Train Loss: 0.6272, Val Loss: 0.6766, F1 Micro: 0.6348, F1 Macro: 0.6306, Accuracy: 0.6348\n","Epoch 135, Train Loss: 0.6300, Val Loss: 0.6809, F1 Micro: 0.6461, F1 Macro: 0.5835, Accuracy: 0.6461\n","Epoch 136, Train Loss: 0.6325, Val Loss: 0.6580, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 137, Train Loss: 0.6241, Val Loss: 0.6788, F1 Micro: 0.6348, F1 Macro: 0.5703, Accuracy: 0.6348\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.7205009101751302\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8101, Val Loss: 0.7480, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 2, Train Loss: 0.7262, Val Loss: 0.6910, F1 Micro: 0.6257, F1 Macro: 0.5940, Accuracy: 0.6257\n","Epoch 3, Train Loss: 0.7307, Val Loss: 0.7365, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 4, Train Loss: 0.6787, Val Loss: 0.7541, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 5, Train Loss: 0.6596, Val Loss: 0.7187, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 6, Train Loss: 0.6581, Val Loss: 0.7004, F1 Micro: 0.5642, F1 Macro: 0.5401, Accuracy: 0.5642\n","Epoch 7, Train Loss: 0.6595, Val Loss: 0.6772, F1 Micro: 0.6648, F1 Macro: 0.6270, Accuracy: 0.6648\n","Epoch 8, Train Loss: 0.6388, Val Loss: 0.7031, F1 Micro: 0.6257, F1 Macro: 0.5912, Accuracy: 0.6257\n","Epoch 9, Train Loss: 0.6536, Val Loss: 0.6713, F1 Micro: 0.6760, F1 Macro: 0.5925, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.6594, Val Loss: 0.7229, F1 Micro: 0.6927, F1 Macro: 0.5612, Accuracy: 0.6927\n","Epoch 11, Train Loss: 0.6412, Val Loss: 0.6881, F1 Micro: 0.6592, F1 Macro: 0.6278, Accuracy: 0.6592\n","Epoch 12, Train Loss: 0.6278, Val Loss: 0.6609, F1 Micro: 0.7095, F1 Macro: 0.6767, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.6493, Val Loss: 0.7159, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 14, Train Loss: 0.6414, Val Loss: 0.7021, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 15, Train Loss: 0.6393, Val Loss: 0.6945, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 16, Train Loss: 0.6605, Val Loss: 0.7048, F1 Micro: 0.5698, F1 Macro: 0.5679, Accuracy: 0.5698\n","Epoch 17, Train Loss: 0.6385, Val Loss: 0.6701, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 18, Train Loss: 0.6309, Val Loss: 0.6632, F1 Micro: 0.6760, F1 Macro: 0.6334, Accuracy: 0.6760\n","Epoch 19, Train Loss: 0.6409, Val Loss: 0.6617, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 20, Train Loss: 0.6303, Val Loss: 0.6643, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 21, Train Loss: 0.6350, Val Loss: 0.6779, F1 Micro: 0.6872, F1 Macro: 0.6362, Accuracy: 0.6872\n","Epoch 22, Train Loss: 0.6422, Val Loss: 0.7163, F1 Micro: 0.6816, F1 Macro: 0.5371, Accuracy: 0.6816\n","Epoch 23, Train Loss: 0.6440, Val Loss: 0.6708, F1 Micro: 0.7151, F1 Macro: 0.6564, Accuracy: 0.7151\n","Epoch 24, Train Loss: 0.6311, Val Loss: 0.6976, F1 Micro: 0.6313, F1 Macro: 0.6087, Accuracy: 0.6313\n","Epoch 25, Train Loss: 0.6443, Val Loss: 0.7006, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 26, Train Loss: 0.6423, Val Loss: 0.6612, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 27, Train Loss: 0.6277, Val Loss: 0.6790, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 28, Train Loss: 0.6353, Val Loss: 0.7059, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 29, Train Loss: 0.6343, Val Loss: 0.6621, F1 Micro: 0.6983, F1 Macro: 0.6669, Accuracy: 0.6983\n","Epoch 30, Train Loss: 0.6437, Val Loss: 0.6834, F1 Micro: 0.6704, F1 Macro: 0.6185, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8213, Val Loss: 0.7223, F1 Micro: 0.6629, F1 Macro: 0.4777, Accuracy: 0.6629\n","Epoch 2, Train Loss: 0.7620, Val Loss: 0.6758, F1 Micro: 0.7079, F1 Macro: 0.6075, Accuracy: 0.7079\n","Epoch 3, Train Loss: 0.7049, Val Loss: 0.6323, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 4, Train Loss: 0.6545, Val Loss: 0.6038, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 5, Train Loss: 0.6827, Val Loss: 0.6205, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 6, Train Loss: 0.7150, Val Loss: 0.6670, F1 Micro: 0.5674, F1 Macro: 0.5674, Accuracy: 0.5674\n","Epoch 7, Train Loss: 0.7072, Val Loss: 0.6278, F1 Micro: 0.7135, F1 Macro: 0.6121, Accuracy: 0.7135\n","Epoch 8, Train Loss: 0.6481, Val Loss: 0.6052, F1 Micro: 0.6854, F1 Macro: 0.5486, Accuracy: 0.6854\n","Epoch 9, Train Loss: 0.6606, Val Loss: 0.5979, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6713, Val Loss: 0.6710, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6616, Val Loss: 0.5966, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 12, Train Loss: 0.6629, Val Loss: 0.6371, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 13, Train Loss: 0.6493, Val Loss: 0.6052, F1 Micro: 0.7022, F1 Macro: 0.6872, Accuracy: 0.7022\n","Epoch 14, Train Loss: 0.6481, Val Loss: 0.6016, F1 Micro: 0.7360, F1 Macro: 0.6626, Accuracy: 0.7360\n","Epoch 15, Train Loss: 0.6403, Val Loss: 0.6230, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 16, Train Loss: 0.6375, Val Loss: 0.5967, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 17, Train Loss: 0.6393, Val Loss: 0.5843, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 18, Train Loss: 0.6443, Val Loss: 0.5858, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 19, Train Loss: 0.6458, Val Loss: 0.5904, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 20, Train Loss: 0.6409, Val Loss: 0.6003, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 21, Train Loss: 0.6495, Val Loss: 0.5982, F1 Micro: 0.7528, F1 Macro: 0.6862, Accuracy: 0.7528\n","Epoch 22, Train Loss: 0.6392, Val Loss: 0.6180, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 23, Train Loss: 0.6457, Val Loss: 0.6044, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6481, Val Loss: 0.5960, F1 Micro: 0.7528, F1 Macro: 0.6902, Accuracy: 0.7528\n","Epoch 25, Train Loss: 0.6497, Val Loss: 0.5994, F1 Micro: 0.7022, F1 Macro: 0.5837, Accuracy: 0.7022\n","Epoch 26, Train Loss: 0.6366, Val Loss: 0.6061, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6482, Val Loss: 0.5979, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 28, Train Loss: 0.6498, Val Loss: 0.6047, F1 Micro: 0.7360, F1 Macro: 0.6626, Accuracy: 0.7360\n","Epoch 29, Train Loss: 0.6452, Val Loss: 0.5932, F1 Micro: 0.7640, F1 Macro: 0.7005, Accuracy: 0.7640\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.9080, Val Loss: 0.6682, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 2, Train Loss: 0.6926, Val Loss: 0.6755, F1 Micro: 0.5618, F1 Macro: 0.5582, Accuracy: 0.5618\n","Epoch 3, Train Loss: 0.6834, Val Loss: 0.6646, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 4, Train Loss: 0.7134, Val Loss: 0.6949, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 5, Train Loss: 0.6627, Val Loss: 0.7044, F1 Micro: 0.5393, F1 Macro: 0.5388, Accuracy: 0.5393\n","Epoch 6, Train Loss: 0.6648, Val Loss: 0.7303, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6637, Val Loss: 0.6599, F1 Micro: 0.6461, F1 Macro: 0.5916, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6644, Val Loss: 0.7514, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 9, Train Loss: 0.6607, Val Loss: 0.7021, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 10, Train Loss: 0.6317, Val Loss: 0.6805, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6612, Val Loss: 0.7044, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6512, Val Loss: 0.6931, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6460, Val Loss: 0.6677, F1 Micro: 0.6404, F1 Macro: 0.5550, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6352, Val Loss: 0.6942, F1 Micro: 0.6236, F1 Macro: 0.4550, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6211, Val Loss: 0.7084, F1 Micro: 0.6292, F1 Macro: 0.5354, Accuracy: 0.6292\n","Epoch 16, Train Loss: 0.6351, Val Loss: 0.7509, F1 Micro: 0.6236, F1 Macro: 0.4981, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6345, Val Loss: 0.6968, F1 Micro: 0.6573, F1 Macro: 0.6451, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6474, Val Loss: 0.7178, F1 Micro: 0.6292, F1 Macro: 0.4858, Accuracy: 0.6292\n","Epoch 19, Train Loss: 0.6452, Val Loss: 0.6772, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8653, Val Loss: 1.0585, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 2, Train Loss: 0.7602, Val Loss: 0.8647, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.7016, Val Loss: 0.7346, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6664, Val Loss: 0.7218, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 5, Train Loss: 0.6786, Val Loss: 0.6744, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 6, Train Loss: 0.6444, Val Loss: 0.7470, F1 Micro: 0.5562, F1 Macro: 0.4329, Accuracy: 0.5562\n","Epoch 7, Train Loss: 0.6298, Val Loss: 0.7637, F1 Micro: 0.5843, F1 Macro: 0.5225, Accuracy: 0.5843\n","Epoch 8, Train Loss: 0.6785, Val Loss: 0.7326, F1 Micro: 0.5562, F1 Macro: 0.4926, Accuracy: 0.5562\n","Epoch 9, Train Loss: 0.6371, Val Loss: 0.6839, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6359, Val Loss: 0.7313, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 11, Train Loss: 0.6431, Val Loss: 0.7234, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 12, Train Loss: 0.6226, Val Loss: 0.7589, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.6399, Val Loss: 0.6513, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6416, Val Loss: 0.6946, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6356, Val Loss: 0.7296, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 16, Train Loss: 0.6186, Val Loss: 0.6823, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 17, Train Loss: 0.6403, Val Loss: 0.8421, F1 Micro: 0.5393, F1 Macro: 0.3903, Accuracy: 0.5393\n","Epoch 18, Train Loss: 0.6373, Val Loss: 0.7216, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6253, Val Loss: 0.6777, F1 Micro: 0.6461, F1 Macro: 0.6301, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.6119, Val Loss: 0.7171, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 21, Train Loss: 0.6284, Val Loss: 0.6958, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 22, Train Loss: 0.6316, Val Loss: 0.6816, F1 Micro: 0.6292, F1 Macro: 0.6245, Accuracy: 0.6292\n","Epoch 23, Train Loss: 0.6191, Val Loss: 0.7554, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8962, Val Loss: 0.6979, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.7012, Val Loss: 0.7190, F1 Micro: 0.5281, F1 Macro: 0.5276, Accuracy: 0.5281\n","Epoch 3, Train Loss: 0.6994, Val Loss: 0.6697, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 4, Train Loss: 0.7301, Val Loss: 0.8272, F1 Micro: 0.6180, F1 Macro: 0.4518, Accuracy: 0.6180\n","Epoch 5, Train Loss: 0.7277, Val Loss: 0.6670, F1 Micro: 0.5787, F1 Macro: 0.5574, Accuracy: 0.5787\n","Epoch 6, Train Loss: 0.6389, Val Loss: 0.6449, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.6441, Val Loss: 0.7304, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 8, Train Loss: 0.6450, Val Loss: 0.6691, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6419, Val Loss: 0.6462, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.6336, Val Loss: 0.6774, F1 Micro: 0.5618, F1 Macro: 0.5591, Accuracy: 0.5618\n","Epoch 11, Train Loss: 0.6343, Val Loss: 0.6456, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 12, Train Loss: 0.6424, Val Loss: 0.6625, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6536, Val Loss: 0.6779, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6275, Val Loss: 0.6404, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 15, Train Loss: 0.6335, Val Loss: 0.6533, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6285, Val Loss: 0.6569, F1 Micro: 0.6236, F1 Macro: 0.6209, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6268, Val Loss: 0.6449, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.6375, Val Loss: 0.6558, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.6304, Val Loss: 0.6499, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 20, Train Loss: 0.6512, Val Loss: 0.6491, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6336, Val Loss: 0.6457, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.6305, Val Loss: 0.6495, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 23, Train Loss: 0.6211, Val Loss: 0.6793, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.6181, Val Loss: 0.6669, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6263, Val Loss: 0.6523, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6192, Val Loss: 0.6459, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6335, Val Loss: 0.6758, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 28, Train Loss: 0.6350, Val Loss: 0.6522, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 29, Train Loss: 0.6259, Val Loss: 0.6779, F1 Micro: 0.5618, F1 Macro: 0.5613, Accuracy: 0.5618\n","Epoch 30, Train Loss: 0.6320, Val Loss: 0.6390, F1 Micro: 0.6742, F1 Macro: 0.6508, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.6330, Val Loss: 0.6475, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.7093026175381333\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8609, Val Loss: 0.8693, F1 Micro: 0.6592, F1 Macro: 0.4856, Accuracy: 0.6592\n","Epoch 2, Train Loss: 0.7253, Val Loss: 0.8245, F1 Micro: 0.6536, F1 Macro: 0.4611, Accuracy: 0.6536\n","Epoch 3, Train Loss: 0.6704, Val Loss: 0.8484, F1 Micro: 0.3855, F1 Macro: 0.3665, Accuracy: 0.3855\n","Epoch 4, Train Loss: 0.6831, Val Loss: 0.7148, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 5, Train Loss: 0.7011, Val Loss: 0.7421, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 6, Train Loss: 0.6616, Val Loss: 0.7025, F1 Micro: 0.6313, F1 Macro: 0.5928, Accuracy: 0.6313\n","Epoch 7, Train Loss: 0.6527, Val Loss: 0.6832, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 8, Train Loss: 0.6646, Val Loss: 0.6796, F1 Micro: 0.6536, F1 Macro: 0.5972, Accuracy: 0.6536\n","Epoch 9, Train Loss: 0.6658, Val Loss: 0.6493, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.6390, Val Loss: 0.6837, F1 Micro: 0.5866, F1 Macro: 0.5808, Accuracy: 0.5866\n","Epoch 11, Train Loss: 0.6360, Val Loss: 0.6991, F1 Micro: 0.6089, F1 Macro: 0.5826, Accuracy: 0.6089\n","Epoch 12, Train Loss: 0.6290, Val Loss: 0.6719, F1 Micro: 0.6536, F1 Macro: 0.5329, Accuracy: 0.6536\n","Epoch 13, Train Loss: 0.6426, Val Loss: 0.6694, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 14, Train Loss: 0.6260, Val Loss: 0.6862, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 15, Train Loss: 0.6310, Val Loss: 0.7118, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 16, Train Loss: 0.6365, Val Loss: 0.6929, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 17, Train Loss: 0.6398, Val Loss: 0.6852, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.6287, Val Loss: 0.6757, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 19, Train Loss: 0.6302, Val Loss: 0.6564, F1 Micro: 0.7207, F1 Macro: 0.6891, Accuracy: 0.7207\n","Epoch 20, Train Loss: 0.6620, Val Loss: 0.6763, F1 Micro: 0.6201, F1 Macro: 0.6032, Accuracy: 0.6201\n","Epoch 21, Train Loss: 0.6409, Val Loss: 0.6510, F1 Micro: 0.7374, F1 Macro: 0.6867, Accuracy: 0.7374\n","Epoch 22, Train Loss: 0.6356, Val Loss: 0.6592, F1 Micro: 0.7207, F1 Macro: 0.6891, Accuracy: 0.7207\n","Epoch 23, Train Loss: 0.6279, Val Loss: 0.6554, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Epoch 24, Train Loss: 0.6281, Val Loss: 0.6717, F1 Micro: 0.6592, F1 Macro: 0.6373, Accuracy: 0.6592\n","Epoch 25, Train Loss: 0.6540, Val Loss: 0.6615, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 26, Train Loss: 0.6511, Val Loss: 0.6712, F1 Micro: 0.6536, F1 Macro: 0.6256, Accuracy: 0.6536\n","Epoch 27, Train Loss: 0.6297, Val Loss: 0.6796, F1 Micro: 0.6536, F1 Macro: 0.6175, Accuracy: 0.6536\n","Epoch 28, Train Loss: 0.6339, Val Loss: 0.6722, F1 Micro: 0.7039, F1 Macro: 0.6151, Accuracy: 0.7039\n","Epoch 29, Train Loss: 0.6331, Val Loss: 0.6544, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 30, Train Loss: 0.6542, Val Loss: 0.6751, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 31, Train Loss: 0.6382, Val Loss: 0.6767, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 32, Train Loss: 0.6375, Val Loss: 0.6663, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 33, Train Loss: 0.6389, Val Loss: 0.6639, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 34, Train Loss: 0.6245, Val Loss: 0.6546, F1 Micro: 0.6536, F1 Macro: 0.5932, Accuracy: 0.6536\n","Epoch 35, Train Loss: 0.6405, Val Loss: 0.6475, F1 Micro: 0.7039, F1 Macro: 0.6743, Accuracy: 0.7039\n","Epoch 36, Train Loss: 0.6346, Val Loss: 0.6773, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 37, Train Loss: 0.6359, Val Loss: 0.6801, F1 Micro: 0.6648, F1 Macro: 0.5979, Accuracy: 0.6648\n","Epoch 38, Train Loss: 0.6368, Val Loss: 0.6697, F1 Micro: 0.6760, F1 Macro: 0.6302, Accuracy: 0.6760\n","Epoch 39, Train Loss: 0.6371, Val Loss: 0.6657, F1 Micro: 0.6648, F1 Macro: 0.6299, Accuracy: 0.6648\n","Epoch 40, Train Loss: 0.6414, Val Loss: 0.6538, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 41, Train Loss: 0.6362, Val Loss: 0.6617, F1 Micro: 0.6872, F1 Macro: 0.5844, Accuracy: 0.6872\n","Epoch 42, Train Loss: 0.6327, Val Loss: 0.6618, F1 Micro: 0.6704, F1 Macro: 0.6374, Accuracy: 0.6704\n","Epoch 43, Train Loss: 0.6396, Val Loss: 0.6828, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 44, Train Loss: 0.6491, Val Loss: 0.6657, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 45, Train Loss: 0.6408, Val Loss: 0.6606, F1 Micro: 0.6536, F1 Macro: 0.6230, Accuracy: 0.6536\n","Epoch 46, Train Loss: 0.6338, Val Loss: 0.6628, F1 Micro: 0.6257, F1 Macro: 0.6117, Accuracy: 0.6257\n","Epoch 47, Train Loss: 0.6375, Val Loss: 0.6497, F1 Micro: 0.6648, F1 Macro: 0.6326, Accuracy: 0.6648\n","Epoch 48, Train Loss: 0.6368, Val Loss: 0.6745, F1 Micro: 0.6872, F1 Macro: 0.5715, Accuracy: 0.6872\n","Epoch 49, Train Loss: 0.6453, Val Loss: 0.6683, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 50, Train Loss: 0.6441, Val Loss: 0.6832, F1 Micro: 0.6480, F1 Macro: 0.6099, Accuracy: 0.6480\n","Epoch 51, Train Loss: 0.6391, Val Loss: 0.6834, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 52, Train Loss: 0.6276, Val Loss: 0.6563, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 53, Train Loss: 0.6355, Val Loss: 0.7438, F1 Micro: 0.6872, F1 Macro: 0.5410, Accuracy: 0.6872\n","Epoch 54, Train Loss: 0.6331, Val Loss: 0.6731, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 55, Train Loss: 0.6306, Val Loss: 0.6961, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 56, Train Loss: 0.6346, Val Loss: 0.6559, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 57, Train Loss: 0.6284, Val Loss: 0.6968, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 58, Train Loss: 0.6361, Val Loss: 0.6686, F1 Micro: 0.6313, F1 Macro: 0.6129, Accuracy: 0.6313\n","Epoch 59, Train Loss: 0.6514, Val Loss: 0.6647, F1 Micro: 0.7151, F1 Macro: 0.6564, Accuracy: 0.7151\n","Epoch 60, Train Loss: 0.6433, Val Loss: 0.6874, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 61, Train Loss: 0.6313, Val Loss: 0.6671, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 62, Train Loss: 0.6282, Val Loss: 0.6704, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 63, Train Loss: 0.6195, Val Loss: 0.6668, F1 Micro: 0.7318, F1 Macro: 0.6710, Accuracy: 0.7318\n","Epoch 64, Train Loss: 0.6381, Val Loss: 0.6503, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 65, Train Loss: 0.6321, Val Loss: 0.6569, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 66, Train Loss: 0.6367, Val Loss: 0.6561, F1 Micro: 0.6592, F1 Macro: 0.6304, Accuracy: 0.6592\n","Epoch 67, Train Loss: 0.6348, Val Loss: 0.6521, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 68, Train Loss: 0.6324, Val Loss: 0.7260, F1 Micro: 0.6816, F1 Macro: 0.5371, Accuracy: 0.6816\n","Epoch 69, Train Loss: 0.6405, Val Loss: 0.6884, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 70, Train Loss: 0.6362, Val Loss: 0.6719, F1 Micro: 0.6034, F1 Macro: 0.5948, Accuracy: 0.6034\n","Epoch 71, Train Loss: 0.6418, Val Loss: 0.6619, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.9081, Val Loss: 0.6397, F1 Micro: 0.7303, F1 Macro: 0.6261, Accuracy: 0.7303\n","Epoch 2, Train Loss: 0.7330, Val Loss: 0.7400, F1 Micro: 0.4382, F1 Macro: 0.4218, Accuracy: 0.4382\n","Epoch 3, Train Loss: 0.6890, Val Loss: 0.9338, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.7253, Val Loss: 0.6922, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6979, Val Loss: 0.6401, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6758, Val Loss: 0.6144, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 7, Train Loss: 0.6791, Val Loss: 0.6677, F1 Micro: 0.7303, F1 Macro: 0.6320, Accuracy: 0.7303\n","Epoch 8, Train Loss: 0.7069, Val Loss: 0.6384, F1 Micro: 0.6629, F1 Macro: 0.6517, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6535, Val Loss: 0.6023, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 10, Train Loss: 0.6526, Val Loss: 0.5999, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 11, Train Loss: 0.6623, Val Loss: 0.5982, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 12, Train Loss: 0.6485, Val Loss: 0.5937, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.6506, Val Loss: 0.6005, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 14, Train Loss: 0.6481, Val Loss: 0.5988, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6493, Val Loss: 0.6075, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6385, Val Loss: 0.5969, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6419, Val Loss: 0.5909, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 18, Train Loss: 0.6456, Val Loss: 0.6077, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 19, Train Loss: 0.6392, Val Loss: 0.5911, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 20, Train Loss: 0.6357, Val Loss: 0.5828, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 21, Train Loss: 0.6415, Val Loss: 0.5812, F1 Micro: 0.7528, F1 Macro: 0.6902, Accuracy: 0.7528\n","Epoch 22, Train Loss: 0.6396, Val Loss: 0.5923, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 23, Train Loss: 0.6308, Val Loss: 0.5980, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6424, Val Loss: 0.5853, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 25, Train Loss: 0.6410, Val Loss: 0.5984, F1 Micro: 0.6798, F1 Macro: 0.5522, Accuracy: 0.6798\n","Epoch 26, Train Loss: 0.6340, Val Loss: 0.5909, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 27, Train Loss: 0.6387, Val Loss: 0.5868, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 28, Train Loss: 0.6445, Val Loss: 0.5784, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 29, Train Loss: 0.6357, Val Loss: 0.5868, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 30, Train Loss: 0.6510, Val Loss: 0.6068, F1 Micro: 0.6910, F1 Macro: 0.5750, Accuracy: 0.6910\n","Epoch 31, Train Loss: 0.6368, Val Loss: 0.6033, F1 Micro: 0.6966, F1 Macro: 0.5567, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6560, Val Loss: 0.5947, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 33, Train Loss: 0.6491, Val Loss: 0.5881, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 34, Train Loss: 0.6309, Val Loss: 0.6030, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 35, Train Loss: 0.6515, Val Loss: 0.5972, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 36, Train Loss: 0.6391, Val Loss: 0.5922, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 37, Train Loss: 0.6348, Val Loss: 0.5883, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 38, Train Loss: 0.6434, Val Loss: 0.5986, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 39, Train Loss: 0.6278, Val Loss: 0.5875, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 40, Train Loss: 0.6489, Val Loss: 0.5886, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 41, Train Loss: 0.6401, Val Loss: 0.6019, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 42, Train Loss: 0.6441, Val Loss: 0.5973, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 43, Train Loss: 0.6359, Val Loss: 0.6117, F1 Micro: 0.7360, F1 Macro: 0.6368, Accuracy: 0.7360\n","Epoch 44, Train Loss: 0.6300, Val Loss: 0.5854, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 45, Train Loss: 0.6354, Val Loss: 0.5813, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 46, Train Loss: 0.6394, Val Loss: 0.6075, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6393, Val Loss: 0.5870, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 48, Train Loss: 0.6361, Val Loss: 0.5791, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 49, Train Loss: 0.6388, Val Loss: 0.6049, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 50, Train Loss: 0.6359, Val Loss: 0.5916, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 51, Train Loss: 0.6319, Val Loss: 0.5937, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 52, Train Loss: 0.6418, Val Loss: 0.6062, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 53, Train Loss: 0.6452, Val Loss: 0.5974, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 54, Train Loss: 0.6440, Val Loss: 0.5856, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 55, Train Loss: 0.6356, Val Loss: 0.6146, F1 Micro: 0.7360, F1 Macro: 0.6425, Accuracy: 0.7360\n","Epoch 56, Train Loss: 0.6480, Val Loss: 0.6144, F1 Micro: 0.7079, F1 Macro: 0.6939, Accuracy: 0.7079\n","Epoch 57, Train Loss: 0.6401, Val Loss: 0.5913, F1 Micro: 0.7360, F1 Macro: 0.6752, Accuracy: 0.7360\n","Epoch 58, Train Loss: 0.6426, Val Loss: 0.5948, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.6469, Val Loss: 0.5865, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 60, Train Loss: 0.6436, Val Loss: 0.5859, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.6303, Val Loss: 0.5866, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 62, Train Loss: 0.6449, Val Loss: 0.5857, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 63, Train Loss: 0.6436, Val Loss: 0.6052, F1 Micro: 0.7135, F1 Macro: 0.6957, Accuracy: 0.7135\n","Epoch 64, Train Loss: 0.6454, Val Loss: 0.5917, F1 Micro: 0.7360, F1 Macro: 0.6626, Accuracy: 0.7360\n","Epoch 65, Train Loss: 0.6454, Val Loss: 0.5876, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 66, Train Loss: 0.6429, Val Loss: 0.5847, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 67, Train Loss: 0.6420, Val Loss: 0.5833, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 68, Train Loss: 0.6449, Val Loss: 0.6126, F1 Micro: 0.6966, F1 Macro: 0.6837, Accuracy: 0.6966\n","Epoch 69, Train Loss: 0.6367, Val Loss: 0.5951, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 70, Train Loss: 0.6409, Val Loss: 0.5985, F1 Micro: 0.7416, F1 Macro: 0.6762, Accuracy: 0.7416\n","Epoch 71, Train Loss: 0.6367, Val Loss: 0.6025, F1 Micro: 0.6854, F1 Macro: 0.5637, Accuracy: 0.6854\n","Epoch 72, Train Loss: 0.6251, Val Loss: 0.6016, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 73, Train Loss: 0.6436, Val Loss: 0.6037, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 74, Train Loss: 0.6369, Val Loss: 0.6032, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 75, Train Loss: 0.6470, Val Loss: 0.5920, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 76, Train Loss: 0.6310, Val Loss: 0.5913, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 77, Train Loss: 0.6351, Val Loss: 0.5889, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 78, Train Loss: 0.6301, Val Loss: 0.6057, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 79, Train Loss: 0.6376, Val Loss: 0.5907, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 80, Train Loss: 0.6419, Val Loss: 0.6018, F1 Micro: 0.7022, F1 Macro: 0.5689, Accuracy: 0.7022\n","Epoch 81, Train Loss: 0.6367, Val Loss: 0.6055, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 82, Train Loss: 0.6419, Val Loss: 0.6105, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 83, Train Loss: 0.6530, Val Loss: 0.5993, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 84, Train Loss: 0.6387, Val Loss: 0.5947, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 85, Train Loss: 0.6324, Val Loss: 0.5894, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 86, Train Loss: 0.6455, Val Loss: 0.5900, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 87, Train Loss: 0.6294, Val Loss: 0.6012, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 88, Train Loss: 0.6394, Val Loss: 0.5945, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 89, Train Loss: 0.6332, Val Loss: 0.6011, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 90, Train Loss: 0.6444, Val Loss: 0.5839, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 91, Train Loss: 0.6524, Val Loss: 0.5989, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 92, Train Loss: 0.6464, Val Loss: 0.6037, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 93, Train Loss: 0.6431, Val Loss: 0.5982, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 94, Train Loss: 0.6422, Val Loss: 0.5894, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 95, Train Loss: 0.6372, Val Loss: 0.5821, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 96, Train Loss: 0.6440, Val Loss: 0.5996, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 97, Train Loss: 0.6536, Val Loss: 0.6019, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 98, Train Loss: 0.6446, Val Loss: 0.5863, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 99, Train Loss: 0.6429, Val Loss: 0.5949, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 100, Train Loss: 0.6353, Val Loss: 0.5823, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 101, Train Loss: 0.6365, Val Loss: 0.5904, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 102, Train Loss: 0.6336, Val Loss: 0.5895, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 103, Train Loss: 0.6320, Val Loss: 0.6507, F1 Micro: 0.6517, F1 Macro: 0.4488, Accuracy: 0.6517\n","Epoch 104, Train Loss: 0.6503, Val Loss: 0.5885, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 105, Train Loss: 0.6465, Val Loss: 0.5954, F1 Micro: 0.7753, F1 Macro: 0.7283, Accuracy: 0.7753\n","Epoch 106, Train Loss: 0.6423, Val Loss: 0.5944, F1 Micro: 0.7416, F1 Macro: 0.6675, Accuracy: 0.7416\n","Epoch 107, Train Loss: 0.6396, Val Loss: 0.6015, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 108, Train Loss: 0.6369, Val Loss: 0.5857, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 109, Train Loss: 0.6399, Val Loss: 0.5864, F1 Micro: 0.7528, F1 Macro: 0.6862, Accuracy: 0.7528\n","Epoch 110, Train Loss: 0.6342, Val Loss: 0.5985, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 111, Train Loss: 0.6497, Val Loss: 0.5864, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 112, Train Loss: 0.6287, Val Loss: 0.5987, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 113, Train Loss: 0.6291, Val Loss: 0.5853, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 114, Train Loss: 0.6371, Val Loss: 0.5915, F1 Micro: 0.7360, F1 Macro: 0.6670, Accuracy: 0.7360\n","Epoch 115, Train Loss: 0.6430, Val Loss: 0.6041, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 116, Train Loss: 0.6430, Val Loss: 0.5959, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 117, Train Loss: 0.6434, Val Loss: 0.5861, F1 Micro: 0.7472, F1 Macro: 0.6890, Accuracy: 0.7472\n","Epoch 118, Train Loss: 0.6336, Val Loss: 0.6192, F1 Micro: 0.6854, F1 Macro: 0.5637, Accuracy: 0.6854\n","Epoch 119, Train Loss: 0.6462, Val Loss: 0.5973, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 120, Train Loss: 0.6388, Val Loss: 0.5965, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 121, Train Loss: 0.6372, Val Loss: 0.6023, F1 Micro: 0.6854, F1 Macro: 0.5403, Accuracy: 0.6854\n","Epoch 122, Train Loss: 0.6358, Val Loss: 0.5861, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 123, Train Loss: 0.6319, Val Loss: 0.6035, F1 Micro: 0.7416, F1 Macro: 0.6629, Accuracy: 0.7416\n","Epoch 124, Train Loss: 0.6408, Val Loss: 0.5933, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 125, Train Loss: 0.6429, Val Loss: 0.6012, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 126, Train Loss: 0.6326, Val Loss: 0.6005, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 127, Train Loss: 0.6419, Val Loss: 0.5818, F1 Micro: 0.7416, F1 Macro: 0.6974, Accuracy: 0.7416\n","Epoch 128, Train Loss: 0.6376, Val Loss: 0.5880, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 129, Train Loss: 0.6362, Val Loss: 0.5880, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 130, Train Loss: 0.6348, Val Loss: 0.6028, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 131, Train Loss: 0.6354, Val Loss: 0.5904, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 132, Train Loss: 0.6384, Val Loss: 0.5833, F1 Micro: 0.7584, F1 Macro: 0.7286, Accuracy: 0.7584\n","Epoch 133, Train Loss: 0.6297, Val Loss: 0.6037, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 134, Train Loss: 0.6341, Val Loss: 0.5972, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 135, Train Loss: 0.6488, Val Loss: 0.5909, F1 Micro: 0.7528, F1 Macro: 0.7278, Accuracy: 0.7528\n","Epoch 136, Train Loss: 0.6292, Val Loss: 0.5870, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 137, Train Loss: 0.6474, Val Loss: 0.5884, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 138, Train Loss: 0.6337, Val Loss: 0.6108, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 139, Train Loss: 0.6415, Val Loss: 0.5845, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 140, Train Loss: 0.6281, Val Loss: 0.5968, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 141, Train Loss: 0.6328, Val Loss: 0.5906, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 142, Train Loss: 0.6390, Val Loss: 0.5930, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 143, Train Loss: 0.6313, Val Loss: 0.5871, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 144, Train Loss: 0.6378, Val Loss: 0.5873, F1 Micro: 0.7528, F1 Macro: 0.6902, Accuracy: 0.7528\n","Epoch 145, Train Loss: 0.6449, Val Loss: 0.5867, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 146, Train Loss: 0.6482, Val Loss: 0.5896, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 147, Train Loss: 0.6341, Val Loss: 0.6017, F1 Micro: 0.6910, F1 Macro: 0.5443, Accuracy: 0.6910\n","Epoch 148, Train Loss: 0.6396, Val Loss: 0.5912, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 149, Train Loss: 0.6314, Val Loss: 0.5926, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 150, Train Loss: 0.6423, Val Loss: 0.5957, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 151, Train Loss: 0.6354, Val Loss: 0.5853, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 152, Train Loss: 0.6401, Val Loss: 0.5881, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 153, Train Loss: 0.6342, Val Loss: 0.5931, F1 Micro: 0.7416, F1 Macro: 0.7194, Accuracy: 0.7416\n","Epoch 154, Train Loss: 0.6350, Val Loss: 0.5857, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 155, Train Loss: 0.6323, Val Loss: 0.5960, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8540, Val Loss: 0.8585, F1 Micro: 0.6292, F1 Macro: 0.4582, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.7482, Val Loss: 0.8386, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 3, Train Loss: 0.7116, Val Loss: 0.6966, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 4, Train Loss: 0.7066, Val Loss: 0.6696, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.7098, Val Loss: 0.6762, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6449, Val Loss: 0.7021, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 7, Train Loss: 0.6516, Val Loss: 0.7231, F1 Micro: 0.6685, F1 Macro: 0.6500, Accuracy: 0.6685\n","Epoch 8, Train Loss: 0.6535, Val Loss: 0.7616, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 9, Train Loss: 0.6576, Val Loss: 0.6870, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6430, Val Loss: 0.6673, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6504, Val Loss: 0.6922, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6365, Val Loss: 0.7175, F1 Micro: 0.6348, F1 Macro: 0.5270, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.6532, Val Loss: 0.7113, F1 Micro: 0.5337, F1 Macro: 0.5325, Accuracy: 0.5337\n","Epoch 14, Train Loss: 0.6710, Val Loss: 0.6830, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6426, Val Loss: 0.6992, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6290, Val Loss: 0.7228, F1 Micro: 0.6124, F1 Macro: 0.4752, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6406, Val Loss: 0.6632, F1 Micro: 0.6404, F1 Macro: 0.5871, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6439, Val Loss: 0.6654, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.6391, Val Loss: 0.6938, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6306, Val Loss: 0.6913, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6346, Val Loss: 0.7048, F1 Micro: 0.6292, F1 Macro: 0.5293, Accuracy: 0.6292\n","Epoch 22, Train Loss: 0.6285, Val Loss: 0.6846, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.6462, Val Loss: 0.7094, F1 Micro: 0.6180, F1 Macro: 0.5151, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.6254, Val Loss: 0.6789, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6358, Val Loss: 0.7013, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 26, Train Loss: 0.6340, Val Loss: 0.6700, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 27, Train Loss: 0.6264, Val Loss: 0.7255, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6466, Val Loss: 0.7215, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6398, Val Loss: 0.6622, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6317, Val Loss: 0.6832, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.6315, Val Loss: 0.6642, F1 Micro: 0.6629, F1 Macro: 0.6430, Accuracy: 0.6629\n","Epoch 32, Train Loss: 0.6310, Val Loss: 0.6929, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.6198, Val Loss: 0.6732, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 34, Train Loss: 0.6227, Val Loss: 0.6777, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 35, Train Loss: 0.6303, Val Loss: 0.6970, F1 Micro: 0.6124, F1 Macro: 0.6046, Accuracy: 0.6124\n","Epoch 36, Train Loss: 0.6184, Val Loss: 0.6869, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.6331, Val Loss: 0.6816, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 38, Train Loss: 0.6310, Val Loss: 0.7136, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 39, Train Loss: 0.6443, Val Loss: 0.6877, F1 Micro: 0.6180, F1 Macro: 0.4944, Accuracy: 0.6180\n","Epoch 40, Train Loss: 0.6346, Val Loss: 0.6651, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 41, Train Loss: 0.6360, Val Loss: 0.6747, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 42, Train Loss: 0.6356, Val Loss: 0.6667, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.6351, Val Loss: 0.6766, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.6418, Val Loss: 0.6554, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 45, Train Loss: 0.6281, Val Loss: 0.6945, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.6265, Val Loss: 0.6797, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6290, Val Loss: 0.6976, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6524, Val Loss: 0.6726, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 49, Train Loss: 0.6268, Val Loss: 0.6845, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 50, Train Loss: 0.6331, Val Loss: 0.7016, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 51, Train Loss: 0.6283, Val Loss: 0.6882, F1 Micro: 0.6404, F1 Macro: 0.5550, Accuracy: 0.6404\n","Epoch 52, Train Loss: 0.6228, Val Loss: 0.6611, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 53, Train Loss: 0.6190, Val Loss: 0.6850, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 54, Train Loss: 0.6275, Val Loss: 0.6952, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 55, Train Loss: 0.6308, Val Loss: 0.6858, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 56, Train Loss: 0.6361, Val Loss: 0.6767, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 57, Train Loss: 0.6481, Val Loss: 0.6798, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6333, Val Loss: 0.6698, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 59, Train Loss: 0.6401, Val Loss: 0.6887, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 60, Train Loss: 0.6413, Val Loss: 0.6572, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 61, Train Loss: 0.6365, Val Loss: 0.6729, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 62, Train Loss: 0.6271, Val Loss: 0.6810, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 63, Train Loss: 0.6324, Val Loss: 0.6810, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 64, Train Loss: 0.6239, Val Loss: 0.6869, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 65, Train Loss: 0.6191, Val Loss: 0.6689, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 66, Train Loss: 0.6360, Val Loss: 0.6911, F1 Micro: 0.6404, F1 Macro: 0.5908, Accuracy: 0.6404\n","Epoch 67, Train Loss: 0.6328, Val Loss: 0.7106, F1 Micro: 0.6180, F1 Macro: 0.4787, Accuracy: 0.6180\n","Epoch 68, Train Loss: 0.6141, Val Loss: 0.6824, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 69, Train Loss: 0.6164, Val Loss: 0.6957, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 70, Train Loss: 0.6231, Val Loss: 0.6824, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 71, Train Loss: 0.6384, Val Loss: 0.6840, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 72, Train Loss: 0.6253, Val Loss: 0.7400, F1 Micro: 0.6180, F1 Macro: 0.4418, Accuracy: 0.6180\n","Epoch 73, Train Loss: 0.6272, Val Loss: 0.7085, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 74, Train Loss: 0.6165, Val Loss: 0.7014, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 75, Train Loss: 0.6170, Val Loss: 0.6894, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 76, Train Loss: 0.6287, Val Loss: 0.6716, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 77, Train Loss: 0.6236, Val Loss: 0.6842, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 78, Train Loss: 0.6446, Val Loss: 0.6713, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 79, Train Loss: 0.6250, Val Loss: 0.6855, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 80, Train Loss: 0.6522, Val Loss: 0.6637, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 81, Train Loss: 0.6243, Val Loss: 0.7060, F1 Micro: 0.6854, F1 Macro: 0.6197, Accuracy: 0.6854\n","Epoch 82, Train Loss: 0.6201, Val Loss: 0.7011, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 83, Train Loss: 0.6302, Val Loss: 0.7436, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 84, Train Loss: 0.6233, Val Loss: 0.6726, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 85, Train Loss: 0.6222, Val Loss: 0.6834, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 86, Train Loss: 0.6265, Val Loss: 0.6699, F1 Micro: 0.6292, F1 Macro: 0.5354, Accuracy: 0.6292\n","Epoch 87, Train Loss: 0.6320, Val Loss: 0.6727, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 88, Train Loss: 0.6196, Val Loss: 0.6835, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 89, Train Loss: 0.6361, Val Loss: 0.6788, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 90, Train Loss: 0.6199, Val Loss: 0.7103, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 91, Train Loss: 0.6168, Val Loss: 0.6938, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 92, Train Loss: 0.6210, Val Loss: 0.6892, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.6208, Val Loss: 0.6829, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 94, Train Loss: 0.6320, Val Loss: 0.7037, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 95, Train Loss: 0.6175, Val Loss: 0.6825, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 96, Train Loss: 0.6188, Val Loss: 0.6908, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 97, Train Loss: 0.6147, Val Loss: 0.6972, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 98, Train Loss: 0.6330, Val Loss: 0.7012, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 99, Train Loss: 0.6199, Val Loss: 0.7262, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 100, Train Loss: 0.6128, Val Loss: 0.6847, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 101, Train Loss: 0.6163, Val Loss: 0.6886, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 102, Train Loss: 0.6366, Val Loss: 0.6969, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 103, Train Loss: 0.6269, Val Loss: 0.6913, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 104, Train Loss: 0.6338, Val Loss: 0.6685, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 105, Train Loss: 0.6212, Val Loss: 0.6938, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 106, Train Loss: 0.6428, Val Loss: 0.6835, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 107, Train Loss: 0.6318, Val Loss: 0.6728, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 108, Train Loss: 0.6218, Val Loss: 0.6970, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 109, Train Loss: 0.6253, Val Loss: 0.7016, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 110, Train Loss: 0.6388, Val Loss: 0.6812, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 111, Train Loss: 0.6412, Val Loss: 0.6632, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 112, Train Loss: 0.6285, Val Loss: 0.7046, F1 Micro: 0.6461, F1 Macro: 0.5916, Accuracy: 0.6461\n","Epoch 113, Train Loss: 0.6336, Val Loss: 0.6852, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 114, Train Loss: 0.6440, Val Loss: 0.6900, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 115, Train Loss: 0.6318, Val Loss: 0.6972, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 116, Train Loss: 0.6288, Val Loss: 0.7076, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 117, Train Loss: 0.6294, Val Loss: 0.7120, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 118, Train Loss: 0.6283, Val Loss: 0.6957, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 119, Train Loss: 0.6266, Val Loss: 0.7282, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 120, Train Loss: 0.6270, Val Loss: 0.7104, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 121, Train Loss: 0.6339, Val Loss: 0.7237, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 122, Train Loss: 0.6268, Val Loss: 0.6804, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 123, Train Loss: 0.6325, Val Loss: 0.6968, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 124, Train Loss: 0.6371, Val Loss: 0.6784, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 125, Train Loss: 0.6141, Val Loss: 0.6928, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 126, Train Loss: 0.6231, Val Loss: 0.6925, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 127, Train Loss: 0.6259, Val Loss: 0.6975, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 128, Train Loss: 0.6264, Val Loss: 0.6934, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 129, Train Loss: 0.6306, Val Loss: 0.6972, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 130, Train Loss: 0.6290, Val Loss: 0.7130, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 131, Train Loss: 0.6266, Val Loss: 0.6709, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8449, Val Loss: 0.8068, F1 Micro: 0.5843, F1 Macro: 0.4916, Accuracy: 0.5843\n","Epoch 2, Train Loss: 0.6677, Val Loss: 0.7805, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.6914, Val Loss: 0.9503, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6647, Val Loss: 0.6901, F1 Micro: 0.6292, F1 Macro: 0.6198, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6782, Val Loss: 0.7676, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6716, Val Loss: 0.7667, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 7, Train Loss: 0.6452, Val Loss: 0.8121, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 8, Train Loss: 0.6388, Val Loss: 0.6588, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6473, Val Loss: 0.8122, F1 Micro: 0.5562, F1 Macro: 0.4879, Accuracy: 0.5562\n","Epoch 10, Train Loss: 0.6621, Val Loss: 0.8301, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 11, Train Loss: 0.6576, Val Loss: 0.7188, F1 Micro: 0.5225, F1 Macro: 0.3726, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6388, Val Loss: 0.6620, F1 Micro: 0.6404, F1 Macro: 0.6326, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6310, Val Loss: 0.6718, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6089, Val Loss: 0.7133, F1 Micro: 0.6348, F1 Macro: 0.6275, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6288, Val Loss: 0.9055, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 16, Train Loss: 0.6251, Val Loss: 0.6817, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 17, Train Loss: 0.6324, Val Loss: 0.7215, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 18, Train Loss: 0.6363, Val Loss: 0.6899, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 19, Train Loss: 0.6454, Val Loss: 0.7139, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 20, Train Loss: 0.6298, Val Loss: 0.6654, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 21, Train Loss: 0.6364, Val Loss: 0.7050, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 22, Train Loss: 0.6204, Val Loss: 0.6810, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6227, Val Loss: 0.7290, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 24, Train Loss: 0.6231, Val Loss: 0.6622, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 25, Train Loss: 0.6185, Val Loss: 0.7773, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 26, Train Loss: 0.6201, Val Loss: 0.7078, F1 Micro: 0.6236, F1 Macro: 0.6201, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6253, Val Loss: 0.8436, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 28, Train Loss: 0.6270, Val Loss: 0.6631, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 29, Train Loss: 0.6243, Val Loss: 0.8053, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 30, Train Loss: 0.6303, Val Loss: 0.7787, F1 Micro: 0.5730, F1 Macro: 0.5141, Accuracy: 0.5730\n","Epoch 31, Train Loss: 0.6272, Val Loss: 0.6914, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 32, Train Loss: 0.6220, Val Loss: 0.7270, F1 Micro: 0.6124, F1 Macro: 0.5986, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.6336, Val Loss: 0.6768, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 34, Train Loss: 0.6204, Val Loss: 0.6694, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 35, Train Loss: 0.6321, Val Loss: 0.7454, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 36, Train Loss: 0.6387, Val Loss: 0.7099, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 37, Train Loss: 0.6221, Val Loss: 0.6863, F1 Micro: 0.6292, F1 Macro: 0.6168, Accuracy: 0.6292\n","Epoch 38, Train Loss: 0.6208, Val Loss: 0.6786, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 39, Train Loss: 0.6213, Val Loss: 0.7438, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6125, Val Loss: 0.6820, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 41, Train Loss: 0.6264, Val Loss: 0.8273, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 42, Train Loss: 0.6099, Val Loss: 0.6820, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 43, Train Loss: 0.6261, Val Loss: 0.6951, F1 Micro: 0.6292, F1 Macro: 0.6095, Accuracy: 0.6292\n","Epoch 44, Train Loss: 0.6226, Val Loss: 0.7022, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 45, Train Loss: 0.6249, Val Loss: 0.7332, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 46, Train Loss: 0.6301, Val Loss: 0.7492, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 47, Train Loss: 0.6297, Val Loss: 0.7183, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 48, Train Loss: 0.6227, Val Loss: 0.7158, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 49, Train Loss: 0.6229, Val Loss: 0.7483, F1 Micro: 0.5730, F1 Macro: 0.4650, Accuracy: 0.5730\n","Epoch 50, Train Loss: 0.6209, Val Loss: 0.7237, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 51, Train Loss: 0.6252, Val Loss: 0.7446, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 52, Train Loss: 0.6215, Val Loss: 0.6857, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 53, Train Loss: 0.6136, Val Loss: 0.7543, F1 Micro: 0.6292, F1 Macro: 0.5780, Accuracy: 0.6292\n","Epoch 54, Train Loss: 0.6202, Val Loss: 0.6673, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 55, Train Loss: 0.6237, Val Loss: 0.7057, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 56, Train Loss: 0.6365, Val Loss: 0.7669, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 57, Train Loss: 0.6341, Val Loss: 0.7360, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 58, Train Loss: 0.6203, Val Loss: 0.7537, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 59, Train Loss: 0.6358, Val Loss: 0.6653, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 60, Train Loss: 0.6324, Val Loss: 0.6753, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 61, Train Loss: 0.6264, Val Loss: 0.6903, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 62, Train Loss: 0.6293, Val Loss: 0.6762, F1 Micro: 0.6348, F1 Macro: 0.6315, Accuracy: 0.6348\n","Epoch 63, Train Loss: 0.6177, Val Loss: 0.7620, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 64, Train Loss: 0.6252, Val Loss: 0.7148, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 65, Train Loss: 0.6134, Val Loss: 0.7540, F1 Micro: 0.5730, F1 Macro: 0.5096, Accuracy: 0.5730\n","Epoch 66, Train Loss: 0.6105, Val Loss: 0.6932, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 67, Train Loss: 0.6278, Val Loss: 0.7355, F1 Micro: 0.6011, F1 Macro: 0.5353, Accuracy: 0.6011\n","Epoch 68, Train Loss: 0.6218, Val Loss: 0.7582, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 69, Train Loss: 0.6276, Val Loss: 0.7106, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 70, Train Loss: 0.6154, Val Loss: 0.6871, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 71, Train Loss: 0.6319, Val Loss: 0.7377, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 72, Train Loss: 0.6290, Val Loss: 0.6931, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 73, Train Loss: 0.6180, Val Loss: 0.6840, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 74, Train Loss: 0.6179, Val Loss: 0.6930, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 75, Train Loss: 0.6221, Val Loss: 0.6911, F1 Micro: 0.6348, F1 Macro: 0.6297, Accuracy: 0.6348\n","Epoch 76, Train Loss: 0.6249, Val Loss: 0.7172, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 77, Train Loss: 0.6187, Val Loss: 0.7853, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 78, Train Loss: 0.6245, Val Loss: 0.7330, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 79, Train Loss: 0.6288, Val Loss: 0.6848, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 80, Train Loss: 0.6140, Val Loss: 0.7332, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 81, Train Loss: 0.6172, Val Loss: 0.7479, F1 Micro: 0.5787, F1 Macro: 0.4935, Accuracy: 0.5787\n","Epoch 82, Train Loss: 0.6266, Val Loss: 0.6827, F1 Micro: 0.6348, F1 Macro: 0.6297, Accuracy: 0.6348\n","Epoch 83, Train Loss: 0.6234, Val Loss: 0.7283, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 84, Train Loss: 0.6281, Val Loss: 0.6891, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 85, Train Loss: 0.6240, Val Loss: 0.7604, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 86, Train Loss: 0.6218, Val Loss: 0.6936, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 87, Train Loss: 0.6178, Val Loss: 0.7845, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 88, Train Loss: 0.6309, Val Loss: 0.7089, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 89, Train Loss: 0.6289, Val Loss: 0.6700, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 90, Train Loss: 0.6261, Val Loss: 0.7241, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 91, Train Loss: 0.6179, Val Loss: 0.7056, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 92, Train Loss: 0.6211, Val Loss: 0.6852, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 93, Train Loss: 0.6215, Val Loss: 0.7495, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 94, Train Loss: 0.6201, Val Loss: 0.7285, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 95, Train Loss: 0.6222, Val Loss: 0.6934, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 96, Train Loss: 0.6233, Val Loss: 0.7483, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 97, Train Loss: 0.6028, Val Loss: 0.7347, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 98, Train Loss: 0.6150, Val Loss: 0.7786, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 99, Train Loss: 0.6188, Val Loss: 0.7615, F1 Micro: 0.5843, F1 Macro: 0.4916, Accuracy: 0.5843\n","Epoch 100, Train Loss: 0.6187, Val Loss: 0.7899, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 101, Train Loss: 0.6078, Val Loss: 0.7094, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 102, Train Loss: 0.6365, Val Loss: 0.7664, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.9274, Val Loss: 0.6480, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.6947, Val Loss: 0.7332, F1 Micro: 0.5843, F1 Macro: 0.5082, Accuracy: 0.5843\n","Epoch 3, Train Loss: 0.6807, Val Loss: 0.6985, F1 Micro: 0.5562, F1 Macro: 0.5561, Accuracy: 0.5562\n","Epoch 4, Train Loss: 0.7363, Val Loss: 0.6467, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6450, Val Loss: 0.6571, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6567, Val Loss: 0.6702, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.6617, Val Loss: 0.6671, F1 Micro: 0.5787, F1 Macro: 0.5783, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.6430, Val Loss: 0.7117, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 9, Train Loss: 0.6419, Val Loss: 0.6661, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 10, Train Loss: 0.6589, Val Loss: 0.6871, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 11, Train Loss: 0.6573, Val Loss: 0.6799, F1 Micro: 0.5674, F1 Macro: 0.5673, Accuracy: 0.5674\n","Epoch 12, Train Loss: 0.6339, Val Loss: 0.6455, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.6353, Val Loss: 0.6550, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6381, Val Loss: 0.6501, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 15, Train Loss: 0.6373, Val Loss: 0.6482, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6345, Val Loss: 0.7028, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6396, Val Loss: 0.6731, F1 Micro: 0.6067, F1 Macro: 0.5982, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6463, Val Loss: 0.6605, F1 Micro: 0.5787, F1 Macro: 0.5715, Accuracy: 0.5787\n","Epoch 19, Train Loss: 0.6302, Val Loss: 0.6568, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6299, Val Loss: 0.6496, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6314, Val Loss: 0.6403, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.6265, Val Loss: 0.6502, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.6392, Val Loss: 0.6639, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 24, Train Loss: 0.6456, Val Loss: 0.6554, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6293, Val Loss: 0.6493, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 26, Train Loss: 0.6220, Val Loss: 0.6521, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 27, Train Loss: 0.6389, Val Loss: 0.6564, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 28, Train Loss: 0.6329, Val Loss: 0.6528, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 29, Train Loss: 0.6252, Val Loss: 0.6554, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 30, Train Loss: 0.6302, Val Loss: 0.6544, F1 Micro: 0.6461, F1 Macro: 0.6301, Accuracy: 0.6461\n","Epoch 31, Train Loss: 0.6355, Val Loss: 0.6447, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 32, Train Loss: 0.6304, Val Loss: 0.6573, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 33, Train Loss: 0.6302, Val Loss: 0.6577, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 34, Train Loss: 0.6400, Val Loss: 0.6810, F1 Micro: 0.5506, F1 Macro: 0.5497, Accuracy: 0.5506\n","Epoch 35, Train Loss: 0.6370, Val Loss: 0.6562, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6258, Val Loss: 0.6493, F1 Micro: 0.6517, F1 Macro: 0.6441, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6293, Val Loss: 0.6548, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 38, Train Loss: 0.6298, Val Loss: 0.6666, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 39, Train Loss: 0.6387, Val Loss: 0.6500, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 40, Train Loss: 0.6328, Val Loss: 0.6476, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 41, Train Loss: 0.6419, Val Loss: 0.6578, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 42, Train Loss: 0.6416, Val Loss: 0.6499, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 43, Train Loss: 0.6253, Val Loss: 0.6654, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 44, Train Loss: 0.6126, Val Loss: 0.6781, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 45, Train Loss: 0.6385, Val Loss: 0.6615, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 46, Train Loss: 0.6344, Val Loss: 0.6535, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 47, Train Loss: 0.6255, Val Loss: 0.6627, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6372, Val Loss: 0.6596, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 49, Train Loss: 0.6242, Val Loss: 0.6674, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 50, Train Loss: 0.6346, Val Loss: 0.6495, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 51, Train Loss: 0.6231, Val Loss: 0.6470, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 52, Train Loss: 0.6303, Val Loss: 0.6541, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 53, Train Loss: 0.6165, Val Loss: 0.6584, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6330, Val Loss: 0.6567, F1 Micro: 0.6854, F1 Macro: 0.6197, Accuracy: 0.6854\n","Epoch 55, Train Loss: 0.6348, Val Loss: 0.6503, F1 Micro: 0.6348, F1 Macro: 0.6262, Accuracy: 0.6348\n","Epoch 56, Train Loss: 0.6270, Val Loss: 0.6412, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 57, Train Loss: 0.6242, Val Loss: 0.6502, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 58, Train Loss: 0.6400, Val Loss: 0.6591, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 59, Train Loss: 0.6244, Val Loss: 0.6716, F1 Micro: 0.6461, F1 Macro: 0.5876, Accuracy: 0.6461\n","Epoch 60, Train Loss: 0.6403, Val Loss: 0.6708, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 61, Train Loss: 0.6231, Val Loss: 0.6578, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.6406, Val Loss: 0.6897, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.7171489548678677\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6822, Val Loss: 0.6733, F1 Micro: 0.6760, F1 Macro: 0.5562, Accuracy: 0.6760\n","Epoch 2, Train Loss: 0.6570, Val Loss: 0.7047, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 3, Train Loss: 0.6441, Val Loss: 0.6876, F1 Micro: 0.6704, F1 Macro: 0.5119, Accuracy: 0.6704\n","Epoch 4, Train Loss: 0.6440, Val Loss: 0.6660, F1 Micro: 0.7151, F1 Macro: 0.6187, Accuracy: 0.7151\n","Epoch 5, Train Loss: 0.6539, Val Loss: 0.6693, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 6, Train Loss: 0.6691, Val Loss: 0.6569, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 7, Train Loss: 0.6547, Val Loss: 0.6569, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 8, Train Loss: 0.6500, Val Loss: 0.6761, F1 Micro: 0.6480, F1 Macro: 0.6001, Accuracy: 0.6480\n","Epoch 9, Train Loss: 0.6357, Val Loss: 0.7204, F1 Micro: 0.6536, F1 Macro: 0.5010, Accuracy: 0.6536\n","Epoch 10, Train Loss: 0.6506, Val Loss: 0.6841, F1 Micro: 0.6089, F1 Macro: 0.5934, Accuracy: 0.6089\n","Epoch 11, Train Loss: 0.6563, Val Loss: 0.7090, F1 Micro: 0.6704, F1 Macro: 0.5119, Accuracy: 0.6704\n","Epoch 12, Train Loss: 0.6325, Val Loss: 0.6689, F1 Micro: 0.6592, F1 Macro: 0.5569, Accuracy: 0.6592\n","Epoch 13, Train Loss: 0.6404, Val Loss: 0.6544, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 14, Train Loss: 0.6474, Val Loss: 0.6555, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6931, Val Loss: 0.7020, F1 Micro: 0.5787, F1 Macro: 0.5499, Accuracy: 0.5787\n","Epoch 2, Train Loss: 0.6681, Val Loss: 0.6517, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.7011, Val Loss: 0.6306, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 4, Train Loss: 0.6525, Val Loss: 0.6373, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 5, Train Loss: 0.6659, Val Loss: 0.6106, F1 Micro: 0.7303, F1 Macro: 0.6621, Accuracy: 0.7303\n","Epoch 6, Train Loss: 0.6481, Val Loss: 0.6246, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.6596, Val Loss: 0.6133, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 8, Train Loss: 0.6612, Val Loss: 0.6259, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 9, Train Loss: 0.6511, Val Loss: 0.6201, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6485, Val Loss: 0.6309, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 11, Train Loss: 0.6465, Val Loss: 0.6131, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6481, Val Loss: 0.6036, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 13, Train Loss: 0.6481, Val Loss: 0.6213, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6555, Val Loss: 0.6499, F1 Micro: 0.7135, F1 Macro: 0.6288, Accuracy: 0.7135\n","Epoch 15, Train Loss: 0.6547, Val Loss: 0.6489, F1 Micro: 0.6798, F1 Macro: 0.5277, Accuracy: 0.6798\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6661, Val Loss: 0.6556, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6553, Val Loss: 0.6613, F1 Micro: 0.6124, F1 Macro: 0.4979, Accuracy: 0.6124\n","Epoch 3, Train Loss: 0.6689, Val Loss: 0.6688, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6490, Val Loss: 0.6746, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6739, Val Loss: 0.6683, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6468, Val Loss: 0.6621, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6786, Val Loss: 0.6378, F1 Micro: 0.6348, F1 Macro: 0.5862, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6469, Val Loss: 0.6335, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6595, Val Loss: 0.6553, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.6418, Val Loss: 0.6737, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6561, Val Loss: 0.6462, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6419, Val Loss: 0.7159, F1 Micro: 0.6517, F1 Macro: 0.4911, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6480, Val Loss: 0.6631, F1 Micro: 0.6573, F1 Macro: 0.6082, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6443, Val Loss: 0.6372, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6420, Val Loss: 0.6430, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6435, Val Loss: 0.6404, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6950, Val Loss: 0.7072, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 2, Train Loss: 0.6676, Val Loss: 0.6859, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6448, Val Loss: 0.6867, F1 Micro: 0.5843, F1 Macro: 0.5082, Accuracy: 0.5843\n","Epoch 4, Train Loss: 0.6451, Val Loss: 0.7039, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 5, Train Loss: 0.6453, Val Loss: 0.6791, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6362, Val Loss: 0.6468, F1 Micro: 0.6685, F1 Macro: 0.6647, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.6636, Val Loss: 0.7050, F1 Micro: 0.5618, F1 Macro: 0.5013, Accuracy: 0.5618\n","Epoch 8, Train Loss: 0.6412, Val Loss: 0.6579, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6470, Val Loss: 0.6557, F1 Micro: 0.6124, F1 Macro: 0.5986, Accuracy: 0.6124\n","Epoch 10, Train Loss: 0.6528, Val Loss: 0.6996, F1 Micro: 0.5787, F1 Macro: 0.5041, Accuracy: 0.5787\n","Epoch 11, Train Loss: 0.6423, Val Loss: 0.6758, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6560, Val Loss: 0.6479, F1 Micro: 0.6573, F1 Macro: 0.6541, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6325, Val Loss: 0.6917, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 14, Train Loss: 0.6285, Val Loss: 0.8748, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 15, Train Loss: 0.6370, Val Loss: 0.7017, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 16, Train Loss: 0.6382, Val Loss: 0.6796, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6695, Val Loss: 0.6694, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6682, Val Loss: 0.7931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6650, Val Loss: 0.6846, F1 Micro: 0.6067, F1 Macro: 0.4795, Accuracy: 0.6067\n","Epoch 4, Train Loss: 0.6535, Val Loss: 0.6850, F1 Micro: 0.6236, F1 Macro: 0.4550, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6620, Val Loss: 0.6617, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 6, Train Loss: 0.6346, Val Loss: 0.7951, F1 Micro: 0.4045, F1 Macro: 0.3535, Accuracy: 0.4045\n","Epoch 7, Train Loss: 0.6925, Val Loss: 0.6722, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6531, Val Loss: 0.6921, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6435, Val Loss: 0.6661, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6543, Val Loss: 0.6442, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6381, Val Loss: 0.6661, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 12, Train Loss: 0.6392, Val Loss: 0.6682, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6330, Val Loss: 0.6675, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6126, Val Loss: 0.6923, F1 Micro: 0.5843, F1 Macro: 0.5817, Accuracy: 0.5843\n","Epoch 15, Train Loss: 0.6596, Val Loss: 0.6765, F1 Micro: 0.6180, F1 Macro: 0.5272, Accuracy: 0.6180\n","Epoch 16, Train Loss: 0.6463, Val Loss: 0.6954, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 17, Train Loss: 0.6484, Val Loss: 0.7480, F1 Micro: 0.6236, F1 Macro: 0.5055, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6563, Val Loss: 0.6809, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.6548, Val Loss: 0.6868, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.6439, Val Loss: 0.6900, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.6890841755068735\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6897, Val Loss: 0.6712, F1 Micro: 0.6927, F1 Macro: 0.5948, Accuracy: 0.6927\n","Epoch 2, Train Loss: 0.6448, Val Loss: 0.6769, F1 Micro: 0.6816, F1 Macro: 0.5530, Accuracy: 0.6816\n","Epoch 3, Train Loss: 0.6517, Val Loss: 0.6825, F1 Micro: 0.6257, F1 Macro: 0.5912, Accuracy: 0.6257\n","Epoch 4, Train Loss: 0.6550, Val Loss: 0.6880, F1 Micro: 0.6480, F1 Macro: 0.4345, Accuracy: 0.6480\n","Epoch 5, Train Loss: 0.6467, Val Loss: 0.6625, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 6, Train Loss: 0.6548, Val Loss: 0.7138, F1 Micro: 0.5587, F1 Macro: 0.5421, Accuracy: 0.5587\n","Epoch 7, Train Loss: 0.6525, Val Loss: 0.6482, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 8, Train Loss: 0.6408, Val Loss: 0.6758, F1 Micro: 0.6257, F1 Macro: 0.5912, Accuracy: 0.6257\n","Epoch 9, Train Loss: 0.6525, Val Loss: 0.6490, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.6453, Val Loss: 0.6648, F1 Micro: 0.6480, F1 Macro: 0.6001, Accuracy: 0.6480\n","Epoch 11, Train Loss: 0.6458, Val Loss: 0.6827, F1 Micro: 0.6257, F1 Macro: 0.5851, Accuracy: 0.6257\n","Epoch 12, Train Loss: 0.6390, Val Loss: 0.6882, F1 Micro: 0.6983, F1 Macro: 0.5654, Accuracy: 0.6983\n","Epoch 13, Train Loss: 0.6487, Val Loss: 0.6732, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 14, Train Loss: 0.6608, Val Loss: 0.6671, F1 Micro: 0.6536, F1 Macro: 0.5096, Accuracy: 0.6536\n","Epoch 15, Train Loss: 0.6536, Val Loss: 0.6520, F1 Micro: 0.6760, F1 Macro: 0.5413, Accuracy: 0.6760\n","Epoch 16, Train Loss: 0.6608, Val Loss: 0.6709, F1 Micro: 0.6648, F1 Macro: 0.6174, Accuracy: 0.6648\n","Epoch 17, Train Loss: 0.6547, Val Loss: 0.6637, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 18, Train Loss: 0.6443, Val Loss: 0.6395, F1 Micro: 0.6648, F1 Macro: 0.5547, Accuracy: 0.6648\n","Epoch 19, Train Loss: 0.6511, Val Loss: 0.7795, F1 Micro: 0.6480, F1 Macro: 0.4216, Accuracy: 0.6480\n","Epoch 20, Train Loss: 0.6460, Val Loss: 0.6522, F1 Micro: 0.6927, F1 Macro: 0.5948, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6522, Val Loss: 0.6605, F1 Micro: 0.6536, F1 Macro: 0.6010, Accuracy: 0.6536\n","Epoch 22, Train Loss: 0.6439, Val Loss: 0.6783, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Epoch 23, Train Loss: 0.6402, Val Loss: 0.6628, F1 Micro: 0.6704, F1 Macro: 0.6185, Accuracy: 0.6704\n","Epoch 24, Train Loss: 0.6373, Val Loss: 0.6653, F1 Micro: 0.6425, F1 Macro: 0.6109, Accuracy: 0.6425\n","Epoch 25, Train Loss: 0.6384, Val Loss: 0.6642, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 26, Train Loss: 0.6386, Val Loss: 0.6485, F1 Micro: 0.6816, F1 Macro: 0.6241, Accuracy: 0.6816\n","Epoch 27, Train Loss: 0.6358, Val Loss: 0.6722, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 28, Train Loss: 0.6355, Val Loss: 0.6582, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 29, Train Loss: 0.6411, Val Loss: 0.6494, F1 Micro: 0.6592, F1 Macro: 0.6056, Accuracy: 0.6592\n","Epoch 30, Train Loss: 0.6505, Val Loss: 0.6741, F1 Micro: 0.6480, F1 Macro: 0.5845, Accuracy: 0.6480\n","Epoch 31, Train Loss: 0.6292, Val Loss: 0.6827, F1 Micro: 0.6872, F1 Macro: 0.5493, Accuracy: 0.6872\n","Epoch 32, Train Loss: 0.6727, Val Loss: 0.6699, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 33, Train Loss: 0.6388, Val Loss: 0.6708, F1 Micro: 0.6704, F1 Macro: 0.6346, Accuracy: 0.6704\n","Epoch 34, Train Loss: 0.6376, Val Loss: 0.6639, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 35, Train Loss: 0.6345, Val Loss: 0.6579, F1 Micro: 0.6648, F1 Macro: 0.6102, Accuracy: 0.6648\n","Epoch 36, Train Loss: 0.6516, Val Loss: 0.6761, F1 Micro: 0.6983, F1 Macro: 0.5729, Accuracy: 0.6983\n","Epoch 37, Train Loss: 0.6481, Val Loss: 0.6863, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 38, Train Loss: 0.6602, Val Loss: 0.6571, F1 Micro: 0.6816, F1 Macro: 0.6241, Accuracy: 0.6816\n","Epoch 39, Train Loss: 0.6438, Val Loss: 0.6474, F1 Micro: 0.7039, F1 Macro: 0.5844, Accuracy: 0.7039\n","Epoch 40, Train Loss: 0.6363, Val Loss: 0.6476, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 41, Train Loss: 0.6363, Val Loss: 0.6504, F1 Micro: 0.6648, F1 Macro: 0.5611, Accuracy: 0.6648\n","Epoch 42, Train Loss: 0.6453, Val Loss: 0.6837, F1 Micro: 0.6425, F1 Macro: 0.5103, Accuracy: 0.6425\n","Epoch 43, Train Loss: 0.6217, Val Loss: 0.6469, F1 Micro: 0.6760, F1 Macro: 0.6268, Accuracy: 0.6760\n","Epoch 44, Train Loss: 0.6300, Val Loss: 0.6461, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 45, Train Loss: 0.6474, Val Loss: 0.6432, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 46, Train Loss: 0.6448, Val Loss: 0.6612, F1 Micro: 0.6872, F1 Macro: 0.6518, Accuracy: 0.6872\n","Epoch 47, Train Loss: 0.6418, Val Loss: 0.6569, F1 Micro: 0.6872, F1 Macro: 0.6545, Accuracy: 0.6872\n","Epoch 48, Train Loss: 0.6285, Val Loss: 0.6454, F1 Micro: 0.6480, F1 Macro: 0.4974, Accuracy: 0.6480\n","Epoch 49, Train Loss: 0.6399, Val Loss: 0.6361, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 50, Train Loss: 0.6332, Val Loss: 0.6475, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 51, Train Loss: 0.6196, Val Loss: 0.6461, F1 Micro: 0.6816, F1 Macro: 0.6241, Accuracy: 0.6816\n","Epoch 52, Train Loss: 0.6307, Val Loss: 0.6611, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 53, Train Loss: 0.6344, Val Loss: 0.6423, F1 Micro: 0.6536, F1 Macro: 0.6175, Accuracy: 0.6536\n","Epoch 54, Train Loss: 0.6267, Val Loss: 0.6437, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 55, Train Loss: 0.6254, Val Loss: 0.6601, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 56, Train Loss: 0.6348, Val Loss: 0.6581, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 57, Train Loss: 0.6416, Val Loss: 0.6771, F1 Micro: 0.6480, F1 Macro: 0.4788, Accuracy: 0.6480\n","Epoch 58, Train Loss: 0.6511, Val Loss: 0.6565, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 59, Train Loss: 0.6189, Val Loss: 0.6533, F1 Micro: 0.6480, F1 Macro: 0.6254, Accuracy: 0.6480\n","Epoch 60, Train Loss: 0.6467, Val Loss: 0.6652, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 61, Train Loss: 0.6363, Val Loss: 0.6400, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 62, Train Loss: 0.6359, Val Loss: 0.6438, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 63, Train Loss: 0.6211, Val Loss: 0.6478, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Epoch 64, Train Loss: 0.6340, Val Loss: 0.6435, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 65, Train Loss: 0.6335, Val Loss: 0.6487, F1 Micro: 0.6648, F1 Macro: 0.6326, Accuracy: 0.6648\n","Epoch 66, Train Loss: 0.6339, Val Loss: 0.6609, F1 Micro: 0.6872, F1 Macro: 0.5904, Accuracy: 0.6872\n","Epoch 67, Train Loss: 0.6323, Val Loss: 0.6434, F1 Micro: 0.6592, F1 Macro: 0.6017, Accuracy: 0.6592\n","Epoch 68, Train Loss: 0.6320, Val Loss: 0.6499, F1 Micro: 0.7207, F1 Macro: 0.6891, Accuracy: 0.7207\n","Epoch 69, Train Loss: 0.6370, Val Loss: 0.6334, F1 Micro: 0.7095, F1 Macro: 0.6622, Accuracy: 0.7095\n","Epoch 70, Train Loss: 0.6309, Val Loss: 0.6496, F1 Micro: 0.6704, F1 Macro: 0.5521, Accuracy: 0.6704\n","Epoch 71, Train Loss: 0.6383, Val Loss: 0.6372, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 72, Train Loss: 0.6252, Val Loss: 0.6456, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 73, Train Loss: 0.6222, Val Loss: 0.6533, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 74, Train Loss: 0.6290, Val Loss: 0.6500, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 75, Train Loss: 0.6161, Val Loss: 0.6772, F1 Micro: 0.6927, F1 Macro: 0.5687, Accuracy: 0.6927\n","Epoch 76, Train Loss: 0.6435, Val Loss: 0.6363, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 77, Train Loss: 0.6167, Val Loss: 0.6595, F1 Micro: 0.6425, F1 Macro: 0.6109, Accuracy: 0.6425\n","Epoch 78, Train Loss: 0.6338, Val Loss: 0.6413, F1 Micro: 0.7263, F1 Macro: 0.6536, Accuracy: 0.7263\n","Epoch 79, Train Loss: 0.6230, Val Loss: 0.6392, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 80, Train Loss: 0.6393, Val Loss: 0.6401, F1 Micro: 0.6704, F1 Macro: 0.6109, Accuracy: 0.6704\n","Epoch 81, Train Loss: 0.6257, Val Loss: 0.6386, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 82, Train Loss: 0.6265, Val Loss: 0.6602, F1 Micro: 0.6816, F1 Macro: 0.6546, Accuracy: 0.6816\n","Epoch 83, Train Loss: 0.6202, Val Loss: 0.6644, F1 Micro: 0.6313, F1 Macro: 0.6064, Accuracy: 0.6313\n","Epoch 84, Train Loss: 0.6218, Val Loss: 0.6807, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 85, Train Loss: 0.6195, Val Loss: 0.6460, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 86, Train Loss: 0.6243, Val Loss: 0.6659, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 87, Train Loss: 0.6222, Val Loss: 0.6789, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 88, Train Loss: 0.6293, Val Loss: 0.6446, F1 Micro: 0.6704, F1 Macro: 0.6317, Accuracy: 0.6704\n","Epoch 89, Train Loss: 0.6433, Val Loss: 0.6529, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 90, Train Loss: 0.6330, Val Loss: 0.6442, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 91, Train Loss: 0.6272, Val Loss: 0.6349, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 92, Train Loss: 0.6248, Val Loss: 0.6511, F1 Micro: 0.6872, F1 Macro: 0.5715, Accuracy: 0.6872\n","Epoch 93, Train Loss: 0.6224, Val Loss: 0.6435, F1 Micro: 0.6760, F1 Macro: 0.6365, Accuracy: 0.6760\n","Epoch 94, Train Loss: 0.6254, Val Loss: 0.6508, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 95, Train Loss: 0.6278, Val Loss: 0.6392, F1 Micro: 0.6927, F1 Macro: 0.6644, Accuracy: 0.6927\n","Epoch 96, Train Loss: 0.6299, Val Loss: 0.6414, F1 Micro: 0.6872, F1 Macro: 0.6362, Accuracy: 0.6872\n","Epoch 97, Train Loss: 0.6091, Val Loss: 0.6667, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 98, Train Loss: 0.6257, Val Loss: 0.6599, F1 Micro: 0.6369, F1 Macro: 0.6178, Accuracy: 0.6369\n","Epoch 99, Train Loss: 0.6305, Val Loss: 0.6373, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 100, Train Loss: 0.6239, Val Loss: 0.6541, F1 Micro: 0.6648, F1 Macro: 0.6299, Accuracy: 0.6648\n","Epoch 101, Train Loss: 0.6148, Val Loss: 0.6455, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 102, Train Loss: 0.6238, Val Loss: 0.6513, F1 Micro: 0.7039, F1 Macro: 0.6468, Accuracy: 0.7039\n","Epoch 103, Train Loss: 0.6272, Val Loss: 0.6880, F1 Micro: 0.6927, F1 Macro: 0.5888, Accuracy: 0.6927\n","Epoch 104, Train Loss: 0.6199, Val Loss: 0.6807, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 105, Train Loss: 0.6321, Val Loss: 0.6412, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 106, Train Loss: 0.6366, Val Loss: 0.6446, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 107, Train Loss: 0.6363, Val Loss: 0.6435, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 108, Train Loss: 0.6256, Val Loss: 0.6455, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 109, Train Loss: 0.6260, Val Loss: 0.6357, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 110, Train Loss: 0.6122, Val Loss: 0.6380, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 111, Train Loss: 0.6268, Val Loss: 0.6545, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 112, Train Loss: 0.6304, Val Loss: 0.6622, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 113, Train Loss: 0.6202, Val Loss: 0.6396, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Epoch 114, Train Loss: 0.6317, Val Loss: 0.6477, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 115, Train Loss: 0.6186, Val Loss: 0.6517, F1 Micro: 0.6536, F1 Macro: 0.6230, Accuracy: 0.6536\n","Epoch 116, Train Loss: 0.6177, Val Loss: 0.6468, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 117, Train Loss: 0.6229, Val Loss: 0.6491, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 118, Train Loss: 0.6223, Val Loss: 0.6466, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 119, Train Loss: 0.6383, Val Loss: 0.6828, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Epoch 120, Train Loss: 0.6277, Val Loss: 0.6384, F1 Micro: 0.6872, F1 Macro: 0.6595, Accuracy: 0.6872\n","Epoch 121, Train Loss: 0.6233, Val Loss: 0.6652, F1 Micro: 0.6089, F1 Macro: 0.5934, Accuracy: 0.6089\n","Epoch 122, Train Loss: 0.6268, Val Loss: 0.6340, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 123, Train Loss: 0.6304, Val Loss: 0.6558, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 124, Train Loss: 0.6153, Val Loss: 0.6428, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 125, Train Loss: 0.6146, Val Loss: 0.6384, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 126, Train Loss: 0.6345, Val Loss: 0.6381, F1 Micro: 0.6872, F1 Macro: 0.6326, Accuracy: 0.6872\n","Epoch 127, Train Loss: 0.6184, Val Loss: 0.6358, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 128, Train Loss: 0.6217, Val Loss: 0.6774, F1 Micro: 0.5922, F1 Macro: 0.5804, Accuracy: 0.5922\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6871, Val Loss: 0.6142, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 2, Train Loss: 0.6831, Val Loss: 0.6373, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.6458, Val Loss: 0.6174, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 4, Train Loss: 0.6771, Val Loss: 0.6286, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 5, Train Loss: 0.6584, Val Loss: 0.6360, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 6, Train Loss: 0.6774, Val Loss: 0.6389, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.6610, Val Loss: 0.6079, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 8, Train Loss: 0.6681, Val Loss: 0.6034, F1 Micro: 0.7416, F1 Macro: 0.6876, Accuracy: 0.7416\n","Epoch 9, Train Loss: 0.6632, Val Loss: 0.6028, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6759, Val Loss: 0.6063, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 11, Train Loss: 0.6469, Val Loss: 0.6511, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6639, Val Loss: 0.6265, F1 Micro: 0.6629, F1 Macro: 0.4665, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6521, Val Loss: 0.6248, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6495, Val Loss: 0.6143, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6546, Val Loss: 0.6047, F1 Micro: 0.7135, F1 Macro: 0.6288, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.6588, Val Loss: 0.6168, F1 Micro: 0.6742, F1 Macro: 0.5053, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6658, Val Loss: 0.6186, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 18, Train Loss: 0.6440, Val Loss: 0.6442, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 19, Train Loss: 0.6508, Val Loss: 0.6181, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Epoch 20, Train Loss: 0.6535, Val Loss: 0.6371, F1 Micro: 0.7247, F1 Macro: 0.6273, Accuracy: 0.7247\n","Epoch 21, Train Loss: 0.6537, Val Loss: 0.6140, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6626, Val Loss: 0.6095, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.6485, Val Loss: 0.6034, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 24, Train Loss: 0.6420, Val Loss: 0.6028, F1 Micro: 0.6798, F1 Macro: 0.5364, Accuracy: 0.6798\n","Epoch 25, Train Loss: 0.6522, Val Loss: 0.6550, F1 Micro: 0.6629, F1 Macro: 0.4665, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.6390, Val Loss: 0.5943, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 27, Train Loss: 0.6437, Val Loss: 0.5985, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 28, Train Loss: 0.6345, Val Loss: 0.6266, F1 Micro: 0.7360, F1 Macro: 0.6368, Accuracy: 0.7360\n","Epoch 29, Train Loss: 0.6649, Val Loss: 0.6086, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 30, Train Loss: 0.6460, Val Loss: 0.6093, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 31, Train Loss: 0.6693, Val Loss: 0.6352, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 32, Train Loss: 0.6262, Val Loss: 0.6117, F1 Micro: 0.7472, F1 Macro: 0.6577, Accuracy: 0.7472\n","Epoch 33, Train Loss: 0.6409, Val Loss: 0.6293, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 34, Train Loss: 0.6528, Val Loss: 0.6083, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 35, Train Loss: 0.6530, Val Loss: 0.6372, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.6583, Val Loss: 0.6167, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 37, Train Loss: 0.6446, Val Loss: 0.5950, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 38, Train Loss: 0.6381, Val Loss: 0.5947, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 39, Train Loss: 0.6401, Val Loss: 0.6324, F1 Micro: 0.6910, F1 Macro: 0.5443, Accuracy: 0.6910\n","Epoch 40, Train Loss: 0.6388, Val Loss: 0.6128, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 41, Train Loss: 0.6271, Val Loss: 0.5950, F1 Micro: 0.7472, F1 Macro: 0.6725, Accuracy: 0.7472\n","Epoch 42, Train Loss: 0.6289, Val Loss: 0.6238, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6353, Val Loss: 0.5988, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 44, Train Loss: 0.6523, Val Loss: 0.5889, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 45, Train Loss: 0.6517, Val Loss: 0.6020, F1 Micro: 0.6910, F1 Macro: 0.5443, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.6356, Val Loss: 0.5973, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 47, Train Loss: 0.6297, Val Loss: 0.6121, F1 Micro: 0.7472, F1 Macro: 0.6770, Accuracy: 0.7472\n","Epoch 48, Train Loss: 0.6516, Val Loss: 0.5930, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 49, Train Loss: 0.6638, Val Loss: 0.5998, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 50, Train Loss: 0.6424, Val Loss: 0.5960, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 51, Train Loss: 0.6454, Val Loss: 0.5889, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7039, Val Loss: 0.6450, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6968, Val Loss: 0.6590, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.6493, Val Loss: 0.6696, F1 Micro: 0.6517, F1 Macro: 0.4814, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6604, Val Loss: 0.6323, F1 Micro: 0.6461, F1 Macro: 0.5990, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6608, Val Loss: 0.6356, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6598, Val Loss: 0.7473, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6554, Val Loss: 0.6415, F1 Micro: 0.6348, F1 Macro: 0.5657, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6429, Val Loss: 0.6591, F1 Micro: 0.6236, F1 Macro: 0.4823, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6536, Val Loss: 0.6473, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6374, Val Loss: 0.6462, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 11, Train Loss: 0.6586, Val Loss: 0.6618, F1 Micro: 0.6124, F1 Macro: 0.4283, Accuracy: 0.6124\n","Epoch 12, Train Loss: 0.6394, Val Loss: 0.6307, F1 Micro: 0.6404, F1 Macro: 0.5977, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6725, Val Loss: 0.6457, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 14, Train Loss: 0.6660, Val Loss: 0.6316, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6541, Val Loss: 0.6378, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6388, Val Loss: 0.6604, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6511, Val Loss: 0.6891, F1 Micro: 0.6067, F1 Macro: 0.4941, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6210, Val Loss: 0.6531, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 19, Train Loss: 0.6302, Val Loss: 0.6772, F1 Micro: 0.6180, F1 Macro: 0.5213, Accuracy: 0.6180\n","Epoch 20, Train Loss: 0.6323, Val Loss: 0.6402, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6570, Val Loss: 0.6389, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 22, Train Loss: 0.6432, Val Loss: 0.6623, F1 Micro: 0.6180, F1 Macro: 0.6035, Accuracy: 0.6180\n","Epoch 23, Train Loss: 0.6560, Val Loss: 0.6431, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 24, Train Loss: 0.6452, Val Loss: 0.6404, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.6431, Val Loss: 0.6374, F1 Micro: 0.6404, F1 Macro: 0.5977, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6606, Val Loss: 0.6500, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.6421, Val Loss: 0.6482, F1 Micro: 0.6236, F1 Macro: 0.5369, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6411, Val Loss: 0.6468, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6383, Val Loss: 0.6355, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 30, Train Loss: 0.6328, Val Loss: 0.6379, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6430, Val Loss: 0.6926, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6333, Val Loss: 0.6560, F1 Micro: 0.6124, F1 Macro: 0.5287, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.6401, Val Loss: 0.6485, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 34, Train Loss: 0.6435, Val Loss: 0.6695, F1 Micro: 0.6180, F1 Macro: 0.4312, Accuracy: 0.6180\n","Epoch 35, Train Loss: 0.6248, Val Loss: 0.7003, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6429, Val Loss: 0.6471, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6261, Val Loss: 0.6647, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 38, Train Loss: 0.6329, Val Loss: 0.6888, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6307, Val Loss: 0.6707, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 40, Train Loss: 0.6422, Val Loss: 0.6500, F1 Micro: 0.6348, F1 Macro: 0.5395, Accuracy: 0.6348\n","Epoch 41, Train Loss: 0.6366, Val Loss: 0.7362, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6324, Val Loss: 0.6752, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6283, Val Loss: 0.6732, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6341, Val Loss: 0.7113, F1 Micro: 0.6236, F1 Macro: 0.4106, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6355, Val Loss: 0.6621, F1 Micro: 0.6180, F1 Macro: 0.5481, Accuracy: 0.6180\n","Epoch 46, Train Loss: 0.6186, Val Loss: 0.6649, F1 Micro: 0.6180, F1 Macro: 0.5382, Accuracy: 0.6180\n","Epoch 47, Train Loss: 0.6514, Val Loss: 0.6601, F1 Micro: 0.6180, F1 Macro: 0.5432, Accuracy: 0.6180\n","Epoch 48, Train Loss: 0.6454, Val Loss: 0.6788, F1 Micro: 0.6292, F1 Macro: 0.5517, Accuracy: 0.6292\n","Epoch 49, Train Loss: 0.6263, Val Loss: 0.6518, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 50, Train Loss: 0.6343, Val Loss: 0.6454, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 51, Train Loss: 0.6191, Val Loss: 0.6540, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 52, Train Loss: 0.6369, Val Loss: 0.6611, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.6506, Val Loss: 0.6728, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 54, Train Loss: 0.6116, Val Loss: 0.6461, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 55, Train Loss: 0.6224, Val Loss: 0.6650, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 56, Train Loss: 0.6309, Val Loss: 0.6635, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 57, Train Loss: 0.6393, Val Loss: 0.6535, F1 Micro: 0.6348, F1 Macro: 0.5746, Accuracy: 0.6348\n","Epoch 58, Train Loss: 0.6267, Val Loss: 0.6578, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 59, Train Loss: 0.6340, Val Loss: 0.6539, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 60, Train Loss: 0.6125, Val Loss: 0.7024, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 61, Train Loss: 0.6276, Val Loss: 0.6604, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Epoch 62, Train Loss: 0.6248, Val Loss: 0.6622, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 63, Train Loss: 0.6301, Val Loss: 0.6537, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 64, Train Loss: 0.6210, Val Loss: 0.6940, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 65, Train Loss: 0.6439, Val Loss: 0.6513, F1 Micro: 0.6180, F1 Macro: 0.5272, Accuracy: 0.6180\n","Epoch 66, Train Loss: 0.6371, Val Loss: 0.6822, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 67, Train Loss: 0.6312, Val Loss: 0.6641, F1 Micro: 0.6180, F1 Macro: 0.5382, Accuracy: 0.6180\n","Epoch 68, Train Loss: 0.6221, Val Loss: 0.6920, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 69, Train Loss: 0.6247, Val Loss: 0.6592, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 70, Train Loss: 0.6370, Val Loss: 0.6601, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 71, Train Loss: 0.6220, Val Loss: 0.6590, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 72, Train Loss: 0.6208, Val Loss: 0.6645, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 73, Train Loss: 0.6485, Val Loss: 0.6731, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.6282, Val Loss: 0.6617, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.6190, Val Loss: 0.6727, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 76, Train Loss: 0.6315, Val Loss: 0.6592, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 77, Train Loss: 0.6394, Val Loss: 0.6559, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 78, Train Loss: 0.6243, Val Loss: 0.6598, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 79, Train Loss: 0.6314, Val Loss: 0.6518, F1 Micro: 0.6236, F1 Macro: 0.5313, Accuracy: 0.6236\n","Epoch 80, Train Loss: 0.6258, Val Loss: 0.6524, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 81, Train Loss: 0.6296, Val Loss: 0.6525, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 82, Train Loss: 0.6156, Val Loss: 0.6947, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 83, Train Loss: 0.6253, Val Loss: 0.6593, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 84, Train Loss: 0.6305, Val Loss: 0.6584, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 85, Train Loss: 0.6263, Val Loss: 0.6580, F1 Micro: 0.6180, F1 Macro: 0.5481, Accuracy: 0.6180\n","Epoch 86, Train Loss: 0.6194, Val Loss: 0.6517, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 87, Train Loss: 0.6239, Val Loss: 0.6610, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 88, Train Loss: 0.6227, Val Loss: 0.6854, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Epoch 89, Train Loss: 0.6159, Val Loss: 0.6536, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 90, Train Loss: 0.6101, Val Loss: 0.6784, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 91, Train Loss: 0.6296, Val Loss: 0.6591, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 92, Train Loss: 0.6258, Val Loss: 0.6915, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 93, Train Loss: 0.6337, Val Loss: 0.6608, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 94, Train Loss: 0.6164, Val Loss: 0.6585, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 95, Train Loss: 0.6085, Val Loss: 0.6572, F1 Micro: 0.6124, F1 Macro: 0.5111, Accuracy: 0.6124\n","Epoch 96, Train Loss: 0.6330, Val Loss: 0.6556, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 97, Train Loss: 0.6300, Val Loss: 0.6578, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 98, Train Loss: 0.6218, Val Loss: 0.6561, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 99, Train Loss: 0.6435, Val Loss: 0.6572, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 100, Train Loss: 0.6168, Val Loss: 0.6620, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 101, Train Loss: 0.6260, Val Loss: 0.6733, F1 Micro: 0.6067, F1 Macro: 0.5900, Accuracy: 0.6067\n","Epoch 102, Train Loss: 0.6318, Val Loss: 0.6896, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 103, Train Loss: 0.6273, Val Loss: 0.6754, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 104, Train Loss: 0.6151, Val Loss: 0.6567, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 105, Train Loss: 0.6337, Val Loss: 0.6539, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 106, Train Loss: 0.6343, Val Loss: 0.6518, F1 Micro: 0.6292, F1 Macro: 0.5659, Accuracy: 0.6292\n","Epoch 107, Train Loss: 0.6199, Val Loss: 0.6557, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 108, Train Loss: 0.6142, Val Loss: 0.6556, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 109, Train Loss: 0.6231, Val Loss: 0.6678, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 110, Train Loss: 0.6272, Val Loss: 0.6556, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 111, Train Loss: 0.6246, Val Loss: 0.6488, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 112, Train Loss: 0.6264, Val Loss: 0.6639, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 113, Train Loss: 0.6166, Val Loss: 0.6551, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 114, Train Loss: 0.6011, Val Loss: 0.7128, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 115, Train Loss: 0.6231, Val Loss: 0.6679, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 116, Train Loss: 0.6358, Val Loss: 0.6799, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 117, Train Loss: 0.6119, Val Loss: 0.6938, F1 Micro: 0.6348, F1 Macro: 0.5334, Accuracy: 0.6348\n","Epoch 118, Train Loss: 0.6136, Val Loss: 0.6568, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 119, Train Loss: 0.6151, Val Loss: 0.6594, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 120, Train Loss: 0.6154, Val Loss: 0.6524, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 121, Train Loss: 0.6168, Val Loss: 0.6508, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 122, Train Loss: 0.6122, Val Loss: 0.6480, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 123, Train Loss: 0.6088, Val Loss: 0.6817, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 124, Train Loss: 0.6177, Val Loss: 0.6688, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 125, Train Loss: 0.6105, Val Loss: 0.6869, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 126, Train Loss: 0.6206, Val Loss: 0.6508, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 127, Train Loss: 0.6225, Val Loss: 0.6683, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 128, Train Loss: 0.6109, Val Loss: 0.6721, F1 Micro: 0.6404, F1 Macro: 0.5374, Accuracy: 0.6404\n","Epoch 129, Train Loss: 0.6493, Val Loss: 0.6603, F1 Micro: 0.6292, F1 Macro: 0.5614, Accuracy: 0.6292\n","Epoch 130, Train Loss: 0.6135, Val Loss: 0.6527, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 131, Train Loss: 0.6262, Val Loss: 0.6640, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 132, Train Loss: 0.6096, Val Loss: 0.6625, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 133, Train Loss: 0.6249, Val Loss: 0.6598, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 134, Train Loss: 0.6399, Val Loss: 0.6552, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 135, Train Loss: 0.6199, Val Loss: 0.6610, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 136, Train Loss: 0.6164, Val Loss: 0.6586, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 137, Train Loss: 0.6119, Val Loss: 0.6540, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 138, Train Loss: 0.6114, Val Loss: 0.6516, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 139, Train Loss: 0.6112, Val Loss: 0.6608, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 140, Train Loss: 0.6073, Val Loss: 0.6682, F1 Micro: 0.6517, F1 Macro: 0.6103, Accuracy: 0.6517\n","Epoch 141, Train Loss: 0.6268, Val Loss: 0.6619, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 142, Train Loss: 0.6193, Val Loss: 0.6563, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 143, Train Loss: 0.6198, Val Loss: 0.6896, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 144, Train Loss: 0.6248, Val Loss: 0.6601, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 145, Train Loss: 0.6201, Val Loss: 0.6852, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 146, Train Loss: 0.6466, Val Loss: 0.6564, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 147, Train Loss: 0.6141, Val Loss: 0.6618, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 148, Train Loss: 0.6111, Val Loss: 0.6603, F1 Micro: 0.6292, F1 Macro: 0.5465, Accuracy: 0.6292\n","Epoch 149, Train Loss: 0.6138, Val Loss: 0.6667, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 150, Train Loss: 0.6205, Val Loss: 0.6629, F1 Micro: 0.6404, F1 Macro: 0.5871, Accuracy: 0.6404\n","Epoch 151, Train Loss: 0.6117, Val Loss: 0.6966, F1 Micro: 0.6236, F1 Macro: 0.5313, Accuracy: 0.6236\n","Epoch 152, Train Loss: 0.6284, Val Loss: 0.6576, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 153, Train Loss: 0.6147, Val Loss: 0.6659, F1 Micro: 0.6236, F1 Macro: 0.5423, Accuracy: 0.6236\n","Epoch 154, Train Loss: 0.6219, Val Loss: 0.6529, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 155, Train Loss: 0.6109, Val Loss: 0.6640, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 156, Train Loss: 0.6176, Val Loss: 0.6696, F1 Micro: 0.6404, F1 Macro: 0.5747, Accuracy: 0.6404\n","Epoch 157, Train Loss: 0.6158, Val Loss: 0.6804, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 158, Train Loss: 0.6146, Val Loss: 0.6627, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 159, Train Loss: 0.6128, Val Loss: 0.6595, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6848, Val Loss: 0.6738, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6711, Val Loss: 0.8539, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6490, Val Loss: 0.6702, F1 Micro: 0.5955, F1 Macro: 0.5545, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6381, Val Loss: 0.6650, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6467, Val Loss: 0.7867, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 6, Train Loss: 0.6434, Val Loss: 0.7081, F1 Micro: 0.5562, F1 Macro: 0.4473, Accuracy: 0.5562\n","Epoch 7, Train Loss: 0.6586, Val Loss: 0.6812, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6419, Val Loss: 0.7559, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 9, Train Loss: 0.6466, Val Loss: 0.7353, F1 Micro: 0.5899, F1 Macro: 0.5070, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6335, Val Loss: 0.6842, F1 Micro: 0.5730, F1 Macro: 0.5183, Accuracy: 0.5730\n","Epoch 11, Train Loss: 0.6415, Val Loss: 0.6866, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6453, Val Loss: 0.7078, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 13, Train Loss: 0.6360, Val Loss: 0.7964, F1 Micro: 0.5393, F1 Macro: 0.3903, Accuracy: 0.5393\n","Epoch 14, Train Loss: 0.6410, Val Loss: 0.6855, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.6384, Val Loss: 0.9243, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6560, Val Loss: 0.6495, F1 Micro: 0.6461, F1 Macro: 0.6460, Accuracy: 0.6461\n","Epoch 17, Train Loss: 0.6477, Val Loss: 0.6747, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.6413, Val Loss: 0.7305, F1 Micro: 0.5787, F1 Macro: 0.5342, Accuracy: 0.5787\n","Epoch 19, Train Loss: 0.6208, Val Loss: 0.8090, F1 Micro: 0.5730, F1 Macro: 0.4949, Accuracy: 0.5730\n","Epoch 20, Train Loss: 0.6306, Val Loss: 0.6516, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 21, Train Loss: 0.6316, Val Loss: 0.6875, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 22, Train Loss: 0.6503, Val Loss: 0.6625, F1 Micro: 0.6404, F1 Macro: 0.6326, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6321, Val Loss: 0.7189, F1 Micro: 0.5787, F1 Macro: 0.5138, Accuracy: 0.5787\n","Epoch 24, Train Loss: 0.6392, Val Loss: 0.6527, F1 Micro: 0.6798, F1 Macro: 0.6733, Accuracy: 0.6798\n","Epoch 25, Train Loss: 0.6402, Val Loss: 0.7050, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 26, Train Loss: 0.6187, Val Loss: 0.7065, F1 Micro: 0.5730, F1 Macro: 0.5050, Accuracy: 0.5730\n","Epoch 27, Train Loss: 0.6203, Val Loss: 0.7286, F1 Micro: 0.5843, F1 Macro: 0.5082, Accuracy: 0.5843\n","Epoch 28, Train Loss: 0.6437, Val Loss: 0.6726, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 29, Train Loss: 0.6429, Val Loss: 0.7553, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 30, Train Loss: 0.6350, Val Loss: 0.7183, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 31, Train Loss: 0.6418, Val Loss: 0.6573, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 32, Train Loss: 0.6215, Val Loss: 0.6606, F1 Micro: 0.6517, F1 Macro: 0.6441, Accuracy: 0.6517\n","Epoch 33, Train Loss: 0.6393, Val Loss: 0.6979, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 34, Train Loss: 0.6324, Val Loss: 0.6615, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 35, Train Loss: 0.6382, Val Loss: 0.7474, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 36, Train Loss: 0.6328, Val Loss: 0.6928, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 37, Train Loss: 0.6201, Val Loss: 0.7563, F1 Micro: 0.6180, F1 Macro: 0.5652, Accuracy: 0.6180\n","Epoch 38, Train Loss: 0.6182, Val Loss: 0.7033, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 39, Train Loss: 0.6257, Val Loss: 0.6666, F1 Micro: 0.6067, F1 Macro: 0.5700, Accuracy: 0.6067\n","Epoch 40, Train Loss: 0.6308, Val Loss: 0.6552, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 41, Train Loss: 0.6190, Val Loss: 0.6660, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 42, Train Loss: 0.6243, Val Loss: 0.7120, F1 Micro: 0.6292, F1 Macro: 0.5780, Accuracy: 0.6292\n","Epoch 43, Train Loss: 0.6272, Val Loss: 0.7388, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6479, Val Loss: 0.7327, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 45, Train Loss: 0.6447, Val Loss: 0.6626, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 46, Train Loss: 0.6249, Val Loss: 0.7627, F1 Micro: 0.5618, F1 Macro: 0.4363, Accuracy: 0.5618\n","Epoch 47, Train Loss: 0.6270, Val Loss: 0.7102, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6331, Val Loss: 0.6538, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 49, Train Loss: 0.6248, Val Loss: 0.7695, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 50, Train Loss: 0.6356, Val Loss: 0.6741, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6341, Val Loss: 0.6573, F1 Micro: 0.6629, F1 Macro: 0.6502, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.6393, Val Loss: 0.8126, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 53, Train Loss: 0.6410, Val Loss: 0.6418, F1 Micro: 0.6685, F1 Macro: 0.6639, Accuracy: 0.6685\n","Epoch 54, Train Loss: 0.6338, Val Loss: 0.6450, F1 Micro: 0.6573, F1 Macro: 0.6480, Accuracy: 0.6573\n","Epoch 55, Train Loss: 0.6223, Val Loss: 0.6996, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 56, Train Loss: 0.6147, Val Loss: 0.6585, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 57, Train Loss: 0.6161, Val Loss: 0.6702, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6297, Val Loss: 0.7155, F1 Micro: 0.5787, F1 Macro: 0.5183, Accuracy: 0.5787\n","Epoch 59, Train Loss: 0.6260, Val Loss: 0.6764, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 60, Train Loss: 0.6196, Val Loss: 0.7263, F1 Micro: 0.6292, F1 Macro: 0.5817, Accuracy: 0.6292\n","Epoch 61, Train Loss: 0.6365, Val Loss: 0.6751, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 62, Train Loss: 0.6297, Val Loss: 0.6959, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 63, Train Loss: 0.6265, Val Loss: 0.7206, F1 Micro: 0.5730, F1 Macro: 0.5141, Accuracy: 0.5730\n","Epoch 64, Train Loss: 0.6396, Val Loss: 0.7028, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 65, Train Loss: 0.6244, Val Loss: 0.6504, F1 Micro: 0.6404, F1 Macro: 0.6299, Accuracy: 0.6404\n","Epoch 66, Train Loss: 0.6197, Val Loss: 0.6377, F1 Micro: 0.6573, F1 Macro: 0.6572, Accuracy: 0.6573\n","Epoch 67, Train Loss: 0.6290, Val Loss: 0.6657, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 68, Train Loss: 0.6184, Val Loss: 0.6635, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 69, Train Loss: 0.6108, Val Loss: 0.7177, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 70, Train Loss: 0.6147, Val Loss: 0.6894, F1 Micro: 0.5843, F1 Macro: 0.5269, Accuracy: 0.5843\n","Epoch 71, Train Loss: 0.6318, Val Loss: 0.7070, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 72, Train Loss: 0.6129, Val Loss: 0.6994, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 73, Train Loss: 0.6223, Val Loss: 0.6487, F1 Micro: 0.6742, F1 Macro: 0.6646, Accuracy: 0.6742\n","Epoch 74, Train Loss: 0.6139, Val Loss: 0.6470, F1 Micro: 0.6573, F1 Macro: 0.6504, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6852, Val Loss: 0.6610, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6466, Val Loss: 0.6969, F1 Micro: 0.5787, F1 Macro: 0.5764, Accuracy: 0.5787\n","Epoch 3, Train Loss: 0.6446, Val Loss: 0.6599, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6826, Val Loss: 0.6789, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6569, Val Loss: 0.6679, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 6, Train Loss: 0.6536, Val Loss: 0.6497, F1 Micro: 0.6348, F1 Macro: 0.5703, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6334, Val Loss: 0.6930, F1 Micro: 0.5787, F1 Macro: 0.5525, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.6523, Val Loss: 0.6725, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6526, Val Loss: 0.6460, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 10, Train Loss: 0.6494, Val Loss: 0.6775, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 11, Train Loss: 0.6645, Val Loss: 0.6626, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6385, Val Loss: 0.6656, F1 Micro: 0.6124, F1 Macro: 0.5231, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6319, Val Loss: 0.6893, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6429, Val Loss: 0.6710, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 15, Train Loss: 0.6399, Val Loss: 0.6538, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6367, Val Loss: 0.7118, F1 Micro: 0.5843, F1 Macro: 0.5598, Accuracy: 0.5843\n","Epoch 17, Train Loss: 0.6384, Val Loss: 0.6563, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6352, Val Loss: 0.6885, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6528, Val Loss: 0.6871, F1 Micro: 0.6124, F1 Macro: 0.4831, Accuracy: 0.6124\n","Epoch 20, Train Loss: 0.6512, Val Loss: 0.6534, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.6410, Val Loss: 0.6892, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6454, Val Loss: 0.6880, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.6307, Val Loss: 0.6652, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 24, Train Loss: 0.6453, Val Loss: 0.7036, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 25, Train Loss: 0.6350, Val Loss: 0.6824, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6409, Val Loss: 0.6720, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 27, Train Loss: 0.6454, Val Loss: 0.7024, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 28, Train Loss: 0.6259, Val Loss: 0.6773, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 29, Train Loss: 0.6452, Val Loss: 0.6910, F1 Micro: 0.6124, F1 Macro: 0.4486, Accuracy: 0.6124\n","Epoch 30, Train Loss: 0.6469, Val Loss: 0.6471, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.6327, Val Loss: 0.6849, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 32, Train Loss: 0.6396, Val Loss: 0.6546, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 33, Train Loss: 0.6482, Val Loss: 0.6807, F1 Micro: 0.6236, F1 Macro: 0.5313, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6435, Val Loss: 0.6861, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6507, Val Loss: 0.6529, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 36, Train Loss: 0.6131, Val Loss: 0.6681, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 37, Train Loss: 0.6392, Val Loss: 0.6783, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 38, Train Loss: 0.6346, Val Loss: 0.6405, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6256, Val Loss: 0.6633, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 40, Train Loss: 0.6440, Val Loss: 0.6526, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 41, Train Loss: 0.6331, Val Loss: 0.6492, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 42, Train Loss: 0.6405, Val Loss: 0.6693, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6402, Val Loss: 0.6410, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 44, Train Loss: 0.6336, Val Loss: 0.6907, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6334, Val Loss: 0.6489, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.6266, Val Loss: 0.6497, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 47, Train Loss: 0.6263, Val Loss: 0.6727, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6295, Val Loss: 0.6551, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 49, Train Loss: 0.6368, Val Loss: 0.6691, F1 Micro: 0.6067, F1 Macro: 0.6027, Accuracy: 0.6067\n","Epoch 50, Train Loss: 0.6402, Val Loss: 0.7042, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6265, Val Loss: 0.6460, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 52, Train Loss: 0.6446, Val Loss: 0.6582, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 53, Train Loss: 0.6343, Val Loss: 0.6533, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6367, Val Loss: 0.6632, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 55, Train Loss: 0.6356, Val Loss: 0.6422, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 56, Train Loss: 0.6495, Val Loss: 0.7297, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 57, Train Loss: 0.6380, Val Loss: 0.6419, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.6202, Val Loss: 0.6540, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 59, Train Loss: 0.6380, Val Loss: 0.6575, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.6204, Val Loss: 0.6714, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 61, Train Loss: 0.6254, Val Loss: 0.6488, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.6427, Val Loss: 0.6763, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 63, Train Loss: 0.6504, Val Loss: 0.6647, F1 Micro: 0.6180, F1 Macro: 0.5213, Accuracy: 0.6180\n","Epoch 64, Train Loss: 0.6288, Val Loss: 0.6599, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 65, Train Loss: 0.6293, Val Loss: 0.6868, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 66, Train Loss: 0.6321, Val Loss: 0.6574, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 67, Train Loss: 0.6305, Val Loss: 0.6639, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 68, Train Loss: 0.6230, Val Loss: 0.6554, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 69, Train Loss: 0.6199, Val Loss: 0.6789, F1 Micro: 0.6067, F1 Macro: 0.5759, Accuracy: 0.6067\n","Epoch 70, Train Loss: 0.6135, Val Loss: 0.6629, F1 Micro: 0.6461, F1 Macro: 0.5876, Accuracy: 0.6461\n","Epoch 71, Train Loss: 0.6221, Val Loss: 0.6463, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 72, Train Loss: 0.6216, Val Loss: 0.6459, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 73, Train Loss: 0.6308, Val Loss: 0.6617, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 74, Train Loss: 0.6276, Val Loss: 0.6710, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 75, Train Loss: 0.6244, Val Loss: 0.6474, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 76, Train Loss: 0.6294, Val Loss: 0.6396, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7070491494570336\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6828, Val Loss: 0.6986, F1 Micro: 0.6257, F1 Macro: 0.5747, Accuracy: 0.6257\n","Epoch 2, Train Loss: 0.6428, Val Loss: 0.7037, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 3, Train Loss: 0.6493, Val Loss: 0.7040, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 4, Train Loss: 0.6437, Val Loss: 0.6962, F1 Micro: 0.7095, F1 Macro: 0.6141, Accuracy: 0.7095\n","Epoch 5, Train Loss: 0.6467, Val Loss: 0.7076, F1 Micro: 0.6704, F1 Macro: 0.5828, Accuracy: 0.6704\n","Epoch 6, Train Loss: 0.6489, Val Loss: 0.7014, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 7, Train Loss: 0.6412, Val Loss: 0.7330, F1 Micro: 0.5754, F1 Macro: 0.5565, Accuracy: 0.5754\n","Epoch 8, Train Loss: 0.6504, Val Loss: 0.6897, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 9, Train Loss: 0.6455, Val Loss: 0.6925, F1 Micro: 0.6145, F1 Macro: 0.5759, Accuracy: 0.6145\n","Epoch 10, Train Loss: 0.6509, Val Loss: 0.7050, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 11, Train Loss: 0.6442, Val Loss: 0.7345, F1 Micro: 0.6816, F1 Macro: 0.5371, Accuracy: 0.6816\n","Epoch 12, Train Loss: 0.6433, Val Loss: 0.6793, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 13, Train Loss: 0.6464, Val Loss: 0.6968, F1 Micro: 0.7151, F1 Macro: 0.6187, Accuracy: 0.7151\n","Epoch 14, Train Loss: 0.6407, Val Loss: 0.6895, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 15, Train Loss: 0.6437, Val Loss: 0.6847, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 16, Train Loss: 0.6389, Val Loss: 0.6998, F1 Micro: 0.6089, F1 Macro: 0.5744, Accuracy: 0.6089\n","Epoch 17, Train Loss: 0.6408, Val Loss: 0.7109, F1 Micro: 0.5810, F1 Macro: 0.5541, Accuracy: 0.5810\n","Epoch 18, Train Loss: 0.6644, Val Loss: 0.6761, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6289, Val Loss: 0.7022, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 20, Train Loss: 0.6453, Val Loss: 0.6882, F1 Micro: 0.7095, F1 Macro: 0.6249, Accuracy: 0.7095\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6944, Val Loss: 0.6494, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 2, Train Loss: 0.6559, Val Loss: 0.6419, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6618, Val Loss: 0.6288, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6669, Val Loss: 0.6381, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6555, Val Loss: 0.6350, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6519, Val Loss: 0.6203, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 7, Train Loss: 0.6735, Val Loss: 0.6349, F1 Micro: 0.7472, F1 Macro: 0.6577, Accuracy: 0.7472\n","Epoch 8, Train Loss: 0.6638, Val Loss: 0.6583, F1 Micro: 0.6573, F1 Macro: 0.4744, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6433, Val Loss: 0.6314, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6592, Val Loss: 0.6147, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 11, Train Loss: 0.6467, Val Loss: 0.6235, F1 Micro: 0.7303, F1 Macro: 0.6431, Accuracy: 0.7303\n","Epoch 12, Train Loss: 0.6532, Val Loss: 0.6203, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.6459, Val Loss: 0.6232, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6540, Val Loss: 0.6241, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6463, Val Loss: 0.6175, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.6578, Val Loss: 0.6391, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 17, Train Loss: 0.6401, Val Loss: 0.6334, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6724, Val Loss: 0.6711, F1 Micro: 0.6292, F1 Macro: 0.4582, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.6540, Val Loss: 0.6561, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6696, Val Loss: 0.6422, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 4, Train Loss: 0.6525, Val Loss: 0.6610, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6656, Val Loss: 0.6631, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6526, Val Loss: 0.6982, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.6440, Val Loss: 0.6703, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6502, Val Loss: 0.6459, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.6426, Val Loss: 0.6701, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6290, Val Loss: 0.6717, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6391, Val Loss: 0.6833, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6462, Val Loss: 0.6669, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6409, Val Loss: 0.6608, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6783, Val Loss: 0.6690, F1 Micro: 0.6517, F1 Macro: 0.6517, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6514, Val Loss: 0.7084, F1 Micro: 0.6011, F1 Macro: 0.5917, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6509, Val Loss: 0.6903, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6547, Val Loss: 0.6661, F1 Micro: 0.6798, F1 Macro: 0.6733, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6428, Val Loss: 0.7689, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 6, Train Loss: 0.6224, Val Loss: 0.6788, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6205, Val Loss: 0.6680, F1 Micro: 0.6404, F1 Macro: 0.6326, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6391, Val Loss: 0.6906, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6309, Val Loss: 0.7662, F1 Micro: 0.5787, F1 Macro: 0.4817, Accuracy: 0.5787\n","Epoch 10, Train Loss: 0.6386, Val Loss: 0.6799, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.6464, Val Loss: 0.6827, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6422, Val Loss: 0.8074, F1 Micro: 0.5955, F1 Macro: 0.5215, Accuracy: 0.5955\n","Epoch 13, Train Loss: 0.6382, Val Loss: 0.7182, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6274, Val Loss: 0.6789, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6742, Val Loss: 0.6661, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 2, Train Loss: 0.6531, Val Loss: 0.6733, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.6319, Val Loss: 0.6985, F1 Micro: 0.6573, F1 Macro: 0.5360, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6583, Val Loss: 0.6629, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6447, Val Loss: 0.6683, F1 Micro: 0.6124, F1 Macro: 0.5231, Accuracy: 0.6124\n","Epoch 6, Train Loss: 0.6330, Val Loss: 0.6930, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6676, Val Loss: 0.6591, F1 Micro: 0.6180, F1 Macro: 0.6149, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6448, Val Loss: 0.6471, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6545, Val Loss: 0.6744, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6371, Val Loss: 0.6717, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 11, Train Loss: 0.6331, Val Loss: 0.6707, F1 Micro: 0.6404, F1 Macro: 0.5871, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6533, Val Loss: 0.6603, F1 Micro: 0.6124, F1 Macro: 0.6032, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6539, Val Loss: 0.6577, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6463, Val Loss: 0.7196, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.6969493440461993\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6726, Val Loss: 0.7138, F1 Micro: 0.5922, F1 Macro: 0.5546, Accuracy: 0.5922\n","Epoch 2, Train Loss: 0.6467, Val Loss: 0.7241, F1 Micro: 0.6592, F1 Macro: 0.5439, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6591, Val Loss: 0.7000, F1 Micro: 0.6313, F1 Macro: 0.5928, Accuracy: 0.6313\n","Epoch 4, Train Loss: 0.6432, Val Loss: 0.7231, F1 Micro: 0.6872, F1 Macro: 0.6015, Accuracy: 0.6872\n","Epoch 5, Train Loss: 0.6596, Val Loss: 0.7124, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 6, Train Loss: 0.6557, Val Loss: 0.6878, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 7, Train Loss: 0.6540, Val Loss: 0.7053, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.6511, Val Loss: 0.7012, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 9, Train Loss: 0.6492, Val Loss: 0.6982, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 10, Train Loss: 0.6411, Val Loss: 0.7087, F1 Micro: 0.5754, F1 Macro: 0.5565, Accuracy: 0.5754\n","Epoch 11, Train Loss: 0.6340, Val Loss: 0.7270, F1 Micro: 0.6816, F1 Macro: 0.5371, Accuracy: 0.6816\n","Epoch 12, Train Loss: 0.6399, Val Loss: 0.6951, F1 Micro: 0.6536, F1 Macro: 0.5932, Accuracy: 0.6536\n","Epoch 13, Train Loss: 0.6381, Val Loss: 0.6842, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 14, Train Loss: 0.6331, Val Loss: 0.6856, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 15, Train Loss: 0.6541, Val Loss: 0.6993, F1 Micro: 0.6983, F1 Macro: 0.5729, Accuracy: 0.6983\n","Epoch 16, Train Loss: 0.6358, Val Loss: 0.6813, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.6399, Val Loss: 0.6816, F1 Micro: 0.6034, F1 Macro: 0.5636, Accuracy: 0.6034\n","Epoch 18, Train Loss: 0.6427, Val Loss: 0.6798, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 19, Train Loss: 0.6231, Val Loss: 0.6998, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 20, Train Loss: 0.6391, Val Loss: 0.7032, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6377, Val Loss: 0.6849, F1 Micro: 0.6760, F1 Macro: 0.6194, Accuracy: 0.6760\n","Epoch 22, Train Loss: 0.6484, Val Loss: 0.7328, F1 Micro: 0.6648, F1 Macro: 0.4989, Accuracy: 0.6648\n","Epoch 23, Train Loss: 0.6445, Val Loss: 0.6848, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 24, Train Loss: 0.6310, Val Loss: 0.6832, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 25, Train Loss: 0.6562, Val Loss: 0.7009, F1 Micro: 0.5922, F1 Macro: 0.5769, Accuracy: 0.5922\n","Epoch 26, Train Loss: 0.6507, Val Loss: 0.7094, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 27, Train Loss: 0.6487, Val Loss: 0.7190, F1 Micro: 0.6760, F1 Macro: 0.5156, Accuracy: 0.6760\n","Epoch 28, Train Loss: 0.6420, Val Loss: 0.6981, F1 Micro: 0.5866, F1 Macro: 0.5784, Accuracy: 0.5866\n","Epoch 29, Train Loss: 0.6432, Val Loss: 0.7043, F1 Micro: 0.7207, F1 Macro: 0.6393, Accuracy: 0.7207\n","Epoch 30, Train Loss: 0.6412, Val Loss: 0.6992, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 31, Train Loss: 0.6256, Val Loss: 0.7079, F1 Micro: 0.5642, F1 Macro: 0.5489, Accuracy: 0.5642\n","Epoch 32, Train Loss: 0.6399, Val Loss: 0.6953, F1 Micro: 0.7039, F1 Macro: 0.6095, Accuracy: 0.7039\n","Epoch 33, Train Loss: 0.6370, Val Loss: 0.7019, F1 Micro: 0.7095, F1 Macro: 0.6141, Accuracy: 0.7095\n","Epoch 34, Train Loss: 0.6320, Val Loss: 0.6783, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 35, Train Loss: 0.6387, Val Loss: 0.7051, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 36, Train Loss: 0.6306, Val Loss: 0.6826, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 37, Train Loss: 0.6373, Val Loss: 0.6786, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 38, Train Loss: 0.6307, Val Loss: 0.6636, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 39, Train Loss: 0.6381, Val Loss: 0.6741, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 40, Train Loss: 0.6302, Val Loss: 0.6878, F1 Micro: 0.6313, F1 Macro: 0.6014, Accuracy: 0.6313\n","Epoch 41, Train Loss: 0.6283, Val Loss: 0.6745, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 42, Train Loss: 0.6380, Val Loss: 0.6765, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 43, Train Loss: 0.6344, Val Loss: 0.6991, F1 Micro: 0.6760, F1 Macro: 0.5696, Accuracy: 0.6760\n","Epoch 44, Train Loss: 0.6447, Val Loss: 0.6999, F1 Micro: 0.5810, F1 Macro: 0.5590, Accuracy: 0.5810\n","Epoch 45, Train Loss: 0.6351, Val Loss: 0.6863, F1 Micro: 0.6704, F1 Macro: 0.5653, Accuracy: 0.6704\n","Epoch 46, Train Loss: 0.6384, Val Loss: 0.6791, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 47, Train Loss: 0.6320, Val Loss: 0.6859, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 48, Train Loss: 0.6376, Val Loss: 0.6865, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 49, Train Loss: 0.6207, Val Loss: 0.7040, F1 Micro: 0.6648, F1 Macro: 0.4890, Accuracy: 0.6648\n","Epoch 50, Train Loss: 0.6328, Val Loss: 0.6693, F1 Micro: 0.6704, F1 Macro: 0.6255, Accuracy: 0.6704\n","Epoch 51, Train Loss: 0.6220, Val Loss: 0.6716, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 52, Train Loss: 0.6251, Val Loss: 0.6738, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 53, Train Loss: 0.6270, Val Loss: 0.7071, F1 Micro: 0.7151, F1 Macro: 0.6187, Accuracy: 0.7151\n","Epoch 54, Train Loss: 0.6382, Val Loss: 0.6627, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 55, Train Loss: 0.6290, Val Loss: 0.6892, F1 Micro: 0.6704, F1 Macro: 0.5979, Accuracy: 0.6704\n","Epoch 56, Train Loss: 0.6321, Val Loss: 0.6643, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 57, Train Loss: 0.6351, Val Loss: 0.6791, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 58, Train Loss: 0.6301, Val Loss: 0.7062, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 59, Train Loss: 0.6303, Val Loss: 0.6719, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Epoch 60, Train Loss: 0.6482, Val Loss: 0.6670, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 61, Train Loss: 0.6326, Val Loss: 0.6762, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 62, Train Loss: 0.6445, Val Loss: 0.6796, F1 Micro: 0.7207, F1 Macro: 0.6343, Accuracy: 0.7207\n","Epoch 63, Train Loss: 0.6341, Val Loss: 0.6687, F1 Micro: 0.6872, F1 Macro: 0.6247, Accuracy: 0.6872\n","Epoch 64, Train Loss: 0.6346, Val Loss: 0.6745, F1 Micro: 0.6536, F1 Macro: 0.6010, Accuracy: 0.6536\n","Epoch 65, Train Loss: 0.6301, Val Loss: 0.6694, F1 Micro: 0.6425, F1 Macro: 0.6109, Accuracy: 0.6425\n","Epoch 66, Train Loss: 0.6252, Val Loss: 0.6951, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 67, Train Loss: 0.6275, Val Loss: 0.6716, F1 Micro: 0.6648, F1 Macro: 0.5730, Accuracy: 0.6648\n","Epoch 68, Train Loss: 0.6429, Val Loss: 0.6660, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 69, Train Loss: 0.6158, Val Loss: 0.6894, F1 Micro: 0.6704, F1 Macro: 0.5373, Accuracy: 0.6704\n","Epoch 70, Train Loss: 0.6267, Val Loss: 0.6668, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 71, Train Loss: 0.6259, Val Loss: 0.6906, F1 Micro: 0.5866, F1 Macro: 0.5702, Accuracy: 0.5866\n","Epoch 72, Train Loss: 0.6316, Val Loss: 0.6910, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 73, Train Loss: 0.6251, Val Loss: 0.6661, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 74, Train Loss: 0.6338, Val Loss: 0.6725, F1 Micro: 0.6983, F1 Macro: 0.6253, Accuracy: 0.6983\n","Epoch 75, Train Loss: 0.6296, Val Loss: 0.6689, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 76, Train Loss: 0.6285, Val Loss: 0.6761, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 77, Train Loss: 0.6360, Val Loss: 0.6914, F1 Micro: 0.6983, F1 Macro: 0.5868, Accuracy: 0.6983\n","Epoch 78, Train Loss: 0.6443, Val Loss: 0.6696, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 79, Train Loss: 0.6259, Val Loss: 0.6721, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6735, Val Loss: 0.6449, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 2, Train Loss: 0.6766, Val Loss: 0.6557, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6726, Val Loss: 0.6225, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 4, Train Loss: 0.6559, Val Loss: 0.6204, F1 Micro: 0.7247, F1 Macro: 0.6572, Accuracy: 0.7247\n","Epoch 5, Train Loss: 0.6602, Val Loss: 0.6135, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 6, Train Loss: 0.6531, Val Loss: 0.6152, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 7, Train Loss: 0.6478, Val Loss: 0.6121, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 8, Train Loss: 0.6414, Val Loss: 0.6248, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6533, Val Loss: 0.6124, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 10, Train Loss: 0.6418, Val Loss: 0.6187, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 11, Train Loss: 0.6735, Val Loss: 0.6229, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.6559, Val Loss: 0.6115, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6459, Val Loss: 0.6273, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6539, Val Loss: 0.6223, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6475, Val Loss: 0.6086, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 16, Train Loss: 0.6526, Val Loss: 0.6154, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 17, Train Loss: 0.6474, Val Loss: 0.6259, F1 Micro: 0.6910, F1 Macro: 0.5443, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.6567, Val Loss: 0.6217, F1 Micro: 0.7303, F1 Macro: 0.6531, Accuracy: 0.7303\n","Epoch 19, Train Loss: 0.6522, Val Loss: 0.6080, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 20, Train Loss: 0.6495, Val Loss: 0.6113, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 21, Train Loss: 0.6509, Val Loss: 0.6299, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Epoch 22, Train Loss: 0.6590, Val Loss: 0.6081, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6532, Val Loss: 0.6346, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 24, Train Loss: 0.6510, Val Loss: 0.6103, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 25, Train Loss: 0.6394, Val Loss: 0.6592, F1 Micro: 0.6573, F1 Macro: 0.4517, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.6555, Val Loss: 0.6283, F1 Micro: 0.7528, F1 Macro: 0.6679, Accuracy: 0.7528\n","Epoch 27, Train Loss: 0.6452, Val Loss: 0.6073, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 28, Train Loss: 0.6407, Val Loss: 0.6248, F1 Micro: 0.6854, F1 Macro: 0.5486, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6561, Val Loss: 0.6294, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 30, Train Loss: 0.6470, Val Loss: 0.6318, F1 Micro: 0.6854, F1 Macro: 0.5316, Accuracy: 0.6854\n","Epoch 31, Train Loss: 0.6423, Val Loss: 0.6228, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6360, Val Loss: 0.6115, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 33, Train Loss: 0.6475, Val Loss: 0.6110, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 34, Train Loss: 0.6552, Val Loss: 0.6056, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 35, Train Loss: 0.6571, Val Loss: 0.6121, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 36, Train Loss: 0.6373, Val Loss: 0.6163, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 37, Train Loss: 0.6429, Val Loss: 0.6098, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 38, Train Loss: 0.6423, Val Loss: 0.6028, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 39, Train Loss: 0.6610, Val Loss: 0.6032, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 40, Train Loss: 0.6402, Val Loss: 0.6014, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 41, Train Loss: 0.6352, Val Loss: 0.6135, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 42, Train Loss: 0.6718, Val Loss: 0.6053, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 43, Train Loss: 0.6412, Val Loss: 0.6114, F1 Micro: 0.7528, F1 Macro: 0.6820, Accuracy: 0.7528\n","Epoch 44, Train Loss: 0.6302, Val Loss: 0.6030, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6367, Val Loss: 0.6044, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 46, Train Loss: 0.6345, Val Loss: 0.6166, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 47, Train Loss: 0.6499, Val Loss: 0.6062, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 48, Train Loss: 0.6486, Val Loss: 0.6071, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 49, Train Loss: 0.6407, Val Loss: 0.6105, F1 Micro: 0.7303, F1 Macro: 0.6482, Accuracy: 0.7303\n","Epoch 50, Train Loss: 0.6431, Val Loss: 0.6105, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 51, Train Loss: 0.6494, Val Loss: 0.6385, F1 Micro: 0.7303, F1 Macro: 0.6261, Accuracy: 0.7303\n","Epoch 52, Train Loss: 0.6426, Val Loss: 0.6108, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 53, Train Loss: 0.6357, Val Loss: 0.6056, F1 Micro: 0.7584, F1 Macro: 0.6913, Accuracy: 0.7584\n","Epoch 54, Train Loss: 0.6470, Val Loss: 0.6079, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 55, Train Loss: 0.6405, Val Loss: 0.5945, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 56, Train Loss: 0.6343, Val Loss: 0.6075, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.6358, Val Loss: 0.6184, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.6283, Val Loss: 0.6130, F1 Micro: 0.7472, F1 Macro: 0.6629, Accuracy: 0.7472\n","Epoch 59, Train Loss: 0.6436, Val Loss: 0.6282, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 60, Train Loss: 0.6434, Val Loss: 0.6010, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 61, Train Loss: 0.6327, Val Loss: 0.6190, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 62, Train Loss: 0.6381, Val Loss: 0.6134, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 63, Train Loss: 0.6356, Val Loss: 0.6009, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.6297, Val Loss: 0.5944, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 65, Train Loss: 0.6298, Val Loss: 0.6023, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 66, Train Loss: 0.6486, Val Loss: 0.5964, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 67, Train Loss: 0.6408, Val Loss: 0.5966, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 68, Train Loss: 0.6414, Val Loss: 0.6174, F1 Micro: 0.7416, F1 Macro: 0.6580, Accuracy: 0.7416\n","Epoch 69, Train Loss: 0.6423, Val Loss: 0.5906, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 70, Train Loss: 0.6351, Val Loss: 0.5987, F1 Micro: 0.7697, F1 Macro: 0.7095, Accuracy: 0.7697\n","Epoch 71, Train Loss: 0.6403, Val Loss: 0.6036, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 72, Train Loss: 0.6465, Val Loss: 0.6241, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Epoch 73, Train Loss: 0.6509, Val Loss: 0.5991, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 74, Train Loss: 0.6279, Val Loss: 0.6021, F1 Micro: 0.7640, F1 Macro: 0.7005, Accuracy: 0.7640\n","Epoch 75, Train Loss: 0.6514, Val Loss: 0.6128, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 76, Train Loss: 0.6421, Val Loss: 0.5989, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 77, Train Loss: 0.6318, Val Loss: 0.6053, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 78, Train Loss: 0.6291, Val Loss: 0.6135, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 79, Train Loss: 0.6354, Val Loss: 0.5884, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 80, Train Loss: 0.6405, Val Loss: 0.5980, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 81, Train Loss: 0.6279, Val Loss: 0.5845, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 82, Train Loss: 0.6338, Val Loss: 0.5913, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 83, Train Loss: 0.6378, Val Loss: 0.5980, F1 Micro: 0.7416, F1 Macro: 0.6720, Accuracy: 0.7416\n","Epoch 84, Train Loss: 0.6279, Val Loss: 0.5989, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 85, Train Loss: 0.6252, Val Loss: 0.5978, F1 Micro: 0.7472, F1 Macro: 0.6629, Accuracy: 0.7472\n","Epoch 86, Train Loss: 0.6476, Val Loss: 0.5946, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 87, Train Loss: 0.6403, Val Loss: 0.5918, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 88, Train Loss: 0.6307, Val Loss: 0.5929, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 89, Train Loss: 0.6361, Val Loss: 0.5874, F1 Micro: 0.7247, F1 Macro: 0.6691, Accuracy: 0.7247\n","Epoch 90, Train Loss: 0.6347, Val Loss: 0.5886, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 91, Train Loss: 0.6494, Val Loss: 0.6275, F1 Micro: 0.6685, F1 Macro: 0.4917, Accuracy: 0.6685\n","Epoch 92, Train Loss: 0.6440, Val Loss: 0.5878, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 93, Train Loss: 0.6437, Val Loss: 0.6048, F1 Micro: 0.7303, F1 Macro: 0.6320, Accuracy: 0.7303\n","Epoch 94, Train Loss: 0.6433, Val Loss: 0.5905, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 95, Train Loss: 0.6357, Val Loss: 0.5905, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 96, Train Loss: 0.6391, Val Loss: 0.5887, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 97, Train Loss: 0.6246, Val Loss: 0.6045, F1 Micro: 0.7472, F1 Macro: 0.6812, Accuracy: 0.7472\n","Epoch 98, Train Loss: 0.6391, Val Loss: 0.5921, F1 Micro: 0.7697, F1 Macro: 0.7095, Accuracy: 0.7697\n","Epoch 99, Train Loss: 0.6265, Val Loss: 0.6035, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 100, Train Loss: 0.6254, Val Loss: 0.5878, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 101, Train Loss: 0.6350, Val Loss: 0.5975, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 102, Train Loss: 0.6461, Val Loss: 0.5891, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 103, Train Loss: 0.6415, Val Loss: 0.6008, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 104, Train Loss: 0.6380, Val Loss: 0.5844, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 105, Train Loss: 0.6306, Val Loss: 0.5886, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 106, Train Loss: 0.6338, Val Loss: 0.5884, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 107, Train Loss: 0.6374, Val Loss: 0.5889, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 108, Train Loss: 0.6325, Val Loss: 0.5932, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 109, Train Loss: 0.6318, Val Loss: 0.6032, F1 Micro: 0.7528, F1 Macro: 0.6728, Accuracy: 0.7528\n","Epoch 110, Train Loss: 0.6232, Val Loss: 0.5866, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 111, Train Loss: 0.6445, Val Loss: 0.5853, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 112, Train Loss: 0.6370, Val Loss: 0.5907, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 113, Train Loss: 0.6414, Val Loss: 0.5875, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 114, Train Loss: 0.6348, Val Loss: 0.5889, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 115, Train Loss: 0.6225, Val Loss: 0.5846, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 116, Train Loss: 0.6220, Val Loss: 0.5940, F1 Micro: 0.7697, F1 Macro: 0.7057, Accuracy: 0.7697\n","Epoch 117, Train Loss: 0.6407, Val Loss: 0.5993, F1 Micro: 0.7360, F1 Macro: 0.6580, Accuracy: 0.7360\n","Epoch 118, Train Loss: 0.6433, Val Loss: 0.5904, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 119, Train Loss: 0.6344, Val Loss: 0.5823, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 120, Train Loss: 0.6206, Val Loss: 0.5928, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6961, Val Loss: 0.6702, F1 Micro: 0.6685, F1 Macro: 0.6607, Accuracy: 0.6685\n","Epoch 2, Train Loss: 0.6788, Val Loss: 0.6536, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 3, Train Loss: 0.6506, Val Loss: 0.6502, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6425, Val Loss: 0.6573, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6415, Val Loss: 0.6415, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.6433, Val Loss: 0.6575, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.6525, Val Loss: 0.7254, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6425, Val Loss: 0.7448, F1 Micro: 0.6348, F1 Macro: 0.4806, Accuracy: 0.6348\n","Epoch 9, Train Loss: 0.6644, Val Loss: 0.7111, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6496, Val Loss: 0.6664, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6493, Val Loss: 0.6518, F1 Micro: 0.6461, F1 Macro: 0.5990, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.6540, Val Loss: 0.7060, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6549, Val Loss: 0.6785, F1 Micro: 0.6348, F1 Macro: 0.6262, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.6555, Val Loss: 0.7518, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6439, Val Loss: 0.6469, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6537, Val Loss: 0.6683, F1 Micro: 0.6742, F1 Macro: 0.5324, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6385, Val Loss: 0.7076, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6415, Val Loss: 0.6981, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6488, Val Loss: 0.7050, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.6558, Val Loss: 0.6571, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6380, Val Loss: 0.7122, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 22, Train Loss: 0.6391, Val Loss: 0.6824, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.6582, Val Loss: 0.7197, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 24, Train Loss: 0.6383, Val Loss: 0.6613, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 25, Train Loss: 0.6363, Val Loss: 0.6518, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 26, Train Loss: 0.6529, Val Loss: 0.6566, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6374, Val Loss: 0.6678, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 28, Train Loss: 0.6568, Val Loss: 0.6683, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 29, Train Loss: 0.6288, Val Loss: 0.6765, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 30, Train Loss: 0.6442, Val Loss: 0.6610, F1 Micro: 0.6573, F1 Macro: 0.5967, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6378, Val Loss: 0.6927, F1 Micro: 0.6236, F1 Macro: 0.4981, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6301, Val Loss: 0.7173, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Epoch 33, Train Loss: 0.6236, Val Loss: 0.6953, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 34, Train Loss: 0.6588, Val Loss: 0.6703, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 35, Train Loss: 0.6339, Val Loss: 0.6970, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6185, Val Loss: 0.6904, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.6262, Val Loss: 0.6689, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 38, Train Loss: 0.6373, Val Loss: 0.6781, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 39, Train Loss: 0.6368, Val Loss: 0.7104, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.6438, Val Loss: 0.6773, F1 Micro: 0.6404, F1 Macro: 0.6040, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6418, Val Loss: 0.6845, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 42, Train Loss: 0.6307, Val Loss: 0.6843, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6412, Val Loss: 0.6879, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 44, Train Loss: 0.6424, Val Loss: 0.7222, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 45, Train Loss: 0.6396, Val Loss: 0.7191, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 46, Train Loss: 0.6295, Val Loss: 0.7519, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 47, Train Loss: 0.6338, Val Loss: 0.7170, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6216, Val Loss: 0.6995, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 49, Train Loss: 0.6319, Val Loss: 0.7100, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.6400, Val Loss: 0.6765, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 51, Train Loss: 0.6354, Val Loss: 0.6722, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 52, Train Loss: 0.6531, Val Loss: 0.7350, F1 Micro: 0.6461, F1 Macro: 0.5051, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6666, Val Loss: 0.6661, F1 Micro: 0.6292, F1 Macro: 0.6168, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.6626, Val Loss: 0.7496, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 3, Train Loss: 0.6444, Val Loss: 0.8399, F1 Micro: 0.5337, F1 Macro: 0.3783, Accuracy: 0.5337\n","Epoch 4, Train Loss: 0.6510, Val Loss: 0.7038, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.6365, Val Loss: 0.7157, F1 Micro: 0.5843, F1 Macro: 0.4974, Accuracy: 0.5843\n","Epoch 6, Train Loss: 0.6468, Val Loss: 0.7799, F1 Micro: 0.5674, F1 Macro: 0.4909, Accuracy: 0.5674\n","Epoch 7, Train Loss: 0.6294, Val Loss: 0.6813, F1 Micro: 0.6742, F1 Macro: 0.6568, Accuracy: 0.6742\n","Epoch 8, Train Loss: 0.6418, Val Loss: 0.7428, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 9, Train Loss: 0.6379, Val Loss: 0.6853, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6457, Val Loss: 0.7025, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6389, Val Loss: 0.7108, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6347, Val Loss: 0.6841, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.6453, Val Loss: 0.7010, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 14, Train Loss: 0.6393, Val Loss: 0.7308, F1 Micro: 0.5787, F1 Macro: 0.4989, Accuracy: 0.5787\n","Epoch 15, Train Loss: 0.6413, Val Loss: 0.7279, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6323, Val Loss: 0.6555, F1 Micro: 0.6461, F1 Macro: 0.6442, Accuracy: 0.6461\n","Epoch 17, Train Loss: 0.6367, Val Loss: 0.7954, F1 Micro: 0.5899, F1 Macro: 0.5174, Accuracy: 0.5899\n","Epoch 18, Train Loss: 0.6320, Val Loss: 0.7470, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.6286, Val Loss: 0.8215, F1 Micro: 0.5674, F1 Macro: 0.4613, Accuracy: 0.5674\n","Epoch 20, Train Loss: 0.6269, Val Loss: 0.7764, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 21, Train Loss: 0.6229, Val Loss: 0.7709, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6420, Val Loss: 0.7026, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 23, Train Loss: 0.6510, Val Loss: 0.7550, F1 Micro: 0.5843, F1 Macro: 0.4974, Accuracy: 0.5843\n","Epoch 24, Train Loss: 0.6366, Val Loss: 0.7569, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 25, Train Loss: 0.6255, Val Loss: 0.7004, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6427, Val Loss: 0.6708, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.6225, Val Loss: 0.7001, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 28, Train Loss: 0.6362, Val Loss: 0.6914, F1 Micro: 0.6124, F1 Macro: 0.5681, Accuracy: 0.6124\n","Epoch 29, Train Loss: 0.6295, Val Loss: 0.6985, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 30, Train Loss: 0.6299, Val Loss: 0.7128, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 31, Train Loss: 0.6198, Val Loss: 0.7291, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6325, Val Loss: 0.7605, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 33, Train Loss: 0.6218, Val Loss: 0.6633, F1 Micro: 0.6573, F1 Macro: 0.6504, Accuracy: 0.6573\n","Epoch 34, Train Loss: 0.6255, Val Loss: 0.6792, F1 Micro: 0.6629, F1 Macro: 0.6468, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6218, Val Loss: 0.6990, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 36, Train Loss: 0.6168, Val Loss: 0.8229, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 37, Train Loss: 0.6296, Val Loss: 0.7221, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6398, Val Loss: 0.7230, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 39, Train Loss: 0.6283, Val Loss: 0.7409, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 40, Train Loss: 0.6317, Val Loss: 0.7419, F1 Micro: 0.5899, F1 Macro: 0.5070, Accuracy: 0.5899\n","Epoch 41, Train Loss: 0.6299, Val Loss: 0.7433, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 42, Train Loss: 0.6150, Val Loss: 0.7178, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 43, Train Loss: 0.6480, Val Loss: 0.7835, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 44, Train Loss: 0.6246, Val Loss: 0.7178, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6182, Val Loss: 0.7133, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6322, Val Loss: 0.7855, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 47, Train Loss: 0.6362, Val Loss: 0.7009, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 48, Train Loss: 0.6286, Val Loss: 0.7480, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6270, Val Loss: 0.7731, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 50, Train Loss: 0.6410, Val Loss: 0.6782, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6347, Val Loss: 0.7811, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 52, Train Loss: 0.6207, Val Loss: 0.6417, F1 Micro: 0.6517, F1 Macro: 0.6506, Accuracy: 0.6517\n","Epoch 53, Train Loss: 0.6274, Val Loss: 0.7018, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 54, Train Loss: 0.6108, Val Loss: 0.7284, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.6189, Val Loss: 0.7088, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.6232, Val Loss: 0.7069, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 57, Train Loss: 0.6157, Val Loss: 0.6910, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6827, Val Loss: 0.6865, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6483, Val Loss: 0.6574, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6401, Val Loss: 0.6624, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6493, Val Loss: 0.6818, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6618, Val Loss: 0.6708, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.6394, Val Loss: 0.7027, F1 Micro: 0.6124, F1 Macro: 0.4486, Accuracy: 0.6124\n","Epoch 7, Train Loss: 0.6312, Val Loss: 0.6780, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 8, Train Loss: 0.6374, Val Loss: 0.6511, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 9, Train Loss: 0.6213, Val Loss: 0.6451, F1 Micro: 0.6517, F1 Macro: 0.6103, Accuracy: 0.6517\n","Epoch 10, Train Loss: 0.6444, Val Loss: 0.6466, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 11, Train Loss: 0.6592, Val Loss: 0.6433, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6525, Val Loss: 0.6471, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6509, Val Loss: 0.6681, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6419, Val Loss: 0.7057, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6364, Val Loss: 0.6415, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 16, Train Loss: 0.6358, Val Loss: 0.6755, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6440, Val Loss: 0.6575, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6426, Val Loss: 0.6640, F1 Micro: 0.6292, F1 Macro: 0.5163, Accuracy: 0.6292\n","Epoch 19, Train Loss: 0.6500, Val Loss: 0.6427, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 20, Train Loss: 0.6318, Val Loss: 0.6657, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.6167, Val Loss: 0.6667, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 22, Train Loss: 0.6529, Val Loss: 0.6773, F1 Micro: 0.5787, F1 Macro: 0.5756, Accuracy: 0.5787\n","Epoch 23, Train Loss: 0.6399, Val Loss: 0.6427, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6283, Val Loss: 0.6803, F1 Micro: 0.6124, F1 Macro: 0.5681, Accuracy: 0.6124\n","Epoch 25, Train Loss: 0.6283, Val Loss: 0.6770, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.6411, Val Loss: 0.6788, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 27, Train Loss: 0.6581, Val Loss: 0.6654, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 28, Train Loss: 0.6359, Val Loss: 0.6430, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 29, Train Loss: 0.6346, Val Loss: 0.6740, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6436, Val Loss: 0.6513, F1 Micro: 0.6404, F1 Macro: 0.5436, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6376, Val Loss: 0.6523, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 32, Train Loss: 0.6286, Val Loss: 0.6607, F1 Micro: 0.6124, F1 Macro: 0.6058, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.6443, Val Loss: 0.6526, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.6259, Val Loss: 0.6717, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 35, Train Loss: 0.6361, Val Loss: 0.6457, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6296, Val Loss: 0.6490, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 37, Train Loss: 0.6344, Val Loss: 0.6856, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 38, Train Loss: 0.6490, Val Loss: 0.7279, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 39, Train Loss: 0.6472, Val Loss: 0.6544, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 40, Train Loss: 0.6238, Val Loss: 0.6549, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 41, Train Loss: 0.6219, Val Loss: 0.6421, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.6348, Val Loss: 0.6606, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 43, Train Loss: 0.6236, Val Loss: 0.6456, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 44, Train Loss: 0.6351, Val Loss: 0.6591, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 45, Train Loss: 0.6314, Val Loss: 0.6739, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 46, Train Loss: 0.6309, Val Loss: 0.6704, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 47, Train Loss: 0.6478, Val Loss: 0.6559, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.6293, Val Loss: 0.6813, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 49, Train Loss: 0.6233, Val Loss: 0.6599, F1 Micro: 0.6011, F1 Macro: 0.5990, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6555, Val Loss: 0.6775, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6309, Val Loss: 0.6460, F1 Micro: 0.6461, F1 Macro: 0.6024, Accuracy: 0.6461\n","Epoch 52, Train Loss: 0.6258, Val Loss: 0.6430, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 53, Train Loss: 0.6225, Val Loss: 0.6582, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 54, Train Loss: 0.6196, Val Loss: 0.6342, F1 Micro: 0.6854, F1 Macro: 0.6735, Accuracy: 0.6854\n","Epoch 55, Train Loss: 0.6374, Val Loss: 0.6607, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 56, Train Loss: 0.6289, Val Loss: 0.6465, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 57, Train Loss: 0.6273, Val Loss: 0.6719, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 58, Train Loss: 0.6290, Val Loss: 0.6899, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 59, Train Loss: 0.6358, Val Loss: 0.6727, F1 Micro: 0.6236, F1 Macro: 0.4823, Accuracy: 0.6236\n","Epoch 60, Train Loss: 0.6299, Val Loss: 0.6924, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7070554265268971\n","Best hyperparameters for Outer FOLD 4: (0.01, 8, 50) with score 0.7205009101751302\n","Epoch 1, Train Loss: 0.8700, Val Loss: 0.7282, F1 Micro: 0.6577, F1 Macro: 0.6149, Accuracy: 0.6577\n","Epoch 2, Train Loss: 0.7595, Val Loss: 0.6401, F1 Micro: 0.6802, F1 Macro: 0.6437, Accuracy: 0.6802\n","Epoch 3, Train Loss: 0.6850, Val Loss: 0.6243, F1 Micro: 0.6441, F1 Macro: 0.6371, Accuracy: 0.6441\n","Epoch 4, Train Loss: 0.6746, Val Loss: 0.6525, F1 Micro: 0.6532, F1 Macro: 0.6136, Accuracy: 0.6532\n","Epoch 5, Train Loss: 0.6520, Val Loss: 0.6698, F1 Micro: 0.6261, F1 Macro: 0.5545, Accuracy: 0.6261\n","Epoch 6, Train Loss: 0.6517, Val Loss: 0.6499, F1 Micro: 0.6757, F1 Macro: 0.6326, Accuracy: 0.6757\n","Epoch 7, Train Loss: 0.6468, Val Loss: 0.6432, F1 Micro: 0.6396, F1 Macro: 0.6220, Accuracy: 0.6396\n","Epoch 8, Train Loss: 0.6425, Val Loss: 0.6459, F1 Micro: 0.6757, F1 Macro: 0.6244, Accuracy: 0.6757\n","Epoch 9, Train Loss: 0.6437, Val Loss: 0.6260, F1 Micro: 0.6982, F1 Macro: 0.6814, Accuracy: 0.6982\n","Epoch 10, Train Loss: 0.6483, Val Loss: 0.6504, F1 Micro: 0.6667, F1 Macro: 0.6299, Accuracy: 0.6667\n","Epoch 11, Train Loss: 0.6424, Val Loss: 0.6239, F1 Micro: 0.6396, F1 Macro: 0.6152, Accuracy: 0.6396\n","Epoch 12, Train Loss: 0.6473, Val Loss: 0.6624, F1 Micro: 0.6937, F1 Macro: 0.6425, Accuracy: 0.6937\n","Epoch 13, Train Loss: 0.6418, Val Loss: 0.6507, F1 Micro: 0.6351, F1 Macro: 0.6148, Accuracy: 0.6351\n","Epoch 14, Train Loss: 0.6341, Val Loss: 0.6503, F1 Micro: 0.6351, F1 Macro: 0.6148, Accuracy: 0.6351\n","Epoch 15, Train Loss: 0.6414, Val Loss: 0.6263, F1 Micro: 0.6486, F1 Macro: 0.6472, Accuracy: 0.6486\n","Epoch 16, Train Loss: 0.6309, Val Loss: 0.6579, F1 Micro: 0.6351, F1 Macro: 0.5614, Accuracy: 0.6351\n","Epoch 17, Train Loss: 0.6490, Val Loss: 0.6600, F1 Micro: 0.6486, F1 Macro: 0.6168, Accuracy: 0.6486\n","Epoch 18, Train Loss: 0.6401, Val Loss: 0.6548, F1 Micro: 0.6486, F1 Macro: 0.6168, Accuracy: 0.6486\n","Epoch 19, Train Loss: 0.6397, Val Loss: 0.6356, F1 Micro: 0.6712, F1 Macro: 0.6607, Accuracy: 0.6712\n","Epoch 20, Train Loss: 0.6618, Val Loss: 0.6588, F1 Micro: 0.6802, F1 Macro: 0.6311, Accuracy: 0.6802\n","Epoch 21, Train Loss: 0.6330, Val Loss: 0.6313, F1 Micro: 0.6757, F1 Macro: 0.6696, Accuracy: 0.6757\n","Epoch 22, Train Loss: 0.6405, Val Loss: 0.6725, F1 Micro: 0.6441, F1 Macro: 0.6438, Accuracy: 0.6441\n","Epoch 23, Train Loss: 0.6419, Val Loss: 0.6185, F1 Micro: 0.7162, F1 Macro: 0.6930, Accuracy: 0.7162\n","Epoch 24, Train Loss: 0.6285, Val Loss: 0.6249, F1 Micro: 0.6486, F1 Macro: 0.5866, Accuracy: 0.6486\n","Epoch 25, Train Loss: 0.6352, Val Loss: 0.6307, F1 Micro: 0.6712, F1 Macro: 0.6403, Accuracy: 0.6712\n","Epoch 26, Train Loss: 0.6364, Val Loss: 0.6332, F1 Micro: 0.6577, F1 Macro: 0.6494, Accuracy: 0.6577\n","Epoch 27, Train Loss: 0.6431, Val Loss: 0.6339, F1 Micro: 0.6667, F1 Macro: 0.6322, Accuracy: 0.6667\n","Epoch 28, Train Loss: 0.6496, Val Loss: 0.6802, F1 Micro: 0.6396, F1 Macro: 0.5794, Accuracy: 0.6396\n","Epoch 29, Train Loss: 0.6384, Val Loss: 0.6275, F1 Micro: 0.6982, F1 Macro: 0.6814, Accuracy: 0.6982\n","Epoch 30, Train Loss: 0.6325, Val Loss: 0.6471, F1 Micro: 0.6396, F1 Macro: 0.6187, Accuracy: 0.6396\n","Epoch 31, Train Loss: 0.6399, Val Loss: 0.6215, F1 Micro: 0.7027, F1 Macro: 0.6776, Accuracy: 0.7027\n","Epoch 32, Train Loss: 0.6361, Val Loss: 0.6327, F1 Micro: 0.6441, F1 Macro: 0.5830, Accuracy: 0.6441\n","Epoch 33, Train Loss: 0.6386, Val Loss: 0.6256, F1 Micro: 0.6802, F1 Macro: 0.6481, Accuracy: 0.6802\n","Epoch 34, Train Loss: 0.6380, Val Loss: 0.6188, F1 Micro: 0.7027, F1 Macro: 0.6739, Accuracy: 0.7027\n","Epoch 35, Train Loss: 0.6368, Val Loss: 0.6424, F1 Micro: 0.6982, F1 Macro: 0.6699, Accuracy: 0.6982\n","Epoch 36, Train Loss: 0.6429, Val Loss: 0.7210, F1 Micro: 0.6171, F1 Macro: 0.5836, Accuracy: 0.6171\n","Epoch 37, Train Loss: 0.6417, Val Loss: 0.6554, F1 Micro: 0.6667, F1 Macro: 0.6078, Accuracy: 0.6667\n","Epoch 38, Train Loss: 0.6306, Val Loss: 0.6734, F1 Micro: 0.6757, F1 Macro: 0.6215, Accuracy: 0.6757\n","Epoch 39, Train Loss: 0.6484, Val Loss: 0.6303, F1 Micro: 0.6892, F1 Macro: 0.6580, Accuracy: 0.6892\n","Epoch 40, Train Loss: 0.6269, Val Loss: 0.6269, F1 Micro: 0.6532, F1 Macro: 0.6228, Accuracy: 0.6532\n","Epoch 41, Train Loss: 0.6437, Val Loss: 0.6607, F1 Micro: 0.6261, F1 Macro: 0.5333, Accuracy: 0.6261\n","Epoch 42, Train Loss: 0.6219, Val Loss: 0.7100, F1 Micro: 0.6081, F1 Macro: 0.4895, Accuracy: 0.6081\n","Epoch 43, Train Loss: 0.6503, Val Loss: 0.6877, F1 Micro: 0.6216, F1 Macro: 0.5390, Accuracy: 0.6216\n","Epoch 44, Train Loss: 0.6382, Val Loss: 0.6238, F1 Micro: 0.6892, F1 Macro: 0.6782, Accuracy: 0.6892\n","Epoch 45, Train Loss: 0.6471, Val Loss: 0.6440, F1 Micro: 0.6757, F1 Macro: 0.6376, Accuracy: 0.6757\n","Epoch 46, Train Loss: 0.6412, Val Loss: 0.6322, F1 Micro: 0.6892, F1 Macro: 0.6733, Accuracy: 0.6892\n","Epoch 47, Train Loss: 0.6353, Val Loss: 0.6502, F1 Micro: 0.6667, F1 Macro: 0.6250, Accuracy: 0.6667\n","Epoch 48, Train Loss: 0.6377, Val Loss: 0.6440, F1 Micro: 0.6216, F1 Macro: 0.6146, Accuracy: 0.6216\n","Epoch 49, Train Loss: 0.6509, Val Loss: 0.6283, F1 Micro: 0.6937, F1 Macro: 0.6744, Accuracy: 0.6937\n","Epoch 50, Train Loss: 0.6363, Val Loss: 0.6455, F1 Micro: 0.6667, F1 Macro: 0.6299, Accuracy: 0.6667\n","Epoch 51, Train Loss: 0.6425, Val Loss: 0.6351, F1 Micro: 0.6802, F1 Macro: 0.6481, Accuracy: 0.6802\n","Epoch 52, Train Loss: 0.6298, Val Loss: 0.6944, F1 Micro: 0.6486, F1 Macro: 0.5758, Accuracy: 0.6486\n","Epoch 53, Train Loss: 0.6535, Val Loss: 0.6593, F1 Micro: 0.6532, F1 Macro: 0.6111, Accuracy: 0.6532\n","Epoch 54, Train Loss: 0.6226, Val Loss: 0.6516, F1 Micro: 0.6532, F1 Macro: 0.6161, Accuracy: 0.6532\n","Epoch 55, Train Loss: 0.6279, Val Loss: 0.6331, F1 Micro: 0.6937, F1 Macro: 0.6678, Accuracy: 0.6937\n","Epoch 56, Train Loss: 0.6311, Val Loss: 0.6619, F1 Micro: 0.6712, F1 Macro: 0.6313, Accuracy: 0.6712\n","Epoch 57, Train Loss: 0.6414, Val Loss: 0.6322, F1 Micro: 0.6847, F1 Macro: 0.6649, Accuracy: 0.6847\n","Epoch 58, Train Loss: 0.6317, Val Loss: 0.6377, F1 Micro: 0.6757, F1 Macro: 0.6598, Accuracy: 0.6757\n","Epoch 59, Train Loss: 0.6375, Val Loss: 0.6577, F1 Micro: 0.6622, F1 Macro: 0.6463, Accuracy: 0.6622\n","Epoch 60, Train Loss: 0.6214, Val Loss: 0.6197, F1 Micro: 0.6757, F1 Macro: 0.6712, Accuracy: 0.6757\n","Epoch 61, Train Loss: 0.6308, Val Loss: 0.6572, F1 Micro: 0.6532, F1 Macro: 0.6305, Accuracy: 0.6532\n","Epoch 62, Train Loss: 0.6458, Val Loss: 0.6331, F1 Micro: 0.6757, F1 Macro: 0.6501, Accuracy: 0.6757\n","Epoch 63, Train Loss: 0.6374, Val Loss: 0.6587, F1 Micro: 0.6532, F1 Macro: 0.6184, Accuracy: 0.6532\n","Epoch 64, Train Loss: 0.6387, Val Loss: 0.6658, F1 Micro: 0.6757, F1 Macro: 0.6215, Accuracy: 0.6757\n","Epoch 65, Train Loss: 0.6433, Val Loss: 0.6281, F1 Micro: 0.6937, F1 Macro: 0.6773, Accuracy: 0.6937\n","Epoch 66, Train Loss: 0.6393, Val Loss: 0.6361, F1 Micro: 0.6577, F1 Macro: 0.6529, Accuracy: 0.6577\n","Epoch 67, Train Loss: 0.6323, Val Loss: 0.6425, F1 Micro: 0.6351, F1 Macro: 0.5533, Accuracy: 0.6351\n","Epoch 68, Train Loss: 0.6410, Val Loss: 0.6613, F1 Micro: 0.6216, F1 Macro: 0.6213, Accuracy: 0.6216\n","Epoch 69, Train Loss: 0.6262, Val Loss: 0.6192, F1 Micro: 0.6982, F1 Macro: 0.6905, Accuracy: 0.6982\n","Epoch 70, Train Loss: 0.6523, Val Loss: 0.6749, F1 Micro: 0.6667, F1 Macro: 0.6011, Accuracy: 0.6667\n","Epoch 71, Train Loss: 0.6374, Val Loss: 0.6428, F1 Micro: 0.6622, F1 Macro: 0.6305, Accuracy: 0.6622\n","Epoch 72, Train Loss: 0.6333, Val Loss: 0.6380, F1 Micro: 0.6847, F1 Macro: 0.6752, Accuracy: 0.6847\n","Epoch 73, Train Loss: 0.6230, Val Loss: 0.6289, F1 Micro: 0.7027, F1 Macro: 0.6719, Accuracy: 0.7027\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.7027, F1 Macro: 0.6719, Accuracy: 0.7027\n"]}]},{"cell_type":"code","source":["update_model_metrics_pr('GraphSAGEModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics_pr)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyXIRoepFsGd","executionInfo":{"status":"ok","timestamp":1711383197963,"user_tz":-60,"elapsed":484,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"53b5ea58-eac1-4408-95aa-0e30513ad8c6"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]], 'f1_macro': [[0.6368645296571416, 0.7291175419792784, 0.5760113268608413, 0.586319141408185, 0.6266265380189431]], 'accuracy': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]]}, 'GraphSAGEModel': {'f1_micro': [[0.6457399103139013, 0.7668161434977578, 0.6681614349775785, 0.6846846846846847, 0.7027027027027027]], 'f1_macro': [[0.6094224587074603, 0.7003927242662258, 0.6639377647442164, 0.6615853658536586, 0.6719211822660098]], 'accuracy': [[0.6457399103139013, 0.7668161434977578, 0.6681614349775785, 0.6846846846846847, 0.7027027027027027]]}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"code","source":["# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list3 = []\n","f1_macro_test_list3 = []\n","accuracy_test_list3 = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_pr)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_pr[train_val_idx]\n","    test_dataset = dataset_pr[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = GINModel(\n","                input_dim=dataset_pr.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_pr.num_classes,\n","                dropout_rate=0.5\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = GINModel(\n","                input_dim=dataset_pr.num_node_features,\n","                hidden_dim=256,\n","                output_dim=dataset_pr.num_classes,\n","                num_layers=2,\n","                dropout_rate=0.5\n","            ).to(device)\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list3.append(f1_micro_test)\n","    f1_macro_test_list3.append(f1_macro_test)\n","    accuracy_test_list3.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'GSAGE_fold_pr{fold}.pth')\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yEeDs79RYzUd","executionInfo":{"status":"ok","timestamp":1711389827352,"user_tz":-60,"elapsed":0,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"343be132-a48a-4075-83b1-d2dd8d02e361"},"execution_count":33,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 14, Train Loss: 0.6347, Val Loss: 0.5959, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6224, Val Loss: 0.5937, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.6274, Val Loss: 0.6044, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 17, Train Loss: 0.6313, Val Loss: 0.6504, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.6222, Val Loss: 0.6157, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 19, Train Loss: 0.6265, Val Loss: 0.5919, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.6256, Val Loss: 0.5996, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 21, Train Loss: 0.6263, Val Loss: 0.5921, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.6239, Val Loss: 0.6003, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6167, Val Loss: 0.5830, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 24, Train Loss: 0.6251, Val Loss: 0.6131, F1 Micro: 0.7079, F1 Macro: 0.7025, Accuracy: 0.7079\n","Epoch 25, Train Loss: 0.6238, Val Loss: 0.5847, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.6150, Val Loss: 0.5916, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6219, Val Loss: 0.5809, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.6183, Val Loss: 0.5829, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 29, Train Loss: 0.6153, Val Loss: 0.5732, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 30, Train Loss: 0.6230, Val Loss: 0.5834, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 31, Train Loss: 0.6146, Val Loss: 0.5759, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 32, Train Loss: 0.6193, Val Loss: 0.6043, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 33, Train Loss: 0.6136, Val Loss: 0.5772, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 34, Train Loss: 0.6134, Val Loss: 0.5743, F1 Micro: 0.7360, F1 Macro: 0.7179, Accuracy: 0.7360\n","Epoch 35, Train Loss: 0.6152, Val Loss: 0.6377, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 36, Train Loss: 0.6280, Val Loss: 0.5915, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 37, Train Loss: 0.6143, Val Loss: 0.5740, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 38, Train Loss: 0.6107, Val Loss: 0.5726, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 39, Train Loss: 0.6076, Val Loss: 0.5823, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 40, Train Loss: 0.6156, Val Loss: 0.5843, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 41, Train Loss: 0.6185, Val Loss: 0.6017, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 42, Train Loss: 0.6083, Val Loss: 0.5834, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 43, Train Loss: 0.6143, Val Loss: 0.5890, F1 Micro: 0.7416, F1 Macro: 0.7263, Accuracy: 0.7416\n","Epoch 44, Train Loss: 0.6061, Val Loss: 0.5827, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 45, Train Loss: 0.6105, Val Loss: 0.5816, F1 Micro: 0.7360, F1 Macro: 0.7179, Accuracy: 0.7360\n","Epoch 46, Train Loss: 0.6165, Val Loss: 0.5957, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6075, Val Loss: 0.5723, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 48, Train Loss: 0.6065, Val Loss: 0.5881, F1 Micro: 0.7247, F1 Macro: 0.7149, Accuracy: 0.7247\n","Epoch 49, Train Loss: 0.6149, Val Loss: 0.6019, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 50, Train Loss: 0.6092, Val Loss: 0.5920, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 51, Train Loss: 0.6135, Val Loss: 0.5863, F1 Micro: 0.7191, F1 Macro: 0.7109, Accuracy: 0.7191\n","Epoch 52, Train Loss: 0.5999, Val Loss: 0.5916, F1 Micro: 0.7303, F1 Macro: 0.7175, Accuracy: 0.7303\n","Epoch 53, Train Loss: 0.6080, Val Loss: 0.5735, F1 Micro: 0.7360, F1 Macro: 0.7179, Accuracy: 0.7360\n","Epoch 54, Train Loss: 0.6088, Val Loss: 0.5907, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 55, Train Loss: 0.6114, Val Loss: 0.5692, F1 Micro: 0.7416, F1 Macro: 0.7213, Accuracy: 0.7416\n","Epoch 56, Train Loss: 0.6086, Val Loss: 0.5689, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 57, Train Loss: 0.6007, Val Loss: 0.5731, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 58, Train Loss: 0.6027, Val Loss: 0.5688, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 59, Train Loss: 0.6033, Val Loss: 0.5739, F1 Micro: 0.7303, F1 Macro: 0.7144, Accuracy: 0.7303\n","Epoch 60, Train Loss: 0.6079, Val Loss: 0.5828, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 61, Train Loss: 0.6060, Val Loss: 0.5720, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7000000000000001\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6878, Val Loss: 0.6667, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 2, Train Loss: 0.6485, Val Loss: 0.8039, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.6425, Val Loss: 0.6705, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6548, Val Loss: 0.6594, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 5, Train Loss: 0.6479, Val Loss: 0.6658, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 6, Train Loss: 0.6472, Val Loss: 0.6735, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6418, Val Loss: 0.7566, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.6425, Val Loss: 0.6553, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 9, Train Loss: 0.6355, Val Loss: 0.6600, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6340, Val Loss: 0.6519, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6347, Val Loss: 0.6629, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7118, Val Loss: 0.8165, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6451, Val Loss: 0.6268, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6512, Val Loss: 0.6428, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6480, Val Loss: 0.6375, F1 Micro: 0.5618, F1 Macro: 0.5507, Accuracy: 0.5618\n","Epoch 5, Train Loss: 0.6397, Val Loss: 0.6386, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Epoch 6, Train Loss: 0.6537, Val Loss: 0.6539, F1 Micro: 0.5506, F1 Macro: 0.5459, Accuracy: 0.5506\n","Epoch 7, Train Loss: 0.6604, Val Loss: 0.6457, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6337, Val Loss: 0.6152, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6311, Val Loss: 0.6182, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 10, Train Loss: 0.6690, Val Loss: 0.6257, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 11, Train Loss: 0.6494, Val Loss: 0.6977, F1 Micro: 0.4157, F1 Macro: 0.3962, Accuracy: 0.4157\n","Epoch 12, Train Loss: 0.6367, Val Loss: 0.6201, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6363, Val Loss: 0.6364, F1 Micro: 0.6011, F1 Macro: 0.5917, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6409, Val Loss: 0.6596, F1 Micro: 0.5393, F1 Macro: 0.5379, Accuracy: 0.5393\n","Epoch 15, Train Loss: 0.6250, Val Loss: 0.6143, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6910, Val Loss: 0.6890, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 2, Train Loss: 0.6757, Val Loss: 0.6895, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.6750, Val Loss: 0.6897, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6727, Val Loss: 0.6933, F1 Micro: 0.5730, F1 Macro: 0.3761, Accuracy: 0.5730\n","Epoch 5, Train Loss: 0.6742, Val Loss: 0.6915, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 6, Train Loss: 0.6746, Val Loss: 0.6920, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 7, Train Loss: 0.6734, Val Loss: 0.6922, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 8, Train Loss: 0.6733, Val Loss: 0.6925, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 9, Train Loss: 0.6737, Val Loss: 0.6926, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6732, Val Loss: 0.6930, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 11, Train Loss: 0.6732, Val Loss: 0.6934, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6736, Val Loss: 0.6936, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6990, Val Loss: 0.6960, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6806, Val Loss: 0.6983, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6753, Val Loss: 0.7010, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6651, Val Loss: 0.6928, F1 Micro: 0.5787, F1 Macro: 0.5041, Accuracy: 0.5787\n","Epoch 5, Train Loss: 0.6729, Val Loss: 0.7073, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6702, Val Loss: 0.7090, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6685, Val Loss: 0.7116, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6681, Val Loss: 0.7132, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6679, Val Loss: 0.7156, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6675, Val Loss: 0.7172, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6683, Val Loss: 0.7188, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6663, Val Loss: 0.7194, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6634, Val Loss: 0.7206, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6702, Val Loss: 0.7135, F1 Micro: 0.5337, F1 Macro: 0.3874, Accuracy: 0.5337\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6845, Val Loss: 0.7230, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 2, Train Loss: 0.6409, Val Loss: 0.6707, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 3, Train Loss: 0.6465, Val Loss: 0.6238, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 4, Train Loss: 0.6451, Val Loss: 0.6288, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 5, Train Loss: 0.6389, Val Loss: 0.6295, F1 Micro: 0.7416, F1 Macro: 0.7263, Accuracy: 0.7416\n","Epoch 6, Train Loss: 0.6359, Val Loss: 0.6164, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 7, Train Loss: 0.6351, Val Loss: 0.6120, F1 Micro: 0.7191, F1 Macro: 0.7042, Accuracy: 0.7191\n","Epoch 8, Train Loss: 0.6427, Val Loss: 0.6154, F1 Micro: 0.7472, F1 Macro: 0.7315, Accuracy: 0.7472\n","Epoch 9, Train Loss: 0.6356, Val Loss: 0.6212, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 10, Train Loss: 0.6236, Val Loss: 0.6166, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 11, Train Loss: 0.6220, Val Loss: 0.6289, F1 Micro: 0.7584, F1 Macro: 0.7487, Accuracy: 0.7584\n","Epoch 12, Train Loss: 0.6239, Val Loss: 0.6535, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6236, Val Loss: 0.7017, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6247, Val Loss: 0.6258, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 15, Train Loss: 0.6223, Val Loss: 0.6398, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 16, Train Loss: 0.6191, Val Loss: 0.6265, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.6251, Val Loss: 0.6331, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6361, Val Loss: 0.6147, F1 Micro: 0.7191, F1 Macro: 0.7120, Accuracy: 0.7191\n","Epoch 19, Train Loss: 0.6295, Val Loss: 0.6520, F1 Micro: 0.6685, F1 Macro: 0.6683, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6126, Val Loss: 0.5995, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 21, Train Loss: 0.6388, Val Loss: 0.6277, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.6449438202247191\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7135, Val Loss: 0.7122, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 2, Train Loss: 0.6948, Val Loss: 0.7301, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.6813, Val Loss: 0.6841, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6727, Val Loss: 0.6455, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.6764, Val Loss: 0.7151, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 6, Train Loss: 0.6676, Val Loss: 0.7140, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6727, Val Loss: 0.6852, F1 Micro: 0.6236, F1 Macro: 0.5253, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6532, Val Loss: 0.7139, F1 Micro: 0.6011, F1 Macro: 0.5655, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6665, Val Loss: 0.7079, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6609, Val Loss: 0.6951, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6593, Val Loss: 0.6859, F1 Micro: 0.6292, F1 Macro: 0.4858, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6601, Val Loss: 0.6721, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6552, Val Loss: 0.6680, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6501, Val Loss: 0.6783, F1 Micro: 0.6404, F1 Macro: 0.4930, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6568, Val Loss: 0.7060, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.6610, Val Loss: 0.6685, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 17, Train Loss: 0.6635, Val Loss: 0.6690, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.6610, Val Loss: 0.6745, F1 Micro: 0.6517, F1 Macro: 0.5247, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.6583, Val Loss: 0.6703, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.6549, Val Loss: 0.6792, F1 Micro: 0.6292, F1 Macro: 0.4679, Accuracy: 0.6292\n","Epoch 21, Train Loss: 0.6583, Val Loss: 0.6628, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.6633, Val Loss: 0.7077, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6535, Val Loss: 0.6641, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 24, Train Loss: 0.6584, Val Loss: 0.6902, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 25, Train Loss: 0.6556, Val Loss: 0.6629, F1 Micro: 0.6404, F1 Macro: 0.5374, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6479, Val Loss: 0.6692, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.6481, Val Loss: 0.6802, F1 Micro: 0.6348, F1 Macro: 0.4977, Accuracy: 0.6348\n","Epoch 28, Train Loss: 0.6355, Val Loss: 0.6509, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 29, Train Loss: 0.6457, Val Loss: 0.6650, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 30, Train Loss: 0.6502, Val Loss: 0.6543, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6280, Val Loss: 0.6587, F1 Micro: 0.6404, F1 Macro: 0.5094, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6350, Val Loss: 0.6900, F1 Micro: 0.5955, F1 Macro: 0.3732, Accuracy: 0.5955\n","Epoch 33, Train Loss: 0.6461, Val Loss: 0.6523, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 34, Train Loss: 0.6244, Val Loss: 0.6377, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 35, Train Loss: 0.6225, Val Loss: 0.6378, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 36, Train Loss: 0.6345, Val Loss: 0.6336, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 37, Train Loss: 0.6249, Val Loss: 0.6380, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 38, Train Loss: 0.6345, Val Loss: 0.6483, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 39, Train Loss: 0.6267, Val Loss: 0.6606, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 40, Train Loss: 0.6207, Val Loss: 0.6250, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 41, Train Loss: 0.6149, Val Loss: 0.6268, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 42, Train Loss: 0.6106, Val Loss: 0.6258, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6134, Val Loss: 0.6377, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 44, Train Loss: 0.6215, Val Loss: 0.6242, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 45, Train Loss: 0.6027, Val Loss: 0.6872, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 46, Train Loss: 0.6269, Val Loss: 0.6233, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 47, Train Loss: 0.6045, Val Loss: 0.6174, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 48, Train Loss: 0.6055, Val Loss: 0.6246, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.5993, Val Loss: 0.6351, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 50, Train Loss: 0.5995, Val Loss: 0.6467, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 51, Train Loss: 0.6032, Val Loss: 0.6430, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 52, Train Loss: 0.6048, Val Loss: 0.6356, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 53, Train Loss: 0.6088, Val Loss: 0.6156, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.5971, Val Loss: 0.6150, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 55, Train Loss: 0.5971, Val Loss: 0.6255, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 56, Train Loss: 0.5923, Val Loss: 0.6132, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 57, Train Loss: 0.5969, Val Loss: 0.6180, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.5834, Val Loss: 0.6308, F1 Micro: 0.6404, F1 Macro: 0.6040, Accuracy: 0.6404\n","Epoch 59, Train Loss: 0.5926, Val Loss: 0.6465, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 60, Train Loss: 0.5953, Val Loss: 0.6224, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 61, Train Loss: 0.5953, Val Loss: 0.6436, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 62, Train Loss: 0.5976, Val Loss: 0.6292, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.5985, Val Loss: 0.6297, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 64, Train Loss: 0.5878, Val Loss: 0.6391, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 65, Train Loss: 0.5808, Val Loss: 0.6281, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 66, Train Loss: 0.5913, Val Loss: 0.6160, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.5925, Val Loss: 0.6129, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 68, Train Loss: 0.5905, Val Loss: 0.6239, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 69, Train Loss: 0.5952, Val Loss: 0.6025, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.5811, Val Loss: 0.6290, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 71, Train Loss: 0.5909, Val Loss: 0.6270, F1 Micro: 0.6404, F1 Macro: 0.5871, Accuracy: 0.6404\n","Epoch 72, Train Loss: 0.5925, Val Loss: 0.6236, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 73, Train Loss: 0.5912, Val Loss: 0.6184, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.5833, Val Loss: 0.6377, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.5857, Val Loss: 0.6312, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 76, Train Loss: 0.5856, Val Loss: 0.6433, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 77, Train Loss: 0.5898, Val Loss: 0.6159, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 78, Train Loss: 0.5794, Val Loss: 0.6530, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 79, Train Loss: 0.5938, Val Loss: 0.6153, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 80, Train Loss: 0.5848, Val Loss: 0.6234, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 81, Train Loss: 0.5807, Val Loss: 0.6566, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 82, Train Loss: 0.5829, Val Loss: 0.6283, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 83, Train Loss: 0.5803, Val Loss: 0.6277, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 84, Train Loss: 0.5823, Val Loss: 0.6250, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 85, Train Loss: 0.5806, Val Loss: 0.6398, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 86, Train Loss: 0.5851, Val Loss: 0.6268, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 87, Train Loss: 0.5833, Val Loss: 0.6209, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 88, Train Loss: 0.5909, Val Loss: 0.6307, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 89, Train Loss: 0.5812, Val Loss: 0.6353, F1 Micro: 0.6461, F1 Macro: 0.5990, Accuracy: 0.6461\n","Epoch 90, Train Loss: 0.5820, Val Loss: 0.6215, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 91, Train Loss: 0.5967, Val Loss: 0.6345, F1 Micro: 0.6461, F1 Macro: 0.6024, Accuracy: 0.6461\n","Epoch 92, Train Loss: 0.5869, Val Loss: 0.6258, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 93, Train Loss: 0.5724, Val Loss: 0.6190, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 94, Train Loss: 0.5881, Val Loss: 0.6127, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 95, Train Loss: 0.5902, Val Loss: 0.6298, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 96, Train Loss: 0.5863, Val Loss: 0.6061, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 97, Train Loss: 0.5824, Val Loss: 0.6264, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 98, Train Loss: 0.5752, Val Loss: 0.6396, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 99, Train Loss: 0.5895, Val Loss: 0.5988, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 100, Train Loss: 0.5811, Val Loss: 0.6607, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 101, Train Loss: 0.5886, Val Loss: 0.6211, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6890, Val Loss: 0.6716, F1 Micro: 0.6854, F1 Macro: 0.5021, Accuracy: 0.6854\n","Epoch 2, Train Loss: 0.6783, Val Loss: 0.6689, F1 Micro: 0.6629, F1 Macro: 0.4882, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6651, Val Loss: 0.6504, F1 Micro: 0.6742, F1 Macro: 0.4843, Accuracy: 0.6742\n","Epoch 4, Train Loss: 0.6536, Val Loss: 0.6236, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6266, Val Loss: 0.6372, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6230, Val Loss: 0.6065, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.6223, Val Loss: 0.5985, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 8, Train Loss: 0.6238, Val Loss: 0.6206, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6165, Val Loss: 0.6035, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 10, Train Loss: 0.6041, Val Loss: 0.5980, F1 Micro: 0.7079, F1 Macro: 0.6014, Accuracy: 0.7079\n","Epoch 11, Train Loss: 0.6141, Val Loss: 0.6351, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6084, Val Loss: 0.5975, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.5948, Val Loss: 0.6148, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.5995, Val Loss: 0.6161, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.5994, Val Loss: 0.6290, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.5926, Val Loss: 0.6071, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.5924, Val Loss: 0.5928, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 18, Train Loss: 0.5968, Val Loss: 0.5938, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 19, Train Loss: 0.5987, Val Loss: 0.6123, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6012, Val Loss: 0.6060, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.5915, Val Loss: 0.6109, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.5910, Val Loss: 0.6160, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 23, Train Loss: 0.5973, Val Loss: 0.6245, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 24, Train Loss: 0.5899, Val Loss: 0.5938, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 25, Train Loss: 0.5892, Val Loss: 0.6084, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 26, Train Loss: 0.6007, Val Loss: 0.6508, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.5889, Val Loss: 0.6225, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.5823, Val Loss: 0.5956, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.5919, Val Loss: 0.5971, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 30, Train Loss: 0.5940, Val Loss: 0.6099, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.5867, Val Loss: 0.5920, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.5858, Val Loss: 0.5882, F1 Micro: 0.7247, F1 Macro: 0.6482, Accuracy: 0.7247\n","Epoch 33, Train Loss: 0.5729, Val Loss: 0.6548, F1 Micro: 0.6180, F1 Macro: 0.6083, Accuracy: 0.6180\n","Epoch 34, Train Loss: 0.5879, Val Loss: 0.6351, F1 Micro: 0.6067, F1 Macro: 0.5919, Accuracy: 0.6067\n","Epoch 35, Train Loss: 0.5825, Val Loss: 0.5955, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 36, Train Loss: 0.5733, Val Loss: 0.5926, F1 Micro: 0.7247, F1 Macro: 0.6383, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.5918, Val Loss: 0.6060, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 38, Train Loss: 0.5792, Val Loss: 0.6097, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 39, Train Loss: 0.5882, Val Loss: 0.5886, F1 Micro: 0.7079, F1 Macro: 0.6339, Accuracy: 0.7079\n","Epoch 40, Train Loss: 0.5777, Val Loss: 0.6088, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 41, Train Loss: 0.5725, Val Loss: 0.5923, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 42, Train Loss: 0.5798, Val Loss: 0.5941, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 43, Train Loss: 0.5732, Val Loss: 0.6124, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 44, Train Loss: 0.5772, Val Loss: 0.6023, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 45, Train Loss: 0.5778, Val Loss: 0.6105, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 46, Train Loss: 0.5756, Val Loss: 0.6352, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 47, Train Loss: 0.5648, Val Loss: 0.5996, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 48, Train Loss: 0.5681, Val Loss: 0.5932, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.5868, Val Loss: 0.5910, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 50, Train Loss: 0.5681, Val Loss: 0.5869, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 51, Train Loss: 0.5716, Val Loss: 0.5932, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.5688, Val Loss: 0.6267, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 53, Train Loss: 0.5809, Val Loss: 0.6006, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.5752, Val Loss: 0.6371, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 55, Train Loss: 0.5783, Val Loss: 0.6360, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.5782, Val Loss: 0.6051, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 57, Train Loss: 0.5850, Val Loss: 0.6242, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 58, Train Loss: 0.5749, Val Loss: 0.5960, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.5734, Val Loss: 0.5966, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 60, Train Loss: 0.5696, Val Loss: 0.6002, F1 Micro: 0.7079, F1 Macro: 0.6339, Accuracy: 0.7079\n","Epoch 61, Train Loss: 0.5837, Val Loss: 0.5995, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.5667, Val Loss: 0.6314, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 63, Train Loss: 0.5689, Val Loss: 0.5965, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 64, Train Loss: 0.5633, Val Loss: 0.5854, F1 Micro: 0.7303, F1 Macro: 0.6577, Accuracy: 0.7303\n","Epoch 65, Train Loss: 0.5727, Val Loss: 0.6003, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 66, Train Loss: 0.5761, Val Loss: 0.5933, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 67, Train Loss: 0.5622, Val Loss: 0.6037, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 68, Train Loss: 0.5631, Val Loss: 0.6011, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 69, Train Loss: 0.5608, Val Loss: 0.5958, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 70, Train Loss: 0.5773, Val Loss: 0.5870, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.5592, Val Loss: 0.5908, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 72, Train Loss: 0.5601, Val Loss: 0.6301, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 73, Train Loss: 0.5685, Val Loss: 0.5977, F1 Micro: 0.7135, F1 Macro: 0.6288, Accuracy: 0.7135\n","Epoch 74, Train Loss: 0.5649, Val Loss: 0.6079, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 75, Train Loss: 0.5697, Val Loss: 0.5888, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 76, Train Loss: 0.5689, Val Loss: 0.5975, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 77, Train Loss: 0.5680, Val Loss: 0.6081, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 78, Train Loss: 0.5738, Val Loss: 0.6014, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.5724, Val Loss: 0.5894, F1 Micro: 0.6966, F1 Macro: 0.6245, Accuracy: 0.6966\n","Epoch 80, Train Loss: 0.5675, Val Loss: 0.5935, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 81, Train Loss: 0.5659, Val Loss: 0.6215, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 82, Train Loss: 0.5717, Val Loss: 0.6078, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 83, Train Loss: 0.5639, Val Loss: 0.5930, F1 Micro: 0.7135, F1 Macro: 0.6555, Accuracy: 0.7135\n","Epoch 84, Train Loss: 0.5633, Val Loss: 0.5882, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 85, Train Loss: 0.5601, Val Loss: 0.5879, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 86, Train Loss: 0.5606, Val Loss: 0.5901, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 87, Train Loss: 0.5610, Val Loss: 0.6152, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 88, Train Loss: 0.5679, Val Loss: 0.5922, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 89, Train Loss: 0.5555, Val Loss: 0.5978, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 90, Train Loss: 0.5588, Val Loss: 0.6016, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 91, Train Loss: 0.5598, Val Loss: 0.6718, F1 Micro: 0.5955, F1 Macro: 0.5837, Accuracy: 0.5955\n","Epoch 92, Train Loss: 0.5670, Val Loss: 0.5960, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 93, Train Loss: 0.5700, Val Loss: 0.5947, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 94, Train Loss: 0.5605, Val Loss: 0.6197, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 95, Train Loss: 0.5472, Val Loss: 0.6105, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 96, Train Loss: 0.5617, Val Loss: 0.6683, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 97, Train Loss: 0.5710, Val Loss: 0.5974, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 98, Train Loss: 0.5578, Val Loss: 0.5980, F1 Micro: 0.7191, F1 Macro: 0.6480, Accuracy: 0.7191\n","Epoch 99, Train Loss: 0.5610, Val Loss: 0.6029, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 100, Train Loss: 0.5617, Val Loss: 0.6138, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 101, Train Loss: 0.5595, Val Loss: 0.5989, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 102, Train Loss: 0.5676, Val Loss: 0.5870, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 103, Train Loss: 0.5730, Val Loss: 0.5957, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 104, Train Loss: 0.5519, Val Loss: 0.5893, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 105, Train Loss: 0.5713, Val Loss: 0.5922, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 106, Train Loss: 0.5683, Val Loss: 0.5952, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 107, Train Loss: 0.5588, Val Loss: 0.6033, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 108, Train Loss: 0.5646, Val Loss: 0.6037, F1 Micro: 0.7191, F1 Macro: 0.6282, Accuracy: 0.7191\n","Epoch 109, Train Loss: 0.5668, Val Loss: 0.5981, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 110, Train Loss: 0.5584, Val Loss: 0.5967, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 111, Train Loss: 0.5566, Val Loss: 0.5955, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 112, Train Loss: 0.5614, Val Loss: 0.5868, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 113, Train Loss: 0.5614, Val Loss: 0.6061, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 114, Train Loss: 0.5579, Val Loss: 0.5913, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6926, Val Loss: 0.6922, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 2, Train Loss: 0.6739, Val Loss: 0.6925, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 3, Train Loss: 0.6733, Val Loss: 0.6927, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 4, Train Loss: 0.6732, Val Loss: 0.6929, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 5, Train Loss: 0.6742, Val Loss: 0.6933, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 6, Train Loss: 0.6732, Val Loss: 0.6934, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 7, Train Loss: 0.6726, Val Loss: 0.6935, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 8, Train Loss: 0.6726, Val Loss: 0.6938, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 9, Train Loss: 0.6731, Val Loss: 0.6939, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6748, Val Loss: 0.6939, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 11, Train Loss: 0.6736, Val Loss: 0.6938, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6741, Val Loss: 0.6940, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 13, Train Loss: 0.6726, Val Loss: 0.6942, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 14, Train Loss: 0.6726, Val Loss: 0.6941, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.6731, Val Loss: 0.6943, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 16, Train Loss: 0.6734, Val Loss: 0.6943, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 17, Train Loss: 0.6731, Val Loss: 0.6942, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 18, Train Loss: 0.6736, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 19, Train Loss: 0.6714, Val Loss: 0.6942, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 20, Train Loss: 0.6730, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 21, Train Loss: 0.6720, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 22, Train Loss: 0.6731, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 23, Train Loss: 0.6731, Val Loss: 0.6948, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 24, Train Loss: 0.6725, Val Loss: 0.6947, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 25, Train Loss: 0.6725, Val Loss: 0.6947, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 26, Train Loss: 0.6737, Val Loss: 0.6948, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 27, Train Loss: 0.6743, Val Loss: 0.6951, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 28, Train Loss: 0.6748, Val Loss: 0.6946, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 29, Train Loss: 0.6737, Val Loss: 0.6943, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 30, Train Loss: 0.6725, Val Loss: 0.6942, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 31, Train Loss: 0.6736, Val Loss: 0.6946, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 32, Train Loss: 0.6719, Val Loss: 0.6943, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 33, Train Loss: 0.6725, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 34, Train Loss: 0.6743, Val Loss: 0.6948, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 35, Train Loss: 0.6725, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 36, Train Loss: 0.6725, Val Loss: 0.6946, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 37, Train Loss: 0.6736, Val Loss: 0.6946, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 38, Train Loss: 0.6736, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 39, Train Loss: 0.6727, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 40, Train Loss: 0.6725, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 41, Train Loss: 0.6731, Val Loss: 0.6948, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 42, Train Loss: 0.6748, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 43, Train Loss: 0.6730, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 44, Train Loss: 0.6737, Val Loss: 0.6946, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 45, Train Loss: 0.6736, Val Loss: 0.6942, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 46, Train Loss: 0.6725, Val Loss: 0.6943, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 47, Train Loss: 0.6731, Val Loss: 0.6943, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 48, Train Loss: 0.6737, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 49, Train Loss: 0.6720, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 50, Train Loss: 0.6725, Val Loss: 0.6944, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 51, Train Loss: 0.6736, Val Loss: 0.6945, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6818, Val Loss: 0.7692, F1 Micro: 0.5449, F1 Macro: 0.4529, Accuracy: 0.5449\n","Epoch 2, Train Loss: 0.6322, Val Loss: 0.6606, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 3, Train Loss: 0.6256, Val Loss: 0.7322, F1 Micro: 0.6236, F1 Macro: 0.5615, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6160, Val Loss: 0.6770, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6104, Val Loss: 0.6924, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6100, Val Loss: 0.7380, F1 Micro: 0.5843, F1 Macro: 0.4916, Accuracy: 0.5843\n","Epoch 7, Train Loss: 0.6071, Val Loss: 0.6379, F1 Micro: 0.6910, F1 Macro: 0.6848, Accuracy: 0.6910\n","Epoch 8, Train Loss: 0.6177, Val Loss: 0.6527, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.6102, Val Loss: 0.6824, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 10, Train Loss: 0.6131, Val Loss: 0.8486, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 11, Train Loss: 0.6152, Val Loss: 0.6393, F1 Micro: 0.6573, F1 Macro: 0.6568, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6024, Val Loss: 0.6734, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.5959, Val Loss: 0.6448, F1 Micro: 0.6966, F1 Macro: 0.6837, Accuracy: 0.6966\n","Epoch 14, Train Loss: 0.6021, Val Loss: 0.6775, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 15, Train Loss: 0.6012, Val Loss: 0.6518, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6052, Val Loss: 0.6743, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.5927, Val Loss: 0.6898, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 18, Train Loss: 0.6042, Val Loss: 0.6768, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.5902, Val Loss: 0.6415, F1 Micro: 0.7079, F1 Macro: 0.6968, Accuracy: 0.7079\n","Epoch 20, Train Loss: 0.6008, Val Loss: 0.6820, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 21, Train Loss: 0.5935, Val Loss: 0.6728, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 22, Train Loss: 0.5815, Val Loss: 0.6852, F1 Micro: 0.6966, F1 Macro: 0.6821, Accuracy: 0.6966\n","Epoch 23, Train Loss: 0.5918, Val Loss: 0.6770, F1 Micro: 0.7135, F1 Macro: 0.7057, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.5928, Val Loss: 0.7241, F1 Micro: 0.6348, F1 Macro: 0.5746, Accuracy: 0.6348\n","Epoch 25, Train Loss: 0.5923, Val Loss: 0.6683, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.5885, Val Loss: 0.6462, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 27, Train Loss: 0.5898, Val Loss: 0.6473, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 28, Train Loss: 0.5836, Val Loss: 0.6304, F1 Micro: 0.7022, F1 Macro: 0.6952, Accuracy: 0.7022\n","Epoch 29, Train Loss: 0.5865, Val Loss: 0.6635, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 30, Train Loss: 0.5898, Val Loss: 0.6331, F1 Micro: 0.6966, F1 Macro: 0.6900, Accuracy: 0.6966\n","Epoch 31, Train Loss: 0.5848, Val Loss: 0.6699, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 32, Train Loss: 0.5738, Val Loss: 0.6824, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.5835, Val Loss: 0.6616, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 34, Train Loss: 0.5835, Val Loss: 0.6688, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 35, Train Loss: 0.5811, Val Loss: 0.7250, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.5830, Val Loss: 0.6310, F1 Micro: 0.7022, F1 Macro: 0.6980, Accuracy: 0.7022\n","Epoch 37, Train Loss: 0.5843, Val Loss: 0.6618, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 38, Train Loss: 0.5908, Val Loss: 0.6603, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 39, Train Loss: 0.5764, Val Loss: 0.6452, F1 Micro: 0.7247, F1 Macro: 0.7208, Accuracy: 0.7247\n","Epoch 40, Train Loss: 0.5933, Val Loss: 0.6471, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 41, Train Loss: 0.5787, Val Loss: 0.6814, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 42, Train Loss: 0.5850, Val Loss: 0.7404, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 43, Train Loss: 0.5940, Val Loss: 0.6570, F1 Micro: 0.7135, F1 Macro: 0.7005, Accuracy: 0.7135\n","Epoch 44, Train Loss: 0.5855, Val Loss: 0.6365, F1 Micro: 0.6910, F1 Macro: 0.6826, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.5804, Val Loss: 0.6517, F1 Micro: 0.7247, F1 Macro: 0.7123, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.5801, Val Loss: 0.6887, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 47, Train Loss: 0.5858, Val Loss: 0.6796, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 48, Train Loss: 0.5804, Val Loss: 0.6389, F1 Micro: 0.6966, F1 Macro: 0.6919, Accuracy: 0.6966\n","Epoch 49, Train Loss: 0.5756, Val Loss: 0.6978, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 50, Train Loss: 0.5807, Val Loss: 0.6285, F1 Micro: 0.6798, F1 Macro: 0.6797, Accuracy: 0.6798\n","Epoch 51, Train Loss: 0.5922, Val Loss: 0.7032, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 52, Train Loss: 0.5960, Val Loss: 0.6362, F1 Micro: 0.6966, F1 Macro: 0.6919, Accuracy: 0.6966\n","Epoch 53, Train Loss: 0.5906, Val Loss: 0.6935, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.5876, Val Loss: 0.6691, F1 Micro: 0.7191, F1 Macro: 0.7097, Accuracy: 0.7191\n","Epoch 55, Train Loss: 0.6010, Val Loss: 0.6772, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 56, Train Loss: 0.5864, Val Loss: 0.7303, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 57, Train Loss: 0.5791, Val Loss: 0.6750, F1 Micro: 0.7191, F1 Macro: 0.7025, Accuracy: 0.7191\n","Epoch 58, Train Loss: 0.5776, Val Loss: 0.6965, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 59, Train Loss: 0.5843, Val Loss: 0.6508, F1 Micro: 0.7135, F1 Macro: 0.7057, Accuracy: 0.7135\n","Epoch 60, Train Loss: 0.5818, Val Loss: 0.6868, F1 Micro: 0.7191, F1 Macro: 0.7025, Accuracy: 0.7191\n","Epoch 61, Train Loss: 0.5809, Val Loss: 0.6504, F1 Micro: 0.7191, F1 Macro: 0.7120, Accuracy: 0.7191\n","Epoch 62, Train Loss: 0.5670, Val Loss: 0.6747, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 63, Train Loss: 0.5767, Val Loss: 0.6436, F1 Micro: 0.7079, F1 Macro: 0.7065, Accuracy: 0.7079\n","Epoch 64, Train Loss: 0.5787, Val Loss: 0.6604, F1 Micro: 0.6910, F1 Macro: 0.6800, Accuracy: 0.6910\n","Epoch 65, Train Loss: 0.5736, Val Loss: 0.6851, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 66, Train Loss: 0.5762, Val Loss: 0.6665, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 67, Train Loss: 0.5664, Val Loss: 0.6423, F1 Micro: 0.7303, F1 Macro: 0.7253, Accuracy: 0.7303\n","Epoch 68, Train Loss: 0.5919, Val Loss: 0.6567, F1 Micro: 0.7360, F1 Macro: 0.7253, Accuracy: 0.7360\n","Epoch 69, Train Loss: 0.5677, Val Loss: 0.7455, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 70, Train Loss: 0.5849, Val Loss: 0.7049, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 71, Train Loss: 0.5786, Val Loss: 0.6711, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 72, Train Loss: 0.5738, Val Loss: 0.6855, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 73, Train Loss: 0.5811, Val Loss: 0.7555, F1 Micro: 0.6461, F1 Macro: 0.5990, Accuracy: 0.6461\n","Epoch 74, Train Loss: 0.5739, Val Loss: 0.6987, F1 Micro: 0.7303, F1 Macro: 0.7175, Accuracy: 0.7303\n","Epoch 75, Train Loss: 0.5661, Val Loss: 0.6459, F1 Micro: 0.6854, F1 Macro: 0.6720, Accuracy: 0.6854\n","Epoch 76, Train Loss: 0.5656, Val Loss: 0.6957, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 77, Train Loss: 0.5728, Val Loss: 0.6398, F1 Micro: 0.7079, F1 Macro: 0.7077, Accuracy: 0.7079\n","Epoch 78, Train Loss: 0.5752, Val Loss: 0.6692, F1 Micro: 0.7022, F1 Macro: 0.6856, Accuracy: 0.7022\n","Epoch 79, Train Loss: 0.5683, Val Loss: 0.7413, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 80, Train Loss: 0.5793, Val Loss: 0.6816, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 81, Train Loss: 0.5787, Val Loss: 0.6918, F1 Micro: 0.7303, F1 Macro: 0.7160, Accuracy: 0.7303\n","Epoch 82, Train Loss: 0.5754, Val Loss: 0.6574, F1 Micro: 0.7247, F1 Macro: 0.7192, Accuracy: 0.7247\n","Epoch 83, Train Loss: 0.5768, Val Loss: 0.6498, F1 Micro: 0.7303, F1 Macro: 0.7269, Accuracy: 0.7303\n","Epoch 84, Train Loss: 0.5767, Val Loss: 0.6429, F1 Micro: 0.7079, F1 Macro: 0.7015, Accuracy: 0.7079\n","Epoch 85, Train Loss: 0.5749, Val Loss: 0.6519, F1 Micro: 0.7360, F1 Macro: 0.7277, Accuracy: 0.7360\n","Epoch 86, Train Loss: 0.5616, Val Loss: 0.7072, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 87, Train Loss: 0.5701, Val Loss: 0.7158, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 88, Train Loss: 0.5762, Val Loss: 0.6727, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 89, Train Loss: 0.5682, Val Loss: 0.6548, F1 Micro: 0.7135, F1 Macro: 0.7020, Accuracy: 0.7135\n","Epoch 90, Train Loss: 0.5748, Val Loss: 0.6566, F1 Micro: 0.7022, F1 Macro: 0.6903, Accuracy: 0.7022\n","Epoch 91, Train Loss: 0.5696, Val Loss: 0.6591, F1 Micro: 0.7135, F1 Macro: 0.7108, Accuracy: 0.7135\n","Epoch 92, Train Loss: 0.5705, Val Loss: 0.6693, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 93, Train Loss: 0.5730, Val Loss: 0.7241, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 94, Train Loss: 0.5740, Val Loss: 0.6608, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 95, Train Loss: 0.5694, Val Loss: 0.6673, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 96, Train Loss: 0.5686, Val Loss: 0.7302, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 97, Train Loss: 0.5746, Val Loss: 0.6992, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 98, Train Loss: 0.5794, Val Loss: 0.6664, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 99, Train Loss: 0.5721, Val Loss: 0.6390, F1 Micro: 0.6798, F1 Macro: 0.6790, Accuracy: 0.6798\n","Epoch 100, Train Loss: 0.5747, Val Loss: 0.6575, F1 Micro: 0.7079, F1 Macro: 0.7025, Accuracy: 0.7079\n","Epoch 101, Train Loss: 0.5752, Val Loss: 0.6682, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 102, Train Loss: 0.5625, Val Loss: 0.6286, F1 Micro: 0.6742, F1 Macro: 0.6738, Accuracy: 0.6742\n","Epoch 103, Train Loss: 0.5695, Val Loss: 0.6444, F1 Micro: 0.6798, F1 Macro: 0.6698, Accuracy: 0.6798\n","Epoch 104, Train Loss: 0.5710, Val Loss: 0.6841, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 105, Train Loss: 0.5787, Val Loss: 0.6648, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 106, Train Loss: 0.5723, Val Loss: 0.6513, F1 Micro: 0.7472, F1 Macro: 0.7382, Accuracy: 0.7472\n","Epoch 107, Train Loss: 0.5807, Val Loss: 0.6362, F1 Micro: 0.6966, F1 Macro: 0.6928, Accuracy: 0.6966\n","Epoch 108, Train Loss: 0.5712, Val Loss: 0.7640, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 109, Train Loss: 0.5699, Val Loss: 0.6421, F1 Micro: 0.7022, F1 Macro: 0.6995, Accuracy: 0.7022\n","Epoch 110, Train Loss: 0.5664, Val Loss: 0.6892, F1 Micro: 0.7416, F1 Macro: 0.7329, Accuracy: 0.7416\n","Epoch 111, Train Loss: 0.5733, Val Loss: 0.6384, F1 Micro: 0.7022, F1 Macro: 0.6929, Accuracy: 0.7022\n","Epoch 112, Train Loss: 0.5712, Val Loss: 0.6399, F1 Micro: 0.7135, F1 Macro: 0.7077, Accuracy: 0.7135\n","Epoch 113, Train Loss: 0.5670, Val Loss: 0.6915, F1 Micro: 0.7191, F1 Macro: 0.7042, Accuracy: 0.7191\n","Epoch 114, Train Loss: 0.5631, Val Loss: 0.6335, F1 Micro: 0.7079, F1 Macro: 0.7033, Accuracy: 0.7079\n","Epoch 115, Train Loss: 0.5720, Val Loss: 0.6790, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 116, Train Loss: 0.5770, Val Loss: 0.6424, F1 Micro: 0.7247, F1 Macro: 0.7192, Accuracy: 0.7247\n","Epoch 117, Train Loss: 0.5717, Val Loss: 0.6445, F1 Micro: 0.7247, F1 Macro: 0.7200, Accuracy: 0.7247\n","Epoch 118, Train Loss: 0.5771, Val Loss: 0.6479, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 119, Train Loss: 0.5694, Val Loss: 0.6606, F1 Micro: 0.7360, F1 Macro: 0.7277, Accuracy: 0.7360\n","Epoch 120, Train Loss: 0.5693, Val Loss: 0.7204, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 121, Train Loss: 0.5680, Val Loss: 0.6514, F1 Micro: 0.7247, F1 Macro: 0.7172, Accuracy: 0.7247\n","Epoch 122, Train Loss: 0.5686, Val Loss: 0.6772, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 123, Train Loss: 0.5683, Val Loss: 0.7280, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 124, Train Loss: 0.5643, Val Loss: 0.6421, F1 Micro: 0.7022, F1 Macro: 0.6903, Accuracy: 0.7022\n","Epoch 125, Train Loss: 0.5664, Val Loss: 0.6504, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 126, Train Loss: 0.5674, Val Loss: 0.6758, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 127, Train Loss: 0.5677, Val Loss: 0.6867, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 128, Train Loss: 0.5662, Val Loss: 0.6767, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 129, Train Loss: 0.5639, Val Loss: 0.6564, F1 Micro: 0.7135, F1 Macro: 0.7045, Accuracy: 0.7135\n","Epoch 130, Train Loss: 0.5680, Val Loss: 0.6462, F1 Micro: 0.7079, F1 Macro: 0.7033, Accuracy: 0.7079\n","Epoch 131, Train Loss: 0.5770, Val Loss: 0.6616, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 132, Train Loss: 0.5680, Val Loss: 0.6472, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 133, Train Loss: 0.5696, Val Loss: 0.6984, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 134, Train Loss: 0.5777, Val Loss: 0.7051, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 135, Train Loss: 0.5535, Val Loss: 0.6820, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 136, Train Loss: 0.5715, Val Loss: 0.6304, F1 Micro: 0.7022, F1 Macro: 0.7011, Accuracy: 0.7022\n","Epoch 137, Train Loss: 0.5651, Val Loss: 0.6732, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 138, Train Loss: 0.5714, Val Loss: 0.6845, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 139, Train Loss: 0.5718, Val Loss: 0.6534, F1 Micro: 0.7135, F1 Macro: 0.6974, Accuracy: 0.7135\n","Epoch 140, Train Loss: 0.5606, Val Loss: 0.6648, F1 Micro: 0.7022, F1 Macro: 0.6872, Accuracy: 0.7022\n","Epoch 141, Train Loss: 0.5654, Val Loss: 0.6850, F1 Micro: 0.7191, F1 Macro: 0.7042, Accuracy: 0.7191\n","Epoch 142, Train Loss: 0.5645, Val Loss: 0.7234, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 143, Train Loss: 0.5709, Val Loss: 0.6437, F1 Micro: 0.7247, F1 Macro: 0.7192, Accuracy: 0.7247\n","Epoch 144, Train Loss: 0.5667, Val Loss: 0.6926, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 145, Train Loss: 0.5728, Val Loss: 0.6664, F1 Micro: 0.7303, F1 Macro: 0.7160, Accuracy: 0.7303\n","Epoch 146, Train Loss: 0.5659, Val Loss: 0.6682, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 147, Train Loss: 0.5621, Val Loss: 0.6508, F1 Micro: 0.7247, F1 Macro: 0.7172, Accuracy: 0.7247\n","Epoch 148, Train Loss: 0.5661, Val Loss: 0.6389, F1 Micro: 0.7135, F1 Macro: 0.7102, Accuracy: 0.7135\n","Epoch 149, Train Loss: 0.5692, Val Loss: 0.6824, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 150, Train Loss: 0.5682, Val Loss: 0.6758, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 151, Train Loss: 0.5584, Val Loss: 0.7032, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 152, Train Loss: 0.5637, Val Loss: 0.8209, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 153, Train Loss: 0.5629, Val Loss: 0.6828, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 154, Train Loss: 0.5658, Val Loss: 0.6636, F1 Micro: 0.7191, F1 Macro: 0.7097, Accuracy: 0.7191\n","Epoch 155, Train Loss: 0.5647, Val Loss: 0.6500, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 156, Train Loss: 0.5716, Val Loss: 0.6624, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6871, Val Loss: 0.6349, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.6513, Val Loss: 0.6417, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 3, Train Loss: 0.6544, Val Loss: 0.6603, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6391, Val Loss: 0.6170, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 5, Train Loss: 0.6384, Val Loss: 0.6136, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6292, Val Loss: 0.6323, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.6363, Val Loss: 0.6600, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6498, Val Loss: 0.6283, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 9, Train Loss: 0.6426, Val Loss: 0.6146, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 10, Train Loss: 0.6411, Val Loss: 0.6386, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.6334, Val Loss: 0.6095, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 12, Train Loss: 0.6292, Val Loss: 0.6098, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 13, Train Loss: 0.6337, Val Loss: 0.6234, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6257, Val Loss: 0.5962, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 15, Train Loss: 0.6265, Val Loss: 0.6273, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6253, Val Loss: 0.5926, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 17, Train Loss: 0.6259, Val Loss: 0.6309, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6274, Val Loss: 0.5920, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.6238, Val Loss: 0.5998, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 20, Train Loss: 0.6246, Val Loss: 0.5946, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6182, Val Loss: 0.6120, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 22, Train Loss: 0.6231, Val Loss: 0.6230, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6247, Val Loss: 0.6246, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6267, Val Loss: 0.6143, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6169, Val Loss: 0.5827, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 26, Train Loss: 0.6333, Val Loss: 0.6225, F1 Micro: 0.6461, F1 Macro: 0.5051, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.6242, Val Loss: 0.5893, F1 Micro: 0.6798, F1 Macro: 0.6305, Accuracy: 0.6798\n","Epoch 28, Train Loss: 0.6235, Val Loss: 0.6213, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6117, Val Loss: 0.5795, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 30, Train Loss: 0.6188, Val Loss: 0.5785, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 31, Train Loss: 0.6140, Val Loss: 0.5914, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 32, Train Loss: 0.6107, Val Loss: 0.5851, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 33, Train Loss: 0.6230, Val Loss: 0.5938, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 34, Train Loss: 0.6157, Val Loss: 0.5916, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 35, Train Loss: 0.6250, Val Loss: 0.5942, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 36, Train Loss: 0.6233, Val Loss: 0.6106, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.6196, Val Loss: 0.5957, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 38, Train Loss: 0.6177, Val Loss: 0.5807, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 39, Train Loss: 0.6180, Val Loss: 0.6013, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.6126, Val Loss: 0.5749, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 41, Train Loss: 0.6141, Val Loss: 0.6399, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 42, Train Loss: 0.6211, Val Loss: 0.6022, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 43, Train Loss: 0.6167, Val Loss: 0.5878, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 44, Train Loss: 0.6177, Val Loss: 0.5745, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 45, Train Loss: 0.6166, Val Loss: 0.5819, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.6073, Val Loss: 0.6559, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 47, Train Loss: 0.6209, Val Loss: 0.6279, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 48, Train Loss: 0.6158, Val Loss: 0.5772, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.6073, Val Loss: 0.5750, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 50, Train Loss: 0.6138, Val Loss: 0.5968, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.6075, Val Loss: 0.5720, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 52, Train Loss: 0.6067, Val Loss: 0.5772, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 53, Train Loss: 0.6145, Val Loss: 0.5870, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6105, Val Loss: 0.5814, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 55, Train Loss: 0.6124, Val Loss: 0.5776, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 56, Train Loss: 0.6265, Val Loss: 0.6197, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 57, Train Loss: 0.6194, Val Loss: 0.6132, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 58, Train Loss: 0.6160, Val Loss: 0.5806, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 59, Train Loss: 0.6052, Val Loss: 0.5820, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 60, Train Loss: 0.6139, Val Loss: 0.5982, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 61, Train Loss: 0.6174, Val Loss: 0.5747, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 62, Train Loss: 0.6155, Val Loss: 0.6009, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 63, Train Loss: 0.6122, Val Loss: 0.6005, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 64, Train Loss: 0.6145, Val Loss: 0.5672, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 65, Train Loss: 0.6113, Val Loss: 0.6078, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 66, Train Loss: 0.6134, Val Loss: 0.6233, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 67, Train Loss: 0.6095, Val Loss: 0.5856, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 68, Train Loss: 0.6079, Val Loss: 0.6490, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 69, Train Loss: 0.6182, Val Loss: 0.5848, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 70, Train Loss: 0.6047, Val Loss: 0.6061, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 71, Train Loss: 0.6046, Val Loss: 0.5661, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 72, Train Loss: 0.6131, Val Loss: 0.5720, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 73, Train Loss: 0.6045, Val Loss: 0.5797, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 74, Train Loss: 0.6064, Val Loss: 0.5641, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.6910112359550562\n","Best hyperparameters for Outer FOLD 2: (0.001, 8, 50) with score 0.7000000000000001\n","Epoch 1, Train Loss: 0.6802, Val Loss: 0.6668, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 2, Train Loss: 0.6575, Val Loss: 0.6556, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 3, Train Loss: 0.6647, Val Loss: 0.6697, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 4, Train Loss: 0.6447, Val Loss: 0.6517, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 5, Train Loss: 0.6465, Val Loss: 0.6501, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 6, Train Loss: 0.6470, Val Loss: 0.6458, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 7, Train Loss: 0.6416, Val Loss: 0.6468, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 8, Train Loss: 0.6437, Val Loss: 0.6659, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 9, Train Loss: 0.6480, Val Loss: 0.6451, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 10, Train Loss: 0.6337, Val Loss: 0.6412, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 11, Train Loss: 0.6272, Val Loss: 0.6677, F1 Micro: 0.5874, F1 Macro: 0.3701, Accuracy: 0.5874\n","Epoch 12, Train Loss: 0.6336, Val Loss: 0.6437, F1 Micro: 0.6457, F1 Macro: 0.6314, Accuracy: 0.6457\n","Epoch 13, Train Loss: 0.6369, Val Loss: 0.6378, F1 Micro: 0.7085, F1 Macro: 0.6918, Accuracy: 0.7085\n","Epoch 14, Train Loss: 0.6344, Val Loss: 0.6671, F1 Micro: 0.6188, F1 Macro: 0.5180, Accuracy: 0.6188\n","Epoch 15, Train Loss: 0.6416, Val Loss: 0.6352, F1 Micro: 0.6637, F1 Macro: 0.6140, Accuracy: 0.6637\n","Epoch 16, Train Loss: 0.6279, Val Loss: 0.6362, F1 Micro: 0.6726, F1 Macro: 0.6433, Accuracy: 0.6726\n","Epoch 17, Train Loss: 0.6207, Val Loss: 0.6499, F1 Micro: 0.6726, F1 Macro: 0.6369, Accuracy: 0.6726\n","Epoch 18, Train Loss: 0.6286, Val Loss: 0.6305, F1 Micro: 0.6726, F1 Macro: 0.6506, Accuracy: 0.6726\n","Epoch 19, Train Loss: 0.6219, Val Loss: 0.6365, F1 Micro: 0.6637, F1 Macro: 0.6536, Accuracy: 0.6637\n","Epoch 20, Train Loss: 0.6214, Val Loss: 0.6330, F1 Micro: 0.6726, F1 Macro: 0.6506, Accuracy: 0.6726\n","Epoch 21, Train Loss: 0.6196, Val Loss: 0.6358, F1 Micro: 0.6502, F1 Macro: 0.6199, Accuracy: 0.6502\n","Epoch 22, Train Loss: 0.6164, Val Loss: 0.6430, F1 Micro: 0.6413, F1 Macro: 0.6396, Accuracy: 0.6413\n","Epoch 23, Train Loss: 0.6122, Val Loss: 0.6339, F1 Micro: 0.6592, F1 Macro: 0.6447, Accuracy: 0.6592\n","Epoch 24, Train Loss: 0.6096, Val Loss: 0.6306, F1 Micro: 0.6771, F1 Macro: 0.6690, Accuracy: 0.6771\n","Epoch 25, Train Loss: 0.6176, Val Loss: 0.6412, F1 Micro: 0.6771, F1 Macro: 0.6593, Accuracy: 0.6771\n","Epoch 26, Train Loss: 0.6146, Val Loss: 0.6339, F1 Micro: 0.6592, F1 Macro: 0.6447, Accuracy: 0.6592\n","Epoch 27, Train Loss: 0.6072, Val Loss: 0.6508, F1 Micro: 0.6547, F1 Macro: 0.6145, Accuracy: 0.6547\n","Epoch 28, Train Loss: 0.6152, Val Loss: 0.6358, F1 Micro: 0.6816, F1 Macro: 0.6661, Accuracy: 0.6816\n","Epoch 29, Train Loss: 0.6077, Val Loss: 0.6302, F1 Micro: 0.6637, F1 Macro: 0.6513, Accuracy: 0.6637\n","Epoch 30, Train Loss: 0.6118, Val Loss: 0.6558, F1 Micro: 0.6637, F1 Macro: 0.6221, Accuracy: 0.6637\n","Epoch 31, Train Loss: 0.6085, Val Loss: 0.6405, F1 Micro: 0.6547, F1 Macro: 0.6297, Accuracy: 0.6547\n","Epoch 32, Train Loss: 0.6084, Val Loss: 0.6347, F1 Micro: 0.6726, F1 Macro: 0.6506, Accuracy: 0.6726\n","Epoch 33, Train Loss: 0.6100, Val Loss: 0.6313, F1 Micro: 0.6368, F1 Macro: 0.6234, Accuracy: 0.6368\n","Epoch 34, Train Loss: 0.6081, Val Loss: 0.6329, F1 Micro: 0.6682, F1 Macro: 0.6527, Accuracy: 0.6682\n","Epoch 35, Train Loss: 0.6055, Val Loss: 0.6422, F1 Micro: 0.6726, F1 Macro: 0.6471, Accuracy: 0.6726\n","Epoch 36, Train Loss: 0.6081, Val Loss: 0.6329, F1 Micro: 0.6682, F1 Macro: 0.6527, Accuracy: 0.6682\n","Epoch 37, Train Loss: 0.6082, Val Loss: 0.6264, F1 Micro: 0.6457, F1 Macro: 0.6300, Accuracy: 0.6457\n","Epoch 38, Train Loss: 0.5953, Val Loss: 0.6327, F1 Micro: 0.6413, F1 Macro: 0.6246, Accuracy: 0.6413\n","Epoch 39, Train Loss: 0.6060, Val Loss: 0.6329, F1 Micro: 0.6502, F1 Macro: 0.6354, Accuracy: 0.6502\n","Epoch 40, Train Loss: 0.6001, Val Loss: 0.6471, F1 Micro: 0.6547, F1 Macro: 0.5875, Accuracy: 0.6547\n","Epoch 41, Train Loss: 0.6069, Val Loss: 0.6340, F1 Micro: 0.6368, F1 Macro: 0.6247, Accuracy: 0.6368\n","Epoch 42, Train Loss: 0.5966, Val Loss: 0.6286, F1 Micro: 0.6368, F1 Macro: 0.6271, Accuracy: 0.6368\n","Epoch 43, Train Loss: 0.6157, Val Loss: 0.6454, F1 Micro: 0.6771, F1 Macro: 0.6528, Accuracy: 0.6771\n","Epoch 44, Train Loss: 0.6018, Val Loss: 0.6576, F1 Micro: 0.6188, F1 Macro: 0.5772, Accuracy: 0.6188\n","Epoch 45, Train Loss: 0.6024, Val Loss: 0.6289, F1 Micro: 0.6457, F1 Macro: 0.6327, Accuracy: 0.6457\n","Epoch 46, Train Loss: 0.5977, Val Loss: 0.6412, F1 Micro: 0.6726, F1 Macro: 0.6538, Accuracy: 0.6726\n","Epoch 47, Train Loss: 0.6043, Val Loss: 0.6361, F1 Micro: 0.6726, F1 Macro: 0.6506, Accuracy: 0.6726\n","Epoch 48, Train Loss: 0.5947, Val Loss: 0.6451, F1 Micro: 0.6726, F1 Macro: 0.6523, Accuracy: 0.6726\n","Epoch 49, Train Loss: 0.6062, Val Loss: 0.6432, F1 Micro: 0.6726, F1 Macro: 0.6523, Accuracy: 0.6726\n","Epoch 50, Train Loss: 0.5978, Val Loss: 0.6339, F1 Micro: 0.6502, F1 Macro: 0.6340, Accuracy: 0.6502\n","Epoch 51, Train Loss: 0.5917, Val Loss: 0.6446, F1 Micro: 0.6637, F1 Macro: 0.6501, Accuracy: 0.6637\n","Epoch 52, Train Loss: 0.5948, Val Loss: 0.6343, F1 Micro: 0.6637, F1 Macro: 0.6443, Accuracy: 0.6637\n","Epoch 53, Train Loss: 0.6030, Val Loss: 0.6306, F1 Micro: 0.6502, F1 Macro: 0.6325, Accuracy: 0.6502\n","Epoch 54, Train Loss: 0.5990, Val Loss: 0.6325, F1 Micro: 0.6592, F1 Macro: 0.6388, Accuracy: 0.6592\n","Epoch 55, Train Loss: 0.5906, Val Loss: 0.6391, F1 Micro: 0.6592, F1 Macro: 0.6434, Accuracy: 0.6592\n","Epoch 56, Train Loss: 0.5919, Val Loss: 0.6417, F1 Micro: 0.6547, F1 Macro: 0.6349, Accuracy: 0.6547\n","Epoch 57, Train Loss: 0.5962, Val Loss: 0.6384, F1 Micro: 0.6457, F1 Macro: 0.6351, Accuracy: 0.6457\n","Epoch 58, Train Loss: 0.5936, Val Loss: 0.6316, F1 Micro: 0.6502, F1 Macro: 0.6403, Accuracy: 0.6502\n","Epoch 59, Train Loss: 0.5884, Val Loss: 0.6390, F1 Micro: 0.6547, F1 Macro: 0.6444, Accuracy: 0.6547\n","Epoch 60, Train Loss: 0.5861, Val Loss: 0.6448, F1 Micro: 0.6457, F1 Macro: 0.6285, Accuracy: 0.6457\n","Epoch 61, Train Loss: 0.5997, Val Loss: 0.6306, F1 Micro: 0.6413, F1 Macro: 0.6322, Accuracy: 0.6413\n","Epoch 62, Train Loss: 0.6006, Val Loss: 0.6347, F1 Micro: 0.6368, F1 Macro: 0.6271, Accuracy: 0.6368\n","Epoch 63, Train Loss: 0.5988, Val Loss: 0.6283, F1 Micro: 0.6547, F1 Macro: 0.6444, Accuracy: 0.6547\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6547, F1 Macro: 0.6444, Accuracy: 0.6547\n","Outer FOLD 3\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6996, Val Loss: 0.6674, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6746, Val Loss: 0.6648, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 3, Train Loss: 0.6748, Val Loss: 0.6646, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 4, Train Loss: 0.6756, Val Loss: 0.6643, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6759, Val Loss: 0.6669, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6752, Val Loss: 0.6678, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.6759, Val Loss: 0.6658, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.6754, Val Loss: 0.6651, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 9, Train Loss: 0.6755, Val Loss: 0.6656, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 10, Train Loss: 0.6753, Val Loss: 0.6685, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6747, Val Loss: 0.6647, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6972, Val Loss: 0.6651, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6777, Val Loss: 0.6664, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6780, Val Loss: 0.6653, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6748, Val Loss: 0.6660, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6775, Val Loss: 0.6654, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6780, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6735, Val Loss: 0.6651, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6740, Val Loss: 0.6651, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6783, Val Loss: 0.6661, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6781, Val Loss: 0.6662, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6748, Val Loss: 0.6658, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6910, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6719, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6724, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6727, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6724, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6760, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6726, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6766, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6724, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6727, Val Loss: 0.6723, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6780, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6875, Val Loss: 0.7131, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6653, Val Loss: 0.7179, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6608, Val Loss: 0.7275, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6601, Val Loss: 0.7257, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6604, Val Loss: 0.7228, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6608, Val Loss: 0.7239, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6603, Val Loss: 0.7261, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6604, Val Loss: 0.7291, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6618, Val Loss: 0.7290, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6665, Val Loss: 0.7321, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6603, Val Loss: 0.7319, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6837, Val Loss: 0.6799, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6756, Val Loss: 0.6806, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6751, Val Loss: 0.6814, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6741, Val Loss: 0.6819, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6704, Val Loss: 0.6818, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6705, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6737, Val Loss: 0.6806, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6700, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6745, Val Loss: 0.6818, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6704, Val Loss: 0.6829, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6696, Val Loss: 0.6815, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.6049023915636181\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7740, Val Loss: 0.6361, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 2, Train Loss: 0.6531, Val Loss: 0.6134, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 3, Train Loss: 0.6592, Val Loss: 0.5969, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 4, Train Loss: 0.6536, Val Loss: 0.6054, F1 Micro: 0.7263, F1 Macro: 0.6988, Accuracy: 0.7263\n","Epoch 5, Train Loss: 0.6528, Val Loss: 0.6021, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 6, Train Loss: 0.6508, Val Loss: 0.6073, F1 Micro: 0.7374, F1 Macro: 0.6989, Accuracy: 0.7374\n","Epoch 7, Train Loss: 0.6446, Val Loss: 0.6206, F1 Micro: 0.6592, F1 Macro: 0.5133, Accuracy: 0.6592\n","Epoch 8, Train Loss: 0.6570, Val Loss: 0.5972, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 9, Train Loss: 0.6398, Val Loss: 0.6424, F1 Micro: 0.6257, F1 Macro: 0.6227, Accuracy: 0.6257\n","Epoch 10, Train Loss: 0.6519, Val Loss: 0.6601, F1 Micro: 0.5978, F1 Macro: 0.5978, Accuracy: 0.5978\n","Epoch 11, Train Loss: 0.6424, Val Loss: 0.6039, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 12, Train Loss: 0.6427, Val Loss: 0.5863, F1 Micro: 0.6816, F1 Macro: 0.6382, Accuracy: 0.6816\n","Epoch 13, Train Loss: 0.6562, Val Loss: 0.7254, F1 Micro: 0.3631, F1 Macro: 0.2664, Accuracy: 0.3631\n","Epoch 14, Train Loss: 0.6588, Val Loss: 0.5994, F1 Micro: 0.7263, F1 Macro: 0.6861, Accuracy: 0.7263\n","Epoch 15, Train Loss: 0.6349, Val Loss: 0.6094, F1 Micro: 0.6872, F1 Macro: 0.6640, Accuracy: 0.6872\n","Epoch 16, Train Loss: 0.6274, Val Loss: 0.5964, F1 Micro: 0.6760, F1 Macro: 0.6334, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.6477, Val Loss: 0.5909, F1 Micro: 0.6983, F1 Macro: 0.6557, Accuracy: 0.6983\n","Epoch 18, Train Loss: 0.6379, Val Loss: 0.5956, F1 Micro: 0.6872, F1 Macro: 0.6326, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6464, Val Loss: 0.6042, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 20, Train Loss: 0.6306, Val Loss: 0.6170, F1 Micro: 0.6480, F1 Macro: 0.6295, Accuracy: 0.6480\n","Epoch 21, Train Loss: 0.6285, Val Loss: 0.5989, F1 Micro: 0.6536, F1 Macro: 0.6303, Accuracy: 0.6536\n","Epoch 22, Train Loss: 0.6272, Val Loss: 0.6062, F1 Micro: 0.6480, F1 Macro: 0.6183, Accuracy: 0.6480\n","Epoch 23, Train Loss: 0.6314, Val Loss: 0.6103, F1 Micro: 0.6536, F1 Macro: 0.6256, Accuracy: 0.6536\n","Epoch 24, Train Loss: 0.6259, Val Loss: 0.6111, F1 Micro: 0.6592, F1 Macro: 0.6222, Accuracy: 0.6592\n","Epoch 25, Train Loss: 0.6366, Val Loss: 0.5989, F1 Micro: 0.6760, F1 Macro: 0.6302, Accuracy: 0.6760\n","Epoch 26, Train Loss: 0.6278, Val Loss: 0.6028, F1 Micro: 0.6760, F1 Macro: 0.6365, Accuracy: 0.6760\n","Epoch 27, Train Loss: 0.6226, Val Loss: 0.6059, F1 Micro: 0.6425, F1 Macro: 0.6227, Accuracy: 0.6425\n","Epoch 28, Train Loss: 0.6219, Val Loss: 0.5987, F1 Micro: 0.6536, F1 Macro: 0.6145, Accuracy: 0.6536\n","Epoch 29, Train Loss: 0.6206, Val Loss: 0.6025, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 30, Train Loss: 0.6256, Val Loss: 0.6041, F1 Micro: 0.6760, F1 Macro: 0.6448, Accuracy: 0.6760\n","Epoch 31, Train Loss: 0.6253, Val Loss: 0.6584, F1 Micro: 0.5866, F1 Macro: 0.5860, Accuracy: 0.5866\n","Epoch 32, Train Loss: 0.6281, Val Loss: 0.6171, F1 Micro: 0.6536, F1 Macro: 0.6364, Accuracy: 0.6536\n","Epoch 33, Train Loss: 0.6042, Val Loss: 0.6087, F1 Micro: 0.6927, F1 Macro: 0.6508, Accuracy: 0.6927\n","Epoch 34, Train Loss: 0.6239, Val Loss: 0.6210, F1 Micro: 0.6592, F1 Macro: 0.6480, Accuracy: 0.6592\n","Epoch 35, Train Loss: 0.6280, Val Loss: 0.6081, F1 Micro: 0.6816, F1 Macro: 0.6546, Accuracy: 0.6816\n","Epoch 36, Train Loss: 0.6349, Val Loss: 0.6106, F1 Micro: 0.6536, F1 Macro: 0.6303, Accuracy: 0.6536\n","Epoch 37, Train Loss: 0.6114, Val Loss: 0.6133, F1 Micro: 0.6592, F1 Macro: 0.6351, Accuracy: 0.6592\n","Epoch 38, Train Loss: 0.6095, Val Loss: 0.6412, F1 Micro: 0.6089, F1 Macro: 0.6089, Accuracy: 0.6089\n","Epoch 39, Train Loss: 0.6190, Val Loss: 0.6166, F1 Micro: 0.6425, F1 Macro: 0.6314, Accuracy: 0.6425\n","Epoch 40, Train Loss: 0.6264, Val Loss: 0.5973, F1 Micro: 0.6872, F1 Macro: 0.6460, Accuracy: 0.6872\n","Epoch 41, Train Loss: 0.6338, Val Loss: 0.6397, F1 Micro: 0.6425, F1 Macro: 0.6299, Accuracy: 0.6425\n","Epoch 42, Train Loss: 0.6232, Val Loss: 0.6083, F1 Micro: 0.6760, F1 Macro: 0.6474, Accuracy: 0.6760\n","Epoch 43, Train Loss: 0.6157, Val Loss: 0.6133, F1 Micro: 0.6592, F1 Macro: 0.6413, Accuracy: 0.6592\n","Epoch 44, Train Loss: 0.6121, Val Loss: 0.6252, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 45, Train Loss: 0.6225, Val Loss: 0.6079, F1 Micro: 0.6648, F1 Macro: 0.6400, Accuracy: 0.6648\n","Epoch 46, Train Loss: 0.6100, Val Loss: 0.6351, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 47, Train Loss: 0.6197, Val Loss: 0.6135, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 48, Train Loss: 0.6172, Val Loss: 0.6083, F1 Micro: 0.6592, F1 Macro: 0.6431, Accuracy: 0.6592\n","Epoch 49, Train Loss: 0.6302, Val Loss: 0.6153, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 50, Train Loss: 0.6102, Val Loss: 0.6033, F1 Micro: 0.6648, F1 Macro: 0.6377, Accuracy: 0.6648\n","Epoch 51, Train Loss: 0.6121, Val Loss: 0.6134, F1 Micro: 0.6313, F1 Macro: 0.6227, Accuracy: 0.6313\n","Epoch 52, Train Loss: 0.6252, Val Loss: 0.6177, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 53, Train Loss: 0.6142, Val Loss: 0.6185, F1 Micro: 0.6425, F1 Macro: 0.6265, Accuracy: 0.6425\n","Epoch 54, Train Loss: 0.6150, Val Loss: 0.6070, F1 Micro: 0.6648, F1 Macro: 0.6443, Accuracy: 0.6648\n","Epoch 55, Train Loss: 0.6127, Val Loss: 0.6113, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 56, Train Loss: 0.6092, Val Loss: 0.6301, F1 Micro: 0.6872, F1 Macro: 0.6460, Accuracy: 0.6872\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7110, Val Loss: 0.6673, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6777, Val Loss: 0.6653, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6776, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6782, Val Loss: 0.6649, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6775, Val Loss: 0.6669, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6750, Val Loss: 0.6661, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6738, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6787, Val Loss: 0.6647, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6744, Val Loss: 0.6678, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6786, Val Loss: 0.6660, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6778, Val Loss: 0.6657, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6751, Val Loss: 0.6644, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6777, Val Loss: 0.6676, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6782, Val Loss: 0.6668, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6746, Val Loss: 0.6660, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6779, Val Loss: 0.6664, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.6787, Val Loss: 0.6644, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6740, Val Loss: 0.6656, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6736, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.6747, Val Loss: 0.6646, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6740, Val Loss: 0.6646, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6784, Val Loss: 0.6653, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6747, Val Loss: 0.6672, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6734, Val Loss: 0.6648, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6792, Val Loss: 0.6660, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6743, Val Loss: 0.6656, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6776, Val Loss: 0.6660, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 28, Train Loss: 0.6739, Val Loss: 0.6645, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6742, Val Loss: 0.6648, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6739, Val Loss: 0.6644, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6774, Val Loss: 0.6657, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6738, Val Loss: 0.6658, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.6740, Val Loss: 0.6649, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.6738, Val Loss: 0.6651, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6739, Val Loss: 0.6644, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6778, Val Loss: 0.6654, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.6741, Val Loss: 0.6647, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6746, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6736, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6779, Val Loss: 0.6652, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6752, Val Loss: 0.6658, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6746, Val Loss: 0.6662, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.6747, Val Loss: 0.6659, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6784, Val Loss: 0.6651, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.6781, Val Loss: 0.6645, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.6746, Val Loss: 0.6648, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6746, Val Loss: 0.6674, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6740, Val Loss: 0.6656, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.6742, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.6736, Val Loss: 0.6643, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6745, Val Loss: 0.6648, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6911, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6723, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6724, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6721, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6758, Val Loss: 0.6722, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6763, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6738, Val Loss: 0.6724, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6725, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6716, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6728, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6724, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6768, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6726, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6769, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6767, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6728, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6725, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6766, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6723, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6730, Val Loss: 0.6720, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6722, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6775, Val Loss: 0.6720, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6728, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6765, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6724, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6716, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6771, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6722, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6774, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6718, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6723, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6726, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6719, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6728, Val Loss: 0.6724, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6758, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6717, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6755, Val Loss: 0.6722, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6759, Val Loss: 0.6726, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6740, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6721, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6720, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6729, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6722, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6750, Val Loss: 0.6720, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6765, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6728, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6767, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6723, Val Loss: 0.6726, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6722, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6760, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6722, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6952, Val Loss: 0.7181, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6605, Val Loss: 0.7230, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6659, Val Loss: 0.7291, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6610, Val Loss: 0.7309, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6662, Val Loss: 0.7246, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6604, Val Loss: 0.7172, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6652, Val Loss: 0.7286, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6617, Val Loss: 0.7115, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6614, Val Loss: 0.7182, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6602, Val Loss: 0.7244, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6612, Val Loss: 0.7190, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6657, Val Loss: 0.7197, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6655, Val Loss: 0.7274, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6604, Val Loss: 0.7218, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6604, Val Loss: 0.7194, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6609, Val Loss: 0.7188, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6653, Val Loss: 0.7240, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6607, Val Loss: 0.7228, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6607, Val Loss: 0.7219, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6603, Val Loss: 0.7227, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6655, Val Loss: 0.7195, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6621, Val Loss: 0.7144, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6596, Val Loss: 0.7298, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6606, Val Loss: 0.7236, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6611, Val Loss: 0.7154, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6653, Val Loss: 0.7285, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6651, Val Loss: 0.7177, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6607, Val Loss: 0.7252, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6604, Val Loss: 0.7219, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6611, Val Loss: 0.7201, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6651, Val Loss: 0.7228, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6665, Val Loss: 0.7286, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6603, Val Loss: 0.7270, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6654, Val Loss: 0.7260, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6600, Val Loss: 0.7256, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6666, Val Loss: 0.7307, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6605, Val Loss: 0.7190, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6616, Val Loss: 0.7205, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6600, Val Loss: 0.7239, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6656, Val Loss: 0.7223, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6652, Val Loss: 0.7222, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6602, Val Loss: 0.7241, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6649, Val Loss: 0.7178, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6599, Val Loss: 0.7331, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6613, Val Loss: 0.7201, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6647, Val Loss: 0.7206, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6609, Val Loss: 0.7277, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6613, Val Loss: 0.7207, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6606, Val Loss: 0.7192, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6602, Val Loss: 0.7279, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6606, Val Loss: 0.7255, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6718, Val Loss: 0.6823, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6701, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6696, Val Loss: 0.6817, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6700, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6697, Val Loss: 0.6853, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6707, Val Loss: 0.6803, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6738, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6739, Val Loss: 0.6799, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6706, Val Loss: 0.6814, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6740, Val Loss: 0.6814, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6739, Val Loss: 0.6798, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6703, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6694, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6742, Val Loss: 0.6817, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6749, Val Loss: 0.6820, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6744, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6742, Val Loss: 0.6819, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6708, Val Loss: 0.6819, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6719, Val Loss: 0.6837, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6744, Val Loss: 0.6823, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 21, Train Loss: 0.6701, Val Loss: 0.6816, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6707, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6757, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 24, Train Loss: 0.6702, Val Loss: 0.6826, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6739, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6702, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.6698, Val Loss: 0.6825, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6747, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6700, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6698, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6749, Val Loss: 0.6819, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6737, Val Loss: 0.6802, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6703, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6692, Val Loss: 0.6841, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6700, Val Loss: 0.6823, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6701, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6701, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.6738, Val Loss: 0.6814, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.6744, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 40, Train Loss: 0.6741, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6694, Val Loss: 0.6825, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6698, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.6736, Val Loss: 0.6803, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.6749, Val Loss: 0.6824, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6699, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.6743, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6747, Val Loss: 0.6840, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6699, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6697, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6740, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 51, Train Loss: 0.6738, Val Loss: 0.6798, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.6250141234071935\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7621, Val Loss: 0.6794, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6764, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 3, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 4, Train Loss: 0.6756, Val Loss: 0.6758, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6754, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6753, Val Loss: 0.6761, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.6736, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 9, Train Loss: 0.6756, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 10, Train Loss: 0.6752, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6755, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.8512, Val Loss: 0.6877, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6766, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6758, Val Loss: 0.6757, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6746, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6752, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6757, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6769, Val Loss: 0.6757, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6755, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6586, Val Loss: 0.5775, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 2, Train Loss: 0.6594, Val Loss: 0.5959, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 3, Train Loss: 0.6457, Val Loss: 0.5992, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 4, Train Loss: 0.6423, Val Loss: 0.5843, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 5, Train Loss: 0.6490, Val Loss: 0.5903, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 6, Train Loss: 0.6369, Val Loss: 0.6053, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 7, Train Loss: 0.6356, Val Loss: 0.5987, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 8, Train Loss: 0.6468, Val Loss: 0.6056, F1 Micro: 0.7191, F1 Macro: 0.7057, Accuracy: 0.7191\n","Epoch 9, Train Loss: 0.6435, Val Loss: 0.6755, F1 Micro: 0.5337, F1 Macro: 0.5227, Accuracy: 0.5337\n","Epoch 10, Train Loss: 0.6555, Val Loss: 0.5868, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 11, Train Loss: 0.6394, Val Loss: 0.6144, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 12, Train Loss: 0.6327, Val Loss: 0.5670, F1 Micro: 0.7584, F1 Macro: 0.7238, Accuracy: 0.7584\n","Epoch 13, Train Loss: 0.6248, Val Loss: 0.5808, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Epoch 14, Train Loss: 0.6437, Val Loss: 0.5815, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 15, Train Loss: 0.6318, Val Loss: 0.5759, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.6295, Val Loss: 0.5672, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 17, Train Loss: 0.6427, Val Loss: 0.5879, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6233, Val Loss: 0.5660, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 19, Train Loss: 0.6370, Val Loss: 0.5749, F1 Micro: 0.7079, F1 Macro: 0.6339, Accuracy: 0.7079\n","Epoch 20, Train Loss: 0.6369, Val Loss: 0.5963, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 21, Train Loss: 0.6415, Val Loss: 0.6093, F1 Micro: 0.7247, F1 Macro: 0.7172, Accuracy: 0.7247\n","Epoch 22, Train Loss: 0.6386, Val Loss: 0.5979, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7408, Val Loss: 0.6970, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6567, Val Loss: 0.8125, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6344, Val Loss: 0.6963, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6369, Val Loss: 0.6943, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6160, Val Loss: 0.8504, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 6, Train Loss: 0.6168, Val Loss: 0.7160, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.6056, Val Loss: 0.8135, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 8, Train Loss: 0.6115, Val Loss: 0.9920, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6320, Val Loss: 0.9393, F1 Micro: 0.5955, F1 Macro: 0.5264, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6092, Val Loss: 0.7856, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6093, Val Loss: 0.8085, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.5995, Val Loss: 0.8167, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 13, Train Loss: 0.5984, Val Loss: 0.7348, F1 Micro: 0.5899, F1 Macro: 0.5645, Accuracy: 0.5899\n","Epoch 14, Train Loss: 0.6003, Val Loss: 0.8364, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 15, Train Loss: 0.5932, Val Loss: 0.8018, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.5918, Val Loss: 0.8426, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 17, Train Loss: 0.6096, Val Loss: 0.7513, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.6117, Val Loss: 0.7119, F1 Micro: 0.5955, F1 Macro: 0.5930, Accuracy: 0.5955\n","Epoch 19, Train Loss: 0.6081, Val Loss: 0.7821, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 20, Train Loss: 0.5972, Val Loss: 0.8055, F1 Micro: 0.5787, F1 Macro: 0.5305, Accuracy: 0.5787\n","Epoch 21, Train Loss: 0.5995, Val Loss: 0.8384, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 22, Train Loss: 0.6082, Val Loss: 0.9641, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 23, Train Loss: 0.6088, Val Loss: 0.6974, F1 Micro: 0.6292, F1 Macro: 0.6254, Accuracy: 0.6292\n","Epoch 24, Train Loss: 0.6046, Val Loss: 0.7136, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6037, Val Loss: 0.8040, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6786, Val Loss: 0.7916, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 2, Train Loss: 0.6244, Val Loss: 0.6866, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6474, Val Loss: 0.9275, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 4, Train Loss: 0.6274, Val Loss: 0.7270, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 5, Train Loss: 0.6342, Val Loss: 0.9064, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 6, Train Loss: 0.6204, Val Loss: 0.8629, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 7, Train Loss: 0.6375, Val Loss: 0.8276, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 8, Train Loss: 0.6447, Val Loss: 0.7614, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6236, Val Loss: 0.6918, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6343, Val Loss: 0.7461, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6178, Val Loss: 0.7071, F1 Micro: 0.6461, F1 Macro: 0.6301, Accuracy: 0.6461\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.6745653129119328\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6714, Val Loss: 0.6797, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 2, Train Loss: 0.6768, Val Loss: 0.6761, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 3, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 4, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6753, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 6, Train Loss: 0.6758, Val Loss: 0.6757, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 7, Train Loss: 0.6769, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 8, Train Loss: 0.6764, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 9, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 10, Train Loss: 0.6747, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6741, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 12, Train Loss: 0.6737, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 13, Train Loss: 0.6741, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 14, Train Loss: 0.6751, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 15, Train Loss: 0.6756, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 16, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 17, Train Loss: 0.6735, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 18, Train Loss: 0.6760, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 19, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 20, Train Loss: 0.6737, Val Loss: 0.6758, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 21, Train Loss: 0.6751, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 22, Train Loss: 0.6752, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 23, Train Loss: 0.6742, Val Loss: 0.6757, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 24, Train Loss: 0.6748, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 25, Train Loss: 0.6763, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 26, Train Loss: 0.6758, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 27, Train Loss: 0.6752, Val Loss: 0.6757, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 28, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 29, Train Loss: 0.6745, Val Loss: 0.6757, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 30, Train Loss: 0.6735, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 31, Train Loss: 0.6757, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 32, Train Loss: 0.6749, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 33, Train Loss: 0.6769, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 34, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 35, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 36, Train Loss: 0.6744, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 37, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 38, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 39, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 40, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 41, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 42, Train Loss: 0.6757, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 43, Train Loss: 0.6743, Val Loss: 0.6756, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 44, Train Loss: 0.6756, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 45, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 46, Train Loss: 0.6748, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 47, Train Loss: 0.6746, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 48, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 49, Train Loss: 0.6748, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 50, Train Loss: 0.6749, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 51, Train Loss: 0.6748, Val Loss: 0.6755, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.9075, Val Loss: 0.7547, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 2, Train Loss: 0.7120, Val Loss: 0.6857, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6784, Val Loss: 0.6759, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6756, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6753, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6752, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6756, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6746, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6761, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6754, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6744, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6747, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.6753, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6770, Val Loss: 0.6758, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6755, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.6752, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6770, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6744, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6757, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6756, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6755, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6752, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 28, Train Loss: 0.6757, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6761, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6755, Val Loss: 0.6757, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.6755, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.6747, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6765, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6762, Val Loss: 0.6757, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6759, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6754, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6753, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6758, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6769, Val Loss: 0.6757, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.6741, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6745, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.6762, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.6758, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6760, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6763, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.6753, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6755, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 52, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6721, Val Loss: 0.6947, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6768, Val Loss: 0.6828, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6721, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6727, Val Loss: 0.6816, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6731, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6736, Val Loss: 0.6817, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6738, Val Loss: 0.6814, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6739, Val Loss: 0.6812, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6731, Val Loss: 0.6813, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6734, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6724, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6724, Val Loss: 0.6814, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6732, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6737, Val Loss: 0.6827, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6734, Val Loss: 0.6816, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6738, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6735, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6735, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6744, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6738, Val Loss: 0.6819, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6733, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6747, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6739, Val Loss: 0.6814, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6736, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6738, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6739, Val Loss: 0.6812, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6736, Val Loss: 0.6817, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6731, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6739, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6735, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6743, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6734, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6734, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6735, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6751, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6742, Val Loss: 0.6817, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6730, Val Loss: 0.6817, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6746, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6727, Val Loss: 0.6814, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6735, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6744, Val Loss: 0.6831, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6752, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6726, Val Loss: 0.6815, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6769, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6740, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6738, Val Loss: 0.6828, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6730, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6734, Val Loss: 0.6819, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6730, Val Loss: 0.6816, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6732, Val Loss: 0.6815, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6723, Val Loss: 0.6813, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6848, Val Loss: 0.7292, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6633, Val Loss: 0.7342, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6627, Val Loss: 0.7345, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6620, Val Loss: 0.7305, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6617, Val Loss: 0.7301, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6631, Val Loss: 0.7304, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6632, Val Loss: 0.7389, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6609, Val Loss: 0.7302, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6618, Val Loss: 0.7380, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6629, Val Loss: 0.7391, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6620, Val Loss: 0.7315, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6610, Val Loss: 0.7328, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6621, Val Loss: 0.7316, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6627, Val Loss: 0.7342, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6606, Val Loss: 0.7299, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6625, Val Loss: 0.7351, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6605, Val Loss: 0.7314, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6636, Val Loss: 0.7311, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6616, Val Loss: 0.7328, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6610, Val Loss: 0.7326, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6627, Val Loss: 0.7362, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6621, Val Loss: 0.7329, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6609, Val Loss: 0.7345, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6622, Val Loss: 0.7337, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6616, Val Loss: 0.7365, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6616, Val Loss: 0.7340, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6617, Val Loss: 0.7366, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6612, Val Loss: 0.7391, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6624, Val Loss: 0.7314, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6630, Val Loss: 0.7296, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6607, Val Loss: 0.7356, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6621, Val Loss: 0.7341, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6617, Val Loss: 0.7336, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6628, Val Loss: 0.7321, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6616, Val Loss: 0.7248, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6627, Val Loss: 0.7331, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6620, Val Loss: 0.7377, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6613, Val Loss: 0.7272, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6619, Val Loss: 0.7312, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6626, Val Loss: 0.7346, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6614, Val Loss: 0.7324, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6610, Val Loss: 0.7339, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6625, Val Loss: 0.7358, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6615, Val Loss: 0.7350, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6631, Val Loss: 0.7354, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6613, Val Loss: 0.7331, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6621, Val Loss: 0.7338, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6620, Val Loss: 0.7371, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6627, Val Loss: 0.7332, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6629, Val Loss: 0.7406, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6617, Val Loss: 0.7349, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6841, Val Loss: 0.6875, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6712, Val Loss: 0.6912, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6701, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6711, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6716, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6715, Val Loss: 0.6922, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6702, Val Loss: 0.6913, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6713, Val Loss: 0.6898, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6717, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6719, Val Loss: 0.6914, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6702, Val Loss: 0.6928, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6712, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6710, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6722, Val Loss: 0.6908, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6727, Val Loss: 0.6916, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6720, Val Loss: 0.6907, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6714, Val Loss: 0.6912, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6715, Val Loss: 0.6911, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6702, Val Loss: 0.6902, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6707, Val Loss: 0.6913, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 21, Train Loss: 0.6720, Val Loss: 0.6920, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6717, Val Loss: 0.6916, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6711, Val Loss: 0.6913, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 24, Train Loss: 0.6717, Val Loss: 0.6920, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6698, Val Loss: 0.6924, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6716, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.6724, Val Loss: 0.6925, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6716, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6704, Val Loss: 0.6920, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6718, Val Loss: 0.6927, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6718, Val Loss: 0.6910, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6706, Val Loss: 0.6922, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6709, Val Loss: 0.6923, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6719, Val Loss: 0.6934, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6719, Val Loss: 0.6908, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6720, Val Loss: 0.6938, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6713, Val Loss: 0.6922, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.6721, Val Loss: 0.6923, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.6715, Val Loss: 0.6894, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 40, Train Loss: 0.6733, Val Loss: 0.6923, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6708, Val Loss: 0.6905, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6724, Val Loss: 0.6910, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.6722, Val Loss: 0.6902, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.6711, Val Loss: 0.6903, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6696, Val Loss: 0.6920, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.6718, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6710, Val Loss: 0.6912, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6713, Val Loss: 0.6925, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6721, Val Loss: 0.6912, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6707, Val Loss: 0.6902, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 51, Train Loss: 0.6708, Val Loss: 0.6905, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.6049023915636181\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6683, Val Loss: 0.6426, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 2, Train Loss: 0.6475, Val Loss: 0.6106, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 3, Train Loss: 0.6502, Val Loss: 0.6029, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 4, Train Loss: 0.6387, Val Loss: 0.6021, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 5, Train Loss: 0.6377, Val Loss: 0.6214, F1 Micro: 0.6816, F1 Macro: 0.6315, Accuracy: 0.6816\n","Epoch 6, Train Loss: 0.6391, Val Loss: 0.6034, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 7, Train Loss: 0.6338, Val Loss: 0.5970, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 8, Train Loss: 0.6272, Val Loss: 0.6096, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 9, Train Loss: 0.6323, Val Loss: 0.6019, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 10, Train Loss: 0.6216, Val Loss: 0.5977, F1 Micro: 0.6983, F1 Macro: 0.6739, Accuracy: 0.6983\n","Epoch 11, Train Loss: 0.6269, Val Loss: 0.5953, F1 Micro: 0.7151, F1 Macro: 0.6842, Accuracy: 0.7151\n","Epoch 12, Train Loss: 0.6200, Val Loss: 0.6060, F1 Micro: 0.7095, F1 Macro: 0.6880, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.6237, Val Loss: 0.5928, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 14, Train Loss: 0.6275, Val Loss: 0.5868, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 15, Train Loss: 0.6250, Val Loss: 0.6122, F1 Micro: 0.6760, F1 Macro: 0.6631, Accuracy: 0.6760\n","Epoch 16, Train Loss: 0.6257, Val Loss: 0.6185, F1 Micro: 0.6648, F1 Macro: 0.6270, Accuracy: 0.6648\n","Epoch 17, Train Loss: 0.6205, Val Loss: 0.5913, F1 Micro: 0.7095, F1 Macro: 0.6816, Accuracy: 0.7095\n","Epoch 18, Train Loss: 0.6159, Val Loss: 0.5857, F1 Micro: 0.7207, F1 Macro: 0.6960, Accuracy: 0.7207\n","Epoch 19, Train Loss: 0.6282, Val Loss: 0.5857, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 20, Train Loss: 0.6186, Val Loss: 0.6011, F1 Micro: 0.6816, F1 Macro: 0.6747, Accuracy: 0.6816\n","Epoch 21, Train Loss: 0.6186, Val Loss: 0.5985, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 22, Train Loss: 0.6268, Val Loss: 0.6111, F1 Micro: 0.6369, F1 Macro: 0.6061, Accuracy: 0.6369\n","Epoch 23, Train Loss: 0.6130, Val Loss: 0.5868, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 24, Train Loss: 0.6266, Val Loss: 0.5865, F1 Micro: 0.6816, F1 Macro: 0.6201, Accuracy: 0.6816\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7362, Val Loss: 0.7466, F1 Micro: 0.4831, F1 Macro: 0.4789, Accuracy: 0.4831\n","Epoch 2, Train Loss: 0.6625, Val Loss: 0.6059, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 3, Train Loss: 0.6481, Val Loss: 0.6180, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 4, Train Loss: 0.6529, Val Loss: 0.6401, F1 Micro: 0.6236, F1 Macro: 0.6183, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6449, Val Loss: 0.6431, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 6, Train Loss: 0.6342, Val Loss: 0.6531, F1 Micro: 0.5787, F1 Macro: 0.5780, Accuracy: 0.5787\n","Epoch 7, Train Loss: 0.6317, Val Loss: 0.6116, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 8, Train Loss: 0.6346, Val Loss: 0.6130, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 9, Train Loss: 0.6219, Val Loss: 0.6125, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 10, Train Loss: 0.6192, Val Loss: 0.6159, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6273, Val Loss: 0.6588, F1 Micro: 0.5787, F1 Macro: 0.5785, Accuracy: 0.5787\n","Epoch 12, Train Loss: 0.6504, Val Loss: 0.6314, F1 Micro: 0.6180, F1 Macro: 0.6131, Accuracy: 0.6180\n","Epoch 13, Train Loss: 0.6347, Val Loss: 0.6211, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 14, Train Loss: 0.6228, Val Loss: 0.6187, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6279, Val Loss: 0.6369, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6323, Val Loss: 0.6102, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 17, Train Loss: 0.6274, Val Loss: 0.6615, F1 Micro: 0.6124, F1 Macro: 0.6123, Accuracy: 0.6124\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7069, Val Loss: 0.6542, F1 Micro: 0.6404, F1 Macro: 0.4310, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6818, Val Loss: 0.6756, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6732, Val Loss: 0.6688, F1 Micro: 0.6517, F1 Macro: 0.4911, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6721, Val Loss: 0.6615, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6722, Val Loss: 0.6655, F1 Micro: 0.6404, F1 Macro: 0.4310, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6630, Val Loss: 0.6563, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 7, Train Loss: 0.6616, Val Loss: 0.6690, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6599, Val Loss: 0.6543, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6598, Val Loss: 0.6513, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6587, Val Loss: 0.6502, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6577, Val Loss: 0.6515, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6622, Val Loss: 0.6483, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6590, Val Loss: 0.6505, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6540, Val Loss: 0.6505, F1 Micro: 0.6573, F1 Macro: 0.5038, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6617, Val Loss: 0.6476, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6602, Val Loss: 0.6473, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7275, Val Loss: 0.6892, F1 Micro: 0.5506, F1 Macro: 0.5408, Accuracy: 0.5506\n","Epoch 2, Train Loss: 0.6519, Val Loss: 0.6882, F1 Micro: 0.5730, F1 Macro: 0.5606, Accuracy: 0.5730\n","Epoch 3, Train Loss: 0.6634, Val Loss: 0.6863, F1 Micro: 0.6292, F1 Macro: 0.6254, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6426, Val Loss: 0.6821, F1 Micro: 0.6124, F1 Macro: 0.6122, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6297, Val Loss: 0.7833, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6292, Val Loss: 0.6949, F1 Micro: 0.6011, F1 Macro: 0.5975, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6457, Val Loss: 0.7567, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6329, Val Loss: 0.8256, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 9, Train Loss: 0.6201, Val Loss: 0.7094, F1 Micro: 0.6011, F1 Macro: 0.5869, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6113, Val Loss: 0.7662, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6345, Val Loss: 0.7161, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6285, Val Loss: 0.6919, F1 Micro: 0.6124, F1 Macro: 0.6123, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6192, Val Loss: 0.7948, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.6257, Val Loss: 0.6976, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 15, Train Loss: 0.6197, Val Loss: 0.6763, F1 Micro: 0.5955, F1 Macro: 0.5955, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.6192, Val Loss: 0.7735, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6098, Val Loss: 0.7201, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6686, Val Loss: 0.6718, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6622, Val Loss: 0.7380, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6476, Val Loss: 0.6925, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6431, Val Loss: 0.6818, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6460, Val Loss: 0.6847, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6403, Val Loss: 0.6775, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.6366, Val Loss: 0.6978, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Epoch 8, Train Loss: 0.6326, Val Loss: 0.6945, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 9, Train Loss: 0.6278, Val Loss: 0.7092, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6285, Val Loss: 0.6925, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 11, Train Loss: 0.6243, Val Loss: 0.6911, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 12, Train Loss: 0.6196, Val Loss: 0.6808, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6190, Val Loss: 0.7038, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.6228, Val Loss: 0.7020, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6085, Val Loss: 0.6728, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6170, Val Loss: 0.6826, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6060, Val Loss: 0.7070, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6123, Val Loss: 0.6867, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 19, Train Loss: 0.6221, Val Loss: 0.6962, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.6980603854120896\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6967, Val Loss: 0.6406, F1 Micro: 0.6257, F1 Macro: 0.6039, Accuracy: 0.6257\n","Epoch 2, Train Loss: 0.6473, Val Loss: 0.5969, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 3, Train Loss: 0.6428, Val Loss: 0.6149, F1 Micro: 0.7039, F1 Macro: 0.6743, Accuracy: 0.7039\n","Epoch 4, Train Loss: 0.6416, Val Loss: 0.6141, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 5, Train Loss: 0.6331, Val Loss: 0.6328, F1 Micro: 0.6034, F1 Macro: 0.5636, Accuracy: 0.6034\n","Epoch 6, Train Loss: 0.6357, Val Loss: 0.6284, F1 Micro: 0.6704, F1 Macro: 0.6633, Accuracy: 0.6704\n","Epoch 7, Train Loss: 0.6355, Val Loss: 0.5901, F1 Micro: 0.7039, F1 Macro: 0.6743, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.6237, Val Loss: 0.5806, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Epoch 9, Train Loss: 0.6308, Val Loss: 0.5863, F1 Micro: 0.6704, F1 Macro: 0.6317, Accuracy: 0.6704\n","Epoch 10, Train Loss: 0.6096, Val Loss: 0.5997, F1 Micro: 0.6480, F1 Macro: 0.5845, Accuracy: 0.6480\n","Epoch 11, Train Loss: 0.6198, Val Loss: 0.6341, F1 Micro: 0.6480, F1 Macro: 0.6128, Accuracy: 0.6480\n","Epoch 12, Train Loss: 0.6195, Val Loss: 0.5899, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 13, Train Loss: 0.6170, Val Loss: 0.5896, F1 Micro: 0.7263, F1 Macro: 0.7119, Accuracy: 0.7263\n","Epoch 14, Train Loss: 0.6175, Val Loss: 0.6090, F1 Micro: 0.6648, F1 Macro: 0.6208, Accuracy: 0.6648\n","Epoch 15, Train Loss: 0.6268, Val Loss: 0.5912, F1 Micro: 0.6927, F1 Macro: 0.6160, Accuracy: 0.6927\n","Epoch 16, Train Loss: 0.6116, Val Loss: 0.6057, F1 Micro: 0.6592, F1 Macro: 0.5934, Accuracy: 0.6592\n","Epoch 17, Train Loss: 0.6169, Val Loss: 0.5838, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 18, Train Loss: 0.6152, Val Loss: 0.6082, F1 Micro: 0.6760, F1 Macro: 0.6334, Accuracy: 0.6760\n","Epoch 19, Train Loss: 0.6208, Val Loss: 0.5921, F1 Micro: 0.6704, F1 Macro: 0.5931, Accuracy: 0.6704\n","Epoch 20, Train Loss: 0.6218, Val Loss: 0.5855, F1 Micro: 0.6927, F1 Macro: 0.6444, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6138, Val Loss: 0.6001, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 22, Train Loss: 0.6150, Val Loss: 0.5843, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 23, Train Loss: 0.6064, Val Loss: 0.6431, F1 Micro: 0.6760, F1 Macro: 0.6615, Accuracy: 0.6760\n","Epoch 24, Train Loss: 0.6121, Val Loss: 0.5868, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 25, Train Loss: 0.6087, Val Loss: 0.6002, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 26, Train Loss: 0.6276, Val Loss: 0.5916, F1 Micro: 0.6872, F1 Macro: 0.6545, Accuracy: 0.6872\n","Epoch 27, Train Loss: 0.6107, Val Loss: 0.5927, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Epoch 28, Train Loss: 0.6059, Val Loss: 0.5821, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 29, Train Loss: 0.6038, Val Loss: 0.5871, F1 Micro: 0.7207, F1 Macro: 0.6840, Accuracy: 0.7207\n","Epoch 30, Train Loss: 0.5960, Val Loss: 0.5960, F1 Micro: 0.6927, F1 Macro: 0.6730, Accuracy: 0.6927\n","Epoch 31, Train Loss: 0.6075, Val Loss: 0.5975, F1 Micro: 0.7039, F1 Macro: 0.6899, Accuracy: 0.7039\n","Epoch 32, Train Loss: 0.6075, Val Loss: 0.5922, F1 Micro: 0.6927, F1 Macro: 0.6538, Accuracy: 0.6927\n","Epoch 33, Train Loss: 0.6067, Val Loss: 0.5943, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 34, Train Loss: 0.5974, Val Loss: 0.6110, F1 Micro: 0.6760, F1 Macro: 0.6646, Accuracy: 0.6760\n","Epoch 35, Train Loss: 0.5918, Val Loss: 0.5920, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 36, Train Loss: 0.5998, Val Loss: 0.6047, F1 Micro: 0.6816, F1 Macro: 0.6747, Accuracy: 0.6816\n","Epoch 37, Train Loss: 0.5964, Val Loss: 0.6117, F1 Micro: 0.6592, F1 Macro: 0.6128, Accuracy: 0.6592\n","Epoch 38, Train Loss: 0.6009, Val Loss: 0.5908, F1 Micro: 0.7095, F1 Macro: 0.6880, Accuracy: 0.7095\n","Epoch 39, Train Loss: 0.5962, Val Loss: 0.6277, F1 Micro: 0.6872, F1 Macro: 0.6809, Accuracy: 0.6872\n","Epoch 40, Train Loss: 0.6030, Val Loss: 0.6149, F1 Micro: 0.6816, F1 Macro: 0.6747, Accuracy: 0.6816\n","Epoch 41, Train Loss: 0.5923, Val Loss: 0.5976, F1 Micro: 0.7207, F1 Macro: 0.6915, Accuracy: 0.7207\n","Epoch 42, Train Loss: 0.6076, Val Loss: 0.6021, F1 Micro: 0.6983, F1 Macro: 0.6877, Accuracy: 0.6983\n","Epoch 43, Train Loss: 0.6020, Val Loss: 0.5867, F1 Micro: 0.7095, F1 Macro: 0.6816, Accuracy: 0.7095\n","Epoch 44, Train Loss: 0.5954, Val Loss: 0.5900, F1 Micro: 0.6816, F1 Macro: 0.6546, Accuracy: 0.6816\n","Epoch 45, Train Loss: 0.6038, Val Loss: 0.5928, F1 Micro: 0.6983, F1 Macro: 0.6849, Accuracy: 0.6983\n","Epoch 46, Train Loss: 0.5937, Val Loss: 0.5898, F1 Micro: 0.7151, F1 Macro: 0.6968, Accuracy: 0.7151\n","Epoch 47, Train Loss: 0.5887, Val Loss: 0.5933, F1 Micro: 0.7095, F1 Macro: 0.6767, Accuracy: 0.7095\n","Epoch 48, Train Loss: 0.5906, Val Loss: 0.5953, F1 Micro: 0.6983, F1 Macro: 0.6760, Accuracy: 0.6983\n","Epoch 49, Train Loss: 0.5850, Val Loss: 0.5927, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 50, Train Loss: 0.5954, Val Loss: 0.5831, F1 Micro: 0.7095, F1 Macro: 0.6684, Accuracy: 0.7095\n","Epoch 51, Train Loss: 0.5910, Val Loss: 0.5851, F1 Micro: 0.6872, F1 Macro: 0.6429, Accuracy: 0.6872\n","Epoch 52, Train Loss: 0.5832, Val Loss: 0.5948, F1 Micro: 0.6983, F1 Macro: 0.6833, Accuracy: 0.6983\n","Epoch 53, Train Loss: 0.5990, Val Loss: 0.5996, F1 Micro: 0.6983, F1 Macro: 0.6816, Accuracy: 0.6983\n","Epoch 54, Train Loss: 0.5899, Val Loss: 0.5997, F1 Micro: 0.6872, F1 Macro: 0.6362, Accuracy: 0.6872\n","Epoch 55, Train Loss: 0.5944, Val Loss: 0.5880, F1 Micro: 0.6816, F1 Macro: 0.6546, Accuracy: 0.6816\n","Epoch 56, Train Loss: 0.5858, Val Loss: 0.5976, F1 Micro: 0.6983, F1 Macro: 0.6849, Accuracy: 0.6983\n","Epoch 57, Train Loss: 0.5945, Val Loss: 0.5951, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 58, Train Loss: 0.5861, Val Loss: 0.5989, F1 Micro: 0.6872, F1 Macro: 0.6571, Accuracy: 0.6872\n","Epoch 59, Train Loss: 0.5933, Val Loss: 0.6217, F1 Micro: 0.6760, F1 Macro: 0.6580, Accuracy: 0.6760\n","Epoch 60, Train Loss: 0.5977, Val Loss: 0.6193, F1 Micro: 0.6760, F1 Macro: 0.6715, Accuracy: 0.6760\n","Epoch 61, Train Loss: 0.5896, Val Loss: 0.5959, F1 Micro: 0.7095, F1 Macro: 0.6899, Accuracy: 0.7095\n","Epoch 62, Train Loss: 0.5831, Val Loss: 0.5946, F1 Micro: 0.6927, F1 Macro: 0.6689, Accuracy: 0.6927\n","Epoch 63, Train Loss: 0.5872, Val Loss: 0.5910, F1 Micro: 0.7039, F1 Macro: 0.6867, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6655, Val Loss: 0.6193, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.6569, Val Loss: 0.6016, F1 Micro: 0.6742, F1 Macro: 0.5405, Accuracy: 0.6742\n","Epoch 3, Train Loss: 0.6604, Val Loss: 0.6017, F1 Micro: 0.6573, F1 Macro: 0.4392, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6490, Val Loss: 0.6508, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6477, Val Loss: 0.6078, F1 Micro: 0.6517, F1 Macro: 0.4712, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6511, Val Loss: 0.6267, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6481, Val Loss: 0.6031, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6474, Val Loss: 0.6840, F1 Micro: 0.5899, F1 Macro: 0.5222, Accuracy: 0.5899\n","Epoch 9, Train Loss: 0.6304, Val Loss: 0.5917, F1 Micro: 0.6517, F1 Macro: 0.4603, Accuracy: 0.6517\n","Epoch 10, Train Loss: 0.6368, Val Loss: 0.6200, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 11, Train Loss: 0.6346, Val Loss: 0.6145, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 12, Train Loss: 0.6392, Val Loss: 0.5838, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 13, Train Loss: 0.6240, Val Loss: 0.6082, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6233, Val Loss: 0.5855, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 15, Train Loss: 0.6252, Val Loss: 0.6428, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 16, Train Loss: 0.6238, Val Loss: 0.5925, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6121, Val Loss: 0.6284, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6183, Val Loss: 0.5874, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 19, Train Loss: 0.6157, Val Loss: 0.5870, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 20, Train Loss: 0.6264, Val Loss: 0.6410, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 21, Train Loss: 0.6160, Val Loss: 0.6411, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 22, Train Loss: 0.6246, Val Loss: 0.5846, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 23, Train Loss: 0.6193, Val Loss: 0.5768, F1 Micro: 0.7191, F1 Macro: 0.6604, Accuracy: 0.7191\n","Epoch 24, Train Loss: 0.6131, Val Loss: 0.5925, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 25, Train Loss: 0.6130, Val Loss: 0.5851, F1 Micro: 0.7191, F1 Macro: 0.6774, Accuracy: 0.7191\n","Epoch 26, Train Loss: 0.6065, Val Loss: 0.5896, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 27, Train Loss: 0.6073, Val Loss: 0.5940, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.6122, Val Loss: 0.6335, F1 Micro: 0.6798, F1 Macro: 0.6653, Accuracy: 0.6798\n","Epoch 29, Train Loss: 0.6086, Val Loss: 0.5899, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.6167, Val Loss: 0.6012, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 31, Train Loss: 0.6174, Val Loss: 0.6802, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6243, Val Loss: 0.5910, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 33, Train Loss: 0.6197, Val Loss: 0.5728, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 34, Train Loss: 0.6223, Val Loss: 0.6348, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.6261, Val Loss: 0.5996, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.6123, Val Loss: 0.6025, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 37, Train Loss: 0.6050, Val Loss: 0.5866, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 38, Train Loss: 0.6095, Val Loss: 0.6091, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 39, Train Loss: 0.5987, Val Loss: 0.6051, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 40, Train Loss: 0.6044, Val Loss: 0.6039, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 41, Train Loss: 0.6045, Val Loss: 0.5907, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 42, Train Loss: 0.5995, Val Loss: 0.5919, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 43, Train Loss: 0.6107, Val Loss: 0.5793, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 44, Train Loss: 0.6024, Val Loss: 0.5782, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 45, Train Loss: 0.6219, Val Loss: 0.5774, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 46, Train Loss: 0.5982, Val Loss: 0.5721, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 47, Train Loss: 0.6083, Val Loss: 0.5886, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 48, Train Loss: 0.5959, Val Loss: 0.5971, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 49, Train Loss: 0.5992, Val Loss: 0.5846, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 50, Train Loss: 0.6036, Val Loss: 0.5989, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 51, Train Loss: 0.6018, Val Loss: 0.5869, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 52, Train Loss: 0.6070, Val Loss: 0.6052, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 53, Train Loss: 0.6093, Val Loss: 0.5812, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 54, Train Loss: 0.6119, Val Loss: 0.5825, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 55, Train Loss: 0.6006, Val Loss: 0.5985, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 56, Train Loss: 0.6129, Val Loss: 0.5755, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 57, Train Loss: 0.6019, Val Loss: 0.6230, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 58, Train Loss: 0.5911, Val Loss: 0.5866, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 59, Train Loss: 0.5981, Val Loss: 0.5678, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 60, Train Loss: 0.5951, Val Loss: 0.5761, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 61, Train Loss: 0.5891, Val Loss: 0.5805, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 62, Train Loss: 0.5935, Val Loss: 0.5934, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 63, Train Loss: 0.5909, Val Loss: 0.5639, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.5911, Val Loss: 0.5924, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 65, Train Loss: 0.5971, Val Loss: 0.5907, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 66, Train Loss: 0.6006, Val Loss: 0.5844, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 67, Train Loss: 0.5980, Val Loss: 0.5872, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 68, Train Loss: 0.5962, Val Loss: 0.5958, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 69, Train Loss: 0.5964, Val Loss: 0.5603, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 70, Train Loss: 0.5870, Val Loss: 0.5984, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 71, Train Loss: 0.5984, Val Loss: 0.5710, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 72, Train Loss: 0.5873, Val Loss: 0.5664, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 73, Train Loss: 0.5932, Val Loss: 0.5729, F1 Micro: 0.6629, F1 Macro: 0.5878, Accuracy: 0.6629\n","Epoch 74, Train Loss: 0.5852, Val Loss: 0.5930, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 75, Train Loss: 0.5899, Val Loss: 0.5761, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 76, Train Loss: 0.5890, Val Loss: 0.5708, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 77, Train Loss: 0.5847, Val Loss: 0.5892, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 78, Train Loss: 0.5900, Val Loss: 0.5971, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 79, Train Loss: 0.5993, Val Loss: 0.6012, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 80, Train Loss: 0.5866, Val Loss: 0.5624, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 81, Train Loss: 0.6104, Val Loss: 0.5860, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 82, Train Loss: 0.5955, Val Loss: 0.5718, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 83, Train Loss: 0.5834, Val Loss: 0.5686, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6861, Val Loss: 0.6640, F1 Micro: 0.6180, F1 Macro: 0.4081, Accuracy: 0.6180\n","Epoch 2, Train Loss: 0.6390, Val Loss: 0.6340, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 3, Train Loss: 0.6505, Val Loss: 0.6414, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6440, Val Loss: 0.5843, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 5, Train Loss: 0.6377, Val Loss: 0.5900, F1 Micro: 0.7360, F1 Macro: 0.6790, Accuracy: 0.7360\n","Epoch 6, Train Loss: 0.6419, Val Loss: 0.5873, F1 Micro: 0.6910, F1 Macro: 0.5750, Accuracy: 0.6910\n","Epoch 7, Train Loss: 0.6318, Val Loss: 0.6056, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 8, Train Loss: 0.6310, Val Loss: 0.5669, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 9, Train Loss: 0.6307, Val Loss: 0.5921, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 10, Train Loss: 0.6358, Val Loss: 0.6159, F1 Micro: 0.7247, F1 Macro: 0.7149, Accuracy: 0.7247\n","Epoch 11, Train Loss: 0.6388, Val Loss: 0.6319, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6386, Val Loss: 0.5671, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 13, Train Loss: 0.6348, Val Loss: 0.5609, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 14, Train Loss: 0.6295, Val Loss: 0.5597, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 15, Train Loss: 0.6248, Val Loss: 0.5611, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 16, Train Loss: 0.6330, Val Loss: 0.5612, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 17, Train Loss: 0.6273, Val Loss: 0.5802, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6259, Val Loss: 0.5899, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 19, Train Loss: 0.6259, Val Loss: 0.5720, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 20, Train Loss: 0.6281, Val Loss: 0.5779, F1 Micro: 0.7303, F1 Macro: 0.7110, Accuracy: 0.7303\n","Epoch 21, Train Loss: 0.6161, Val Loss: 0.5986, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 22, Train Loss: 0.6279, Val Loss: 0.5673, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 23, Train Loss: 0.6223, Val Loss: 0.6027, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 24, Train Loss: 0.6342, Val Loss: 0.6133, F1 Micro: 0.6292, F1 Macro: 0.4370, Accuracy: 0.6292\n","Epoch 25, Train Loss: 0.6294, Val Loss: 0.5805, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.6187, Val Loss: 0.5622, F1 Micro: 0.7247, F1 Macro: 0.6760, Accuracy: 0.7247\n","Epoch 27, Train Loss: 0.6226, Val Loss: 0.6107, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 28, Train Loss: 0.6248, Val Loss: 0.5559, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.6194, Val Loss: 0.5687, F1 Micro: 0.7303, F1 Macro: 0.6663, Accuracy: 0.7303\n","Epoch 30, Train Loss: 0.6164, Val Loss: 0.5643, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 31, Train Loss: 0.6121, Val Loss: 0.5698, F1 Micro: 0.7135, F1 Macro: 0.6339, Accuracy: 0.7135\n","Epoch 32, Train Loss: 0.6183, Val Loss: 0.5692, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 33, Train Loss: 0.6082, Val Loss: 0.5619, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 34, Train Loss: 0.6148, Val Loss: 0.5721, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 35, Train Loss: 0.6019, Val Loss: 0.5629, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 36, Train Loss: 0.6108, Val Loss: 0.5555, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.6143, Val Loss: 0.5636, F1 Micro: 0.7079, F1 Macro: 0.6189, Accuracy: 0.7079\n","Epoch 38, Train Loss: 0.6084, Val Loss: 0.5601, F1 Micro: 0.7303, F1 Macro: 0.6874, Accuracy: 0.7303\n","Epoch 39, Train Loss: 0.6101, Val Loss: 0.5921, F1 Micro: 0.7135, F1 Macro: 0.6387, Accuracy: 0.7135\n","Epoch 40, Train Loss: 0.6075, Val Loss: 0.5736, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 41, Train Loss: 0.6106, Val Loss: 0.5653, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 42, Train Loss: 0.6210, Val Loss: 0.5648, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 43, Train Loss: 0.6030, Val Loss: 0.5742, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 44, Train Loss: 0.6109, Val Loss: 0.5719, F1 Micro: 0.7303, F1 Macro: 0.7144, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6053, Val Loss: 0.5648, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 46, Train Loss: 0.6067, Val Loss: 0.5592, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 47, Train Loss: 0.6178, Val Loss: 0.5567, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 48, Train Loss: 0.6127, Val Loss: 0.5701, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 49, Train Loss: 0.6051, Val Loss: 0.5679, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 50, Train Loss: 0.6134, Val Loss: 0.5999, F1 Micro: 0.6685, F1 Macro: 0.6175, Accuracy: 0.6685\n","Epoch 51, Train Loss: 0.6020, Val Loss: 0.5975, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 52, Train Loss: 0.6072, Val Loss: 0.5507, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 53, Train Loss: 0.6132, Val Loss: 0.5780, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 54, Train Loss: 0.6068, Val Loss: 0.5610, F1 Micro: 0.6966, F1 Macro: 0.6097, Accuracy: 0.6966\n","Epoch 55, Train Loss: 0.6016, Val Loss: 0.5819, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 56, Train Loss: 0.6030, Val Loss: 0.5633, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 57, Train Loss: 0.6143, Val Loss: 0.6001, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 58, Train Loss: 0.6020, Val Loss: 0.5913, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 59, Train Loss: 0.6155, Val Loss: 0.5679, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 60, Train Loss: 0.6011, Val Loss: 0.5480, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 61, Train Loss: 0.5972, Val Loss: 0.5444, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6132, Val Loss: 0.5492, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6731, Val Loss: 0.8220, F1 Micro: 0.5337, F1 Macro: 0.4193, Accuracy: 0.5337\n","Epoch 2, Train Loss: 0.6269, Val Loss: 0.7551, F1 Micro: 0.6067, F1 Macro: 0.5635, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6103, Val Loss: 0.6937, F1 Micro: 0.6124, F1 Macro: 0.6032, Accuracy: 0.6124\n","Epoch 4, Train Loss: 0.6089, Val Loss: 0.7302, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.5961, Val Loss: 0.7445, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 6, Train Loss: 0.6019, Val Loss: 0.7119, F1 Micro: 0.6180, F1 Macro: 0.5906, Accuracy: 0.6180\n","Epoch 7, Train Loss: 0.6072, Val Loss: 0.7874, F1 Micro: 0.5843, F1 Macro: 0.5349, Accuracy: 0.5843\n","Epoch 8, Train Loss: 0.5953, Val Loss: 0.7395, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6072, Val Loss: 0.7064, F1 Micro: 0.5899, F1 Macro: 0.5669, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.5886, Val Loss: 0.7466, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.5945, Val Loss: 0.7810, F1 Micro: 0.5618, F1 Macro: 0.4919, Accuracy: 0.5618\n","Epoch 12, Train Loss: 0.6027, Val Loss: 0.7354, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 13, Train Loss: 0.5939, Val Loss: 0.7198, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.5948, Val Loss: 0.6734, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 15, Train Loss: 0.5884, Val Loss: 0.7463, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 16, Train Loss: 0.5855, Val Loss: 0.7782, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.5805, Val Loss: 0.7309, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.6003, Val Loss: 0.7118, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.5948, Val Loss: 0.7313, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 20, Train Loss: 0.5850, Val Loss: 0.7546, F1 Micro: 0.5730, F1 Macro: 0.5223, Accuracy: 0.5730\n","Epoch 21, Train Loss: 0.5783, Val Loss: 0.8321, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 22, Train Loss: 0.5824, Val Loss: 0.7266, F1 Micro: 0.6292, F1 Macro: 0.6095, Accuracy: 0.6292\n","Epoch 23, Train Loss: 0.6025, Val Loss: 0.7765, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 24, Train Loss: 0.5939, Val Loss: 0.7034, F1 Micro: 0.6124, F1 Macro: 0.6018, Accuracy: 0.6124\n","Epoch 25, Train Loss: 0.5965, Val Loss: 0.6865, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.5925, Val Loss: 0.7655, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 27, Train Loss: 0.5992, Val Loss: 0.8109, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.5955, Val Loss: 0.7493, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.5874, Val Loss: 0.7464, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 30, Train Loss: 0.5708, Val Loss: 0.7440, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 31, Train Loss: 0.5861, Val Loss: 0.7640, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 32, Train Loss: 0.5921, Val Loss: 0.7199, F1 Micro: 0.6180, F1 Macro: 0.6035, Accuracy: 0.6180\n","Epoch 33, Train Loss: 0.5777, Val Loss: 0.7350, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 34, Train Loss: 0.5900, Val Loss: 0.8081, F1 Micro: 0.5730, F1 Macro: 0.5223, Accuracy: 0.5730\n","Epoch 35, Train Loss: 0.5915, Val Loss: 0.7237, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 36, Train Loss: 0.5898, Val Loss: 0.6786, F1 Micro: 0.6011, F1 Macro: 0.5931, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.5963, Val Loss: 0.6989, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.5800, Val Loss: 0.7243, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.5813, Val Loss: 0.7474, F1 Micro: 0.6236, F1 Macro: 0.6003, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.5726, Val Loss: 0.7868, F1 Micro: 0.5787, F1 Macro: 0.5183, Accuracy: 0.5787\n","Epoch 41, Train Loss: 0.5933, Val Loss: 0.7198, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 42, Train Loss: 0.5884, Val Loss: 0.6990, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 43, Train Loss: 0.5903, Val Loss: 0.7836, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 44, Train Loss: 0.5809, Val Loss: 0.7820, F1 Micro: 0.5674, F1 Macro: 0.5055, Accuracy: 0.5674\n","Epoch 45, Train Loss: 0.5832, Val Loss: 0.7073, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.5834, Val Loss: 0.7289, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 47, Train Loss: 0.5807, Val Loss: 0.6728, F1 Micro: 0.6180, F1 Macro: 0.6156, Accuracy: 0.6180\n","Epoch 48, Train Loss: 0.5725, Val Loss: 0.7378, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 49, Train Loss: 0.5864, Val Loss: 0.6957, F1 Micro: 0.5955, F1 Macro: 0.5783, Accuracy: 0.5955\n","Epoch 50, Train Loss: 0.5812, Val Loss: 0.6982, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 51, Train Loss: 0.5681, Val Loss: 0.8147, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 52, Train Loss: 0.5820, Val Loss: 0.7120, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 53, Train Loss: 0.5826, Val Loss: 0.7384, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 54, Train Loss: 0.5812, Val Loss: 0.7292, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 55, Train Loss: 0.5718, Val Loss: 0.7307, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 56, Train Loss: 0.5750, Val Loss: 0.6761, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 57, Train Loss: 0.5833, Val Loss: 0.7236, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 58, Train Loss: 0.5695, Val Loss: 0.8391, F1 Micro: 0.5562, F1 Macro: 0.4777, Accuracy: 0.5562\n","Epoch 59, Train Loss: 0.5827, Val Loss: 0.7429, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 60, Train Loss: 0.5797, Val Loss: 0.7917, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 61, Train Loss: 0.5739, Val Loss: 0.7534, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 62, Train Loss: 0.5805, Val Loss: 0.6938, F1 Micro: 0.6180, F1 Macro: 0.6052, Accuracy: 0.6180\n","Epoch 63, Train Loss: 0.5742, Val Loss: 0.7900, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 64, Train Loss: 0.5834, Val Loss: 0.7514, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 65, Train Loss: 0.5773, Val Loss: 0.7088, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 66, Train Loss: 0.5669, Val Loss: 0.7295, F1 Micro: 0.6461, F1 Macro: 0.6389, Accuracy: 0.6461\n","Epoch 67, Train Loss: 0.5743, Val Loss: 0.7459, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 68, Train Loss: 0.5694, Val Loss: 0.7266, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 69, Train Loss: 0.5724, Val Loss: 0.8147, F1 Micro: 0.5787, F1 Macro: 0.5138, Accuracy: 0.5787\n","Epoch 70, Train Loss: 0.5871, Val Loss: 0.7293, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 71, Train Loss: 0.5771, Val Loss: 0.7385, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 72, Train Loss: 0.5753, Val Loss: 0.7416, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 73, Train Loss: 0.5715, Val Loss: 0.7601, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 74, Train Loss: 0.5720, Val Loss: 0.7250, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 75, Train Loss: 0.5721, Val Loss: 0.7102, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 76, Train Loss: 0.5862, Val Loss: 0.7744, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 77, Train Loss: 0.5744, Val Loss: 0.7085, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 78, Train Loss: 0.5763, Val Loss: 0.6974, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 79, Train Loss: 0.5761, Val Loss: 0.7466, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 80, Train Loss: 0.5634, Val Loss: 0.7236, F1 Micro: 0.6124, F1 Macro: 0.5906, Accuracy: 0.6124\n","Epoch 81, Train Loss: 0.5701, Val Loss: 0.7678, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 82, Train Loss: 0.5840, Val Loss: 0.7484, F1 Micro: 0.5787, F1 Macro: 0.5305, Accuracy: 0.5787\n","Epoch 83, Train Loss: 0.5726, Val Loss: 0.7280, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 84, Train Loss: 0.5657, Val Loss: 0.7070, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 85, Train Loss: 0.5744, Val Loss: 0.7575, F1 Micro: 0.6124, F1 Macro: 0.5833, Accuracy: 0.6124\n","Epoch 86, Train Loss: 0.5686, Val Loss: 0.7195, F1 Micro: 0.6124, F1 Macro: 0.6114, Accuracy: 0.6124\n","Epoch 87, Train Loss: 0.5720, Val Loss: 0.7086, F1 Micro: 0.6124, F1 Macro: 0.6002, Accuracy: 0.6124\n","Epoch 88, Train Loss: 0.5842, Val Loss: 0.7595, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 89, Train Loss: 0.5731, Val Loss: 0.8146, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 90, Train Loss: 0.5613, Val Loss: 0.7718, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 91, Train Loss: 0.5820, Val Loss: 0.7299, F1 Micro: 0.6011, F1 Macro: 0.5788, Accuracy: 0.6011\n","Epoch 92, Train Loss: 0.5745, Val Loss: 0.6995, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 93, Train Loss: 0.5657, Val Loss: 0.7102, F1 Micro: 0.6067, F1 Macro: 0.5919, Accuracy: 0.6067\n","Epoch 94, Train Loss: 0.5746, Val Loss: 0.8093, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 95, Train Loss: 0.5710, Val Loss: 0.6854, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Epoch 96, Train Loss: 0.5667, Val Loss: 0.7764, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 97, Train Loss: 0.5675, Val Loss: 0.7946, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 98, Train Loss: 0.5680, Val Loss: 0.7475, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 99, Train Loss: 0.5640, Val Loss: 0.7981, F1 Micro: 0.6236, F1 Macro: 0.5979, Accuracy: 0.6236\n","Epoch 100, Train Loss: 0.5857, Val Loss: 0.7294, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 101, Train Loss: 0.5695, Val Loss: 0.7481, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 102, Train Loss: 0.5627, Val Loss: 0.7152, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 103, Train Loss: 0.5765, Val Loss: 0.7743, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 104, Train Loss: 0.5681, Val Loss: 0.7460, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 105, Train Loss: 0.5754, Val Loss: 0.7526, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 106, Train Loss: 0.5823, Val Loss: 0.7868, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 107, Train Loss: 0.5666, Val Loss: 0.7118, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 108, Train Loss: 0.5667, Val Loss: 0.7251, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 109, Train Loss: 0.5639, Val Loss: 0.7151, F1 Micro: 0.6292, F1 Macro: 0.6168, Accuracy: 0.6292\n","Epoch 110, Train Loss: 0.5732, Val Loss: 0.7496, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 111, Train Loss: 0.5651, Val Loss: 0.7617, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 112, Train Loss: 0.5649, Val Loss: 0.7650, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 113, Train Loss: 0.5658, Val Loss: 0.7986, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 114, Train Loss: 0.5573, Val Loss: 0.7684, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 115, Train Loss: 0.5629, Val Loss: 0.8019, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 116, Train Loss: 0.5705, Val Loss: 0.7429, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 117, Train Loss: 0.5724, Val Loss: 0.7786, F1 Micro: 0.6292, F1 Macro: 0.6027, Accuracy: 0.6292\n","Epoch 118, Train Loss: 0.5763, Val Loss: 0.8142, F1 Micro: 0.6124, F1 Macro: 0.5777, Accuracy: 0.6124\n","Epoch 119, Train Loss: 0.5608, Val Loss: 0.7180, F1 Micro: 0.6180, F1 Macro: 0.6140, Accuracy: 0.6180\n","Epoch 120, Train Loss: 0.5642, Val Loss: 0.7776, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 121, Train Loss: 0.5686, Val Loss: 0.7633, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 122, Train Loss: 0.5660, Val Loss: 0.8299, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 123, Train Loss: 0.5615, Val Loss: 0.7481, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 124, Train Loss: 0.5606, Val Loss: 0.7637, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 125, Train Loss: 0.5691, Val Loss: 0.7231, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 126, Train Loss: 0.5656, Val Loss: 0.7738, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 127, Train Loss: 0.5519, Val Loss: 0.7527, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 128, Train Loss: 0.5559, Val Loss: 0.8255, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 129, Train Loss: 0.5576, Val Loss: 0.7731, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 130, Train Loss: 0.5652, Val Loss: 0.8198, F1 Micro: 0.6124, F1 Macro: 0.5714, Accuracy: 0.6124\n","Epoch 131, Train Loss: 0.5643, Val Loss: 0.8085, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 132, Train Loss: 0.5754, Val Loss: 0.7581, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 133, Train Loss: 0.5597, Val Loss: 0.7817, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 134, Train Loss: 0.5592, Val Loss: 0.7413, F1 Micro: 0.6461, F1 Macro: 0.6350, Accuracy: 0.6461\n","Epoch 135, Train Loss: 0.5691, Val Loss: 0.6979, F1 Micro: 0.6236, F1 Macro: 0.6160, Accuracy: 0.6236\n","Epoch 136, Train Loss: 0.5615, Val Loss: 0.7391, F1 Micro: 0.6124, F1 Macro: 0.6002, Accuracy: 0.6124\n","Epoch 137, Train Loss: 0.5558, Val Loss: 0.7356, F1 Micro: 0.6236, F1 Macro: 0.6147, Accuracy: 0.6236\n","Epoch 138, Train Loss: 0.5649, Val Loss: 0.7269, F1 Micro: 0.6180, F1 Macro: 0.6140, Accuracy: 0.6180\n","Epoch 139, Train Loss: 0.5688, Val Loss: 0.7348, F1 Micro: 0.6348, F1 Macro: 0.6275, Accuracy: 0.6348\n","Epoch 140, Train Loss: 0.5685, Val Loss: 0.7277, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 141, Train Loss: 0.5525, Val Loss: 0.8685, F1 Micro: 0.6124, F1 Macro: 0.5746, Accuracy: 0.6124\n","Epoch 142, Train Loss: 0.5667, Val Loss: 0.7543, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 143, Train Loss: 0.5628, Val Loss: 0.8682, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 144, Train Loss: 0.5665, Val Loss: 0.7872, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 145, Train Loss: 0.5667, Val Loss: 0.7644, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 146, Train Loss: 0.5599, Val Loss: 0.7376, F1 Micro: 0.6180, F1 Macro: 0.6068, Accuracy: 0.6180\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7559, Val Loss: 0.7300, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 2, Train Loss: 0.7281, Val Loss: 0.7133, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 3, Train Loss: 0.7107, Val Loss: 0.7014, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 4, Train Loss: 0.6978, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6894, Val Loss: 0.6874, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6826, Val Loss: 0.6842, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6799, Val Loss: 0.6819, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6752, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6758, Val Loss: 0.6801, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6719, Val Loss: 0.6799, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6741, Val Loss: 0.6798, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6704, Val Loss: 0.6798, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6734, Val Loss: 0.6800, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6733, Val Loss: 0.6800, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6696, Val Loss: 0.6801, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6694, Val Loss: 0.6803, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6694, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6692, Val Loss: 0.6806, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6732, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6692, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 21, Train Loss: 0.6691, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6690, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6733, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 24, Train Loss: 0.6732, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6733, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6691, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.6732, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6732, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6732, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6692, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6732, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6692, Val Loss: 0.6806, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6691, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6692, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6690, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6690, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6690, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.6732, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.6690, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 40, Train Loss: 0.6690, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6690, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6690, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.6732, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.6689, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6732, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.6731, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6690, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6690, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6691, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6690, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 51, Train Loss: 0.6692, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 52, Train Loss: 0.6708, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 53, Train Loss: 0.6733, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 54, Train Loss: 0.6691, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.6946895988952357\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6639, Val Loss: 0.6280, F1 Micro: 0.6704, F1 Macro: 0.5589, Accuracy: 0.6704\n","Epoch 2, Train Loss: 0.6382, Val Loss: 0.6363, F1 Micro: 0.7542, F1 Macro: 0.7052, Accuracy: 0.7542\n","Epoch 3, Train Loss: 0.6451, Val Loss: 0.6046, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 4, Train Loss: 0.6417, Val Loss: 0.6057, F1 Micro: 0.6760, F1 Macro: 0.6070, Accuracy: 0.6760\n","Epoch 5, Train Loss: 0.6319, Val Loss: 0.6124, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 6, Train Loss: 0.6361, Val Loss: 0.6015, F1 Micro: 0.7374, F1 Macro: 0.6989, Accuracy: 0.7374\n","Epoch 7, Train Loss: 0.6356, Val Loss: 0.6105, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.6291, Val Loss: 0.5979, F1 Micro: 0.7430, F1 Macro: 0.7067, Accuracy: 0.7430\n","Epoch 9, Train Loss: 0.6311, Val Loss: 0.6033, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.6268, Val Loss: 0.6080, F1 Micro: 0.7095, F1 Macro: 0.6880, Accuracy: 0.7095\n","Epoch 11, Train Loss: 0.6288, Val Loss: 0.6003, F1 Micro: 0.7598, F1 Macro: 0.7069, Accuracy: 0.7598\n","Epoch 12, Train Loss: 0.6302, Val Loss: 0.6131, F1 Micro: 0.7039, F1 Macro: 0.6810, Accuracy: 0.7039\n","Epoch 13, Train Loss: 0.6262, Val Loss: 0.6087, F1 Micro: 0.6983, F1 Macro: 0.5868, Accuracy: 0.6983\n","Epoch 14, Train Loss: 0.6205, Val Loss: 0.6022, F1 Micro: 0.7095, F1 Macro: 0.6860, Accuracy: 0.7095\n","Epoch 15, Train Loss: 0.6209, Val Loss: 0.6014, F1 Micro: 0.7039, F1 Macro: 0.6718, Accuracy: 0.7039\n","Epoch 16, Train Loss: 0.6253, Val Loss: 0.5982, F1 Micro: 0.6816, F1 Macro: 0.6069, Accuracy: 0.6816\n","Epoch 17, Train Loss: 0.6232, Val Loss: 0.5934, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 18, Train Loss: 0.6186, Val Loss: 0.5896, F1 Micro: 0.7207, F1 Macro: 0.6840, Accuracy: 0.7207\n","Epoch 19, Train Loss: 0.6138, Val Loss: 0.5974, F1 Micro: 0.6927, F1 Macro: 0.5888, Accuracy: 0.6927\n","Epoch 20, Train Loss: 0.6164, Val Loss: 0.6245, F1 Micro: 0.6480, F1 Macro: 0.6416, Accuracy: 0.6480\n","Epoch 21, Train Loss: 0.6257, Val Loss: 0.5994, F1 Micro: 0.6704, F1 Macro: 0.6548, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6881, Val Loss: 0.7062, F1 Micro: 0.4382, F1 Macro: 0.4051, Accuracy: 0.4382\n","Epoch 2, Train Loss: 0.6690, Val Loss: 0.6008, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 3, Train Loss: 0.6372, Val Loss: 0.5940, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6233, Val Loss: 0.6128, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 5, Train Loss: 0.6363, Val Loss: 0.6272, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6442, Val Loss: 0.6072, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.6327, Val Loss: 0.6177, F1 Micro: 0.6348, F1 Macro: 0.6297, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6315, Val Loss: 0.6010, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6285, Val Loss: 0.6660, F1 Micro: 0.5506, F1 Macro: 0.5506, Accuracy: 0.5506\n","Epoch 10, Train Loss: 0.6371, Val Loss: 0.6042, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 11, Train Loss: 0.6191, Val Loss: 0.6014, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 12, Train Loss: 0.6191, Val Loss: 0.6125, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6124, Val Loss: 0.5962, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.6102, Val Loss: 0.6173, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7433, Val Loss: 0.7257, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 2, Train Loss: 0.7266, Val Loss: 0.7158, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 3, Train Loss: 0.7159, Val Loss: 0.7077, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 4, Train Loss: 0.7075, Val Loss: 0.7003, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 5, Train Loss: 0.6999, Val Loss: 0.6960, F1 Micro: 0.3764, F1 Macro: 0.2735, Accuracy: 0.3764\n","Epoch 6, Train Loss: 0.6943, Val Loss: 0.6923, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6897, Val Loss: 0.6909, F1 Micro: 0.5787, F1 Macro: 0.4007, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.6836, Val Loss: 0.6846, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6887, Val Loss: 0.6846, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6805, Val Loss: 0.6833, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6790, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6777, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6761, Val Loss: 0.6814, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6753, Val Loss: 0.6811, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6743, Val Loss: 0.6810, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6731, Val Loss: 0.6809, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6775, Val Loss: 0.8044, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6557, Val Loss: 0.7516, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6432, Val Loss: 0.7325, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6442, Val Loss: 0.7194, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6394, Val Loss: 0.7409, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6276, Val Loss: 0.7126, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6269, Val Loss: 0.7389, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6280, Val Loss: 0.7081, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6427, Val Loss: 0.7075, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6474, Val Loss: 0.7056, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6420, Val Loss: 0.9655, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7277, Val Loss: 0.7073, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 2, Train Loss: 0.7112, Val Loss: 0.7014, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 3, Train Loss: 0.7029, Val Loss: 0.6962, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 4, Train Loss: 0.6954, Val Loss: 0.7003, F1 Micro: 0.4213, F1 Macro: 0.4172, Accuracy: 0.4213\n","Epoch 5, Train Loss: 0.6904, Val Loss: 0.6901, F1 Micro: 0.5955, F1 Macro: 0.4865, Accuracy: 0.5955\n","Epoch 6, Train Loss: 0.6846, Val Loss: 0.6876, F1 Micro: 0.6461, F1 Macro: 0.5132, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6817, Val Loss: 0.6858, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6772, Val Loss: 0.6854, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6722, Val Loss: 0.6863, F1 Micro: 0.5899, F1 Macro: 0.5070, Accuracy: 0.5899\n","Epoch 10, Train Loss: 0.6701, Val Loss: 0.6820, F1 Micro: 0.5955, F1 Macro: 0.4931, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6690, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.4903, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6650, Val Loss: 0.6819, F1 Micro: 0.6461, F1 Macro: 0.4875, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.6643, Val Loss: 0.6852, F1 Micro: 0.5955, F1 Macro: 0.5053, Accuracy: 0.5955\n","Epoch 14, Train Loss: 0.6614, Val Loss: 0.6816, F1 Micro: 0.6011, F1 Macro: 0.4903, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6620, Val Loss: 0.6794, F1 Micro: 0.6404, F1 Macro: 0.5094, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6601, Val Loss: 0.6792, F1 Micro: 0.6180, F1 Macro: 0.5016, Accuracy: 0.6180\n","Epoch 17, Train Loss: 0.6575, Val Loss: 0.6831, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.6553260937794237\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7208, Val Loss: 0.6699, F1 Micro: 0.6760, F1 Macro: 0.6334, Accuracy: 0.6760\n","Epoch 2, Train Loss: 0.6794, Val Loss: 0.7065, F1 Micro: 0.4413, F1 Macro: 0.4191, Accuracy: 0.4413\n","Epoch 3, Train Loss: 0.6681, Val Loss: 0.6115, F1 Micro: 0.6536, F1 Macro: 0.6429, Accuracy: 0.6536\n","Epoch 4, Train Loss: 0.6579, Val Loss: 0.6002, F1 Micro: 0.6369, F1 Macro: 0.6290, Accuracy: 0.6369\n","Epoch 5, Train Loss: 0.6714, Val Loss: 0.5970, F1 Micro: 0.6816, F1 Macro: 0.6497, Accuracy: 0.6816\n","Epoch 6, Train Loss: 0.6525, Val Loss: 0.6510, F1 Micro: 0.5922, F1 Macro: 0.5922, Accuracy: 0.5922\n","Epoch 7, Train Loss: 0.6553, Val Loss: 0.5946, F1 Micro: 0.6760, F1 Macro: 0.6631, Accuracy: 0.6760\n","Epoch 8, Train Loss: 0.6470, Val Loss: 0.5910, F1 Micro: 0.6816, F1 Macro: 0.6590, Accuracy: 0.6816\n","Epoch 9, Train Loss: 0.6418, Val Loss: 0.7153, F1 Micro: 0.4134, F1 Macro: 0.3593, Accuracy: 0.4134\n","Epoch 10, Train Loss: 0.6561, Val Loss: 0.6115, F1 Micro: 0.6760, F1 Macro: 0.6232, Accuracy: 0.6760\n","Epoch 11, Train Loss: 0.6266, Val Loss: 0.6157, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 12, Train Loss: 0.6288, Val Loss: 0.6491, F1 Micro: 0.6816, F1 Macro: 0.5970, Accuracy: 0.6816\n","Epoch 13, Train Loss: 0.6253, Val Loss: 0.5914, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 14, Train Loss: 0.6451, Val Loss: 0.5882, F1 Micro: 0.7039, F1 Macro: 0.6867, Accuracy: 0.7039\n","Epoch 15, Train Loss: 0.6393, Val Loss: 0.5890, F1 Micro: 0.6816, F1 Macro: 0.6648, Accuracy: 0.6816\n","Epoch 16, Train Loss: 0.6293, Val Loss: 0.6088, F1 Micro: 0.7151, F1 Macro: 0.6866, Accuracy: 0.7151\n","Epoch 17, Train Loss: 0.6293, Val Loss: 0.6400, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 18, Train Loss: 0.6096, Val Loss: 0.6733, F1 Micro: 0.5307, F1 Macro: 0.5242, Accuracy: 0.5307\n","Epoch 19, Train Loss: 0.6214, Val Loss: 0.6204, F1 Micro: 0.6201, F1 Macro: 0.6181, Accuracy: 0.6201\n","Epoch 20, Train Loss: 0.6274, Val Loss: 0.5965, F1 Micro: 0.6816, F1 Macro: 0.6442, Accuracy: 0.6816\n","Epoch 21, Train Loss: 0.6247, Val Loss: 0.6748, F1 Micro: 0.5363, F1 Macro: 0.5305, Accuracy: 0.5363\n","Epoch 22, Train Loss: 0.6199, Val Loss: 0.6290, F1 Micro: 0.6145, F1 Macro: 0.6122, Accuracy: 0.6145\n","Epoch 23, Train Loss: 0.6140, Val Loss: 0.5971, F1 Micro: 0.6536, F1 Macro: 0.6399, Accuracy: 0.6536\n","Epoch 24, Train Loss: 0.6261, Val Loss: 0.6422, F1 Micro: 0.5922, F1 Macro: 0.5921, Accuracy: 0.5922\n","Epoch 25, Train Loss: 0.6186, Val Loss: 0.5895, F1 Micro: 0.6760, F1 Macro: 0.6497, Accuracy: 0.6760\n","Epoch 26, Train Loss: 0.6259, Val Loss: 0.5925, F1 Micro: 0.6927, F1 Macro: 0.6689, Accuracy: 0.6927\n","Epoch 27, Train Loss: 0.6151, Val Loss: 0.5888, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 28, Train Loss: 0.6064, Val Loss: 0.6153, F1 Micro: 0.6034, F1 Macro: 0.5919, Accuracy: 0.6034\n","Epoch 29, Train Loss: 0.6316, Val Loss: 0.5908, F1 Micro: 0.6872, F1 Macro: 0.6595, Accuracy: 0.6872\n","Epoch 30, Train Loss: 0.6108, Val Loss: 0.6030, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 31, Train Loss: 0.6212, Val Loss: 0.5946, F1 Micro: 0.7039, F1 Macro: 0.6718, Accuracy: 0.7039\n","Epoch 32, Train Loss: 0.6239, Val Loss: 0.6029, F1 Micro: 0.6983, F1 Macro: 0.6557, Accuracy: 0.6983\n","Epoch 33, Train Loss: 0.6167, Val Loss: 0.6385, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 34, Train Loss: 0.6165, Val Loss: 0.6102, F1 Micro: 0.7039, F1 Macro: 0.6429, Accuracy: 0.7039\n","Epoch 35, Train Loss: 0.6305, Val Loss: 0.5884, F1 Micro: 0.6704, F1 Macro: 0.6400, Accuracy: 0.6704\n","Epoch 36, Train Loss: 0.6150, Val Loss: 0.6038, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 37, Train Loss: 0.6217, Val Loss: 0.5974, F1 Micro: 0.6816, F1 Macro: 0.6546, Accuracy: 0.6816\n","Epoch 38, Train Loss: 0.6257, Val Loss: 0.5962, F1 Micro: 0.6536, F1 Macro: 0.6382, Accuracy: 0.6536\n","Epoch 39, Train Loss: 0.6222, Val Loss: 0.6096, F1 Micro: 0.6201, F1 Macro: 0.6137, Accuracy: 0.6201\n","Epoch 40, Train Loss: 0.6083, Val Loss: 0.6072, F1 Micro: 0.6648, F1 Macro: 0.6601, Accuracy: 0.6648\n","Epoch 41, Train Loss: 0.6123, Val Loss: 0.5975, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 42, Train Loss: 0.6207, Val Loss: 0.5905, F1 Micro: 0.6927, F1 Macro: 0.6667, Accuracy: 0.6927\n","Epoch 43, Train Loss: 0.6018, Val Loss: 0.5986, F1 Micro: 0.6816, F1 Macro: 0.6546, Accuracy: 0.6816\n","Epoch 44, Train Loss: 0.6202, Val Loss: 0.5954, F1 Micro: 0.6927, F1 Macro: 0.6644, Accuracy: 0.6927\n","Epoch 45, Train Loss: 0.6132, Val Loss: 0.6043, F1 Micro: 0.6425, F1 Macro: 0.6265, Accuracy: 0.6425\n","Epoch 46, Train Loss: 0.6126, Val Loss: 0.6132, F1 Micro: 0.6592, F1 Macro: 0.6530, Accuracy: 0.6592\n","Epoch 47, Train Loss: 0.6248, Val Loss: 0.5927, F1 Micro: 0.6760, F1 Macro: 0.6520, Accuracy: 0.6760\n","Epoch 48, Train Loss: 0.6157, Val Loss: 0.5992, F1 Micro: 0.6592, F1 Macro: 0.6413, Accuracy: 0.6592\n","Epoch 49, Train Loss: 0.6104, Val Loss: 0.6031, F1 Micro: 0.6536, F1 Macro: 0.6364, Accuracy: 0.6536\n","Epoch 50, Train Loss: 0.6079, Val Loss: 0.6136, F1 Micro: 0.6816, F1 Macro: 0.6470, Accuracy: 0.6816\n","Epoch 51, Train Loss: 0.6241, Val Loss: 0.5995, F1 Micro: 0.6872, F1 Macro: 0.6618, Accuracy: 0.6872\n","Epoch 52, Train Loss: 0.6075, Val Loss: 0.5982, F1 Micro: 0.6872, F1 Macro: 0.6680, Accuracy: 0.6872\n","Epoch 53, Train Loss: 0.6068, Val Loss: 0.6012, F1 Micro: 0.6425, F1 Macro: 0.6246, Accuracy: 0.6425\n","Epoch 54, Train Loss: 0.6037, Val Loss: 0.5888, F1 Micro: 0.6704, F1 Macro: 0.6425, Accuracy: 0.6704\n","Epoch 55, Train Loss: 0.6140, Val Loss: 0.6208, F1 Micro: 0.6536, F1 Macro: 0.6497, Accuracy: 0.6536\n","Epoch 56, Train Loss: 0.6127, Val Loss: 0.5949, F1 Micro: 0.6648, F1 Macro: 0.6352, Accuracy: 0.6648\n","Epoch 57, Train Loss: 0.6215, Val Loss: 0.6444, F1 Micro: 0.6034, F1 Macro: 0.6032, Accuracy: 0.6034\n","Epoch 58, Train Loss: 0.6137, Val Loss: 0.5951, F1 Micro: 0.6648, F1 Macro: 0.6377, Accuracy: 0.6648\n","Epoch 59, Train Loss: 0.6161, Val Loss: 0.5956, F1 Micro: 0.6760, F1 Macro: 0.6520, Accuracy: 0.6760\n","Epoch 60, Train Loss: 0.6161, Val Loss: 0.5983, F1 Micro: 0.6816, F1 Macro: 0.6696, Accuracy: 0.6816\n","Epoch 61, Train Loss: 0.6059, Val Loss: 0.5960, F1 Micro: 0.6704, F1 Macro: 0.6512, Accuracy: 0.6704\n","Epoch 62, Train Loss: 0.6115, Val Loss: 0.5976, F1 Micro: 0.6480, F1 Macro: 0.6314, Accuracy: 0.6480\n","Epoch 63, Train Loss: 0.6145, Val Loss: 0.6002, F1 Micro: 0.6872, F1 Macro: 0.6732, Accuracy: 0.6872\n","Epoch 64, Train Loss: 0.6089, Val Loss: 0.6225, F1 Micro: 0.6369, F1 Macro: 0.6323, Accuracy: 0.6369\n","Epoch 65, Train Loss: 0.6178, Val Loss: 0.5982, F1 Micro: 0.6760, F1 Macro: 0.6631, Accuracy: 0.6760\n","Epoch 66, Train Loss: 0.6167, Val Loss: 0.6197, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 67, Train Loss: 0.6014, Val Loss: 0.6016, F1 Micro: 0.6983, F1 Macro: 0.6890, Accuracy: 0.6983\n","Epoch 68, Train Loss: 0.6203, Val Loss: 0.6103, F1 Micro: 0.6480, F1 Macro: 0.6379, Accuracy: 0.6480\n","Epoch 69, Train Loss: 0.6125, Val Loss: 0.6121, F1 Micro: 0.6592, F1 Macro: 0.6557, Accuracy: 0.6592\n","Epoch 70, Train Loss: 0.6097, Val Loss: 0.5962, F1 Micro: 0.6536, F1 Macro: 0.6345, Accuracy: 0.6536\n","Epoch 71, Train Loss: 0.6064, Val Loss: 0.6124, F1 Micro: 0.6704, F1 Macro: 0.6633, Accuracy: 0.6704\n","Epoch 72, Train Loss: 0.6148, Val Loss: 0.5956, F1 Micro: 0.6480, F1 Macro: 0.6232, Accuracy: 0.6480\n","Epoch 73, Train Loss: 0.6040, Val Loss: 0.5932, F1 Micro: 0.6592, F1 Macro: 0.6449, Accuracy: 0.6592\n","Epoch 74, Train Loss: 0.6089, Val Loss: 0.6208, F1 Micro: 0.6592, F1 Macro: 0.6557, Accuracy: 0.6592\n","Epoch 75, Train Loss: 0.6147, Val Loss: 0.5995, F1 Micro: 0.6648, F1 Macro: 0.6422, Accuracy: 0.6648\n","Epoch 76, Train Loss: 0.6016, Val Loss: 0.5985, F1 Micro: 0.6592, F1 Macro: 0.6351, Accuracy: 0.6592\n","Epoch 77, Train Loss: 0.6162, Val Loss: 0.6039, F1 Micro: 0.6872, F1 Macro: 0.6819, Accuracy: 0.6872\n","Epoch 78, Train Loss: 0.5977, Val Loss: 0.6229, F1 Micro: 0.6480, F1 Macro: 0.6436, Accuracy: 0.6480\n","Epoch 79, Train Loss: 0.6113, Val Loss: 0.5925, F1 Micro: 0.6760, F1 Macro: 0.6615, Accuracy: 0.6760\n","Epoch 80, Train Loss: 0.6077, Val Loss: 0.6297, F1 Micro: 0.6034, F1 Macro: 0.6032, Accuracy: 0.6034\n","Epoch 81, Train Loss: 0.6077, Val Loss: 0.6057, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 82, Train Loss: 0.6113, Val Loss: 0.6062, F1 Micro: 0.6760, F1 Macro: 0.6365, Accuracy: 0.6760\n","Epoch 83, Train Loss: 0.6016, Val Loss: 0.5947, F1 Micro: 0.6592, F1 Macro: 0.6413, Accuracy: 0.6592\n","Epoch 84, Train Loss: 0.5964, Val Loss: 0.5920, F1 Micro: 0.6983, F1 Macro: 0.6557, Accuracy: 0.6983\n","Epoch 85, Train Loss: 0.6093, Val Loss: 0.5927, F1 Micro: 0.6704, F1 Macro: 0.6425, Accuracy: 0.6704\n","Epoch 86, Train Loss: 0.6016, Val Loss: 0.5906, F1 Micro: 0.6648, F1 Macro: 0.6481, Accuracy: 0.6648\n","Epoch 87, Train Loss: 0.5972, Val Loss: 0.5929, F1 Micro: 0.6648, F1 Macro: 0.6377, Accuracy: 0.6648\n","Epoch 88, Train Loss: 0.6067, Val Loss: 0.6352, F1 Micro: 0.6313, F1 Macro: 0.6307, Accuracy: 0.6313\n","Epoch 89, Train Loss: 0.6191, Val Loss: 0.5933, F1 Micro: 0.6704, F1 Macro: 0.6512, Accuracy: 0.6704\n","Epoch 90, Train Loss: 0.6138, Val Loss: 0.6263, F1 Micro: 0.6257, F1 Macro: 0.6249, Accuracy: 0.6257\n","Epoch 91, Train Loss: 0.6053, Val Loss: 0.5948, F1 Micro: 0.6592, F1 Macro: 0.6394, Accuracy: 0.6592\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7064, Val Loss: 0.7288, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 2, Train Loss: 0.6779, Val Loss: 0.6195, F1 Micro: 0.6067, F1 Macro: 0.6035, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6754, Val Loss: 0.6477, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 4, Train Loss: 0.6950, Val Loss: 0.6079, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 5, Train Loss: 0.6486, Val Loss: 0.6102, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 6, Train Loss: 0.6408, Val Loss: 0.5938, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 7, Train Loss: 0.6406, Val Loss: 0.6329, F1 Micro: 0.6011, F1 Macro: 0.5975, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6325, Val Loss: 0.6685, F1 Micro: 0.5393, F1 Macro: 0.5388, Accuracy: 0.5393\n","Epoch 9, Train Loss: 0.6380, Val Loss: 0.6206, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.6340, Val Loss: 0.5923, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.6232, Val Loss: 0.6984, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6358, Val Loss: 0.5884, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 13, Train Loss: 0.6292, Val Loss: 0.5915, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 14, Train Loss: 0.6306, Val Loss: 0.6019, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6367, Val Loss: 0.5776, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 16, Train Loss: 0.6287, Val Loss: 0.6325, F1 Micro: 0.6067, F1 Macro: 0.6027, Accuracy: 0.6067\n","Epoch 17, Train Loss: 0.6183, Val Loss: 0.6290, F1 Micro: 0.6067, F1 Macro: 0.6017, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6297, Val Loss: 0.6412, F1 Micro: 0.6011, F1 Macro: 0.5975, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6359, Val Loss: 0.5926, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 20, Train Loss: 0.6267, Val Loss: 0.6210, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 21, Train Loss: 0.6244, Val Loss: 0.6190, F1 Micro: 0.6404, F1 Macro: 0.6359, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6144, Val Loss: 0.6005, F1 Micro: 0.6404, F1 Macro: 0.6299, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6106, Val Loss: 0.5754, F1 Micro: 0.7584, F1 Macro: 0.7286, Accuracy: 0.7584\n","Epoch 24, Train Loss: 0.6224, Val Loss: 0.6048, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6246, Val Loss: 0.5875, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 26, Train Loss: 0.6291, Val Loss: 0.6017, F1 Micro: 0.6404, F1 Macro: 0.6299, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6238, Val Loss: 0.5911, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 28, Train Loss: 0.6176, Val Loss: 0.5873, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 29, Train Loss: 0.6155, Val Loss: 0.5823, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 30, Train Loss: 0.6185, Val Loss: 0.6056, F1 Micro: 0.6629, F1 Macro: 0.6502, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.6068, Val Loss: 0.5789, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 32, Train Loss: 0.6162, Val Loss: 0.6532, F1 Micro: 0.5843, F1 Macro: 0.5766, Accuracy: 0.5843\n","Epoch 33, Train Loss: 0.6451, Val Loss: 0.6341, F1 Micro: 0.6292, F1 Macro: 0.6262, Accuracy: 0.6292\n","Epoch 34, Train Loss: 0.6227, Val Loss: 0.6000, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 35, Train Loss: 0.6146, Val Loss: 0.6020, F1 Micro: 0.6629, F1 Macro: 0.6502, Accuracy: 0.6629\n","Epoch 36, Train Loss: 0.6192, Val Loss: 0.6135, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 37, Train Loss: 0.6214, Val Loss: 0.6328, F1 Micro: 0.6124, F1 Macro: 0.6114, Accuracy: 0.6124\n","Epoch 38, Train Loss: 0.6226, Val Loss: 0.6240, F1 Micro: 0.6124, F1 Macro: 0.6046, Accuracy: 0.6124\n","Epoch 39, Train Loss: 0.6198, Val Loss: 0.5847, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 40, Train Loss: 0.6165, Val Loss: 0.5833, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 41, Train Loss: 0.6101, Val Loss: 0.6134, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.6129, Val Loss: 0.5940, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 43, Train Loss: 0.6154, Val Loss: 0.6006, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 44, Train Loss: 0.6075, Val Loss: 0.6251, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 45, Train Loss: 0.6151, Val Loss: 0.6107, F1 Micro: 0.6854, F1 Macro: 0.6796, Accuracy: 0.6854\n","Epoch 46, Train Loss: 0.6059, Val Loss: 0.6060, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6116, Val Loss: 0.5915, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.6166, Val Loss: 0.6143, F1 Micro: 0.6292, F1 Macro: 0.6223, Accuracy: 0.6292\n","Epoch 49, Train Loss: 0.6146, Val Loss: 0.6069, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 50, Train Loss: 0.6091, Val Loss: 0.6045, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6087, Val Loss: 0.5934, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 52, Train Loss: 0.6092, Val Loss: 0.5785, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 53, Train Loss: 0.6138, Val Loss: 0.6203, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 54, Train Loss: 0.6133, Val Loss: 0.5973, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 55, Train Loss: 0.6120, Val Loss: 0.5828, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 56, Train Loss: 0.6155, Val Loss: 0.6189, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 57, Train Loss: 0.6079, Val Loss: 0.6029, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 58, Train Loss: 0.6042, Val Loss: 0.6377, F1 Micro: 0.6348, F1 Macro: 0.6339, Accuracy: 0.6348\n","Epoch 59, Train Loss: 0.6098, Val Loss: 0.5986, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 60, Train Loss: 0.6081, Val Loss: 0.6460, F1 Micro: 0.6292, F1 Macro: 0.6285, Accuracy: 0.6292\n","Epoch 61, Train Loss: 0.6143, Val Loss: 0.6072, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 62, Train Loss: 0.5980, Val Loss: 0.5938, F1 Micro: 0.7135, F1 Macro: 0.6236, Accuracy: 0.7135\n","Epoch 63, Train Loss: 0.6138, Val Loss: 0.5934, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 64, Train Loss: 0.5987, Val Loss: 0.6079, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.6084, Val Loss: 0.5884, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 66, Train Loss: 0.6036, Val Loss: 0.5994, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 67, Train Loss: 0.6045, Val Loss: 0.5915, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 68, Train Loss: 0.6088, Val Loss: 0.5902, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 69, Train Loss: 0.6079, Val Loss: 0.5817, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 70, Train Loss: 0.6034, Val Loss: 0.5962, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 71, Train Loss: 0.5982, Val Loss: 0.6278, F1 Micro: 0.6348, F1 Macro: 0.6262, Accuracy: 0.6348\n","Epoch 72, Train Loss: 0.6129, Val Loss: 0.6257, F1 Micro: 0.6348, F1 Macro: 0.6329, Accuracy: 0.6348\n","Epoch 73, Train Loss: 0.6042, Val Loss: 0.6067, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7226, Val Loss: 0.6017, F1 Micro: 0.7135, F1 Macro: 0.7045, Accuracy: 0.7135\n","Epoch 2, Train Loss: 0.6744, Val Loss: 0.6223, F1 Micro: 0.7528, F1 Macro: 0.7076, Accuracy: 0.7528\n","Epoch 3, Train Loss: 0.6591, Val Loss: 0.6207, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 4, Train Loss: 0.6528, Val Loss: 0.6327, F1 Micro: 0.6292, F1 Macro: 0.6292, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6740, Val Loss: 0.6571, F1 Micro: 0.5449, F1 Macro: 0.5408, Accuracy: 0.5449\n","Epoch 6, Train Loss: 0.6490, Val Loss: 0.6341, F1 Micro: 0.6461, F1 Macro: 0.6458, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6476, Val Loss: 0.6081, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 8, Train Loss: 0.6610, Val Loss: 0.6101, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.6718, Val Loss: 0.5995, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 10, Train Loss: 0.6603, Val Loss: 0.6195, F1 Micro: 0.7247, F1 Macro: 0.7149, Accuracy: 0.7247\n","Epoch 11, Train Loss: 0.6436, Val Loss: 0.6308, F1 Micro: 0.6629, F1 Macro: 0.6619, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6654, Val Loss: 0.6242, F1 Micro: 0.7022, F1 Macro: 0.6972, Accuracy: 0.7022\n","Epoch 13, Train Loss: 0.6320, Val Loss: 0.6155, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 14, Train Loss: 0.6566, Val Loss: 0.6127, F1 Micro: 0.7022, F1 Macro: 0.6888, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6410, Val Loss: 0.6101, F1 Micro: 0.7303, F1 Macro: 0.7160, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.6404, Val Loss: 0.6241, F1 Micro: 0.6685, F1 Macro: 0.6639, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6449, Val Loss: 0.6252, F1 Micro: 0.6798, F1 Macro: 0.6684, Accuracy: 0.6798\n","Epoch 18, Train Loss: 0.6532, Val Loss: 0.6179, F1 Micro: 0.6854, F1 Macro: 0.6762, Accuracy: 0.6854\n","Epoch 19, Train Loss: 0.6321, Val Loss: 0.6302, F1 Micro: 0.6798, F1 Macro: 0.6761, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.6445, Val Loss: 0.6432, F1 Micro: 0.6404, F1 Macro: 0.6393, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6453, Val Loss: 0.6719, F1 Micro: 0.5787, F1 Macro: 0.5738, Accuracy: 0.5787\n","Epoch 22, Train Loss: 0.6516, Val Loss: 0.6432, F1 Micro: 0.6854, F1 Macro: 0.6844, Accuracy: 0.6854\n","Epoch 23, Train Loss: 0.6499, Val Loss: 0.6129, F1 Micro: 0.7360, F1 Macro: 0.6860, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6283, Val Loss: 0.6106, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6350, Val Loss: 0.6211, F1 Micro: 0.6854, F1 Macro: 0.6749, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6460, Val Loss: 0.6518, F1 Micro: 0.6573, F1 Macro: 0.6560, Accuracy: 0.6573\n","Epoch 27, Train Loss: 0.6351, Val Loss: 0.6092, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Epoch 28, Train Loss: 0.6429, Val Loss: 0.6204, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 29, Train Loss: 0.6388, Val Loss: 0.6194, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 30, Train Loss: 0.6220, Val Loss: 0.6398, F1 Micro: 0.6629, F1 Macro: 0.6614, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.6356, Val Loss: 0.6182, F1 Micro: 0.6966, F1 Macro: 0.6865, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6253, Val Loss: 0.6152, F1 Micro: 0.6854, F1 Macro: 0.6735, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.6245, Val Loss: 0.6043, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 34, Train Loss: 0.6243, Val Loss: 0.6623, F1 Micro: 0.7191, F1 Macro: 0.6642, Accuracy: 0.7191\n","Epoch 35, Train Loss: 0.6315, Val Loss: 0.6222, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.6289, Val Loss: 0.6122, F1 Micro: 0.7022, F1 Macro: 0.6888, Accuracy: 0.7022\n","Epoch 37, Train Loss: 0.6329, Val Loss: 0.5962, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 38, Train Loss: 0.6298, Val Loss: 0.5945, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 39, Train Loss: 0.6279, Val Loss: 0.5945, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 40, Train Loss: 0.6257, Val Loss: 0.6413, F1 Micro: 0.6236, F1 Macro: 0.6236, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6370, Val Loss: 0.6072, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 42, Train Loss: 0.6276, Val Loss: 0.6112, F1 Micro: 0.7079, F1 Macro: 0.6981, Accuracy: 0.7079\n","Epoch 43, Train Loss: 0.6401, Val Loss: 0.6107, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 44, Train Loss: 0.6296, Val Loss: 0.6439, F1 Micro: 0.6180, F1 Macro: 0.6175, Accuracy: 0.6180\n","Epoch 45, Train Loss: 0.6316, Val Loss: 0.6150, F1 Micro: 0.6854, F1 Macro: 0.6774, Accuracy: 0.6854\n","Epoch 46, Train Loss: 0.6309, Val Loss: 0.6061, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 47, Train Loss: 0.6317, Val Loss: 0.6474, F1 Micro: 0.6180, F1 Macro: 0.6172, Accuracy: 0.6180\n","Epoch 48, Train Loss: 0.6296, Val Loss: 0.6066, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 49, Train Loss: 0.6271, Val Loss: 0.6259, F1 Micro: 0.6966, F1 Macro: 0.6919, Accuracy: 0.6966\n","Epoch 50, Train Loss: 0.6262, Val Loss: 0.5984, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 51, Train Loss: 0.6327, Val Loss: 0.6056, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 52, Train Loss: 0.6362, Val Loss: 0.6006, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6337, Val Loss: 0.8057, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 2, Train Loss: 0.6134, Val Loss: 0.8120, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 3, Train Loss: 0.6051, Val Loss: 0.7682, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6051, Val Loss: 0.7178, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6109, Val Loss: 0.7381, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6111, Val Loss: 0.7233, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.5977, Val Loss: 0.7939, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.5924, Val Loss: 0.7823, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 9, Train Loss: 0.5895, Val Loss: 0.7149, F1 Micro: 0.6236, F1 Macro: 0.6133, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.5977, Val Loss: 0.7539, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.5930, Val Loss: 0.7352, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 12, Train Loss: 0.5951, Val Loss: 0.8010, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 13, Train Loss: 0.5921, Val Loss: 0.7565, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.5862, Val Loss: 0.7855, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.5840, Val Loss: 0.7207, F1 Micro: 0.6124, F1 Macro: 0.5968, Accuracy: 0.6124\n","Epoch 16, Train Loss: 0.5894, Val Loss: 0.7457, F1 Micro: 0.5730, F1 Macro: 0.5001, Accuracy: 0.5730\n","Epoch 17, Train Loss: 0.5936, Val Loss: 0.7890, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.5841, Val Loss: 0.7370, F1 Micro: 0.6124, F1 Macro: 0.5949, Accuracy: 0.6124\n","Epoch 19, Train Loss: 0.5832, Val Loss: 0.7710, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.5857, Val Loss: 0.7732, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.5874, Val Loss: 0.7176, F1 Micro: 0.6067, F1 Macro: 0.5900, Accuracy: 0.6067\n","Epoch 22, Train Loss: 0.5827, Val Loss: 0.7400, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 23, Train Loss: 0.5769, Val Loss: 0.7895, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 24, Train Loss: 0.5719, Val Loss: 0.7811, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 25, Train Loss: 0.5759, Val Loss: 0.7626, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.5832, Val Loss: 0.7720, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.5721, Val Loss: 0.7608, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 28, Train Loss: 0.5712, Val Loss: 0.7088, F1 Micro: 0.6067, F1 Macro: 0.5995, Accuracy: 0.6067\n","Epoch 29, Train Loss: 0.5705, Val Loss: 0.7721, F1 Micro: 0.5899, F1 Macro: 0.5500, Accuracy: 0.5899\n","Epoch 30, Train Loss: 0.5708, Val Loss: 0.7190, F1 Micro: 0.6404, F1 Macro: 0.6313, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.5666, Val Loss: 0.7420, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 32, Train Loss: 0.5716, Val Loss: 0.7196, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.5677, Val Loss: 0.7264, F1 Micro: 0.5955, F1 Macro: 0.5880, Accuracy: 0.5955\n","Epoch 34, Train Loss: 0.5693, Val Loss: 0.7337, F1 Micro: 0.6292, F1 Macro: 0.6115, Accuracy: 0.6292\n","Epoch 35, Train Loss: 0.5823, Val Loss: 0.7601, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 36, Train Loss: 0.5745, Val Loss: 0.8631, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.5758, Val Loss: 0.7469, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.5620, Val Loss: 0.7046, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.5769, Val Loss: 0.6975, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 40, Train Loss: 0.5729, Val Loss: 0.7283, F1 Micro: 0.5843, F1 Macro: 0.5644, Accuracy: 0.5843\n","Epoch 41, Train Loss: 0.5690, Val Loss: 0.7516, F1 Micro: 0.6067, F1 Macro: 0.5786, Accuracy: 0.6067\n","Epoch 42, Train Loss: 0.5629, Val Loss: 0.7267, F1 Micro: 0.6067, F1 Macro: 0.5936, Accuracy: 0.6067\n","Epoch 43, Train Loss: 0.5690, Val Loss: 0.7257, F1 Micro: 0.6461, F1 Macro: 0.6301, Accuracy: 0.6461\n","Epoch 44, Train Loss: 0.5691, Val Loss: 0.7555, F1 Micro: 0.6517, F1 Macro: 0.6218, Accuracy: 0.6517\n","Epoch 45, Train Loss: 0.5609, Val Loss: 0.7316, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.5631, Val Loss: 0.7469, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 47, Train Loss: 0.5611, Val Loss: 0.7231, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 48, Train Loss: 0.5611, Val Loss: 0.7350, F1 Micro: 0.6124, F1 Macro: 0.6002, Accuracy: 0.6124\n","Epoch 49, Train Loss: 0.5679, Val Loss: 0.7348, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.5643, Val Loss: 0.7470, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.5555, Val Loss: 0.7341, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 52, Train Loss: 0.5551, Val Loss: 0.7581, F1 Micro: 0.6180, F1 Macro: 0.5977, Accuracy: 0.6180\n","Epoch 53, Train Loss: 0.5602, Val Loss: 0.7657, F1 Micro: 0.6011, F1 Macro: 0.5739, Accuracy: 0.6011\n","Epoch 54, Train Loss: 0.5576, Val Loss: 0.7565, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 55, Train Loss: 0.5683, Val Loss: 0.7436, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 56, Train Loss: 0.5661, Val Loss: 0.7636, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 57, Train Loss: 0.5591, Val Loss: 0.8094, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 58, Train Loss: 0.5592, Val Loss: 0.8206, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 59, Train Loss: 0.5579, Val Loss: 0.7566, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 60, Train Loss: 0.5583, Val Loss: 0.7326, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 61, Train Loss: 0.5611, Val Loss: 0.7340, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 62, Train Loss: 0.5567, Val Loss: 0.7295, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 63, Train Loss: 0.5556, Val Loss: 0.7215, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 64, Train Loss: 0.5603, Val Loss: 0.8062, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 65, Train Loss: 0.5596, Val Loss: 0.7078, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 66, Train Loss: 0.5565, Val Loss: 0.7631, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 67, Train Loss: 0.5447, Val Loss: 0.7332, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 68, Train Loss: 0.5545, Val Loss: 0.7237, F1 Micro: 0.6180, F1 Macro: 0.6017, Accuracy: 0.6180\n","Epoch 69, Train Loss: 0.5618, Val Loss: 0.7089, F1 Micro: 0.6348, F1 Macro: 0.6183, Accuracy: 0.6348\n","Epoch 70, Train Loss: 0.5567, Val Loss: 0.7540, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 71, Train Loss: 0.5527, Val Loss: 0.7409, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 72, Train Loss: 0.5397, Val Loss: 0.7515, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 73, Train Loss: 0.5497, Val Loss: 0.6910, F1 Micro: 0.6124, F1 Macro: 0.6018, Accuracy: 0.6124\n","Epoch 74, Train Loss: 0.5576, Val Loss: 0.7425, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 75, Train Loss: 0.5526, Val Loss: 0.7045, F1 Micro: 0.6236, F1 Macro: 0.6147, Accuracy: 0.6236\n","Epoch 76, Train Loss: 0.5507, Val Loss: 0.8254, F1 Micro: 0.6180, F1 Macro: 0.5793, Accuracy: 0.6180\n","Epoch 77, Train Loss: 0.5517, Val Loss: 0.7694, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 78, Train Loss: 0.5467, Val Loss: 0.7509, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 79, Train Loss: 0.5554, Val Loss: 0.7179, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 80, Train Loss: 0.5596, Val Loss: 0.7526, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 81, Train Loss: 0.5516, Val Loss: 0.8160, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 82, Train Loss: 0.5621, Val Loss: 0.7791, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 83, Train Loss: 0.5549, Val Loss: 0.8442, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 84, Train Loss: 0.5572, Val Loss: 0.7223, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 85, Train Loss: 0.5603, Val Loss: 0.7012, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 86, Train Loss: 0.5497, Val Loss: 0.7189, F1 Micro: 0.6011, F1 Macro: 0.5851, Accuracy: 0.6011\n","Epoch 87, Train Loss: 0.5473, Val Loss: 0.7072, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 88, Train Loss: 0.5497, Val Loss: 0.7982, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 89, Train Loss: 0.5466, Val Loss: 0.7423, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 90, Train Loss: 0.5488, Val Loss: 0.7204, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 91, Train Loss: 0.5534, Val Loss: 0.7754, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 92, Train Loss: 0.5487, Val Loss: 0.7390, F1 Micro: 0.6124, F1 Macro: 0.5986, Accuracy: 0.6124\n","Epoch 93, Train Loss: 0.5539, Val Loss: 0.7168, F1 Micro: 0.6236, F1 Macro: 0.6102, Accuracy: 0.6236\n","Epoch 94, Train Loss: 0.5497, Val Loss: 0.7135, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7009, Val Loss: 0.6702, F1 Micro: 0.6124, F1 Macro: 0.4283, Accuracy: 0.6124\n","Epoch 2, Train Loss: 0.6448, Val Loss: 0.7094, F1 Micro: 0.6011, F1 Macro: 0.4903, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6467, Val Loss: 0.6803, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6474, Val Loss: 0.6866, F1 Micro: 0.6011, F1 Macro: 0.4903, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6542, Val Loss: 0.8614, F1 Micro: 0.5955, F1 Macro: 0.4391, Accuracy: 0.5955\n","Epoch 6, Train Loss: 0.6256, Val Loss: 0.7859, F1 Micro: 0.6124, F1 Macro: 0.5111, Accuracy: 0.6124\n","Epoch 7, Train Loss: 0.6314, Val Loss: 0.8611, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6274, Val Loss: 0.7742, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 9, Train Loss: 0.6312, Val Loss: 0.7108, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.6241, Val Loss: 0.7121, F1 Micro: 0.6236, F1 Macro: 0.5369, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6326, Val Loss: 0.7528, F1 Micro: 0.6124, F1 Macro: 0.4172, Accuracy: 0.6124\n","Epoch 12, Train Loss: 0.6229, Val Loss: 0.7492, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6236, Val Loss: 0.7564, F1 Micro: 0.6124, F1 Macro: 0.4055, Accuracy: 0.6124\n","Epoch 14, Train Loss: 0.6229, Val Loss: 0.7067, F1 Micro: 0.6067, F1 Macro: 0.5836, Accuracy: 0.6067\n","Epoch 15, Train Loss: 0.6197, Val Loss: 0.7541, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6120, Val Loss: 0.8151, F1 Micro: 0.6124, F1 Macro: 0.4387, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6220, Val Loss: 0.7790, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6117, Val Loss: 0.7630, F1 Micro: 0.6067, F1 Macro: 0.5008, Accuracy: 0.6067\n","Epoch 19, Train Loss: 0.6081, Val Loss: 0.7248, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.6097, Val Loss: 0.7346, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.6093, Val Loss: 0.7035, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6118, Val Loss: 0.7739, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 23, Train Loss: 0.6236, Val Loss: 0.7820, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 24, Train Loss: 0.6130, Val Loss: 0.7308, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6246, Val Loss: 0.7975, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Epoch 26, Train Loss: 0.6108, Val Loss: 0.7897, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6045, Val Loss: 0.7824, F1 Micro: 0.6517, F1 Macro: 0.6103, Accuracy: 0.6517\n","Epoch 28, Train Loss: 0.5998, Val Loss: 0.7461, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6040, Val Loss: 0.7652, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.5952, Val Loss: 0.7903, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.6027, Val Loss: 0.7372, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6100, Val Loss: 0.7438, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.6028, Val Loss: 0.8090, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 34, Train Loss: 0.5968, Val Loss: 0.7505, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 35, Train Loss: 0.6133, Val Loss: 0.7458, F1 Micro: 0.6461, F1 Macro: 0.6087, Accuracy: 0.6461\n","Epoch 36, Train Loss: 0.5955, Val Loss: 0.7245, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 37, Train Loss: 0.5991, Val Loss: 0.7526, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 38, Train Loss: 0.6027, Val Loss: 0.7715, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 39, Train Loss: 0.6057, Val Loss: 0.7461, F1 Micro: 0.6517, F1 Macro: 0.6036, Accuracy: 0.6517\n","Epoch 40, Train Loss: 0.5994, Val Loss: 0.6889, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 41, Train Loss: 0.6119, Val Loss: 0.7285, F1 Micro: 0.6404, F1 Macro: 0.5977, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6002, Val Loss: 0.7337, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 43, Train Loss: 0.5973, Val Loss: 0.7248, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 44, Train Loss: 0.5944, Val Loss: 0.7116, F1 Micro: 0.6573, F1 Macro: 0.6451, Accuracy: 0.6573\n","Epoch 45, Train Loss: 0.6001, Val Loss: 0.7415, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 46, Train Loss: 0.6033, Val Loss: 0.7344, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6012, Val Loss: 0.7715, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 48, Train Loss: 0.5921, Val Loss: 0.7597, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 49, Train Loss: 0.5977, Val Loss: 0.7087, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 50, Train Loss: 0.5938, Val Loss: 0.7127, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 51, Train Loss: 0.5873, Val Loss: 0.7572, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 52, Train Loss: 0.5982, Val Loss: 0.6986, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 53, Train Loss: 0.5967, Val Loss: 0.7477, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.5909, Val Loss: 0.6958, F1 Micro: 0.6742, F1 Macro: 0.6508, Accuracy: 0.6742\n","Epoch 55, Train Loss: 0.5886, Val Loss: 0.7201, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 56, Train Loss: 0.5912, Val Loss: 0.7020, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 57, Train Loss: 0.6027, Val Loss: 0.7361, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.5960, Val Loss: 0.7681, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.5912, Val Loss: 0.7498, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 60, Train Loss: 0.5903, Val Loss: 0.7270, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.5975, Val Loss: 0.7348, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 62, Train Loss: 0.5901, Val Loss: 0.7043, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 63, Train Loss: 0.5898, Val Loss: 0.7856, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 64, Train Loss: 0.5906, Val Loss: 0.8329, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 65, Train Loss: 0.6017, Val Loss: 0.7519, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 66, Train Loss: 0.5854, Val Loss: 0.7573, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 67, Train Loss: 0.5869, Val Loss: 0.7021, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 68, Train Loss: 0.5890, Val Loss: 0.7179, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 69, Train Loss: 0.5862, Val Loss: 0.7149, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 70, Train Loss: 0.5819, Val Loss: 0.7346, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 71, Train Loss: 0.5936, Val Loss: 0.7363, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 72, Train Loss: 0.5892, Val Loss: 0.7159, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 73, Train Loss: 0.5841, Val Loss: 0.6922, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.5881, Val Loss: 0.7818, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 75, Train Loss: 0.5714, Val Loss: 0.7489, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 76, Train Loss: 0.5860, Val Loss: 0.7504, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.5938, Val Loss: 0.6939, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 78, Train Loss: 0.5918, Val Loss: 0.7601, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 79, Train Loss: 0.5767, Val Loss: 0.7185, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 80, Train Loss: 0.5824, Val Loss: 0.6895, F1 Micro: 0.6404, F1 Macro: 0.6359, Accuracy: 0.6404\n","Epoch 81, Train Loss: 0.5910, Val Loss: 0.7384, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 82, Train Loss: 0.5792, Val Loss: 0.7067, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 83, Train Loss: 0.5805, Val Loss: 0.7000, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 84, Train Loss: 0.5861, Val Loss: 0.7856, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 85, Train Loss: 0.5785, Val Loss: 0.6837, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 86, Train Loss: 0.5730, Val Loss: 0.6881, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 87, Train Loss: 0.5767, Val Loss: 0.7094, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 88, Train Loss: 0.5821, Val Loss: 0.7076, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 89, Train Loss: 0.5771, Val Loss: 0.7262, F1 Micro: 0.6404, F1 Macro: 0.5831, Accuracy: 0.6404\n","Epoch 90, Train Loss: 0.5746, Val Loss: 0.6917, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 91, Train Loss: 0.5743, Val Loss: 0.7768, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 92, Train Loss: 0.5827, Val Loss: 0.6930, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.5914, Val Loss: 0.6984, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 94, Train Loss: 0.5849, Val Loss: 0.7805, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 95, Train Loss: 0.5690, Val Loss: 0.7164, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 96, Train Loss: 0.5817, Val Loss: 0.7190, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 97, Train Loss: 0.5834, Val Loss: 0.7101, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 98, Train Loss: 0.5727, Val Loss: 0.7421, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 99, Train Loss: 0.5801, Val Loss: 0.7046, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 100, Train Loss: 0.5788, Val Loss: 0.6930, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 101, Train Loss: 0.5724, Val Loss: 0.7237, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 102, Train Loss: 0.5802, Val Loss: 0.7334, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 103, Train Loss: 0.5827, Val Loss: 0.7631, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 104, Train Loss: 0.5711, Val Loss: 0.7434, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 105, Train Loss: 0.5740, Val Loss: 0.7691, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 106, Train Loss: 0.5809, Val Loss: 0.7769, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 107, Train Loss: 0.5760, Val Loss: 0.6962, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 108, Train Loss: 0.5825, Val Loss: 0.7132, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 109, Train Loss: 0.5780, Val Loss: 0.7036, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 110, Train Loss: 0.5864, Val Loss: 0.6993, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 111, Train Loss: 0.5692, Val Loss: 0.7794, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 112, Train Loss: 0.5650, Val Loss: 0.7446, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 113, Train Loss: 0.5732, Val Loss: 0.7368, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 114, Train Loss: 0.5640, Val Loss: 0.7121, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 115, Train Loss: 0.5724, Val Loss: 0.7855, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 116, Train Loss: 0.5666, Val Loss: 0.7864, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 117, Train Loss: 0.5734, Val Loss: 0.7124, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 118, Train Loss: 0.5731, Val Loss: 0.6902, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 119, Train Loss: 0.5753, Val Loss: 0.7317, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 120, Train Loss: 0.5759, Val Loss: 0.7542, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 121, Train Loss: 0.5703, Val Loss: 0.6782, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 122, Train Loss: 0.5764, Val Loss: 0.6905, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 123, Train Loss: 0.5681, Val Loss: 0.7549, F1 Micro: 0.6685, F1 Macro: 0.6363, Accuracy: 0.6685\n","Epoch 124, Train Loss: 0.5737, Val Loss: 0.7194, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 125, Train Loss: 0.5744, Val Loss: 0.7501, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 126, Train Loss: 0.5744, Val Loss: 0.7183, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 127, Train Loss: 0.5650, Val Loss: 0.6998, F1 Micro: 0.6629, F1 Macro: 0.6468, Accuracy: 0.6629\n","Epoch 128, Train Loss: 0.5702, Val Loss: 0.7002, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 129, Train Loss: 0.5600, Val Loss: 0.7131, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 130, Train Loss: 0.5643, Val Loss: 0.7052, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 131, Train Loss: 0.5641, Val Loss: 0.6800, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 132, Train Loss: 0.5632, Val Loss: 0.7877, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 133, Train Loss: 0.5703, Val Loss: 0.6890, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 134, Train Loss: 0.5652, Val Loss: 0.7108, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7205322955244491\n","Best hyperparameters for Outer FOLD 3: (0.001, 16, 50) with score 0.7205322955244491\n","Epoch 1, Train Loss: 0.7409, Val Loss: 0.6960, F1 Micro: 0.5766, F1 Macro: 0.5697, Accuracy: 0.5766\n","Epoch 2, Train Loss: 0.6823, Val Loss: 0.6665, F1 Micro: 0.6441, F1 Macro: 0.6340, Accuracy: 0.6441\n","Epoch 3, Train Loss: 0.6481, Val Loss: 0.6966, F1 Micro: 0.5856, F1 Macro: 0.4801, Accuracy: 0.5856\n","Epoch 4, Train Loss: 0.6268, Val Loss: 0.6345, F1 Micro: 0.6441, F1 Macro: 0.6415, Accuracy: 0.6441\n","Epoch 5, Train Loss: 0.6273, Val Loss: 0.6346, F1 Micro: 0.6622, F1 Macro: 0.6591, Accuracy: 0.6622\n","Epoch 6, Train Loss: 0.6261, Val Loss: 0.7041, F1 Micro: 0.6171, F1 Macro: 0.5678, Accuracy: 0.6171\n","Epoch 7, Train Loss: 0.6246, Val Loss: 0.6564, F1 Micro: 0.6757, F1 Macro: 0.6463, Accuracy: 0.6757\n","Epoch 8, Train Loss: 0.6199, Val Loss: 0.6231, F1 Micro: 0.6892, F1 Macro: 0.6793, Accuracy: 0.6892\n","Epoch 9, Train Loss: 0.6279, Val Loss: 0.6630, F1 Micro: 0.6532, F1 Macro: 0.6354, Accuracy: 0.6532\n","Epoch 10, Train Loss: 0.6304, Val Loss: 0.6337, F1 Micro: 0.6667, F1 Macro: 0.6530, Accuracy: 0.6667\n","Epoch 11, Train Loss: 0.6183, Val Loss: 0.7193, F1 Micro: 0.5946, F1 Macro: 0.4806, Accuracy: 0.5946\n","Epoch 12, Train Loss: 0.6221, Val Loss: 0.6244, F1 Micro: 0.6622, F1 Macro: 0.6585, Accuracy: 0.6622\n","Epoch 13, Train Loss: 0.6294, Val Loss: 0.6403, F1 Micro: 0.6306, F1 Macro: 0.6304, Accuracy: 0.6306\n","Epoch 14, Train Loss: 0.6216, Val Loss: 0.7006, F1 Micro: 0.5000, F1 Macro: 0.4430, Accuracy: 0.5000\n","Epoch 15, Train Loss: 0.6346, Val Loss: 0.6319, F1 Micro: 0.6757, F1 Macro: 0.6747, Accuracy: 0.6757\n","Epoch 16, Train Loss: 0.6215, Val Loss: 0.6393, F1 Micro: 0.6532, F1 Macro: 0.6228, Accuracy: 0.6532\n","Epoch 17, Train Loss: 0.6221, Val Loss: 0.6449, F1 Micro: 0.5991, F1 Macro: 0.5961, Accuracy: 0.5991\n","Epoch 18, Train Loss: 0.6163, Val Loss: 0.6709, F1 Micro: 0.6036, F1 Macro: 0.5256, Accuracy: 0.6036\n","Epoch 19, Train Loss: 0.6185, Val Loss: 0.6298, F1 Micro: 0.6441, F1 Macro: 0.6441, Accuracy: 0.6441\n","Epoch 20, Train Loss: 0.6225, Val Loss: 0.6170, F1 Micro: 0.6937, F1 Macro: 0.6823, Accuracy: 0.6937\n","Epoch 21, Train Loss: 0.6232, Val Loss: 0.6283, F1 Micro: 0.6577, F1 Macro: 0.6409, Accuracy: 0.6577\n","Epoch 22, Train Loss: 0.6203, Val Loss: 0.6231, F1 Micro: 0.6937, F1 Macro: 0.6696, Accuracy: 0.6937\n","Epoch 23, Train Loss: 0.6099, Val Loss: 0.6455, F1 Micro: 0.6712, F1 Macro: 0.6424, Accuracy: 0.6712\n","Epoch 24, Train Loss: 0.6053, Val Loss: 0.6181, F1 Micro: 0.7072, F1 Macro: 0.6958, Accuracy: 0.7072\n","Epoch 25, Train Loss: 0.6180, Val Loss: 0.6524, F1 Micro: 0.6396, F1 Macro: 0.5946, Accuracy: 0.6396\n","Epoch 26, Train Loss: 0.6206, Val Loss: 0.6518, F1 Micro: 0.6171, F1 Macro: 0.5221, Accuracy: 0.6171\n","Epoch 27, Train Loss: 0.6149, Val Loss: 0.6149, F1 Micro: 0.7117, F1 Macro: 0.6999, Accuracy: 0.7117\n","Epoch 28, Train Loss: 0.6184, Val Loss: 0.6849, F1 Micro: 0.6171, F1 Macro: 0.5121, Accuracy: 0.6171\n","Epoch 29, Train Loss: 0.6060, Val Loss: 0.6159, F1 Micro: 0.7027, F1 Macro: 0.6905, Accuracy: 0.7027\n","Epoch 30, Train Loss: 0.6074, Val Loss: 0.6464, F1 Micro: 0.6396, F1 Macro: 0.5973, Accuracy: 0.6396\n","Epoch 31, Train Loss: 0.6048, Val Loss: 0.6329, F1 Micro: 0.6081, F1 Macro: 0.5513, Accuracy: 0.6081\n","Epoch 32, Train Loss: 0.6071, Val Loss: 0.6413, F1 Micro: 0.6486, F1 Macro: 0.6020, Accuracy: 0.6486\n","Epoch 33, Train Loss: 0.6061, Val Loss: 0.6305, F1 Micro: 0.6847, F1 Macro: 0.6718, Accuracy: 0.6847\n","Epoch 34, Train Loss: 0.6071, Val Loss: 0.6180, F1 Micro: 0.6982, F1 Macro: 0.6800, Accuracy: 0.6982\n","Epoch 35, Train Loss: 0.6113, Val Loss: 0.6290, F1 Micro: 0.6577, F1 Macro: 0.6266, Accuracy: 0.6577\n","Epoch 36, Train Loss: 0.6069, Val Loss: 0.6148, F1 Micro: 0.7072, F1 Macro: 0.6947, Accuracy: 0.7072\n","Epoch 37, Train Loss: 0.6069, Val Loss: 0.6712, F1 Micro: 0.6532, F1 Macro: 0.5999, Accuracy: 0.6532\n","Epoch 38, Train Loss: 0.6151, Val Loss: 0.6118, F1 Micro: 0.7072, F1 Macro: 0.6988, Accuracy: 0.7072\n","Epoch 39, Train Loss: 0.6073, Val Loss: 0.6119, F1 Micro: 0.7027, F1 Macro: 0.6937, Accuracy: 0.7027\n","Epoch 40, Train Loss: 0.6086, Val Loss: 0.6355, F1 Micro: 0.6396, F1 Macro: 0.6047, Accuracy: 0.6396\n","Epoch 41, Train Loss: 0.5976, Val Loss: 0.6204, F1 Micro: 0.6982, F1 Macro: 0.6864, Accuracy: 0.6982\n","Epoch 42, Train Loss: 0.6053, Val Loss: 0.6164, F1 Micro: 0.6982, F1 Macro: 0.6914, Accuracy: 0.6982\n","Epoch 43, Train Loss: 0.6184, Val Loss: 0.6182, F1 Micro: 0.6757, F1 Macro: 0.6718, Accuracy: 0.6757\n","Epoch 44, Train Loss: 0.6157, Val Loss: 0.6148, F1 Micro: 0.7072, F1 Macro: 0.7006, Accuracy: 0.7072\n","Epoch 45, Train Loss: 0.6134, Val Loss: 0.6193, F1 Micro: 0.7027, F1 Macro: 0.6947, Accuracy: 0.7027\n","Epoch 46, Train Loss: 0.6119, Val Loss: 0.6198, F1 Micro: 0.6982, F1 Macro: 0.6949, Accuracy: 0.6982\n","Epoch 47, Train Loss: 0.6037, Val Loss: 0.6180, F1 Micro: 0.7117, F1 Macro: 0.7083, Accuracy: 0.7117\n","Epoch 48, Train Loss: 0.6083, Val Loss: 0.6230, F1 Micro: 0.7072, F1 Macro: 0.6895, Accuracy: 0.7072\n","Epoch 49, Train Loss: 0.6004, Val Loss: 0.6120, F1 Micro: 0.7162, F1 Macro: 0.7029, Accuracy: 0.7162\n","Epoch 50, Train Loss: 0.6042, Val Loss: 0.6119, F1 Micro: 0.7117, F1 Macro: 0.7010, Accuracy: 0.7117\n","Epoch 51, Train Loss: 0.6046, Val Loss: 0.6285, F1 Micro: 0.6937, F1 Macro: 0.6759, Accuracy: 0.6937\n","Epoch 52, Train Loss: 0.6034, Val Loss: 0.6549, F1 Micro: 0.6892, F1 Macro: 0.6600, Accuracy: 0.6892\n","Epoch 53, Train Loss: 0.6078, Val Loss: 0.6104, F1 Micro: 0.7117, F1 Macro: 0.7010, Accuracy: 0.7117\n","Epoch 54, Train Loss: 0.6070, Val Loss: 0.6241, F1 Micro: 0.6802, F1 Macro: 0.6559, Accuracy: 0.6802\n","Epoch 55, Train Loss: 0.6054, Val Loss: 0.6196, F1 Micro: 0.6847, F1 Macro: 0.6633, Accuracy: 0.6847\n","Epoch 56, Train Loss: 0.6031, Val Loss: 0.6124, F1 Micro: 0.7117, F1 Macro: 0.7083, Accuracy: 0.7117\n","Epoch 57, Train Loss: 0.6049, Val Loss: 0.6275, F1 Micro: 0.6937, F1 Macro: 0.6787, Accuracy: 0.6937\n","Epoch 58, Train Loss: 0.5967, Val Loss: 0.6157, F1 Micro: 0.7072, F1 Macro: 0.6988, Accuracy: 0.7072\n","Epoch 59, Train Loss: 0.6018, Val Loss: 0.6123, F1 Micro: 0.7117, F1 Macro: 0.7020, Accuracy: 0.7117\n","Epoch 60, Train Loss: 0.5938, Val Loss: 0.6133, F1 Micro: 0.7162, F1 Macro: 0.7062, Accuracy: 0.7162\n","Epoch 61, Train Loss: 0.6043, Val Loss: 0.6162, F1 Micro: 0.7027, F1 Macro: 0.6894, Accuracy: 0.7027\n","Epoch 62, Train Loss: 0.6028, Val Loss: 0.6108, F1 Micro: 0.7162, F1 Macro: 0.7062, Accuracy: 0.7162\n","Epoch 63, Train Loss: 0.6038, Val Loss: 0.6191, F1 Micro: 0.6757, F1 Macro: 0.6679, Accuracy: 0.6757\n","Epoch 64, Train Loss: 0.6005, Val Loss: 0.6426, F1 Micro: 0.6216, F1 Macro: 0.5683, Accuracy: 0.6216\n","Epoch 65, Train Loss: 0.5943, Val Loss: 0.6667, F1 Micro: 0.6802, F1 Macro: 0.6481, Accuracy: 0.6802\n","Epoch 66, Train Loss: 0.6036, Val Loss: 0.6174, F1 Micro: 0.6982, F1 Macro: 0.6814, Accuracy: 0.6982\n","Epoch 67, Train Loss: 0.5986, Val Loss: 0.6277, F1 Micro: 0.6757, F1 Macro: 0.6463, Accuracy: 0.6757\n","Epoch 68, Train Loss: 0.6036, Val Loss: 0.6124, F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Epoch 69, Train Loss: 0.6106, Val Loss: 0.6174, F1 Micro: 0.6937, F1 Macro: 0.6812, Accuracy: 0.6937\n","Epoch 70, Train Loss: 0.6076, Val Loss: 0.6124, F1 Micro: 0.7072, F1 Macro: 0.6997, Accuracy: 0.7072\n","Epoch 71, Train Loss: 0.6113, Val Loss: 0.6211, F1 Micro: 0.6667, F1 Macro: 0.6385, Accuracy: 0.6667\n","Epoch 72, Train Loss: 0.6054, Val Loss: 0.6170, F1 Micro: 0.6847, F1 Macro: 0.6633, Accuracy: 0.6847\n","Epoch 73, Train Loss: 0.6070, Val Loss: 0.6163, F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Epoch 74, Train Loss: 0.6029, Val Loss: 0.6854, F1 Micro: 0.6261, F1 Macro: 0.5506, Accuracy: 0.6261\n","Epoch 75, Train Loss: 0.5942, Val Loss: 0.6117, F1 Micro: 0.7072, F1 Macro: 0.6979, Accuracy: 0.7072\n","Epoch 76, Train Loss: 0.5972, Val Loss: 0.6311, F1 Micro: 0.7072, F1 Macro: 0.6909, Accuracy: 0.7072\n","Epoch 77, Train Loss: 0.6005, Val Loss: 0.6209, F1 Micro: 0.6667, F1 Macro: 0.6343, Accuracy: 0.6667\n","Epoch 78, Train Loss: 0.6009, Val Loss: 0.6572, F1 Micro: 0.6622, F1 Macro: 0.6160, Accuracy: 0.6622\n","Epoch 79, Train Loss: 0.5982, Val Loss: 0.6171, F1 Micro: 0.7072, F1 Macro: 0.6935, Accuracy: 0.7072\n","Epoch 80, Train Loss: 0.6023, Val Loss: 0.6251, F1 Micro: 0.6577, F1 Macro: 0.6245, Accuracy: 0.6577\n","Epoch 81, Train Loss: 0.5958, Val Loss: 0.6138, F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Epoch 82, Train Loss: 0.5988, Val Loss: 0.6679, F1 Micro: 0.6351, F1 Macro: 0.5791, Accuracy: 0.6351\n","Epoch 83, Train Loss: 0.6029, Val Loss: 0.6105, F1 Micro: 0.7207, F1 Macro: 0.7155, Accuracy: 0.7207\n","Epoch 84, Train Loss: 0.6078, Val Loss: 0.6473, F1 Micro: 0.6667, F1 Macro: 0.6343, Accuracy: 0.6667\n","Epoch 85, Train Loss: 0.6045, Val Loss: 0.6241, F1 Micro: 0.7027, F1 Macro: 0.6854, Accuracy: 0.7027\n","Epoch 86, Train Loss: 0.6101, Val Loss: 0.6381, F1 Micro: 0.6892, F1 Macro: 0.6638, Accuracy: 0.6892\n","Epoch 87, Train Loss: 0.5937, Val Loss: 0.6885, F1 Micro: 0.6306, F1 Macro: 0.5580, Accuracy: 0.6306\n","Epoch 88, Train Loss: 0.5947, Val Loss: 0.6200, F1 Micro: 0.6982, F1 Macro: 0.6814, Accuracy: 0.6982\n","Epoch 89, Train Loss: 0.5954, Val Loss: 0.6094, F1 Micro: 0.6757, F1 Macro: 0.6688, Accuracy: 0.6757\n","Epoch 90, Train Loss: 0.6110, Val Loss: 0.6243, F1 Micro: 0.6667, F1 Macro: 0.6385, Accuracy: 0.6667\n","Epoch 91, Train Loss: 0.6004, Val Loss: 0.6339, F1 Micro: 0.6532, F1 Macro: 0.6111, Accuracy: 0.6532\n","Epoch 92, Train Loss: 0.5988, Val Loss: 0.6150, F1 Micro: 0.7072, F1 Macro: 0.6979, Accuracy: 0.7072\n","Epoch 93, Train Loss: 0.5899, Val Loss: 0.6749, F1 Micro: 0.6396, F1 Macro: 0.5609, Accuracy: 0.6396\n","Epoch 94, Train Loss: 0.5985, Val Loss: 0.6154, F1 Micro: 0.7027, F1 Macro: 0.6947, Accuracy: 0.7027\n","Epoch 95, Train Loss: 0.5894, Val Loss: 0.6516, F1 Micro: 0.6802, F1 Macro: 0.6502, Accuracy: 0.6802\n","Epoch 96, Train Loss: 0.5974, Val Loss: 0.6190, F1 Micro: 0.6847, F1 Macro: 0.6741, Accuracy: 0.6847\n","Epoch 97, Train Loss: 0.5954, Val Loss: 0.6403, F1 Micro: 0.6396, F1 Macro: 0.5999, Accuracy: 0.6396\n","Epoch 98, Train Loss: 0.5985, Val Loss: 0.6130, F1 Micro: 0.7117, F1 Macro: 0.7030, Accuracy: 0.7117\n","Epoch 99, Train Loss: 0.6002, Val Loss: 0.6162, F1 Micro: 0.6712, F1 Macro: 0.6692, Accuracy: 0.6712\n","Epoch 100, Train Loss: 0.5960, Val Loss: 0.6221, F1 Micro: 0.6937, F1 Macro: 0.6713, Accuracy: 0.6937\n","Epoch 101, Train Loss: 0.5978, Val Loss: 0.6354, F1 Micro: 0.6892, F1 Macro: 0.6719, Accuracy: 0.6892\n","Epoch 102, Train Loss: 0.5920, Val Loss: 0.6146, F1 Micro: 0.6982, F1 Macro: 0.6814, Accuracy: 0.6982\n","Epoch 103, Train Loss: 0.5963, Val Loss: 0.6317, F1 Micro: 0.6667, F1 Macro: 0.6322, Accuracy: 0.6667\n","Epoch 104, Train Loss: 0.5975, Val Loss: 0.6135, F1 Micro: 0.7117, F1 Macro: 0.7030, Accuracy: 0.7117\n","Epoch 105, Train Loss: 0.6062, Val Loss: 0.6999, F1 Micro: 0.6261, F1 Macro: 0.5423, Accuracy: 0.6261\n","Epoch 106, Train Loss: 0.6006, Val Loss: 0.6178, F1 Micro: 0.6892, F1 Macro: 0.6733, Accuracy: 0.6892\n","Epoch 107, Train Loss: 0.5907, Val Loss: 0.6379, F1 Micro: 0.6712, F1 Macro: 0.6382, Accuracy: 0.6712\n","Epoch 108, Train Loss: 0.5967, Val Loss: 0.6391, F1 Micro: 0.6982, F1 Macro: 0.6638, Accuracy: 0.6982\n","Epoch 109, Train Loss: 0.5987, Val Loss: 0.6138, F1 Micro: 0.7117, F1 Macro: 0.6988, Accuracy: 0.7117\n","Epoch 110, Train Loss: 0.5919, Val Loss: 0.6201, F1 Micro: 0.6802, F1 Macro: 0.6624, Accuracy: 0.6802\n","Epoch 111, Train Loss: 0.5915, Val Loss: 0.6316, F1 Micro: 0.6667, F1 Macro: 0.6343, Accuracy: 0.6667\n","Epoch 112, Train Loss: 0.5998, Val Loss: 0.6452, F1 Micro: 0.6847, F1 Macro: 0.6499, Accuracy: 0.6847\n","Epoch 113, Train Loss: 0.5927, Val Loss: 0.6296, F1 Micro: 0.6802, F1 Macro: 0.6638, Accuracy: 0.6802\n","Epoch 114, Train Loss: 0.5908, Val Loss: 0.6245, F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Epoch 115, Train Loss: 0.5912, Val Loss: 0.6129, F1 Micro: 0.7027, F1 Macro: 0.6917, Accuracy: 0.7027\n","Epoch 116, Train Loss: 0.6021, Val Loss: 0.6137, F1 Micro: 0.6757, F1 Macro: 0.6553, Accuracy: 0.6757\n","Epoch 117, Train Loss: 0.5938, Val Loss: 0.6482, F1 Micro: 0.6486, F1 Macro: 0.6020, Accuracy: 0.6486\n","Epoch 118, Train Loss: 0.6018, Val Loss: 0.6231, F1 Micro: 0.6937, F1 Macro: 0.6773, Accuracy: 0.6937\n","Epoch 119, Train Loss: 0.5941, Val Loss: 0.6185, F1 Micro: 0.6757, F1 Macro: 0.6501, Accuracy: 0.6757\n","Epoch 120, Train Loss: 0.5962, Val Loss: 0.6168, F1 Micro: 0.7072, F1 Macro: 0.6969, Accuracy: 0.7072\n","Epoch 121, Train Loss: 0.5884, Val Loss: 0.6478, F1 Micro: 0.6847, F1 Macro: 0.6520, Accuracy: 0.6847\n","Epoch 122, Train Loss: 0.5978, Val Loss: 0.6113, F1 Micro: 0.6982, F1 Macro: 0.6914, Accuracy: 0.6982\n","Epoch 123, Train Loss: 0.6005, Val Loss: 0.6304, F1 Micro: 0.6667, F1 Macro: 0.6322, Accuracy: 0.6667\n","Epoch 124, Train Loss: 0.5907, Val Loss: 0.6222, F1 Micro: 0.6892, F1 Macro: 0.6704, Accuracy: 0.6892\n","Epoch 125, Train Loss: 0.5855, Val Loss: 0.6142, F1 Micro: 0.6847, F1 Macro: 0.6598, Accuracy: 0.6847\n","Epoch 126, Train Loss: 0.5875, Val Loss: 0.6209, F1 Micro: 0.6937, F1 Macro: 0.6729, Accuracy: 0.6937\n","Epoch 127, Train Loss: 0.5893, Val Loss: 0.6170, F1 Micro: 0.6577, F1 Macro: 0.6554, Accuracy: 0.6577\n","Epoch 128, Train Loss: 0.5927, Val Loss: 0.6329, F1 Micro: 0.6577, F1 Macro: 0.6245, Accuracy: 0.6577\n","Epoch 129, Train Loss: 0.5919, Val Loss: 0.6157, F1 Micro: 0.7027, F1 Macro: 0.6894, Accuracy: 0.7027\n","Epoch 130, Train Loss: 0.5973, Val Loss: 0.6142, F1 Micro: 0.6892, F1 Macro: 0.6759, Accuracy: 0.6892\n","Epoch 131, Train Loss: 0.5908, Val Loss: 0.6191, F1 Micro: 0.6757, F1 Macro: 0.6568, Accuracy: 0.6757\n","Epoch 132, Train Loss: 0.5903, Val Loss: 0.6149, F1 Micro: 0.6892, F1 Macro: 0.6733, Accuracy: 0.6892\n","Epoch 133, Train Loss: 0.5883, Val Loss: 0.6185, F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6982, F1 Macro: 0.6853, Accuracy: 0.6982\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7630, Val Loss: 0.6795, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6766, Val Loss: 0.6641, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6754, Val Loss: 0.6638, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6752, Val Loss: 0.6638, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6757, Val Loss: 0.6665, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6760, Val Loss: 0.6619, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 7, Train Loss: 0.6754, Val Loss: 0.6618, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6752, Val Loss: 0.6647, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6746, Val Loss: 0.6632, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6750, Val Loss: 0.6635, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 11, Train Loss: 0.6756, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7798, Val Loss: 0.6843, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6746, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6735, Val Loss: 0.6663, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6773, Val Loss: 0.6656, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6787, Val Loss: 0.6654, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6784, Val Loss: 0.6644, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6776, Val Loss: 0.6658, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6733, Val Loss: 0.6666, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6733, Val Loss: 0.6653, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6746, Val Loss: 0.6645, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6735, Val Loss: 0.6647, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6871, Val Loss: 0.6721, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6782, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6725, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6753, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6711, Val Loss: 0.6718, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6726, Val Loss: 0.6719, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6717, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6714, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6718, Val Loss: 0.6725, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6745, Val Loss: 0.6728, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6721, Val Loss: 0.6717, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6734, Val Loss: 0.7239, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6598, Val Loss: 0.7285, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6649, Val Loss: 0.7244, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6649, Val Loss: 0.7317, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6601, Val Loss: 0.7246, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6644, Val Loss: 0.7135, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6658, Val Loss: 0.7208, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6649, Val Loss: 0.7288, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6644, Val Loss: 0.7242, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6647, Val Loss: 0.7299, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6595, Val Loss: 0.7244, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7006, Val Loss: 0.6802, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6693, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6730, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6731, Val Loss: 0.6803, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6700, Val Loss: 0.6818, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6735, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6688, Val Loss: 0.6814, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6694, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6732, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6696, Val Loss: 0.6827, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6739, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.6060197099993723\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6907, Val Loss: 0.6623, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6750, Val Loss: 0.6627, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6753, Val Loss: 0.6628, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6752, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6746, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6754, Val Loss: 0.6658, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 7, Train Loss: 0.6754, Val Loss: 0.6625, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6751, Val Loss: 0.6629, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6754, Val Loss: 0.6618, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6777, Val Loss: 0.6617, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 11, Train Loss: 0.6758, Val Loss: 0.6621, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 12, Train Loss: 0.6758, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 13, Train Loss: 0.6753, Val Loss: 0.6629, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 14, Train Loss: 0.6756, Val Loss: 0.6654, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 15, Train Loss: 0.6772, Val Loss: 0.6621, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 16, Train Loss: 0.6748, Val Loss: 0.6636, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 17, Train Loss: 0.6754, Val Loss: 0.6625, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 18, Train Loss: 0.6756, Val Loss: 0.6622, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 19, Train Loss: 0.6749, Val Loss: 0.6644, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 20, Train Loss: 0.6749, Val Loss: 0.6637, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 21, Train Loss: 0.6749, Val Loss: 0.6626, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 22, Train Loss: 0.6764, Val Loss: 0.6629, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 23, Train Loss: 0.6760, Val Loss: 0.6630, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 24, Train Loss: 0.6750, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 25, Train Loss: 0.6755, Val Loss: 0.6627, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 26, Train Loss: 0.6762, Val Loss: 0.6624, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 27, Train Loss: 0.6759, Val Loss: 0.6625, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 28, Train Loss: 0.6761, Val Loss: 0.6632, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 29, Train Loss: 0.6754, Val Loss: 0.6658, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 30, Train Loss: 0.6752, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 31, Train Loss: 0.6754, Val Loss: 0.6630, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 32, Train Loss: 0.6756, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 33, Train Loss: 0.6753, Val Loss: 0.6638, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 34, Train Loss: 0.6754, Val Loss: 0.6634, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 35, Train Loss: 0.6752, Val Loss: 0.6628, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 36, Train Loss: 0.6752, Val Loss: 0.6621, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 37, Train Loss: 0.6762, Val Loss: 0.6617, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 38, Train Loss: 0.6755, Val Loss: 0.6628, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 39, Train Loss: 0.6751, Val Loss: 0.6618, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 40, Train Loss: 0.6749, Val Loss: 0.6653, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 41, Train Loss: 0.6751, Val Loss: 0.6623, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 42, Train Loss: 0.6754, Val Loss: 0.6624, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 43, Train Loss: 0.6751, Val Loss: 0.6630, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 44, Train Loss: 0.6753, Val Loss: 0.6638, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 45, Train Loss: 0.6749, Val Loss: 0.6628, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 46, Train Loss: 0.6754, Val Loss: 0.6653, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 47, Train Loss: 0.6755, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 48, Train Loss: 0.6748, Val Loss: 0.6623, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 49, Train Loss: 0.6755, Val Loss: 0.6635, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 50, Train Loss: 0.6749, Val Loss: 0.6639, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 51, Train Loss: 0.6751, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7116, Val Loss: 0.6588, F1 Micro: 0.7135, F1 Macro: 0.6121, Accuracy: 0.7135\n","Epoch 2, Train Loss: 0.6678, Val Loss: 0.7000, F1 Micro: 0.6854, F1 Macro: 0.5486, Accuracy: 0.6854\n","Epoch 3, Train Loss: 0.6560, Val Loss: 0.6206, F1 Micro: 0.7865, F1 Macro: 0.7389, Accuracy: 0.7865\n","Epoch 4, Train Loss: 0.6473, Val Loss: 0.5972, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 5, Train Loss: 0.6456, Val Loss: 0.6103, F1 Micro: 0.7584, F1 Macro: 0.7263, Accuracy: 0.7584\n","Epoch 6, Train Loss: 0.6442, Val Loss: 0.6234, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 7, Train Loss: 0.6502, Val Loss: 0.5952, F1 Micro: 0.7584, F1 Macro: 0.7238, Accuracy: 0.7584\n","Epoch 8, Train Loss: 0.6602, Val Loss: 0.5918, F1 Micro: 0.7528, F1 Macro: 0.6820, Accuracy: 0.7528\n","Epoch 9, Train Loss: 0.6402, Val Loss: 0.5869, F1 Micro: 0.7865, F1 Macro: 0.7389, Accuracy: 0.7865\n","Epoch 10, Train Loss: 0.6390, Val Loss: 0.6481, F1 Micro: 0.7022, F1 Macro: 0.5837, Accuracy: 0.7022\n","Epoch 11, Train Loss: 0.6391, Val Loss: 0.5999, F1 Micro: 0.7640, F1 Macro: 0.7005, Accuracy: 0.7640\n","Epoch 12, Train Loss: 0.6574, Val Loss: 0.6054, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 13, Train Loss: 0.6478, Val Loss: 0.5865, F1 Micro: 0.7865, F1 Macro: 0.7358, Accuracy: 0.7865\n","Epoch 14, Train Loss: 0.6597, Val Loss: 0.5861, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 15, Train Loss: 0.6337, Val Loss: 0.5905, F1 Micro: 0.7865, F1 Macro: 0.7475, Accuracy: 0.7865\n","Epoch 16, Train Loss: 0.6337, Val Loss: 0.6209, F1 Micro: 0.7865, F1 Macro: 0.7358, Accuracy: 0.7865\n","Epoch 17, Train Loss: 0.6410, Val Loss: 0.6550, F1 Micro: 0.6180, F1 Macro: 0.6175, Accuracy: 0.6180\n","Epoch 18, Train Loss: 0.6486, Val Loss: 0.6752, F1 Micro: 0.5730, F1 Macro: 0.5717, Accuracy: 0.5730\n","Epoch 19, Train Loss: 0.6435, Val Loss: 0.5847, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 20, Train Loss: 0.6493, Val Loss: 0.5953, F1 Micro: 0.7809, F1 Macro: 0.7394, Accuracy: 0.7809\n","Epoch 21, Train Loss: 0.6354, Val Loss: 0.5939, F1 Micro: 0.7697, F1 Macro: 0.7199, Accuracy: 0.7697\n","Epoch 22, Train Loss: 0.6505, Val Loss: 0.5833, F1 Micro: 0.7865, F1 Macro: 0.7448, Accuracy: 0.7865\n","Epoch 23, Train Loss: 0.6326, Val Loss: 0.5851, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 24, Train Loss: 0.6357, Val Loss: 0.5877, F1 Micro: 0.7640, F1 Macro: 0.7315, Accuracy: 0.7640\n","Epoch 25, Train Loss: 0.6296, Val Loss: 0.6061, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.6298, Val Loss: 0.5821, F1 Micro: 0.7809, F1 Macro: 0.7394, Accuracy: 0.7809\n","Epoch 27, Train Loss: 0.6305, Val Loss: 0.6092, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 28, Train Loss: 0.6277, Val Loss: 0.6039, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 29, Train Loss: 0.6382, Val Loss: 0.6017, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 30, Train Loss: 0.6322, Val Loss: 0.5871, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 31, Train Loss: 0.6416, Val Loss: 0.5823, F1 Micro: 0.7528, F1 Macro: 0.7106, Accuracy: 0.7528\n","Epoch 32, Train Loss: 0.6362, Val Loss: 0.5936, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 33, Train Loss: 0.6381, Val Loss: 0.5895, F1 Micro: 0.7921, F1 Macro: 0.7528, Accuracy: 0.7921\n","Epoch 34, Train Loss: 0.6333, Val Loss: 0.5769, F1 Micro: 0.7809, F1 Macro: 0.7422, Accuracy: 0.7809\n","Epoch 35, Train Loss: 0.6236, Val Loss: 0.6025, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 36, Train Loss: 0.6184, Val Loss: 0.5761, F1 Micro: 0.7697, F1 Macro: 0.7342, Accuracy: 0.7697\n","Epoch 37, Train Loss: 0.6328, Val Loss: 0.5948, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 38, Train Loss: 0.6360, Val Loss: 0.5783, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 39, Train Loss: 0.6275, Val Loss: 0.5705, F1 Micro: 0.7697, F1 Macro: 0.7231, Accuracy: 0.7697\n","Epoch 40, Train Loss: 0.6256, Val Loss: 0.5798, F1 Micro: 0.7809, F1 Macro: 0.7472, Accuracy: 0.7809\n","Epoch 41, Train Loss: 0.6226, Val Loss: 0.5808, F1 Micro: 0.7697, F1 Macro: 0.7390, Accuracy: 0.7697\n","Epoch 42, Train Loss: 0.6158, Val Loss: 0.5720, F1 Micro: 0.7360, F1 Macro: 0.6924, Accuracy: 0.7360\n","Epoch 43, Train Loss: 0.6257, Val Loss: 0.5699, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 44, Train Loss: 0.6438, Val Loss: 0.5802, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 45, Train Loss: 0.6322, Val Loss: 0.5839, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 46, Train Loss: 0.6330, Val Loss: 0.6080, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 47, Train Loss: 0.6338, Val Loss: 0.5862, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 48, Train Loss: 0.6374, Val Loss: 0.5998, F1 Micro: 0.7978, F1 Macro: 0.7555, Accuracy: 0.7978\n","Epoch 49, Train Loss: 0.6119, Val Loss: 0.5824, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 50, Train Loss: 0.6205, Val Loss: 0.5645, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 51, Train Loss: 0.6359, Val Loss: 0.5845, F1 Micro: 0.7697, F1 Macro: 0.7412, Accuracy: 0.7697\n","Epoch 52, Train Loss: 0.6259, Val Loss: 0.5775, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 53, Train Loss: 0.6306, Val Loss: 0.5945, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 54, Train Loss: 0.6263, Val Loss: 0.5774, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 55, Train Loss: 0.6312, Val Loss: 0.6399, F1 Micro: 0.6292, F1 Macro: 0.6254, Accuracy: 0.6292\n","Epoch 56, Train Loss: 0.6328, Val Loss: 0.5888, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 57, Train Loss: 0.6285, Val Loss: 0.5780, F1 Micro: 0.7584, F1 Macro: 0.7096, Accuracy: 0.7584\n","Epoch 58, Train Loss: 0.6219, Val Loss: 0.5700, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 59, Train Loss: 0.6258, Val Loss: 0.5735, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 60, Train Loss: 0.6236, Val Loss: 0.5980, F1 Micro: 0.7809, F1 Macro: 0.7305, Accuracy: 0.7809\n","Epoch 61, Train Loss: 0.6139, Val Loss: 0.6402, F1 Micro: 0.6180, F1 Macro: 0.6162, Accuracy: 0.6180\n","Epoch 62, Train Loss: 0.6295, Val Loss: 0.5739, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 63, Train Loss: 0.6308, Val Loss: 0.5723, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 64, Train Loss: 0.6365, Val Loss: 0.6218, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 65, Train Loss: 0.6242, Val Loss: 0.5992, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 66, Train Loss: 0.6221, Val Loss: 0.5895, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 67, Train Loss: 0.6367, Val Loss: 0.5717, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 68, Train Loss: 0.6275, Val Loss: 0.5706, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 69, Train Loss: 0.6223, Val Loss: 0.5732, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 70, Train Loss: 0.6339, Val Loss: 0.5660, F1 Micro: 0.7753, F1 Macro: 0.7283, Accuracy: 0.7753\n","Epoch 71, Train Loss: 0.6200, Val Loss: 0.5688, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 72, Train Loss: 0.6270, Val Loss: 0.5674, F1 Micro: 0.7697, F1 Macro: 0.7367, Accuracy: 0.7697\n","Epoch 73, Train Loss: 0.6124, Val Loss: 0.5967, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 74, Train Loss: 0.6142, Val Loss: 0.5767, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 75, Train Loss: 0.6256, Val Loss: 0.5665, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 76, Train Loss: 0.6235, Val Loss: 0.5709, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 77, Train Loss: 0.6256, Val Loss: 0.5754, F1 Micro: 0.7360, F1 Macro: 0.6670, Accuracy: 0.7360\n","Epoch 78, Train Loss: 0.6248, Val Loss: 0.5630, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 79, Train Loss: 0.6162, Val Loss: 0.5629, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 80, Train Loss: 0.6220, Val Loss: 0.5694, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 81, Train Loss: 0.6123, Val Loss: 0.5761, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 82, Train Loss: 0.6230, Val Loss: 0.5768, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 83, Train Loss: 0.6127, Val Loss: 0.5742, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 84, Train Loss: 0.6254, Val Loss: 0.5807, F1 Micro: 0.7697, F1 Macro: 0.7390, Accuracy: 0.7697\n","Epoch 85, Train Loss: 0.6158, Val Loss: 0.5721, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Epoch 86, Train Loss: 0.6212, Val Loss: 0.5710, F1 Micro: 0.7809, F1 Macro: 0.7394, Accuracy: 0.7809\n","Epoch 87, Train Loss: 0.6210, Val Loss: 0.5738, F1 Micro: 0.7640, F1 Macro: 0.7005, Accuracy: 0.7640\n","Epoch 88, Train Loss: 0.6379, Val Loss: 0.5657, F1 Micro: 0.7753, F1 Macro: 0.7313, Accuracy: 0.7753\n","Epoch 89, Train Loss: 0.6163, Val Loss: 0.5751, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 90, Train Loss: 0.6203, Val Loss: 0.5688, F1 Micro: 0.7360, F1 Macro: 0.6893, Accuracy: 0.7360\n","Epoch 91, Train Loss: 0.6234, Val Loss: 0.5742, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 92, Train Loss: 0.6300, Val Loss: 0.5645, F1 Micro: 0.7640, F1 Macro: 0.7179, Accuracy: 0.7640\n","Epoch 93, Train Loss: 0.6229, Val Loss: 0.5678, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 94, Train Loss: 0.6145, Val Loss: 0.5713, F1 Micro: 0.7472, F1 Macro: 0.7055, Accuracy: 0.7472\n","Epoch 95, Train Loss: 0.6275, Val Loss: 0.5687, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 96, Train Loss: 0.6155, Val Loss: 0.5661, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 97, Train Loss: 0.6245, Val Loss: 0.5648, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 98, Train Loss: 0.6292, Val Loss: 0.5656, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7261, Val Loss: 0.6622, F1 Micro: 0.6461, F1 Macro: 0.6024, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.6544, Val Loss: 0.6788, F1 Micro: 0.6292, F1 Macro: 0.6288, Accuracy: 0.6292\n","Epoch 3, Train Loss: 0.6335, Val Loss: 0.6664, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6410, Val Loss: 0.6591, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6463, Val Loss: 0.6934, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.6344, Val Loss: 0.6903, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6403, Val Loss: 0.7107, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 8, Train Loss: 0.6227, Val Loss: 0.6846, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 9, Train Loss: 0.6314, Val Loss: 0.6615, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 10, Train Loss: 0.6361, Val Loss: 0.6917, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.6680, Val Loss: 0.7318, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6374, Val Loss: 0.6986, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6305, Val Loss: 0.6765, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6303, Val Loss: 0.7027, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6363, Val Loss: 0.6670, F1 Micro: 0.6573, F1 Macro: 0.6181, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6309, Val Loss: 0.6766, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6249, Val Loss: 0.6603, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6172, Val Loss: 0.7116, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6370, Val Loss: 0.7632, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 20, Train Loss: 0.6234, Val Loss: 0.7474, F1 Micro: 0.6742, F1 Macro: 0.6104, Accuracy: 0.6742\n","Epoch 21, Train Loss: 0.6182, Val Loss: 0.6902, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 22, Train Loss: 0.6255, Val Loss: 0.6588, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6152, Val Loss: 0.6989, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6320, Val Loss: 0.6872, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 25, Train Loss: 0.6174, Val Loss: 0.6652, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6296, Val Loss: 0.8164, F1 Micro: 0.6404, F1 Macro: 0.5550, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6211, Val Loss: 0.6626, F1 Micro: 0.6292, F1 Macro: 0.6168, Accuracy: 0.6292\n","Epoch 28, Train Loss: 0.6330, Val Loss: 0.6715, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.6215, Val Loss: 0.7765, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 30, Train Loss: 0.6261, Val Loss: 0.6970, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6126, Val Loss: 0.7091, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.6216, Val Loss: 0.6655, F1 Micro: 0.6180, F1 Macro: 0.6083, Accuracy: 0.6180\n","Epoch 33, Train Loss: 0.6122, Val Loss: 0.6854, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 34, Train Loss: 0.6165, Val Loss: 0.6671, F1 Micro: 0.6292, F1 Macro: 0.6134, Accuracy: 0.6292\n","Epoch 35, Train Loss: 0.6350, Val Loss: 0.6603, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 36, Train Loss: 0.6108, Val Loss: 0.7381, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 37, Train Loss: 0.6328, Val Loss: 0.6592, F1 Micro: 0.6629, F1 Macro: 0.6315, Accuracy: 0.6629\n","Epoch 38, Train Loss: 0.6101, Val Loss: 0.6926, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 39, Train Loss: 0.6067, Val Loss: 0.7606, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 40, Train Loss: 0.6221, Val Loss: 0.8030, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.6091, Val Loss: 0.6724, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 42, Train Loss: 0.6189, Val Loss: 0.7019, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.6206, Val Loss: 0.7063, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.6150, Val Loss: 0.6877, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 45, Train Loss: 0.6245, Val Loss: 0.6595, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6066, Val Loss: 0.7447, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6184, Val Loss: 0.7427, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 48, Train Loss: 0.6218, Val Loss: 0.6678, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 49, Train Loss: 0.5995, Val Loss: 0.7265, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 50, Train Loss: 0.6007, Val Loss: 0.6650, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6009, Val Loss: 0.6506, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 52, Train Loss: 0.6069, Val Loss: 0.6752, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 53, Train Loss: 0.6155, Val Loss: 0.6629, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 54, Train Loss: 0.6092, Val Loss: 0.7201, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 55, Train Loss: 0.6178, Val Loss: 0.6868, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 56, Train Loss: 0.6085, Val Loss: 0.6673, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 57, Train Loss: 0.6025, Val Loss: 0.6573, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 58, Train Loss: 0.6140, Val Loss: 0.6527, F1 Micro: 0.6685, F1 Macro: 0.6414, Accuracy: 0.6685\n","Epoch 59, Train Loss: 0.6013, Val Loss: 0.6850, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 60, Train Loss: 0.6119, Val Loss: 0.6926, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.6178, Val Loss: 0.6602, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 62, Train Loss: 0.6060, Val Loss: 0.6764, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.6011, Val Loss: 0.7042, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 64, Train Loss: 0.6194, Val Loss: 0.6669, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 65, Train Loss: 0.5930, Val Loss: 0.6578, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 66, Train Loss: 0.6030, Val Loss: 0.7246, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 67, Train Loss: 0.6148, Val Loss: 0.6726, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 68, Train Loss: 0.6017, Val Loss: 0.7893, F1 Micro: 0.6573, F1 Macro: 0.5880, Accuracy: 0.6573\n","Epoch 69, Train Loss: 0.6130, Val Loss: 0.6506, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.6006, Val Loss: 0.6627, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 71, Train Loss: 0.5983, Val Loss: 0.7466, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 72, Train Loss: 0.6188, Val Loss: 0.6685, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 73, Train Loss: 0.5974, Val Loss: 0.6752, F1 Micro: 0.6067, F1 Macro: 0.5919, Accuracy: 0.6067\n","Epoch 74, Train Loss: 0.6143, Val Loss: 0.6629, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 75, Train Loss: 0.6001, Val Loss: 0.6914, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 76, Train Loss: 0.6077, Val Loss: 0.6810, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 77, Train Loss: 0.6102, Val Loss: 0.7776, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 78, Train Loss: 0.6203, Val Loss: 0.6785, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 79, Train Loss: 0.6130, Val Loss: 0.6572, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 80, Train Loss: 0.6004, Val Loss: 0.7157, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 81, Train Loss: 0.6044, Val Loss: 0.7095, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 82, Train Loss: 0.6079, Val Loss: 0.6952, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 83, Train Loss: 0.6028, Val Loss: 0.6557, F1 Micro: 0.6348, F1 Macro: 0.6234, Accuracy: 0.6348\n","Epoch 84, Train Loss: 0.6013, Val Loss: 0.7101, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 85, Train Loss: 0.5926, Val Loss: 0.7062, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 86, Train Loss: 0.6106, Val Loss: 0.6597, F1 Micro: 0.6292, F1 Macro: 0.6152, Accuracy: 0.6292\n","Epoch 87, Train Loss: 0.6085, Val Loss: 0.7693, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 88, Train Loss: 0.5982, Val Loss: 0.7331, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 89, Train Loss: 0.6053, Val Loss: 0.7223, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 90, Train Loss: 0.6175, Val Loss: 0.7293, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 91, Train Loss: 0.5993, Val Loss: 0.6766, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 92, Train Loss: 0.5976, Val Loss: 0.7047, F1 Micro: 0.6798, F1 Macro: 0.6432, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.6151, Val Loss: 0.6681, F1 Micro: 0.6180, F1 Macro: 0.6109, Accuracy: 0.6180\n","Epoch 94, Train Loss: 0.6054, Val Loss: 0.6881, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 95, Train Loss: 0.6115, Val Loss: 0.6888, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 96, Train Loss: 0.5948, Val Loss: 0.7011, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 97, Train Loss: 0.6040, Val Loss: 0.7420, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 98, Train Loss: 0.6094, Val Loss: 0.7032, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 99, Train Loss: 0.5967, Val Loss: 0.6762, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 100, Train Loss: 0.5904, Val Loss: 0.6700, F1 Micro: 0.6348, F1 Macro: 0.6218, Accuracy: 0.6348\n","Epoch 101, Train Loss: 0.5872, Val Loss: 0.6700, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 102, Train Loss: 0.5953, Val Loss: 0.7141, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 103, Train Loss: 0.6007, Val Loss: 0.6660, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 104, Train Loss: 0.6153, Val Loss: 0.6847, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6935, Val Loss: 0.7211, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6597, Val Loss: 0.7234, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6595, Val Loss: 0.7202, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6592, Val Loss: 0.7335, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6608, Val Loss: 0.7160, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6609, Val Loss: 0.7156, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6601, Val Loss: 0.7275, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6642, Val Loss: 0.7167, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6603, Val Loss: 0.7203, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6652, Val Loss: 0.7212, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6644, Val Loss: 0.7208, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6602, Val Loss: 0.7225, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6651, Val Loss: 0.7192, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6600, Val Loss: 0.7206, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6598, Val Loss: 0.7235, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6644, Val Loss: 0.7213, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6603, Val Loss: 0.7231, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6653, Val Loss: 0.7239, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6639, Val Loss: 0.7177, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6609, Val Loss: 0.7334, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6598, Val Loss: 0.7170, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6648, Val Loss: 0.7221, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6652, Val Loss: 0.7216, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6647, Val Loss: 0.7204, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6607, Val Loss: 0.7149, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6589, Val Loss: 0.7300, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6599, Val Loss: 0.7299, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6599, Val Loss: 0.7282, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6650, Val Loss: 0.7252, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6654, Val Loss: 0.7250, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6598, Val Loss: 0.7263, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6649, Val Loss: 0.7285, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6650, Val Loss: 0.7268, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6597, Val Loss: 0.7266, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6596, Val Loss: 0.7252, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6663, Val Loss: 0.7272, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6646, Val Loss: 0.7189, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6606, Val Loss: 0.7202, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6594, Val Loss: 0.7273, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6649, Val Loss: 0.7202, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6601, Val Loss: 0.7176, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6602, Val Loss: 0.7165, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6641, Val Loss: 0.7186, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6596, Val Loss: 0.7259, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6603, Val Loss: 0.7276, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6599, Val Loss: 0.7143, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6601, Val Loss: 0.7211, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6589, Val Loss: 0.7293, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6652, Val Loss: 0.7237, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6607, Val Loss: 0.7203, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6646, Val Loss: 0.7214, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6800, Val Loss: 0.6816, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6698, Val Loss: 0.6800, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6732, Val Loss: 0.6800, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6738, Val Loss: 0.6808, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6693, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6746, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6700, Val Loss: 0.6801, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6700, Val Loss: 0.6833, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6691, Val Loss: 0.6820, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6695, Val Loss: 0.6801, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6736, Val Loss: 0.6803, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6693, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6693, Val Loss: 0.6827, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6696, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6734, Val Loss: 0.6834, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6697, Val Loss: 0.6798, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6693, Val Loss: 0.6830, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6694, Val Loss: 0.6813, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6694, Val Loss: 0.6802, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6692, Val Loss: 0.6825, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 21, Train Loss: 0.6694, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6690, Val Loss: 0.6825, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6734, Val Loss: 0.6812, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 24, Train Loss: 0.6739, Val Loss: 0.6840, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6697, Val Loss: 0.6832, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6736, Val Loss: 0.6818, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.6710, Val Loss: 0.6816, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6750, Val Loss: 0.6814, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6736, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6748, Val Loss: 0.6809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6697, Val Loss: 0.6798, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6697, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6741, Val Loss: 0.6816, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6732, Val Loss: 0.6800, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6700, Val Loss: 0.6804, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6693, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6688, Val Loss: 0.6819, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.6693, Val Loss: 0.6818, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.6750, Val Loss: 0.6807, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 40, Train Loss: 0.6701, Val Loss: 0.6816, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6740, Val Loss: 0.6823, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6692, Val Loss: 0.6833, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.6704, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.6691, Val Loss: 0.6806, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6695, Val Loss: 0.6810, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.6688, Val Loss: 0.6827, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6703, Val Loss: 0.6800, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6703, Val Loss: 0.6811, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6689, Val Loss: 0.6829, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6697, Val Loss: 0.6822, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 51, Train Loss: 0.6691, Val Loss: 0.6827, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.6520871257297094\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7401, Val Loss: 0.6823, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6786, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6749, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6753, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6778, Val Loss: 0.6738, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6752, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 7, Train Loss: 0.6755, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6743, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6755, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6740, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 11, Train Loss: 0.6753, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6670, Val Loss: 0.6538, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 2, Train Loss: 0.6504, Val Loss: 0.6053, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 3, Train Loss: 0.6528, Val Loss: 0.6596, F1 Micro: 0.7247, F1 Macro: 0.7077, Accuracy: 0.7247\n","Epoch 4, Train Loss: 0.6501, Val Loss: 0.6174, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 5, Train Loss: 0.6591, Val Loss: 0.6880, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6494, Val Loss: 0.5979, F1 Micro: 0.7697, F1 Macro: 0.7095, Accuracy: 0.7697\n","Epoch 7, Train Loss: 0.6459, Val Loss: 0.6678, F1 Micro: 0.6067, F1 Macro: 0.6067, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6535, Val Loss: 0.6037, F1 Micro: 0.7921, F1 Macro: 0.7528, Accuracy: 0.7921\n","Epoch 9, Train Loss: 0.6453, Val Loss: 0.5934, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 10, Train Loss: 0.6340, Val Loss: 0.5916, F1 Micro: 0.7697, F1 Macro: 0.7367, Accuracy: 0.7697\n","Epoch 11, Train Loss: 0.6418, Val Loss: 0.5907, F1 Micro: 0.7753, F1 Macro: 0.7419, Accuracy: 0.7753\n","Epoch 12, Train Loss: 0.6321, Val Loss: 0.5955, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 13, Train Loss: 0.6397, Val Loss: 0.6816, F1 Micro: 0.5000, F1 Macro: 0.4899, Accuracy: 0.5000\n","Epoch 14, Train Loss: 0.6426, Val Loss: 0.5830, F1 Micro: 0.7865, F1 Macro: 0.7475, Accuracy: 0.7865\n","Epoch 15, Train Loss: 0.6288, Val Loss: 0.5939, F1 Micro: 0.7584, F1 Macro: 0.7263, Accuracy: 0.7584\n","Epoch 16, Train Loss: 0.6420, Val Loss: 0.6158, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 17, Train Loss: 0.6409, Val Loss: 0.5806, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 18, Train Loss: 0.6316, Val Loss: 0.5934, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7353, Val Loss: 0.6805, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6722, Val Loss: 0.6805, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6724, Val Loss: 0.6785, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6680, Val Loss: 0.6983, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6600, Val Loss: 0.7855, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6523, Val Loss: 0.6868, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6444, Val Loss: 0.6913, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6463, Val Loss: 0.6819, F1 Micro: 0.6517, F1 Macro: 0.6103, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6505, Val Loss: 0.7761, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 10, Train Loss: 0.6885, Val Loss: 0.6799, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6435, Val Loss: 0.7274, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6442, Val Loss: 0.7954, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6527, Val Loss: 0.7769, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6571, Val Loss: 0.7396, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6280, Val Loss: 0.7397, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 16, Train Loss: 0.6266, Val Loss: 0.6841, F1 Micro: 0.6742, F1 Macro: 0.6355, Accuracy: 0.6742\n","Epoch 17, Train Loss: 0.6187, Val Loss: 0.7921, F1 Micro: 0.6292, F1 Macro: 0.5780, Accuracy: 0.6292\n","Epoch 18, Train Loss: 0.6251, Val Loss: 0.7726, F1 Micro: 0.6461, F1 Macro: 0.5835, Accuracy: 0.6461\n","Epoch 19, Train Loss: 0.6245, Val Loss: 0.7053, F1 Micro: 0.5506, F1 Macro: 0.5469, Accuracy: 0.5506\n","Epoch 20, Train Loss: 0.6379, Val Loss: 0.7489, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 21, Train Loss: 0.6363, Val Loss: 0.7617, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 22, Train Loss: 0.6345, Val Loss: 0.7370, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.6084, Val Loss: 0.7747, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 24, Train Loss: 0.6224, Val Loss: 0.7780, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 25, Train Loss: 0.6340, Val Loss: 0.7985, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 26, Train Loss: 0.6249, Val Loss: 0.8836, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6841, Val Loss: 0.6523, F1 Micro: 0.6348, F1 Macro: 0.6348, Accuracy: 0.6348\n","Epoch 2, Train Loss: 0.6759, Val Loss: 0.6615, F1 Micro: 0.6685, F1 Macro: 0.6639, Accuracy: 0.6685\n","Epoch 3, Train Loss: 0.6303, Val Loss: 0.6988, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 4, Train Loss: 0.6325, Val Loss: 0.7088, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6247, Val Loss: 0.6722, F1 Micro: 0.6404, F1 Macro: 0.6299, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6331, Val Loss: 0.8135, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 7, Train Loss: 0.6155, Val Loss: 0.6882, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6150, Val Loss: 0.6567, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6297, Val Loss: 0.6553, F1 Micro: 0.6629, F1 Macro: 0.6608, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6292, Val Loss: 0.7578, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 11, Train Loss: 0.6210, Val Loss: 0.7450, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 12, Train Loss: 0.6262, Val Loss: 0.6747, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7398, Val Loss: 0.6855, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6709, Val Loss: 0.6901, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6717, Val Loss: 0.6926, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6704, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6716, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6710, Val Loss: 0.6914, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6719, Val Loss: 0.6923, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6700, Val Loss: 0.6909, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6708, Val Loss: 0.6932, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6696, Val Loss: 0.6920, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6709, Val Loss: 0.6925, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.6756826313476869\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7093, Val Loss: 0.6748, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6762, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.6737, Val Loss: 0.6737, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6744, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.6742, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 6, Train Loss: 0.6755, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 7, Train Loss: 0.6742, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6763, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6748, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6768, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 11, Train Loss: 0.6749, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 12, Train Loss: 0.6744, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 13, Train Loss: 0.6746, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 14, Train Loss: 0.6742, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 15, Train Loss: 0.6758, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 16, Train Loss: 0.6746, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 17, Train Loss: 0.6745, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 18, Train Loss: 0.6761, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 19, Train Loss: 0.6737, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 20, Train Loss: 0.6741, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 21, Train Loss: 0.6740, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 22, Train Loss: 0.6752, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 23, Train Loss: 0.6743, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 24, Train Loss: 0.6751, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 25, Train Loss: 0.6745, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 26, Train Loss: 0.6758, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 27, Train Loss: 0.6751, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 28, Train Loss: 0.6745, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 29, Train Loss: 0.6738, Val Loss: 0.6736, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 30, Train Loss: 0.6735, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 31, Train Loss: 0.6749, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 32, Train Loss: 0.6739, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 33, Train Loss: 0.6753, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 34, Train Loss: 0.6740, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 35, Train Loss: 0.6745, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 36, Train Loss: 0.6758, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 37, Train Loss: 0.6747, Val Loss: 0.6740, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 38, Train Loss: 0.6752, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 39, Train Loss: 0.6755, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 40, Train Loss: 0.6755, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 41, Train Loss: 0.6754, Val Loss: 0.6738, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 42, Train Loss: 0.6758, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 43, Train Loss: 0.6756, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 44, Train Loss: 0.6742, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 45, Train Loss: 0.6760, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 46, Train Loss: 0.6759, Val Loss: 0.6734, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 47, Train Loss: 0.6752, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 48, Train Loss: 0.6745, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 49, Train Loss: 0.6757, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 50, Train Loss: 0.6741, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 51, Train Loss: 0.6746, Val Loss: 0.6735, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6860, Val Loss: 0.6125, F1 Micro: 0.7079, F1 Macro: 0.6427, Accuracy: 0.7079\n","Epoch 2, Train Loss: 0.6481, Val Loss: 0.5738, F1 Micro: 0.7640, F1 Macro: 0.7237, Accuracy: 0.7640\n","Epoch 3, Train Loss: 0.6352, Val Loss: 0.6079, F1 Micro: 0.7640, F1 Macro: 0.7005, Accuracy: 0.7640\n","Epoch 4, Train Loss: 0.6377, Val Loss: 0.6355, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 5, Train Loss: 0.6445, Val Loss: 0.5731, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 6, Train Loss: 0.6452, Val Loss: 0.5836, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 7, Train Loss: 0.6691, Val Loss: 0.5868, F1 Micro: 0.7809, F1 Macro: 0.7305, Accuracy: 0.7809\n","Epoch 8, Train Loss: 0.6341, Val Loss: 0.6026, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 9, Train Loss: 0.6278, Val Loss: 0.5721, F1 Micro: 0.7809, F1 Macro: 0.7336, Accuracy: 0.7809\n","Epoch 10, Train Loss: 0.6386, Val Loss: 0.6828, F1 Micro: 0.4663, F1 Macro: 0.4448, Accuracy: 0.4663\n","Epoch 11, Train Loss: 0.6368, Val Loss: 0.5782, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 12, Train Loss: 0.6319, Val Loss: 0.5861, F1 Micro: 0.7753, F1 Macro: 0.7395, Accuracy: 0.7753\n","Epoch 13, Train Loss: 0.6484, Val Loss: 0.6090, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 14, Train Loss: 0.6348, Val Loss: 0.5943, F1 Micro: 0.7809, F1 Macro: 0.7422, Accuracy: 0.7809\n","Epoch 15, Train Loss: 0.6273, Val Loss: 0.5935, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 16, Train Loss: 0.6297, Val Loss: 0.5789, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 17, Train Loss: 0.6414, Val Loss: 0.5929, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 18, Train Loss: 0.6256, Val Loss: 0.6003, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 19, Train Loss: 0.6328, Val Loss: 0.5733, F1 Micro: 0.7921, F1 Macro: 0.7473, Accuracy: 0.7921\n","Epoch 20, Train Loss: 0.6253, Val Loss: 0.5919, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 21, Train Loss: 0.6230, Val Loss: 0.5842, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.6352, Val Loss: 0.5718, F1 Micro: 0.7809, F1 Macro: 0.7305, Accuracy: 0.7809\n","Epoch 23, Train Loss: 0.6361, Val Loss: 0.5963, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 24, Train Loss: 0.6432, Val Loss: 0.5765, F1 Micro: 0.7809, F1 Macro: 0.7472, Accuracy: 0.7809\n","Epoch 25, Train Loss: 0.6257, Val Loss: 0.5809, F1 Micro: 0.7584, F1 Macro: 0.7238, Accuracy: 0.7584\n","Epoch 26, Train Loss: 0.6392, Val Loss: 0.5902, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 27, Train Loss: 0.6190, Val Loss: 0.5733, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 28, Train Loss: 0.6213, Val Loss: 0.5809, F1 Micro: 0.7135, F1 Macro: 0.6236, Accuracy: 0.7135\n","Epoch 29, Train Loss: 0.6265, Val Loss: 0.5756, F1 Micro: 0.7528, F1 Macro: 0.7161, Accuracy: 0.7528\n","Epoch 30, Train Loss: 0.6280, Val Loss: 0.5731, F1 Micro: 0.7921, F1 Macro: 0.7473, Accuracy: 0.7921\n","Epoch 31, Train Loss: 0.6237, Val Loss: 0.5619, F1 Micro: 0.7809, F1 Macro: 0.7394, Accuracy: 0.7809\n","Epoch 32, Train Loss: 0.6200, Val Loss: 0.5655, F1 Micro: 0.7697, F1 Macro: 0.7199, Accuracy: 0.7697\n","Epoch 33, Train Loss: 0.6253, Val Loss: 0.5755, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 34, Train Loss: 0.6308, Val Loss: 0.5602, F1 Micro: 0.7697, F1 Macro: 0.7132, Accuracy: 0.7697\n","Epoch 35, Train Loss: 0.6236, Val Loss: 0.5774, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 36, Train Loss: 0.6148, Val Loss: 0.6582, F1 Micro: 0.5618, F1 Macro: 0.5598, Accuracy: 0.5618\n","Epoch 37, Train Loss: 0.6553, Val Loss: 0.5755, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 38, Train Loss: 0.6164, Val Loss: 0.5714, F1 Micro: 0.7865, F1 Macro: 0.7525, Accuracy: 0.7865\n","Epoch 39, Train Loss: 0.6391, Val Loss: 0.6126, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 40, Train Loss: 0.6428, Val Loss: 0.5880, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 41, Train Loss: 0.6205, Val Loss: 0.5766, F1 Micro: 0.7753, F1 Macro: 0.7342, Accuracy: 0.7753\n","Epoch 42, Train Loss: 0.6263, Val Loss: 0.5848, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 43, Train Loss: 0.6330, Val Loss: 0.5690, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 44, Train Loss: 0.6263, Val Loss: 0.5860, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 45, Train Loss: 0.6190, Val Loss: 0.5910, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 46, Train Loss: 0.6182, Val Loss: 0.5640, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 47, Train Loss: 0.6157, Val Loss: 0.5761, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 48, Train Loss: 0.6107, Val Loss: 0.5633, F1 Micro: 0.7753, F1 Macro: 0.7369, Accuracy: 0.7753\n","Epoch 49, Train Loss: 0.6273, Val Loss: 0.5907, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 50, Train Loss: 0.6317, Val Loss: 0.5665, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 51, Train Loss: 0.6278, Val Loss: 0.5633, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 52, Train Loss: 0.6383, Val Loss: 0.5821, F1 Micro: 0.7472, F1 Macro: 0.6994, Accuracy: 0.7472\n","Epoch 53, Train Loss: 0.6260, Val Loss: 0.5719, F1 Micro: 0.7753, F1 Macro: 0.7443, Accuracy: 0.7753\n","Epoch 54, Train Loss: 0.6155, Val Loss: 0.5622, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 55, Train Loss: 0.6269, Val Loss: 0.6031, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 56, Train Loss: 0.6155, Val Loss: 0.5876, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 57, Train Loss: 0.6272, Val Loss: 0.5861, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 58, Train Loss: 0.6215, Val Loss: 0.6037, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 59, Train Loss: 0.6208, Val Loss: 0.5816, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 60, Train Loss: 0.6229, Val Loss: 0.5872, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 61, Train Loss: 0.6345, Val Loss: 0.5690, F1 Micro: 0.7640, F1 Macro: 0.7264, Accuracy: 0.7640\n","Epoch 62, Train Loss: 0.6226, Val Loss: 0.5771, F1 Micro: 0.7640, F1 Macro: 0.7315, Accuracy: 0.7640\n","Epoch 63, Train Loss: 0.6213, Val Loss: 0.5743, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 64, Train Loss: 0.6207, Val Loss: 0.5615, F1 Micro: 0.7640, F1 Macro: 0.7209, Accuracy: 0.7640\n","Epoch 65, Train Loss: 0.6232, Val Loss: 0.5641, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 66, Train Loss: 0.6232, Val Loss: 0.5875, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 67, Train Loss: 0.6322, Val Loss: 0.5715, F1 Micro: 0.7360, F1 Macro: 0.6981, Accuracy: 0.7360\n","Epoch 68, Train Loss: 0.6267, Val Loss: 0.5687, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 69, Train Loss: 0.6205, Val Loss: 0.5648, F1 Micro: 0.7528, F1 Macro: 0.7012, Accuracy: 0.7528\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7613, Val Loss: 0.6844, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6744, Val Loss: 0.6815, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6734, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6718, Val Loss: 0.6819, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6733, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6728, Val Loss: 0.6816, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6722, Val Loss: 0.6829, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6743, Val Loss: 0.6819, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6724, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6730, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6736, Val Loss: 0.6819, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6725, Val Loss: 0.6812, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6723, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6735, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6724, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6730, Val Loss: 0.6827, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6723, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6738, Val Loss: 0.6835, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6732, Val Loss: 0.6814, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6721, Val Loss: 0.6816, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6716, Val Loss: 0.6826, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6734, Val Loss: 0.6815, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6725, Val Loss: 0.6827, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6724, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6725, Val Loss: 0.6815, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6716, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6728, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6736, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6725, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6742, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6739, Val Loss: 0.6824, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6741, Val Loss: 0.6831, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6741, Val Loss: 0.6825, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6731, Val Loss: 0.6816, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6728, Val Loss: 0.6828, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6731, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6726, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6712, Val Loss: 0.6825, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6737, Val Loss: 0.6823, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6739, Val Loss: 0.6813, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6731, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6723, Val Loss: 0.6817, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6719, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6729, Val Loss: 0.6828, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6727, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6727, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6730, Val Loss: 0.6822, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6754, Val Loss: 0.6831, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6743, Val Loss: 0.6818, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6734, Val Loss: 0.6821, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6721, Val Loss: 0.6825, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6728, Val Loss: 0.7263, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6612, Val Loss: 0.7306, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6619, Val Loss: 0.7370, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6609, Val Loss: 0.7350, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6618, Val Loss: 0.7307, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6607, Val Loss: 0.7341, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6604, Val Loss: 0.7372, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6629, Val Loss: 0.7351, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6635, Val Loss: 0.7388, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6612, Val Loss: 0.7292, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6613, Val Loss: 0.7352, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6614, Val Loss: 0.7351, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6606, Val Loss: 0.7333, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6600, Val Loss: 0.7301, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6610, Val Loss: 0.7336, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6618, Val Loss: 0.7326, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6619, Val Loss: 0.7395, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6624, Val Loss: 0.7426, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6609, Val Loss: 0.7331, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6608, Val Loss: 0.7324, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6612, Val Loss: 0.7343, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6613, Val Loss: 0.7345, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6608, Val Loss: 0.7334, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6612, Val Loss: 0.7380, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6618, Val Loss: 0.7310, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6610, Val Loss: 0.7301, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6615, Val Loss: 0.7317, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6607, Val Loss: 0.7356, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6612, Val Loss: 0.7332, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6610, Val Loss: 0.7361, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6624, Val Loss: 0.7288, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6614, Val Loss: 0.7329, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6631, Val Loss: 0.7335, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6614, Val Loss: 0.7334, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6628, Val Loss: 0.7360, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6615, Val Loss: 0.7363, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6619, Val Loss: 0.7331, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6625, Val Loss: 0.7380, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6620, Val Loss: 0.7288, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6600, Val Loss: 0.7297, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6612, Val Loss: 0.7367, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6614, Val Loss: 0.7390, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6607, Val Loss: 0.7363, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6617, Val Loss: 0.7409, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6618, Val Loss: 0.7328, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6607, Val Loss: 0.7337, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6601, Val Loss: 0.7372, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6612, Val Loss: 0.7351, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6614, Val Loss: 0.7391, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6614, Val Loss: 0.7313, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6612, Val Loss: 0.7344, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6823, Val Loss: 0.6718, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 2, Train Loss: 0.6367, Val Loss: 0.6565, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 3, Train Loss: 0.6380, Val Loss: 0.6781, F1 Micro: 0.5056, F1 Macro: 0.4979, Accuracy: 0.5056\n","Epoch 4, Train Loss: 0.6433, Val Loss: 0.6653, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6329, Val Loss: 0.6799, F1 Micro: 0.5112, F1 Macro: 0.5056, Accuracy: 0.5112\n","Epoch 6, Train Loss: 0.6330, Val Loss: 0.6460, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 7, Train Loss: 0.6304, Val Loss: 0.6440, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6156, Val Loss: 0.6979, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 9, Train Loss: 0.6386, Val Loss: 0.6351, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 10, Train Loss: 0.6186, Val Loss: 0.6319, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6252, Val Loss: 0.6276, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 12, Train Loss: 0.6423, Val Loss: 0.6254, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 13, Train Loss: 0.6257, Val Loss: 0.6187, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.6465, Val Loss: 0.6331, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 15, Train Loss: 0.6217, Val Loss: 0.6308, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 16, Train Loss: 0.6292, Val Loss: 0.6305, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 17, Train Loss: 0.6144, Val Loss: 0.6334, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.6173, Val Loss: 0.6102, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 19, Train Loss: 0.6267, Val Loss: 0.6288, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 20, Train Loss: 0.6188, Val Loss: 0.6170, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 21, Train Loss: 0.6166, Val Loss: 0.6576, F1 Micro: 0.6124, F1 Macro: 0.6122, Accuracy: 0.6124\n","Epoch 22, Train Loss: 0.6387, Val Loss: 0.6263, F1 Micro: 0.6966, F1 Macro: 0.6706, Accuracy: 0.6966\n","Epoch 23, Train Loss: 0.6090, Val Loss: 0.6325, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.6165, Val Loss: 0.6445, F1 Micro: 0.6348, F1 Macro: 0.6339, Accuracy: 0.6348\n","Epoch 25, Train Loss: 0.6203, Val Loss: 0.6134, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6157, Val Loss: 0.6184, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6267, Val Loss: 0.6186, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 28, Train Loss: 0.6193, Val Loss: 0.6073, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 29, Train Loss: 0.6164, Val Loss: 0.6197, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 30, Train Loss: 0.6191, Val Loss: 0.6188, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 31, Train Loss: 0.6132, Val Loss: 0.6166, F1 Micro: 0.6854, F1 Macro: 0.6668, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.6200, Val Loss: 0.6136, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 33, Train Loss: 0.6188, Val Loss: 0.6503, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 34, Train Loss: 0.6208, Val Loss: 0.6288, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6134, Val Loss: 0.6144, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 36, Train Loss: 0.6096, Val Loss: 0.5977, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 37, Train Loss: 0.6317, Val Loss: 0.6401, F1 Micro: 0.6292, F1 Macro: 0.6292, Accuracy: 0.6292\n","Epoch 38, Train Loss: 0.6232, Val Loss: 0.6173, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.6255, Val Loss: 0.6676, F1 Micro: 0.5169, F1 Macro: 0.5094, Accuracy: 0.5169\n","Epoch 40, Train Loss: 0.6136, Val Loss: 0.6088, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 41, Train Loss: 0.6079, Val Loss: 0.6025, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 42, Train Loss: 0.6190, Val Loss: 0.6286, F1 Micro: 0.6517, F1 Macro: 0.6481, Accuracy: 0.6517\n","Epoch 43, Train Loss: 0.6289, Val Loss: 0.6194, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 44, Train Loss: 0.6138, Val Loss: 0.6006, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6175, Val Loss: 0.6113, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.6048, Val Loss: 0.5980, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 47, Train Loss: 0.6131, Val Loss: 0.6114, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 48, Train Loss: 0.6136, Val Loss: 0.6099, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 49, Train Loss: 0.6227, Val Loss: 0.6041, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 50, Train Loss: 0.6098, Val Loss: 0.6013, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 51, Train Loss: 0.5947, Val Loss: 0.6006, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 52, Train Loss: 0.6017, Val Loss: 0.5868, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 53, Train Loss: 0.6110, Val Loss: 0.6158, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 54, Train Loss: 0.6110, Val Loss: 0.6159, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 55, Train Loss: 0.6227, Val Loss: 0.6060, F1 Micro: 0.7472, F1 Macro: 0.7160, Accuracy: 0.7472\n","Epoch 56, Train Loss: 0.6185, Val Loss: 0.5993, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 57, Train Loss: 0.6076, Val Loss: 0.6144, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 58, Train Loss: 0.6119, Val Loss: 0.5990, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 59, Train Loss: 0.6180, Val Loss: 0.6168, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 60, Train Loss: 0.6074, Val Loss: 0.6209, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 61, Train Loss: 0.6086, Val Loss: 0.5934, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 62, Train Loss: 0.6169, Val Loss: 0.5996, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 63, Train Loss: 0.5973, Val Loss: 0.6230, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.6291, Val Loss: 0.6069, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 65, Train Loss: 0.6042, Val Loss: 0.6168, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 66, Train Loss: 0.6057, Val Loss: 0.6571, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.6103, Val Loss: 0.5941, F1 Micro: 0.7135, F1 Macro: 0.6957, Accuracy: 0.7135\n","Epoch 68, Train Loss: 0.6088, Val Loss: 0.5943, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 69, Train Loss: 0.6247, Val Loss: 0.5975, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 70, Train Loss: 0.5952, Val Loss: 0.5983, F1 Micro: 0.7640, F1 Macro: 0.7360, Accuracy: 0.7640\n","Epoch 71, Train Loss: 0.6075, Val Loss: 0.6032, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 72, Train Loss: 0.6101, Val Loss: 0.5966, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 73, Train Loss: 0.5987, Val Loss: 0.6048, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 74, Train Loss: 0.6068, Val Loss: 0.6067, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 75, Train Loss: 0.6085, Val Loss: 0.5899, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 76, Train Loss: 0.5991, Val Loss: 0.6008, F1 Micro: 0.6854, F1 Macro: 0.6749, Accuracy: 0.6854\n","Epoch 77, Train Loss: 0.5998, Val Loss: 0.5885, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 78, Train Loss: 0.6039, Val Loss: 0.6600, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 79, Train Loss: 0.6058, Val Loss: 0.6008, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 80, Train Loss: 0.6071, Val Loss: 0.6143, F1 Micro: 0.7191, F1 Macro: 0.6711, Accuracy: 0.7191\n","Epoch 81, Train Loss: 0.6033, Val Loss: 0.5973, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 82, Train Loss: 0.5992, Val Loss: 0.5897, F1 Micro: 0.7022, F1 Macro: 0.6856, Accuracy: 0.7022\n","Epoch 83, Train Loss: 0.5970, Val Loss: 0.6005, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 84, Train Loss: 0.5999, Val Loss: 0.6318, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 85, Train Loss: 0.6065, Val Loss: 0.5926, F1 Micro: 0.7079, F1 Macro: 0.7005, Accuracy: 0.7079\n","Epoch 86, Train Loss: 0.6043, Val Loss: 0.6216, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 87, Train Loss: 0.6132, Val Loss: 0.6049, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 88, Train Loss: 0.6094, Val Loss: 0.6281, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 89, Train Loss: 0.6137, Val Loss: 0.5985, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 90, Train Loss: 0.6015, Val Loss: 0.5922, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 91, Train Loss: 0.6034, Val Loss: 0.6015, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 92, Train Loss: 0.6101, Val Loss: 0.5975, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 93, Train Loss: 0.5993, Val Loss: 0.6085, F1 Micro: 0.7528, F1 Macro: 0.7211, Accuracy: 0.7528\n","Epoch 94, Train Loss: 0.6052, Val Loss: 0.6010, F1 Micro: 0.6798, F1 Macro: 0.6684, Accuracy: 0.6798\n","Epoch 95, Train Loss: 0.6158, Val Loss: 0.6232, F1 Micro: 0.6404, F1 Macro: 0.6349, Accuracy: 0.6404\n","Epoch 96, Train Loss: 0.6007, Val Loss: 0.6023, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 97, Train Loss: 0.5991, Val Loss: 0.5960, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 98, Train Loss: 0.6107, Val Loss: 0.6093, F1 Micro: 0.6517, F1 Macro: 0.6501, Accuracy: 0.6517\n","Epoch 99, Train Loss: 0.6070, Val Loss: 0.5858, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 100, Train Loss: 0.6067, Val Loss: 0.5924, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 101, Train Loss: 0.5986, Val Loss: 0.5897, F1 Micro: 0.7416, F1 Macro: 0.7194, Accuracy: 0.7416\n","Epoch 102, Train Loss: 0.6081, Val Loss: 0.5997, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 103, Train Loss: 0.5975, Val Loss: 0.6054, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 104, Train Loss: 0.6103, Val Loss: 0.6396, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 105, Train Loss: 0.5917, Val Loss: 0.5892, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 106, Train Loss: 0.6029, Val Loss: 0.6222, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 107, Train Loss: 0.6021, Val Loss: 0.5886, F1 Micro: 0.7079, F1 Macro: 0.6954, Accuracy: 0.7079\n","Epoch 108, Train Loss: 0.6105, Val Loss: 0.5972, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 109, Train Loss: 0.5874, Val Loss: 0.5968, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 110, Train Loss: 0.6014, Val Loss: 0.5883, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 111, Train Loss: 0.5960, Val Loss: 0.6140, F1 Micro: 0.6517, F1 Macro: 0.6428, Accuracy: 0.6517\n","Epoch 112, Train Loss: 0.5993, Val Loss: 0.5869, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 113, Train Loss: 0.6065, Val Loss: 0.5906, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 114, Train Loss: 0.6044, Val Loss: 0.6037, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 115, Train Loss: 0.6059, Val Loss: 0.6281, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 116, Train Loss: 0.6054, Val Loss: 0.6217, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 117, Train Loss: 0.6020, Val Loss: 0.6150, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 118, Train Loss: 0.6148, Val Loss: 0.6044, F1 Micro: 0.6517, F1 Macro: 0.6452, Accuracy: 0.6517\n","Epoch 119, Train Loss: 0.5986, Val Loss: 0.5948, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 120, Train Loss: 0.5882, Val Loss: 0.5989, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.6689410583139791\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7393, Val Loss: 0.7805, F1 Micro: 0.6983, F1 Macro: 0.6760, Accuracy: 0.6983\n","Epoch 2, Train Loss: 0.6948, Val Loss: 0.7379, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 3, Train Loss: 0.6778, Val Loss: 1.0389, F1 Micro: 0.6425, F1 Macro: 0.5250, Accuracy: 0.6425\n","Epoch 4, Train Loss: 0.6730, Val Loss: 0.6494, F1 Micro: 0.6872, F1 Macro: 0.6640, Accuracy: 0.6872\n","Epoch 5, Train Loss: 0.6595, Val Loss: 0.6877, F1 Micro: 0.5587, F1 Macro: 0.5567, Accuracy: 0.5587\n","Epoch 6, Train Loss: 0.6539, Val Loss: 0.6477, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 7, Train Loss: 0.6566, Val Loss: 0.6649, F1 Micro: 0.6760, F1 Macro: 0.5872, Accuracy: 0.6760\n","Epoch 8, Train Loss: 0.6554, Val Loss: 0.6380, F1 Micro: 0.6704, F1 Macro: 0.6400, Accuracy: 0.6704\n","Epoch 9, Train Loss: 0.6485, Val Loss: 0.6426, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 10, Train Loss: 0.6517, Val Loss: 0.6532, F1 Micro: 0.6089, F1 Macro: 0.5998, Accuracy: 0.6089\n","Epoch 11, Train Loss: 0.6383, Val Loss: 0.6461, F1 Micro: 0.6704, F1 Macro: 0.6492, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7267, Val Loss: 0.8403, F1 Micro: 0.6685, F1 Macro: 0.5285, Accuracy: 0.6685\n","Epoch 2, Train Loss: 0.6685, Val Loss: 0.5992, F1 Micro: 0.7360, F1 Macro: 0.6712, Accuracy: 0.7360\n","Epoch 3, Train Loss: 0.6387, Val Loss: 0.5951, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 4, Train Loss: 0.6451, Val Loss: 0.6143, F1 Micro: 0.7191, F1 Macro: 0.6336, Accuracy: 0.7191\n","Epoch 5, Train Loss: 0.6431, Val Loss: 0.5975, F1 Micro: 0.7247, F1 Macro: 0.6824, Accuracy: 0.7247\n","Epoch 6, Train Loss: 0.6454, Val Loss: 0.6021, F1 Micro: 0.7191, F1 Macro: 0.7008, Accuracy: 0.7191\n","Epoch 7, Train Loss: 0.6325, Val Loss: 0.5835, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 8, Train Loss: 0.6309, Val Loss: 0.5777, F1 Micro: 0.7753, F1 Macro: 0.7342, Accuracy: 0.7753\n","Epoch 9, Train Loss: 0.6391, Val Loss: 0.5704, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 10, Train Loss: 0.6367, Val Loss: 0.5862, F1 Micro: 0.7697, F1 Macro: 0.7367, Accuracy: 0.7697\n","Epoch 11, Train Loss: 0.6273, Val Loss: 0.5811, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 12, Train Loss: 0.6457, Val Loss: 0.5895, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 13, Train Loss: 0.6313, Val Loss: 0.5825, F1 Micro: 0.7247, F1 Macro: 0.6434, Accuracy: 0.7247\n","Epoch 14, Train Loss: 0.6415, Val Loss: 0.5766, F1 Micro: 0.7360, F1 Macro: 0.6826, Accuracy: 0.7360\n","Epoch 15, Train Loss: 0.6317, Val Loss: 0.5792, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 16, Train Loss: 0.6330, Val Loss: 0.5828, F1 Micro: 0.7528, F1 Macro: 0.6941, Accuracy: 0.7528\n","Epoch 17, Train Loss: 0.6338, Val Loss: 0.5810, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 18, Train Loss: 0.6284, Val Loss: 0.5765, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7077, Val Loss: 0.6718, F1 Micro: 0.6180, F1 Macro: 0.6035, Accuracy: 0.6180\n","Epoch 2, Train Loss: 0.6751, Val Loss: 0.6847, F1 Micro: 0.5169, F1 Macro: 0.5119, Accuracy: 0.5169\n","Epoch 3, Train Loss: 0.6508, Val Loss: 0.6750, F1 Micro: 0.6517, F1 Macro: 0.6103, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6508, Val Loss: 0.7299, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 5, Train Loss: 0.6474, Val Loss: 0.7263, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 6, Train Loss: 0.6534, Val Loss: 0.7365, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6407, Val Loss: 0.6603, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 8, Train Loss: 0.6361, Val Loss: 0.6866, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6453, Val Loss: 0.6677, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6447, Val Loss: 0.6706, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.6337, Val Loss: 0.6954, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6343, Val Loss: 0.7027, F1 Micro: 0.6180, F1 Macro: 0.5481, Accuracy: 0.6180\n","Epoch 13, Train Loss: 0.6312, Val Loss: 0.6590, F1 Micro: 0.6348, F1 Macro: 0.5657, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.6300, Val Loss: 0.6725, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 15, Train Loss: 0.6305, Val Loss: 0.7202, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6231, Val Loss: 0.6982, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 17, Train Loss: 0.6239, Val Loss: 0.6976, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.6185, Val Loss: 0.6870, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 19, Train Loss: 0.6301, Val Loss: 0.6567, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 20, Train Loss: 0.6159, Val Loss: 0.6730, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6623, Val Loss: 0.8212, F1 Micro: 0.5899, F1 Macro: 0.5014, Accuracy: 0.5899\n","Epoch 2, Train Loss: 0.6408, Val Loss: 0.6829, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 3, Train Loss: 0.6317, Val Loss: 0.7664, F1 Micro: 0.5955, F1 Macro: 0.5110, Accuracy: 0.5955\n","Epoch 4, Train Loss: 0.6271, Val Loss: 0.7390, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 5, Train Loss: 0.6229, Val Loss: 0.7017, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6232, Val Loss: 0.6677, F1 Micro: 0.6236, F1 Macro: 0.6201, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6184, Val Loss: 0.7241, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.6220, Val Loss: 0.6750, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6147, Val Loss: 0.6828, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 10, Train Loss: 0.6329, Val Loss: 0.6796, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 11, Train Loss: 0.6122, Val Loss: 0.6585, F1 Micro: 0.6348, F1 Macro: 0.6262, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6147, Val Loss: 0.6684, F1 Micro: 0.6292, F1 Macro: 0.6095, Accuracy: 0.6292\n","Epoch 13, Train Loss: 0.6280, Val Loss: 0.6820, F1 Micro: 0.6236, F1 Macro: 0.5870, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6056, Val Loss: 0.6559, F1 Micro: 0.6573, F1 Macro: 0.6549, Accuracy: 0.6573\n","Epoch 15, Train Loss: 0.6067, Val Loss: 0.6573, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6106, Val Loss: 0.6564, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.6037, Val Loss: 0.7399, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6122, Val Loss: 0.6626, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 19, Train Loss: 0.6126, Val Loss: 0.6981, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 20, Train Loss: 0.6074, Val Loss: 0.7070, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.6065, Val Loss: 0.6873, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.5981, Val Loss: 0.7215, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.6100, Val Loss: 0.6952, F1 Micro: 0.6180, F1 Macro: 0.5823, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.5982, Val Loss: 0.6801, F1 Micro: 0.6404, F1 Macro: 0.6123, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6637, Val Loss: 0.6747, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6373, Val Loss: 0.7355, F1 Micro: 0.6404, F1 Macro: 0.4746, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6315, Val Loss: 0.6595, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6282, Val Loss: 0.6404, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 5, Train Loss: 0.6272, Val Loss: 0.6635, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6328, Val Loss: 0.6368, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 7, Train Loss: 0.6252, Val Loss: 0.6574, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6216, Val Loss: 0.6282, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 9, Train Loss: 0.6252, Val Loss: 0.6381, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.6209, Val Loss: 0.6631, F1 Micro: 0.6292, F1 Macro: 0.4858, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6249, Val Loss: 0.6486, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 12, Train Loss: 0.6221, Val Loss: 0.6249, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 13, Train Loss: 0.6217, Val Loss: 0.6289, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.6356, Val Loss: 0.6312, F1 Micro: 0.7022, F1 Macro: 0.6756, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6175, Val Loss: 0.6216, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 16, Train Loss: 0.6275, Val Loss: 0.6334, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6152, Val Loss: 0.6166, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6207, Val Loss: 0.6324, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.7070805348063524\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8057, Val Loss: 0.7869, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 2, Train Loss: 0.7595, Val Loss: 0.7575, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 3, Train Loss: 0.7364, Val Loss: 0.7340, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 4, Train Loss: 0.7188, Val Loss: 0.7158, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 5, Train Loss: 0.7058, Val Loss: 0.7020, F1 Micro: 0.3575, F1 Macro: 0.2634, Accuracy: 0.3575\n","Epoch 6, Train Loss: 0.6962, Val Loss: 0.6923, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 7, Train Loss: 0.6894, Val Loss: 0.6843, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 8, Train Loss: 0.6848, Val Loss: 0.6790, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 9, Train Loss: 0.6811, Val Loss: 0.6748, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 10, Train Loss: 0.6776, Val Loss: 0.6726, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.6794, Val Loss: 0.6691, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 12, Train Loss: 0.6762, Val Loss: 0.6675, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 13, Train Loss: 0.6756, Val Loss: 0.6667, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 14, Train Loss: 0.6753, Val Loss: 0.6656, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 15, Train Loss: 0.6760, Val Loss: 0.6652, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 16, Train Loss: 0.6747, Val Loss: 0.6649, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 17, Train Loss: 0.6746, Val Loss: 0.6643, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 18, Train Loss: 0.6745, Val Loss: 0.6641, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 19, Train Loss: 0.6757, Val Loss: 0.6794, F1 Micro: 0.6257, F1 Macro: 0.4350, Accuracy: 0.6257\n","Epoch 20, Train Loss: 0.6679, Val Loss: 0.6630, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 21, Train Loss: 0.6743, Val Loss: 0.6629, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 22, Train Loss: 0.6743, Val Loss: 0.6630, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 23, Train Loss: 0.6744, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 24, Train Loss: 0.6747, Val Loss: 0.6629, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 25, Train Loss: 0.6743, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 26, Train Loss: 0.6743, Val Loss: 0.6632, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 27, Train Loss: 0.6744, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 28, Train Loss: 0.6743, Val Loss: 0.6632, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 29, Train Loss: 0.6744, Val Loss: 0.6632, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 30, Train Loss: 0.6745, Val Loss: 0.6634, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 31, Train Loss: 0.6742, Val Loss: 0.6633, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 32, Train Loss: 0.6721, Val Loss: 0.6879, F1 Micro: 0.5754, F1 Macro: 0.5013, Accuracy: 0.5754\n","Epoch 33, Train Loss: 0.6744, Val Loss: 0.6627, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 34, Train Loss: 0.6743, Val Loss: 0.6628, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 35, Train Loss: 0.6743, Val Loss: 0.6628, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 36, Train Loss: 0.6737, Val Loss: 0.6631, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 37, Train Loss: 0.6682, Val Loss: 0.6651, F1 Micro: 0.6369, F1 Macro: 0.5065, Accuracy: 0.6369\n","Epoch 38, Train Loss: 0.6608, Val Loss: 0.6625, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 39, Train Loss: 0.6647, Val Loss: 0.6570, F1 Micro: 0.6480, F1 Macro: 0.5217, Accuracy: 0.6480\n","Epoch 40, Train Loss: 0.6589, Val Loss: 0.6621, F1 Micro: 0.6480, F1 Macro: 0.5217, Accuracy: 0.6480\n","Epoch 41, Train Loss: 0.6613, Val Loss: 0.6505, F1 Micro: 0.6704, F1 Macro: 0.5293, Accuracy: 0.6704\n","Epoch 42, Train Loss: 0.6598, Val Loss: 0.6554, F1 Micro: 0.6536, F1 Macro: 0.5329, Accuracy: 0.6536\n","Epoch 43, Train Loss: 0.6561, Val Loss: 0.6502, F1 Micro: 0.6648, F1 Macro: 0.5334, Accuracy: 0.6648\n","Epoch 44, Train Loss: 0.6545, Val Loss: 0.6511, F1 Micro: 0.6760, F1 Macro: 0.5246, Accuracy: 0.6760\n","Epoch 45, Train Loss: 0.6582, Val Loss: 0.6500, F1 Micro: 0.6872, F1 Macro: 0.5323, Accuracy: 0.6872\n","Epoch 46, Train Loss: 0.6597, Val Loss: 0.6542, F1 Micro: 0.6425, F1 Macro: 0.5178, Accuracy: 0.6425\n","Epoch 47, Train Loss: 0.6591, Val Loss: 0.6517, F1 Micro: 0.6592, F1 Macro: 0.5369, Accuracy: 0.6592\n","Epoch 48, Train Loss: 0.6453, Val Loss: 0.6543, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 49, Train Loss: 0.6369, Val Loss: 0.6588, F1 Micro: 0.6592, F1 Macro: 0.5793, Accuracy: 0.6592\n","Epoch 50, Train Loss: 0.6335, Val Loss: 0.6453, F1 Micro: 0.6592, F1 Macro: 0.5630, Accuracy: 0.6592\n","Epoch 51, Train Loss: 0.6299, Val Loss: 0.6366, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 52, Train Loss: 0.6282, Val Loss: 0.6486, F1 Micro: 0.6648, F1 Macro: 0.6270, Accuracy: 0.6648\n","Epoch 53, Train Loss: 0.6199, Val Loss: 0.6361, F1 Micro: 0.7039, F1 Macro: 0.6429, Accuracy: 0.7039\n","Epoch 54, Train Loss: 0.6157, Val Loss: 0.6355, F1 Micro: 0.6872, F1 Macro: 0.5645, Accuracy: 0.6872\n","Epoch 55, Train Loss: 0.6225, Val Loss: 0.6336, F1 Micro: 0.6648, F1 Macro: 0.5480, Accuracy: 0.6648\n","Epoch 56, Train Loss: 0.6216, Val Loss: 0.6335, F1 Micro: 0.6592, F1 Macro: 0.5506, Accuracy: 0.6592\n","Epoch 57, Train Loss: 0.6153, Val Loss: 0.6313, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 58, Train Loss: 0.6146, Val Loss: 0.6458, F1 Micro: 0.6536, F1 Macro: 0.5698, Accuracy: 0.6536\n","Epoch 59, Train Loss: 0.6124, Val Loss: 0.6381, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 60, Train Loss: 0.6146, Val Loss: 0.6367, F1 Micro: 0.6704, F1 Macro: 0.5715, Accuracy: 0.6704\n","Epoch 61, Train Loss: 0.6098, Val Loss: 0.6363, F1 Micro: 0.6648, F1 Macro: 0.5730, Accuracy: 0.6648\n","Epoch 62, Train Loss: 0.6140, Val Loss: 0.6289, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 63, Train Loss: 0.6083, Val Loss: 0.6377, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 64, Train Loss: 0.6055, Val Loss: 0.6278, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 65, Train Loss: 0.6143, Val Loss: 0.6145, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 66, Train Loss: 0.6101, Val Loss: 0.6246, F1 Micro: 0.6816, F1 Macro: 0.6115, Accuracy: 0.6816\n","Epoch 67, Train Loss: 0.6027, Val Loss: 0.6295, F1 Micro: 0.7095, F1 Macro: 0.6392, Accuracy: 0.7095\n","Epoch 68, Train Loss: 0.6067, Val Loss: 0.6320, F1 Micro: 0.7095, F1 Macro: 0.6249, Accuracy: 0.7095\n","Epoch 69, Train Loss: 0.6075, Val Loss: 0.6271, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 70, Train Loss: 0.6078, Val Loss: 0.6475, F1 Micro: 0.6648, F1 Macro: 0.6239, Accuracy: 0.6648\n","Epoch 71, Train Loss: 0.6078, Val Loss: 0.6191, F1 Micro: 0.6927, F1 Macro: 0.6334, Accuracy: 0.6927\n","Epoch 72, Train Loss: 0.5977, Val Loss: 0.6144, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 73, Train Loss: 0.6030, Val Loss: 0.6121, F1 Micro: 0.6983, F1 Macro: 0.6669, Accuracy: 0.6983\n","Epoch 74, Train Loss: 0.5983, Val Loss: 0.6065, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 75, Train Loss: 0.5970, Val Loss: 0.6172, F1 Micro: 0.7263, F1 Macro: 0.6801, Accuracy: 0.7263\n","Epoch 76, Train Loss: 0.6036, Val Loss: 0.6348, F1 Micro: 0.6648, F1 Macro: 0.6299, Accuracy: 0.6648\n","Epoch 77, Train Loss: 0.6062, Val Loss: 0.6152, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 78, Train Loss: 0.5950, Val Loss: 0.6163, F1 Micro: 0.7318, F1 Macro: 0.6670, Accuracy: 0.7318\n","Epoch 79, Train Loss: 0.5996, Val Loss: 0.6152, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 80, Train Loss: 0.6017, Val Loss: 0.6154, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 81, Train Loss: 0.5919, Val Loss: 0.6103, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 82, Train Loss: 0.5992, Val Loss: 0.6196, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 83, Train Loss: 0.5929, Val Loss: 0.6093, F1 Micro: 0.7318, F1 Macro: 0.6783, Accuracy: 0.7318\n","Epoch 84, Train Loss: 0.5976, Val Loss: 0.6186, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 85, Train Loss: 0.6051, Val Loss: 0.6131, F1 Micro: 0.7207, F1 Macro: 0.6719, Accuracy: 0.7207\n","Epoch 86, Train Loss: 0.6039, Val Loss: 0.6110, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 87, Train Loss: 0.5981, Val Loss: 0.6200, F1 Micro: 0.7318, F1 Macro: 0.6818, Accuracy: 0.7318\n","Epoch 88, Train Loss: 0.6033, Val Loss: 0.6182, F1 Micro: 0.7095, F1 Macro: 0.6515, Accuracy: 0.7095\n","Epoch 89, Train Loss: 0.6014, Val Loss: 0.6184, F1 Micro: 0.6983, F1 Macro: 0.6457, Accuracy: 0.6983\n","Epoch 90, Train Loss: 0.5963, Val Loss: 0.6184, F1 Micro: 0.7263, F1 Macro: 0.6832, Accuracy: 0.7263\n","Epoch 91, Train Loss: 0.5958, Val Loss: 0.6185, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 92, Train Loss: 0.5966, Val Loss: 0.6440, F1 Micro: 0.6760, F1 Macro: 0.6422, Accuracy: 0.6760\n","Epoch 93, Train Loss: 0.5961, Val Loss: 0.6126, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 94, Train Loss: 0.5956, Val Loss: 0.6227, F1 Micro: 0.7151, F1 Macro: 0.6790, Accuracy: 0.7151\n","Epoch 95, Train Loss: 0.5952, Val Loss: 0.6207, F1 Micro: 0.6983, F1 Macro: 0.6669, Accuracy: 0.6983\n","Epoch 96, Train Loss: 0.5925, Val Loss: 0.6221, F1 Micro: 0.7207, F1 Macro: 0.6752, Accuracy: 0.7207\n","Epoch 97, Train Loss: 0.5901, Val Loss: 0.6229, F1 Micro: 0.6983, F1 Macro: 0.6643, Accuracy: 0.6983\n","Epoch 98, Train Loss: 0.5913, Val Loss: 0.6240, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 99, Train Loss: 0.5968, Val Loss: 0.6137, F1 Micro: 0.7207, F1 Macro: 0.6685, Accuracy: 0.7207\n","Epoch 100, Train Loss: 0.5880, Val Loss: 0.6193, F1 Micro: 0.7151, F1 Macro: 0.6817, Accuracy: 0.7151\n","Epoch 101, Train Loss: 0.5950, Val Loss: 0.6067, F1 Micro: 0.7263, F1 Macro: 0.6734, Accuracy: 0.7263\n","Epoch 102, Train Loss: 0.5921, Val Loss: 0.6116, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 103, Train Loss: 0.5983, Val Loss: 0.6144, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 104, Train Loss: 0.5917, Val Loss: 0.6183, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 105, Train Loss: 0.5965, Val Loss: 0.6177, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 106, Train Loss: 0.5968, Val Loss: 0.6193, F1 Micro: 0.7318, F1 Macro: 0.6818, Accuracy: 0.7318\n","Epoch 107, Train Loss: 0.5899, Val Loss: 0.6217, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 108, Train Loss: 0.5997, Val Loss: 0.6186, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 109, Train Loss: 0.6006, Val Loss: 0.6167, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 110, Train Loss: 0.5963, Val Loss: 0.6327, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 111, Train Loss: 0.5917, Val Loss: 0.6230, F1 Micro: 0.7039, F1 Macro: 0.6664, Accuracy: 0.7039\n","Epoch 112, Train Loss: 0.5896, Val Loss: 0.6171, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 113, Train Loss: 0.5905, Val Loss: 0.6272, F1 Micro: 0.7039, F1 Macro: 0.6505, Accuracy: 0.7039\n","Epoch 114, Train Loss: 0.5914, Val Loss: 0.6187, F1 Micro: 0.7151, F1 Macro: 0.6670, Accuracy: 0.7151\n","Epoch 115, Train Loss: 0.5888, Val Loss: 0.6179, F1 Micro: 0.7318, F1 Macro: 0.6747, Accuracy: 0.7318\n","Epoch 116, Train Loss: 0.5922, Val Loss: 0.6189, F1 Micro: 0.7095, F1 Macro: 0.6622, Accuracy: 0.7095\n","Epoch 117, Train Loss: 0.5895, Val Loss: 0.6193, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 118, Train Loss: 0.5900, Val Loss: 0.6240, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 119, Train Loss: 0.5861, Val Loss: 0.6310, F1 Micro: 0.6872, F1 Macro: 0.6545, Accuracy: 0.6872\n","Epoch 120, Train Loss: 0.5966, Val Loss: 0.6279, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 121, Train Loss: 0.5922, Val Loss: 0.6038, F1 Micro: 0.7095, F1 Macro: 0.6435, Accuracy: 0.7095\n","Epoch 122, Train Loss: 0.6019, Val Loss: 0.6137, F1 Micro: 0.7318, F1 Macro: 0.6747, Accuracy: 0.7318\n","Epoch 123, Train Loss: 0.5913, Val Loss: 0.6180, F1 Micro: 0.7039, F1 Macro: 0.6540, Accuracy: 0.7039\n","Epoch 124, Train Loss: 0.5799, Val Loss: 0.6176, F1 Micro: 0.7263, F1 Macro: 0.6801, Accuracy: 0.7263\n","Epoch 125, Train Loss: 0.5874, Val Loss: 0.6122, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 126, Train Loss: 0.5917, Val Loss: 0.6306, F1 Micro: 0.7039, F1 Macro: 0.6635, Accuracy: 0.7039\n","Epoch 127, Train Loss: 0.5978, Val Loss: 0.6122, F1 Micro: 0.7207, F1 Macro: 0.6612, Accuracy: 0.7207\n","Epoch 128, Train Loss: 0.5922, Val Loss: 0.6293, F1 Micro: 0.7039, F1 Macro: 0.6692, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6809, Val Loss: 0.6554, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6731, Val Loss: 0.6476, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6675, Val Loss: 0.6313, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6564, Val Loss: 0.6280, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6642, Val Loss: 0.6651, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6640, Val Loss: 0.6248, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6491, Val Loss: 0.6166, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6554, Val Loss: 0.6222, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6573, Val Loss: 0.6352, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6488, Val Loss: 0.6263, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6526, Val Loss: 0.6114, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6415, Val Loss: 0.6148, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6455, Val Loss: 0.6036, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6440, Val Loss: 0.6190, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6465, Val Loss: 0.6408, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6356, Val Loss: 0.6265, F1 Micro: 0.7472, F1 Macro: 0.6961, Accuracy: 0.7472\n","Epoch 17, Train Loss: 0.6466, Val Loss: 0.6037, F1 Micro: 0.7865, F1 Macro: 0.7389, Accuracy: 0.7865\n","Epoch 18, Train Loss: 0.6396, Val Loss: 0.5925, F1 Micro: 0.7584, F1 Macro: 0.6913, Accuracy: 0.7584\n","Epoch 19, Train Loss: 0.6343, Val Loss: 0.5946, F1 Micro: 0.6910, F1 Macro: 0.5605, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.6359, Val Loss: 0.6111, F1 Micro: 0.7022, F1 Macro: 0.5904, Accuracy: 0.7022\n","Epoch 21, Train Loss: 0.6353, Val Loss: 0.6198, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.6434, Val Loss: 0.6048, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6350, Val Loss: 0.6054, F1 Micro: 0.7640, F1 Macro: 0.7237, Accuracy: 0.7640\n","Epoch 24, Train Loss: 0.6359, Val Loss: 0.5886, F1 Micro: 0.7921, F1 Macro: 0.7473, Accuracy: 0.7921\n","Epoch 25, Train Loss: 0.6400, Val Loss: 0.5838, F1 Micro: 0.7528, F1 Macro: 0.6862, Accuracy: 0.7528\n","Epoch 26, Train Loss: 0.6379, Val Loss: 0.6142, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6357, Val Loss: 0.5871, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 28, Train Loss: 0.6301, Val Loss: 0.5864, F1 Micro: 0.7809, F1 Macro: 0.7336, Accuracy: 0.7809\n","Epoch 29, Train Loss: 0.6247, Val Loss: 0.5886, F1 Micro: 0.7753, F1 Macro: 0.7369, Accuracy: 0.7753\n","Epoch 30, Train Loss: 0.6267, Val Loss: 0.5828, F1 Micro: 0.7809, F1 Macro: 0.7366, Accuracy: 0.7809\n","Epoch 31, Train Loss: 0.6212, Val Loss: 0.5836, F1 Micro: 0.7865, F1 Macro: 0.7389, Accuracy: 0.7865\n","Epoch 32, Train Loss: 0.6214, Val Loss: 0.5788, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 33, Train Loss: 0.6328, Val Loss: 0.5832, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 34, Train Loss: 0.6240, Val Loss: 0.5769, F1 Micro: 0.7809, F1 Macro: 0.7305, Accuracy: 0.7809\n","Epoch 35, Train Loss: 0.6268, Val Loss: 0.5806, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 36, Train Loss: 0.6246, Val Loss: 0.5870, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 37, Train Loss: 0.6299, Val Loss: 0.5715, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 38, Train Loss: 0.6259, Val Loss: 0.5827, F1 Micro: 0.7921, F1 Macro: 0.7473, Accuracy: 0.7921\n","Epoch 39, Train Loss: 0.6240, Val Loss: 0.5756, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 40, Train Loss: 0.6344, Val Loss: 0.5851, F1 Micro: 0.7584, F1 Macro: 0.7238, Accuracy: 0.7584\n","Epoch 41, Train Loss: 0.6326, Val Loss: 0.5645, F1 Micro: 0.7640, F1 Macro: 0.7005, Accuracy: 0.7640\n","Epoch 42, Train Loss: 0.6280, Val Loss: 0.5734, F1 Micro: 0.7640, F1 Macro: 0.7209, Accuracy: 0.7640\n","Epoch 43, Train Loss: 0.6235, Val Loss: 0.5975, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 44, Train Loss: 0.6242, Val Loss: 0.5806, F1 Micro: 0.7472, F1 Macro: 0.7136, Accuracy: 0.7472\n","Epoch 45, Train Loss: 0.6246, Val Loss: 0.5704, F1 Micro: 0.7697, F1 Macro: 0.7231, Accuracy: 0.7697\n","Epoch 46, Train Loss: 0.6292, Val Loss: 0.5766, F1 Micro: 0.7528, F1 Macro: 0.7134, Accuracy: 0.7528\n","Epoch 47, Train Loss: 0.6353, Val Loss: 0.5654, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 48, Train Loss: 0.6205, Val Loss: 0.5773, F1 Micro: 0.7697, F1 Macro: 0.7289, Accuracy: 0.7697\n","Epoch 49, Train Loss: 0.6183, Val Loss: 0.5708, F1 Micro: 0.7584, F1 Macro: 0.7157, Accuracy: 0.7584\n","Epoch 50, Train Loss: 0.6208, Val Loss: 0.5787, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 51, Train Loss: 0.6273, Val Loss: 0.5653, F1 Micro: 0.7753, F1 Macro: 0.7283, Accuracy: 0.7753\n","Epoch 52, Train Loss: 0.6199, Val Loss: 0.5972, F1 Micro: 0.6966, F1 Macro: 0.6805, Accuracy: 0.6966\n","Epoch 53, Train Loss: 0.6289, Val Loss: 0.5651, F1 Micro: 0.7753, F1 Macro: 0.7313, Accuracy: 0.7753\n","Epoch 54, Train Loss: 0.6208, Val Loss: 0.5666, F1 Micro: 0.7697, F1 Macro: 0.7261, Accuracy: 0.7697\n","Epoch 55, Train Loss: 0.6239, Val Loss: 0.5692, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 56, Train Loss: 0.6174, Val Loss: 0.5649, F1 Micro: 0.7528, F1 Macro: 0.7076, Accuracy: 0.7528\n","Epoch 57, Train Loss: 0.6227, Val Loss: 0.5689, F1 Micro: 0.7584, F1 Macro: 0.7186, Accuracy: 0.7584\n","Epoch 58, Train Loss: 0.6148, Val Loss: 0.5620, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 59, Train Loss: 0.6203, Val Loss: 0.5587, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 60, Train Loss: 0.6162, Val Loss: 0.5676, F1 Micro: 0.7416, F1 Macro: 0.7032, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.6339, Val Loss: 0.5630, F1 Micro: 0.7303, F1 Macro: 0.6810, Accuracy: 0.7303\n","Epoch 62, Train Loss: 0.6170, Val Loss: 0.5579, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 63, Train Loss: 0.6131, Val Loss: 0.5577, F1 Micro: 0.7584, F1 Macro: 0.7127, Accuracy: 0.7584\n","Epoch 64, Train Loss: 0.6175, Val Loss: 0.5751, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 65, Train Loss: 0.6144, Val Loss: 0.5715, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 66, Train Loss: 0.6164, Val Loss: 0.5918, F1 Micro: 0.7079, F1 Macro: 0.6906, Accuracy: 0.7079\n","Epoch 67, Train Loss: 0.6127, Val Loss: 0.5538, F1 Micro: 0.7753, F1 Macro: 0.7184, Accuracy: 0.7753\n","Epoch 68, Train Loss: 0.6197, Val Loss: 0.5821, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 69, Train Loss: 0.6154, Val Loss: 0.5711, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 70, Train Loss: 0.6194, Val Loss: 0.5660, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 71, Train Loss: 0.6186, Val Loss: 0.5624, F1 Micro: 0.7640, F1 Macro: 0.7290, Accuracy: 0.7640\n","Epoch 72, Train Loss: 0.6104, Val Loss: 0.5523, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 73, Train Loss: 0.6135, Val Loss: 0.5603, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 74, Train Loss: 0.6177, Val Loss: 0.5585, F1 Micro: 0.7640, F1 Macro: 0.7237, Accuracy: 0.7640\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7054, Val Loss: 0.7007, F1 Micro: 0.5281, F1 Macro: 0.4841, Accuracy: 0.5281\n","Epoch 2, Train Loss: 0.6731, Val Loss: 0.6784, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 3, Train Loss: 0.6687, Val Loss: 0.7002, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6725, Val Loss: 0.6471, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6530, Val Loss: 0.8890, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6656, Val Loss: 0.6432, F1 Micro: 0.6348, F1 Macro: 0.4282, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6546, Val Loss: 0.6609, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6504, Val Loss: 0.6629, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6399, Val Loss: 0.6616, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6446, Val Loss: 0.6712, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6478, Val Loss: 0.6483, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6443, Val Loss: 0.6468, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6416, Val Loss: 0.6545, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6423, Val Loss: 0.6723, F1 Micro: 0.5899, F1 Macro: 0.4532, Accuracy: 0.5899\n","Epoch 15, Train Loss: 0.6500, Val Loss: 0.6565, F1 Micro: 0.6067, F1 Macro: 0.4547, Accuracy: 0.6067\n","Epoch 16, Train Loss: 0.6427, Val Loss: 0.7299, F1 Micro: 0.5843, F1 Macro: 0.4415, Accuracy: 0.5843\n","Epoch 17, Train Loss: 0.6438, Val Loss: 0.6620, F1 Micro: 0.5674, F1 Macro: 0.4232, Accuracy: 0.5674\n","Epoch 18, Train Loss: 0.6431, Val Loss: 0.6554, F1 Micro: 0.6011, F1 Macro: 0.4326, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6330, Val Loss: 0.7660, F1 Micro: 0.6011, F1 Macro: 0.4514, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6430, Val Loss: 0.7098, F1 Micro: 0.5955, F1 Macro: 0.4090, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.6393, Val Loss: 0.6564, F1 Micro: 0.6011, F1 Macro: 0.4117, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6295, Val Loss: 0.7025, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 23, Train Loss: 0.6245, Val Loss: 0.7095, F1 Micro: 0.5730, F1 Macro: 0.5526, Accuracy: 0.5730\n","Epoch 24, Train Loss: 0.6319, Val Loss: 0.6747, F1 Micro: 0.6011, F1 Macro: 0.4117, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6235, Val Loss: 0.6773, F1 Micro: 0.6292, F1 Macro: 0.5701, Accuracy: 0.6292\n","Epoch 26, Train Loss: 0.6374, Val Loss: 0.6964, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 27, Train Loss: 0.6238, Val Loss: 0.6935, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.6233, Val Loss: 0.6820, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.6189, Val Loss: 0.6790, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 30, Train Loss: 0.6120, Val Loss: 0.6748, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 31, Train Loss: 0.6159, Val Loss: 0.6940, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 32, Train Loss: 0.6130, Val Loss: 0.6922, F1 Micro: 0.6685, F1 Macro: 0.6500, Accuracy: 0.6685\n","Epoch 33, Train Loss: 0.6117, Val Loss: 0.7629, F1 Micro: 0.6348, F1 Macro: 0.5746, Accuracy: 0.6348\n","Epoch 34, Train Loss: 0.6187, Val Loss: 0.6889, F1 Micro: 0.6404, F1 Macro: 0.5944, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6029, Val Loss: 0.6914, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6104, Val Loss: 0.6920, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.6193, Val Loss: 0.7057, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 38, Train Loss: 0.6176, Val Loss: 0.6902, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 39, Train Loss: 0.6058, Val Loss: 0.7012, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6141, Val Loss: 0.6851, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 41, Train Loss: 0.6000, Val Loss: 0.7305, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 42, Train Loss: 0.6014, Val Loss: 0.7416, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 43, Train Loss: 0.6085, Val Loss: 0.7146, F1 Micro: 0.6461, F1 Macro: 0.5954, Accuracy: 0.6461\n","Epoch 44, Train Loss: 0.6055, Val Loss: 0.7355, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 45, Train Loss: 0.5999, Val Loss: 0.7268, F1 Micro: 0.6292, F1 Macro: 0.5614, Accuracy: 0.6292\n","Epoch 46, Train Loss: 0.6108, Val Loss: 0.6785, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 47, Train Loss: 0.5976, Val Loss: 0.7284, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 48, Train Loss: 0.6054, Val Loss: 0.6937, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 49, Train Loss: 0.6106, Val Loss: 0.6782, F1 Micro: 0.6124, F1 Macro: 0.5949, Accuracy: 0.6124\n","Epoch 50, Train Loss: 0.6026, Val Loss: 0.7257, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6022, Val Loss: 0.6865, F1 Micro: 0.6461, F1 Macro: 0.5646, Accuracy: 0.6461\n","Epoch 52, Train Loss: 0.6078, Val Loss: 0.6840, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 53, Train Loss: 0.6001, Val Loss: 0.7396, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 54, Train Loss: 0.6050, Val Loss: 0.7020, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 55, Train Loss: 0.6060, Val Loss: 0.7035, F1 Micro: 0.6180, F1 Macro: 0.6052, Accuracy: 0.6180\n","Epoch 56, Train Loss: 0.6079, Val Loss: 0.6979, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 57, Train Loss: 0.5939, Val Loss: 0.7074, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.5975, Val Loss: 0.7484, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 59, Train Loss: 0.6011, Val Loss: 0.6902, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 60, Train Loss: 0.5987, Val Loss: 0.6881, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 61, Train Loss: 0.5994, Val Loss: 0.6883, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 62, Train Loss: 0.5963, Val Loss: 0.6931, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 63, Train Loss: 0.5995, Val Loss: 0.6524, F1 Micro: 0.6404, F1 Macro: 0.6040, Accuracy: 0.6404\n","Epoch 64, Train Loss: 0.5835, Val Loss: 0.7551, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 65, Train Loss: 0.6076, Val Loss: 0.6732, F1 Micro: 0.6292, F1 Macro: 0.5946, Accuracy: 0.6292\n","Epoch 66, Train Loss: 0.6011, Val Loss: 0.6802, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 67, Train Loss: 0.6040, Val Loss: 0.6898, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 68, Train Loss: 0.5979, Val Loss: 0.6792, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 69, Train Loss: 0.5984, Val Loss: 0.7024, F1 Micro: 0.6348, F1 Macro: 0.5746, Accuracy: 0.6348\n","Epoch 70, Train Loss: 0.5996, Val Loss: 0.6623, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 71, Train Loss: 0.6018, Val Loss: 0.6806, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 72, Train Loss: 0.6013, Val Loss: 0.6722, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 73, Train Loss: 0.6025, Val Loss: 0.6852, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 74, Train Loss: 0.5811, Val Loss: 0.6702, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 75, Train Loss: 0.6012, Val Loss: 0.6850, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 76, Train Loss: 0.5865, Val Loss: 0.7008, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 77, Train Loss: 0.5848, Val Loss: 0.7237, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 78, Train Loss: 0.5932, Val Loss: 0.7055, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.5912, Val Loss: 0.6865, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 80, Train Loss: 0.5878, Val Loss: 0.6734, F1 Micro: 0.6573, F1 Macro: 0.6117, Accuracy: 0.6573\n","Epoch 81, Train Loss: 0.5976, Val Loss: 0.7269, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 82, Train Loss: 0.5979, Val Loss: 0.6982, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 83, Train Loss: 0.5902, Val Loss: 0.6592, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 84, Train Loss: 0.5971, Val Loss: 0.6918, F1 Micro: 0.6404, F1 Macro: 0.6123, Accuracy: 0.6404\n","Epoch 85, Train Loss: 0.5924, Val Loss: 0.6862, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 86, Train Loss: 0.5962, Val Loss: 0.7035, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 87, Train Loss: 0.5936, Val Loss: 0.7017, F1 Micro: 0.6573, F1 Macro: 0.6046, Accuracy: 0.6573\n","Epoch 88, Train Loss: 0.6007, Val Loss: 0.6691, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 89, Train Loss: 0.5937, Val Loss: 0.6809, F1 Micro: 0.6404, F1 Macro: 0.5908, Accuracy: 0.6404\n","Epoch 90, Train Loss: 0.5939, Val Loss: 0.6533, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 91, Train Loss: 0.5923, Val Loss: 0.6455, F1 Micro: 0.6517, F1 Macro: 0.6164, Accuracy: 0.6517\n","Epoch 92, Train Loss: 0.5911, Val Loss: 0.6761, F1 Micro: 0.6573, F1 Macro: 0.6267, Accuracy: 0.6573\n","Epoch 93, Train Loss: 0.5934, Val Loss: 0.6995, F1 Micro: 0.6517, F1 Macro: 0.5922, Accuracy: 0.6517\n","Epoch 94, Train Loss: 0.5972, Val Loss: 0.6907, F1 Micro: 0.6348, F1 Macro: 0.5862, Accuracy: 0.6348\n","Epoch 95, Train Loss: 0.5908, Val Loss: 0.6577, F1 Micro: 0.6517, F1 Macro: 0.6103, Accuracy: 0.6517\n","Epoch 96, Train Loss: 0.5967, Val Loss: 0.6429, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 97, Train Loss: 0.5914, Val Loss: 0.7163, F1 Micro: 0.6404, F1 Macro: 0.5944, Accuracy: 0.6404\n","Epoch 98, Train Loss: 0.5824, Val Loss: 0.6688, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 99, Train Loss: 0.5863, Val Loss: 0.7308, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 100, Train Loss: 0.5835, Val Loss: 0.7030, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 101, Train Loss: 0.5847, Val Loss: 0.7062, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 102, Train Loss: 0.5819, Val Loss: 0.6783, F1 Micro: 0.6404, F1 Macro: 0.5977, Accuracy: 0.6404\n","Epoch 103, Train Loss: 0.5911, Val Loss: 0.7540, F1 Micro: 0.6517, F1 Macro: 0.5789, Accuracy: 0.6517\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6824, Val Loss: 0.7071, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6599, Val Loss: 0.7148, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6544, Val Loss: 0.7027, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6454, Val Loss: 0.7078, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6504, Val Loss: 0.7115, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6357, Val Loss: 0.7064, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6374, Val Loss: 0.6964, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6347, Val Loss: 0.6977, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6349, Val Loss: 0.6922, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6378, Val Loss: 0.6918, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6329, Val Loss: 0.6843, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6193, Val Loss: 0.6813, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6298, Val Loss: 0.7138, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6179, Val Loss: 0.7184, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6226, Val Loss: 0.6706, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6219, Val Loss: 0.6762, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 17, Train Loss: 0.6144, Val Loss: 0.6978, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6332, Val Loss: 0.6709, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 19, Train Loss: 0.6330, Val Loss: 0.6833, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 20, Train Loss: 0.6171, Val Loss: 0.6642, F1 Micro: 0.6461, F1 Macro: 0.6170, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6186, Val Loss: 0.6736, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6005, Val Loss: 0.7312, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 23, Train Loss: 0.6183, Val Loss: 0.7418, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 24, Train Loss: 0.6161, Val Loss: 0.7193, F1 Micro: 0.5899, F1 Macro: 0.5174, Accuracy: 0.5899\n","Epoch 25, Train Loss: 0.6168, Val Loss: 0.6938, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6043, Val Loss: 0.7393, F1 Micro: 0.6180, F1 Macro: 0.5652, Accuracy: 0.6180\n","Epoch 27, Train Loss: 0.6246, Val Loss: 0.6835, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.5978, Val Loss: 0.6912, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6083, Val Loss: 0.6851, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6047, Val Loss: 0.6706, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.6083, Val Loss: 0.6671, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.5973, Val Loss: 0.6959, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 33, Train Loss: 0.6047, Val Loss: 0.6682, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 34, Train Loss: 0.6089, Val Loss: 0.7828, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 35, Train Loss: 0.6128, Val Loss: 0.7238, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 36, Train Loss: 0.5932, Val Loss: 0.6642, F1 Micro: 0.6573, F1 Macro: 0.6564, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.6086, Val Loss: 0.7345, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 38, Train Loss: 0.5970, Val Loss: 0.8271, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6071, Val Loss: 0.7025, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 40, Train Loss: 0.5993, Val Loss: 0.6605, F1 Micro: 0.6573, F1 Macro: 0.6492, Accuracy: 0.6573\n","Epoch 41, Train Loss: 0.5987, Val Loss: 0.6685, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.5948, Val Loss: 0.6714, F1 Micro: 0.6517, F1 Macro: 0.6481, Accuracy: 0.6517\n","Epoch 43, Train Loss: 0.5944, Val Loss: 0.6628, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.5941, Val Loss: 0.6818, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 45, Train Loss: 0.5928, Val Loss: 0.6772, F1 Micro: 0.6742, F1 Macro: 0.6691, Accuracy: 0.6742\n","Epoch 46, Train Loss: 0.5957, Val Loss: 0.6955, F1 Micro: 0.6067, F1 Macro: 0.5635, Accuracy: 0.6067\n","Epoch 47, Train Loss: 0.5937, Val Loss: 0.7421, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.5878, Val Loss: 0.8068, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 49, Train Loss: 0.5871, Val Loss: 0.7063, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 50, Train Loss: 0.5944, Val Loss: 0.6866, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6014, Val Loss: 0.7029, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 52, Train Loss: 0.6034, Val Loss: 0.7030, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 53, Train Loss: 0.6016, Val Loss: 0.6985, F1 Micro: 0.6798, F1 Macro: 0.6743, Accuracy: 0.6798\n","Epoch 54, Train Loss: 0.5950, Val Loss: 0.7153, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 55, Train Loss: 0.5886, Val Loss: 0.6775, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 56, Train Loss: 0.5941, Val Loss: 0.6831, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 57, Train Loss: 0.5951, Val Loss: 0.6982, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.5917, Val Loss: 0.6704, F1 Micro: 0.6742, F1 Macro: 0.6646, Accuracy: 0.6742\n","Epoch 59, Train Loss: 0.5786, Val Loss: 0.6770, F1 Micro: 0.6742, F1 Macro: 0.6681, Accuracy: 0.6742\n","Epoch 60, Train Loss: 0.5842, Val Loss: 0.6892, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 61, Train Loss: 0.5933, Val Loss: 0.7261, F1 Micro: 0.6629, F1 Macro: 0.6430, Accuracy: 0.6629\n","Epoch 62, Train Loss: 0.5989, Val Loss: 0.6867, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.5827, Val Loss: 0.7141, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 64, Train Loss: 0.5852, Val Loss: 0.7435, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 65, Train Loss: 0.5942, Val Loss: 0.7416, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 66, Train Loss: 0.5869, Val Loss: 0.7135, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 67, Train Loss: 0.5861, Val Loss: 0.8316, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 68, Train Loss: 0.5925, Val Loss: 0.7710, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 69, Train Loss: 0.5810, Val Loss: 0.6599, F1 Micro: 0.6742, F1 Macro: 0.6721, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.5815, Val Loss: 0.6978, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 71, Train Loss: 0.5849, Val Loss: 0.7799, F1 Micro: 0.6404, F1 Macro: 0.5944, Accuracy: 0.6404\n","Epoch 72, Train Loss: 0.5795, Val Loss: 0.7275, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 73, Train Loss: 0.5923, Val Loss: 0.7078, F1 Micro: 0.6517, F1 Macro: 0.6463, Accuracy: 0.6517\n","Epoch 74, Train Loss: 0.5899, Val Loss: 0.6721, F1 Micro: 0.6910, F1 Macro: 0.6866, Accuracy: 0.6910\n","Epoch 75, Train Loss: 0.5781, Val Loss: 0.6858, F1 Micro: 0.6742, F1 Macro: 0.6633, Accuracy: 0.6742\n","Epoch 76, Train Loss: 0.5857, Val Loss: 0.7052, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 77, Train Loss: 0.5797, Val Loss: 0.6600, F1 Micro: 0.6685, F1 Macro: 0.6595, Accuracy: 0.6685\n","Epoch 78, Train Loss: 0.5831, Val Loss: 0.7379, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Epoch 79, Train Loss: 0.5768, Val Loss: 0.6743, F1 Micro: 0.7079, F1 Macro: 0.7025, Accuracy: 0.7079\n","Epoch 80, Train Loss: 0.5716, Val Loss: 0.7274, F1 Micro: 0.6742, F1 Macro: 0.6691, Accuracy: 0.6742\n","Epoch 81, Train Loss: 0.5892, Val Loss: 0.7803, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 82, Train Loss: 0.5994, Val Loss: 0.7655, F1 Micro: 0.6517, F1 Macro: 0.6244, Accuracy: 0.6517\n","Epoch 83, Train Loss: 0.5815, Val Loss: 0.7383, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 84, Train Loss: 0.5856, Val Loss: 0.6856, F1 Micro: 0.6742, F1 Macro: 0.6715, Accuracy: 0.6742\n","Epoch 85, Train Loss: 0.5774, Val Loss: 0.7275, F1 Micro: 0.6742, F1 Macro: 0.6633, Accuracy: 0.6742\n","Epoch 86, Train Loss: 0.5831, Val Loss: 0.7516, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 87, Train Loss: 0.5670, Val Loss: 0.8188, F1 Micro: 0.6404, F1 Macro: 0.6040, Accuracy: 0.6404\n","Epoch 88, Train Loss: 0.5844, Val Loss: 0.7056, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 89, Train Loss: 0.5651, Val Loss: 0.7117, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 90, Train Loss: 0.5779, Val Loss: 0.7459, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.5770, Val Loss: 0.7031, F1 Micro: 0.6966, F1 Macro: 0.6865, Accuracy: 0.6966\n","Epoch 92, Train Loss: 0.5886, Val Loss: 0.7352, F1 Micro: 0.6798, F1 Macro: 0.6653, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.5773, Val Loss: 0.8071, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 94, Train Loss: 0.5725, Val Loss: 0.8661, F1 Micro: 0.5955, F1 Macro: 0.5310, Accuracy: 0.5955\n","Epoch 95, Train Loss: 0.5847, Val Loss: 0.7493, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 96, Train Loss: 0.5722, Val Loss: 0.9135, F1 Micro: 0.5899, F1 Macro: 0.5070, Accuracy: 0.5899\n","Epoch 97, Train Loss: 0.5743, Val Loss: 0.7521, F1 Micro: 0.6798, F1 Macro: 0.6733, Accuracy: 0.6798\n","Epoch 98, Train Loss: 0.5695, Val Loss: 0.8160, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 99, Train Loss: 0.5852, Val Loss: 0.6989, F1 Micro: 0.6798, F1 Macro: 0.6710, Accuracy: 0.6798\n","Epoch 100, Train Loss: 0.5811, Val Loss: 0.8115, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 101, Train Loss: 0.5732, Val Loss: 0.7375, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 102, Train Loss: 0.5676, Val Loss: 0.6921, F1 Micro: 0.6798, F1 Macro: 0.6669, Accuracy: 0.6798\n","Epoch 103, Train Loss: 0.5787, Val Loss: 0.7203, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 104, Train Loss: 0.5751, Val Loss: 0.7616, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 105, Train Loss: 0.5667, Val Loss: 0.7277, F1 Micro: 0.6742, F1 Macro: 0.6700, Accuracy: 0.6742\n","Epoch 106, Train Loss: 0.5752, Val Loss: 0.6943, F1 Micro: 0.6461, F1 Macro: 0.6458, Accuracy: 0.6461\n","Epoch 107, Train Loss: 0.5777, Val Loss: 0.7179, F1 Micro: 0.6629, F1 Macro: 0.6577, Accuracy: 0.6629\n","Epoch 108, Train Loss: 0.5709, Val Loss: 0.7494, F1 Micro: 0.6742, F1 Macro: 0.6568, Accuracy: 0.6742\n","Epoch 109, Train Loss: 0.5699, Val Loss: 0.7337, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 110, Train Loss: 0.5791, Val Loss: 0.7259, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 111, Train Loss: 0.5684, Val Loss: 0.7575, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 112, Train Loss: 0.5658, Val Loss: 0.7991, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 113, Train Loss: 0.5870, Val Loss: 0.8460, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 114, Train Loss: 0.5772, Val Loss: 0.7998, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 115, Train Loss: 0.5728, Val Loss: 0.7261, F1 Micro: 0.6854, F1 Macro: 0.6687, Accuracy: 0.6854\n","Epoch 116, Train Loss: 0.5791, Val Loss: 0.8482, F1 Micro: 0.6685, F1 Macro: 0.6500, Accuracy: 0.6685\n","Epoch 117, Train Loss: 0.5673, Val Loss: 0.7590, F1 Micro: 0.6742, F1 Macro: 0.6646, Accuracy: 0.6742\n","Epoch 118, Train Loss: 0.5842, Val Loss: 0.7034, F1 Micro: 0.6461, F1 Macro: 0.6428, Accuracy: 0.6461\n","Epoch 119, Train Loss: 0.5572, Val Loss: 0.6895, F1 Micro: 0.6798, F1 Macro: 0.6733, Accuracy: 0.6798\n","Epoch 120, Train Loss: 0.5702, Val Loss: 0.7101, F1 Micro: 0.6685, F1 Macro: 0.6668, Accuracy: 0.6685\n","Epoch 121, Train Loss: 0.5752, Val Loss: 0.7183, F1 Micro: 0.6404, F1 Macro: 0.6400, Accuracy: 0.6404\n","Epoch 122, Train Loss: 0.5818, Val Loss: 0.6601, F1 Micro: 0.6404, F1 Macro: 0.6404, Accuracy: 0.6404\n","Epoch 123, Train Loss: 0.5785, Val Loss: 0.7919, F1 Micro: 0.6629, F1 Macro: 0.6340, Accuracy: 0.6629\n","Epoch 124, Train Loss: 0.5746, Val Loss: 0.7256, F1 Micro: 0.6629, F1 Macro: 0.6556, Accuracy: 0.6629\n","Epoch 125, Train Loss: 0.5723, Val Loss: 0.7431, F1 Micro: 0.6685, F1 Macro: 0.6655, Accuracy: 0.6685\n","Epoch 126, Train Loss: 0.5768, Val Loss: 0.9111, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 127, Train Loss: 0.5658, Val Loss: 0.7138, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 128, Train Loss: 0.5791, Val Loss: 0.7258, F1 Micro: 0.6685, F1 Macro: 0.6647, Accuracy: 0.6685\n","Epoch 129, Train Loss: 0.5698, Val Loss: 0.7241, F1 Micro: 0.6854, F1 Macro: 0.6749, Accuracy: 0.6854\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6649, Val Loss: 0.6861, F1 Micro: 0.5225, F1 Macro: 0.4679, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6440, Val Loss: 0.6562, F1 Micro: 0.6124, F1 Macro: 0.4907, Accuracy: 0.6124\n","Epoch 3, Train Loss: 0.6490, Val Loss: 0.6575, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6377, Val Loss: 0.6566, F1 Micro: 0.6124, F1 Macro: 0.4387, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6451, Val Loss: 0.6485, F1 Micro: 0.6292, F1 Macro: 0.4679, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6365, Val Loss: 0.6908, F1 Micro: 0.6236, F1 Macro: 0.4341, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6470, Val Loss: 0.6552, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6411, Val Loss: 0.6502, F1 Micro: 0.6292, F1 Macro: 0.5093, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6226, Val Loss: 0.6474, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6190, Val Loss: 0.6473, F1 Micro: 0.6292, F1 Macro: 0.4479, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6212, Val Loss: 0.6281, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 12, Train Loss: 0.6266, Val Loss: 0.6432, F1 Micro: 0.6124, F1 Macro: 0.5047, Accuracy: 0.6124\n","Epoch 13, Train Loss: 0.6287, Val Loss: 0.6468, F1 Micro: 0.6124, F1 Macro: 0.4283, Accuracy: 0.6124\n","Epoch 14, Train Loss: 0.6222, Val Loss: 0.6478, F1 Micro: 0.6180, F1 Macro: 0.5016, Accuracy: 0.6180\n","Epoch 15, Train Loss: 0.6238, Val Loss: 0.6350, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6164, Val Loss: 0.6319, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6202, Val Loss: 0.6480, F1 Micro: 0.6348, F1 Macro: 0.5746, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.6243, Val Loss: 0.6486, F1 Micro: 0.6404, F1 Macro: 0.5944, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6269, Val Loss: 0.6393, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6176, Val Loss: 0.6359, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 21, Train Loss: 0.6244, Val Loss: 0.6367, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 22, Train Loss: 0.6152, Val Loss: 0.6496, F1 Micro: 0.6348, F1 Macro: 0.5746, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.6215, Val Loss: 0.6411, F1 Micro: 0.6517, F1 Macro: 0.6192, Accuracy: 0.6517\n","Epoch 24, Train Loss: 0.6228, Val Loss: 0.6371, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.6187, Val Loss: 0.6378, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.6187, Val Loss: 0.6307, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 27, Train Loss: 0.6226, Val Loss: 0.6225, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 28, Train Loss: 0.6145, Val Loss: 0.6284, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.6155, Val Loss: 0.6245, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.6177, Val Loss: 0.6235, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 31, Train Loss: 0.6098, Val Loss: 0.6202, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6193, Val Loss: 0.6311, F1 Micro: 0.6685, F1 Macro: 0.6336, Accuracy: 0.6685\n","Epoch 33, Train Loss: 0.6107, Val Loss: 0.6305, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 34, Train Loss: 0.6181, Val Loss: 0.6242, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 35, Train Loss: 0.6202, Val Loss: 0.6180, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 36, Train Loss: 0.6132, Val Loss: 0.6347, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.6108, Val Loss: 0.6555, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 38, Train Loss: 0.6089, Val Loss: 0.6258, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 39, Train Loss: 0.6156, Val Loss: 0.6476, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 40, Train Loss: 0.6069, Val Loss: 0.6554, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6093, Val Loss: 0.6345, F1 Micro: 0.6404, F1 Macro: 0.5944, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6114, Val Loss: 0.6254, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 43, Train Loss: 0.6088, Val Loss: 0.6386, F1 Micro: 0.6742, F1 Macro: 0.6549, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.6017, Val Loss: 0.6447, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 45, Train Loss: 0.6147, Val Loss: 0.6235, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.6113, Val Loss: 0.6246, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 47, Train Loss: 0.6093, Val Loss: 0.6359, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6169, Val Loss: 0.6337, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.6068, Val Loss: 0.6102, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Epoch 50, Train Loss: 0.6022, Val Loss: 0.6353, F1 Micro: 0.6573, F1 Macro: 0.6150, Accuracy: 0.6573\n","Epoch 51, Train Loss: 0.6063, Val Loss: 0.6356, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 52, Train Loss: 0.6066, Val Loss: 0.6187, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 53, Train Loss: 0.6062, Val Loss: 0.6302, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 54, Train Loss: 0.6061, Val Loss: 0.6083, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 55, Train Loss: 0.6143, Val Loss: 0.6174, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 56, Train Loss: 0.6047, Val Loss: 0.6305, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 57, Train Loss: 0.6196, Val Loss: 0.6337, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 58, Train Loss: 0.6114, Val Loss: 0.6280, F1 Micro: 0.7135, F1 Macro: 0.6856, Accuracy: 0.7135\n","Epoch 59, Train Loss: 0.6104, Val Loss: 0.6244, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 60, Train Loss: 0.6018, Val Loss: 0.6300, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 61, Train Loss: 0.5995, Val Loss: 0.6216, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 62, Train Loss: 0.6014, Val Loss: 0.6484, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 63, Train Loss: 0.5914, Val Loss: 0.6312, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 64, Train Loss: 0.6107, Val Loss: 0.6309, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 65, Train Loss: 0.6063, Val Loss: 0.6279, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 66, Train Loss: 0.6008, Val Loss: 0.6400, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 67, Train Loss: 0.6081, Val Loss: 0.6221, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 68, Train Loss: 0.6052, Val Loss: 0.6161, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 69, Train Loss: 0.6089, Val Loss: 0.6185, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 70, Train Loss: 0.6076, Val Loss: 0.6213, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Epoch 71, Train Loss: 0.6127, Val Loss: 0.6244, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 72, Train Loss: 0.6032, Val Loss: 0.6298, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 73, Train Loss: 0.6064, Val Loss: 0.6233, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 74, Train Loss: 0.5948, Val Loss: 0.6198, F1 Micro: 0.6798, F1 Macro: 0.6599, Accuracy: 0.6798\n","Epoch 75, Train Loss: 0.6120, Val Loss: 0.6321, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 76, Train Loss: 0.5995, Val Loss: 0.6129, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 77, Train Loss: 0.6010, Val Loss: 0.6305, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 78, Train Loss: 0.6023, Val Loss: 0.6303, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 79, Train Loss: 0.6070, Val Loss: 0.6225, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 80, Train Loss: 0.6032, Val Loss: 0.6298, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 81, Train Loss: 0.6019, Val Loss: 0.6217, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 82, Train Loss: 0.6020, Val Loss: 0.6070, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 83, Train Loss: 0.6108, Val Loss: 0.6176, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 84, Train Loss: 0.5934, Val Loss: 0.6284, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 85, Train Loss: 0.6118, Val Loss: 0.6144, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 86, Train Loss: 0.5948, Val Loss: 0.6327, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 87, Train Loss: 0.6082, Val Loss: 0.6205, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 88, Train Loss: 0.6009, Val Loss: 0.6269, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 89, Train Loss: 0.5996, Val Loss: 0.6229, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 90, Train Loss: 0.6035, Val Loss: 0.6177, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 91, Train Loss: 0.6031, Val Loss: 0.6163, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 92, Train Loss: 0.5954, Val Loss: 0.6099, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 93, Train Loss: 0.6010, Val Loss: 0.6272, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 94, Train Loss: 0.6025, Val Loss: 0.6445, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 95, Train Loss: 0.6079, Val Loss: 0.6197, F1 Micro: 0.7247, F1 Macro: 0.6881, Accuracy: 0.7247\n","Epoch 96, Train Loss: 0.5969, Val Loss: 0.6101, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 97, Train Loss: 0.5966, Val Loss: 0.6197, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 98, Train Loss: 0.6053, Val Loss: 0.6477, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 99, Train Loss: 0.5965, Val Loss: 0.6047, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 100, Train Loss: 0.6013, Val Loss: 0.6222, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 101, Train Loss: 0.6033, Val Loss: 0.5980, F1 Micro: 0.7416, F1 Macro: 0.7132, Accuracy: 0.7416\n","Epoch 102, Train Loss: 0.5915, Val Loss: 0.6172, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 103, Train Loss: 0.5981, Val Loss: 0.6081, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 104, Train Loss: 0.6013, Val Loss: 0.6279, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 105, Train Loss: 0.5979, Val Loss: 0.6363, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 106, Train Loss: 0.6073, Val Loss: 0.6151, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 107, Train Loss: 0.5922, Val Loss: 0.6430, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 108, Train Loss: 0.5983, Val Loss: 0.6200, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 109, Train Loss: 0.6083, Val Loss: 0.6078, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 110, Train Loss: 0.5989, Val Loss: 0.6071, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 111, Train Loss: 0.5963, Val Loss: 0.6197, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 112, Train Loss: 0.5956, Val Loss: 0.6008, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 113, Train Loss: 0.5929, Val Loss: 0.6042, F1 Micro: 0.7135, F1 Macro: 0.6939, Accuracy: 0.7135\n","Epoch 114, Train Loss: 0.5997, Val Loss: 0.5989, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 115, Train Loss: 0.5905, Val Loss: 0.6143, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 116, Train Loss: 0.5904, Val Loss: 0.6043, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 117, Train Loss: 0.5979, Val Loss: 0.6104, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 118, Train Loss: 0.5930, Val Loss: 0.6030, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 119, Train Loss: 0.6013, Val Loss: 0.6093, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 120, Train Loss: 0.5911, Val Loss: 0.5819, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 121, Train Loss: 0.5923, Val Loss: 0.6178, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 122, Train Loss: 0.5829, Val Loss: 0.6190, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 123, Train Loss: 0.5915, Val Loss: 0.6004, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 124, Train Loss: 0.5960, Val Loss: 0.6017, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 125, Train Loss: 0.5906, Val Loss: 0.6164, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 126, Train Loss: 0.5948, Val Loss: 0.6016, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 127, Train Loss: 0.5961, Val Loss: 0.6109, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 128, Train Loss: 0.5874, Val Loss: 0.6165, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 129, Train Loss: 0.5900, Val Loss: 0.5987, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 130, Train Loss: 0.5878, Val Loss: 0.5874, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 131, Train Loss: 0.5868, Val Loss: 0.6054, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 132, Train Loss: 0.5917, Val Loss: 0.5961, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 133, Train Loss: 0.5858, Val Loss: 0.6155, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 134, Train Loss: 0.5862, Val Loss: 0.6024, F1 Micro: 0.7079, F1 Macro: 0.6889, Accuracy: 0.7079\n","Epoch 135, Train Loss: 0.5955, Val Loss: 0.6019, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 136, Train Loss: 0.5829, Val Loss: 0.6081, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 137, Train Loss: 0.5921, Val Loss: 0.6091, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 138, Train Loss: 0.5914, Val Loss: 0.6031, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 139, Train Loss: 0.5880, Val Loss: 0.6019, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 140, Train Loss: 0.5932, Val Loss: 0.6073, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 141, Train Loss: 0.5924, Val Loss: 0.6551, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 142, Train Loss: 0.5874, Val Loss: 0.5982, F1 Micro: 0.7360, F1 Macro: 0.7103, Accuracy: 0.7360\n","Epoch 143, Train Loss: 0.5760, Val Loss: 0.5877, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 144, Train Loss: 0.5912, Val Loss: 0.6334, F1 Micro: 0.6517, F1 Macro: 0.6428, Accuracy: 0.6517\n","Epoch 145, Train Loss: 0.5892, Val Loss: 0.6090, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 146, Train Loss: 0.5828, Val Loss: 0.6066, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 147, Train Loss: 0.5960, Val Loss: 0.6023, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 148, Train Loss: 0.5878, Val Loss: 0.6076, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 149, Train Loss: 0.5897, Val Loss: 0.5997, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 150, Train Loss: 0.5854, Val Loss: 0.5988, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 151, Train Loss: 0.5822, Val Loss: 0.6045, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.7317619735107652\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6887, Val Loss: 0.6669, F1 Micro: 0.6480, F1 Macro: 0.5845, Accuracy: 0.6480\n","Epoch 2, Train Loss: 0.6551, Val Loss: 0.6978, F1 Micro: 0.5531, F1 Macro: 0.5456, Accuracy: 0.5531\n","Epoch 3, Train Loss: 0.6527, Val Loss: 0.6693, F1 Micro: 0.6983, F1 Macro: 0.5932, Accuracy: 0.6983\n","Epoch 4, Train Loss: 0.6497, Val Loss: 0.6656, F1 Micro: 0.7263, F1 Macro: 0.6441, Accuracy: 0.7263\n","Epoch 5, Train Loss: 0.6472, Val Loss: 0.6427, F1 Micro: 0.7039, F1 Macro: 0.5976, Accuracy: 0.7039\n","Epoch 6, Train Loss: 0.6380, Val Loss: 0.6810, F1 Micro: 0.6648, F1 Macro: 0.5082, Accuracy: 0.6648\n","Epoch 7, Train Loss: 0.6441, Val Loss: 0.6325, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 8, Train Loss: 0.6380, Val Loss: 0.6632, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 9, Train Loss: 0.6417, Val Loss: 0.6517, F1 Micro: 0.6760, F1 Macro: 0.5332, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.6390, Val Loss: 0.6654, F1 Micro: 0.6425, F1 Macro: 0.5989, Accuracy: 0.6425\n","Epoch 11, Train Loss: 0.6215, Val Loss: 0.6324, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 12, Train Loss: 0.6145, Val Loss: 0.6324, F1 Micro: 0.6816, F1 Macro: 0.5738, Accuracy: 0.6816\n","Epoch 13, Train Loss: 0.6149, Val Loss: 0.6448, F1 Micro: 0.6480, F1 Macro: 0.5965, Accuracy: 0.6480\n","Epoch 14, Train Loss: 0.6169, Val Loss: 0.6637, F1 Micro: 0.6592, F1 Macro: 0.5890, Accuracy: 0.6592\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6883, Val Loss: 0.6283, F1 Micro: 0.7416, F1 Macro: 0.6910, Accuracy: 0.7416\n","Epoch 2, Train Loss: 0.6895, Val Loss: 0.6316, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 3, Train Loss: 0.6670, Val Loss: 0.6126, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 4, Train Loss: 0.6435, Val Loss: 0.6521, F1 Micro: 0.6011, F1 Macro: 0.6008, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6465, Val Loss: 0.6486, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 6, Train Loss: 0.6455, Val Loss: 0.6083, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 7, Train Loss: 0.6497, Val Loss: 0.6367, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 8, Train Loss: 0.6564, Val Loss: 0.5849, F1 Micro: 0.7753, F1 Macro: 0.7395, Accuracy: 0.7753\n","Epoch 9, Train Loss: 0.6507, Val Loss: 0.6379, F1 Micro: 0.6292, F1 Macro: 0.6290, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6623, Val Loss: 0.5718, F1 Micro: 0.7472, F1 Macro: 0.6926, Accuracy: 0.7472\n","Epoch 11, Train Loss: 0.6546, Val Loss: 0.5951, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 12, Train Loss: 0.6535, Val Loss: 0.5801, F1 Micro: 0.7753, F1 Macro: 0.7342, Accuracy: 0.7753\n","Epoch 13, Train Loss: 0.6562, Val Loss: 0.6565, F1 Micro: 0.6573, F1 Macro: 0.6568, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6484, Val Loss: 0.5953, F1 Micro: 0.7697, F1 Macro: 0.7316, Accuracy: 0.7697\n","Epoch 15, Train Loss: 0.6528, Val Loss: 0.5768, F1 Micro: 0.7528, F1 Macro: 0.7045, Accuracy: 0.7528\n","Epoch 16, Train Loss: 0.6449, Val Loss: 0.5942, F1 Micro: 0.7584, F1 Macro: 0.7286, Accuracy: 0.7584\n","Epoch 17, Train Loss: 0.6339, Val Loss: 0.6321, F1 Micro: 0.7584, F1 Macro: 0.7286, Accuracy: 0.7584\n","Epoch 18, Train Loss: 0.6461, Val Loss: 0.6124, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7189, Val Loss: 0.7211, F1 Micro: 0.6292, F1 Macro: 0.4370, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.6715, Val Loss: 0.6829, F1 Micro: 0.6348, F1 Macro: 0.4713, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.6721, Val Loss: 0.7147, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6810, Val Loss: 0.6858, F1 Micro: 0.6067, F1 Macro: 0.4357, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.6674, Val Loss: 0.6877, F1 Micro: 0.6517, F1 Macro: 0.4603, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6723, Val Loss: 0.6882, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6660, Val Loss: 0.7107, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 8, Train Loss: 0.6484, Val Loss: 0.7257, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6532, Val Loss: 0.7340, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6504, Val Loss: 0.6930, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.6320, Val Loss: 0.7490, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 12, Train Loss: 0.6403, Val Loss: 0.7370, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 13, Train Loss: 0.6379, Val Loss: 0.6785, F1 Micro: 0.6517, F1 Macro: 0.5635, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.6367, Val Loss: 0.6973, F1 Micro: 0.6292, F1 Macro: 0.5293, Accuracy: 0.6292\n","Epoch 15, Train Loss: 0.6279, Val Loss: 0.6986, F1 Micro: 0.6348, F1 Macro: 0.4806, Accuracy: 0.6348\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7011, Val Loss: 0.6651, F1 Micro: 0.6180, F1 Macro: 0.6052, Accuracy: 0.6180\n","Epoch 2, Train Loss: 0.6324, Val Loss: 0.7526, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6200, Val Loss: 0.6802, F1 Micro: 0.6180, F1 Macro: 0.6068, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.6223, Val Loss: 0.7466, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.6199, Val Loss: 0.7010, F1 Micro: 0.6011, F1 Macro: 0.5788, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6200, Val Loss: 0.6961, F1 Micro: 0.5562, F1 Macro: 0.5561, Accuracy: 0.5562\n","Epoch 7, Train Loss: 0.6065, Val Loss: 0.7397, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 8, Train Loss: 0.6136, Val Loss: 0.6897, F1 Micro: 0.6461, F1 Macro: 0.6420, Accuracy: 0.6461\n","Epoch 9, Train Loss: 0.6068, Val Loss: 0.7476, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 10, Train Loss: 0.6110, Val Loss: 0.8428, F1 Micro: 0.5787, F1 Macro: 0.4753, Accuracy: 0.5787\n","Epoch 11, Train Loss: 0.6074, Val Loss: 0.8083, F1 Micro: 0.6180, F1 Macro: 0.5652, Accuracy: 0.6180\n","Epoch 12, Train Loss: 0.5960, Val Loss: 0.6756, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6238, Val Loss: 0.6784, F1 Micro: 0.6573, F1 Macro: 0.6480, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.5973, Val Loss: 0.7178, F1 Micro: 0.5449, F1 Macro: 0.5385, Accuracy: 0.5449\n","Epoch 15, Train Loss: 0.5875, Val Loss: 0.7267, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 16, Train Loss: 0.6084, Val Loss: 0.8257, F1 Micro: 0.6348, F1 Macro: 0.5862, Accuracy: 0.6348\n","Epoch 17, Train Loss: 0.5849, Val Loss: 0.7174, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.5984, Val Loss: 0.7009, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 19, Train Loss: 0.5965, Val Loss: 0.7479, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 20, Train Loss: 0.5927, Val Loss: 0.8080, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.5940, Val Loss: 0.6930, F1 Micro: 0.6629, F1 Macro: 0.6468, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.5748, Val Loss: 0.7563, F1 Micro: 0.6348, F1 Macro: 0.6022, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.5852, Val Loss: 0.6931, F1 Micro: 0.6573, F1 Macro: 0.6451, Accuracy: 0.6573\n","Epoch 24, Train Loss: 0.5871, Val Loss: 0.7598, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.5961, Val Loss: 0.6930, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6017, Val Loss: 0.6705, F1 Micro: 0.6685, F1 Macro: 0.6582, Accuracy: 0.6685\n","Epoch 27, Train Loss: 0.5879, Val Loss: 0.7374, F1 Micro: 0.6067, F1 Macro: 0.5995, Accuracy: 0.6067\n","Epoch 28, Train Loss: 0.5795, Val Loss: 0.7409, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 29, Train Loss: 0.5814, Val Loss: 0.7514, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 30, Train Loss: 0.5889, Val Loss: 0.7948, F1 Micro: 0.6573, F1 Macro: 0.6316, Accuracy: 0.6573\n","Epoch 31, Train Loss: 0.5733, Val Loss: 0.7039, F1 Micro: 0.6236, F1 Macro: 0.6201, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.5775, Val Loss: 0.7469, F1 Micro: 0.5955, F1 Macro: 0.5955, Accuracy: 0.5955\n","Epoch 33, Train Loss: 0.5946, Val Loss: 0.6618, F1 Micro: 0.6573, F1 Macro: 0.6525, Accuracy: 0.6573\n","Epoch 34, Train Loss: 0.5867, Val Loss: 0.7509, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 35, Train Loss: 0.5790, Val Loss: 0.7717, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 36, Train Loss: 0.5782, Val Loss: 0.6986, F1 Micro: 0.6629, F1 Macro: 0.6531, Accuracy: 0.6629\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6806, Val Loss: 0.7261, F1 Micro: 0.6180, F1 Macro: 0.4944, Accuracy: 0.6180\n","Epoch 2, Train Loss: 0.6640, Val Loss: 0.7155, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6473, Val Loss: 0.6441, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 4, Train Loss: 0.6327, Val Loss: 0.6251, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 5, Train Loss: 0.6217, Val Loss: 0.6979, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6207, Val Loss: 0.6271, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 7, Train Loss: 0.6103, Val Loss: 0.6242, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 8, Train Loss: 0.6092, Val Loss: 0.6354, F1 Micro: 0.6742, F1 Macro: 0.6646, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6041, Val Loss: 0.6289, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.6100, Val Loss: 0.6189, F1 Micro: 0.6798, F1 Macro: 0.6684, Accuracy: 0.6798\n","Epoch 11, Train Loss: 0.6108, Val Loss: 0.6206, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 12, Train Loss: 0.6075, Val Loss: 0.6377, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6177, Val Loss: 0.6215, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 14, Train Loss: 0.6056, Val Loss: 0.6221, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.6050, Val Loss: 0.6144, F1 Micro: 0.6798, F1 Macro: 0.6698, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6041, Val Loss: 0.6268, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 17, Train Loss: 0.6071, Val Loss: 0.6209, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 18, Train Loss: 0.6141, Val Loss: 0.6308, F1 Micro: 0.6742, F1 Macro: 0.6185, Accuracy: 0.6742\n","Epoch 19, Train Loss: 0.6071, Val Loss: 0.6190, F1 Micro: 0.6685, F1 Macro: 0.6567, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.6061, Val Loss: 0.6172, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 21, Train Loss: 0.6015, Val Loss: 0.6173, F1 Micro: 0.7079, F1 Macro: 0.6758, Accuracy: 0.7079\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.7104199359738874\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6763, Val Loss: 0.7458, F1 Micro: 0.6816, F1 Macro: 0.5603, Accuracy: 0.6816\n","Epoch 2, Train Loss: 0.6526, Val Loss: 0.6916, F1 Micro: 0.6592, F1 Macro: 0.6093, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.6432, Val Loss: 0.6409, F1 Micro: 0.6536, F1 Macro: 0.6230, Accuracy: 0.6536\n","Epoch 4, Train Loss: 0.6448, Val Loss: 0.6644, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 5, Train Loss: 0.6387, Val Loss: 0.6394, F1 Micro: 0.7207, F1 Macro: 0.6442, Accuracy: 0.7207\n","Epoch 6, Train Loss: 0.6319, Val Loss: 0.6521, F1 Micro: 0.6816, F1 Macro: 0.6569, Accuracy: 0.6816\n","Epoch 7, Train Loss: 0.6201, Val Loss: 0.6412, F1 Micro: 0.7039, F1 Macro: 0.6692, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.6241, Val Loss: 0.6426, F1 Micro: 0.7263, F1 Macro: 0.6941, Accuracy: 0.7263\n","Epoch 9, Train Loss: 0.6233, Val Loss: 0.6548, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 10, Train Loss: 0.6156, Val Loss: 0.6514, F1 Micro: 0.6145, F1 Macro: 0.6001, Accuracy: 0.6145\n","Epoch 11, Train Loss: 0.6378, Val Loss: 0.6653, F1 Micro: 0.6983, F1 Macro: 0.6525, Accuracy: 0.6983\n","Epoch 12, Train Loss: 0.6217, Val Loss: 0.6455, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 13, Train Loss: 0.6246, Val Loss: 0.6630, F1 Micro: 0.5978, F1 Macro: 0.5910, Accuracy: 0.5978\n","Epoch 14, Train Loss: 0.6181, Val Loss: 0.6731, F1 Micro: 0.6034, F1 Macro: 0.5961, Accuracy: 0.6034\n","Epoch 15, Train Loss: 0.6144, Val Loss: 0.6299, F1 Micro: 0.7095, F1 Macro: 0.6816, Accuracy: 0.7095\n","Epoch 16, Train Loss: 0.6154, Val Loss: 0.6365, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 17, Train Loss: 0.6125, Val Loss: 0.6535, F1 Micro: 0.6872, F1 Macro: 0.6460, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.6263, Val Loss: 0.6449, F1 Micro: 0.6872, F1 Macro: 0.6595, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.6096, Val Loss: 0.6468, F1 Micro: 0.6592, F1 Macro: 0.6251, Accuracy: 0.6592\n","Epoch 20, Train Loss: 0.6043, Val Loss: 0.6412, F1 Micro: 0.6927, F1 Macro: 0.6689, Accuracy: 0.6927\n","Epoch 21, Train Loss: 0.6109, Val Loss: 0.6393, F1 Micro: 0.6872, F1 Macro: 0.6490, Accuracy: 0.6872\n","Epoch 22, Train Loss: 0.6060, Val Loss: 0.6529, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 23, Train Loss: 0.6100, Val Loss: 0.6648, F1 Micro: 0.5866, F1 Macro: 0.5784, Accuracy: 0.5866\n","Epoch 24, Train Loss: 0.6043, Val Loss: 0.6985, F1 Micro: 0.5587, F1 Macro: 0.5542, Accuracy: 0.5587\n","Epoch 25, Train Loss: 0.6115, Val Loss: 0.6400, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 26, Train Loss: 0.6024, Val Loss: 0.6905, F1 Micro: 0.5251, F1 Macro: 0.5246, Accuracy: 0.5251\n","Epoch 27, Train Loss: 0.6134, Val Loss: 0.6314, F1 Micro: 0.7318, F1 Macro: 0.7082, Accuracy: 0.7318\n","Epoch 28, Train Loss: 0.6057, Val Loss: 0.6500, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 29, Train Loss: 0.6096, Val Loss: 0.6502, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 30, Train Loss: 0.6002, Val Loss: 0.6412, F1 Micro: 0.6927, F1 Macro: 0.6477, Accuracy: 0.6927\n","Epoch 31, Train Loss: 0.5976, Val Loss: 0.6421, F1 Micro: 0.7151, F1 Macro: 0.6888, Accuracy: 0.7151\n","Epoch 32, Train Loss: 0.5988, Val Loss: 0.6348, F1 Micro: 0.6816, F1 Macro: 0.6569, Accuracy: 0.6816\n","Epoch 33, Train Loss: 0.6040, Val Loss: 0.6200, F1 Micro: 0.7095, F1 Macro: 0.6838, Accuracy: 0.7095\n","Epoch 34, Train Loss: 0.6044, Val Loss: 0.6613, F1 Micro: 0.6145, F1 Macro: 0.6001, Accuracy: 0.6145\n","Epoch 35, Train Loss: 0.5910, Val Loss: 0.6771, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 36, Train Loss: 0.6058, Val Loss: 0.6288, F1 Micro: 0.7207, F1 Macro: 0.6782, Accuracy: 0.7207\n","Epoch 37, Train Loss: 0.5993, Val Loss: 0.6450, F1 Micro: 0.6872, F1 Macro: 0.5715, Accuracy: 0.6872\n","Epoch 38, Train Loss: 0.6017, Val Loss: 0.6450, F1 Micro: 0.7039, F1 Macro: 0.6810, Accuracy: 0.7039\n","Epoch 39, Train Loss: 0.5944, Val Loss: 0.6406, F1 Micro: 0.6648, F1 Macro: 0.6063, Accuracy: 0.6648\n","Epoch 40, Train Loss: 0.6028, Val Loss: 0.6243, F1 Micro: 0.6927, F1 Macro: 0.6667, Accuracy: 0.6927\n","Epoch 41, Train Loss: 0.5982, Val Loss: 0.6483, F1 Micro: 0.6760, F1 Macro: 0.6580, Accuracy: 0.6760\n","Epoch 42, Train Loss: 0.5915, Val Loss: 0.6529, F1 Micro: 0.6201, F1 Macro: 0.6113, Accuracy: 0.6201\n","Epoch 43, Train Loss: 0.5875, Val Loss: 0.6511, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 44, Train Loss: 0.5980, Val Loss: 0.6533, F1 Micro: 0.5922, F1 Macro: 0.5897, Accuracy: 0.5922\n","Epoch 45, Train Loss: 0.6030, Val Loss: 0.6535, F1 Micro: 0.7318, F1 Macro: 0.6911, Accuracy: 0.7318\n","Epoch 46, Train Loss: 0.5934, Val Loss: 0.6338, F1 Micro: 0.5978, F1 Macro: 0.5932, Accuracy: 0.5978\n","Epoch 47, Train Loss: 0.5971, Val Loss: 0.6919, F1 Micro: 0.5307, F1 Macro: 0.5304, Accuracy: 0.5307\n","Epoch 48, Train Loss: 0.6010, Val Loss: 0.6372, F1 Micro: 0.7318, F1 Macro: 0.7016, Accuracy: 0.7318\n","Epoch 49, Train Loss: 0.5916, Val Loss: 0.6436, F1 Micro: 0.7318, F1 Macro: 0.6783, Accuracy: 0.7318\n","Epoch 50, Train Loss: 0.5912, Val Loss: 0.6551, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 51, Train Loss: 0.5979, Val Loss: 0.6461, F1 Micro: 0.7151, F1 Macro: 0.6524, Accuracy: 0.7151\n","Epoch 52, Train Loss: 0.5835, Val Loss: 0.6429, F1 Micro: 0.7151, F1 Macro: 0.6842, Accuracy: 0.7151\n","Epoch 53, Train Loss: 0.5908, Val Loss: 0.6691, F1 Micro: 0.5754, F1 Macro: 0.5738, Accuracy: 0.5754\n","Epoch 54, Train Loss: 0.5851, Val Loss: 0.6561, F1 Micro: 0.6927, F1 Macro: 0.6567, Accuracy: 0.6927\n","Epoch 55, Train Loss: 0.5896, Val Loss: 0.6372, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 56, Train Loss: 0.5759, Val Loss: 0.6638, F1 Micro: 0.6760, F1 Macro: 0.6580, Accuracy: 0.6760\n","Epoch 57, Train Loss: 0.5901, Val Loss: 0.6472, F1 Micro: 0.6536, F1 Macro: 0.6280, Accuracy: 0.6536\n","Epoch 58, Train Loss: 0.5865, Val Loss: 0.6374, F1 Micro: 0.6872, F1 Macro: 0.6571, Accuracy: 0.6872\n","Epoch 59, Train Loss: 0.5727, Val Loss: 0.6444, F1 Micro: 0.6480, F1 Macro: 0.6349, Accuracy: 0.6480\n","Epoch 60, Train Loss: 0.5882, Val Loss: 0.6365, F1 Micro: 0.6872, F1 Macro: 0.6545, Accuracy: 0.6872\n","Epoch 61, Train Loss: 0.5888, Val Loss: 0.6541, F1 Micro: 0.6034, F1 Macro: 0.6016, Accuracy: 0.6034\n","Epoch 62, Train Loss: 0.5865, Val Loss: 0.6707, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 63, Train Loss: 0.5840, Val Loss: 0.6531, F1 Micro: 0.6201, F1 Macro: 0.6084, Accuracy: 0.6201\n","Epoch 64, Train Loss: 0.5880, Val Loss: 0.6326, F1 Micro: 0.6704, F1 Macro: 0.6492, Accuracy: 0.6704\n","Epoch 65, Train Loss: 0.5894, Val Loss: 0.6226, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 66, Train Loss: 0.5822, Val Loss: 0.6347, F1 Micro: 0.6592, F1 Macro: 0.6373, Accuracy: 0.6592\n","Epoch 67, Train Loss: 0.5818, Val Loss: 0.6287, F1 Micro: 0.7263, F1 Macro: 0.6734, Accuracy: 0.7263\n","Epoch 68, Train Loss: 0.5820, Val Loss: 0.6304, F1 Micro: 0.6313, F1 Macro: 0.6183, Accuracy: 0.6313\n","Epoch 69, Train Loss: 0.5903, Val Loss: 0.6427, F1 Micro: 0.6257, F1 Macro: 0.6149, Accuracy: 0.6257\n","Epoch 70, Train Loss: 0.5847, Val Loss: 0.6491, F1 Micro: 0.6704, F1 Macro: 0.6425, Accuracy: 0.6704\n","Epoch 71, Train Loss: 0.5794, Val Loss: 0.6566, F1 Micro: 0.6536, F1 Macro: 0.6256, Accuracy: 0.6536\n","Epoch 72, Train Loss: 0.5759, Val Loss: 0.6233, F1 Micro: 0.6704, F1 Macro: 0.6492, Accuracy: 0.6704\n","Epoch 73, Train Loss: 0.5820, Val Loss: 0.6367, F1 Micro: 0.6760, F1 Macro: 0.6155, Accuracy: 0.6760\n","Epoch 74, Train Loss: 0.5797, Val Loss: 0.6353, F1 Micro: 0.7151, F1 Macro: 0.6817, Accuracy: 0.7151\n","Epoch 75, Train Loss: 0.5812, Val Loss: 0.6300, F1 Micro: 0.6927, F1 Macro: 0.6730, Accuracy: 0.6927\n","Epoch 76, Train Loss: 0.5852, Val Loss: 0.6536, F1 Micro: 0.6648, F1 Macro: 0.6377, Accuracy: 0.6648\n","Epoch 77, Train Loss: 0.5724, Val Loss: 0.6730, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.9267, Val Loss: 0.8779, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 2, Train Loss: 0.8689, Val Loss: 0.8545, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 3, Train Loss: 0.8474, Val Loss: 0.8333, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 4, Train Loss: 0.8261, Val Loss: 0.8129, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 5, Train Loss: 0.8045, Val Loss: 0.7945, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 6, Train Loss: 0.7884, Val Loss: 0.7784, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 7, Train Loss: 0.7733, Val Loss: 0.7637, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 8, Train Loss: 0.7592, Val Loss: 0.7508, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 9, Train Loss: 0.7461, Val Loss: 0.7393, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 10, Train Loss: 0.7357, Val Loss: 0.7294, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 11, Train Loss: 0.7269, Val Loss: 0.7213, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 12, Train Loss: 0.7182, Val Loss: 0.7135, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 13, Train Loss: 0.7109, Val Loss: 0.7070, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 14, Train Loss: 0.7049, Val Loss: 0.7015, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 15, Train Loss: 0.6997, Val Loss: 0.6969, F1 Micro: 0.3596, F1 Macro: 0.2645, Accuracy: 0.3596\n","Epoch 16, Train Loss: 0.6950, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.6913, Val Loss: 0.6897, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6883, Val Loss: 0.6868, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6857, Val Loss: 0.6846, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.6837, Val Loss: 0.6827, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6817, Val Loss: 0.6813, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6804, Val Loss: 0.6801, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6789, Val Loss: 0.6790, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6783, Val Loss: 0.6783, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6770, Val Loss: 0.6778, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6767, Val Loss: 0.6772, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6774, Val Loss: 0.6767, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 28, Train Loss: 0.6751, Val Loss: 0.6764, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6753, Val Loss: 0.6762, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6752, Val Loss: 0.6761, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6746, Val Loss: 0.6759, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6751, Val Loss: 0.6758, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.6746, Val Loss: 0.6607, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 34, Train Loss: 0.6749, Val Loss: 0.6756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6749, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6737, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.6737, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.6747, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6746, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.6751, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 52, Train Loss: 0.6747, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 54, Train Loss: 0.6748, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 55, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 56, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 57, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 58, Train Loss: 0.6746, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 59, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 60, Train Loss: 0.6738, Val Loss: 0.6767, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 61, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 62, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 63, Train Loss: 0.6750, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 64, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 65, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 66, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 67, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 68, Train Loss: 0.6731, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 69, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 70, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 71, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 72, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 73, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 74, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 75, Train Loss: 0.6743, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 76, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 77, Train Loss: 0.6729, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 78, Train Loss: 0.6747, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 79, Train Loss: 0.6729, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 80, Train Loss: 0.6738, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 81, Train Loss: 0.6734, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 82, Train Loss: 0.6739, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 83, Train Loss: 0.6742, Val Loss: 0.6755, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7064, Val Loss: 0.6692, F1 Micro: 0.6236, F1 Macro: 0.3978, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6493, Val Loss: 0.7489, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.6466, Val Loss: 0.6589, F1 Micro: 0.6348, F1 Macro: 0.5657, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6317, Val Loss: 0.6683, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6357, Val Loss: 0.7114, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6376, Val Loss: 0.6998, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6317, Val Loss: 0.8924, F1 Micro: 0.6517, F1 Macro: 0.5170, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.6364, Val Loss: 0.6532, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.6293, Val Loss: 0.6682, F1 Micro: 0.6292, F1 Macro: 0.5567, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6262, Val Loss: 0.6623, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6198, Val Loss: 0.6479, F1 Micro: 0.6292, F1 Macro: 0.5614, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.6216, Val Loss: 0.7042, F1 Micro: 0.6348, F1 Macro: 0.5508, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.6246, Val Loss: 0.6546, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6152, Val Loss: 0.6825, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6166, Val Loss: 0.6463, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 16, Train Loss: 0.6124, Val Loss: 0.6559, F1 Micro: 0.6629, F1 Macro: 0.6229, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6118, Val Loss: 0.6839, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6153, Val Loss: 0.7455, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 19, Train Loss: 0.6161, Val Loss: 0.7008, F1 Micro: 0.6348, F1 Macro: 0.5825, Accuracy: 0.6348\n","Epoch 20, Train Loss: 0.6164, Val Loss: 0.8666, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Epoch 21, Train Loss: 0.6172, Val Loss: 0.6590, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 22, Train Loss: 0.6188, Val Loss: 0.6490, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.6191, Val Loss: 0.6502, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 24, Train Loss: 0.6152, Val Loss: 0.7105, F1 Micro: 0.6404, F1 Macro: 0.5908, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6003, Val Loss: 0.6923, F1 Micro: 0.6461, F1 Macro: 0.5916, Accuracy: 0.6461\n","Epoch 26, Train Loss: 0.6152, Val Loss: 0.6684, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.6082, Val Loss: 0.7211, F1 Micro: 0.6461, F1 Macro: 0.5791, Accuracy: 0.6461\n","Epoch 28, Train Loss: 0.6045, Val Loss: 0.6454, F1 Micro: 0.6461, F1 Macro: 0.5916, Accuracy: 0.6461\n","Epoch 29, Train Loss: 0.6001, Val Loss: 0.7015, F1 Micro: 0.6461, F1 Macro: 0.5745, Accuracy: 0.6461\n","Epoch 30, Train Loss: 0.6130, Val Loss: 0.6797, F1 Micro: 0.6461, F1 Macro: 0.6056, Accuracy: 0.6461\n","Epoch 31, Train Loss: 0.6045, Val Loss: 0.7084, F1 Micro: 0.6517, F1 Macro: 0.5962, Accuracy: 0.6517\n","Epoch 32, Train Loss: 0.6040, Val Loss: 0.7286, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 33, Train Loss: 0.5972, Val Loss: 0.6994, F1 Micro: 0.6404, F1 Macro: 0.5944, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.5994, Val Loss: 0.6586, F1 Micro: 0.6461, F1 Macro: 0.6219, Accuracy: 0.6461\n","Epoch 35, Train Loss: 0.6014, Val Loss: 0.6725, F1 Micro: 0.6461, F1 Macro: 0.6024, Accuracy: 0.6461\n","Epoch 36, Train Loss: 0.5921, Val Loss: 0.7002, F1 Micro: 0.6573, F1 Macro: 0.5925, Accuracy: 0.6573\n","Epoch 37, Train Loss: 0.5955, Val Loss: 0.6676, F1 Micro: 0.6854, F1 Macro: 0.6704, Accuracy: 0.6854\n","Epoch 38, Train Loss: 0.5988, Val Loss: 0.7521, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 39, Train Loss: 0.5972, Val Loss: 0.6404, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 40, Train Loss: 0.5880, Val Loss: 0.6796, F1 Micro: 0.6404, F1 Macro: 0.6040, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.5968, Val Loss: 0.7235, F1 Micro: 0.6461, F1 Macro: 0.5697, Accuracy: 0.6461\n","Epoch 42, Train Loss: 0.5972, Val Loss: 0.7488, F1 Micro: 0.6629, F1 Macro: 0.6430, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.5986, Val Loss: 0.7594, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 44, Train Loss: 0.5927, Val Loss: 0.8717, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 45, Train Loss: 0.5952, Val Loss: 0.7042, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 46, Train Loss: 0.5869, Val Loss: 0.6844, F1 Micro: 0.6685, F1 Macro: 0.6437, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.5951, Val Loss: 0.7498, F1 Micro: 0.6798, F1 Macro: 0.6579, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.5925, Val Loss: 0.7242, F1 Micro: 0.6404, F1 Macro: 0.5701, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.5871, Val Loss: 0.7538, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 50, Train Loss: 0.5876, Val Loss: 0.6929, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.5835, Val Loss: 0.8000, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 52, Train Loss: 0.5910, Val Loss: 0.8614, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 53, Train Loss: 0.5869, Val Loss: 0.7319, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Epoch 54, Train Loss: 0.5894, Val Loss: 0.7409, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 55, Train Loss: 0.5893, Val Loss: 0.6442, F1 Micro: 0.6573, F1 Macro: 0.6339, Accuracy: 0.6573\n","Epoch 56, Train Loss: 0.5846, Val Loss: 0.8714, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 57, Train Loss: 0.5817, Val Loss: 0.7673, F1 Micro: 0.6629, F1 Macro: 0.6288, Accuracy: 0.6629\n","Epoch 58, Train Loss: 0.5825, Val Loss: 0.8220, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 59, Train Loss: 0.5896, Val Loss: 0.8065, F1 Micro: 0.6573, F1 Macro: 0.6007, Accuracy: 0.6573\n","Epoch 60, Train Loss: 0.5877, Val Loss: 0.7928, F1 Micro: 0.6742, F1 Macro: 0.6384, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.5897, Val Loss: 0.6723, F1 Micro: 0.6517, F1 Macro: 0.6134, Accuracy: 0.6517\n","Epoch 62, Train Loss: 0.5750, Val Loss: 0.7886, F1 Micro: 0.6517, F1 Macro: 0.6000, Accuracy: 0.6517\n","Epoch 63, Train Loss: 0.5765, Val Loss: 0.8080, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 64, Train Loss: 0.5835, Val Loss: 0.8331, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 65, Train Loss: 0.5873, Val Loss: 0.7135, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 66, Train Loss: 0.5815, Val Loss: 0.7675, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 67, Train Loss: 0.5754, Val Loss: 0.8187, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 68, Train Loss: 0.5881, Val Loss: 0.8871, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 69, Train Loss: 0.5880, Val Loss: 0.7335, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 70, Train Loss: 0.5767, Val Loss: 0.8115, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 71, Train Loss: 0.5771, Val Loss: 0.7015, F1 Micro: 0.6742, F1 Macro: 0.6292, Accuracy: 0.6742\n","Epoch 72, Train Loss: 0.5798, Val Loss: 0.7783, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 73, Train Loss: 0.5798, Val Loss: 0.7097, F1 Micro: 0.6573, F1 Macro: 0.6211, Accuracy: 0.6573\n","Epoch 74, Train Loss: 0.5756, Val Loss: 0.7474, F1 Micro: 0.6685, F1 Macro: 0.6211, Accuracy: 0.6685\n","Epoch 75, Train Loss: 0.5785, Val Loss: 0.7887, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 76, Train Loss: 0.5790, Val Loss: 0.7138, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 77, Train Loss: 0.5778, Val Loss: 0.8632, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 78, Train Loss: 0.5708, Val Loss: 0.7566, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 79, Train Loss: 0.5676, Val Loss: 0.6871, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 80, Train Loss: 0.5774, Val Loss: 0.6705, F1 Micro: 0.6404, F1 Macro: 0.6193, Accuracy: 0.6404\n","Epoch 81, Train Loss: 0.5851, Val Loss: 0.8180, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 82, Train Loss: 0.5804, Val Loss: 0.7587, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 83, Train Loss: 0.5734, Val Loss: 0.6807, F1 Micro: 0.6742, F1 Macro: 0.6438, Accuracy: 0.6742\n","Epoch 84, Train Loss: 0.5767, Val Loss: 0.9150, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 85, Train Loss: 0.5778, Val Loss: 0.6870, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 86, Train Loss: 0.5793, Val Loss: 0.7860, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 87, Train Loss: 0.5724, Val Loss: 0.7310, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 88, Train Loss: 0.5809, Val Loss: 0.7163, F1 Micro: 0.6629, F1 Macro: 0.6164, Accuracy: 0.6629\n","Epoch 89, Train Loss: 0.5698, Val Loss: 0.7628, F1 Micro: 0.6685, F1 Macro: 0.6307, Accuracy: 0.6685\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7012, Val Loss: 0.7045, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 2, Train Loss: 0.6204, Val Loss: 0.7077, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 3, Train Loss: 0.6210, Val Loss: 0.7625, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6115, Val Loss: 0.7045, F1 Micro: 0.6124, F1 Macro: 0.5833, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6131, Val Loss: 0.7293, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 6, Train Loss: 0.6090, Val Loss: 0.7004, F1 Micro: 0.6236, F1 Macro: 0.6046, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6154, Val Loss: 0.6624, F1 Micro: 0.6236, F1 Macro: 0.6160, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6107, Val Loss: 0.7009, F1 Micro: 0.6124, F1 Macro: 0.5968, Accuracy: 0.6124\n","Epoch 9, Train Loss: 0.6055, Val Loss: 0.7722, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6059, Val Loss: 0.6845, F1 Micro: 0.6292, F1 Macro: 0.6211, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6075, Val Loss: 0.7691, F1 Micro: 0.5899, F1 Macro: 0.5123, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6172, Val Loss: 0.7219, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6094, Val Loss: 0.7501, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 14, Train Loss: 0.6051, Val Loss: 0.7001, F1 Micro: 0.6348, F1 Macro: 0.6075, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6103, Val Loss: 0.6976, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 16, Train Loss: 0.5982, Val Loss: 0.6891, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 17, Train Loss: 0.5991, Val Loss: 0.7093, F1 Micro: 0.6348, F1 Macro: 0.6099, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.6010, Val Loss: 0.7046, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6061, Val Loss: 0.7401, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.5970, Val Loss: 0.6984, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6011, Val Loss: 0.6642, F1 Micro: 0.6292, F1 Macro: 0.6269, Accuracy: 0.6292\n","Epoch 22, Train Loss: 0.6036, Val Loss: 0.7463, F1 Micro: 0.5843, F1 Macro: 0.5132, Accuracy: 0.5843\n","Epoch 23, Train Loss: 0.6007, Val Loss: 0.7120, F1 Micro: 0.6236, F1 Macro: 0.6025, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.5969, Val Loss: 0.6947, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.5968, Val Loss: 0.7015, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 26, Train Loss: 0.5915, Val Loss: 0.6697, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6039, Val Loss: 0.6683, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.5947, Val Loss: 0.8290, F1 Micro: 0.5955, F1 Macro: 0.5215, Accuracy: 0.5955\n","Epoch 29, Train Loss: 0.6013, Val Loss: 0.6877, F1 Micro: 0.6180, F1 Macro: 0.6035, Accuracy: 0.6180\n","Epoch 30, Train Loss: 0.5996, Val Loss: 0.7013, F1 Micro: 0.6236, F1 Macro: 0.6118, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.5965, Val Loss: 0.7502, F1 Micro: 0.5899, F1 Macro: 0.5222, Accuracy: 0.5899\n","Epoch 32, Train Loss: 0.6086, Val Loss: 0.7327, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.5932, Val Loss: 0.7188, F1 Micro: 0.6180, F1 Macro: 0.6149, Accuracy: 0.6180\n","Epoch 34, Train Loss: 0.5846, Val Loss: 0.6940, F1 Micro: 0.5955, F1 Macro: 0.5692, Accuracy: 0.5955\n","Epoch 35, Train Loss: 0.5901, Val Loss: 0.7230, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.5832, Val Loss: 0.7302, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.5946, Val Loss: 0.8169, F1 Micro: 0.5562, F1 Macro: 0.4604, Accuracy: 0.5562\n","Epoch 38, Train Loss: 0.5968, Val Loss: 0.6547, F1 Micro: 0.6517, F1 Macro: 0.6385, Accuracy: 0.6517\n","Epoch 39, Train Loss: 0.5979, Val Loss: 0.6748, F1 Micro: 0.6292, F1 Macro: 0.6262, Accuracy: 0.6292\n","Epoch 40, Train Loss: 0.5901, Val Loss: 0.7006, F1 Micro: 0.6292, F1 Macro: 0.6051, Accuracy: 0.6292\n","Epoch 41, Train Loss: 0.5918, Val Loss: 0.7592, F1 Micro: 0.6348, F1 Macro: 0.5993, Accuracy: 0.6348\n","Epoch 42, Train Loss: 0.5933, Val Loss: 0.7077, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 43, Train Loss: 0.5891, Val Loss: 0.7002, F1 Micro: 0.6348, F1 Macro: 0.6144, Accuracy: 0.6348\n","Epoch 44, Train Loss: 0.5850, Val Loss: 0.7292, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.5946, Val Loss: 0.7113, F1 Micro: 0.6292, F1 Macro: 0.6184, Accuracy: 0.6292\n","Epoch 46, Train Loss: 0.5818, Val Loss: 0.7130, F1 Micro: 0.6180, F1 Macro: 0.5931, Accuracy: 0.6180\n","Epoch 47, Train Loss: 0.5847, Val Loss: 0.7329, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 48, Train Loss: 0.5843, Val Loss: 0.7139, F1 Micro: 0.6180, F1 Macro: 0.5880, Accuracy: 0.6180\n","Epoch 49, Train Loss: 0.5997, Val Loss: 0.6974, F1 Micro: 0.6236, F1 Macro: 0.6118, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.5850, Val Loss: 0.6667, F1 Micro: 0.6517, F1 Macro: 0.6481, Accuracy: 0.6517\n","Epoch 51, Train Loss: 0.6038, Val Loss: 0.6525, F1 Micro: 0.6404, F1 Macro: 0.6338, Accuracy: 0.6404\n","Epoch 52, Train Loss: 0.5853, Val Loss: 0.6946, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.5869, Val Loss: 0.6859, F1 Micro: 0.6517, F1 Macro: 0.6415, Accuracy: 0.6517\n","Epoch 54, Train Loss: 0.5742, Val Loss: 0.7064, F1 Micro: 0.6461, F1 Macro: 0.6318, Accuracy: 0.6461\n","Epoch 55, Train Loss: 0.5783, Val Loss: 0.6788, F1 Micro: 0.6292, F1 Macro: 0.6235, Accuracy: 0.6292\n","Epoch 56, Train Loss: 0.5852, Val Loss: 0.7335, F1 Micro: 0.6011, F1 Macro: 0.5712, Accuracy: 0.6011\n","Epoch 57, Train Loss: 0.5842, Val Loss: 0.7047, F1 Micro: 0.6629, F1 Macro: 0.6502, Accuracy: 0.6629\n","Epoch 58, Train Loss: 0.5723, Val Loss: 0.7367, F1 Micro: 0.6348, F1 Macro: 0.6049, Accuracy: 0.6348\n","Epoch 59, Train Loss: 0.5905, Val Loss: 0.6988, F1 Micro: 0.6517, F1 Macro: 0.6463, Accuracy: 0.6517\n","Epoch 60, Train Loss: 0.5798, Val Loss: 0.7177, F1 Micro: 0.6236, F1 Macro: 0.5927, Accuracy: 0.6236\n","Epoch 61, Train Loss: 0.5734, Val Loss: 0.7268, F1 Micro: 0.6685, F1 Macro: 0.6552, Accuracy: 0.6685\n","Epoch 62, Train Loss: 0.5835, Val Loss: 0.6883, F1 Micro: 0.6629, F1 Macro: 0.6544, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.5837, Val Loss: 0.6981, F1 Micro: 0.6348, F1 Macro: 0.6297, Accuracy: 0.6348\n","Epoch 64, Train Loss: 0.5853, Val Loss: 0.7623, F1 Micro: 0.6292, F1 Macro: 0.6001, Accuracy: 0.6292\n","Epoch 65, Train Loss: 0.5773, Val Loss: 0.7622, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 66, Train Loss: 0.5716, Val Loss: 0.6742, F1 Micro: 0.6461, F1 Macro: 0.6364, Accuracy: 0.6461\n","Epoch 67, Train Loss: 0.5856, Val Loss: 0.7929, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 68, Train Loss: 0.5758, Val Loss: 0.7098, F1 Micro: 0.6124, F1 Macro: 0.5806, Accuracy: 0.6124\n","Epoch 69, Train Loss: 0.5833, Val Loss: 0.7377, F1 Micro: 0.6517, F1 Macro: 0.6268, Accuracy: 0.6517\n","Epoch 70, Train Loss: 0.5839, Val Loss: 0.7011, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 71, Train Loss: 0.5785, Val Loss: 0.7157, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 72, Train Loss: 0.5922, Val Loss: 0.7407, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 73, Train Loss: 0.5769, Val Loss: 0.7029, F1 Micro: 0.6685, F1 Macro: 0.6680, Accuracy: 0.6685\n","Epoch 74, Train Loss: 0.5729, Val Loss: 0.7206, F1 Micro: 0.6461, F1 Macro: 0.6301, Accuracy: 0.6461\n","Epoch 75, Train Loss: 0.5791, Val Loss: 0.7301, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 76, Train Loss: 0.5823, Val Loss: 0.6892, F1 Micro: 0.6461, F1 Macro: 0.6401, Accuracy: 0.6461\n","Epoch 77, Train Loss: 0.5858, Val Loss: 0.7288, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 78, Train Loss: 0.5763, Val Loss: 0.6817, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 79, Train Loss: 0.5739, Val Loss: 0.7136, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 80, Train Loss: 0.5835, Val Loss: 0.6846, F1 Micro: 0.6573, F1 Macro: 0.6504, Accuracy: 0.6573\n","Epoch 81, Train Loss: 0.5703, Val Loss: 0.7330, F1 Micro: 0.6180, F1 Macro: 0.5955, Accuracy: 0.6180\n","Epoch 82, Train Loss: 0.5784, Val Loss: 0.7672, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 83, Train Loss: 0.5769, Val Loss: 0.7440, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 84, Train Loss: 0.5747, Val Loss: 0.7671, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 85, Train Loss: 0.5695, Val Loss: 0.7659, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 86, Train Loss: 0.5802, Val Loss: 0.8067, F1 Micro: 0.6067, F1 Macro: 0.5731, Accuracy: 0.6067\n","Epoch 87, Train Loss: 0.5613, Val Loss: 0.7228, F1 Micro: 0.6685, F1 Macro: 0.6647, Accuracy: 0.6685\n","Epoch 88, Train Loss: 0.5896, Val Loss: 0.7832, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 89, Train Loss: 0.5807, Val Loss: 0.7621, F1 Micro: 0.6348, F1 Macro: 0.6122, Accuracy: 0.6348\n","Epoch 90, Train Loss: 0.5844, Val Loss: 0.7798, F1 Micro: 0.6292, F1 Macro: 0.5975, Accuracy: 0.6292\n","Epoch 91, Train Loss: 0.5732, Val Loss: 0.7219, F1 Micro: 0.6629, F1 Macro: 0.6517, Accuracy: 0.6629\n","Epoch 92, Train Loss: 0.5749, Val Loss: 0.7341, F1 Micro: 0.6124, F1 Macro: 0.6018, Accuracy: 0.6124\n","Epoch 93, Train Loss: 0.5863, Val Loss: 0.7670, F1 Micro: 0.6461, F1 Macro: 0.6301, Accuracy: 0.6461\n","Epoch 94, Train Loss: 0.5734, Val Loss: 0.7270, F1 Micro: 0.6348, F1 Macro: 0.6249, Accuracy: 0.6348\n","Epoch 95, Train Loss: 0.5782, Val Loss: 0.7171, F1 Micro: 0.6348, F1 Macro: 0.6322, Accuracy: 0.6348\n","Epoch 96, Train Loss: 0.5770, Val Loss: 0.7618, F1 Micro: 0.6348, F1 Macro: 0.6164, Accuracy: 0.6348\n","Epoch 97, Train Loss: 0.5646, Val Loss: 0.7974, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 98, Train Loss: 0.5666, Val Loss: 0.7240, F1 Micro: 0.6180, F1 Macro: 0.6068, Accuracy: 0.6180\n","Epoch 99, Train Loss: 0.5753, Val Loss: 0.8143, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 100, Train Loss: 0.5791, Val Loss: 0.8600, F1 Micro: 0.6236, F1 Macro: 0.5899, Accuracy: 0.6236\n","Epoch 101, Train Loss: 0.5725, Val Loss: 0.7183, F1 Micro: 0.6292, F1 Macro: 0.6288, Accuracy: 0.6292\n","Epoch 102, Train Loss: 0.5686, Val Loss: 0.8404, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 103, Train Loss: 0.5774, Val Loss: 0.7256, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 104, Train Loss: 0.5723, Val Loss: 0.7750, F1 Micro: 0.6011, F1 Macro: 0.5655, Accuracy: 0.6011\n","Epoch 105, Train Loss: 0.5784, Val Loss: 0.7574, F1 Micro: 0.6404, F1 Macro: 0.6233, Accuracy: 0.6404\n","Epoch 106, Train Loss: 0.5718, Val Loss: 0.7569, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 107, Train Loss: 0.5745, Val Loss: 0.7845, F1 Micro: 0.6180, F1 Macro: 0.5853, Accuracy: 0.6180\n","Epoch 108, Train Loss: 0.5676, Val Loss: 0.7710, F1 Micro: 0.6461, F1 Macro: 0.6435, Accuracy: 0.6461\n","Epoch 109, Train Loss: 0.5724, Val Loss: 0.7491, F1 Micro: 0.6573, F1 Macro: 0.6525, Accuracy: 0.6573\n","Epoch 110, Train Loss: 0.5674, Val Loss: 0.7648, F1 Micro: 0.6573, F1 Macro: 0.6515, Accuracy: 0.6573\n","Epoch 111, Train Loss: 0.5784, Val Loss: 0.8619, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6609, Val Loss: 0.6958, F1 Micro: 0.6348, F1 Macro: 0.5786, Accuracy: 0.6348\n","Epoch 2, Train Loss: 0.6412, Val Loss: 0.6523, F1 Micro: 0.6517, F1 Macro: 0.6070, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6381, Val Loss: 0.6434, F1 Micro: 0.6517, F1 Macro: 0.6428, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6395, Val Loss: 0.6795, F1 Micro: 0.5393, F1 Macro: 0.5365, Accuracy: 0.5393\n","Epoch 5, Train Loss: 0.6346, Val Loss: 0.6480, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 6, Train Loss: 0.6174, Val Loss: 0.6663, F1 Micro: 0.6124, F1 Macro: 0.6069, Accuracy: 0.6124\n","Epoch 7, Train Loss: 0.6261, Val Loss: 0.6370, F1 Micro: 0.6629, F1 Macro: 0.6365, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6178, Val Loss: 0.6313, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6272, Val Loss: 0.6293, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6202, Val Loss: 0.6371, F1 Micro: 0.6629, F1 Macro: 0.6531, Accuracy: 0.6629\n","Epoch 11, Train Loss: 0.6156, Val Loss: 0.6838, F1 Micro: 0.6236, F1 Macro: 0.5253, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6235, Val Loss: 0.6349, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 13, Train Loss: 0.6306, Val Loss: 0.6335, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 14, Train Loss: 0.6113, Val Loss: 0.6217, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6231, Val Loss: 0.6320, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6228, Val Loss: 0.6205, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6111, Val Loss: 0.6214, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 18, Train Loss: 0.6131, Val Loss: 0.6152, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 19, Train Loss: 0.6173, Val Loss: 0.6425, F1 Micro: 0.6573, F1 Macro: 0.6466, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6232, Val Loss: 0.6178, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 21, Train Loss: 0.6222, Val Loss: 0.6238, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 22, Train Loss: 0.6206, Val Loss: 0.6224, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6108, Val Loss: 0.6292, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 24, Train Loss: 0.6087, Val Loss: 0.6161, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6089, Val Loss: 0.6341, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.6116, Val Loss: 0.6290, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 27, Train Loss: 0.6165, Val Loss: 0.6185, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 28, Train Loss: 0.6180, Val Loss: 0.6193, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6218, Val Loss: 0.6387, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.6100, Val Loss: 0.6233, F1 Micro: 0.6685, F1 Macro: 0.6500, Accuracy: 0.6685\n","Epoch 31, Train Loss: 0.6158, Val Loss: 0.6254, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 32, Train Loss: 0.6172, Val Loss: 0.6164, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 33, Train Loss: 0.6074, Val Loss: 0.6251, F1 Micro: 0.6685, F1 Macro: 0.6518, Accuracy: 0.6685\n","Epoch 34, Train Loss: 0.6183, Val Loss: 0.6228, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 35, Train Loss: 0.6163, Val Loss: 0.6173, F1 Micro: 0.7022, F1 Macro: 0.6778, Accuracy: 0.7022\n","Epoch 36, Train Loss: 0.6129, Val Loss: 0.6199, F1 Micro: 0.6742, F1 Macro: 0.6568, Accuracy: 0.6742\n","Epoch 37, Train Loss: 0.6167, Val Loss: 0.6120, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 38, Train Loss: 0.6052, Val Loss: 0.6271, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 39, Train Loss: 0.6120, Val Loss: 0.6539, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 40, Train Loss: 0.6177, Val Loss: 0.6201, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.6177, Val Loss: 0.6256, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6140, Val Loss: 0.6110, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 43, Train Loss: 0.6197, Val Loss: 0.6170, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 44, Train Loss: 0.6076, Val Loss: 0.6083, F1 Micro: 0.7303, F1 Macro: 0.7052, Accuracy: 0.7303\n","Epoch 45, Train Loss: 0.6089, Val Loss: 0.6252, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 46, Train Loss: 0.6144, Val Loss: 0.6159, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.6059, Val Loss: 0.6153, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 48, Train Loss: 0.6085, Val Loss: 0.6185, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 49, Train Loss: 0.6054, Val Loss: 0.6188, F1 Micro: 0.6517, F1 Macro: 0.6428, Accuracy: 0.6517\n","Epoch 50, Train Loss: 0.6088, Val Loss: 0.6346, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 51, Train Loss: 0.6118, Val Loss: 0.6167, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 52, Train Loss: 0.6099, Val Loss: 0.6281, F1 Micro: 0.6966, F1 Macro: 0.6577, Accuracy: 0.6966\n","Epoch 53, Train Loss: 0.6077, Val Loss: 0.6148, F1 Micro: 0.6742, F1 Macro: 0.6618, Accuracy: 0.6742\n","Epoch 54, Train Loss: 0.6025, Val Loss: 0.6455, F1 Micro: 0.6742, F1 Macro: 0.6145, Accuracy: 0.6742\n","Epoch 55, Train Loss: 0.6161, Val Loss: 0.6242, F1 Micro: 0.6629, F1 Macro: 0.6567, Accuracy: 0.6629\n","Epoch 56, Train Loss: 0.6039, Val Loss: 0.6566, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 57, Train Loss: 0.6071, Val Loss: 0.6129, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6145, Val Loss: 0.6279, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 59, Train Loss: 0.6173, Val Loss: 0.6137, F1 Micro: 0.6742, F1 Macro: 0.6568, Accuracy: 0.6742\n","Epoch 60, Train Loss: 0.6089, Val Loss: 0.6170, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 61, Train Loss: 0.6126, Val Loss: 0.6127, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 62, Train Loss: 0.6069, Val Loss: 0.6069, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 63, Train Loss: 0.6085, Val Loss: 0.6179, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 64, Train Loss: 0.6116, Val Loss: 0.6038, F1 Micro: 0.7022, F1 Macro: 0.6856, Accuracy: 0.7022\n","Epoch 65, Train Loss: 0.6056, Val Loss: 0.6153, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 66, Train Loss: 0.6144, Val Loss: 0.6219, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 67, Train Loss: 0.6079, Val Loss: 0.6049, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 68, Train Loss: 0.6049, Val Loss: 0.6133, F1 Micro: 0.6742, F1 Macro: 0.6586, Accuracy: 0.6742\n","Epoch 69, Train Loss: 0.6062, Val Loss: 0.6023, F1 Micro: 0.6966, F1 Macro: 0.6769, Accuracy: 0.6966\n","Epoch 70, Train Loss: 0.6112, Val Loss: 0.6062, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.6046, Val Loss: 0.6048, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 72, Train Loss: 0.6036, Val Loss: 0.6225, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 73, Train Loss: 0.6021, Val Loss: 0.6127, F1 Micro: 0.7416, F1 Macro: 0.7154, Accuracy: 0.7416\n","Epoch 74, Train Loss: 0.6000, Val Loss: 0.6200, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 75, Train Loss: 0.6044, Val Loss: 0.6586, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 76, Train Loss: 0.6059, Val Loss: 0.6147, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 77, Train Loss: 0.6010, Val Loss: 0.6108, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 78, Train Loss: 0.6025, Val Loss: 0.6150, F1 Micro: 0.6798, F1 Macro: 0.6636, Accuracy: 0.6798\n","Epoch 79, Train Loss: 0.6008, Val Loss: 0.6095, F1 Micro: 0.6629, F1 Macro: 0.6544, Accuracy: 0.6629\n","Epoch 80, Train Loss: 0.6046, Val Loss: 0.6274, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 81, Train Loss: 0.6101, Val Loss: 0.6328, F1 Micro: 0.6685, F1 Macro: 0.5922, Accuracy: 0.6685\n","Epoch 82, Train Loss: 0.6055, Val Loss: 0.6164, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 83, Train Loss: 0.5997, Val Loss: 0.6109, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 84, Train Loss: 0.6039, Val Loss: 0.6010, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 85, Train Loss: 0.6079, Val Loss: 0.6133, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 86, Train Loss: 0.6115, Val Loss: 0.6123, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 87, Train Loss: 0.6041, Val Loss: 0.6069, F1 Micro: 0.7472, F1 Macro: 0.7205, Accuracy: 0.7472\n","Epoch 88, Train Loss: 0.5923, Val Loss: 0.6204, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 89, Train Loss: 0.6021, Val Loss: 0.6069, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 90, Train Loss: 0.5969, Val Loss: 0.6061, F1 Micro: 0.6685, F1 Macro: 0.6536, Accuracy: 0.6685\n","Epoch 91, Train Loss: 0.6076, Val Loss: 0.6078, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 92, Train Loss: 0.6100, Val Loss: 0.6139, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.6154, Val Loss: 0.6153, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 94, Train Loss: 0.6113, Val Loss: 0.5981, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 95, Train Loss: 0.6017, Val Loss: 0.6186, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 96, Train Loss: 0.5941, Val Loss: 0.5980, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 97, Train Loss: 0.6021, Val Loss: 0.6085, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 98, Train Loss: 0.5970, Val Loss: 0.6184, F1 Micro: 0.6461, F1 Macro: 0.6377, Accuracy: 0.6461\n","Epoch 99, Train Loss: 0.5973, Val Loss: 0.6144, F1 Micro: 0.7079, F1 Macro: 0.6704, Accuracy: 0.7079\n","Epoch 100, Train Loss: 0.6020, Val Loss: 0.6109, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 101, Train Loss: 0.6039, Val Loss: 0.6071, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 102, Train Loss: 0.6047, Val Loss: 0.6060, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 103, Train Loss: 0.6057, Val Loss: 0.6189, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 104, Train Loss: 0.5948, Val Loss: 0.6036, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 105, Train Loss: 0.5994, Val Loss: 0.5988, F1 Micro: 0.7022, F1 Macro: 0.6819, Accuracy: 0.7022\n","Epoch 106, Train Loss: 0.5914, Val Loss: 0.6083, F1 Micro: 0.7303, F1 Macro: 0.6931, Accuracy: 0.7303\n","Epoch 107, Train Loss: 0.6058, Val Loss: 0.6052, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 108, Train Loss: 0.6074, Val Loss: 0.6010, F1 Micro: 0.6910, F1 Macro: 0.6771, Accuracy: 0.6910\n","Epoch 109, Train Loss: 0.6048, Val Loss: 0.6064, F1 Micro: 0.6685, F1 Macro: 0.6500, Accuracy: 0.6685\n","Epoch 110, Train Loss: 0.5959, Val Loss: 0.6051, F1 Micro: 0.6798, F1 Macro: 0.6618, Accuracy: 0.6798\n","Epoch 111, Train Loss: 0.6008, Val Loss: 0.6093, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 112, Train Loss: 0.5932, Val Loss: 0.6215, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 113, Train Loss: 0.6027, Val Loss: 0.6276, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 114, Train Loss: 0.6044, Val Loss: 0.6011, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 115, Train Loss: 0.5975, Val Loss: 0.6111, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 116, Train Loss: 0.6033, Val Loss: 0.6037, F1 Micro: 0.6573, F1 Macro: 0.6492, Accuracy: 0.6573\n","Epoch 117, Train Loss: 0.6013, Val Loss: 0.6256, F1 Micro: 0.7303, F1 Macro: 0.6958, Accuracy: 0.7303\n","Epoch 118, Train Loss: 0.6041, Val Loss: 0.6286, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 119, Train Loss: 0.6076, Val Loss: 0.5919, F1 Micro: 0.6910, F1 Macro: 0.6786, Accuracy: 0.6910\n","Epoch 120, Train Loss: 0.5936, Val Loss: 0.5974, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 121, Train Loss: 0.5982, Val Loss: 0.6079, F1 Micro: 0.6517, F1 Macro: 0.6368, Accuracy: 0.6517\n","Epoch 122, Train Loss: 0.5952, Val Loss: 0.6176, F1 Micro: 0.6573, F1 Macro: 0.6240, Accuracy: 0.6573\n","Epoch 123, Train Loss: 0.5958, Val Loss: 0.6202, F1 Micro: 0.6404, F1 Macro: 0.6268, Accuracy: 0.6404\n","Epoch 124, Train Loss: 0.6025, Val Loss: 0.6068, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 125, Train Loss: 0.5931, Val Loss: 0.5968, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 126, Train Loss: 0.6122, Val Loss: 0.6368, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 127, Train Loss: 0.6004, Val Loss: 0.6089, F1 Micro: 0.6517, F1 Macro: 0.6401, Accuracy: 0.6517\n","Epoch 128, Train Loss: 0.5933, Val Loss: 0.6124, F1 Micro: 0.6798, F1 Macro: 0.6486, Accuracy: 0.6798\n","Epoch 129, Train Loss: 0.5885, Val Loss: 0.6179, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 130, Train Loss: 0.6070, Val Loss: 0.6320, F1 Micro: 0.6404, F1 Macro: 0.6284, Accuracy: 0.6404\n","Epoch 131, Train Loss: 0.6030, Val Loss: 0.6316, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 132, Train Loss: 0.5978, Val Loss: 0.6259, F1 Micro: 0.6236, F1 Macro: 0.5954, Accuracy: 0.6236\n","Epoch 133, Train Loss: 0.5898, Val Loss: 0.6110, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 134, Train Loss: 0.5933, Val Loss: 0.6084, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 135, Train Loss: 0.5899, Val Loss: 0.6057, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 136, Train Loss: 0.5951, Val Loss: 0.6028, F1 Micro: 0.6742, F1 Macro: 0.6603, Accuracy: 0.6742\n","Epoch 137, Train Loss: 0.6023, Val Loss: 0.6208, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.7047956813759338\n","Best hyperparameters for Outer FOLD 4: (0.001, 8, 50) with score 0.7317619735107652\n","Epoch 1, Train Loss: 0.6830, Val Loss: 0.6886, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 2, Train Loss: 0.6728, Val Loss: 0.6896, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 3, Train Loss: 0.6739, Val Loss: 0.6860, F1 Micro: 0.5676, F1 Macro: 0.3891, Accuracy: 0.5676\n","Epoch 4, Train Loss: 0.6730, Val Loss: 0.6919, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 5, Train Loss: 0.6707, Val Loss: 0.6915, F1 Micro: 0.5541, F1 Macro: 0.3656, Accuracy: 0.5541\n","Epoch 6, Train Loss: 0.6731, Val Loss: 0.6933, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 7, Train Loss: 0.6689, Val Loss: 0.6960, F1 Micro: 0.5586, F1 Macro: 0.4149, Accuracy: 0.5586\n","Epoch 8, Train Loss: 0.6663, Val Loss: 0.6957, F1 Micro: 0.5541, F1 Macro: 0.3656, Accuracy: 0.5541\n","Epoch 9, Train Loss: 0.6675, Val Loss: 0.6992, F1 Micro: 0.5450, F1 Macro: 0.3528, Accuracy: 0.5450\n","Epoch 10, Train Loss: 0.6665, Val Loss: 0.6952, F1 Micro: 0.5631, F1 Macro: 0.3784, Accuracy: 0.5631\n","Epoch 11, Train Loss: 0.6622, Val Loss: 0.6961, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 12, Train Loss: 0.6640, Val Loss: 0.6992, F1 Micro: 0.5495, F1 Macro: 0.3636, Accuracy: 0.5495\n","Epoch 13, Train Loss: 0.6641, Val Loss: 0.6978, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 14, Train Loss: 0.6650, Val Loss: 0.6958, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 15, Train Loss: 0.6659, Val Loss: 0.6979, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 16, Train Loss: 0.6659, Val Loss: 0.6969, F1 Micro: 0.5541, F1 Macro: 0.3565, Accuracy: 0.5541\n","Epoch 17, Train Loss: 0.6640, Val Loss: 0.6887, F1 Micro: 0.5586, F1 Macro: 0.4717, Accuracy: 0.5586\n","Epoch 18, Train Loss: 0.6771, Val Loss: 0.6978, F1 Micro: 0.5631, F1 Macro: 0.4838, Accuracy: 0.5631\n","Epoch 19, Train Loss: 0.6645, Val Loss: 0.7072, F1 Micro: 0.5405, F1 Macro: 0.4680, Accuracy: 0.5405\n","Epoch 20, Train Loss: 0.6583, Val Loss: 0.6795, F1 Micro: 0.5856, F1 Macro: 0.4997, Accuracy: 0.5856\n","Epoch 21, Train Loss: 0.6591, Val Loss: 0.6983, F1 Micro: 0.5766, F1 Macro: 0.5058, Accuracy: 0.5766\n","Epoch 22, Train Loss: 0.6586, Val Loss: 0.6794, F1 Micro: 0.6036, F1 Macro: 0.5077, Accuracy: 0.6036\n","Epoch 23, Train Loss: 0.6474, Val Loss: 0.6434, F1 Micro: 0.6847, F1 Macro: 0.6320, Accuracy: 0.6847\n","Epoch 24, Train Loss: 0.6400, Val Loss: 0.6478, F1 Micro: 0.6667, F1 Macro: 0.6045, Accuracy: 0.6667\n","Epoch 25, Train Loss: 0.6288, Val Loss: 0.6692, F1 Micro: 0.6171, F1 Macro: 0.5221, Accuracy: 0.6171\n","Epoch 26, Train Loss: 0.6319, Val Loss: 0.6670, F1 Micro: 0.6126, F1 Macro: 0.5442, Accuracy: 0.6126\n","Epoch 27, Train Loss: 0.6321, Val Loss: 0.6328, F1 Micro: 0.6577, F1 Macro: 0.6361, Accuracy: 0.6577\n","Epoch 28, Train Loss: 0.6262, Val Loss: 0.6528, F1 Micro: 0.6622, F1 Macro: 0.5939, Accuracy: 0.6622\n","Epoch 29, Train Loss: 0.6290, Val Loss: 0.6285, F1 Micro: 0.6802, F1 Macro: 0.6460, Accuracy: 0.6802\n","Epoch 30, Train Loss: 0.6285, Val Loss: 0.6250, F1 Micro: 0.6847, F1 Macro: 0.6520, Accuracy: 0.6847\n","Epoch 31, Train Loss: 0.6256, Val Loss: 0.6347, F1 Micro: 0.6757, F1 Macro: 0.6273, Accuracy: 0.6757\n","Epoch 32, Train Loss: 0.6272, Val Loss: 0.6210, F1 Micro: 0.6892, F1 Macro: 0.6600, Accuracy: 0.6892\n","Epoch 33, Train Loss: 0.6158, Val Loss: 0.6331, F1 Micro: 0.6892, F1 Macro: 0.6467, Accuracy: 0.6892\n","Epoch 34, Train Loss: 0.6122, Val Loss: 0.6389, F1 Micro: 0.6577, F1 Macro: 0.6199, Accuracy: 0.6577\n","Epoch 35, Train Loss: 0.6231, Val Loss: 0.6288, F1 Micro: 0.6802, F1 Macro: 0.6390, Accuracy: 0.6802\n","Epoch 36, Train Loss: 0.6118, Val Loss: 0.6277, F1 Micro: 0.6757, F1 Macro: 0.6399, Accuracy: 0.6757\n","Epoch 37, Train Loss: 0.6102, Val Loss: 0.6265, F1 Micro: 0.6577, F1 Macro: 0.6222, Accuracy: 0.6577\n","Epoch 38, Train Loss: 0.6095, Val Loss: 0.6078, F1 Micro: 0.6667, F1 Macro: 0.6543, Accuracy: 0.6667\n","Epoch 39, Train Loss: 0.6117, Val Loss: 0.6162, F1 Micro: 0.6892, F1 Macro: 0.6638, Accuracy: 0.6892\n","Epoch 40, Train Loss: 0.6071, Val Loss: 0.6087, F1 Micro: 0.6847, F1 Macro: 0.6598, Accuracy: 0.6847\n","Epoch 41, Train Loss: 0.6133, Val Loss: 0.6496, F1 Micro: 0.6396, F1 Macro: 0.5649, Accuracy: 0.6396\n","Epoch 42, Train Loss: 0.6145, Val Loss: 0.6066, F1 Micro: 0.6847, F1 Macro: 0.6678, Accuracy: 0.6847\n","Epoch 43, Train Loss: 0.6108, Val Loss: 0.6151, F1 Micro: 0.6847, F1 Macro: 0.6561, Accuracy: 0.6847\n","Epoch 44, Train Loss: 0.6069, Val Loss: 0.6228, F1 Micro: 0.6577, F1 Macro: 0.6307, Accuracy: 0.6577\n","Epoch 45, Train Loss: 0.6077, Val Loss: 0.6337, F1 Micro: 0.7027, F1 Macro: 0.6608, Accuracy: 0.7027\n","Epoch 46, Train Loss: 0.6010, Val Loss: 0.6066, F1 Micro: 0.6802, F1 Macro: 0.6652, Accuracy: 0.6802\n","Epoch 47, Train Loss: 0.6075, Val Loss: 0.6077, F1 Micro: 0.6982, F1 Macro: 0.6886, Accuracy: 0.6982\n","Epoch 48, Train Loss: 0.6097, Val Loss: 0.6116, F1 Micro: 0.6712, F1 Macro: 0.6443, Accuracy: 0.6712\n","Epoch 49, Train Loss: 0.6030, Val Loss: 0.6259, F1 Micro: 0.6532, F1 Macro: 0.6268, Accuracy: 0.6532\n","Epoch 50, Train Loss: 0.6041, Val Loss: 0.6211, F1 Micro: 0.6802, F1 Macro: 0.6460, Accuracy: 0.6802\n","Epoch 51, Train Loss: 0.6079, Val Loss: 0.6102, F1 Micro: 0.6802, F1 Macro: 0.6522, Accuracy: 0.6802\n","Epoch 52, Train Loss: 0.6087, Val Loss: 0.5828, F1 Micro: 0.7117, F1 Macro: 0.7020, Accuracy: 0.7117\n","Epoch 53, Train Loss: 0.6053, Val Loss: 0.6127, F1 Micro: 0.6802, F1 Macro: 0.6576, Accuracy: 0.6802\n","Epoch 54, Train Loss: 0.5949, Val Loss: 0.6142, F1 Micro: 0.6847, F1 Macro: 0.6580, Accuracy: 0.6847\n","Epoch 55, Train Loss: 0.6109, Val Loss: 0.6193, F1 Micro: 0.6622, F1 Macro: 0.6401, Accuracy: 0.6622\n","Epoch 56, Train Loss: 0.5978, Val Loss: 0.6275, F1 Micro: 0.6847, F1 Macro: 0.6476, Accuracy: 0.6847\n","Epoch 57, Train Loss: 0.5959, Val Loss: 0.6146, F1 Micro: 0.6802, F1 Macro: 0.6502, Accuracy: 0.6802\n","Epoch 58, Train Loss: 0.6000, Val Loss: 0.6103, F1 Micro: 0.6847, F1 Macro: 0.6649, Accuracy: 0.6847\n","Epoch 59, Train Loss: 0.5998, Val Loss: 0.6089, F1 Micro: 0.6802, F1 Macro: 0.6710, Accuracy: 0.6802\n","Epoch 60, Train Loss: 0.6066, Val Loss: 0.6377, F1 Micro: 0.6802, F1 Macro: 0.6390, Accuracy: 0.6802\n","Epoch 61, Train Loss: 0.5953, Val Loss: 0.6180, F1 Micro: 0.6937, F1 Macro: 0.6599, Accuracy: 0.6937\n","Epoch 62, Train Loss: 0.6031, Val Loss: 0.6188, F1 Micro: 0.6667, F1 Macro: 0.6365, Accuracy: 0.6667\n","Epoch 63, Train Loss: 0.6108, Val Loss: 0.6272, F1 Micro: 0.6937, F1 Macro: 0.6554, Accuracy: 0.6937\n","Epoch 64, Train Loss: 0.5997, Val Loss: 0.6165, F1 Micro: 0.6847, F1 Macro: 0.6580, Accuracy: 0.6847\n","Epoch 65, Train Loss: 0.6023, Val Loss: 0.5991, F1 Micro: 0.6892, F1 Macro: 0.6733, Accuracy: 0.6892\n","Epoch 66, Train Loss: 0.5977, Val Loss: 0.6114, F1 Micro: 0.6892, F1 Macro: 0.6620, Accuracy: 0.6892\n","Epoch 67, Train Loss: 0.5968, Val Loss: 0.6115, F1 Micro: 0.6937, F1 Macro: 0.6834, Accuracy: 0.6937\n","Epoch 68, Train Loss: 0.6090, Val Loss: 0.6092, F1 Micro: 0.6847, F1 Macro: 0.6664, Accuracy: 0.6847\n","Epoch 69, Train Loss: 0.5966, Val Loss: 0.6116, F1 Micro: 0.6757, F1 Macro: 0.6519, Accuracy: 0.6757\n","Epoch 70, Train Loss: 0.6016, Val Loss: 0.6174, F1 Micro: 0.6892, F1 Macro: 0.6638, Accuracy: 0.6892\n","Epoch 71, Train Loss: 0.6002, Val Loss: 0.6108, F1 Micro: 0.6802, F1 Macro: 0.6608, Accuracy: 0.6802\n","Epoch 72, Train Loss: 0.5989, Val Loss: 0.6309, F1 Micro: 0.6757, F1 Macro: 0.6399, Accuracy: 0.6757\n","Epoch 73, Train Loss: 0.6009, Val Loss: 0.6118, F1 Micro: 0.6892, F1 Macro: 0.6638, Accuracy: 0.6892\n","Epoch 74, Train Loss: 0.6026, Val Loss: 0.6262, F1 Micro: 0.6757, F1 Macro: 0.6463, Accuracy: 0.6757\n","Epoch 75, Train Loss: 0.5928, Val Loss: 0.6309, F1 Micro: 0.6892, F1 Macro: 0.6491, Accuracy: 0.6892\n","Epoch 76, Train Loss: 0.6073, Val Loss: 0.6240, F1 Micro: 0.6892, F1 Macro: 0.6560, Accuracy: 0.6892\n","Epoch 77, Train Loss: 0.5991, Val Loss: 0.6307, F1 Micro: 0.6892, F1 Macro: 0.6538, Accuracy: 0.6892\n","Epoch 78, Train Loss: 0.5929, Val Loss: 0.6175, F1 Micro: 0.6802, F1 Macro: 0.6559, Accuracy: 0.6802\n","Epoch 79, Train Loss: 0.6048, Val Loss: 0.6066, F1 Micro: 0.6847, F1 Macro: 0.6730, Accuracy: 0.6847\n","Epoch 80, Train Loss: 0.5983, Val Loss: 0.6207, F1 Micro: 0.6847, F1 Macro: 0.6520, Accuracy: 0.6847\n","Epoch 81, Train Loss: 0.6042, Val Loss: 0.6178, F1 Micro: 0.6892, F1 Macro: 0.6620, Accuracy: 0.6892\n","Epoch 82, Train Loss: 0.5984, Val Loss: 0.6174, F1 Micro: 0.6892, F1 Macro: 0.6733, Accuracy: 0.6892\n","Epoch 83, Train Loss: 0.5952, Val Loss: 0.6180, F1 Micro: 0.6847, F1 Macro: 0.6520, Accuracy: 0.6847\n","Epoch 84, Train Loss: 0.5995, Val Loss: 0.6295, F1 Micro: 0.6622, F1 Macro: 0.6326, Accuracy: 0.6622\n","Epoch 85, Train Loss: 0.5928, Val Loss: 0.6108, F1 Micro: 0.6802, F1 Macro: 0.6541, Accuracy: 0.6802\n","Epoch 86, Train Loss: 0.5970, Val Loss: 0.6116, F1 Micro: 0.6802, F1 Macro: 0.6576, Accuracy: 0.6802\n","Epoch 87, Train Loss: 0.5908, Val Loss: 0.6121, F1 Micro: 0.6802, F1 Macro: 0.6593, Accuracy: 0.6802\n","Epoch 88, Train Loss: 0.6006, Val Loss: 0.6115, F1 Micro: 0.6892, F1 Macro: 0.6689, Accuracy: 0.6892\n","Epoch 89, Train Loss: 0.5933, Val Loss: 0.6249, F1 Micro: 0.6667, F1 Macro: 0.6365, Accuracy: 0.6667\n","Epoch 90, Train Loss: 0.5986, Val Loss: 0.6147, F1 Micro: 0.6712, F1 Macro: 0.6462, Accuracy: 0.6712\n","Epoch 91, Train Loss: 0.5993, Val Loss: 0.6133, F1 Micro: 0.6802, F1 Macro: 0.6559, Accuracy: 0.6802\n","Epoch 92, Train Loss: 0.5897, Val Loss: 0.6314, F1 Micro: 0.6892, F1 Macro: 0.6515, Accuracy: 0.6892\n","Epoch 93, Train Loss: 0.5860, Val Loss: 0.6125, F1 Micro: 0.6847, F1 Macro: 0.6649, Accuracy: 0.6847\n","Epoch 94, Train Loss: 0.5962, Val Loss: 0.6245, F1 Micro: 0.6982, F1 Macro: 0.6638, Accuracy: 0.6982\n","Epoch 95, Train Loss: 0.5973, Val Loss: 0.6234, F1 Micro: 0.6802, F1 Macro: 0.6541, Accuracy: 0.6802\n","Epoch 96, Train Loss: 0.5942, Val Loss: 0.6156, F1 Micro: 0.6712, F1 Macro: 0.6497, Accuracy: 0.6712\n","Epoch 97, Train Loss: 0.5889, Val Loss: 0.6301, F1 Micro: 0.6847, F1 Macro: 0.6499, Accuracy: 0.6847\n","Epoch 98, Train Loss: 0.5927, Val Loss: 0.6257, F1 Micro: 0.6847, F1 Macro: 0.6541, Accuracy: 0.6847\n","Epoch 99, Train Loss: 0.5977, Val Loss: 0.6092, F1 Micro: 0.6982, F1 Macro: 0.6769, Accuracy: 0.6982\n","Epoch 100, Train Loss: 0.5971, Val Loss: 0.5974, F1 Micro: 0.6892, F1 Macro: 0.6771, Accuracy: 0.6892\n","Epoch 101, Train Loss: 0.6001, Val Loss: 0.6326, F1 Micro: 0.6802, F1 Macro: 0.6481, Accuracy: 0.6802\n","Epoch 102, Train Loss: 0.5975, Val Loss: 0.6257, F1 Micro: 0.6892, F1 Macro: 0.6580, Accuracy: 0.6892\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6892, F1 Macro: 0.6580, Accuracy: 0.6892\n"]}]},{"cell_type":"code","source":["update_model_metrics_pr('GINModel', f1_micro_test_list3, f1_macro_test_list3, accuracy_test_list3)\n","\n","print(models_evaluation_metrics_pr)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOsqlLkfZHhD","executionInfo":{"status":"ok","timestamp":1711389856522,"user_tz":-60,"elapsed":556,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"49d362ff-fdc3-48ac-ef0a-8b5ed6d0e57a"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]], 'f1_macro': [[0.6368645296571416, 0.7291175419792784, 0.5760113268608413, 0.586319141408185, 0.6266265380189431]], 'accuracy': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]]}, 'GraphSAGEModel': {'f1_micro': [[0.6457399103139013, 0.7668161434977578, 0.6681614349775785, 0.6846846846846847, 0.7027027027027027]], 'f1_macro': [[0.6094224587074603, 0.7003927242662258, 0.6639377647442164, 0.6615853658536586, 0.6719211822660098]], 'accuracy': [[0.6457399103139013, 0.7668161434977578, 0.6681614349775785, 0.6846846846846847, 0.7027027027027027]]}, 'GINModel': {'f1_micro': [[0.6322869955156951, 0.6860986547085202, 0.6547085201793722, 0.6981981981981982, 0.6891891891891891]], 'f1_macro': [[0.5933552748621241, 0.40691489361702127, 0.6443823133478306, 0.6852662984828286, 0.6580421922089519]], 'accuracy': [[0.6322869955156951, 0.6860986547085202, 0.6547085201793722, 0.6981981981981982, 0.6891891891891891]]}}\n"]}]},{"cell_type":"code","source":["data = {\n","    'BasicGraphModel': {'f1_micro': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]],\n","                     'f1_macro': [[0.6368645296571416, 0.7291175419792784, 0.5760113268608413, 0.586319141408185, 0.6266265380189431]],\n","                     'accuracy': [[0.672645739910314, 0.7713004484304933, 0.57847533632287, 0.6441441441441441, 0.6576576576576577]]},\n"," 'GraphSAGEModel': {'f1_micro': [[0.6457399103139013, 0.7668161434977578, 0.6681614349775785, 0.6846846846846847, 0.7027027027027027]],\n","                    'f1_macro': [[0.6094224587074603, 0.7003927242662258, 0.6639377647442164, 0.6615853658536586, 0.6719211822660098]],\n","                    'accuracy': [[0.6457399103139013, 0.7668161434977578, 0.6681614349775785, 0.6846846846846847, 0.7027027027027027]]},\n"," 'GINModel': {'f1_micro': [[0.6322869955156951, 0.6860986547085202, 0.6547085201793722, 0.6981981981981982, 0.6891891891891891]],\n","              'f1_macro': [[0.5933552748621241, 0.40691489361702127, 0.6443823133478306, 0.6852662984828286, 0.6580421922089519]],\n","              'accuracy': [[0.6322869955156951, 0.6860986547085202, 0.6547085201793722, 0.6981981981981982, 0.6891891891891891]]}}\n","\n","\n","# Convert the nested structure to a flat structure suitable for DataFrame\n","records = []\n","for model_name, metrics in data.items():\n","    for metric_name, metric_values in metrics.items():\n","        for values in metric_values:  # metric_values is a list of lists\n","            record = {\"Model\": model_name, \"Metric\": metric_name}\n","            # Assuming a fixed number of folds, e.g., 5\n","            for fold_index, value in enumerate(values, start=1):\n","                record[f\"Fold{fold_index}\"] = value\n","            records.append(record)\n","\n","# Create DataFrame\n","df = pd.DataFrame(records)\n","df['Mean'] = df.mean(axis=1)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIK87W1rgC0v","executionInfo":{"status":"ok","timestamp":1711555661340,"user_tz":-60,"elapsed":188,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"e4589ed5-feb3-49c7-ece8-e505b99a55d9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-21302c92b6fe>:26: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n","  df['Mean'] = df.mean(axis=1)\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"m2x9a8KmUd7x","executionInfo":{"status":"ok","timestamp":1711555663534,"user_tz":-60,"elapsed":4,"user":{"displayName":"Hanwen XU","userId":"13475811192698411200"}},"outputId":"de99ac54-d4bf-4d28-c44f-22f8a7cdf641"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             Model    Metric     Fold1     Fold2     Fold3     Fold4  \\\n","0  BasicGraphModel  f1_micro  0.672646  0.771300  0.578475  0.644144   \n","1  BasicGraphModel  f1_macro  0.636865  0.729118  0.576011  0.586319   \n","2  BasicGraphModel  accuracy  0.672646  0.771300  0.578475  0.644144   \n","3   GraphSAGEModel  f1_micro  0.645740  0.766816  0.668161  0.684685   \n","4   GraphSAGEModel  f1_macro  0.609422  0.700393  0.663938  0.661585   \n","5   GraphSAGEModel  accuracy  0.645740  0.766816  0.668161  0.684685   \n","6         GINModel  f1_micro  0.632287  0.686099  0.654709  0.698198   \n","7         GINModel  f1_macro  0.593355  0.406915  0.644382  0.685266   \n","8         GINModel  accuracy  0.632287  0.686099  0.654709  0.698198   \n","\n","      Fold5      Mean  \n","0  0.657658  0.664845  \n","1  0.626627  0.630988  \n","2  0.657658  0.664845  \n","3  0.702703  0.693621  \n","4  0.671921  0.661452  \n","5  0.702703  0.693621  \n","6  0.689189  0.672096  \n","7  0.658042  0.597592  \n","8  0.689189  0.672096  "],"text/html":["\n","  <div id=\"df-116bf135-047a-4e60-acce-9cab760f40b9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Metric</th>\n","      <th>Fold1</th>\n","      <th>Fold2</th>\n","      <th>Fold3</th>\n","      <th>Fold4</th>\n","      <th>Fold5</th>\n","      <th>Mean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BasicGraphModel</td>\n","      <td>f1_micro</td>\n","      <td>0.672646</td>\n","      <td>0.771300</td>\n","      <td>0.578475</td>\n","      <td>0.644144</td>\n","      <td>0.657658</td>\n","      <td>0.664845</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BasicGraphModel</td>\n","      <td>f1_macro</td>\n","      <td>0.636865</td>\n","      <td>0.729118</td>\n","      <td>0.576011</td>\n","      <td>0.586319</td>\n","      <td>0.626627</td>\n","      <td>0.630988</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BasicGraphModel</td>\n","      <td>accuracy</td>\n","      <td>0.672646</td>\n","      <td>0.771300</td>\n","      <td>0.578475</td>\n","      <td>0.644144</td>\n","      <td>0.657658</td>\n","      <td>0.664845</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GraphSAGEModel</td>\n","      <td>f1_micro</td>\n","      <td>0.645740</td>\n","      <td>0.766816</td>\n","      <td>0.668161</td>\n","      <td>0.684685</td>\n","      <td>0.702703</td>\n","      <td>0.693621</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GraphSAGEModel</td>\n","      <td>f1_macro</td>\n","      <td>0.609422</td>\n","      <td>0.700393</td>\n","      <td>0.663938</td>\n","      <td>0.661585</td>\n","      <td>0.671921</td>\n","      <td>0.661452</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>GraphSAGEModel</td>\n","      <td>accuracy</td>\n","      <td>0.645740</td>\n","      <td>0.766816</td>\n","      <td>0.668161</td>\n","      <td>0.684685</td>\n","      <td>0.702703</td>\n","      <td>0.693621</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>GINModel</td>\n","      <td>f1_micro</td>\n","      <td>0.632287</td>\n","      <td>0.686099</td>\n","      <td>0.654709</td>\n","      <td>0.698198</td>\n","      <td>0.689189</td>\n","      <td>0.672096</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>GINModel</td>\n","      <td>f1_macro</td>\n","      <td>0.593355</td>\n","      <td>0.406915</td>\n","      <td>0.644382</td>\n","      <td>0.685266</td>\n","      <td>0.658042</td>\n","      <td>0.597592</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>GINModel</td>\n","      <td>accuracy</td>\n","      <td>0.632287</td>\n","      <td>0.686099</td>\n","      <td>0.654709</td>\n","      <td>0.698198</td>\n","      <td>0.689189</td>\n","      <td>0.672096</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-116bf135-047a-4e60-acce-9cab760f40b9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-116bf135-047a-4e60-acce-9cab760f40b9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-116bf135-047a-4e60-acce-9cab760f40b9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8cc2d663-7cb6-4343-8196-0a3cd0818e3e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cc2d663-7cb6-4343-8196-0a3cd0818e3e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8cc2d663-7cb6-4343-8196-0a3cd0818e3e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BasicGraphModel\",\n          \"GraphSAGEModel\",\n          \"GINModel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"f1_micro\",\n          \"f1_macro\",\n          \"accuracy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025972934469360456,\n        \"min\": 0.5933552748621241,\n        \"max\": 0.672645739910314,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.672645739910314,\n          0.6368645296571416,\n          0.5933552748621241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11521945275966362,\n        \"min\": 0.40691489361702127,\n        \"max\": 0.7713004484304933,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.7713004484304933,\n          0.7291175419792784,\n          0.40691489361702127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04135879519855216,\n        \"min\": 0.5760113268608413,\n        \"max\": 0.6681614349775785,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.57847533632287,\n          0.5760113268608413,\n          0.6443823133478306\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.036162234937870366,\n        \"min\": 0.586319141408185,\n        \"max\": 0.6981981981981982,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6441441441441441,\n          0.586319141408185,\n          0.6852662984828286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fold5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02533441976368149,\n        \"min\": 0.6266265380189431,\n        \"max\": 0.7027027027027027,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6576576576576577,\n          0.6266265380189431,\n          0.6580421922089519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030259387066482634,\n        \"min\": 0.5975921945037512,\n        \"max\": 0.693620975235325,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6648446652930958,\n          0.6309878155848778,\n          0.5975921945037512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"JBUS9J6DUv8y"},"execution_count":null,"outputs":[]}]}