{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMtQyb6RRGwIUfKhdw2ORnn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Cg1yS7CtWxhL"},"outputs":[],"source":["!pip install torch_geometric"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch_geometric.nn as graphnn\n","from sklearn.metrics import f1_score\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.utils import scatter\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.model_selection import KFold\n","from itertools import product"],"metadata":{"id":"aINE03GAW555","executionInfo":{"status":"ok","timestamp":1711483877798,"user_tz":-60,"elapsed":13200,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from torch_geometric.datasets import TUDataset\n","\n","dataset_en = TUDataset(root='', name='ENZYMES',use_node_attr = True)\n","dataset_rd = TUDataset(root='', name='REDDIT-BINARY')\n","dataset_pr = TUDataset(root='', name='PROTEINS')"],"metadata":{"id":"49g8dOkOW_P-","executionInfo":{"status":"ok","timestamp":1711483900053,"user_tz":-60,"elapsed":16802,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7a5637b-c202-49b1-c732-c0fbe4f405ee"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n","Processing...\n","Done!\n","Downloading https://www.chrsmrrs.com/graphkerneldatasets/REDDIT-BINARY.zip\n","Processing...\n","Done!\n","Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n","Processing...\n","Done!\n"]}]},{"cell_type":"code","source":["print(len(dataset_en))\n","print(len(dataset_rd))\n","print(len(dataset_pr))\n","\n","print(dataset_en.num_classes)\n","print(dataset_rd.num_classes)\n","print(dataset_pr.num_classes)\n","\n","print(dataset_en.num_node_features)\n","print(dataset_rd.num_node_features)\n","print(dataset_pr.num_node_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3NklUcvXA8f","executionInfo":{"status":"ok","timestamp":1711483902037,"user_tz":-60,"elapsed":285,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"129db298-bb2e-4c43-83c4-414f2cb254be"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["600\n","2000\n","1113\n","6\n","2\n","2\n","21\n","0\n","3\n"]}]},{"cell_type":"code","source":["from torch_geometric.loader import DataLoader\n","train_en = dataset_en[:int(len(dataset_en)*0.8)]\n","val_en = dataset_en[int(len(dataset_en)*0.8):int(len(dataset_en)*0.9)]\n","test_en = dataset_en[int(len(dataset_en)*0.9):]\n","\n","train_en_loader = DataLoader(train_en, batch_size=32, shuffle=True)\n","val_en_loader = DataLoader(val_en, batch_size=32, shuffle=False)\n","test_en_loader = DataLoader(test_en, batch_size=32, shuffle=False)"],"metadata":{"id":"aNc7viMVXDkb","executionInfo":{"status":"ok","timestamp":1711483904039,"user_tz":-60,"elapsed":258,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class MLP1(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(MLP1, self).__init__()\n","\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, data):\n","        x = self.fc1(data.x)\n","        x = graphnn.global_add_pool(x, data.batch)\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"6qGeQhCXXF6F","executionInfo":{"status":"ok","timestamp":1711487544952,"user_tz":-60,"elapsed":234,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def train(model, loss_fcn, device, optimizer, max_epochs, train_dataloader, val_dataloader, patience=30):\n","    best_val_score = 0\n","    patience_counter = 0\n","    metrics_history = {'train_loss': [], 'val_loss': [], 'f1_micro': [], 'f1_macro': [], 'accuracy': [], 'best_score':[]}\n","\n","    for epoch in range(max_epochs):\n","        model.train()\n","        train_losses = []\n","        for batch in train_dataloader:\n","            if batch.x is None:\n","                raise ValueError(\"Node features are missing. Ensure data.x is correctly set.\")\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            logits = model(batch)\n","            loss = loss_fcn(logits, batch.y)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","\n","        val_loss = evaluate_loss(model, loss_fcn, device, val_dataloader)\n","        f1_micro, f1_macro, accuracy = evaluate_metrics(model, device, val_dataloader)\n","\n","        # Save metrics\n","        metrics_history['train_loss'].append(np.mean(train_losses))\n","        metrics_history['val_loss'].append(val_loss)\n","        metrics_history['f1_micro'].append(f1_micro)\n","        metrics_history['f1_macro'].append(f1_macro)\n","        metrics_history['accuracy'].append(accuracy)\n","\n","        print(f\"Epoch {epoch+1}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {val_loss:.4f}, F1 Micro: {f1_micro:.4f}, F1 Macro: {f1_macro:.4f}, Accuracy: {accuracy:.4f}\")\n","\n","        # Early stopping logic using f1_micro score\n","        if f1_micro > best_val_score:\n","            best_val_score = f1_micro\n","            metrics_history['best_score'] = best_val_score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(\"Early stopping triggered\")\n","                break\n","\n","    return metrics_history"],"metadata":{"id":"O3Zv_TFlXMWX","executionInfo":{"status":"ok","timestamp":1711487546891,"user_tz":-60,"elapsed":318,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def evaluate_loss(model, loss_fcn, device, dataloader):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            batch = batch.to(device)\n","            outputs = model(batch)\n","            loss = loss_fcn(outputs, batch.y)\n","            total_loss += loss.item()\n","    return total_loss / len(dataloader)"],"metadata":{"id":"rBFF8bHzXQSy","executionInfo":{"status":"ok","timestamp":1711487547890,"user_tz":-60,"elapsed":1,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def evaluate_metrics(model, device, dataloader):\n","    model.eval()\n","    total_preds = []\n","    total_targets = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            batch = batch.to(device)\n","            outputs = model(batch)\n","            _, predicted = torch.max(outputs, 1)\n","            total_preds.extend(predicted.view(-1).cpu().numpy())\n","            total_targets.extend(batch.y.view(-1).cpu().numpy())\n","\n","    f1_micro = f1_score(total_targets, total_preds, average='micro')\n","    f1_macro = f1_score(total_targets, total_preds, average='macro')\n","    accuracy = accuracy_score(total_targets, total_preds)\n","    return f1_micro, f1_macro, accuracy"],"metadata":{"id":"QGs4rkPjXZ-I","executionInfo":{"status":"ok","timestamp":1711487548581,"user_tz":-60,"elapsed":1,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"\\nDevice: \", device)\n","\n","### Max number of epochs\n","max_epochs = 500\n","n_features = dataset_en.num_node_features\n","n_classes = dataset_en.num_classes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7aG1cGCXb_w","executionInfo":{"status":"ok","timestamp":1711487550005,"user_tz":-60,"elapsed":234,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"c933a71b-8e09-4e45-c4f5-4c5ef814de63"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Device:  cuda\n"]}]},{"cell_type":"code","source":["baseline = MLP1(\n","    input_size=n_features, hidden_size=256, output_size=n_classes\n",").to(device)\n","\n","### DEFINE LOSS FUNCTION\n","loss_fcn = nn.CrossEntropyLoss()\n","### DEFINE OPTIMIZER\n","optimizer = torch.optim.Adam(baseline.parameters(), lr=0.005)\n","\n","### TRAIN THE MODEL\n","metrics_history=train(\n","    baseline,\n","    loss_fcn,\n","    device,\n","    optimizer,\n","    max_epochs,\n","    train_en_loader,\n","    val_en_loader,\n",")"],"metadata":{"id":"FLfFUtH0Xd4H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711487557097,"user_tz":-60,"elapsed":4386,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"dbadd39a-fa3f-4cc5-855b-313c11cf8476"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 222.7368, Val Loss: 956.3276, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 2, Train Loss: 97.3466, Val Loss: 833.8297, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 3, Train Loss: 56.3178, Val Loss: 782.7109, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 4, Train Loss: 58.0872, Val Loss: 847.0623, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 5, Train Loss: 54.6008, Val Loss: 755.0434, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 6, Train Loss: 23.8182, Val Loss: 677.7715, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 7, Train Loss: 33.5637, Val Loss: 657.1805, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 8, Train Loss: 39.5702, Val Loss: 639.0893, F1 Micro: 0.1500, F1 Macro: 0.1364, Accuracy: 0.1500\n","Epoch 9, Train Loss: 27.9771, Val Loss: 581.0397, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 10, Train Loss: 15.2881, Val Loss: 552.8737, F1 Micro: 0.1000, F1 Macro: 0.0923, Accuracy: 0.1000\n","Epoch 11, Train Loss: 18.0720, Val Loss: 581.8611, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 12, Train Loss: 24.5558, Val Loss: 540.6567, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 13, Train Loss: 19.6676, Val Loss: 495.1346, F1 Micro: 0.0667, F1 Macro: 0.0615, Accuracy: 0.0667\n","Epoch 14, Train Loss: 17.1004, Val Loss: 496.7846, F1 Micro: 0.3000, F1 Macro: 0.1169, Accuracy: 0.3000\n","Epoch 15, Train Loss: 14.8639, Val Loss: 467.2037, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 16, Train Loss: 12.5241, Val Loss: 461.6641, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 17, Train Loss: 11.2832, Val Loss: 442.6768, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 18, Train Loss: 10.4874, Val Loss: 433.6441, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 19, Train Loss: 13.4123, Val Loss: 421.3462, F1 Micro: 0.1833, F1 Macro: 0.2222, Accuracy: 0.1833\n","Epoch 20, Train Loss: 14.8784, Val Loss: 412.8246, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 21, Train Loss: 10.6793, Val Loss: 390.7954, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 22, Train Loss: 11.7487, Val Loss: 388.5843, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 23, Train Loss: 20.0180, Val Loss: 406.8352, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 24, Train Loss: 14.5351, Val Loss: 339.5113, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 25, Train Loss: 9.1047, Val Loss: 331.5635, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 26, Train Loss: 10.5124, Val Loss: 324.1704, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 27, Train Loss: 5.8399, Val Loss: 304.4910, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 28, Train Loss: 5.4262, Val Loss: 296.9874, F1 Micro: 0.0500, F1 Macro: 0.0522, Accuracy: 0.0500\n","Epoch 29, Train Loss: 5.6756, Val Loss: 284.7333, F1 Micro: 0.2667, F1 Macro: 0.1702, Accuracy: 0.2667\n","Epoch 30, Train Loss: 7.6618, Val Loss: 293.9548, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 31, Train Loss: 8.6102, Val Loss: 287.5772, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 32, Train Loss: 7.0024, Val Loss: 279.2270, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 33, Train Loss: 9.4472, Val Loss: 279.8362, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 34, Train Loss: 12.0128, Val Loss: 242.6815, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 35, Train Loss: 8.3096, Val Loss: 243.9947, F1 Micro: 0.0167, F1 Macro: 0.0182, Accuracy: 0.0167\n","Epoch 36, Train Loss: 6.7197, Val Loss: 233.3485, F1 Micro: 0.2167, F1 Macro: 0.1083, Accuracy: 0.2167\n","Epoch 37, Train Loss: 6.5793, Val Loss: 224.1694, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 38, Train Loss: 6.2121, Val Loss: 219.8386, F1 Micro: 0.1667, F1 Macro: 0.1290, Accuracy: 0.1667\n","Epoch 39, Train Loss: 8.5853, Val Loss: 214.8379, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 40, Train Loss: 10.0289, Val Loss: 205.3139, F1 Micro: 0.2500, F1 Macro: 0.1395, Accuracy: 0.2500\n","Epoch 41, Train Loss: 9.4571, Val Loss: 203.7851, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Epoch 42, Train Loss: 6.8766, Val Loss: 190.1399, F1 Micro: 0.0667, F1 Macro: 0.0593, Accuracy: 0.0667\n","Epoch 43, Train Loss: 6.5307, Val Loss: 169.9431, F1 Micro: 0.2000, F1 Macro: 0.1500, Accuracy: 0.2000\n","Epoch 44, Train Loss: 4.5588, Val Loss: 163.0050, F1 Micro: 0.0000, F1 Macro: 0.0000, Accuracy: 0.0000\n","Early stopping triggered\n"]}]},{"cell_type":"code","source":["def plot_metrics(metrics_history):\n","    epochs = range(1, len(metrics_history['train_loss']) + 1)\n","\n","    plt.figure(figsize=(14, 10))\n","\n","    plt.subplot(2, 2, 1)\n","    plt.plot(epochs, metrics_history['train_loss'], label='Train Loss')\n","    plt.plot(epochs, metrics_history['val_loss'], label='Validation Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(2, 2, 2)\n","    plt.plot(epochs, metrics_history['f1_micro'], label='F1 Score (Micro)')\n","    plt.plot(epochs, metrics_history['f1_macro'], label='F1 Score (Macro)')\n","    plt.title('F1 Scores')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('F1 Score')\n","    plt.legend()\n","\n","    plt.subplot(2, 2, 3)\n","    plt.plot(epochs, metrics_history['accuracy'], label='Accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"XuDsvwIcZCxG","executionInfo":{"status":"ok","timestamp":1711487561866,"user_tz":-60,"elapsed":236,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from itertools import product\n","\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_en)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_en[train_val_idx]\n","    test_dataset = dataset_en[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = MLP1(\n","                input_size=dataset_en.num_node_features,\n","                hidden_size=256,\n","                output_size=dataset_en.num_classes\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = MLP1(\n","        input_size=dataset_en.num_node_features,\n","        hidden_size=256,\n","        output_size=dataset_en.num_classes\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'Basic_model_fold_{fold}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"opYRujoqZGIC","executionInfo":{"status":"ok","timestamp":1711489585721,"user_tz":-60,"elapsed":2016642,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"4b18bbb1-abab-4f7d-ceb4-4dfd7af7fcc7"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 60, Train Loss: 11.1851, Val Loss: 11.5204, F1 Micro: 0.1875, F1 Macro: 0.1142, Accuracy: 0.1875\n","Epoch 61, Train Loss: 7.4297, Val Loss: 7.5818, F1 Micro: 0.2396, F1 Macro: 0.1544, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 615.2097, Val Loss: 199.2527, F1 Micro: 0.2188, F1 Macro: 0.1458, Accuracy: 0.2188\n","Epoch 2, Train Loss: 95.9572, Val Loss: 31.0099, F1 Micro: 0.1667, F1 Macro: 0.1186, Accuracy: 0.1667\n","Epoch 3, Train Loss: 21.6182, Val Loss: 13.5147, F1 Micro: 0.1667, F1 Macro: 0.1095, Accuracy: 0.1667\n","Epoch 4, Train Loss: 11.4158, Val Loss: 16.6105, F1 Micro: 0.1250, F1 Macro: 0.0858, Accuracy: 0.1250\n","Epoch 5, Train Loss: 15.7774, Val Loss: 20.5447, F1 Micro: 0.1979, F1 Macro: 0.1423, Accuracy: 0.1979\n","Epoch 6, Train Loss: 10.0722, Val Loss: 8.1791, F1 Micro: 0.2708, F1 Macro: 0.2134, Accuracy: 0.2708\n","Epoch 7, Train Loss: 8.5989, Val Loss: 5.9588, F1 Micro: 0.2396, F1 Macro: 0.1327, Accuracy: 0.2396\n","Epoch 8, Train Loss: 6.9865, Val Loss: 9.8283, F1 Micro: 0.1771, F1 Macro: 0.1321, Accuracy: 0.1771\n","Epoch 9, Train Loss: 6.2324, Val Loss: 6.0097, F1 Micro: 0.2396, F1 Macro: 0.1944, Accuracy: 0.2396\n","Epoch 10, Train Loss: 5.8059, Val Loss: 4.2002, F1 Micro: 0.2292, F1 Macro: 0.1861, Accuracy: 0.2292\n","Epoch 11, Train Loss: 5.0415, Val Loss: 4.2567, F1 Micro: 0.3333, F1 Macro: 0.2811, Accuracy: 0.3333\n","Epoch 12, Train Loss: 4.7805, Val Loss: 3.7586, F1 Micro: 0.2292, F1 Macro: 0.1672, Accuracy: 0.2292\n","Epoch 13, Train Loss: 4.7995, Val Loss: 3.8151, F1 Micro: 0.2812, F1 Macro: 0.2617, Accuracy: 0.2812\n","Epoch 14, Train Loss: 5.0517, Val Loss: 5.6860, F1 Micro: 0.3333, F1 Macro: 0.2790, Accuracy: 0.3333\n","Epoch 15, Train Loss: 5.6812, Val Loss: 5.6618, F1 Micro: 0.2396, F1 Macro: 0.1687, Accuracy: 0.2396\n","Epoch 16, Train Loss: 6.5672, Val Loss: 4.6427, F1 Micro: 0.2396, F1 Macro: 0.2410, Accuracy: 0.2396\n","Epoch 17, Train Loss: 4.9018, Val Loss: 5.9434, F1 Micro: 0.1667, F1 Macro: 0.1162, Accuracy: 0.1667\n","Epoch 18, Train Loss: 5.2911, Val Loss: 4.8523, F1 Micro: 0.2500, F1 Macro: 0.1746, Accuracy: 0.2500\n","Epoch 19, Train Loss: 5.8389, Val Loss: 5.3094, F1 Micro: 0.2812, F1 Macro: 0.2557, Accuracy: 0.2812\n","Epoch 20, Train Loss: 4.1271, Val Loss: 4.2186, F1 Micro: 0.2083, F1 Macro: 0.1806, Accuracy: 0.2083\n","Epoch 21, Train Loss: 4.5106, Val Loss: 6.9770, F1 Micro: 0.1875, F1 Macro: 0.1401, Accuracy: 0.1875\n","Epoch 22, Train Loss: 4.7671, Val Loss: 2.5294, F1 Micro: 0.3125, F1 Macro: 0.2748, Accuracy: 0.3125\n","Epoch 23, Train Loss: 3.6452, Val Loss: 6.6210, F1 Micro: 0.1771, F1 Macro: 0.1626, Accuracy: 0.1771\n","Epoch 24, Train Loss: 5.5046, Val Loss: 4.2519, F1 Micro: 0.1562, F1 Macro: 0.1152, Accuracy: 0.1562\n","Epoch 25, Train Loss: 3.7246, Val Loss: 3.4428, F1 Micro: 0.1667, F1 Macro: 0.1584, Accuracy: 0.1667\n","Epoch 26, Train Loss: 3.6516, Val Loss: 3.7737, F1 Micro: 0.2396, F1 Macro: 0.1909, Accuracy: 0.2396\n","Epoch 27, Train Loss: 4.5262, Val Loss: 3.7098, F1 Micro: 0.1354, F1 Macro: 0.1356, Accuracy: 0.1354\n","Epoch 28, Train Loss: 4.3669, Val Loss: 4.1369, F1 Micro: 0.3229, F1 Macro: 0.2270, Accuracy: 0.3229\n","Epoch 29, Train Loss: 3.0951, Val Loss: 2.0879, F1 Micro: 0.3854, F1 Macro: 0.3074, Accuracy: 0.3854\n","Epoch 30, Train Loss: 2.6919, Val Loss: 2.8147, F1 Micro: 0.2917, F1 Macro: 0.2703, Accuracy: 0.2917\n","Epoch 31, Train Loss: 3.1956, Val Loss: 3.2543, F1 Micro: 0.3438, F1 Macro: 0.2484, Accuracy: 0.3438\n","Epoch 32, Train Loss: 4.7396, Val Loss: 4.7238, F1 Micro: 0.2500, F1 Macro: 0.2099, Accuracy: 0.2500\n","Epoch 33, Train Loss: 3.3397, Val Loss: 2.7406, F1 Micro: 0.2604, F1 Macro: 0.2049, Accuracy: 0.2604\n","Epoch 34, Train Loss: 2.8807, Val Loss: 2.4815, F1 Micro: 0.2292, F1 Macro: 0.1673, Accuracy: 0.2292\n","Epoch 35, Train Loss: 3.2827, Val Loss: 2.6480, F1 Micro: 0.2812, F1 Macro: 0.2522, Accuracy: 0.2812\n","Epoch 36, Train Loss: 2.4358, Val Loss: 3.2311, F1 Micro: 0.2396, F1 Macro: 0.1983, Accuracy: 0.2396\n","Epoch 37, Train Loss: 4.0654, Val Loss: 5.3683, F1 Micro: 0.1562, F1 Macro: 0.1527, Accuracy: 0.1562\n","Epoch 38, Train Loss: 4.8788, Val Loss: 6.8489, F1 Micro: 0.2708, F1 Macro: 0.2019, Accuracy: 0.2708\n","Epoch 39, Train Loss: 4.7947, Val Loss: 4.0765, F1 Micro: 0.2604, F1 Macro: 0.1957, Accuracy: 0.2604\n","Epoch 40, Train Loss: 3.3806, Val Loss: 3.6475, F1 Micro: 0.1562, F1 Macro: 0.1175, Accuracy: 0.1562\n","Epoch 41, Train Loss: 4.1544, Val Loss: 4.8566, F1 Micro: 0.2396, F1 Macro: 0.1693, Accuracy: 0.2396\n","Epoch 42, Train Loss: 3.0840, Val Loss: 2.3449, F1 Micro: 0.3021, F1 Macro: 0.2175, Accuracy: 0.3021\n","Epoch 43, Train Loss: 2.9329, Val Loss: 2.1337, F1 Micro: 0.2917, F1 Macro: 0.2970, Accuracy: 0.2917\n","Epoch 44, Train Loss: 3.0481, Val Loss: 2.5548, F1 Micro: 0.3646, F1 Macro: 0.2981, Accuracy: 0.3646\n","Epoch 45, Train Loss: 2.8870, Val Loss: 3.0098, F1 Micro: 0.2917, F1 Macro: 0.1762, Accuracy: 0.2917\n","Epoch 46, Train Loss: 3.3565, Val Loss: 2.1291, F1 Micro: 0.3750, F1 Macro: 0.3208, Accuracy: 0.3750\n","Epoch 47, Train Loss: 2.4176, Val Loss: 1.7678, F1 Micro: 0.3333, F1 Macro: 0.2635, Accuracy: 0.3333\n","Epoch 48, Train Loss: 2.3176, Val Loss: 1.9561, F1 Micro: 0.2188, F1 Macro: 0.1986, Accuracy: 0.2188\n","Epoch 49, Train Loss: 3.8911, Val Loss: 6.1971, F1 Micro: 0.2292, F1 Macro: 0.0705, Accuracy: 0.2292\n","Epoch 50, Train Loss: 11.8162, Val Loss: 14.5638, F1 Micro: 0.1042, F1 Macro: 0.0683, Accuracy: 0.1042\n","Epoch 51, Train Loss: 23.5125, Val Loss: 48.0869, F1 Micro: 0.1458, F1 Macro: 0.0886, Accuracy: 0.1458\n","Epoch 52, Train Loss: 29.3783, Val Loss: 28.4009, F1 Micro: 0.2292, F1 Macro: 0.0985, Accuracy: 0.2292\n","Epoch 53, Train Loss: 52.5791, Val Loss: 30.5438, F1 Micro: 0.2604, F1 Macro: 0.1292, Accuracy: 0.2604\n","Epoch 54, Train Loss: 67.8119, Val Loss: 32.7249, F1 Micro: 0.1979, F1 Macro: 0.1334, Accuracy: 0.1979\n","Epoch 55, Train Loss: 18.5053, Val Loss: 9.2719, F1 Micro: 0.1250, F1 Macro: 0.0592, Accuracy: 0.1250\n","Epoch 56, Train Loss: 13.3468, Val Loss: 14.1798, F1 Micro: 0.3229, F1 Macro: 0.2354, Accuracy: 0.3229\n","Epoch 57, Train Loss: 35.1680, Val Loss: 28.3148, F1 Micro: 0.2708, F1 Macro: 0.1503, Accuracy: 0.2708\n","Epoch 58, Train Loss: 64.3294, Val Loss: 88.9773, F1 Micro: 0.1875, F1 Macro: 0.1301, Accuracy: 0.1875\n","Epoch 59, Train Loss: 132.2816, Val Loss: 131.7169, F1 Micro: 0.2188, F1 Macro: 0.1344, Accuracy: 0.2188\n","Epoch 60, Train Loss: 262.1042, Val Loss: 454.2336, F1 Micro: 0.1354, F1 Macro: 0.0682, Accuracy: 0.1354\n","Epoch 61, Train Loss: 519.8602, Val Loss: 571.4778, F1 Micro: 0.1875, F1 Macro: 0.1064, Accuracy: 0.1875\n","Epoch 62, Train Loss: 326.5043, Val Loss: 266.8256, F1 Micro: 0.2188, F1 Macro: 0.1185, Accuracy: 0.2188\n","Epoch 63, Train Loss: 172.0545, Val Loss: 104.6678, F1 Micro: 0.1667, F1 Macro: 0.0825, Accuracy: 0.1667\n","Epoch 64, Train Loss: 66.2722, Val Loss: 22.3728, F1 Micro: 0.2292, F1 Macro: 0.1674, Accuracy: 0.2292\n","Epoch 65, Train Loss: 26.9852, Val Loss: 14.3201, F1 Micro: 0.1979, F1 Macro: 0.1314, Accuracy: 0.1979\n","Epoch 66, Train Loss: 12.2745, Val Loss: 7.6991, F1 Micro: 0.2083, F1 Macro: 0.2072, Accuracy: 0.2083\n","Epoch 67, Train Loss: 7.7287, Val Loss: 5.0972, F1 Micro: 0.2083, F1 Macro: 0.1718, Accuracy: 0.2083\n","Epoch 68, Train Loss: 3.4041, Val Loss: 2.9062, F1 Micro: 0.2812, F1 Macro: 0.2170, Accuracy: 0.2812\n","Epoch 69, Train Loss: 2.7378, Val Loss: 1.7893, F1 Micro: 0.2604, F1 Macro: 0.2177, Accuracy: 0.2604\n","Epoch 70, Train Loss: 2.1790, Val Loss: 2.5841, F1 Micro: 0.1667, F1 Macro: 0.1323, Accuracy: 0.1667\n","Epoch 71, Train Loss: 2.3069, Val Loss: 3.2101, F1 Micro: 0.2604, F1 Macro: 0.2485, Accuracy: 0.2604\n","Epoch 72, Train Loss: 2.7067, Val Loss: 3.2156, F1 Micro: 0.3125, F1 Macro: 0.2718, Accuracy: 0.3125\n","Epoch 73, Train Loss: 2.9912, Val Loss: 1.8966, F1 Micro: 0.3333, F1 Macro: 0.2693, Accuracy: 0.3333\n","Epoch 74, Train Loss: 2.4257, Val Loss: 2.2744, F1 Micro: 0.2708, F1 Macro: 0.2335, Accuracy: 0.2708\n","Epoch 75, Train Loss: 2.3647, Val Loss: 2.2202, F1 Micro: 0.3750, F1 Macro: 0.3546, Accuracy: 0.3750\n","Epoch 76, Train Loss: 2.5341, Val Loss: 2.7126, F1 Micro: 0.3333, F1 Macro: 0.3380, Accuracy: 0.3333\n","Epoch 77, Train Loss: 2.1368, Val Loss: 1.8511, F1 Micro: 0.3750, F1 Macro: 0.3602, Accuracy: 0.3750\n","Epoch 78, Train Loss: 2.0706, Val Loss: 2.3657, F1 Micro: 0.3438, F1 Macro: 0.3173, Accuracy: 0.3438\n","Epoch 79, Train Loss: 2.1943, Val Loss: 2.5360, F1 Micro: 0.3125, F1 Macro: 0.2560, Accuracy: 0.3125\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 544.6645, Val Loss: 239.6242, F1 Micro: 0.1979, F1 Macro: 0.1534, Accuracy: 0.1979\n","Epoch 2, Train Loss: 114.0427, Val Loss: 38.3076, F1 Micro: 0.2396, F1 Macro: 0.1831, Accuracy: 0.2396\n","Epoch 3, Train Loss: 32.9358, Val Loss: 23.8331, F1 Micro: 0.2083, F1 Macro: 0.1139, Accuracy: 0.2083\n","Epoch 4, Train Loss: 19.2862, Val Loss: 21.1261, F1 Micro: 0.1979, F1 Macro: 0.1028, Accuracy: 0.1979\n","Epoch 5, Train Loss: 16.8877, Val Loss: 12.3234, F1 Micro: 0.1979, F1 Macro: 0.0560, Accuracy: 0.1979\n","Epoch 6, Train Loss: 12.3665, Val Loss: 10.3226, F1 Micro: 0.1875, F1 Macro: 0.1232, Accuracy: 0.1875\n","Epoch 7, Train Loss: 10.6037, Val Loss: 8.4894, F1 Micro: 0.2917, F1 Macro: 0.1853, Accuracy: 0.2917\n","Epoch 8, Train Loss: 7.6986, Val Loss: 6.8237, F1 Micro: 0.2812, F1 Macro: 0.2615, Accuracy: 0.2812\n","Epoch 9, Train Loss: 6.2186, Val Loss: 6.1018, F1 Micro: 0.3125, F1 Macro: 0.2287, Accuracy: 0.3125\n","Epoch 10, Train Loss: 7.5810, Val Loss: 5.8936, F1 Micro: 0.2604, F1 Macro: 0.1958, Accuracy: 0.2604\n","Epoch 11, Train Loss: 5.0255, Val Loss: 5.5578, F1 Micro: 0.2083, F1 Macro: 0.1840, Accuracy: 0.2083\n","Epoch 12, Train Loss: 4.0598, Val Loss: 5.7487, F1 Micro: 0.2604, F1 Macro: 0.2397, Accuracy: 0.2604\n","Epoch 13, Train Loss: 3.6644, Val Loss: 5.1607, F1 Micro: 0.2917, F1 Macro: 0.2303, Accuracy: 0.2917\n","Epoch 14, Train Loss: 3.9301, Val Loss: 4.4498, F1 Micro: 0.2708, F1 Macro: 0.1997, Accuracy: 0.2708\n","Epoch 15, Train Loss: 3.6260, Val Loss: 6.5296, F1 Micro: 0.2500, F1 Macro: 0.2395, Accuracy: 0.2500\n","Epoch 16, Train Loss: 5.5661, Val Loss: 4.0422, F1 Micro: 0.2500, F1 Macro: 0.1677, Accuracy: 0.2500\n","Epoch 17, Train Loss: 4.9059, Val Loss: 5.4981, F1 Micro: 0.2396, F1 Macro: 0.1914, Accuracy: 0.2396\n","Epoch 18, Train Loss: 4.7147, Val Loss: 4.0894, F1 Micro: 0.2604, F1 Macro: 0.2387, Accuracy: 0.2604\n","Epoch 19, Train Loss: 3.2991, Val Loss: 3.4267, F1 Micro: 0.2708, F1 Macro: 0.2190, Accuracy: 0.2708\n","Epoch 20, Train Loss: 3.5619, Val Loss: 4.6122, F1 Micro: 0.1875, F1 Macro: 0.1482, Accuracy: 0.1875\n","Epoch 21, Train Loss: 6.5979, Val Loss: 5.1332, F1 Micro: 0.2604, F1 Macro: 0.2021, Accuracy: 0.2604\n","Epoch 22, Train Loss: 4.9499, Val Loss: 3.8006, F1 Micro: 0.2604, F1 Macro: 0.2130, Accuracy: 0.2604\n","Epoch 23, Train Loss: 4.4908, Val Loss: 3.0482, F1 Micro: 0.3438, F1 Macro: 0.2602, Accuracy: 0.3438\n","Epoch 24, Train Loss: 3.8278, Val Loss: 3.3400, F1 Micro: 0.3021, F1 Macro: 0.2925, Accuracy: 0.3021\n","Epoch 25, Train Loss: 3.5709, Val Loss: 6.5554, F1 Micro: 0.2396, F1 Macro: 0.1445, Accuracy: 0.2396\n","Epoch 26, Train Loss: 6.2090, Val Loss: 5.0571, F1 Micro: 0.1667, F1 Macro: 0.1296, Accuracy: 0.1667\n","Epoch 27, Train Loss: 4.6777, Val Loss: 5.4731, F1 Micro: 0.2917, F1 Macro: 0.2492, Accuracy: 0.2917\n","Epoch 28, Train Loss: 5.2631, Val Loss: 6.5241, F1 Micro: 0.2396, F1 Macro: 0.2020, Accuracy: 0.2396\n","Epoch 29, Train Loss: 4.5545, Val Loss: 3.0081, F1 Micro: 0.2708, F1 Macro: 0.2250, Accuracy: 0.2708\n","Epoch 30, Train Loss: 3.4541, Val Loss: 2.7920, F1 Micro: 0.2708, F1 Macro: 0.2453, Accuracy: 0.2708\n","Epoch 31, Train Loss: 5.5777, Val Loss: 3.8404, F1 Micro: 0.2604, F1 Macro: 0.2149, Accuracy: 0.2604\n","Epoch 32, Train Loss: 4.1700, Val Loss: 3.9713, F1 Micro: 0.1771, F1 Macro: 0.1497, Accuracy: 0.1771\n","Epoch 33, Train Loss: 3.7904, Val Loss: 3.7771, F1 Micro: 0.3125, F1 Macro: 0.2893, Accuracy: 0.3125\n","Epoch 34, Train Loss: 3.1516, Val Loss: 2.9862, F1 Micro: 0.3021, F1 Macro: 0.2386, Accuracy: 0.3021\n","Epoch 35, Train Loss: 3.3183, Val Loss: 3.4705, F1 Micro: 0.3229, F1 Macro: 0.2969, Accuracy: 0.3229\n","Epoch 36, Train Loss: 3.4247, Val Loss: 2.6267, F1 Micro: 0.2604, F1 Macro: 0.2076, Accuracy: 0.2604\n","Epoch 37, Train Loss: 2.8083, Val Loss: 2.3594, F1 Micro: 0.2708, F1 Macro: 0.2726, Accuracy: 0.2708\n","Epoch 38, Train Loss: 2.7929, Val Loss: 2.5876, F1 Micro: 0.3333, F1 Macro: 0.2788, Accuracy: 0.3333\n","Epoch 39, Train Loss: 3.3398, Val Loss: 2.2027, F1 Micro: 0.3438, F1 Macro: 0.2713, Accuracy: 0.3438\n","Epoch 40, Train Loss: 2.5474, Val Loss: 2.6310, F1 Micro: 0.2396, F1 Macro: 0.2015, Accuracy: 0.2396\n","Epoch 41, Train Loss: 2.7441, Val Loss: 2.6828, F1 Micro: 0.2604, F1 Macro: 0.1946, Accuracy: 0.2604\n","Epoch 42, Train Loss: 2.7042, Val Loss: 2.4883, F1 Micro: 0.2188, F1 Macro: 0.1919, Accuracy: 0.2188\n","Epoch 43, Train Loss: 2.3766, Val Loss: 2.2521, F1 Micro: 0.3646, F1 Macro: 0.3262, Accuracy: 0.3646\n","Epoch 44, Train Loss: 2.7513, Val Loss: 2.9371, F1 Micro: 0.2396, F1 Macro: 0.2197, Accuracy: 0.2396\n","Epoch 45, Train Loss: 3.4724, Val Loss: 4.0656, F1 Micro: 0.2396, F1 Macro: 0.1523, Accuracy: 0.2396\n","Epoch 46, Train Loss: 3.3077, Val Loss: 3.0939, F1 Micro: 0.1667, F1 Macro: 0.1449, Accuracy: 0.1667\n","Epoch 47, Train Loss: 3.1466, Val Loss: 3.3093, F1 Micro: 0.2500, F1 Macro: 0.2417, Accuracy: 0.2500\n","Epoch 48, Train Loss: 2.2751, Val Loss: 2.3589, F1 Micro: 0.2396, F1 Macro: 0.1972, Accuracy: 0.2396\n","Epoch 49, Train Loss: 2.4050, Val Loss: 3.7251, F1 Micro: 0.1562, F1 Macro: 0.1311, Accuracy: 0.1562\n","Epoch 50, Train Loss: 2.3584, Val Loss: 2.6137, F1 Micro: 0.2292, F1 Macro: 0.2131, Accuracy: 0.2292\n","Epoch 51, Train Loss: 2.3554, Val Loss: 2.2265, F1 Micro: 0.1979, F1 Macro: 0.1871, Accuracy: 0.1979\n","Epoch 52, Train Loss: 2.2008, Val Loss: 2.1982, F1 Micro: 0.2292, F1 Macro: 0.1840, Accuracy: 0.2292\n","Epoch 53, Train Loss: 2.5485, Val Loss: 2.7317, F1 Micro: 0.3021, F1 Macro: 0.2187, Accuracy: 0.3021\n","Epoch 54, Train Loss: 2.3133, Val Loss: 2.6689, F1 Micro: 0.2708, F1 Macro: 0.2408, Accuracy: 0.2708\n","Epoch 55, Train Loss: 2.2170, Val Loss: 2.0378, F1 Micro: 0.2708, F1 Macro: 0.2294, Accuracy: 0.2708\n","Epoch 56, Train Loss: 2.3300, Val Loss: 2.1816, F1 Micro: 0.2917, F1 Macro: 0.2162, Accuracy: 0.2917\n","Epoch 57, Train Loss: 2.7125, Val Loss: 3.3725, F1 Micro: 0.1875, F1 Macro: 0.1179, Accuracy: 0.1875\n","Epoch 58, Train Loss: 3.0008, Val Loss: 3.3641, F1 Micro: 0.2812, F1 Macro: 0.1822, Accuracy: 0.2812\n","Epoch 59, Train Loss: 2.5524, Val Loss: 2.5506, F1 Micro: 0.2188, F1 Macro: 0.1828, Accuracy: 0.2188\n","Epoch 60, Train Loss: 3.5018, Val Loss: 3.5177, F1 Micro: 0.3542, F1 Macro: 0.2675, Accuracy: 0.3542\n","Epoch 61, Train Loss: 3.8158, Val Loss: 3.0466, F1 Micro: 0.1875, F1 Macro: 0.1047, Accuracy: 0.1875\n","Epoch 62, Train Loss: 4.8008, Val Loss: 9.2944, F1 Micro: 0.1771, F1 Macro: 0.0738, Accuracy: 0.1771\n","Epoch 63, Train Loss: 25.4918, Val Loss: 82.8307, F1 Micro: 0.1562, F1 Macro: 0.0463, Accuracy: 0.1562\n","Epoch 64, Train Loss: 73.0971, Val Loss: 267.2691, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 65, Train Loss: 249.5162, Val Loss: 354.3694, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 66, Train Loss: 366.3280, Val Loss: 348.8264, F1 Micro: 0.1250, F1 Macro: 0.0785, Accuracy: 0.1250\n","Epoch 67, Train Loss: 331.3266, Val Loss: 164.9664, F1 Micro: 0.1667, F1 Macro: 0.1249, Accuracy: 0.1667\n","Epoch 68, Train Loss: 100.6250, Val Loss: 76.1854, F1 Micro: 0.1875, F1 Macro: 0.0952, Accuracy: 0.1875\n","Epoch 69, Train Loss: 40.4763, Val Loss: 12.4936, F1 Micro: 0.2188, F1 Macro: 0.1915, Accuracy: 0.2188\n","Epoch 70, Train Loss: 17.8329, Val Loss: 11.6916, F1 Micro: 0.2500, F1 Macro: 0.2311, Accuracy: 0.2500\n","Epoch 71, Train Loss: 7.7652, Val Loss: 5.7866, F1 Micro: 0.2604, F1 Macro: 0.1945, Accuracy: 0.2604\n","Epoch 72, Train Loss: 4.7089, Val Loss: 3.6053, F1 Micro: 0.2604, F1 Macro: 0.2623, Accuracy: 0.2604\n","Epoch 73, Train Loss: 3.1597, Val Loss: 3.3787, F1 Micro: 0.2292, F1 Macro: 0.1912, Accuracy: 0.2292\n","Epoch 74, Train Loss: 3.2355, Val Loss: 3.2378, F1 Micro: 0.2917, F1 Macro: 0.2495, Accuracy: 0.2917\n","Epoch 75, Train Loss: 2.6195, Val Loss: 1.8018, F1 Micro: 0.3125, F1 Macro: 0.2930, Accuracy: 0.3125\n","Epoch 76, Train Loss: 2.6235, Val Loss: 1.9742, F1 Micro: 0.3229, F1 Macro: 0.3158, Accuracy: 0.3229\n","Epoch 77, Train Loss: 2.5668, Val Loss: 2.1769, F1 Micro: 0.3438, F1 Macro: 0.2392, Accuracy: 0.3438\n","Epoch 78, Train Loss: 2.8567, Val Loss: 2.8198, F1 Micro: 0.2500, F1 Macro: 0.2171, Accuracy: 0.2500\n","Epoch 79, Train Loss: 2.2159, Val Loss: 2.5861, F1 Micro: 0.2396, F1 Macro: 0.2218, Accuracy: 0.2396\n","Epoch 80, Train Loss: 2.1592, Val Loss: 1.8732, F1 Micro: 0.2812, F1 Macro: 0.2715, Accuracy: 0.2812\n","Epoch 81, Train Loss: 2.5221, Val Loss: 2.4819, F1 Micro: 0.3229, F1 Macro: 0.3019, Accuracy: 0.3229\n","Epoch 82, Train Loss: 2.1662, Val Loss: 1.9801, F1 Micro: 0.3125, F1 Macro: 0.2783, Accuracy: 0.3125\n","Epoch 83, Train Loss: 2.2620, Val Loss: 2.6686, F1 Micro: 0.2500, F1 Macro: 0.1945, Accuracy: 0.2500\n","Epoch 84, Train Loss: 2.4495, Val Loss: 2.8441, F1 Micro: 0.2292, F1 Macro: 0.1809, Accuracy: 0.2292\n","Epoch 85, Train Loss: 2.8102, Val Loss: 2.7683, F1 Micro: 0.2396, F1 Macro: 0.1810, Accuracy: 0.2396\n","Epoch 86, Train Loss: 2.6036, Val Loss: 2.3599, F1 Micro: 0.3646, F1 Macro: 0.2703, Accuracy: 0.3646\n","Epoch 87, Train Loss: 2.2211, Val Loss: 2.0699, F1 Micro: 0.3542, F1 Macro: 0.3009, Accuracy: 0.3542\n","Epoch 88, Train Loss: 2.0280, Val Loss: 2.2726, F1 Micro: 0.2812, F1 Macro: 0.2659, Accuracy: 0.2812\n","Epoch 89, Train Loss: 2.1438, Val Loss: 2.1944, F1 Micro: 0.2396, F1 Macro: 0.2159, Accuracy: 0.2396\n","Epoch 90, Train Loss: 1.9337, Val Loss: 1.9108, F1 Micro: 0.3229, F1 Macro: 0.2902, Accuracy: 0.3229\n","Epoch 91, Train Loss: 1.8828, Val Loss: 1.9802, F1 Micro: 0.2708, F1 Macro: 0.2292, Accuracy: 0.2708\n","Epoch 92, Train Loss: 1.7964, Val Loss: 2.0665, F1 Micro: 0.3438, F1 Macro: 0.2898, Accuracy: 0.3438\n","Epoch 93, Train Loss: 2.0465, Val Loss: 1.7262, F1 Micro: 0.3750, F1 Macro: 0.3518, Accuracy: 0.3750\n","Epoch 94, Train Loss: 1.9066, Val Loss: 2.1863, F1 Micro: 0.2708, F1 Macro: 0.2318, Accuracy: 0.2708\n","Epoch 95, Train Loss: 1.9560, Val Loss: 2.0164, F1 Micro: 0.2812, F1 Macro: 0.2799, Accuracy: 0.2812\n","Epoch 96, Train Loss: 1.9517, Val Loss: 1.9092, F1 Micro: 0.2917, F1 Macro: 0.2908, Accuracy: 0.2917\n","Epoch 97, Train Loss: 1.8099, Val Loss: 2.1580, F1 Micro: 0.2083, F1 Macro: 0.1882, Accuracy: 0.2083\n","Epoch 98, Train Loss: 1.8136, Val Loss: 2.1325, F1 Micro: 0.3021, F1 Macro: 0.2742, Accuracy: 0.3021\n","Epoch 99, Train Loss: 1.9683, Val Loss: 1.9227, F1 Micro: 0.3021, F1 Macro: 0.2473, Accuracy: 0.3021\n","Epoch 100, Train Loss: 1.9882, Val Loss: 2.1026, F1 Micro: 0.3958, F1 Macro: 0.3072, Accuracy: 0.3958\n","Epoch 101, Train Loss: 2.0908, Val Loss: 2.0664, F1 Micro: 0.3542, F1 Macro: 0.3041, Accuracy: 0.3542\n","Epoch 102, Train Loss: 2.1353, Val Loss: 2.0215, F1 Micro: 0.3438, F1 Macro: 0.2964, Accuracy: 0.3438\n","Epoch 103, Train Loss: 2.3746, Val Loss: 1.9922, F1 Micro: 0.2812, F1 Macro: 0.2526, Accuracy: 0.2812\n","Epoch 104, Train Loss: 1.8997, Val Loss: 1.8218, F1 Micro: 0.3646, F1 Macro: 0.2761, Accuracy: 0.3646\n","Epoch 105, Train Loss: 2.0429, Val Loss: 2.2437, F1 Micro: 0.2292, F1 Macro: 0.2075, Accuracy: 0.2292\n","Epoch 106, Train Loss: 2.1076, Val Loss: 1.6761, F1 Micro: 0.4167, F1 Macro: 0.3960, Accuracy: 0.4167\n","Epoch 107, Train Loss: 1.9634, Val Loss: 2.0042, F1 Micro: 0.3750, F1 Macro: 0.3030, Accuracy: 0.3750\n","Epoch 108, Train Loss: 1.8325, Val Loss: 2.4752, F1 Micro: 0.2500, F1 Macro: 0.1904, Accuracy: 0.2500\n","Epoch 109, Train Loss: 2.0537, Val Loss: 1.7775, F1 Micro: 0.3229, F1 Macro: 0.2960, Accuracy: 0.3229\n","Epoch 110, Train Loss: 1.7605, Val Loss: 2.0076, F1 Micro: 0.3021, F1 Macro: 0.2931, Accuracy: 0.3021\n","Epoch 111, Train Loss: 1.8497, Val Loss: 2.0403, F1 Micro: 0.2708, F1 Macro: 0.2666, Accuracy: 0.2708\n","Epoch 112, Train Loss: 1.8973, Val Loss: 1.7721, F1 Micro: 0.3542, F1 Macro: 0.3302, Accuracy: 0.3542\n","Epoch 113, Train Loss: 1.9031, Val Loss: 1.7928, F1 Micro: 0.3542, F1 Macro: 0.3096, Accuracy: 0.3542\n","Epoch 114, Train Loss: 1.7440, Val Loss: 1.8133, F1 Micro: 0.3333, F1 Macro: 0.2927, Accuracy: 0.3333\n","Epoch 115, Train Loss: 1.8016, Val Loss: 2.1601, F1 Micro: 0.2500, F1 Macro: 0.2069, Accuracy: 0.2500\n","Epoch 116, Train Loss: 1.8740, Val Loss: 1.8877, F1 Micro: 0.2500, F1 Macro: 0.2071, Accuracy: 0.2500\n","Epoch 117, Train Loss: 1.7957, Val Loss: 1.5950, F1 Micro: 0.4271, F1 Macro: 0.4050, Accuracy: 0.4271\n","Epoch 118, Train Loss: 1.9204, Val Loss: 2.1301, F1 Micro: 0.3229, F1 Macro: 0.2948, Accuracy: 0.3229\n","Epoch 119, Train Loss: 2.0019, Val Loss: 1.9987, F1 Micro: 0.2500, F1 Macro: 0.2165, Accuracy: 0.2500\n","Epoch 120, Train Loss: 2.1694, Val Loss: 2.1741, F1 Micro: 0.2917, F1 Macro: 0.2990, Accuracy: 0.2917\n","Epoch 121, Train Loss: 1.8453, Val Loss: 1.6615, F1 Micro: 0.3854, F1 Macro: 0.3847, Accuracy: 0.3854\n","Epoch 122, Train Loss: 1.6766, Val Loss: 2.1488, F1 Micro: 0.3333, F1 Macro: 0.2948, Accuracy: 0.3333\n","Epoch 123, Train Loss: 1.9326, Val Loss: 2.1100, F1 Micro: 0.3438, F1 Macro: 0.3242, Accuracy: 0.3438\n","Epoch 124, Train Loss: 1.8978, Val Loss: 2.4885, F1 Micro: 0.1771, F1 Macro: 0.1089, Accuracy: 0.1771\n","Epoch 125, Train Loss: 2.4063, Val Loss: 1.9774, F1 Micro: 0.2708, F1 Macro: 0.2141, Accuracy: 0.2708\n","Epoch 126, Train Loss: 2.2122, Val Loss: 1.8835, F1 Micro: 0.2917, F1 Macro: 0.2888, Accuracy: 0.2917\n","Epoch 127, Train Loss: 2.1366, Val Loss: 1.7089, F1 Micro: 0.3646, F1 Macro: 0.3462, Accuracy: 0.3646\n","Epoch 128, Train Loss: 1.8528, Val Loss: 1.5750, F1 Micro: 0.3958, F1 Macro: 0.3863, Accuracy: 0.3958\n","Epoch 129, Train Loss: 1.7823, Val Loss: 2.0085, F1 Micro: 0.3125, F1 Macro: 0.2621, Accuracy: 0.3125\n","Epoch 130, Train Loss: 2.0389, Val Loss: 1.8648, F1 Micro: 0.3125, F1 Macro: 0.2503, Accuracy: 0.3125\n","Epoch 131, Train Loss: 1.8790, Val Loss: 2.1915, F1 Micro: 0.3021, F1 Macro: 0.2404, Accuracy: 0.3021\n","Epoch 132, Train Loss: 2.2529, Val Loss: 2.0152, F1 Micro: 0.3229, F1 Macro: 0.2624, Accuracy: 0.3229\n","Epoch 133, Train Loss: 3.1057, Val Loss: 4.0698, F1 Micro: 0.2083, F1 Macro: 0.1532, Accuracy: 0.2083\n","Epoch 134, Train Loss: 2.6080, Val Loss: 3.2759, F1 Micro: 0.3021, F1 Macro: 0.2032, Accuracy: 0.3021\n","Epoch 135, Train Loss: 2.5321, Val Loss: 2.0050, F1 Micro: 0.3229, F1 Macro: 0.2496, Accuracy: 0.3229\n","Epoch 136, Train Loss: 2.1633, Val Loss: 2.7060, F1 Micro: 0.2500, F1 Macro: 0.1660, Accuracy: 0.2500\n","Epoch 137, Train Loss: 3.0530, Val Loss: 2.8611, F1 Micro: 0.2396, F1 Macro: 0.1554, Accuracy: 0.2396\n","Epoch 138, Train Loss: 2.7131, Val Loss: 1.9640, F1 Micro: 0.3333, F1 Macro: 0.2768, Accuracy: 0.3333\n","Epoch 139, Train Loss: 2.0874, Val Loss: 2.2160, F1 Micro: 0.3125, F1 Macro: 0.2880, Accuracy: 0.3125\n","Epoch 140, Train Loss: 2.3434, Val Loss: 4.7574, F1 Micro: 0.1458, F1 Macro: 0.1224, Accuracy: 0.1458\n","Epoch 141, Train Loss: 4.1122, Val Loss: 2.3021, F1 Micro: 0.3646, F1 Macro: 0.3018, Accuracy: 0.3646\n","Epoch 142, Train Loss: 2.7205, Val Loss: 2.8233, F1 Micro: 0.2604, F1 Macro: 0.1505, Accuracy: 0.2604\n","Epoch 143, Train Loss: 2.4998, Val Loss: 2.4295, F1 Micro: 0.3333, F1 Macro: 0.2348, Accuracy: 0.3333\n","Epoch 144, Train Loss: 2.9140, Val Loss: 6.2733, F1 Micro: 0.1146, F1 Macro: 0.0820, Accuracy: 0.1146\n","Epoch 145, Train Loss: 4.0214, Val Loss: 5.9099, F1 Micro: 0.2292, F1 Macro: 0.1623, Accuracy: 0.2292\n","Epoch 146, Train Loss: 4.9302, Val Loss: 6.5767, F1 Micro: 0.1875, F1 Macro: 0.1402, Accuracy: 0.1875\n","Epoch 147, Train Loss: 23.7290, Val Loss: 30.9341, F1 Micro: 0.1979, F1 Macro: 0.1213, Accuracy: 0.1979\n","Epoch 148, Train Loss: 105.5973, Val Loss: 168.1294, F1 Micro: 0.1875, F1 Macro: 0.0880, Accuracy: 0.1875\n","Epoch 149, Train Loss: 157.6048, Val Loss: 463.9955, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 150, Train Loss: 440.8895, Val Loss: 937.6250, F1 Micro: 0.1979, F1 Macro: 0.0955, Accuracy: 0.1979\n","Epoch 151, Train Loss: 496.1106, Val Loss: 382.0180, F1 Micro: 0.2083, F1 Macro: 0.0580, Accuracy: 0.2083\n","Epoch 152, Train Loss: 379.5206, Val Loss: 199.7241, F1 Micro: 0.1354, F1 Macro: 0.0724, Accuracy: 0.1354\n","Epoch 153, Train Loss: 228.6379, Val Loss: 63.6650, F1 Micro: 0.1875, F1 Macro: 0.1234, Accuracy: 0.1875\n","Epoch 154, Train Loss: 108.0254, Val Loss: 60.8084, F1 Micro: 0.2396, F1 Macro: 0.1745, Accuracy: 0.2396\n","Epoch 155, Train Loss: 59.2678, Val Loss: 72.7943, F1 Micro: 0.2708, F1 Macro: 0.1712, Accuracy: 0.2708\n","Epoch 156, Train Loss: 35.2748, Val Loss: 59.9885, F1 Micro: 0.2396, F1 Macro: 0.1523, Accuracy: 0.2396\n","Epoch 157, Train Loss: 32.1534, Val Loss: 11.6888, F1 Micro: 0.3125, F1 Macro: 0.2473, Accuracy: 0.3125\n","Epoch 158, Train Loss: 10.5544, Val Loss: 5.1125, F1 Micro: 0.2500, F1 Macro: 0.1727, Accuracy: 0.2500\n","Epoch 159, Train Loss: 6.8539, Val Loss: 4.1552, F1 Micro: 0.3333, F1 Macro: 0.2464, Accuracy: 0.3333\n","Epoch 160, Train Loss: 3.7546, Val Loss: 3.2859, F1 Micro: 0.2917, F1 Macro: 0.2850, Accuracy: 0.2917\n","Epoch 161, Train Loss: 3.4213, Val Loss: 2.5291, F1 Micro: 0.3646, F1 Macro: 0.2639, Accuracy: 0.3646\n","Epoch 162, Train Loss: 2.9576, Val Loss: 2.4296, F1 Micro: 0.2812, F1 Macro: 0.2616, Accuracy: 0.2812\n","Epoch 163, Train Loss: 2.4474, Val Loss: 3.6517, F1 Micro: 0.2396, F1 Macro: 0.2206, Accuracy: 0.2396\n","Epoch 164, Train Loss: 2.9029, Val Loss: 3.4547, F1 Micro: 0.3333, F1 Macro: 0.2318, Accuracy: 0.3333\n","Epoch 165, Train Loss: 2.7024, Val Loss: 2.3897, F1 Micro: 0.3542, F1 Macro: 0.2889, Accuracy: 0.3542\n","Epoch 166, Train Loss: 2.2788, Val Loss: 3.4979, F1 Micro: 0.2708, F1 Macro: 0.2405, Accuracy: 0.2708\n","Epoch 167, Train Loss: 2.3157, Val Loss: 1.7327, F1 Micro: 0.3646, F1 Macro: 0.3472, Accuracy: 0.3646\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 524.2696, Val Loss: 297.2020, F1 Micro: 0.1979, F1 Macro: 0.1141, Accuracy: 0.1979\n","Epoch 2, Train Loss: 107.0271, Val Loss: 47.1531, F1 Micro: 0.2500, F1 Macro: 0.1948, Accuracy: 0.2500\n","Epoch 3, Train Loss: 41.9621, Val Loss: 41.1662, F1 Micro: 0.1458, F1 Macro: 0.0747, Accuracy: 0.1458\n","Epoch 4, Train Loss: 22.9488, Val Loss: 16.3134, F1 Micro: 0.2188, F1 Macro: 0.1524, Accuracy: 0.2188\n","Epoch 5, Train Loss: 14.5592, Val Loss: 13.9387, F1 Micro: 0.2396, F1 Macro: 0.1329, Accuracy: 0.2396\n","Epoch 6, Train Loss: 19.4934, Val Loss: 12.8420, F1 Micro: 0.2604, F1 Macro: 0.1849, Accuracy: 0.2604\n","Epoch 7, Train Loss: 8.0225, Val Loss: 9.4701, F1 Micro: 0.2083, F1 Macro: 0.1714, Accuracy: 0.2083\n","Epoch 8, Train Loss: 5.5104, Val Loss: 4.8496, F1 Micro: 0.3021, F1 Macro: 0.2822, Accuracy: 0.3021\n","Epoch 9, Train Loss: 4.6177, Val Loss: 7.4668, F1 Micro: 0.2083, F1 Macro: 0.1659, Accuracy: 0.2083\n","Epoch 10, Train Loss: 5.2140, Val Loss: 5.9573, F1 Micro: 0.2708, F1 Macro: 0.2081, Accuracy: 0.2708\n","Epoch 11, Train Loss: 6.1808, Val Loss: 5.4875, F1 Micro: 0.1979, F1 Macro: 0.1352, Accuracy: 0.1979\n","Epoch 12, Train Loss: 5.8889, Val Loss: 4.7868, F1 Micro: 0.2708, F1 Macro: 0.1987, Accuracy: 0.2708\n","Epoch 13, Train Loss: 5.0858, Val Loss: 8.8407, F1 Micro: 0.2292, F1 Macro: 0.1852, Accuracy: 0.2292\n","Epoch 14, Train Loss: 6.9786, Val Loss: 4.6673, F1 Micro: 0.2500, F1 Macro: 0.1997, Accuracy: 0.2500\n","Epoch 15, Train Loss: 5.0950, Val Loss: 5.3921, F1 Micro: 0.2396, F1 Macro: 0.1784, Accuracy: 0.2396\n","Epoch 16, Train Loss: 6.0645, Val Loss: 5.8020, F1 Micro: 0.2604, F1 Macro: 0.1979, Accuracy: 0.2604\n","Epoch 17, Train Loss: 3.5994, Val Loss: 3.7765, F1 Micro: 0.1979, F1 Macro: 0.1420, Accuracy: 0.1979\n","Epoch 18, Train Loss: 3.5076, Val Loss: 4.2411, F1 Micro: 0.2292, F1 Macro: 0.1767, Accuracy: 0.2292\n","Epoch 19, Train Loss: 3.9021, Val Loss: 3.8126, F1 Micro: 0.2917, F1 Macro: 0.2198, Accuracy: 0.2917\n","Epoch 20, Train Loss: 3.6684, Val Loss: 3.4596, F1 Micro: 0.2708, F1 Macro: 0.2794, Accuracy: 0.2708\n","Epoch 21, Train Loss: 4.4852, Val Loss: 8.1656, F1 Micro: 0.1875, F1 Macro: 0.1288, Accuracy: 0.1875\n","Epoch 22, Train Loss: 8.4415, Val Loss: 7.7648, F1 Micro: 0.2083, F1 Macro: 0.1316, Accuracy: 0.2083\n","Epoch 23, Train Loss: 7.7915, Val Loss: 7.1092, F1 Micro: 0.2292, F1 Macro: 0.1649, Accuracy: 0.2292\n","Epoch 24, Train Loss: 5.1919, Val Loss: 3.9920, F1 Micro: 0.2708, F1 Macro: 0.2246, Accuracy: 0.2708\n","Epoch 25, Train Loss: 3.6649, Val Loss: 5.1710, F1 Micro: 0.1771, F1 Macro: 0.1210, Accuracy: 0.1771\n","Epoch 26, Train Loss: 3.8622, Val Loss: 4.6674, F1 Micro: 0.1979, F1 Macro: 0.1507, Accuracy: 0.1979\n","Epoch 27, Train Loss: 3.9660, Val Loss: 4.2411, F1 Micro: 0.2604, F1 Macro: 0.1981, Accuracy: 0.2604\n","Epoch 28, Train Loss: 3.3388, Val Loss: 5.5951, F1 Micro: 0.2708, F1 Macro: 0.2285, Accuracy: 0.2708\n","Epoch 29, Train Loss: 4.7074, Val Loss: 5.6576, F1 Micro: 0.1667, F1 Macro: 0.1491, Accuracy: 0.1667\n","Epoch 30, Train Loss: 5.8934, Val Loss: 5.7332, F1 Micro: 0.2500, F1 Macro: 0.2229, Accuracy: 0.2500\n","Epoch 31, Train Loss: 4.5679, Val Loss: 7.4666, F1 Micro: 0.2188, F1 Macro: 0.1214, Accuracy: 0.2188\n","Epoch 32, Train Loss: 4.0407, Val Loss: 3.8411, F1 Micro: 0.1979, F1 Macro: 0.1529, Accuracy: 0.1979\n","Epoch 33, Train Loss: 3.9238, Val Loss: 3.8029, F1 Micro: 0.2396, F1 Macro: 0.2150, Accuracy: 0.2396\n","Epoch 34, Train Loss: 5.2749, Val Loss: 7.6964, F1 Micro: 0.2188, F1 Macro: 0.1182, Accuracy: 0.2188\n","Epoch 35, Train Loss: 4.7413, Val Loss: 6.9849, F1 Micro: 0.1979, F1 Macro: 0.0878, Accuracy: 0.1979\n","Epoch 36, Train Loss: 4.6811, Val Loss: 4.1163, F1 Micro: 0.2083, F1 Macro: 0.1621, Accuracy: 0.2083\n","Epoch 37, Train Loss: 5.2232, Val Loss: 3.3428, F1 Micro: 0.2083, F1 Macro: 0.1555, Accuracy: 0.2083\n","Epoch 38, Train Loss: 3.0350, Val Loss: 3.1909, F1 Micro: 0.2708, F1 Macro: 0.2196, Accuracy: 0.2708\n","Epoch 39, Train Loss: 2.2943, Val Loss: 2.3803, F1 Micro: 0.3229, F1 Macro: 0.3176, Accuracy: 0.3229\n","Epoch 40, Train Loss: 2.3164, Val Loss: 2.2717, F1 Micro: 0.3125, F1 Macro: 0.2449, Accuracy: 0.3125\n","Epoch 41, Train Loss: 2.8548, Val Loss: 2.7789, F1 Micro: 0.2708, F1 Macro: 0.2222, Accuracy: 0.2708\n","Epoch 42, Train Loss: 3.5166, Val Loss: 3.5963, F1 Micro: 0.1667, F1 Macro: 0.0963, Accuracy: 0.1667\n","Epoch 43, Train Loss: 2.7803, Val Loss: 2.3810, F1 Micro: 0.3333, F1 Macro: 0.2917, Accuracy: 0.3333\n","Epoch 44, Train Loss: 2.6355, Val Loss: 2.1547, F1 Micro: 0.2500, F1 Macro: 0.2174, Accuracy: 0.2500\n","Epoch 45, Train Loss: 2.3707, Val Loss: 2.4509, F1 Micro: 0.2708, F1 Macro: 0.2261, Accuracy: 0.2708\n","Epoch 46, Train Loss: 2.3164, Val Loss: 2.9152, F1 Micro: 0.2812, F1 Macro: 0.2784, Accuracy: 0.2812\n","Epoch 47, Train Loss: 2.3137, Val Loss: 2.0935, F1 Micro: 0.3229, F1 Macro: 0.2650, Accuracy: 0.3229\n","Epoch 48, Train Loss: 2.0558, Val Loss: 2.4948, F1 Micro: 0.2708, F1 Macro: 0.2580, Accuracy: 0.2708\n","Epoch 49, Train Loss: 2.0434, Val Loss: 1.9555, F1 Micro: 0.2917, F1 Macro: 0.2491, Accuracy: 0.2917\n","Epoch 50, Train Loss: 1.8673, Val Loss: 2.1797, F1 Micro: 0.2500, F1 Macro: 0.2119, Accuracy: 0.2500\n","Epoch 51, Train Loss: 2.8007, Val Loss: 2.6710, F1 Micro: 0.3021, F1 Macro: 0.2738, Accuracy: 0.3021\n","Epoch 52, Train Loss: 2.3761, Val Loss: 2.8499, F1 Micro: 0.2917, F1 Macro: 0.2308, Accuracy: 0.2917\n","Epoch 53, Train Loss: 3.2894, Val Loss: 2.4985, F1 Micro: 0.2396, F1 Macro: 0.1818, Accuracy: 0.2396\n","Epoch 54, Train Loss: 3.7579, Val Loss: 3.6921, F1 Micro: 0.3125, F1 Macro: 0.2263, Accuracy: 0.3125\n","Epoch 55, Train Loss: 3.1418, Val Loss: 2.1918, F1 Micro: 0.3125, F1 Macro: 0.2652, Accuracy: 0.3125\n","Epoch 56, Train Loss: 3.0930, Val Loss: 4.7408, F1 Micro: 0.1875, F1 Macro: 0.1182, Accuracy: 0.1875\n","Epoch 57, Train Loss: 2.7037, Val Loss: 2.0788, F1 Micro: 0.2917, F1 Macro: 0.2598, Accuracy: 0.2917\n","Epoch 58, Train Loss: 1.9956, Val Loss: 1.8899, F1 Micro: 0.3125, F1 Macro: 0.2930, Accuracy: 0.3125\n","Epoch 59, Train Loss: 2.0564, Val Loss: 2.5909, F1 Micro: 0.2083, F1 Macro: 0.1272, Accuracy: 0.2083\n","Epoch 60, Train Loss: 3.5528, Val Loss: 5.8698, F1 Micro: 0.2083, F1 Macro: 0.1216, Accuracy: 0.2083\n","Epoch 61, Train Loss: 4.6800, Val Loss: 3.0414, F1 Micro: 0.3021, F1 Macro: 0.2577, Accuracy: 0.3021\n","Epoch 62, Train Loss: 5.7144, Val Loss: 4.5259, F1 Micro: 0.2708, F1 Macro: 0.2262, Accuracy: 0.2708\n","Epoch 63, Train Loss: 8.8760, Val Loss: 8.7970, F1 Micro: 0.1562, F1 Macro: 0.1051, Accuracy: 0.1562\n","Epoch 64, Train Loss: 26.9618, Val Loss: 35.8404, F1 Micro: 0.1667, F1 Macro: 0.0498, Accuracy: 0.1667\n","Epoch 65, Train Loss: 46.6107, Val Loss: 44.0117, F1 Micro: 0.1458, F1 Macro: 0.0440, Accuracy: 0.1458\n","Epoch 66, Train Loss: 91.7103, Val Loss: 104.6870, F1 Micro: 0.1667, F1 Macro: 0.0811, Accuracy: 0.1667\n","Epoch 67, Train Loss: 95.1260, Val Loss: 74.4349, F1 Micro: 0.2604, F1 Macro: 0.1601, Accuracy: 0.2604\n","Epoch 68, Train Loss: 67.3193, Val Loss: 64.4077, F1 Micro: 0.1979, F1 Macro: 0.1185, Accuracy: 0.1979\n","Epoch 69, Train Loss: 77.1612, Val Loss: 72.7018, F1 Micro: 0.1875, F1 Macro: 0.0951, Accuracy: 0.1875\n","Epoch 70, Train Loss: 54.6414, Val Loss: 110.5678, F1 Micro: 0.1771, F1 Macro: 0.0656, Accuracy: 0.1771\n","Epoch 71, Train Loss: 53.7999, Val Loss: 41.5785, F1 Micro: 0.1875, F1 Macro: 0.0864, Accuracy: 0.1875\n","Epoch 72, Train Loss: 46.0616, Val Loss: 19.0323, F1 Micro: 0.1771, F1 Macro: 0.1077, Accuracy: 0.1771\n","Epoch 73, Train Loss: 32.1204, Val Loss: 35.4573, F1 Micro: 0.1771, F1 Macro: 0.1102, Accuracy: 0.1771\n","Epoch 74, Train Loss: 22.8899, Val Loss: 13.5229, F1 Micro: 0.2604, F1 Macro: 0.1565, Accuracy: 0.2604\n","Epoch 75, Train Loss: 11.7459, Val Loss: 11.9620, F1 Micro: 0.2708, F1 Macro: 0.1937, Accuracy: 0.2708\n","Epoch 76, Train Loss: 6.4215, Val Loss: 4.4366, F1 Micro: 0.2083, F1 Macro: 0.1621, Accuracy: 0.2083\n","Epoch 77, Train Loss: 3.1708, Val Loss: 3.4320, F1 Micro: 0.2188, F1 Macro: 0.1592, Accuracy: 0.2188\n","Epoch 78, Train Loss: 2.5767, Val Loss: 2.7309, F1 Micro: 0.1979, F1 Macro: 0.1786, Accuracy: 0.1979\n","Epoch 79, Train Loss: 2.8009, Val Loss: 3.0628, F1 Micro: 0.1875, F1 Macro: 0.1261, Accuracy: 0.1875\n","Epoch 80, Train Loss: 2.2741, Val Loss: 2.0860, F1 Micro: 0.3125, F1 Macro: 0.3013, Accuracy: 0.3125\n","Epoch 81, Train Loss: 1.8811, Val Loss: 1.9943, F1 Micro: 0.3125, F1 Macro: 0.3019, Accuracy: 0.3125\n","Epoch 82, Train Loss: 1.8165, Val Loss: 2.3228, F1 Micro: 0.2292, F1 Macro: 0.2224, Accuracy: 0.2292\n","Epoch 83, Train Loss: 1.7270, Val Loss: 1.9096, F1 Micro: 0.3333, F1 Macro: 0.3297, Accuracy: 0.3333\n","Epoch 84, Train Loss: 1.7916, Val Loss: 1.9941, F1 Micro: 0.3438, F1 Macro: 0.3513, Accuracy: 0.3438\n","Epoch 85, Train Loss: 1.9855, Val Loss: 2.4555, F1 Micro: 0.2917, F1 Macro: 0.2193, Accuracy: 0.2917\n","Epoch 86, Train Loss: 2.0115, Val Loss: 2.0805, F1 Micro: 0.2917, F1 Macro: 0.2679, Accuracy: 0.2917\n","Epoch 87, Train Loss: 2.1582, Val Loss: 2.0668, F1 Micro: 0.3333, F1 Macro: 0.2605, Accuracy: 0.3333\n","Epoch 88, Train Loss: 2.0394, Val Loss: 2.2526, F1 Micro: 0.3021, F1 Macro: 0.2634, Accuracy: 0.3021\n","Epoch 89, Train Loss: 1.9836, Val Loss: 2.0682, F1 Micro: 0.3542, F1 Macro: 0.3002, Accuracy: 0.3542\n","Epoch 90, Train Loss: 1.9747, Val Loss: 2.5199, F1 Micro: 0.3021, F1 Macro: 0.2652, Accuracy: 0.3021\n","Epoch 91, Train Loss: 2.2113, Val Loss: 2.4596, F1 Micro: 0.3021, F1 Macro: 0.2332, Accuracy: 0.3021\n","Epoch 92, Train Loss: 1.9297, Val Loss: 2.2037, F1 Micro: 0.3021, F1 Macro: 0.2462, Accuracy: 0.3021\n","Epoch 93, Train Loss: 1.9994, Val Loss: 2.4281, F1 Micro: 0.3646, F1 Macro: 0.3203, Accuracy: 0.3646\n","Epoch 94, Train Loss: 2.5053, Val Loss: 3.0312, F1 Micro: 0.2708, F1 Macro: 0.2099, Accuracy: 0.2708\n","Epoch 95, Train Loss: 2.2164, Val Loss: 2.7090, F1 Micro: 0.2917, F1 Macro: 0.2152, Accuracy: 0.2917\n","Epoch 96, Train Loss: 2.1491, Val Loss: 2.7982, F1 Micro: 0.3229, F1 Macro: 0.2595, Accuracy: 0.3229\n","Epoch 97, Train Loss: 2.2938, Val Loss: 2.5180, F1 Micro: 0.2188, F1 Macro: 0.1773, Accuracy: 0.2188\n","Epoch 98, Train Loss: 1.8074, Val Loss: 1.7736, F1 Micro: 0.3750, F1 Macro: 0.3634, Accuracy: 0.3750\n","Epoch 99, Train Loss: 1.8661, Val Loss: 2.1665, F1 Micro: 0.3333, F1 Macro: 0.3309, Accuracy: 0.3333\n","Epoch 100, Train Loss: 1.8172, Val Loss: 2.1434, F1 Micro: 0.3021, F1 Macro: 0.2655, Accuracy: 0.3021\n","Epoch 101, Train Loss: 1.7966, Val Loss: 1.9584, F1 Micro: 0.2917, F1 Macro: 0.2848, Accuracy: 0.2917\n","Epoch 102, Train Loss: 1.8891, Val Loss: 2.3761, F1 Micro: 0.2604, F1 Macro: 0.2500, Accuracy: 0.2604\n","Epoch 103, Train Loss: 1.9433, Val Loss: 2.0957, F1 Micro: 0.3333, F1 Macro: 0.2957, Accuracy: 0.3333\n","Epoch 104, Train Loss: 2.0318, Val Loss: 2.1555, F1 Micro: 0.2917, F1 Macro: 0.2490, Accuracy: 0.2917\n","Epoch 105, Train Loss: 2.1460, Val Loss: 2.4754, F1 Micro: 0.3021, F1 Macro: 0.2842, Accuracy: 0.3021\n","Epoch 106, Train Loss: 2.3045, Val Loss: 2.5258, F1 Micro: 0.2396, F1 Macro: 0.1864, Accuracy: 0.2396\n","Epoch 107, Train Loss: 2.4655, Val Loss: 2.2058, F1 Micro: 0.2917, F1 Macro: 0.2695, Accuracy: 0.2917\n","Epoch 108, Train Loss: 2.1679, Val Loss: 2.5789, F1 Micro: 0.3229, F1 Macro: 0.2651, Accuracy: 0.3229\n","Epoch 109, Train Loss: 2.3896, Val Loss: 1.9663, F1 Micro: 0.2917, F1 Macro: 0.2579, Accuracy: 0.2917\n","Epoch 110, Train Loss: 2.4979, Val Loss: 2.7996, F1 Micro: 0.2396, F1 Macro: 0.1840, Accuracy: 0.2396\n","Epoch 111, Train Loss: 2.0775, Val Loss: 2.5187, F1 Micro: 0.3125, F1 Macro: 0.2335, Accuracy: 0.3125\n","Epoch 112, Train Loss: 2.6177, Val Loss: 2.0599, F1 Micro: 0.3646, F1 Macro: 0.3620, Accuracy: 0.3646\n","Epoch 113, Train Loss: 2.1550, Val Loss: 2.5916, F1 Micro: 0.2292, F1 Macro: 0.1909, Accuracy: 0.2292\n","Epoch 114, Train Loss: 2.2818, Val Loss: 2.1208, F1 Micro: 0.2917, F1 Macro: 0.2405, Accuracy: 0.2917\n","Epoch 115, Train Loss: 2.6869, Val Loss: 2.9980, F1 Micro: 0.3125, F1 Macro: 0.2698, Accuracy: 0.3125\n","Epoch 116, Train Loss: 3.2038, Val Loss: 6.0941, F1 Micro: 0.1771, F1 Macro: 0.1114, Accuracy: 0.1771\n","Epoch 117, Train Loss: 3.3729, Val Loss: 2.7697, F1 Micro: 0.2708, F1 Macro: 0.2295, Accuracy: 0.2708\n","Epoch 118, Train Loss: 3.4911, Val Loss: 9.2222, F1 Micro: 0.1771, F1 Macro: 0.1237, Accuracy: 0.1771\n","Epoch 119, Train Loss: 4.8791, Val Loss: 4.0817, F1 Micro: 0.1771, F1 Macro: 0.1097, Accuracy: 0.1771\n","Epoch 120, Train Loss: 4.0932, Val Loss: 5.5174, F1 Micro: 0.2188, F1 Macro: 0.1384, Accuracy: 0.2188\n","Epoch 121, Train Loss: 14.8100, Val Loss: 72.9349, F1 Micro: 0.2083, F1 Macro: 0.0933, Accuracy: 0.2083\n","Epoch 122, Train Loss: 67.4898, Val Loss: 78.9387, F1 Micro: 0.1875, F1 Macro: 0.0719, Accuracy: 0.1875\n","Epoch 123, Train Loss: 230.0228, Val Loss: 251.9152, F1 Micro: 0.2083, F1 Macro: 0.1421, Accuracy: 0.2083\n","Epoch 124, Train Loss: 251.7429, Val Loss: 111.6543, F1 Micro: 0.2083, F1 Macro: 0.1101, Accuracy: 0.2083\n","Epoch 125, Train Loss: 180.4874, Val Loss: 186.2233, F1 Micro: 0.1875, F1 Macro: 0.0970, Accuracy: 0.1875\n","Epoch 126, Train Loss: 110.3904, Val Loss: 73.7573, F1 Micro: 0.1875, F1 Macro: 0.0878, Accuracy: 0.1875\n","Epoch 127, Train Loss: 55.4932, Val Loss: 123.6981, F1 Micro: 0.1875, F1 Macro: 0.0947, Accuracy: 0.1875\n","Epoch 128, Train Loss: 52.8410, Val Loss: 27.6223, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 129, Train Loss: 15.1259, Val Loss: 10.5778, F1 Micro: 0.3125, F1 Macro: 0.2141, Accuracy: 0.3125\n","Epoch 130, Train Loss: 9.3878, Val Loss: 4.3236, F1 Micro: 0.3021, F1 Macro: 0.2805, Accuracy: 0.3021\n","Epoch 131, Train Loss: 7.1551, Val Loss: 4.9485, F1 Micro: 0.2500, F1 Macro: 0.1878, Accuracy: 0.2500\n","Epoch 132, Train Loss: 3.9416, Val Loss: 4.4945, F1 Micro: 0.2292, F1 Macro: 0.1541, Accuracy: 0.2292\n","Epoch 133, Train Loss: 3.5838, Val Loss: 5.0189, F1 Micro: 0.1458, F1 Macro: 0.0987, Accuracy: 0.1458\n","Epoch 134, Train Loss: 4.1614, Val Loss: 4.0755, F1 Micro: 0.2083, F1 Macro: 0.1859, Accuracy: 0.2083\n","Epoch 135, Train Loss: 3.1374, Val Loss: 2.9318, F1 Micro: 0.2188, F1 Macro: 0.1591, Accuracy: 0.2188\n","Epoch 136, Train Loss: 2.7461, Val Loss: 2.9644, F1 Micro: 0.3021, F1 Macro: 0.2473, Accuracy: 0.3021\n","Epoch 137, Train Loss: 2.1930, Val Loss: 2.3744, F1 Micro: 0.2708, F1 Macro: 0.2227, Accuracy: 0.2708\n","Epoch 138, Train Loss: 1.9613, Val Loss: 2.0170, F1 Micro: 0.3438, F1 Macro: 0.3208, Accuracy: 0.3438\n","Epoch 139, Train Loss: 1.9004, Val Loss: 2.1127, F1 Micro: 0.3333, F1 Macro: 0.2813, Accuracy: 0.3333\n","Epoch 140, Train Loss: 1.8193, Val Loss: 2.1846, F1 Micro: 0.3229, F1 Macro: 0.2847, Accuracy: 0.3229\n","Epoch 141, Train Loss: 2.0409, Val Loss: 2.2205, F1 Micro: 0.3854, F1 Macro: 0.3614, Accuracy: 0.3854\n","Epoch 142, Train Loss: 2.1792, Val Loss: 1.9529, F1 Micro: 0.3438, F1 Macro: 0.2799, Accuracy: 0.3438\n","Epoch 143, Train Loss: 2.1107, Val Loss: 2.2119, F1 Micro: 0.2708, F1 Macro: 0.2446, Accuracy: 0.2708\n","Epoch 144, Train Loss: 2.2214, Val Loss: 2.2428, F1 Micro: 0.3021, F1 Macro: 0.2945, Accuracy: 0.3021\n","Epoch 145, Train Loss: 1.9018, Val Loss: 1.9940, F1 Micro: 0.3438, F1 Macro: 0.3192, Accuracy: 0.3438\n","Epoch 146, Train Loss: 1.8191, Val Loss: 2.0730, F1 Micro: 0.2812, F1 Macro: 0.2567, Accuracy: 0.2812\n","Epoch 147, Train Loss: 1.8653, Val Loss: 2.1361, F1 Micro: 0.3542, F1 Macro: 0.2869, Accuracy: 0.3542\n","Epoch 148, Train Loss: 1.8535, Val Loss: 2.1716, F1 Micro: 0.3229, F1 Macro: 0.2948, Accuracy: 0.3229\n","Epoch 149, Train Loss: 1.9275, Val Loss: 2.0126, F1 Micro: 0.2708, F1 Macro: 0.2653, Accuracy: 0.2708\n","Epoch 150, Train Loss: 1.8994, Val Loss: 2.0937, F1 Micro: 0.2708, F1 Macro: 0.2132, Accuracy: 0.2708\n","Epoch 151, Train Loss: 1.7944, Val Loss: 1.9421, F1 Micro: 0.3229, F1 Macro: 0.2649, Accuracy: 0.3229\n","Epoch 152, Train Loss: 1.7052, Val Loss: 2.0332, F1 Micro: 0.3542, F1 Macro: 0.3110, Accuracy: 0.3542\n","Epoch 153, Train Loss: 1.8747, Val Loss: 2.4800, F1 Micro: 0.3229, F1 Macro: 0.3037, Accuracy: 0.3229\n","Epoch 154, Train Loss: 1.9226, Val Loss: 1.9474, F1 Micro: 0.3646, F1 Macro: 0.3276, Accuracy: 0.3646\n","Epoch 155, Train Loss: 1.9192, Val Loss: 2.0514, F1 Micro: 0.3438, F1 Macro: 0.2870, Accuracy: 0.3438\n","Epoch 156, Train Loss: 1.7842, Val Loss: 1.8102, F1 Micro: 0.3750, F1 Macro: 0.3572, Accuracy: 0.3750\n","Epoch 157, Train Loss: 1.8949, Val Loss: 2.2428, F1 Micro: 0.4167, F1 Macro: 0.3797, Accuracy: 0.4167\n","Epoch 158, Train Loss: 2.0327, Val Loss: 2.4879, F1 Micro: 0.2188, F1 Macro: 0.1932, Accuracy: 0.2188\n","Epoch 159, Train Loss: 1.9175, Val Loss: 2.3023, F1 Micro: 0.3438, F1 Macro: 0.2898, Accuracy: 0.3438\n","Epoch 160, Train Loss: 1.7913, Val Loss: 1.8247, F1 Micro: 0.3958, F1 Macro: 0.3750, Accuracy: 0.3958\n","Epoch 161, Train Loss: 1.8806, Val Loss: 2.6724, F1 Micro: 0.1979, F1 Macro: 0.1694, Accuracy: 0.1979\n","Epoch 162, Train Loss: 1.9526, Val Loss: 2.1508, F1 Micro: 0.2812, F1 Macro: 0.2650, Accuracy: 0.2812\n","Epoch 163, Train Loss: 1.7551, Val Loss: 2.0363, F1 Micro: 0.2604, F1 Macro: 0.2283, Accuracy: 0.2604\n","Epoch 164, Train Loss: 1.8869, Val Loss: 2.2071, F1 Micro: 0.2708, F1 Macro: 0.2356, Accuracy: 0.2708\n","Epoch 165, Train Loss: 2.0064, Val Loss: 2.5331, F1 Micro: 0.2292, F1 Macro: 0.1488, Accuracy: 0.2292\n","Epoch 166, Train Loss: 2.3456, Val Loss: 3.1901, F1 Micro: 0.2500, F1 Macro: 0.2223, Accuracy: 0.2500\n","Epoch 167, Train Loss: 2.4274, Val Loss: 3.3647, F1 Micro: 0.2396, F1 Macro: 0.1921, Accuracy: 0.2396\n","Epoch 168, Train Loss: 2.3966, Val Loss: 2.1224, F1 Micro: 0.3229, F1 Macro: 0.2889, Accuracy: 0.3229\n","Epoch 169, Train Loss: 1.8685, Val Loss: 2.2965, F1 Micro: 0.2708, F1 Macro: 0.2102, Accuracy: 0.2708\n","Epoch 170, Train Loss: 1.8578, Val Loss: 1.8736, F1 Micro: 0.2812, F1 Macro: 0.2617, Accuracy: 0.2812\n","Epoch 171, Train Loss: 1.9544, Val Loss: 1.9712, F1 Micro: 0.2812, F1 Macro: 0.2661, Accuracy: 0.2812\n","Epoch 172, Train Loss: 2.3678, Val Loss: 2.6880, F1 Micro: 0.3229, F1 Macro: 0.2591, Accuracy: 0.3229\n","Epoch 173, Train Loss: 2.3819, Val Loss: 1.9981, F1 Micro: 0.2917, F1 Macro: 0.2753, Accuracy: 0.2917\n","Epoch 174, Train Loss: 1.9522, Val Loss: 1.7392, F1 Micro: 0.3333, F1 Macro: 0.3235, Accuracy: 0.3333\n","Epoch 175, Train Loss: 1.8670, Val Loss: 2.2060, F1 Micro: 0.2708, F1 Macro: 0.2521, Accuracy: 0.2708\n","Epoch 176, Train Loss: 1.8395, Val Loss: 2.0345, F1 Micro: 0.3229, F1 Macro: 0.3238, Accuracy: 0.3229\n","Epoch 177, Train Loss: 1.8004, Val Loss: 1.9971, F1 Micro: 0.2708, F1 Macro: 0.2208, Accuracy: 0.2708\n","Epoch 178, Train Loss: 2.0610, Val Loss: 2.5578, F1 Micro: 0.2604, F1 Macro: 0.2102, Accuracy: 0.2604\n","Epoch 179, Train Loss: 2.3043, Val Loss: 2.6262, F1 Micro: 0.2917, F1 Macro: 0.2324, Accuracy: 0.2917\n","Epoch 180, Train Loss: 2.5753, Val Loss: 2.9923, F1 Micro: 0.2708, F1 Macro: 0.1930, Accuracy: 0.2708\n","Epoch 181, Train Loss: 2.8919, Val Loss: 3.2049, F1 Micro: 0.2812, F1 Macro: 0.2334, Accuracy: 0.2812\n","Epoch 182, Train Loss: 3.4418, Val Loss: 4.2851, F1 Micro: 0.2604, F1 Macro: 0.1737, Accuracy: 0.2604\n","Epoch 183, Train Loss: 4.0244, Val Loss: 4.2787, F1 Micro: 0.2500, F1 Macro: 0.1648, Accuracy: 0.2500\n","Epoch 184, Train Loss: 3.4152, Val Loss: 3.7714, F1 Micro: 0.2292, F1 Macro: 0.1748, Accuracy: 0.2292\n","Epoch 185, Train Loss: 3.6637, Val Loss: 3.4762, F1 Micro: 0.1667, F1 Macro: 0.0809, Accuracy: 0.1667\n","Epoch 186, Train Loss: 3.3877, Val Loss: 5.0770, F1 Micro: 0.2188, F1 Macro: 0.1278, Accuracy: 0.2188\n","Epoch 187, Train Loss: 4.2272, Val Loss: 3.9833, F1 Micro: 0.2812, F1 Macro: 0.1919, Accuracy: 0.2812\n","Epoch 188, Train Loss: 3.1134, Val Loss: 2.1135, F1 Micro: 0.2917, F1 Macro: 0.2576, Accuracy: 0.2917\n","Epoch 189, Train Loss: 2.0808, Val Loss: 3.3357, F1 Micro: 0.2604, F1 Macro: 0.2014, Accuracy: 0.2604\n","Epoch 190, Train Loss: 2.3223, Val Loss: 2.5215, F1 Micro: 0.3021, F1 Macro: 0.2813, Accuracy: 0.3021\n","Epoch 191, Train Loss: 2.4912, Val Loss: 3.0041, F1 Micro: 0.2604, F1 Macro: 0.2079, Accuracy: 0.2604\n","Epoch 192, Train Loss: 2.5172, Val Loss: 2.8209, F1 Micro: 0.3229, F1 Macro: 0.2602, Accuracy: 0.3229\n","Epoch 193, Train Loss: 2.2975, Val Loss: 2.3415, F1 Micro: 0.3333, F1 Macro: 0.2885, Accuracy: 0.3333\n","Epoch 194, Train Loss: 3.8245, Val Loss: 4.4128, F1 Micro: 0.2708, F1 Macro: 0.2037, Accuracy: 0.2708\n","Epoch 195, Train Loss: 7.9676, Val Loss: 10.1479, F1 Micro: 0.1771, F1 Macro: 0.0844, Accuracy: 0.1771\n","Epoch 196, Train Loss: 61.3553, Val Loss: 82.9465, F1 Micro: 0.1667, F1 Macro: 0.0494, Accuracy: 0.1667\n","Epoch 197, Train Loss: 132.8261, Val Loss: 149.1577, F1 Micro: 0.2083, F1 Macro: 0.0907, Accuracy: 0.2083\n","Epoch 198, Train Loss: 160.5761, Val Loss: 321.1803, F1 Micro: 0.1458, F1 Macro: 0.0436, Accuracy: 0.1458\n","Epoch 199, Train Loss: 234.3459, Val Loss: 212.0701, F1 Micro: 0.1875, F1 Macro: 0.0881, Accuracy: 0.1875\n","Epoch 200, Train Loss: 216.3243, Val Loss: 173.3093, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 518.6514, Val Loss: 74.4386, F1 Micro: 0.2188, F1 Macro: 0.1331, Accuracy: 0.2188\n","Epoch 2, Train Loss: 48.7985, Val Loss: 14.1515, F1 Micro: 0.1875, F1 Macro: 0.1364, Accuracy: 0.1875\n","Epoch 3, Train Loss: 30.2314, Val Loss: 38.5287, F1 Micro: 0.2708, F1 Macro: 0.1614, Accuracy: 0.2708\n","Epoch 4, Train Loss: 31.7318, Val Loss: 16.9587, F1 Micro: 0.2812, F1 Macro: 0.2407, Accuracy: 0.2812\n","Epoch 5, Train Loss: 19.2134, Val Loss: 17.8348, F1 Micro: 0.2292, F1 Macro: 0.1436, Accuracy: 0.2292\n","Epoch 6, Train Loss: 10.3676, Val Loss: 7.1066, F1 Micro: 0.2500, F1 Macro: 0.1793, Accuracy: 0.2500\n","Epoch 7, Train Loss: 10.1662, Val Loss: 6.5471, F1 Micro: 0.2188, F1 Macro: 0.2070, Accuracy: 0.2188\n","Epoch 8, Train Loss: 9.3399, Val Loss: 7.7806, F1 Micro: 0.1979, F1 Macro: 0.1212, Accuracy: 0.1979\n","Epoch 9, Train Loss: 7.4848, Val Loss: 6.0199, F1 Micro: 0.3229, F1 Macro: 0.2779, Accuracy: 0.3229\n","Epoch 10, Train Loss: 7.2475, Val Loss: 5.7548, F1 Micro: 0.2708, F1 Macro: 0.2338, Accuracy: 0.2708\n","Epoch 11, Train Loss: 6.9143, Val Loss: 4.2958, F1 Micro: 0.3333, F1 Macro: 0.2737, Accuracy: 0.3333\n","Epoch 12, Train Loss: 5.5795, Val Loss: 5.4980, F1 Micro: 0.3229, F1 Macro: 0.3140, Accuracy: 0.3229\n","Epoch 13, Train Loss: 5.6380, Val Loss: 6.2120, F1 Micro: 0.2604, F1 Macro: 0.2059, Accuracy: 0.2604\n","Epoch 14, Train Loss: 5.7198, Val Loss: 3.7956, F1 Micro: 0.4062, F1 Macro: 0.3922, Accuracy: 0.4062\n","Epoch 15, Train Loss: 4.7147, Val Loss: 3.8396, F1 Micro: 0.3229, F1 Macro: 0.2849, Accuracy: 0.3229\n","Epoch 16, Train Loss: 3.9636, Val Loss: 3.0892, F1 Micro: 0.3333, F1 Macro: 0.3079, Accuracy: 0.3333\n","Epoch 17, Train Loss: 5.0486, Val Loss: 7.5940, F1 Micro: 0.1979, F1 Macro: 0.1592, Accuracy: 0.1979\n","Epoch 18, Train Loss: 4.9516, Val Loss: 5.4281, F1 Micro: 0.2500, F1 Macro: 0.2152, Accuracy: 0.2500\n","Epoch 19, Train Loss: 5.0236, Val Loss: 5.5918, F1 Micro: 0.4271, F1 Macro: 0.3565, Accuracy: 0.4271\n","Epoch 20, Train Loss: 5.1070, Val Loss: 4.2301, F1 Micro: 0.2604, F1 Macro: 0.2071, Accuracy: 0.2604\n","Epoch 21, Train Loss: 4.2013, Val Loss: 3.7171, F1 Micro: 0.3229, F1 Macro: 0.2822, Accuracy: 0.3229\n","Epoch 22, Train Loss: 4.2450, Val Loss: 3.2047, F1 Micro: 0.4167, F1 Macro: 0.3950, Accuracy: 0.4167\n","Epoch 23, Train Loss: 3.6115, Val Loss: 3.5096, F1 Micro: 0.3333, F1 Macro: 0.2701, Accuracy: 0.3333\n","Epoch 24, Train Loss: 3.9156, Val Loss: 5.3718, F1 Micro: 0.2396, F1 Macro: 0.2046, Accuracy: 0.2396\n","Epoch 25, Train Loss: 3.9675, Val Loss: 4.7340, F1 Micro: 0.3646, F1 Macro: 0.3019, Accuracy: 0.3646\n","Epoch 26, Train Loss: 3.7769, Val Loss: 6.2533, F1 Micro: 0.1875, F1 Macro: 0.1081, Accuracy: 0.1875\n","Epoch 27, Train Loss: 3.9223, Val Loss: 3.4802, F1 Micro: 0.2292, F1 Macro: 0.2020, Accuracy: 0.2292\n","Epoch 28, Train Loss: 5.0199, Val Loss: 8.0716, F1 Micro: 0.2083, F1 Macro: 0.1322, Accuracy: 0.2083\n","Epoch 29, Train Loss: 5.8876, Val Loss: 3.3272, F1 Micro: 0.3125, F1 Macro: 0.2418, Accuracy: 0.3125\n","Epoch 30, Train Loss: 10.7998, Val Loss: 7.9529, F1 Micro: 0.3542, F1 Macro: 0.2858, Accuracy: 0.3542\n","Epoch 31, Train Loss: 10.7794, Val Loss: 11.9652, F1 Micro: 0.2812, F1 Macro: 0.2386, Accuracy: 0.2812\n","Epoch 32, Train Loss: 7.6327, Val Loss: 4.1803, F1 Micro: 0.3229, F1 Macro: 0.2815, Accuracy: 0.3229\n","Epoch 33, Train Loss: 6.1747, Val Loss: 5.5889, F1 Micro: 0.2708, F1 Macro: 0.2071, Accuracy: 0.2708\n","Epoch 34, Train Loss: 4.5614, Val Loss: 4.5891, F1 Micro: 0.2292, F1 Macro: 0.1316, Accuracy: 0.2292\n","Epoch 35, Train Loss: 3.7113, Val Loss: 3.7314, F1 Micro: 0.2812, F1 Macro: 0.2152, Accuracy: 0.2812\n","Epoch 36, Train Loss: 2.7243, Val Loss: 2.6393, F1 Micro: 0.2917, F1 Macro: 0.2657, Accuracy: 0.2917\n","Epoch 37, Train Loss: 2.3415, Val Loss: 2.5565, F1 Micro: 0.3646, F1 Macro: 0.2932, Accuracy: 0.3646\n","Epoch 38, Train Loss: 2.5845, Val Loss: 3.7789, F1 Micro: 0.3021, F1 Macro: 0.2590, Accuracy: 0.3021\n","Epoch 39, Train Loss: 2.9288, Val Loss: 2.8222, F1 Micro: 0.2604, F1 Macro: 0.2254, Accuracy: 0.2604\n","Epoch 40, Train Loss: 2.3510, Val Loss: 2.1131, F1 Micro: 0.4167, F1 Macro: 0.3799, Accuracy: 0.4167\n","Epoch 41, Train Loss: 2.2185, Val Loss: 1.6877, F1 Micro: 0.4688, F1 Macro: 0.4405, Accuracy: 0.4688\n","Epoch 42, Train Loss: 2.3696, Val Loss: 3.3687, F1 Micro: 0.1979, F1 Macro: 0.1491, Accuracy: 0.1979\n","Epoch 43, Train Loss: 2.7669, Val Loss: 2.3286, F1 Micro: 0.2083, F1 Macro: 0.1619, Accuracy: 0.2083\n","Epoch 44, Train Loss: 2.4122, Val Loss: 1.9439, F1 Micro: 0.2604, F1 Macro: 0.2204, Accuracy: 0.2604\n","Epoch 45, Train Loss: 2.4742, Val Loss: 2.8966, F1 Micro: 0.2604, F1 Macro: 0.2129, Accuracy: 0.2604\n","Epoch 46, Train Loss: 2.5492, Val Loss: 2.3793, F1 Micro: 0.3542, F1 Macro: 0.2882, Accuracy: 0.3542\n","Epoch 47, Train Loss: 2.6719, Val Loss: 2.8180, F1 Micro: 0.3125, F1 Macro: 0.2406, Accuracy: 0.3125\n","Epoch 48, Train Loss: 3.6738, Val Loss: 4.1440, F1 Micro: 0.2188, F1 Macro: 0.1850, Accuracy: 0.2188\n","Epoch 49, Train Loss: 4.5994, Val Loss: 3.0795, F1 Micro: 0.2500, F1 Macro: 0.1938, Accuracy: 0.2500\n","Epoch 50, Train Loss: 3.5104, Val Loss: 3.2198, F1 Micro: 0.3750, F1 Macro: 0.3460, Accuracy: 0.3750\n","Epoch 51, Train Loss: 2.5390, Val Loss: 2.1933, F1 Micro: 0.3229, F1 Macro: 0.2821, Accuracy: 0.3229\n","Epoch 52, Train Loss: 2.3681, Val Loss: 3.0975, F1 Micro: 0.2396, F1 Macro: 0.1691, Accuracy: 0.2396\n","Epoch 53, Train Loss: 3.1470, Val Loss: 3.2581, F1 Micro: 0.2812, F1 Macro: 0.2155, Accuracy: 0.2812\n","Epoch 54, Train Loss: 3.0401, Val Loss: 4.3514, F1 Micro: 0.2917, F1 Macro: 0.2437, Accuracy: 0.2917\n","Epoch 55, Train Loss: 3.3205, Val Loss: 2.9690, F1 Micro: 0.3750, F1 Macro: 0.3061, Accuracy: 0.3750\n","Epoch 56, Train Loss: 2.9492, Val Loss: 2.8707, F1 Micro: 0.2708, F1 Macro: 0.1792, Accuracy: 0.2708\n","Epoch 57, Train Loss: 2.6286, Val Loss: 1.8537, F1 Micro: 0.4062, F1 Macro: 0.3816, Accuracy: 0.4062\n","Epoch 58, Train Loss: 2.7156, Val Loss: 2.4472, F1 Micro: 0.3438, F1 Macro: 0.2956, Accuracy: 0.3438\n","Epoch 59, Train Loss: 2.7996, Val Loss: 2.4374, F1 Micro: 0.2812, F1 Macro: 0.2630, Accuracy: 0.2812\n","Epoch 60, Train Loss: 2.4606, Val Loss: 1.7475, F1 Micro: 0.3854, F1 Macro: 0.3485, Accuracy: 0.3854\n","Epoch 61, Train Loss: 1.9435, Val Loss: 1.9087, F1 Micro: 0.3542, F1 Macro: 0.3249, Accuracy: 0.3542\n","Epoch 62, Train Loss: 2.2605, Val Loss: 2.2150, F1 Micro: 0.3438, F1 Macro: 0.2901, Accuracy: 0.3438\n","Epoch 63, Train Loss: 2.6936, Val Loss: 2.8044, F1 Micro: 0.2812, F1 Macro: 0.2155, Accuracy: 0.2812\n","Epoch 64, Train Loss: 2.7699, Val Loss: 1.8484, F1 Micro: 0.3958, F1 Macro: 0.3738, Accuracy: 0.3958\n","Epoch 65, Train Loss: 2.5223, Val Loss: 2.3123, F1 Micro: 0.3021, F1 Macro: 0.2601, Accuracy: 0.3021\n","Epoch 66, Train Loss: 2.8900, Val Loss: 3.3173, F1 Micro: 0.3229, F1 Macro: 0.2579, Accuracy: 0.3229\n","Epoch 67, Train Loss: 4.0263, Val Loss: 8.7601, F1 Micro: 0.2188, F1 Macro: 0.1321, Accuracy: 0.2188\n","Epoch 68, Train Loss: 4.3610, Val Loss: 7.0680, F1 Micro: 0.2188, F1 Macro: 0.1453, Accuracy: 0.2188\n","Epoch 69, Train Loss: 6.0485, Val Loss: 8.8711, F1 Micro: 0.3125, F1 Macro: 0.1884, Accuracy: 0.3125\n","Epoch 70, Train Loss: 13.1454, Val Loss: 34.3287, F1 Micro: 0.1771, F1 Macro: 0.0645, Accuracy: 0.1771\n","Epoch 71, Train Loss: 59.9265, Val Loss: 148.2366, F1 Micro: 0.2188, F1 Macro: 0.1116, Accuracy: 0.2188\n","Epoch 72, Train Loss: 150.1517, Val Loss: 280.2514, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 73, Train Loss: 290.2803, Val Loss: 718.7805, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 74, Train Loss: 284.3390, Val Loss: 399.0257, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 75, Train Loss: 236.4279, Val Loss: 127.1471, F1 Micro: 0.2500, F1 Macro: 0.1565, Accuracy: 0.2500\n","Epoch 76, Train Loss: 175.3380, Val Loss: 128.1159, F1 Micro: 0.2083, F1 Macro: 0.0874, Accuracy: 0.2083\n","Epoch 77, Train Loss: 123.3271, Val Loss: 104.3363, F1 Micro: 0.2188, F1 Macro: 0.1553, Accuracy: 0.2188\n","Epoch 78, Train Loss: 79.4211, Val Loss: 56.7625, F1 Micro: 0.1979, F1 Macro: 0.1172, Accuracy: 0.1979\n","Epoch 79, Train Loss: 42.2287, Val Loss: 26.2709, F1 Micro: 0.1979, F1 Macro: 0.1206, Accuracy: 0.1979\n","Epoch 80, Train Loss: 29.9594, Val Loss: 13.3263, F1 Micro: 0.2500, F1 Macro: 0.1499, Accuracy: 0.2500\n","Epoch 81, Train Loss: 9.7156, Val Loss: 5.6031, F1 Micro: 0.1458, F1 Macro: 0.1099, Accuracy: 0.1458\n","Epoch 82, Train Loss: 6.2170, Val Loss: 5.5001, F1 Micro: 0.2500, F1 Macro: 0.1338, Accuracy: 0.2500\n","Epoch 83, Train Loss: 3.8920, Val Loss: 4.7308, F1 Micro: 0.2917, F1 Macro: 0.2512, Accuracy: 0.2917\n","Epoch 84, Train Loss: 3.6034, Val Loss: 2.4788, F1 Micro: 0.3333, F1 Macro: 0.2970, Accuracy: 0.3333\n","Epoch 85, Train Loss: 2.1722, Val Loss: 2.1807, F1 Micro: 0.3958, F1 Macro: 0.3896, Accuracy: 0.3958\n","Epoch 86, Train Loss: 2.1275, Val Loss: 1.7556, F1 Micro: 0.4167, F1 Macro: 0.3670, Accuracy: 0.4167\n","Epoch 87, Train Loss: 1.9926, Val Loss: 1.7424, F1 Micro: 0.4062, F1 Macro: 0.3700, Accuracy: 0.4062\n","Epoch 88, Train Loss: 1.9059, Val Loss: 1.7712, F1 Micro: 0.3438, F1 Macro: 0.3114, Accuracy: 0.3438\n","Epoch 89, Train Loss: 1.9289, Val Loss: 1.7416, F1 Micro: 0.4375, F1 Macro: 0.4203, Accuracy: 0.4375\n","Epoch 90, Train Loss: 2.0648, Val Loss: 2.3369, F1 Micro: 0.4062, F1 Macro: 0.3411, Accuracy: 0.4062\n","Epoch 91, Train Loss: 2.0739, Val Loss: 1.7420, F1 Micro: 0.4167, F1 Macro: 0.3959, Accuracy: 0.4167\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.425\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 54.3896, Val Loss: 40.1240, F1 Micro: 0.1562, F1 Macro: 0.0764, Accuracy: 0.1562\n","Epoch 2, Train Loss: 27.8270, Val Loss: 31.2029, F1 Micro: 0.3021, F1 Macro: 0.1793, Accuracy: 0.3021\n","Epoch 3, Train Loss: 33.7718, Val Loss: 16.6601, F1 Micro: 0.2500, F1 Macro: 0.2061, Accuracy: 0.2500\n","Epoch 4, Train Loss: 21.9978, Val Loss: 57.6256, F1 Micro: 0.1771, F1 Macro: 0.1248, Accuracy: 0.1771\n","Epoch 5, Train Loss: 31.2012, Val Loss: 19.3400, F1 Micro: 0.2812, F1 Macro: 0.2028, Accuracy: 0.2812\n","Epoch 6, Train Loss: 19.0590, Val Loss: 23.7089, F1 Micro: 0.2500, F1 Macro: 0.1893, Accuracy: 0.2500\n","Epoch 7, Train Loss: 29.3506, Val Loss: 34.1659, F1 Micro: 0.3229, F1 Macro: 0.2157, Accuracy: 0.3229\n","Epoch 8, Train Loss: 22.4537, Val Loss: 22.2967, F1 Micro: 0.1771, F1 Macro: 0.1235, Accuracy: 0.1771\n","Epoch 9, Train Loss: 16.1156, Val Loss: 21.1954, F1 Micro: 0.2083, F1 Macro: 0.1561, Accuracy: 0.2083\n","Epoch 10, Train Loss: 20.0209, Val Loss: 12.2231, F1 Micro: 0.2500, F1 Macro: 0.2110, Accuracy: 0.2500\n","Epoch 11, Train Loss: 16.1197, Val Loss: 18.4369, F1 Micro: 0.2396, F1 Macro: 0.1397, Accuracy: 0.2396\n","Epoch 12, Train Loss: 18.8046, Val Loss: 19.3476, F1 Micro: 0.1562, F1 Macro: 0.0571, Accuracy: 0.1562\n","Epoch 13, Train Loss: 17.1210, Val Loss: 30.8465, F1 Micro: 0.1667, F1 Macro: 0.0918, Accuracy: 0.1667\n","Epoch 14, Train Loss: 29.0241, Val Loss: 36.2084, F1 Micro: 0.2396, F1 Macro: 0.1515, Accuracy: 0.2396\n","Epoch 15, Train Loss: 26.6234, Val Loss: 40.4703, F1 Micro: 0.1458, F1 Macro: 0.0655, Accuracy: 0.1458\n","Epoch 16, Train Loss: 18.3115, Val Loss: 31.1604, F1 Micro: 0.3021, F1 Macro: 0.1965, Accuracy: 0.3021\n","Epoch 17, Train Loss: 31.5284, Val Loss: 23.7873, F1 Micro: 0.2083, F1 Macro: 0.1416, Accuracy: 0.2083\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 74.6663, Val Loss: 21.3793, F1 Micro: 0.2292, F1 Macro: 0.1525, Accuracy: 0.2292\n","Epoch 2, Train Loss: 40.4955, Val Loss: 20.2051, F1 Micro: 0.2812, F1 Macro: 0.1621, Accuracy: 0.2812\n","Epoch 3, Train Loss: 28.3844, Val Loss: 25.9895, F1 Micro: 0.2500, F1 Macro: 0.1548, Accuracy: 0.2500\n","Epoch 4, Train Loss: 29.7553, Val Loss: 33.2623, F1 Micro: 0.2292, F1 Macro: 0.1588, Accuracy: 0.2292\n","Epoch 5, Train Loss: 24.3620, Val Loss: 21.1578, F1 Micro: 0.2917, F1 Macro: 0.2163, Accuracy: 0.2917\n","Epoch 6, Train Loss: 24.0305, Val Loss: 11.6514, F1 Micro: 0.2396, F1 Macro: 0.2150, Accuracy: 0.2396\n","Epoch 7, Train Loss: 16.9487, Val Loss: 12.5873, F1 Micro: 0.1875, F1 Macro: 0.1399, Accuracy: 0.1875\n","Epoch 8, Train Loss: 23.8161, Val Loss: 38.0887, F1 Micro: 0.1875, F1 Macro: 0.1474, Accuracy: 0.1875\n","Epoch 9, Train Loss: 30.4225, Val Loss: 15.2679, F1 Micro: 0.3021, F1 Macro: 0.2086, Accuracy: 0.3021\n","Epoch 10, Train Loss: 25.2968, Val Loss: 17.7437, F1 Micro: 0.1667, F1 Macro: 0.1057, Accuracy: 0.1667\n","Epoch 11, Train Loss: 18.0567, Val Loss: 31.0900, F1 Micro: 0.1771, F1 Macro: 0.1069, Accuracy: 0.1771\n","Epoch 12, Train Loss: 23.3507, Val Loss: 24.4209, F1 Micro: 0.1771, F1 Macro: 0.1563, Accuracy: 0.1771\n","Epoch 13, Train Loss: 31.1231, Val Loss: 35.7009, F1 Micro: 0.1667, F1 Macro: 0.0959, Accuracy: 0.1667\n","Epoch 14, Train Loss: 19.5571, Val Loss: 11.7791, F1 Micro: 0.2604, F1 Macro: 0.1751, Accuracy: 0.2604\n","Epoch 15, Train Loss: 23.0982, Val Loss: 19.6045, F1 Micro: 0.2917, F1 Macro: 0.2318, Accuracy: 0.2917\n","Epoch 16, Train Loss: 24.9945, Val Loss: 15.0767, F1 Micro: 0.2917, F1 Macro: 0.2064, Accuracy: 0.2917\n","Epoch 17, Train Loss: 24.1050, Val Loss: 17.2372, F1 Micro: 0.2396, F1 Macro: 0.1727, Accuracy: 0.2396\n","Epoch 18, Train Loss: 19.1316, Val Loss: 11.2569, F1 Micro: 0.1875, F1 Macro: 0.1530, Accuracy: 0.1875\n","Epoch 19, Train Loss: 17.7894, Val Loss: 16.5191, F1 Micro: 0.1667, F1 Macro: 0.1109, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 55.2013, Val Loss: 40.3108, F1 Micro: 0.2083, F1 Macro: 0.1352, Accuracy: 0.2083\n","Epoch 2, Train Loss: 25.7210, Val Loss: 30.0146, F1 Micro: 0.1250, F1 Macro: 0.0909, Accuracy: 0.1250\n","Epoch 3, Train Loss: 23.8526, Val Loss: 23.1014, F1 Micro: 0.1979, F1 Macro: 0.1422, Accuracy: 0.1979\n","Epoch 4, Train Loss: 29.9496, Val Loss: 18.2360, F1 Micro: 0.1771, F1 Macro: 0.0858, Accuracy: 0.1771\n","Epoch 5, Train Loss: 31.0749, Val Loss: 18.9994, F1 Micro: 0.1979, F1 Macro: 0.1086, Accuracy: 0.1979\n","Epoch 6, Train Loss: 17.9004, Val Loss: 24.9565, F1 Micro: 0.1875, F1 Macro: 0.1158, Accuracy: 0.1875\n","Epoch 7, Train Loss: 18.5064, Val Loss: 23.5357, F1 Micro: 0.2917, F1 Macro: 0.1684, Accuracy: 0.2917\n","Epoch 8, Train Loss: 16.7812, Val Loss: 17.2027, F1 Micro: 0.2917, F1 Macro: 0.1846, Accuracy: 0.2917\n","Epoch 9, Train Loss: 29.9635, Val Loss: 32.5968, F1 Micro: 0.2188, F1 Macro: 0.1396, Accuracy: 0.2188\n","Epoch 10, Train Loss: 21.8818, Val Loss: 17.6680, F1 Micro: 0.2083, F1 Macro: 0.1696, Accuracy: 0.2083\n","Epoch 11, Train Loss: 18.0185, Val Loss: 21.2522, F1 Micro: 0.1146, F1 Macro: 0.0732, Accuracy: 0.1146\n","Epoch 12, Train Loss: 16.6393, Val Loss: 32.9081, F1 Micro: 0.2917, F1 Macro: 0.2233, Accuracy: 0.2917\n","Epoch 13, Train Loss: 17.4018, Val Loss: 15.6373, F1 Micro: 0.1979, F1 Macro: 0.1795, Accuracy: 0.1979\n","Epoch 14, Train Loss: 17.9977, Val Loss: 38.1373, F1 Micro: 0.1562, F1 Macro: 0.1074, Accuracy: 0.1562\n","Epoch 15, Train Loss: 20.1758, Val Loss: 11.9440, F1 Micro: 0.3333, F1 Macro: 0.2470, Accuracy: 0.3333\n","Epoch 16, Train Loss: 17.8507, Val Loss: 13.9308, F1 Micro: 0.2083, F1 Macro: 0.1156, Accuracy: 0.2083\n","Epoch 17, Train Loss: 14.3826, Val Loss: 25.8102, F1 Micro: 0.2500, F1 Macro: 0.1167, Accuracy: 0.2500\n","Epoch 18, Train Loss: 20.4991, Val Loss: 12.6964, F1 Micro: 0.2604, F1 Macro: 0.1593, Accuracy: 0.2604\n","Epoch 19, Train Loss: 18.7264, Val Loss: 15.5864, F1 Micro: 0.3125, F1 Macro: 0.2226, Accuracy: 0.3125\n","Epoch 20, Train Loss: 11.9870, Val Loss: 41.0616, F1 Micro: 0.2396, F1 Macro: 0.1634, Accuracy: 0.2396\n","Epoch 21, Train Loss: 17.8092, Val Loss: 13.3825, F1 Micro: 0.1979, F1 Macro: 0.1043, Accuracy: 0.1979\n","Epoch 22, Train Loss: 22.9967, Val Loss: 22.4499, F1 Micro: 0.2604, F1 Macro: 0.1571, Accuracy: 0.2604\n","Epoch 23, Train Loss: 18.4510, Val Loss: 25.2818, F1 Micro: 0.2083, F1 Macro: 0.1329, Accuracy: 0.2083\n","Epoch 24, Train Loss: 24.2847, Val Loss: 20.9978, F1 Micro: 0.2396, F1 Macro: 0.1571, Accuracy: 0.2396\n","Epoch 25, Train Loss: 17.8428, Val Loss: 13.8956, F1 Micro: 0.1771, F1 Macro: 0.1381, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 62.2290, Val Loss: 41.0921, F1 Micro: 0.1250, F1 Macro: 0.0597, Accuracy: 0.1250\n","Epoch 2, Train Loss: 33.6772, Val Loss: 30.5597, F1 Micro: 0.1979, F1 Macro: 0.0858, Accuracy: 0.1979\n","Epoch 3, Train Loss: 34.9917, Val Loss: 35.2650, F1 Micro: 0.2188, F1 Macro: 0.1068, Accuracy: 0.2188\n","Epoch 4, Train Loss: 29.5794, Val Loss: 24.8305, F1 Micro: 0.2083, F1 Macro: 0.1095, Accuracy: 0.2083\n","Epoch 5, Train Loss: 28.5962, Val Loss: 19.6082, F1 Micro: 0.1667, F1 Macro: 0.0774, Accuracy: 0.1667\n","Epoch 6, Train Loss: 27.7053, Val Loss: 28.1695, F1 Micro: 0.2292, F1 Macro: 0.1883, Accuracy: 0.2292\n","Epoch 7, Train Loss: 24.4113, Val Loss: 18.8333, F1 Micro: 0.2500, F1 Macro: 0.1942, Accuracy: 0.2500\n","Epoch 8, Train Loss: 18.0126, Val Loss: 15.0898, F1 Micro: 0.1771, F1 Macro: 0.0711, Accuracy: 0.1771\n","Epoch 9, Train Loss: 15.8848, Val Loss: 10.2766, F1 Micro: 0.3229, F1 Macro: 0.2620, Accuracy: 0.3229\n","Epoch 10, Train Loss: 14.8354, Val Loss: 12.6436, F1 Micro: 0.2083, F1 Macro: 0.1339, Accuracy: 0.2083\n","Epoch 11, Train Loss: 19.6184, Val Loss: 17.1884, F1 Micro: 0.2292, F1 Macro: 0.1568, Accuracy: 0.2292\n","Epoch 12, Train Loss: 17.0148, Val Loss: 32.1696, F1 Micro: 0.1875, F1 Macro: 0.0861, Accuracy: 0.1875\n","Epoch 13, Train Loss: 27.1858, Val Loss: 17.0360, F1 Micro: 0.2188, F1 Macro: 0.1243, Accuracy: 0.2188\n","Epoch 14, Train Loss: 22.2240, Val Loss: 10.1403, F1 Micro: 0.3125, F1 Macro: 0.2028, Accuracy: 0.3125\n","Epoch 15, Train Loss: 20.1322, Val Loss: 19.0816, F1 Micro: 0.2500, F1 Macro: 0.1779, Accuracy: 0.2500\n","Epoch 16, Train Loss: 19.4073, Val Loss: 17.4305, F1 Micro: 0.2083, F1 Macro: 0.1186, Accuracy: 0.2083\n","Epoch 17, Train Loss: 18.3744, Val Loss: 21.5678, F1 Micro: 0.2188, F1 Macro: 0.1119, Accuracy: 0.2188\n","Epoch 18, Train Loss: 23.2440, Val Loss: 14.1035, F1 Micro: 0.2396, F1 Macro: 0.1496, Accuracy: 0.2396\n","Epoch 19, Train Loss: 20.2643, Val Loss: 23.6004, F1 Micro: 0.1875, F1 Macro: 0.0887, Accuracy: 0.1875\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 51.8703, Val Loss: 30.3280, F1 Micro: 0.1771, F1 Macro: 0.0785, Accuracy: 0.1771\n","Epoch 2, Train Loss: 25.9448, Val Loss: 25.8947, F1 Micro: 0.1458, F1 Macro: 0.1048, Accuracy: 0.1458\n","Epoch 3, Train Loss: 21.8035, Val Loss: 36.9284, F1 Micro: 0.1562, F1 Macro: 0.0910, Accuracy: 0.1562\n","Epoch 4, Train Loss: 33.7478, Val Loss: 48.7649, F1 Micro: 0.2500, F1 Macro: 0.1906, Accuracy: 0.2500\n","Epoch 5, Train Loss: 26.4431, Val Loss: 19.2071, F1 Micro: 0.3333, F1 Macro: 0.2164, Accuracy: 0.3333\n","Epoch 6, Train Loss: 14.1235, Val Loss: 20.6688, F1 Micro: 0.2292, F1 Macro: 0.1647, Accuracy: 0.2292\n","Epoch 7, Train Loss: 22.6245, Val Loss: 14.1847, F1 Micro: 0.2812, F1 Macro: 0.1885, Accuracy: 0.2812\n","Epoch 8, Train Loss: 20.7880, Val Loss: 10.6545, F1 Micro: 0.2500, F1 Macro: 0.2010, Accuracy: 0.2500\n","Epoch 9, Train Loss: 18.7456, Val Loss: 22.2316, F1 Micro: 0.2083, F1 Macro: 0.1113, Accuracy: 0.2083\n","Epoch 10, Train Loss: 28.3110, Val Loss: 16.9647, F1 Micro: 0.2812, F1 Macro: 0.2320, Accuracy: 0.2812\n","Epoch 11, Train Loss: 32.0118, Val Loss: 11.6706, F1 Micro: 0.2396, F1 Macro: 0.1762, Accuracy: 0.2396\n","Epoch 12, Train Loss: 17.3972, Val Loss: 23.8153, F1 Micro: 0.3021, F1 Macro: 0.2456, Accuracy: 0.3021\n","Epoch 13, Train Loss: 22.6530, Val Loss: 16.9638, F1 Micro: 0.2396, F1 Macro: 0.1732, Accuracy: 0.2396\n","Epoch 14, Train Loss: 17.0724, Val Loss: 27.9497, F1 Micro: 0.2708, F1 Macro: 0.1962, Accuracy: 0.2708\n","Epoch 15, Train Loss: 22.2111, Val Loss: 19.7829, F1 Micro: 0.1771, F1 Macro: 0.0650, Accuracy: 0.1771\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.32291666666666663\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 55.8191, Val Loss: 22.4853, F1 Micro: 0.2188, F1 Macro: 0.1616, Accuracy: 0.2188\n","Epoch 2, Train Loss: 35.0775, Val Loss: 39.2002, F1 Micro: 0.1771, F1 Macro: 0.1083, Accuracy: 0.1771\n","Epoch 3, Train Loss: 26.8693, Val Loss: 37.7999, F1 Micro: 0.1354, F1 Macro: 0.0704, Accuracy: 0.1354\n","Epoch 4, Train Loss: 27.7809, Val Loss: 37.5350, F1 Micro: 0.2188, F1 Macro: 0.1689, Accuracy: 0.2188\n","Epoch 5, Train Loss: 24.1812, Val Loss: 26.9335, F1 Micro: 0.3021, F1 Macro: 0.2035, Accuracy: 0.3021\n","Epoch 6, Train Loss: 21.1004, Val Loss: 18.3544, F1 Micro: 0.2708, F1 Macro: 0.2209, Accuracy: 0.2708\n","Epoch 7, Train Loss: 22.8000, Val Loss: 21.3372, F1 Micro: 0.2917, F1 Macro: 0.2061, Accuracy: 0.2917\n","Epoch 8, Train Loss: 25.0076, Val Loss: 50.0012, F1 Micro: 0.1562, F1 Macro: 0.0692, Accuracy: 0.1562\n","Epoch 9, Train Loss: 30.1541, Val Loss: 21.5772, F1 Micro: 0.2812, F1 Macro: 0.1916, Accuracy: 0.2812\n","Epoch 10, Train Loss: 21.3954, Val Loss: 30.2445, F1 Micro: 0.2708, F1 Macro: 0.1957, Accuracy: 0.2708\n","Epoch 11, Train Loss: 27.0354, Val Loss: 19.0344, F1 Micro: 0.2604, F1 Macro: 0.2287, Accuracy: 0.2604\n","Epoch 12, Train Loss: 25.8579, Val Loss: 30.4656, F1 Micro: 0.3125, F1 Macro: 0.2490, Accuracy: 0.3125\n","Epoch 13, Train Loss: 35.4298, Val Loss: 47.6834, F1 Micro: 0.2292, F1 Macro: 0.1643, Accuracy: 0.2292\n","Epoch 14, Train Loss: 21.0028, Val Loss: 26.8437, F1 Micro: 0.2708, F1 Macro: 0.2734, Accuracy: 0.2708\n","Epoch 15, Train Loss: 15.3779, Val Loss: 32.4794, F1 Micro: 0.2083, F1 Macro: 0.1688, Accuracy: 0.2083\n","Epoch 16, Train Loss: 25.2552, Val Loss: 28.3256, F1 Micro: 0.1667, F1 Macro: 0.0949, Accuracy: 0.1667\n","Epoch 17, Train Loss: 17.4096, Val Loss: 20.8907, F1 Micro: 0.2604, F1 Macro: 0.1801, Accuracy: 0.2604\n","Epoch 18, Train Loss: 18.0859, Val Loss: 10.3147, F1 Micro: 0.3125, F1 Macro: 0.2785, Accuracy: 0.3125\n","Epoch 19, Train Loss: 15.9612, Val Loss: 16.0325, F1 Micro: 0.2812, F1 Macro: 0.1971, Accuracy: 0.2812\n","Epoch 20, Train Loss: 17.4118, Val Loss: 10.5080, F1 Micro: 0.2604, F1 Macro: 0.1583, Accuracy: 0.2604\n","Epoch 21, Train Loss: 14.0930, Val Loss: 14.5376, F1 Micro: 0.2604, F1 Macro: 0.2349, Accuracy: 0.2604\n","Epoch 22, Train Loss: 18.8489, Val Loss: 21.0408, F1 Micro: 0.2292, F1 Macro: 0.1945, Accuracy: 0.2292\n","Epoch 23, Train Loss: 26.1763, Val Loss: 18.7489, F1 Micro: 0.3125, F1 Macro: 0.2325, Accuracy: 0.3125\n","Epoch 24, Train Loss: 19.0980, Val Loss: 16.6789, F1 Micro: 0.1771, F1 Macro: 0.1406, Accuracy: 0.1771\n","Epoch 25, Train Loss: 23.0843, Val Loss: 30.5443, F1 Micro: 0.2708, F1 Macro: 0.1995, Accuracy: 0.2708\n","Epoch 26, Train Loss: 23.9276, Val Loss: 30.1718, F1 Micro: 0.2292, F1 Macro: 0.1774, Accuracy: 0.2292\n","Epoch 27, Train Loss: 20.6795, Val Loss: 16.3563, F1 Micro: 0.1875, F1 Macro: 0.1599, Accuracy: 0.1875\n","Epoch 28, Train Loss: 16.9406, Val Loss: 24.9402, F1 Micro: 0.2708, F1 Macro: 0.1547, Accuracy: 0.2708\n","Epoch 29, Train Loss: 20.4416, Val Loss: 17.4329, F1 Micro: 0.2188, F1 Macro: 0.1049, Accuracy: 0.2188\n","Epoch 30, Train Loss: 13.8082, Val Loss: 19.2621, F1 Micro: 0.2604, F1 Macro: 0.1936, Accuracy: 0.2604\n","Epoch 31, Train Loss: 17.9906, Val Loss: 18.9350, F1 Micro: 0.2708, F1 Macro: 0.2064, Accuracy: 0.2708\n","Epoch 32, Train Loss: 21.1751, Val Loss: 34.4344, F1 Micro: 0.2604, F1 Macro: 0.1465, Accuracy: 0.2604\n","Epoch 33, Train Loss: 20.8840, Val Loss: 16.6681, F1 Micro: 0.3333, F1 Macro: 0.3030, Accuracy: 0.3333\n","Epoch 34, Train Loss: 17.8761, Val Loss: 14.1236, F1 Micro: 0.2708, F1 Macro: 0.2394, Accuracy: 0.2708\n","Epoch 35, Train Loss: 15.3130, Val Loss: 28.0091, F1 Micro: 0.3021, F1 Macro: 0.2162, Accuracy: 0.3021\n","Epoch 36, Train Loss: 16.9468, Val Loss: 21.3697, F1 Micro: 0.2917, F1 Macro: 0.2044, Accuracy: 0.2917\n","Epoch 37, Train Loss: 16.9163, Val Loss: 28.0070, F1 Micro: 0.1979, F1 Macro: 0.1601, Accuracy: 0.1979\n","Epoch 38, Train Loss: 13.2139, Val Loss: 16.3870, F1 Micro: 0.2292, F1 Macro: 0.1645, Accuracy: 0.2292\n","Epoch 39, Train Loss: 15.4500, Val Loss: 20.7316, F1 Micro: 0.2188, F1 Macro: 0.1285, Accuracy: 0.2188\n","Epoch 40, Train Loss: 13.0211, Val Loss: 12.9998, F1 Micro: 0.2500, F1 Macro: 0.2108, Accuracy: 0.2500\n","Epoch 41, Train Loss: 11.4125, Val Loss: 20.8683, F1 Micro: 0.3229, F1 Macro: 0.2150, Accuracy: 0.3229\n","Epoch 42, Train Loss: 17.8264, Val Loss: 29.1013, F1 Micro: 0.2396, F1 Macro: 0.1372, Accuracy: 0.2396\n","Epoch 43, Train Loss: 15.6776, Val Loss: 9.7957, F1 Micro: 0.3333, F1 Macro: 0.2558, Accuracy: 0.3333\n","Epoch 44, Train Loss: 16.0702, Val Loss: 9.9530, F1 Micro: 0.2812, F1 Macro: 0.2654, Accuracy: 0.2812\n","Epoch 45, Train Loss: 15.7422, Val Loss: 25.5180, F1 Micro: 0.2396, F1 Macro: 0.2193, Accuracy: 0.2396\n","Epoch 46, Train Loss: 21.5805, Val Loss: 16.7055, F1 Micro: 0.2917, F1 Macro: 0.1922, Accuracy: 0.2917\n","Epoch 47, Train Loss: 13.2879, Val Loss: 17.6760, F1 Micro: 0.2708, F1 Macro: 0.2144, Accuracy: 0.2708\n","Epoch 48, Train Loss: 13.3115, Val Loss: 15.3692, F1 Micro: 0.3021, F1 Macro: 0.2387, Accuracy: 0.3021\n","Epoch 49, Train Loss: 17.4177, Val Loss: 19.8645, F1 Micro: 0.3125, F1 Macro: 0.1653, Accuracy: 0.3125\n","Epoch 50, Train Loss: 12.9475, Val Loss: 14.7859, F1 Micro: 0.3021, F1 Macro: 0.2753, Accuracy: 0.3021\n","Epoch 51, Train Loss: 11.2418, Val Loss: 11.8755, F1 Micro: 0.2083, F1 Macro: 0.1226, Accuracy: 0.2083\n","Epoch 52, Train Loss: 14.3539, Val Loss: 20.8949, F1 Micro: 0.2708, F1 Macro: 0.1848, Accuracy: 0.2708\n","Epoch 53, Train Loss: 12.0722, Val Loss: 10.7044, F1 Micro: 0.3333, F1 Macro: 0.2369, Accuracy: 0.3333\n","Epoch 54, Train Loss: 10.6578, Val Loss: 14.1441, F1 Micro: 0.2917, F1 Macro: 0.2301, Accuracy: 0.2917\n","Epoch 55, Train Loss: 12.1128, Val Loss: 10.7511, F1 Micro: 0.1667, F1 Macro: 0.1274, Accuracy: 0.1667\n","Epoch 56, Train Loss: 11.6576, Val Loss: 8.9773, F1 Micro: 0.3438, F1 Macro: 0.2583, Accuracy: 0.3438\n","Epoch 57, Train Loss: 11.7126, Val Loss: 6.9628, F1 Micro: 0.3542, F1 Macro: 0.2722, Accuracy: 0.3542\n","Epoch 58, Train Loss: 10.5145, Val Loss: 12.2115, F1 Micro: 0.4167, F1 Macro: 0.3252, Accuracy: 0.4167\n","Epoch 59, Train Loss: 14.4198, Val Loss: 22.4623, F1 Micro: 0.2604, F1 Macro: 0.1627, Accuracy: 0.2604\n","Epoch 60, Train Loss: 17.7620, Val Loss: 10.1970, F1 Micro: 0.1875, F1 Macro: 0.1418, Accuracy: 0.1875\n","Epoch 61, Train Loss: 11.7196, Val Loss: 20.7859, F1 Micro: 0.3333, F1 Macro: 0.2356, Accuracy: 0.3333\n","Epoch 62, Train Loss: 12.9180, Val Loss: 14.3809, F1 Micro: 0.2292, F1 Macro: 0.1873, Accuracy: 0.2292\n","Epoch 63, Train Loss: 18.8760, Val Loss: 10.7606, F1 Micro: 0.2708, F1 Macro: 0.2398, Accuracy: 0.2708\n","Epoch 64, Train Loss: 9.9616, Val Loss: 10.3583, F1 Micro: 0.3646, F1 Macro: 0.2924, Accuracy: 0.3646\n","Epoch 65, Train Loss: 16.3534, Val Loss: 24.3284, F1 Micro: 0.2188, F1 Macro: 0.1674, Accuracy: 0.2188\n","Epoch 66, Train Loss: 13.5753, Val Loss: 13.4001, F1 Micro: 0.3229, F1 Macro: 0.2620, Accuracy: 0.3229\n","Epoch 67, Train Loss: 11.0277, Val Loss: 23.5077, F1 Micro: 0.2083, F1 Macro: 0.1366, Accuracy: 0.2083\n","Epoch 68, Train Loss: 10.6445, Val Loss: 12.3517, F1 Micro: 0.2604, F1 Macro: 0.2112, Accuracy: 0.2604\n","Epoch 69, Train Loss: 13.5164, Val Loss: 19.0760, F1 Micro: 0.1562, F1 Macro: 0.0610, Accuracy: 0.1562\n","Epoch 70, Train Loss: 12.8845, Val Loss: 12.0560, F1 Micro: 0.2396, F1 Macro: 0.2121, Accuracy: 0.2396\n","Epoch 71, Train Loss: 9.6915, Val Loss: 14.8830, F1 Micro: 0.2083, F1 Macro: 0.2008, Accuracy: 0.2083\n","Epoch 72, Train Loss: 8.8108, Val Loss: 9.8339, F1 Micro: 0.2292, F1 Macro: 0.1329, Accuracy: 0.2292\n","Epoch 73, Train Loss: 11.1195, Val Loss: 11.7773, F1 Micro: 0.2917, F1 Macro: 0.2142, Accuracy: 0.2917\n","Epoch 74, Train Loss: 11.2222, Val Loss: 16.3311, F1 Micro: 0.2812, F1 Macro: 0.2033, Accuracy: 0.2812\n","Epoch 75, Train Loss: 11.4689, Val Loss: 9.3814, F1 Micro: 0.3438, F1 Macro: 0.2652, Accuracy: 0.3438\n","Epoch 76, Train Loss: 7.8226, Val Loss: 14.5292, F1 Micro: 0.2708, F1 Macro: 0.2085, Accuracy: 0.2708\n","Epoch 77, Train Loss: 9.9002, Val Loss: 13.0317, F1 Micro: 0.2396, F1 Macro: 0.1976, Accuracy: 0.2396\n","Epoch 78, Train Loss: 7.6564, Val Loss: 13.3693, F1 Micro: 0.3229, F1 Macro: 0.2675, Accuracy: 0.3229\n","Epoch 79, Train Loss: 9.5679, Val Loss: 10.7278, F1 Micro: 0.2396, F1 Macro: 0.2144, Accuracy: 0.2396\n","Epoch 80, Train Loss: 7.9948, Val Loss: 18.3153, F1 Micro: 0.2396, F1 Macro: 0.2150, Accuracy: 0.2396\n","Epoch 81, Train Loss: 8.2387, Val Loss: 8.8122, F1 Micro: 0.2917, F1 Macro: 0.2731, Accuracy: 0.2917\n","Epoch 82, Train Loss: 12.8658, Val Loss: 16.6879, F1 Micro: 0.1562, F1 Macro: 0.0804, Accuracy: 0.1562\n","Epoch 83, Train Loss: 8.3948, Val Loss: 7.1015, F1 Micro: 0.2708, F1 Macro: 0.2371, Accuracy: 0.2708\n","Epoch 84, Train Loss: 8.0469, Val Loss: 10.0008, F1 Micro: 0.2083, F1 Macro: 0.1595, Accuracy: 0.2083\n","Epoch 85, Train Loss: 9.2536, Val Loss: 9.5761, F1 Micro: 0.3021, F1 Macro: 0.2297, Accuracy: 0.3021\n","Epoch 86, Train Loss: 15.8311, Val Loss: 21.3011, F1 Micro: 0.3229, F1 Macro: 0.2359, Accuracy: 0.3229\n","Epoch 87, Train Loss: 14.4133, Val Loss: 22.2429, F1 Micro: 0.1458, F1 Macro: 0.0609, Accuracy: 0.1458\n","Epoch 88, Train Loss: 10.7898, Val Loss: 11.7283, F1 Micro: 0.2188, F1 Macro: 0.1881, Accuracy: 0.2188\n","Epoch 89, Train Loss: 8.4180, Val Loss: 6.6180, F1 Micro: 0.3021, F1 Macro: 0.2539, Accuracy: 0.3021\n","Epoch 90, Train Loss: 6.4756, Val Loss: 8.7935, F1 Micro: 0.2708, F1 Macro: 0.2327, Accuracy: 0.2708\n","Epoch 91, Train Loss: 6.7744, Val Loss: 8.5253, F1 Micro: 0.2083, F1 Macro: 0.1608, Accuracy: 0.2083\n","Epoch 92, Train Loss: 6.1223, Val Loss: 17.3957, F1 Micro: 0.2708, F1 Macro: 0.2171, Accuracy: 0.2708\n","Epoch 93, Train Loss: 9.8395, Val Loss: 6.2516, F1 Micro: 0.3750, F1 Macro: 0.3315, Accuracy: 0.3750\n","Epoch 94, Train Loss: 9.3754, Val Loss: 26.5711, F1 Micro: 0.2604, F1 Macro: 0.1902, Accuracy: 0.2604\n","Epoch 95, Train Loss: 10.8493, Val Loss: 16.5359, F1 Micro: 0.2500, F1 Macro: 0.2091, Accuracy: 0.2500\n","Epoch 96, Train Loss: 6.6232, Val Loss: 9.2625, F1 Micro: 0.1771, F1 Macro: 0.1313, Accuracy: 0.1771\n","Epoch 97, Train Loss: 6.9625, Val Loss: 7.7764, F1 Micro: 0.3958, F1 Macro: 0.3437, Accuracy: 0.3958\n","Epoch 98, Train Loss: 6.4970, Val Loss: 7.3593, F1 Micro: 0.3750, F1 Macro: 0.3359, Accuracy: 0.3750\n","Epoch 99, Train Loss: 6.6433, Val Loss: 4.6771, F1 Micro: 0.3333, F1 Macro: 0.2978, Accuracy: 0.3333\n","Epoch 100, Train Loss: 6.1388, Val Loss: 7.5592, F1 Micro: 0.3229, F1 Macro: 0.2356, Accuracy: 0.3229\n","Epoch 101, Train Loss: 8.7703, Val Loss: 8.6551, F1 Micro: 0.2292, F1 Macro: 0.1022, Accuracy: 0.2292\n","Epoch 102, Train Loss: 7.3709, Val Loss: 8.5449, F1 Micro: 0.2812, F1 Macro: 0.2372, Accuracy: 0.2812\n","Epoch 103, Train Loss: 5.6235, Val Loss: 6.4703, F1 Micro: 0.2917, F1 Macro: 0.2510, Accuracy: 0.2917\n","Epoch 104, Train Loss: 8.0014, Val Loss: 9.1972, F1 Micro: 0.3333, F1 Macro: 0.2944, Accuracy: 0.3333\n","Epoch 105, Train Loss: 7.3929, Val Loss: 9.3413, F1 Micro: 0.2917, F1 Macro: 0.2530, Accuracy: 0.2917\n","Epoch 106, Train Loss: 8.5024, Val Loss: 6.3740, F1 Micro: 0.3125, F1 Macro: 0.2451, Accuracy: 0.3125\n","Epoch 107, Train Loss: 5.4846, Val Loss: 5.4542, F1 Micro: 0.2812, F1 Macro: 0.2226, Accuracy: 0.2812\n","Epoch 108, Train Loss: 5.6110, Val Loss: 8.2001, F1 Micro: 0.3333, F1 Macro: 0.2585, Accuracy: 0.3333\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 64.8483, Val Loss: 32.1250, F1 Micro: 0.1250, F1 Macro: 0.0579, Accuracy: 0.1250\n","Epoch 2, Train Loss: 26.5071, Val Loss: 25.1134, F1 Micro: 0.1458, F1 Macro: 0.0938, Accuracy: 0.1458\n","Epoch 3, Train Loss: 24.7182, Val Loss: 40.9918, F1 Micro: 0.1250, F1 Macro: 0.0562, Accuracy: 0.1250\n","Epoch 4, Train Loss: 31.0679, Val Loss: 53.4550, F1 Micro: 0.2604, F1 Macro: 0.1327, Accuracy: 0.2604\n","Epoch 5, Train Loss: 44.5990, Val Loss: 40.2459, F1 Micro: 0.2708, F1 Macro: 0.1726, Accuracy: 0.2708\n","Epoch 6, Train Loss: 35.2566, Val Loss: 33.2605, F1 Micro: 0.2812, F1 Macro: 0.1621, Accuracy: 0.2812\n","Epoch 7, Train Loss: 27.2824, Val Loss: 10.1434, F1 Micro: 0.2708, F1 Macro: 0.2352, Accuracy: 0.2708\n","Epoch 8, Train Loss: 20.3013, Val Loss: 13.0550, F1 Micro: 0.3125, F1 Macro: 0.2235, Accuracy: 0.3125\n","Epoch 9, Train Loss: 21.8040, Val Loss: 16.2091, F1 Micro: 0.1771, F1 Macro: 0.0903, Accuracy: 0.1771\n","Epoch 10, Train Loss: 21.7020, Val Loss: 16.2479, F1 Micro: 0.1562, F1 Macro: 0.1442, Accuracy: 0.1562\n","Epoch 11, Train Loss: 21.8730, Val Loss: 37.0925, F1 Micro: 0.2500, F1 Macro: 0.1481, Accuracy: 0.2500\n","Epoch 12, Train Loss: 25.5111, Val Loss: 14.4188, F1 Micro: 0.2083, F1 Macro: 0.1520, Accuracy: 0.2083\n","Epoch 13, Train Loss: 19.6090, Val Loss: 25.9072, F1 Micro: 0.2083, F1 Macro: 0.1069, Accuracy: 0.2083\n","Epoch 14, Train Loss: 21.2572, Val Loss: 29.9175, F1 Micro: 0.1458, F1 Macro: 0.0858, Accuracy: 0.1458\n","Epoch 15, Train Loss: 25.1445, Val Loss: 24.4788, F1 Micro: 0.3021, F1 Macro: 0.2175, Accuracy: 0.3021\n","Epoch 16, Train Loss: 20.6374, Val Loss: 36.6973, F1 Micro: 0.1667, F1 Macro: 0.1005, Accuracy: 0.1667\n","Epoch 17, Train Loss: 27.1187, Val Loss: 27.8026, F1 Micro: 0.2708, F1 Macro: 0.1934, Accuracy: 0.2708\n","Epoch 18, Train Loss: 22.2441, Val Loss: 11.6204, F1 Micro: 0.2604, F1 Macro: 0.1598, Accuracy: 0.2604\n","Epoch 19, Train Loss: 18.2407, Val Loss: 13.9550, F1 Micro: 0.2188, F1 Macro: 0.1458, Accuracy: 0.2188\n","Epoch 20, Train Loss: 16.3439, Val Loss: 20.8689, F1 Micro: 0.3125, F1 Macro: 0.2354, Accuracy: 0.3125\n","Epoch 21, Train Loss: 20.9659, Val Loss: 25.1490, F1 Micro: 0.1979, F1 Macro: 0.1358, Accuracy: 0.1979\n","Epoch 22, Train Loss: 18.9172, Val Loss: 19.6711, F1 Micro: 0.2396, F1 Macro: 0.1499, Accuracy: 0.2396\n","Epoch 23, Train Loss: 22.5636, Val Loss: 17.1162, F1 Micro: 0.2188, F1 Macro: 0.1688, Accuracy: 0.2188\n","Epoch 24, Train Loss: 14.5523, Val Loss: 19.2661, F1 Micro: 0.3021, F1 Macro: 0.1998, Accuracy: 0.3021\n","Epoch 25, Train Loss: 21.5577, Val Loss: 8.8475, F1 Micro: 0.2083, F1 Macro: 0.1703, Accuracy: 0.2083\n","Epoch 26, Train Loss: 19.0730, Val Loss: 13.9679, F1 Micro: 0.2604, F1 Macro: 0.2034, Accuracy: 0.2604\n","Epoch 27, Train Loss: 16.8593, Val Loss: 12.3741, F1 Micro: 0.2188, F1 Macro: 0.1304, Accuracy: 0.2188\n","Epoch 28, Train Loss: 18.5191, Val Loss: 10.2009, F1 Micro: 0.3125, F1 Macro: 0.2910, Accuracy: 0.3125\n","Epoch 29, Train Loss: 15.9834, Val Loss: 7.2218, F1 Micro: 0.2917, F1 Macro: 0.2023, Accuracy: 0.2917\n","Epoch 30, Train Loss: 20.6278, Val Loss: 7.8062, F1 Micro: 0.3333, F1 Macro: 0.2824, Accuracy: 0.3333\n","Epoch 31, Train Loss: 12.1130, Val Loss: 7.1122, F1 Micro: 0.1771, F1 Macro: 0.1345, Accuracy: 0.1771\n","Epoch 32, Train Loss: 13.5292, Val Loss: 14.0610, F1 Micro: 0.1562, F1 Macro: 0.1002, Accuracy: 0.1562\n","Epoch 33, Train Loss: 10.1609, Val Loss: 23.3151, F1 Micro: 0.1042, F1 Macro: 0.0321, Accuracy: 0.1042\n","Epoch 34, Train Loss: 24.3965, Val Loss: 17.2242, F1 Micro: 0.2604, F1 Macro: 0.2208, Accuracy: 0.2604\n","Epoch 35, Train Loss: 20.7540, Val Loss: 18.4036, F1 Micro: 0.2396, F1 Macro: 0.1467, Accuracy: 0.2396\n","Epoch 36, Train Loss: 14.7440, Val Loss: 10.3240, F1 Micro: 0.2500, F1 Macro: 0.1523, Accuracy: 0.2500\n","Epoch 37, Train Loss: 20.2562, Val Loss: 20.7309, F1 Micro: 0.2500, F1 Macro: 0.1484, Accuracy: 0.2500\n","Epoch 38, Train Loss: 16.0009, Val Loss: 9.6229, F1 Micro: 0.2708, F1 Macro: 0.1832, Accuracy: 0.2708\n","Epoch 39, Train Loss: 16.0810, Val Loss: 11.5208, F1 Micro: 0.1771, F1 Macro: 0.1191, Accuracy: 0.1771\n","Epoch 40, Train Loss: 17.8357, Val Loss: 20.8233, F1 Micro: 0.2500, F1 Macro: 0.2123, Accuracy: 0.2500\n","Epoch 41, Train Loss: 18.1624, Val Loss: 14.5550, F1 Micro: 0.2708, F1 Macro: 0.2205, Accuracy: 0.2708\n","Epoch 42, Train Loss: 13.0602, Val Loss: 6.7448, F1 Micro: 0.2917, F1 Macro: 0.1915, Accuracy: 0.2917\n","Epoch 43, Train Loss: 15.2577, Val Loss: 8.2437, F1 Micro: 0.2604, F1 Macro: 0.1726, Accuracy: 0.2604\n","Epoch 44, Train Loss: 17.1708, Val Loss: 12.1751, F1 Micro: 0.1562, F1 Macro: 0.1141, Accuracy: 0.1562\n","Epoch 45, Train Loss: 13.2690, Val Loss: 13.7229, F1 Micro: 0.3646, F1 Macro: 0.2207, Accuracy: 0.3646\n","Epoch 46, Train Loss: 15.4295, Val Loss: 16.3006, F1 Micro: 0.2083, F1 Macro: 0.1058, Accuracy: 0.2083\n","Epoch 47, Train Loss: 18.1456, Val Loss: 25.5309, F1 Micro: 0.2812, F1 Macro: 0.1971, Accuracy: 0.2812\n","Epoch 48, Train Loss: 20.6076, Val Loss: 15.0749, F1 Micro: 0.2083, F1 Macro: 0.1586, Accuracy: 0.2083\n","Epoch 49, Train Loss: 20.2440, Val Loss: 18.6773, F1 Micro: 0.2396, F1 Macro: 0.1856, Accuracy: 0.2396\n","Epoch 50, Train Loss: 14.5122, Val Loss: 21.5722, F1 Micro: 0.2500, F1 Macro: 0.1441, Accuracy: 0.2500\n","Epoch 51, Train Loss: 18.0353, Val Loss: 22.7556, F1 Micro: 0.1562, F1 Macro: 0.0823, Accuracy: 0.1562\n","Epoch 52, Train Loss: 11.0475, Val Loss: 10.8086, F1 Micro: 0.2917, F1 Macro: 0.1807, Accuracy: 0.2917\n","Epoch 53, Train Loss: 13.1950, Val Loss: 16.6739, F1 Micro: 0.2292, F1 Macro: 0.1266, Accuracy: 0.2292\n","Epoch 54, Train Loss: 14.4814, Val Loss: 12.7084, F1 Micro: 0.2812, F1 Macro: 0.2004, Accuracy: 0.2812\n","Epoch 55, Train Loss: 11.4786, Val Loss: 8.9620, F1 Micro: 0.1458, F1 Macro: 0.1210, Accuracy: 0.1458\n","Epoch 56, Train Loss: 17.8095, Val Loss: 10.5127, F1 Micro: 0.2917, F1 Macro: 0.1901, Accuracy: 0.2917\n","Epoch 57, Train Loss: 13.0271, Val Loss: 5.6173, F1 Micro: 0.3542, F1 Macro: 0.3029, Accuracy: 0.3542\n","Epoch 58, Train Loss: 10.9006, Val Loss: 7.3827, F1 Micro: 0.3750, F1 Macro: 0.2883, Accuracy: 0.3750\n","Epoch 59, Train Loss: 11.2694, Val Loss: 13.6124, F1 Micro: 0.3229, F1 Macro: 0.2427, Accuracy: 0.3229\n","Epoch 60, Train Loss: 11.5376, Val Loss: 10.5231, F1 Micro: 0.2812, F1 Macro: 0.2309, Accuracy: 0.2812\n","Epoch 61, Train Loss: 14.7498, Val Loss: 7.5699, F1 Micro: 0.1979, F1 Macro: 0.1487, Accuracy: 0.1979\n","Epoch 62, Train Loss: 6.5576, Val Loss: 9.6849, F1 Micro: 0.2917, F1 Macro: 0.2201, Accuracy: 0.2917\n","Epoch 63, Train Loss: 12.1592, Val Loss: 9.0222, F1 Micro: 0.3021, F1 Macro: 0.2338, Accuracy: 0.3021\n","Epoch 64, Train Loss: 12.2065, Val Loss: 9.0322, F1 Micro: 0.3542, F1 Macro: 0.2730, Accuracy: 0.3542\n","Epoch 65, Train Loss: 9.3431, Val Loss: 17.0296, F1 Micro: 0.2396, F1 Macro: 0.1699, Accuracy: 0.2396\n","Epoch 66, Train Loss: 9.8147, Val Loss: 10.2667, F1 Micro: 0.3438, F1 Macro: 0.2436, Accuracy: 0.3438\n","Epoch 67, Train Loss: 11.5754, Val Loss: 11.4023, F1 Micro: 0.2917, F1 Macro: 0.1956, Accuracy: 0.2917\n","Epoch 68, Train Loss: 16.7001, Val Loss: 12.4689, F1 Micro: 0.2812, F1 Macro: 0.1988, Accuracy: 0.2812\n","Epoch 69, Train Loss: 10.2379, Val Loss: 8.3792, F1 Micro: 0.3750, F1 Macro: 0.2913, Accuracy: 0.3750\n","Epoch 70, Train Loss: 9.3856, Val Loss: 5.5354, F1 Micro: 0.1771, F1 Macro: 0.1261, Accuracy: 0.1771\n","Epoch 71, Train Loss: 9.4316, Val Loss: 9.7034, F1 Micro: 0.4375, F1 Macro: 0.3594, Accuracy: 0.4375\n","Epoch 72, Train Loss: 8.9729, Val Loss: 9.7819, F1 Micro: 0.2292, F1 Macro: 0.1260, Accuracy: 0.2292\n","Epoch 73, Train Loss: 10.5965, Val Loss: 6.6274, F1 Micro: 0.2188, F1 Macro: 0.1924, Accuracy: 0.2188\n","Epoch 74, Train Loss: 8.1286, Val Loss: 10.6575, F1 Micro: 0.2083, F1 Macro: 0.1043, Accuracy: 0.2083\n","Epoch 75, Train Loss: 9.6499, Val Loss: 14.2761, F1 Micro: 0.2917, F1 Macro: 0.1906, Accuracy: 0.2917\n","Epoch 76, Train Loss: 8.5462, Val Loss: 15.1222, F1 Micro: 0.1979, F1 Macro: 0.1272, Accuracy: 0.1979\n","Epoch 77, Train Loss: 9.1758, Val Loss: 13.4853, F1 Micro: 0.1458, F1 Macro: 0.0621, Accuracy: 0.1458\n","Epoch 78, Train Loss: 8.9511, Val Loss: 12.7914, F1 Micro: 0.1875, F1 Macro: 0.1158, Accuracy: 0.1875\n","Epoch 79, Train Loss: 8.7417, Val Loss: 5.5355, F1 Micro: 0.3958, F1 Macro: 0.3364, Accuracy: 0.3958\n","Epoch 80, Train Loss: 10.5675, Val Loss: 10.4785, F1 Micro: 0.3229, F1 Macro: 0.2108, Accuracy: 0.3229\n","Epoch 81, Train Loss: 8.8451, Val Loss: 9.0851, F1 Micro: 0.3646, F1 Macro: 0.2845, Accuracy: 0.3646\n","Epoch 82, Train Loss: 10.2353, Val Loss: 11.9318, F1 Micro: 0.1771, F1 Macro: 0.1344, Accuracy: 0.1771\n","Epoch 83, Train Loss: 7.9395, Val Loss: 4.1582, F1 Micro: 0.3125, F1 Macro: 0.2863, Accuracy: 0.3125\n","Epoch 84, Train Loss: 6.9312, Val Loss: 10.2462, F1 Micro: 0.1562, F1 Macro: 0.1030, Accuracy: 0.1562\n","Epoch 85, Train Loss: 11.1443, Val Loss: 13.2561, F1 Micro: 0.1875, F1 Macro: 0.1474, Accuracy: 0.1875\n","Epoch 86, Train Loss: 9.6120, Val Loss: 14.0271, F1 Micro: 0.2917, F1 Macro: 0.1996, Accuracy: 0.2917\n","Epoch 87, Train Loss: 11.4415, Val Loss: 15.7678, F1 Micro: 0.1562, F1 Macro: 0.1264, Accuracy: 0.1562\n","Epoch 88, Train Loss: 10.5278, Val Loss: 4.3842, F1 Micro: 0.3125, F1 Macro: 0.2777, Accuracy: 0.3125\n","Epoch 89, Train Loss: 8.3543, Val Loss: 6.8897, F1 Micro: 0.2604, F1 Macro: 0.2253, Accuracy: 0.2604\n","Epoch 90, Train Loss: 8.3114, Val Loss: 6.0393, F1 Micro: 0.4375, F1 Macro: 0.3405, Accuracy: 0.4375\n","Epoch 91, Train Loss: 8.8045, Val Loss: 4.3946, F1 Micro: 0.4062, F1 Macro: 0.3603, Accuracy: 0.4062\n","Epoch 92, Train Loss: 8.6828, Val Loss: 11.2217, F1 Micro: 0.1979, F1 Macro: 0.1504, Accuracy: 0.1979\n","Epoch 93, Train Loss: 10.6107, Val Loss: 10.7740, F1 Micro: 0.2812, F1 Macro: 0.2420, Accuracy: 0.2812\n","Epoch 94, Train Loss: 8.3126, Val Loss: 4.4234, F1 Micro: 0.3854, F1 Macro: 0.3371, Accuracy: 0.3854\n","Epoch 95, Train Loss: 6.6804, Val Loss: 3.1439, F1 Micro: 0.3229, F1 Macro: 0.2452, Accuracy: 0.3229\n","Epoch 96, Train Loss: 6.6286, Val Loss: 11.7009, F1 Micro: 0.1667, F1 Macro: 0.1361, Accuracy: 0.1667\n","Epoch 97, Train Loss: 9.0324, Val Loss: 10.3879, F1 Micro: 0.2292, F1 Macro: 0.1717, Accuracy: 0.2292\n","Epoch 98, Train Loss: 7.0947, Val Loss: 5.4029, F1 Micro: 0.2708, F1 Macro: 0.2220, Accuracy: 0.2708\n","Epoch 99, Train Loss: 5.8293, Val Loss: 5.5758, F1 Micro: 0.2500, F1 Macro: 0.2148, Accuracy: 0.2500\n","Epoch 100, Train Loss: 9.4006, Val Loss: 8.2608, F1 Micro: 0.2812, F1 Macro: 0.1870, Accuracy: 0.2812\n","Epoch 101, Train Loss: 7.7319, Val Loss: 15.3351, F1 Micro: 0.1979, F1 Macro: 0.1135, Accuracy: 0.1979\n","Epoch 102, Train Loss: 10.6110, Val Loss: 4.7605, F1 Micro: 0.3438, F1 Macro: 0.2551, Accuracy: 0.3438\n","Epoch 103, Train Loss: 6.5899, Val Loss: 5.4147, F1 Micro: 0.3229, F1 Macro: 0.2620, Accuracy: 0.3229\n","Epoch 104, Train Loss: 5.8403, Val Loss: 5.4133, F1 Micro: 0.2812, F1 Macro: 0.2611, Accuracy: 0.2812\n","Epoch 105, Train Loss: 6.6711, Val Loss: 5.2070, F1 Micro: 0.2604, F1 Macro: 0.2171, Accuracy: 0.2604\n","Epoch 106, Train Loss: 6.8137, Val Loss: 5.2800, F1 Micro: 0.3438, F1 Macro: 0.2846, Accuracy: 0.3438\n","Epoch 107, Train Loss: 6.2938, Val Loss: 7.9918, F1 Micro: 0.2396, F1 Macro: 0.1569, Accuracy: 0.2396\n","Epoch 108, Train Loss: 7.6075, Val Loss: 4.8390, F1 Micro: 0.1875, F1 Macro: 0.1419, Accuracy: 0.1875\n","Epoch 109, Train Loss: 6.5891, Val Loss: 8.2435, F1 Micro: 0.3021, F1 Macro: 0.2188, Accuracy: 0.3021\n","Epoch 110, Train Loss: 6.1545, Val Loss: 6.2230, F1 Micro: 0.1875, F1 Macro: 0.1768, Accuracy: 0.1875\n","Epoch 111, Train Loss: 6.1108, Val Loss: 3.8733, F1 Micro: 0.3229, F1 Macro: 0.2865, Accuracy: 0.3229\n","Epoch 112, Train Loss: 5.0929, Val Loss: 7.4105, F1 Micro: 0.1979, F1 Macro: 0.1183, Accuracy: 0.1979\n","Epoch 113, Train Loss: 5.4541, Val Loss: 4.7097, F1 Micro: 0.2396, F1 Macro: 0.1573, Accuracy: 0.2396\n","Epoch 114, Train Loss: 6.0879, Val Loss: 5.7763, F1 Micro: 0.2396, F1 Macro: 0.1905, Accuracy: 0.2396\n","Epoch 115, Train Loss: 6.1571, Val Loss: 6.9834, F1 Micro: 0.3125, F1 Macro: 0.2662, Accuracy: 0.3125\n","Epoch 116, Train Loss: 7.5424, Val Loss: 7.8040, F1 Micro: 0.2812, F1 Macro: 0.1610, Accuracy: 0.2812\n","Epoch 117, Train Loss: 6.2760, Val Loss: 4.7506, F1 Micro: 0.2500, F1 Macro: 0.1741, Accuracy: 0.2500\n","Epoch 118, Train Loss: 6.2197, Val Loss: 4.1761, F1 Micro: 0.2396, F1 Macro: 0.2018, Accuracy: 0.2396\n","Epoch 119, Train Loss: 6.1171, Val Loss: 6.7188, F1 Micro: 0.1562, F1 Macro: 0.1342, Accuracy: 0.1562\n","Epoch 120, Train Loss: 6.2351, Val Loss: 3.2208, F1 Micro: 0.4167, F1 Macro: 0.3541, Accuracy: 0.4167\n","Epoch 121, Train Loss: 5.8411, Val Loss: 5.6997, F1 Micro: 0.2604, F1 Macro: 0.2155, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 55.2920, Val Loss: 21.1272, F1 Micro: 0.1771, F1 Macro: 0.0998, Accuracy: 0.1771\n","Epoch 2, Train Loss: 26.1236, Val Loss: 24.1991, F1 Micro: 0.2188, F1 Macro: 0.1122, Accuracy: 0.2188\n","Epoch 3, Train Loss: 28.1116, Val Loss: 21.1056, F1 Micro: 0.2292, F1 Macro: 0.1519, Accuracy: 0.2292\n","Epoch 4, Train Loss: 24.7485, Val Loss: 33.8713, F1 Micro: 0.1771, F1 Macro: 0.0749, Accuracy: 0.1771\n","Epoch 5, Train Loss: 26.7743, Val Loss: 15.3292, F1 Micro: 0.1771, F1 Macro: 0.1264, Accuracy: 0.1771\n","Epoch 6, Train Loss: 14.2868, Val Loss: 19.0496, F1 Micro: 0.1979, F1 Macro: 0.1176, Accuracy: 0.1979\n","Epoch 7, Train Loss: 20.7632, Val Loss: 26.7208, F1 Micro: 0.2708, F1 Macro: 0.1327, Accuracy: 0.2708\n","Epoch 8, Train Loss: 19.1370, Val Loss: 34.4096, F1 Micro: 0.1667, F1 Macro: 0.0752, Accuracy: 0.1667\n","Epoch 9, Train Loss: 32.0949, Val Loss: 44.0792, F1 Micro: 0.2188, F1 Macro: 0.1058, Accuracy: 0.2188\n","Epoch 10, Train Loss: 30.5692, Val Loss: 18.8912, F1 Micro: 0.2604, F1 Macro: 0.2045, Accuracy: 0.2604\n","Epoch 11, Train Loss: 21.3423, Val Loss: 22.7906, F1 Micro: 0.2188, F1 Macro: 0.1411, Accuracy: 0.2188\n","Epoch 12, Train Loss: 23.0292, Val Loss: 19.8159, F1 Micro: 0.2083, F1 Macro: 0.1500, Accuracy: 0.2083\n","Epoch 13, Train Loss: 16.9055, Val Loss: 12.1020, F1 Micro: 0.2500, F1 Macro: 0.1140, Accuracy: 0.2500\n","Epoch 14, Train Loss: 22.1148, Val Loss: 20.4586, F1 Micro: 0.2708, F1 Macro: 0.1713, Accuracy: 0.2708\n","Epoch 15, Train Loss: 19.8712, Val Loss: 14.0065, F1 Micro: 0.1771, F1 Macro: 0.0865, Accuracy: 0.1771\n","Epoch 16, Train Loss: 16.3417, Val Loss: 10.7092, F1 Micro: 0.3021, F1 Macro: 0.2341, Accuracy: 0.3021\n","Epoch 17, Train Loss: 18.2423, Val Loss: 31.5316, F1 Micro: 0.2292, F1 Macro: 0.1905, Accuracy: 0.2292\n","Epoch 18, Train Loss: 24.0969, Val Loss: 26.6681, F1 Micro: 0.2292, F1 Macro: 0.1376, Accuracy: 0.2292\n","Epoch 19, Train Loss: 22.7990, Val Loss: 19.0715, F1 Micro: 0.1771, F1 Macro: 0.1555, Accuracy: 0.1771\n","Epoch 20, Train Loss: 21.6890, Val Loss: 20.2364, F1 Micro: 0.2083, F1 Macro: 0.1478, Accuracy: 0.2083\n","Epoch 21, Train Loss: 16.7030, Val Loss: 14.3530, F1 Micro: 0.3438, F1 Macro: 0.2560, Accuracy: 0.3438\n","Epoch 22, Train Loss: 15.6165, Val Loss: 16.5165, F1 Micro: 0.2083, F1 Macro: 0.0776, Accuracy: 0.2083\n","Epoch 23, Train Loss: 16.4544, Val Loss: 20.4750, F1 Micro: 0.2500, F1 Macro: 0.1917, Accuracy: 0.2500\n","Epoch 24, Train Loss: 12.6642, Val Loss: 12.4547, F1 Micro: 0.3125, F1 Macro: 0.1963, Accuracy: 0.3125\n","Epoch 25, Train Loss: 14.5254, Val Loss: 22.9489, F1 Micro: 0.3229, F1 Macro: 0.2160, Accuracy: 0.3229\n","Epoch 26, Train Loss: 15.4145, Val Loss: 31.2365, F1 Micro: 0.1771, F1 Macro: 0.1127, Accuracy: 0.1771\n","Epoch 27, Train Loss: 20.4083, Val Loss: 28.0285, F1 Micro: 0.2604, F1 Macro: 0.1847, Accuracy: 0.2604\n","Epoch 28, Train Loss: 21.5840, Val Loss: 25.1478, F1 Micro: 0.2500, F1 Macro: 0.1474, Accuracy: 0.2500\n","Epoch 29, Train Loss: 17.5973, Val Loss: 38.8184, F1 Micro: 0.1458, F1 Macro: 0.0449, Accuracy: 0.1458\n","Epoch 30, Train Loss: 18.9660, Val Loss: 13.4435, F1 Micro: 0.2812, F1 Macro: 0.2140, Accuracy: 0.2812\n","Epoch 31, Train Loss: 16.0850, Val Loss: 15.7177, F1 Micro: 0.2292, F1 Macro: 0.1965, Accuracy: 0.2292\n","Epoch 32, Train Loss: 13.4977, Val Loss: 9.3308, F1 Micro: 0.3021, F1 Macro: 0.2108, Accuracy: 0.3021\n","Epoch 33, Train Loss: 16.7212, Val Loss: 9.5567, F1 Micro: 0.3125, F1 Macro: 0.2822, Accuracy: 0.3125\n","Epoch 34, Train Loss: 15.7482, Val Loss: 15.7508, F1 Micro: 0.2292, F1 Macro: 0.1682, Accuracy: 0.2292\n","Epoch 35, Train Loss: 11.6507, Val Loss: 18.4552, F1 Micro: 0.2292, F1 Macro: 0.1105, Accuracy: 0.2292\n","Epoch 36, Train Loss: 16.3484, Val Loss: 17.9259, F1 Micro: 0.2812, F1 Macro: 0.1599, Accuracy: 0.2812\n","Epoch 37, Train Loss: 14.1072, Val Loss: 17.9285, F1 Micro: 0.2188, F1 Macro: 0.1457, Accuracy: 0.2188\n","Epoch 38, Train Loss: 11.8191, Val Loss: 11.4797, F1 Micro: 0.2500, F1 Macro: 0.1732, Accuracy: 0.2500\n","Epoch 39, Train Loss: 15.2112, Val Loss: 8.1305, F1 Micro: 0.3021, F1 Macro: 0.2409, Accuracy: 0.3021\n","Epoch 40, Train Loss: 13.6652, Val Loss: 11.1311, F1 Micro: 0.1875, F1 Macro: 0.1676, Accuracy: 0.1875\n","Epoch 41, Train Loss: 12.2718, Val Loss: 11.6443, F1 Micro: 0.2292, F1 Macro: 0.1700, Accuracy: 0.2292\n","Epoch 42, Train Loss: 11.8857, Val Loss: 11.3603, F1 Micro: 0.2396, F1 Macro: 0.2176, Accuracy: 0.2396\n","Epoch 43, Train Loss: 14.0115, Val Loss: 13.8821, F1 Micro: 0.3125, F1 Macro: 0.2569, Accuracy: 0.3125\n","Epoch 44, Train Loss: 14.2189, Val Loss: 12.1266, F1 Micro: 0.1354, F1 Macro: 0.0413, Accuracy: 0.1354\n","Epoch 45, Train Loss: 13.2478, Val Loss: 12.8136, F1 Micro: 0.2917, F1 Macro: 0.1799, Accuracy: 0.2917\n","Epoch 46, Train Loss: 8.5648, Val Loss: 9.0440, F1 Micro: 0.2188, F1 Macro: 0.1887, Accuracy: 0.2188\n","Epoch 47, Train Loss: 9.6437, Val Loss: 8.2000, F1 Micro: 0.2917, F1 Macro: 0.2703, Accuracy: 0.2917\n","Epoch 48, Train Loss: 17.6287, Val Loss: 10.6564, F1 Micro: 0.3646, F1 Macro: 0.3147, Accuracy: 0.3646\n","Epoch 49, Train Loss: 12.1239, Val Loss: 13.7417, F1 Micro: 0.3021, F1 Macro: 0.1913, Accuracy: 0.3021\n","Epoch 50, Train Loss: 11.7463, Val Loss: 22.1137, F1 Micro: 0.1667, F1 Macro: 0.1245, Accuracy: 0.1667\n","Epoch 51, Train Loss: 11.6414, Val Loss: 10.7324, F1 Micro: 0.2292, F1 Macro: 0.1721, Accuracy: 0.2292\n","Epoch 52, Train Loss: 14.3841, Val Loss: 14.8940, F1 Micro: 0.2500, F1 Macro: 0.1573, Accuracy: 0.2500\n","Epoch 53, Train Loss: 13.7721, Val Loss: 22.2145, F1 Micro: 0.2396, F1 Macro: 0.1538, Accuracy: 0.2396\n","Epoch 54, Train Loss: 12.6279, Val Loss: 16.1270, F1 Micro: 0.1979, F1 Macro: 0.1564, Accuracy: 0.1979\n","Epoch 55, Train Loss: 12.1290, Val Loss: 11.3458, F1 Micro: 0.2188, F1 Macro: 0.1381, Accuracy: 0.2188\n","Epoch 56, Train Loss: 11.3409, Val Loss: 4.4904, F1 Micro: 0.3333, F1 Macro: 0.3206, Accuracy: 0.3333\n","Epoch 57, Train Loss: 18.6683, Val Loss: 10.9973, F1 Micro: 0.2396, F1 Macro: 0.1820, Accuracy: 0.2396\n","Epoch 58, Train Loss: 11.2501, Val Loss: 13.0441, F1 Micro: 0.2708, F1 Macro: 0.2110, Accuracy: 0.2708\n","Epoch 59, Train Loss: 16.6026, Val Loss: 11.0427, F1 Micro: 0.2604, F1 Macro: 0.1708, Accuracy: 0.2604\n","Epoch 60, Train Loss: 10.5013, Val Loss: 8.9910, F1 Micro: 0.3125, F1 Macro: 0.2192, Accuracy: 0.3125\n","Epoch 61, Train Loss: 9.5030, Val Loss: 6.2700, F1 Micro: 0.2500, F1 Macro: 0.1918, Accuracy: 0.2500\n","Epoch 62, Train Loss: 10.1887, Val Loss: 10.5158, F1 Micro: 0.3333, F1 Macro: 0.1908, Accuracy: 0.3333\n","Epoch 63, Train Loss: 10.6888, Val Loss: 10.1370, F1 Micro: 0.2812, F1 Macro: 0.2565, Accuracy: 0.2812\n","Epoch 64, Train Loss: 12.4820, Val Loss: 13.3792, F1 Micro: 0.3229, F1 Macro: 0.2581, Accuracy: 0.3229\n","Epoch 65, Train Loss: 9.7847, Val Loss: 11.4809, F1 Micro: 0.2292, F1 Macro: 0.1686, Accuracy: 0.2292\n","Epoch 66, Train Loss: 10.2611, Val Loss: 10.3680, F1 Micro: 0.2917, F1 Macro: 0.1722, Accuracy: 0.2917\n","Epoch 67, Train Loss: 12.1231, Val Loss: 16.3745, F1 Micro: 0.2083, F1 Macro: 0.1507, Accuracy: 0.2083\n","Epoch 68, Train Loss: 10.6218, Val Loss: 13.1916, F1 Micro: 0.3438, F1 Macro: 0.2736, Accuracy: 0.3438\n","Epoch 69, Train Loss: 6.6338, Val Loss: 7.7354, F1 Micro: 0.2500, F1 Macro: 0.1893, Accuracy: 0.2500\n","Epoch 70, Train Loss: 9.1686, Val Loss: 7.7437, F1 Micro: 0.2083, F1 Macro: 0.1524, Accuracy: 0.2083\n","Epoch 71, Train Loss: 8.3576, Val Loss: 15.2797, F1 Micro: 0.2188, F1 Macro: 0.1320, Accuracy: 0.2188\n","Epoch 72, Train Loss: 11.4356, Val Loss: 10.5523, F1 Micro: 0.2500, F1 Macro: 0.1571, Accuracy: 0.2500\n","Epoch 73, Train Loss: 9.2685, Val Loss: 11.9389, F1 Micro: 0.2708, F1 Macro: 0.1850, Accuracy: 0.2708\n","Epoch 74, Train Loss: 10.4429, Val Loss: 6.2909, F1 Micro: 0.2812, F1 Macro: 0.2023, Accuracy: 0.2812\n","Epoch 75, Train Loss: 8.0893, Val Loss: 5.2452, F1 Micro: 0.3750, F1 Macro: 0.3642, Accuracy: 0.3750\n","Epoch 76, Train Loss: 11.1893, Val Loss: 15.4049, F1 Micro: 0.2292, F1 Macro: 0.0896, Accuracy: 0.2292\n","Epoch 77, Train Loss: 13.6277, Val Loss: 4.3009, F1 Micro: 0.2812, F1 Macro: 0.1984, Accuracy: 0.2812\n","Epoch 78, Train Loss: 6.8577, Val Loss: 4.4593, F1 Micro: 0.2917, F1 Macro: 0.1963, Accuracy: 0.2917\n","Epoch 79, Train Loss: 7.7281, Val Loss: 8.6197, F1 Micro: 0.2604, F1 Macro: 0.1929, Accuracy: 0.2604\n","Epoch 80, Train Loss: 10.6274, Val Loss: 7.8452, F1 Micro: 0.1979, F1 Macro: 0.1354, Accuracy: 0.1979\n","Epoch 81, Train Loss: 7.2553, Val Loss: 14.6376, F1 Micro: 0.3438, F1 Macro: 0.3077, Accuracy: 0.3438\n","Epoch 82, Train Loss: 6.7171, Val Loss: 5.0346, F1 Micro: 0.2604, F1 Macro: 0.2460, Accuracy: 0.2604\n","Epoch 83, Train Loss: 6.2996, Val Loss: 6.5718, F1 Micro: 0.3125, F1 Macro: 0.2323, Accuracy: 0.3125\n","Epoch 84, Train Loss: 9.8382, Val Loss: 8.8186, F1 Micro: 0.2604, F1 Macro: 0.2119, Accuracy: 0.2604\n","Epoch 85, Train Loss: 6.0754, Val Loss: 8.5231, F1 Micro: 0.3438, F1 Macro: 0.2840, Accuracy: 0.3438\n","Epoch 86, Train Loss: 6.2895, Val Loss: 4.0417, F1 Micro: 0.3542, F1 Macro: 0.2855, Accuracy: 0.3542\n","Epoch 87, Train Loss: 5.7047, Val Loss: 9.5538, F1 Micro: 0.2396, F1 Macro: 0.1692, Accuracy: 0.2396\n","Epoch 88, Train Loss: 9.2265, Val Loss: 7.6204, F1 Micro: 0.2812, F1 Macro: 0.2531, Accuracy: 0.2812\n","Epoch 89, Train Loss: 11.5059, Val Loss: 8.4926, F1 Micro: 0.2604, F1 Macro: 0.1224, Accuracy: 0.2604\n","Epoch 90, Train Loss: 9.0783, Val Loss: 7.2335, F1 Micro: 0.2604, F1 Macro: 0.1869, Accuracy: 0.2604\n","Epoch 91, Train Loss: 6.6031, Val Loss: 7.1244, F1 Micro: 0.1771, F1 Macro: 0.1554, Accuracy: 0.1771\n","Epoch 92, Train Loss: 5.7777, Val Loss: 6.1648, F1 Micro: 0.2396, F1 Macro: 0.1613, Accuracy: 0.2396\n","Epoch 93, Train Loss: 5.9848, Val Loss: 5.1311, F1 Micro: 0.2604, F1 Macro: 0.1957, Accuracy: 0.2604\n","Epoch 94, Train Loss: 7.5381, Val Loss: 6.2091, F1 Micro: 0.2188, F1 Macro: 0.1443, Accuracy: 0.2188\n","Epoch 95, Train Loss: 8.0139, Val Loss: 10.3779, F1 Micro: 0.3021, F1 Macro: 0.2573, Accuracy: 0.3021\n","Epoch 96, Train Loss: 6.3846, Val Loss: 7.1906, F1 Micro: 0.2604, F1 Macro: 0.1353, Accuracy: 0.2604\n","Epoch 97, Train Loss: 8.3428, Val Loss: 5.8820, F1 Micro: 0.2604, F1 Macro: 0.1927, Accuracy: 0.2604\n","Epoch 98, Train Loss: 9.0396, Val Loss: 7.4602, F1 Micro: 0.3229, F1 Macro: 0.2977, Accuracy: 0.3229\n","Epoch 99, Train Loss: 5.7857, Val Loss: 7.9176, F1 Micro: 0.2708, F1 Macro: 0.1925, Accuracy: 0.2708\n","Epoch 100, Train Loss: 8.7580, Val Loss: 15.9768, F1 Micro: 0.1667, F1 Macro: 0.0860, Accuracy: 0.1667\n","Epoch 101, Train Loss: 8.3368, Val Loss: 5.5845, F1 Micro: 0.3021, F1 Macro: 0.2128, Accuracy: 0.3021\n","Epoch 102, Train Loss: 7.1931, Val Loss: 5.5547, F1 Micro: 0.2917, F1 Macro: 0.2358, Accuracy: 0.2917\n","Epoch 103, Train Loss: 7.7757, Val Loss: 5.1624, F1 Micro: 0.3125, F1 Macro: 0.2316, Accuracy: 0.3125\n","Epoch 104, Train Loss: 7.4416, Val Loss: 3.0854, F1 Micro: 0.3750, F1 Macro: 0.3564, Accuracy: 0.3750\n","Epoch 105, Train Loss: 6.3741, Val Loss: 5.4902, F1 Micro: 0.2708, F1 Macro: 0.2017, Accuracy: 0.2708\n","Epoch 106, Train Loss: 5.3495, Val Loss: 4.2987, F1 Micro: 0.3646, F1 Macro: 0.3100, Accuracy: 0.3646\n","Epoch 107, Train Loss: 5.3756, Val Loss: 13.3565, F1 Micro: 0.2292, F1 Macro: 0.1701, Accuracy: 0.2292\n","Epoch 108, Train Loss: 7.6012, Val Loss: 7.3513, F1 Micro: 0.1979, F1 Macro: 0.1389, Accuracy: 0.1979\n","Epoch 109, Train Loss: 5.5336, Val Loss: 3.6943, F1 Micro: 0.3229, F1 Macro: 0.2892, Accuracy: 0.3229\n","Epoch 110, Train Loss: 4.8990, Val Loss: 5.6721, F1 Micro: 0.2708, F1 Macro: 0.2080, Accuracy: 0.2708\n","Epoch 111, Train Loss: 5.1313, Val Loss: 4.3659, F1 Micro: 0.3333, F1 Macro: 0.2677, Accuracy: 0.3333\n","Epoch 112, Train Loss: 5.5640, Val Loss: 5.0236, F1 Micro: 0.2500, F1 Macro: 0.2015, Accuracy: 0.2500\n","Epoch 113, Train Loss: 5.9162, Val Loss: 7.8468, F1 Micro: 0.2500, F1 Macro: 0.1911, Accuracy: 0.2500\n","Epoch 114, Train Loss: 5.4094, Val Loss: 4.9345, F1 Micro: 0.2812, F1 Macro: 0.2499, Accuracy: 0.2812\n","Epoch 115, Train Loss: 4.1402, Val Loss: 3.6373, F1 Micro: 0.3542, F1 Macro: 0.3127, Accuracy: 0.3542\n","Epoch 116, Train Loss: 6.8284, Val Loss: 6.9374, F1 Micro: 0.2500, F1 Macro: 0.1551, Accuracy: 0.2500\n","Epoch 117, Train Loss: 4.6876, Val Loss: 6.9153, F1 Micro: 0.2812, F1 Macro: 0.2140, Accuracy: 0.2812\n","Epoch 118, Train Loss: 5.2976, Val Loss: 6.2591, F1 Micro: 0.3333, F1 Macro: 0.2652, Accuracy: 0.3333\n","Epoch 119, Train Loss: 3.8495, Val Loss: 3.0559, F1 Micro: 0.2708, F1 Macro: 0.2685, Accuracy: 0.2708\n","Epoch 120, Train Loss: 4.1984, Val Loss: 5.8351, F1 Micro: 0.1771, F1 Macro: 0.1572, Accuracy: 0.1771\n","Epoch 121, Train Loss: 5.2475, Val Loss: 4.0531, F1 Micro: 0.3021, F1 Macro: 0.2312, Accuracy: 0.3021\n","Epoch 122, Train Loss: 4.1984, Val Loss: 4.1140, F1 Micro: 0.3125, F1 Macro: 0.2674, Accuracy: 0.3125\n","Epoch 123, Train Loss: 5.4166, Val Loss: 3.0010, F1 Micro: 0.2917, F1 Macro: 0.2832, Accuracy: 0.2917\n","Epoch 124, Train Loss: 4.0712, Val Loss: 3.9128, F1 Micro: 0.2604, F1 Macro: 0.2136, Accuracy: 0.2604\n","Epoch 125, Train Loss: 3.4912, Val Loss: 4.6019, F1 Micro: 0.2812, F1 Macro: 0.2321, Accuracy: 0.2812\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 40.5384, Val Loss: 18.5839, F1 Micro: 0.2083, F1 Macro: 0.0994, Accuracy: 0.2083\n","Epoch 2, Train Loss: 31.0573, Val Loss: 40.2418, F1 Micro: 0.1667, F1 Macro: 0.0832, Accuracy: 0.1667\n","Epoch 3, Train Loss: 30.3133, Val Loss: 31.2502, F1 Micro: 0.2292, F1 Macro: 0.1356, Accuracy: 0.2292\n","Epoch 4, Train Loss: 23.7538, Val Loss: 31.5533, F1 Micro: 0.2188, F1 Macro: 0.1410, Accuracy: 0.2188\n","Epoch 5, Train Loss: 26.7590, Val Loss: 27.0287, F1 Micro: 0.1875, F1 Macro: 0.0854, Accuracy: 0.1875\n","Epoch 6, Train Loss: 31.7418, Val Loss: 59.2603, F1 Micro: 0.1979, F1 Macro: 0.1197, Accuracy: 0.1979\n","Epoch 7, Train Loss: 41.7833, Val Loss: 43.2132, F1 Micro: 0.1667, F1 Macro: 0.0738, Accuracy: 0.1667\n","Epoch 8, Train Loss: 25.1897, Val Loss: 11.3776, F1 Micro: 0.1667, F1 Macro: 0.1221, Accuracy: 0.1667\n","Epoch 9, Train Loss: 10.3428, Val Loss: 18.7543, F1 Micro: 0.2292, F1 Macro: 0.1313, Accuracy: 0.2292\n","Epoch 10, Train Loss: 21.6437, Val Loss: 42.1590, F1 Micro: 0.2188, F1 Macro: 0.1061, Accuracy: 0.2188\n","Epoch 11, Train Loss: 25.7795, Val Loss: 17.5816, F1 Micro: 0.2604, F1 Macro: 0.2079, Accuracy: 0.2604\n","Epoch 12, Train Loss: 17.8827, Val Loss: 29.3876, F1 Micro: 0.1875, F1 Macro: 0.0878, Accuracy: 0.1875\n","Epoch 13, Train Loss: 23.2354, Val Loss: 13.5419, F1 Micro: 0.2188, F1 Macro: 0.1706, Accuracy: 0.2188\n","Epoch 14, Train Loss: 17.2047, Val Loss: 41.0955, F1 Micro: 0.1562, F1 Macro: 0.0621, Accuracy: 0.1562\n","Epoch 15, Train Loss: 23.9999, Val Loss: 18.5444, F1 Micro: 0.2396, F1 Macro: 0.1707, Accuracy: 0.2396\n","Epoch 16, Train Loss: 16.8630, Val Loss: 12.1628, F1 Micro: 0.2083, F1 Macro: 0.1237, Accuracy: 0.2083\n","Epoch 17, Train Loss: 14.9994, Val Loss: 5.8032, F1 Micro: 0.3333, F1 Macro: 0.2804, Accuracy: 0.3333\n","Epoch 18, Train Loss: 19.4040, Val Loss: 23.8746, F1 Micro: 0.2500, F1 Macro: 0.2015, Accuracy: 0.2500\n","Epoch 19, Train Loss: 20.1513, Val Loss: 28.0217, F1 Micro: 0.2396, F1 Macro: 0.1191, Accuracy: 0.2396\n","Epoch 20, Train Loss: 19.2816, Val Loss: 24.7170, F1 Micro: 0.1771, F1 Macro: 0.1318, Accuracy: 0.1771\n","Epoch 21, Train Loss: 21.4454, Val Loss: 34.1523, F1 Micro: 0.1979, F1 Macro: 0.1321, Accuracy: 0.1979\n","Epoch 22, Train Loss: 26.9980, Val Loss: 17.2943, F1 Micro: 0.2292, F1 Macro: 0.1345, Accuracy: 0.2292\n","Epoch 23, Train Loss: 17.3857, Val Loss: 8.9231, F1 Micro: 0.2188, F1 Macro: 0.1659, Accuracy: 0.2188\n","Epoch 24, Train Loss: 18.1396, Val Loss: 21.2183, F1 Micro: 0.2188, F1 Macro: 0.1303, Accuracy: 0.2188\n","Epoch 25, Train Loss: 17.8543, Val Loss: 25.2776, F1 Micro: 0.1562, F1 Macro: 0.0889, Accuracy: 0.1562\n","Epoch 26, Train Loss: 17.5777, Val Loss: 13.6973, F1 Micro: 0.1875, F1 Macro: 0.1473, Accuracy: 0.1875\n","Epoch 27, Train Loss: 18.5404, Val Loss: 26.0130, F1 Micro: 0.1354, F1 Macro: 0.0787, Accuracy: 0.1354\n","Epoch 28, Train Loss: 15.9672, Val Loss: 15.2011, F1 Micro: 0.1979, F1 Macro: 0.0858, Accuracy: 0.1979\n","Epoch 29, Train Loss: 17.2788, Val Loss: 8.9959, F1 Micro: 0.2812, F1 Macro: 0.2318, Accuracy: 0.2812\n","Epoch 30, Train Loss: 13.6296, Val Loss: 9.9449, F1 Micro: 0.2396, F1 Macro: 0.2180, Accuracy: 0.2396\n","Epoch 31, Train Loss: 14.5164, Val Loss: 30.6558, F1 Micro: 0.1458, F1 Macro: 0.0444, Accuracy: 0.1458\n","Epoch 32, Train Loss: 16.8753, Val Loss: 37.6918, F1 Micro: 0.1562, F1 Macro: 0.0662, Accuracy: 0.1562\n","Epoch 33, Train Loss: 19.0811, Val Loss: 14.2945, F1 Micro: 0.2812, F1 Macro: 0.1821, Accuracy: 0.2812\n","Epoch 34, Train Loss: 14.1687, Val Loss: 15.3450, F1 Micro: 0.2604, F1 Macro: 0.1846, Accuracy: 0.2604\n","Epoch 35, Train Loss: 11.1281, Val Loss: 19.5364, F1 Micro: 0.1979, F1 Macro: 0.0896, Accuracy: 0.1979\n","Epoch 36, Train Loss: 14.3998, Val Loss: 9.0822, F1 Micro: 0.2708, F1 Macro: 0.1920, Accuracy: 0.2708\n","Epoch 37, Train Loss: 13.8813, Val Loss: 15.0865, F1 Micro: 0.2292, F1 Macro: 0.1773, Accuracy: 0.2292\n","Epoch 38, Train Loss: 14.3714, Val Loss: 16.7285, F1 Micro: 0.2292, F1 Macro: 0.1345, Accuracy: 0.2292\n","Epoch 39, Train Loss: 18.1468, Val Loss: 10.9497, F1 Micro: 0.2188, F1 Macro: 0.1282, Accuracy: 0.2188\n","Epoch 40, Train Loss: 13.6442, Val Loss: 17.4475, F1 Micro: 0.1562, F1 Macro: 0.0907, Accuracy: 0.1562\n","Epoch 41, Train Loss: 10.1376, Val Loss: 14.6978, F1 Micro: 0.2292, F1 Macro: 0.1827, Accuracy: 0.2292\n","Epoch 42, Train Loss: 12.7605, Val Loss: 10.6983, F1 Micro: 0.1875, F1 Macro: 0.1535, Accuracy: 0.1875\n","Epoch 43, Train Loss: 13.6965, Val Loss: 17.4367, F1 Micro: 0.2396, F1 Macro: 0.1590, Accuracy: 0.2396\n","Epoch 44, Train Loss: 12.3870, Val Loss: 24.2831, F1 Micro: 0.2812, F1 Macro: 0.1637, Accuracy: 0.2812\n","Epoch 45, Train Loss: 16.4719, Val Loss: 12.1345, F1 Micro: 0.2292, F1 Macro: 0.1548, Accuracy: 0.2292\n","Epoch 46, Train Loss: 8.6276, Val Loss: 7.8846, F1 Micro: 0.2292, F1 Macro: 0.1607, Accuracy: 0.2292\n","Epoch 47, Train Loss: 11.3979, Val Loss: 15.1654, F1 Micro: 0.1979, F1 Macro: 0.1437, Accuracy: 0.1979\n","Epoch 48, Train Loss: 11.0580, Val Loss: 19.7616, F1 Micro: 0.2292, F1 Macro: 0.1559, Accuracy: 0.2292\n","Epoch 49, Train Loss: 16.1797, Val Loss: 15.2962, F1 Micro: 0.2812, F1 Macro: 0.1699, Accuracy: 0.2812\n","Epoch 50, Train Loss: 10.3942, Val Loss: 13.4150, F1 Micro: 0.2188, F1 Macro: 0.1520, Accuracy: 0.2188\n","Epoch 51, Train Loss: 11.9085, Val Loss: 17.2672, F1 Micro: 0.2083, F1 Macro: 0.1526, Accuracy: 0.2083\n","Epoch 52, Train Loss: 9.7963, Val Loss: 11.8963, F1 Micro: 0.2604, F1 Macro: 0.2024, Accuracy: 0.2604\n","Epoch 53, Train Loss: 11.5229, Val Loss: 14.2412, F1 Micro: 0.1979, F1 Macro: 0.1358, Accuracy: 0.1979\n","Epoch 54, Train Loss: 15.2233, Val Loss: 27.6436, F1 Micro: 0.2188, F1 Macro: 0.1215, Accuracy: 0.2188\n","Epoch 55, Train Loss: 10.7907, Val Loss: 9.7674, F1 Micro: 0.2083, F1 Macro: 0.1432, Accuracy: 0.2083\n","Epoch 56, Train Loss: 10.8588, Val Loss: 15.6944, F1 Micro: 0.2500, F1 Macro: 0.1529, Accuracy: 0.2500\n","Epoch 57, Train Loss: 11.8677, Val Loss: 18.9865, F1 Micro: 0.1979, F1 Macro: 0.1037, Accuracy: 0.1979\n","Epoch 58, Train Loss: 6.3454, Val Loss: 5.3460, F1 Micro: 0.2188, F1 Macro: 0.1785, Accuracy: 0.2188\n","Epoch 59, Train Loss: 9.7634, Val Loss: 10.5396, F1 Micro: 0.2292, F1 Macro: 0.1787, Accuracy: 0.2292\n","Epoch 60, Train Loss: 9.9256, Val Loss: 10.1385, F1 Micro: 0.1979, F1 Macro: 0.1183, Accuracy: 0.1979\n","Epoch 61, Train Loss: 11.9952, Val Loss: 12.0894, F1 Micro: 0.2396, F1 Macro: 0.1952, Accuracy: 0.2396\n","Epoch 62, Train Loss: 10.8144, Val Loss: 21.6029, F1 Micro: 0.2812, F1 Macro: 0.1759, Accuracy: 0.2812\n","Epoch 63, Train Loss: 8.9431, Val Loss: 9.4062, F1 Micro: 0.2917, F1 Macro: 0.2420, Accuracy: 0.2917\n","Epoch 64, Train Loss: 8.2929, Val Loss: 9.1053, F1 Micro: 0.2917, F1 Macro: 0.2290, Accuracy: 0.2917\n","Epoch 65, Train Loss: 7.3525, Val Loss: 11.1016, F1 Micro: 0.2812, F1 Macro: 0.1997, Accuracy: 0.2812\n","Epoch 66, Train Loss: 9.4771, Val Loss: 11.3430, F1 Micro: 0.1771, F1 Macro: 0.1181, Accuracy: 0.1771\n","Epoch 67, Train Loss: 9.5820, Val Loss: 12.1642, F1 Micro: 0.2083, F1 Macro: 0.1448, Accuracy: 0.2083\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 38.5491, Val Loss: 17.3838, F1 Micro: 0.2500, F1 Macro: 0.1830, Accuracy: 0.2500\n","Epoch 2, Train Loss: 26.4099, Val Loss: 37.2213, F1 Micro: 0.2500, F1 Macro: 0.1658, Accuracy: 0.2500\n","Epoch 3, Train Loss: 29.6766, Val Loss: 15.2942, F1 Micro: 0.1771, F1 Macro: 0.1428, Accuracy: 0.1771\n","Epoch 4, Train Loss: 32.0053, Val Loss: 19.5997, F1 Micro: 0.2812, F1 Macro: 0.1703, Accuracy: 0.2812\n","Epoch 5, Train Loss: 27.6272, Val Loss: 29.9992, F1 Micro: 0.2708, F1 Macro: 0.1802, Accuracy: 0.2708\n","Epoch 6, Train Loss: 20.7476, Val Loss: 28.2355, F1 Micro: 0.2500, F1 Macro: 0.1768, Accuracy: 0.2500\n","Epoch 7, Train Loss: 17.2337, Val Loss: 37.1102, F1 Micro: 0.2188, F1 Macro: 0.1344, Accuracy: 0.2188\n","Epoch 8, Train Loss: 18.7533, Val Loss: 20.4596, F1 Micro: 0.1771, F1 Macro: 0.0925, Accuracy: 0.1771\n","Epoch 9, Train Loss: 19.6865, Val Loss: 20.3954, F1 Micro: 0.1979, F1 Macro: 0.1118, Accuracy: 0.1979\n","Epoch 10, Train Loss: 21.4419, Val Loss: 37.7181, F1 Micro: 0.2188, F1 Macro: 0.1291, Accuracy: 0.2188\n","Epoch 11, Train Loss: 32.8548, Val Loss: 26.3004, F1 Micro: 0.1667, F1 Macro: 0.0726, Accuracy: 0.1667\n","Epoch 12, Train Loss: 24.4236, Val Loss: 34.4965, F1 Micro: 0.1875, F1 Macro: 0.1398, Accuracy: 0.1875\n","Epoch 13, Train Loss: 25.3230, Val Loss: 30.7144, F1 Micro: 0.3021, F1 Macro: 0.1930, Accuracy: 0.3021\n","Epoch 14, Train Loss: 19.3644, Val Loss: 11.8617, F1 Micro: 0.2917, F1 Macro: 0.2255, Accuracy: 0.2917\n","Epoch 15, Train Loss: 19.5423, Val Loss: 37.9507, F1 Micro: 0.2083, F1 Macro: 0.1414, Accuracy: 0.2083\n","Epoch 16, Train Loss: 20.7078, Val Loss: 19.3116, F1 Micro: 0.2604, F1 Macro: 0.1818, Accuracy: 0.2604\n","Epoch 17, Train Loss: 20.6734, Val Loss: 15.9810, F1 Micro: 0.2500, F1 Macro: 0.1718, Accuracy: 0.2500\n","Epoch 18, Train Loss: 17.2253, Val Loss: 37.7793, F1 Micro: 0.2083, F1 Macro: 0.1103, Accuracy: 0.2083\n","Epoch 19, Train Loss: 16.8957, Val Loss: 20.7070, F1 Micro: 0.1875, F1 Macro: 0.1092, Accuracy: 0.1875\n","Epoch 20, Train Loss: 15.8637, Val Loss: 5.7835, F1 Micro: 0.2708, F1 Macro: 0.2635, Accuracy: 0.2708\n","Epoch 21, Train Loss: 11.7477, Val Loss: 19.3069, F1 Micro: 0.1875, F1 Macro: 0.0885, Accuracy: 0.1875\n","Epoch 22, Train Loss: 21.9009, Val Loss: 25.1828, F1 Micro: 0.3333, F1 Macro: 0.2641, Accuracy: 0.3333\n","Epoch 23, Train Loss: 15.8746, Val Loss: 21.9873, F1 Micro: 0.2396, F1 Macro: 0.1459, Accuracy: 0.2396\n","Epoch 24, Train Loss: 14.9928, Val Loss: 14.1933, F1 Micro: 0.2500, F1 Macro: 0.1817, Accuracy: 0.2500\n","Epoch 25, Train Loss: 15.5462, Val Loss: 15.8970, F1 Micro: 0.1979, F1 Macro: 0.1423, Accuracy: 0.1979\n","Epoch 26, Train Loss: 17.8286, Val Loss: 20.6209, F1 Micro: 0.3021, F1 Macro: 0.2507, Accuracy: 0.3021\n","Epoch 27, Train Loss: 16.4491, Val Loss: 14.8428, F1 Micro: 0.2083, F1 Macro: 0.1380, Accuracy: 0.2083\n","Epoch 28, Train Loss: 14.0294, Val Loss: 9.0704, F1 Micro: 0.2812, F1 Macro: 0.2276, Accuracy: 0.2812\n","Epoch 29, Train Loss: 16.8564, Val Loss: 20.1706, F1 Micro: 0.2604, F1 Macro: 0.1351, Accuracy: 0.2604\n","Epoch 30, Train Loss: 18.5238, Val Loss: 22.1398, F1 Micro: 0.3542, F1 Macro: 0.2385, Accuracy: 0.3542\n","Epoch 31, Train Loss: 23.0986, Val Loss: 23.4188, F1 Micro: 0.2917, F1 Macro: 0.2213, Accuracy: 0.2917\n","Epoch 32, Train Loss: 14.7319, Val Loss: 15.8305, F1 Micro: 0.2292, F1 Macro: 0.1741, Accuracy: 0.2292\n","Epoch 33, Train Loss: 13.0124, Val Loss: 10.9356, F1 Micro: 0.2812, F1 Macro: 0.2260, Accuracy: 0.2812\n","Epoch 34, Train Loss: 15.2955, Val Loss: 15.4455, F1 Micro: 0.1979, F1 Macro: 0.1178, Accuracy: 0.1979\n","Epoch 35, Train Loss: 16.5690, Val Loss: 11.2116, F1 Micro: 0.2812, F1 Macro: 0.1936, Accuracy: 0.2812\n","Epoch 36, Train Loss: 12.8303, Val Loss: 20.6952, F1 Micro: 0.2604, F1 Macro: 0.2097, Accuracy: 0.2604\n","Epoch 37, Train Loss: 13.9075, Val Loss: 10.0658, F1 Micro: 0.2604, F1 Macro: 0.1812, Accuracy: 0.2604\n","Epoch 38, Train Loss: 11.4236, Val Loss: 11.6774, F1 Micro: 0.2812, F1 Macro: 0.2050, Accuracy: 0.2812\n","Epoch 39, Train Loss: 20.8473, Val Loss: 20.1700, F1 Micro: 0.2396, F1 Macro: 0.1166, Accuracy: 0.2396\n","Epoch 40, Train Loss: 15.4138, Val Loss: 17.6055, F1 Micro: 0.2188, F1 Macro: 0.1381, Accuracy: 0.2188\n","Epoch 41, Train Loss: 18.6454, Val Loss: 13.5867, F1 Micro: 0.2396, F1 Macro: 0.1736, Accuracy: 0.2396\n","Epoch 42, Train Loss: 12.7787, Val Loss: 12.3944, F1 Micro: 0.2500, F1 Macro: 0.1341, Accuracy: 0.2500\n","Epoch 43, Train Loss: 12.9118, Val Loss: 7.8152, F1 Micro: 0.3958, F1 Macro: 0.3435, Accuracy: 0.3958\n","Epoch 44, Train Loss: 11.4455, Val Loss: 7.7273, F1 Micro: 0.3021, F1 Macro: 0.2163, Accuracy: 0.3021\n","Epoch 45, Train Loss: 10.3316, Val Loss: 12.0492, F1 Micro: 0.1979, F1 Macro: 0.1028, Accuracy: 0.1979\n","Epoch 46, Train Loss: 13.8374, Val Loss: 16.1837, F1 Micro: 0.2708, F1 Macro: 0.1909, Accuracy: 0.2708\n","Epoch 47, Train Loss: 9.9829, Val Loss: 10.3515, F1 Micro: 0.3542, F1 Macro: 0.3088, Accuracy: 0.3542\n","Epoch 48, Train Loss: 14.9632, Val Loss: 17.1685, F1 Micro: 0.2604, F1 Macro: 0.1466, Accuracy: 0.2604\n","Epoch 49, Train Loss: 13.5011, Val Loss: 19.2388, F1 Micro: 0.1875, F1 Macro: 0.1404, Accuracy: 0.1875\n","Epoch 50, Train Loss: 10.4529, Val Loss: 8.3048, F1 Micro: 0.3438, F1 Macro: 0.2864, Accuracy: 0.3438\n","Epoch 51, Train Loss: 15.1643, Val Loss: 13.9214, F1 Micro: 0.2396, F1 Macro: 0.1486, Accuracy: 0.2396\n","Epoch 52, Train Loss: 12.7273, Val Loss: 11.0738, F1 Micro: 0.2500, F1 Macro: 0.1657, Accuracy: 0.2500\n","Epoch 53, Train Loss: 18.8133, Val Loss: 14.2630, F1 Micro: 0.3021, F1 Macro: 0.2522, Accuracy: 0.3021\n","Epoch 54, Train Loss: 13.2420, Val Loss: 13.5954, F1 Micro: 0.3125, F1 Macro: 0.1948, Accuracy: 0.3125\n","Epoch 55, Train Loss: 10.8296, Val Loss: 11.2850, F1 Micro: 0.3021, F1 Macro: 0.2324, Accuracy: 0.3021\n","Epoch 56, Train Loss: 9.1969, Val Loss: 13.3793, F1 Micro: 0.3021, F1 Macro: 0.2524, Accuracy: 0.3021\n","Epoch 57, Train Loss: 14.1801, Val Loss: 6.6597, F1 Micro: 0.3438, F1 Macro: 0.3130, Accuracy: 0.3438\n","Epoch 58, Train Loss: 13.0766, Val Loss: 6.4681, F1 Micro: 0.3750, F1 Macro: 0.3256, Accuracy: 0.3750\n","Epoch 59, Train Loss: 11.7704, Val Loss: 7.1869, F1 Micro: 0.3438, F1 Macro: 0.3332, Accuracy: 0.3438\n","Epoch 60, Train Loss: 11.1508, Val Loss: 12.1037, F1 Micro: 0.2604, F1 Macro: 0.1247, Accuracy: 0.2604\n","Epoch 61, Train Loss: 10.0446, Val Loss: 7.7156, F1 Micro: 0.2812, F1 Macro: 0.2189, Accuracy: 0.2812\n","Epoch 62, Train Loss: 8.8678, Val Loss: 9.5330, F1 Micro: 0.3333, F1 Macro: 0.2480, Accuracy: 0.3333\n","Epoch 63, Train Loss: 10.5964, Val Loss: 12.6833, F1 Micro: 0.2604, F1 Macro: 0.2145, Accuracy: 0.2604\n","Epoch 64, Train Loss: 18.2785, Val Loss: 15.8433, F1 Micro: 0.3125, F1 Macro: 0.2908, Accuracy: 0.3125\n","Epoch 65, Train Loss: 13.4827, Val Loss: 13.7275, F1 Micro: 0.3333, F1 Macro: 0.2634, Accuracy: 0.3333\n","Epoch 66, Train Loss: 11.1664, Val Loss: 15.1113, F1 Micro: 0.3125, F1 Macro: 0.2474, Accuracy: 0.3125\n","Epoch 67, Train Loss: 10.2034, Val Loss: 8.9074, F1 Micro: 0.2812, F1 Macro: 0.2331, Accuracy: 0.2812\n","Epoch 68, Train Loss: 6.9654, Val Loss: 9.8696, F1 Micro: 0.2917, F1 Macro: 0.1965, Accuracy: 0.2917\n","Epoch 69, Train Loss: 8.5980, Val Loss: 11.3591, F1 Micro: 0.3021, F1 Macro: 0.2072, Accuracy: 0.3021\n","Epoch 70, Train Loss: 7.4810, Val Loss: 14.9871, F1 Micro: 0.2083, F1 Macro: 0.1149, Accuracy: 0.2083\n","Epoch 71, Train Loss: 11.0528, Val Loss: 8.5629, F1 Micro: 0.3229, F1 Macro: 0.2574, Accuracy: 0.3229\n","Epoch 72, Train Loss: 7.1829, Val Loss: 8.1526, F1 Micro: 0.2917, F1 Macro: 0.2530, Accuracy: 0.2917\n","Epoch 73, Train Loss: 10.5656, Val Loss: 8.7580, F1 Micro: 0.2292, F1 Macro: 0.1775, Accuracy: 0.2292\n","Epoch 74, Train Loss: 11.1719, Val Loss: 8.9610, F1 Micro: 0.3542, F1 Macro: 0.2713, Accuracy: 0.3542\n","Epoch 75, Train Loss: 10.2066, Val Loss: 9.8789, F1 Micro: 0.2604, F1 Macro: 0.2027, Accuracy: 0.2604\n","Epoch 76, Train Loss: 7.2698, Val Loss: 10.0417, F1 Micro: 0.2292, F1 Macro: 0.1710, Accuracy: 0.2292\n","Epoch 77, Train Loss: 9.6973, Val Loss: 13.0881, F1 Micro: 0.3021, F1 Macro: 0.2268, Accuracy: 0.3021\n","Epoch 78, Train Loss: 10.7903, Val Loss: 27.8816, F1 Micro: 0.1562, F1 Macro: 0.0643, Accuracy: 0.1562\n","Epoch 79, Train Loss: 12.8576, Val Loss: 16.7546, F1 Micro: 0.2083, F1 Macro: 0.1393, Accuracy: 0.2083\n","Epoch 80, Train Loss: 8.1919, Val Loss: 13.1906, F1 Micro: 0.2604, F1 Macro: 0.2087, Accuracy: 0.2604\n","Epoch 81, Train Loss: 12.7408, Val Loss: 9.8334, F1 Micro: 0.2708, F1 Macro: 0.1963, Accuracy: 0.2708\n","Epoch 82, Train Loss: 9.4802, Val Loss: 6.5862, F1 Micro: 0.3542, F1 Macro: 0.2611, Accuracy: 0.3542\n","Epoch 83, Train Loss: 11.0732, Val Loss: 9.1314, F1 Micro: 0.3646, F1 Macro: 0.2847, Accuracy: 0.3646\n","Epoch 84, Train Loss: 13.5824, Val Loss: 9.9790, F1 Micro: 0.2396, F1 Macro: 0.1495, Accuracy: 0.2396\n","Epoch 85, Train Loss: 7.4967, Val Loss: 8.4951, F1 Micro: 0.3229, F1 Macro: 0.2535, Accuracy: 0.3229\n","Epoch 86, Train Loss: 8.7793, Val Loss: 14.1549, F1 Micro: 0.2604, F1 Macro: 0.2055, Accuracy: 0.2604\n","Epoch 87, Train Loss: 12.3688, Val Loss: 4.7025, F1 Micro: 0.3750, F1 Macro: 0.3575, Accuracy: 0.3750\n","Epoch 88, Train Loss: 6.8862, Val Loss: 8.1678, F1 Micro: 0.2708, F1 Macro: 0.2194, Accuracy: 0.2708\n","Epoch 89, Train Loss: 6.6625, Val Loss: 6.0531, F1 Micro: 0.2917, F1 Macro: 0.2991, Accuracy: 0.2917\n","Epoch 90, Train Loss: 11.5183, Val Loss: 10.9571, F1 Micro: 0.2708, F1 Macro: 0.2032, Accuracy: 0.2708\n","Epoch 91, Train Loss: 8.4485, Val Loss: 8.1812, F1 Micro: 0.2708, F1 Macro: 0.2389, Accuracy: 0.2708\n","Epoch 92, Train Loss: 7.5273, Val Loss: 8.2592, F1 Micro: 0.3229, F1 Macro: 0.2463, Accuracy: 0.3229\n","Epoch 93, Train Loss: 11.8323, Val Loss: 20.9135, F1 Micro: 0.2083, F1 Macro: 0.1103, Accuracy: 0.2083\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.39166666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 84.8654, Val Loss: 34.3323, F1 Micro: 0.1458, F1 Macro: 0.0444, Accuracy: 0.1458\n","Epoch 2, Train Loss: 30.7323, Val Loss: 30.7659, F1 Micro: 0.1771, F1 Macro: 0.0672, Accuracy: 0.1771\n","Epoch 3, Train Loss: 19.7468, Val Loss: 16.7711, F1 Micro: 0.1562, F1 Macro: 0.1216, Accuracy: 0.1562\n","Epoch 4, Train Loss: 22.7962, Val Loss: 15.2089, F1 Micro: 0.3125, F1 Macro: 0.1893, Accuracy: 0.3125\n","Epoch 5, Train Loss: 19.7787, Val Loss: 23.8020, F1 Micro: 0.2500, F1 Macro: 0.2019, Accuracy: 0.2500\n","Epoch 6, Train Loss: 27.8921, Val Loss: 20.3091, F1 Micro: 0.1354, F1 Macro: 0.0417, Accuracy: 0.1354\n","Epoch 7, Train Loss: 21.4917, Val Loss: 22.0098, F1 Micro: 0.1979, F1 Macro: 0.1049, Accuracy: 0.1979\n","Epoch 8, Train Loss: 14.8537, Val Loss: 12.3960, F1 Micro: 0.3125, F1 Macro: 0.2492, Accuracy: 0.3125\n","Epoch 9, Train Loss: 12.1457, Val Loss: 13.9541, F1 Micro: 0.2812, F1 Macro: 0.1672, Accuracy: 0.2812\n","Epoch 10, Train Loss: 18.4495, Val Loss: 14.0045, F1 Micro: 0.2708, F1 Macro: 0.2017, Accuracy: 0.2708\n","Epoch 11, Train Loss: 19.9824, Val Loss: 23.2769, F1 Micro: 0.2917, F1 Macro: 0.1343, Accuracy: 0.2917\n","Epoch 12, Train Loss: 24.5577, Val Loss: 36.2238, F1 Micro: 0.2083, F1 Macro: 0.1484, Accuracy: 0.2083\n","Epoch 13, Train Loss: 22.4502, Val Loss: 36.8337, F1 Micro: 0.1771, F1 Macro: 0.1083, Accuracy: 0.1771\n","Epoch 14, Train Loss: 20.0081, Val Loss: 14.1304, F1 Micro: 0.1771, F1 Macro: 0.1192, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 78.3451, Val Loss: 29.1846, F1 Micro: 0.1562, F1 Macro: 0.1136, Accuracy: 0.1562\n","Epoch 2, Train Loss: 33.5787, Val Loss: 20.6549, F1 Micro: 0.1458, F1 Macro: 0.0780, Accuracy: 0.1458\n","Epoch 3, Train Loss: 31.8997, Val Loss: 35.4075, F1 Micro: 0.2188, F1 Macro: 0.1674, Accuracy: 0.2188\n","Epoch 4, Train Loss: 28.7833, Val Loss: 18.2794, F1 Micro: 0.1354, F1 Macro: 0.1061, Accuracy: 0.1354\n","Epoch 5, Train Loss: 19.9926, Val Loss: 21.2521, F1 Micro: 0.2292, F1 Macro: 0.1592, Accuracy: 0.2292\n","Epoch 6, Train Loss: 21.0003, Val Loss: 19.8040, F1 Micro: 0.1667, F1 Macro: 0.0841, Accuracy: 0.1667\n","Epoch 7, Train Loss: 28.4041, Val Loss: 15.4533, F1 Micro: 0.2604, F1 Macro: 0.2124, Accuracy: 0.2604\n","Epoch 8, Train Loss: 20.6518, Val Loss: 25.3946, F1 Micro: 0.1562, F1 Macro: 0.1010, Accuracy: 0.1562\n","Epoch 9, Train Loss: 26.2972, Val Loss: 13.7339, F1 Micro: 0.1771, F1 Macro: 0.0988, Accuracy: 0.1771\n","Epoch 10, Train Loss: 17.4450, Val Loss: 10.9240, F1 Micro: 0.2708, F1 Macro: 0.1561, Accuracy: 0.2708\n","Epoch 11, Train Loss: 17.1510, Val Loss: 12.9417, F1 Micro: 0.2917, F1 Macro: 0.1893, Accuracy: 0.2917\n","Epoch 12, Train Loss: 17.3940, Val Loss: 23.4675, F1 Micro: 0.1042, F1 Macro: 0.0321, Accuracy: 0.1042\n","Epoch 13, Train Loss: 17.7152, Val Loss: 8.7659, F1 Micro: 0.2812, F1 Macro: 0.1872, Accuracy: 0.2812\n","Epoch 14, Train Loss: 16.0830, Val Loss: 11.2783, F1 Micro: 0.3125, F1 Macro: 0.1961, Accuracy: 0.3125\n","Epoch 15, Train Loss: 23.8808, Val Loss: 20.6177, F1 Micro: 0.2292, F1 Macro: 0.1528, Accuracy: 0.2292\n","Epoch 16, Train Loss: 24.4296, Val Loss: 19.2397, F1 Micro: 0.1667, F1 Macro: 0.0896, Accuracy: 0.1667\n","Epoch 17, Train Loss: 17.0473, Val Loss: 18.6276, F1 Micro: 0.2604, F1 Macro: 0.1742, Accuracy: 0.2604\n","Epoch 18, Train Loss: 17.7815, Val Loss: 13.9843, F1 Micro: 0.3021, F1 Macro: 0.1834, Accuracy: 0.3021\n","Epoch 19, Train Loss: 18.3885, Val Loss: 18.4522, F1 Micro: 0.1250, F1 Macro: 0.1036, Accuracy: 0.1250\n","Epoch 20, Train Loss: 19.5882, Val Loss: 11.9113, F1 Micro: 0.2292, F1 Macro: 0.1802, Accuracy: 0.2292\n","Epoch 21, Train Loss: 16.5930, Val Loss: 10.1547, F1 Micro: 0.1875, F1 Macro: 0.1541, Accuracy: 0.1875\n","Epoch 22, Train Loss: 18.7037, Val Loss: 15.7951, F1 Micro: 0.1771, F1 Macro: 0.1255, Accuracy: 0.1771\n","Epoch 23, Train Loss: 17.8750, Val Loss: 13.2775, F1 Micro: 0.2604, F1 Macro: 0.1381, Accuracy: 0.2604\n","Epoch 24, Train Loss: 24.3142, Val Loss: 32.8540, F1 Micro: 0.1042, F1 Macro: 0.0597, Accuracy: 0.1042\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 81.6398, Val Loss: 47.7497, F1 Micro: 0.2083, F1 Macro: 0.0612, Accuracy: 0.2083\n","Epoch 2, Train Loss: 29.6261, Val Loss: 25.3830, F1 Micro: 0.1875, F1 Macro: 0.1193, Accuracy: 0.1875\n","Epoch 3, Train Loss: 17.8776, Val Loss: 7.7024, F1 Micro: 0.2604, F1 Macro: 0.1449, Accuracy: 0.2604\n","Epoch 4, Train Loss: 11.5425, Val Loss: 10.2045, F1 Micro: 0.2917, F1 Macro: 0.2493, Accuracy: 0.2917\n","Epoch 5, Train Loss: 10.3411, Val Loss: 18.6701, F1 Micro: 0.2292, F1 Macro: 0.1135, Accuracy: 0.2292\n","Epoch 6, Train Loss: 23.0740, Val Loss: 22.5694, F1 Micro: 0.2188, F1 Macro: 0.0984, Accuracy: 0.2188\n","Epoch 7, Train Loss: 19.0851, Val Loss: 17.3208, F1 Micro: 0.2604, F1 Macro: 0.1780, Accuracy: 0.2604\n","Epoch 8, Train Loss: 20.8811, Val Loss: 22.2074, F1 Micro: 0.1250, F1 Macro: 0.0912, Accuracy: 0.1250\n","Epoch 9, Train Loss: 23.9721, Val Loss: 38.1950, F1 Micro: 0.2396, F1 Macro: 0.1402, Accuracy: 0.2396\n","Epoch 10, Train Loss: 23.4100, Val Loss: 7.5572, F1 Micro: 0.3021, F1 Macro: 0.2330, Accuracy: 0.3021\n","Epoch 11, Train Loss: 14.5133, Val Loss: 15.7859, F1 Micro: 0.1979, F1 Macro: 0.1334, Accuracy: 0.1979\n","Epoch 12, Train Loss: 14.7265, Val Loss: 16.0342, F1 Micro: 0.1979, F1 Macro: 0.1726, Accuracy: 0.1979\n","Epoch 13, Train Loss: 13.9007, Val Loss: 15.5969, F1 Micro: 0.2812, F1 Macro: 0.1992, Accuracy: 0.2812\n","Epoch 14, Train Loss: 12.7854, Val Loss: 15.3948, F1 Micro: 0.2396, F1 Macro: 0.1516, Accuracy: 0.2396\n","Epoch 15, Train Loss: 18.7899, Val Loss: 25.9334, F1 Micro: 0.2708, F1 Macro: 0.1726, Accuracy: 0.2708\n","Epoch 16, Train Loss: 18.5847, Val Loss: 23.9486, F1 Micro: 0.2083, F1 Macro: 0.0580, Accuracy: 0.2083\n","Epoch 17, Train Loss: 17.5879, Val Loss: 28.0142, F1 Micro: 0.2188, F1 Macro: 0.1099, Accuracy: 0.2188\n","Epoch 18, Train Loss: 10.9609, Val Loss: 14.9550, F1 Micro: 0.2604, F1 Macro: 0.2070, Accuracy: 0.2604\n","Epoch 19, Train Loss: 16.9880, Val Loss: 12.8051, F1 Micro: 0.2708, F1 Macro: 0.1689, Accuracy: 0.2708\n","Epoch 20, Train Loss: 20.1463, Val Loss: 13.7642, F1 Micro: 0.2604, F1 Macro: 0.2264, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 113.2857, Val Loss: 43.1120, F1 Micro: 0.1771, F1 Macro: 0.0861, Accuracy: 0.1771\n","Epoch 2, Train Loss: 43.1717, Val Loss: 36.1103, F1 Micro: 0.2500, F1 Macro: 0.1567, Accuracy: 0.2500\n","Epoch 3, Train Loss: 27.8401, Val Loss: 31.3934, F1 Micro: 0.1667, F1 Macro: 0.0950, Accuracy: 0.1667\n","Epoch 4, Train Loss: 17.2242, Val Loss: 12.7822, F1 Micro: 0.2396, F1 Macro: 0.1795, Accuracy: 0.2396\n","Epoch 5, Train Loss: 13.0838, Val Loss: 16.9406, F1 Micro: 0.2812, F1 Macro: 0.2359, Accuracy: 0.2812\n","Epoch 6, Train Loss: 16.0847, Val Loss: 28.2566, F1 Micro: 0.2396, F1 Macro: 0.1643, Accuracy: 0.2396\n","Epoch 7, Train Loss: 20.4062, Val Loss: 14.4991, F1 Micro: 0.1875, F1 Macro: 0.1165, Accuracy: 0.1875\n","Epoch 8, Train Loss: 17.7273, Val Loss: 10.3900, F1 Micro: 0.1875, F1 Macro: 0.1265, Accuracy: 0.1875\n","Epoch 9, Train Loss: 13.2638, Val Loss: 14.9868, F1 Micro: 0.2083, F1 Macro: 0.1423, Accuracy: 0.2083\n","Epoch 10, Train Loss: 18.3630, Val Loss: 22.4585, F1 Micro: 0.2083, F1 Macro: 0.1203, Accuracy: 0.2083\n","Epoch 11, Train Loss: 19.4262, Val Loss: 27.5629, F1 Micro: 0.2396, F1 Macro: 0.1319, Accuracy: 0.2396\n","Epoch 12, Train Loss: 24.3553, Val Loss: 32.4369, F1 Micro: 0.2292, F1 Macro: 0.1552, Accuracy: 0.2292\n","Epoch 13, Train Loss: 22.6772, Val Loss: 20.1368, F1 Micro: 0.1979, F1 Macro: 0.1092, Accuracy: 0.1979\n","Epoch 14, Train Loss: 11.0277, Val Loss: 14.5388, F1 Micro: 0.2708, F1 Macro: 0.1916, Accuracy: 0.2708\n","Epoch 15, Train Loss: 16.5772, Val Loss: 28.0457, F1 Micro: 0.1771, F1 Macro: 0.0698, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 137.0543, Val Loss: 42.1197, F1 Micro: 0.1562, F1 Macro: 0.0500, Accuracy: 0.1562\n","Epoch 2, Train Loss: 54.6192, Val Loss: 32.5665, F1 Micro: 0.2292, F1 Macro: 0.1179, Accuracy: 0.2292\n","Epoch 3, Train Loss: 28.3619, Val Loss: 25.7232, F1 Micro: 0.2292, F1 Macro: 0.1348, Accuracy: 0.2292\n","Epoch 4, Train Loss: 18.9624, Val Loss: 10.9985, F1 Micro: 0.2708, F1 Macro: 0.2155, Accuracy: 0.2708\n","Epoch 5, Train Loss: 18.1882, Val Loss: 18.1342, F1 Micro: 0.2292, F1 Macro: 0.0812, Accuracy: 0.2292\n","Epoch 6, Train Loss: 29.0370, Val Loss: 27.8613, F1 Micro: 0.2500, F1 Macro: 0.1875, Accuracy: 0.2500\n","Epoch 7, Train Loss: 29.3121, Val Loss: 27.4194, F1 Micro: 0.2604, F1 Macro: 0.1948, Accuracy: 0.2604\n","Epoch 8, Train Loss: 17.2599, Val Loss: 11.7095, F1 Micro: 0.2396, F1 Macro: 0.1807, Accuracy: 0.2396\n","Epoch 9, Train Loss: 18.3141, Val Loss: 28.7832, F1 Micro: 0.1979, F1 Macro: 0.1066, Accuracy: 0.1979\n","Epoch 10, Train Loss: 21.5116, Val Loss: 15.4204, F1 Micro: 0.2188, F1 Macro: 0.1504, Accuracy: 0.2188\n","Epoch 11, Train Loss: 25.6571, Val Loss: 22.2569, F1 Micro: 0.2604, F1 Macro: 0.1684, Accuracy: 0.2604\n","Epoch 12, Train Loss: 29.9736, Val Loss: 39.2506, F1 Micro: 0.2500, F1 Macro: 0.2103, Accuracy: 0.2500\n","Epoch 13, Train Loss: 20.0305, Val Loss: 18.0199, F1 Micro: 0.2604, F1 Macro: 0.1777, Accuracy: 0.2604\n","Epoch 14, Train Loss: 11.6598, Val Loss: 15.1198, F1 Micro: 0.3229, F1 Macro: 0.1895, Accuracy: 0.3229\n","Epoch 15, Train Loss: 13.5171, Val Loss: 10.4041, F1 Micro: 0.1771, F1 Macro: 0.1095, Accuracy: 0.1771\n","Epoch 16, Train Loss: 16.2370, Val Loss: 18.2055, F1 Micro: 0.2292, F1 Macro: 0.1617, Accuracy: 0.2292\n","Epoch 17, Train Loss: 25.9246, Val Loss: 26.1295, F1 Micro: 0.1875, F1 Macro: 0.1114, Accuracy: 0.1875\n","Epoch 18, Train Loss: 13.4167, Val Loss: 13.0599, F1 Micro: 0.2396, F1 Macro: 0.1251, Accuracy: 0.2396\n","Epoch 19, Train Loss: 14.5983, Val Loss: 15.2967, F1 Micro: 0.2083, F1 Macro: 0.1241, Accuracy: 0.2083\n","Epoch 20, Train Loss: 18.5574, Val Loss: 31.1783, F1 Micro: 0.2604, F1 Macro: 0.1536, Accuracy: 0.2604\n","Epoch 21, Train Loss: 21.4507, Val Loss: 17.2387, F1 Micro: 0.2292, F1 Macro: 0.1880, Accuracy: 0.2292\n","Epoch 22, Train Loss: 14.4258, Val Loss: 41.7906, F1 Micro: 0.2708, F1 Macro: 0.2207, Accuracy: 0.2708\n","Epoch 23, Train Loss: 28.2048, Val Loss: 35.5188, F1 Micro: 0.2083, F1 Macro: 0.1141, Accuracy: 0.2083\n","Epoch 24, Train Loss: 19.5402, Val Loss: 17.2551, F1 Micro: 0.3646, F1 Macro: 0.2947, Accuracy: 0.3646\n","Epoch 25, Train Loss: 15.7281, Val Loss: 12.6559, F1 Micro: 0.1875, F1 Macro: 0.1232, Accuracy: 0.1875\n","Epoch 26, Train Loss: 10.0164, Val Loss: 16.9641, F1 Micro: 0.2604, F1 Macro: 0.1837, Accuracy: 0.2604\n","Epoch 27, Train Loss: 13.8447, Val Loss: 9.4780, F1 Micro: 0.2708, F1 Macro: 0.1438, Accuracy: 0.2708\n","Epoch 28, Train Loss: 17.4654, Val Loss: 13.2245, F1 Micro: 0.2396, F1 Macro: 0.1713, Accuracy: 0.2396\n","Epoch 29, Train Loss: 18.6118, Val Loss: 12.4215, F1 Micro: 0.2500, F1 Macro: 0.1715, Accuracy: 0.2500\n","Epoch 30, Train Loss: 14.5866, Val Loss: 24.2501, F1 Micro: 0.2188, F1 Macro: 0.1444, Accuracy: 0.2188\n","Epoch 31, Train Loss: 21.7405, Val Loss: 23.5605, F1 Micro: 0.3125, F1 Macro: 0.2492, Accuracy: 0.3125\n","Epoch 32, Train Loss: 19.2296, Val Loss: 16.7758, F1 Micro: 0.2917, F1 Macro: 0.2059, Accuracy: 0.2917\n","Epoch 33, Train Loss: 10.3622, Val Loss: 14.2509, F1 Micro: 0.2292, F1 Macro: 0.1568, Accuracy: 0.2292\n","Epoch 34, Train Loss: 16.7067, Val Loss: 10.5559, F1 Micro: 0.2396, F1 Macro: 0.1772, Accuracy: 0.2396\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.3145833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 55.9089, Val Loss: 28.5426, F1 Micro: 0.1250, F1 Macro: 0.1035, Accuracy: 0.1250\n","Epoch 2, Train Loss: 19.2736, Val Loss: 14.9718, F1 Micro: 0.3646, F1 Macro: 0.2489, Accuracy: 0.3646\n","Epoch 3, Train Loss: 17.1806, Val Loss: 8.8209, F1 Micro: 0.2917, F1 Macro: 0.1557, Accuracy: 0.2917\n","Epoch 4, Train Loss: 11.0553, Val Loss: 16.8780, F1 Micro: 0.1979, F1 Macro: 0.1340, Accuracy: 0.1979\n","Epoch 5, Train Loss: 36.5125, Val Loss: 49.7417, F1 Micro: 0.1667, F1 Macro: 0.1139, Accuracy: 0.1667\n","Epoch 6, Train Loss: 29.8666, Val Loss: 24.3827, F1 Micro: 0.2812, F1 Macro: 0.1762, Accuracy: 0.2812\n","Epoch 7, Train Loss: 21.7009, Val Loss: 25.4204, F1 Micro: 0.1458, F1 Macro: 0.0432, Accuracy: 0.1458\n","Epoch 8, Train Loss: 16.4725, Val Loss: 9.9466, F1 Micro: 0.3125, F1 Macro: 0.1982, Accuracy: 0.3125\n","Epoch 9, Train Loss: 12.6179, Val Loss: 22.0430, F1 Micro: 0.2812, F1 Macro: 0.1413, Accuracy: 0.2812\n","Epoch 10, Train Loss: 27.3858, Val Loss: 20.1558, F1 Micro: 0.2083, F1 Macro: 0.1646, Accuracy: 0.2083\n","Epoch 11, Train Loss: 26.9207, Val Loss: 45.7027, F1 Micro: 0.2500, F1 Macro: 0.1478, Accuracy: 0.2500\n","Epoch 12, Train Loss: 27.1249, Val Loss: 15.7162, F1 Micro: 0.2917, F1 Macro: 0.2294, Accuracy: 0.2917\n","Epoch 13, Train Loss: 13.9168, Val Loss: 31.1810, F1 Micro: 0.3021, F1 Macro: 0.2151, Accuracy: 0.3021\n","Epoch 14, Train Loss: 13.7053, Val Loss: 16.8765, F1 Micro: 0.1771, F1 Macro: 0.1286, Accuracy: 0.1771\n","Epoch 15, Train Loss: 9.6201, Val Loss: 19.2500, F1 Micro: 0.2500, F1 Macro: 0.2052, Accuracy: 0.2500\n","Epoch 16, Train Loss: 14.2708, Val Loss: 24.8474, F1 Micro: 0.1875, F1 Macro: 0.1045, Accuracy: 0.1875\n","Epoch 17, Train Loss: 17.2130, Val Loss: 16.1034, F1 Micro: 0.2188, F1 Macro: 0.1306, Accuracy: 0.2188\n","Epoch 18, Train Loss: 21.1591, Val Loss: 51.6368, F1 Micro: 0.2500, F1 Macro: 0.1936, Accuracy: 0.2500\n","Epoch 19, Train Loss: 29.2894, Val Loss: 25.3852, F1 Micro: 0.2917, F1 Macro: 0.1640, Accuracy: 0.2917\n","Epoch 20, Train Loss: 19.8454, Val Loss: 36.9753, F1 Micro: 0.1771, F1 Macro: 0.0901, Accuracy: 0.1771\n","Epoch 21, Train Loss: 20.2549, Val Loss: 36.3826, F1 Micro: 0.1562, F1 Macro: 0.1041, Accuracy: 0.1562\n","Epoch 22, Train Loss: 13.2958, Val Loss: 8.0098, F1 Micro: 0.3438, F1 Macro: 0.2714, Accuracy: 0.3438\n","Epoch 23, Train Loss: 10.7322, Val Loss: 13.1698, F1 Micro: 0.1875, F1 Macro: 0.1553, Accuracy: 0.1875\n","Epoch 24, Train Loss: 9.4536, Val Loss: 25.5660, F1 Micro: 0.2083, F1 Macro: 0.1390, Accuracy: 0.2083\n","Epoch 25, Train Loss: 17.8091, Val Loss: 22.0279, F1 Micro: 0.3438, F1 Macro: 0.2157, Accuracy: 0.3438\n","Epoch 26, Train Loss: 15.7340, Val Loss: 15.2051, F1 Micro: 0.2292, F1 Macro: 0.1922, Accuracy: 0.2292\n","Epoch 27, Train Loss: 14.8783, Val Loss: 26.6662, F1 Micro: 0.1667, F1 Macro: 0.0701, Accuracy: 0.1667\n","Epoch 28, Train Loss: 13.3242, Val Loss: 6.7247, F1 Micro: 0.2396, F1 Macro: 0.2237, Accuracy: 0.2396\n","Epoch 29, Train Loss: 11.8370, Val Loss: 12.2604, F1 Micro: 0.3125, F1 Macro: 0.1589, Accuracy: 0.3125\n","Epoch 30, Train Loss: 15.5708, Val Loss: 4.7648, F1 Micro: 0.4062, F1 Macro: 0.3502, Accuracy: 0.4062\n","Epoch 31, Train Loss: 11.1651, Val Loss: 15.9472, F1 Micro: 0.2917, F1 Macro: 0.2020, Accuracy: 0.2917\n","Epoch 32, Train Loss: 11.3175, Val Loss: 15.7230, F1 Micro: 0.2708, F1 Macro: 0.1922, Accuracy: 0.2708\n","Epoch 33, Train Loss: 11.3676, Val Loss: 7.2674, F1 Micro: 0.3646, F1 Macro: 0.3054, Accuracy: 0.3646\n","Epoch 34, Train Loss: 10.7115, Val Loss: 9.9537, F1 Micro: 0.2604, F1 Macro: 0.1547, Accuracy: 0.2604\n","Epoch 35, Train Loss: 10.9146, Val Loss: 10.4110, F1 Micro: 0.2708, F1 Macro: 0.1964, Accuracy: 0.2708\n","Epoch 36, Train Loss: 12.3182, Val Loss: 20.5309, F1 Micro: 0.1979, F1 Macro: 0.1070, Accuracy: 0.1979\n","Epoch 37, Train Loss: 16.0420, Val Loss: 10.1444, F1 Micro: 0.3229, F1 Macro: 0.2931, Accuracy: 0.3229\n","Epoch 38, Train Loss: 10.6136, Val Loss: 11.4881, F1 Micro: 0.2188, F1 Macro: 0.1474, Accuracy: 0.2188\n","Epoch 39, Train Loss: 15.5449, Val Loss: 27.0879, F1 Micro: 0.2083, F1 Macro: 0.1631, Accuracy: 0.2083\n","Epoch 40, Train Loss: 13.7624, Val Loss: 12.9132, F1 Micro: 0.2500, F1 Macro: 0.2008, Accuracy: 0.2500\n","Epoch 41, Train Loss: 13.1836, Val Loss: 22.2921, F1 Micro: 0.1562, F1 Macro: 0.0889, Accuracy: 0.1562\n","Epoch 42, Train Loss: 12.0455, Val Loss: 8.7800, F1 Micro: 0.3438, F1 Macro: 0.2790, Accuracy: 0.3438\n","Epoch 43, Train Loss: 7.2311, Val Loss: 9.9903, F1 Micro: 0.3229, F1 Macro: 0.2366, Accuracy: 0.3229\n","Epoch 44, Train Loss: 9.8516, Val Loss: 12.0007, F1 Micro: 0.2604, F1 Macro: 0.1934, Accuracy: 0.2604\n","Epoch 45, Train Loss: 14.8820, Val Loss: 10.1305, F1 Micro: 0.2604, F1 Macro: 0.1640, Accuracy: 0.2604\n","Epoch 46, Train Loss: 13.1723, Val Loss: 13.2865, F1 Micro: 0.3021, F1 Macro: 0.2458, Accuracy: 0.3021\n","Epoch 47, Train Loss: 14.4115, Val Loss: 8.8309, F1 Micro: 0.3229, F1 Macro: 0.2038, Accuracy: 0.3229\n","Epoch 48, Train Loss: 12.0854, Val Loss: 12.5427, F1 Micro: 0.2604, F1 Macro: 0.2176, Accuracy: 0.2604\n","Epoch 49, Train Loss: 10.8668, Val Loss: 10.8692, F1 Micro: 0.3438, F1 Macro: 0.2954, Accuracy: 0.3438\n","Epoch 50, Train Loss: 9.2023, Val Loss: 20.2784, F1 Micro: 0.3125, F1 Macro: 0.2247, Accuracy: 0.3125\n","Epoch 51, Train Loss: 12.6332, Val Loss: 13.8203, F1 Micro: 0.2396, F1 Macro: 0.1590, Accuracy: 0.2396\n","Epoch 52, Train Loss: 11.2552, Val Loss: 8.4087, F1 Micro: 0.3854, F1 Macro: 0.3211, Accuracy: 0.3854\n","Epoch 53, Train Loss: 11.6192, Val Loss: 10.6788, F1 Micro: 0.3542, F1 Macro: 0.2461, Accuracy: 0.3542\n","Epoch 54, Train Loss: 17.0070, Val Loss: 22.8279, F1 Micro: 0.2396, F1 Macro: 0.1846, Accuracy: 0.2396\n","Epoch 55, Train Loss: 11.6411, Val Loss: 7.8616, F1 Micro: 0.2292, F1 Macro: 0.1471, Accuracy: 0.2292\n","Epoch 56, Train Loss: 10.1434, Val Loss: 28.3971, F1 Micro: 0.2188, F1 Macro: 0.1237, Accuracy: 0.2188\n","Epoch 57, Train Loss: 19.2156, Val Loss: 13.2505, F1 Micro: 0.2708, F1 Macro: 0.1604, Accuracy: 0.2708\n","Epoch 58, Train Loss: 18.7990, Val Loss: 20.0157, F1 Micro: 0.1667, F1 Macro: 0.0630, Accuracy: 0.1667\n","Epoch 59, Train Loss: 14.6948, Val Loss: 11.5423, F1 Micro: 0.3542, F1 Macro: 0.2652, Accuracy: 0.3542\n","Epoch 60, Train Loss: 12.1579, Val Loss: 15.6651, F1 Micro: 0.2292, F1 Macro: 0.1891, Accuracy: 0.2292\n","Epoch 61, Train Loss: 13.0056, Val Loss: 14.4835, F1 Micro: 0.2917, F1 Macro: 0.1952, Accuracy: 0.2917\n","Epoch 62, Train Loss: 13.4460, Val Loss: 18.7196, F1 Micro: 0.2812, F1 Macro: 0.2318, Accuracy: 0.2812\n","Epoch 63, Train Loss: 20.4212, Val Loss: 17.0908, F1 Micro: 0.1979, F1 Macro: 0.1060, Accuracy: 0.1979\n","Epoch 64, Train Loss: 20.7237, Val Loss: 35.1438, F1 Micro: 0.1771, F1 Macro: 0.1252, Accuracy: 0.1771\n","Epoch 65, Train Loss: 18.7172, Val Loss: 24.5891, F1 Micro: 0.2083, F1 Macro: 0.1723, Accuracy: 0.2083\n","Epoch 66, Train Loss: 16.2038, Val Loss: 14.3333, F1 Micro: 0.3021, F1 Macro: 0.2357, Accuracy: 0.3021\n","Epoch 67, Train Loss: 8.9386, Val Loss: 9.3045, F1 Micro: 0.2292, F1 Macro: 0.1847, Accuracy: 0.2292\n","Epoch 68, Train Loss: 10.5913, Val Loss: 6.3866, F1 Micro: 0.3646, F1 Macro: 0.2897, Accuracy: 0.3646\n","Epoch 69, Train Loss: 7.5362, Val Loss: 12.5124, F1 Micro: 0.2292, F1 Macro: 0.1931, Accuracy: 0.2292\n","Epoch 70, Train Loss: 7.9540, Val Loss: 8.0981, F1 Micro: 0.2292, F1 Macro: 0.1795, Accuracy: 0.2292\n","Epoch 71, Train Loss: 9.8428, Val Loss: 14.1306, F1 Micro: 0.1667, F1 Macro: 0.0850, Accuracy: 0.1667\n","Epoch 72, Train Loss: 9.6633, Val Loss: 18.5144, F1 Micro: 0.3229, F1 Macro: 0.2022, Accuracy: 0.3229\n","Epoch 73, Train Loss: 16.7074, Val Loss: 9.0578, F1 Micro: 0.2917, F1 Macro: 0.2679, Accuracy: 0.2917\n","Epoch 74, Train Loss: 8.5303, Val Loss: 4.7552, F1 Micro: 0.3438, F1 Macro: 0.2884, Accuracy: 0.3438\n","Epoch 75, Train Loss: 11.4322, Val Loss: 16.3731, F1 Micro: 0.3125, F1 Macro: 0.2681, Accuracy: 0.3125\n","Epoch 76, Train Loss: 10.9710, Val Loss: 12.5713, F1 Micro: 0.1354, F1 Macro: 0.0677, Accuracy: 0.1354\n","Epoch 77, Train Loss: 9.6753, Val Loss: 16.0777, F1 Micro: 0.4167, F1 Macro: 0.3337, Accuracy: 0.4167\n","Epoch 78, Train Loss: 9.5022, Val Loss: 8.0687, F1 Micro: 0.2396, F1 Macro: 0.1736, Accuracy: 0.2396\n","Epoch 79, Train Loss: 12.8761, Val Loss: 8.6740, F1 Micro: 0.2500, F1 Macro: 0.1973, Accuracy: 0.2500\n","Epoch 80, Train Loss: 14.0453, Val Loss: 18.2151, F1 Micro: 0.1562, F1 Macro: 0.0920, Accuracy: 0.1562\n","Epoch 81, Train Loss: 17.4953, Val Loss: 14.6874, F1 Micro: 0.1458, F1 Macro: 0.1048, Accuracy: 0.1458\n","Epoch 82, Train Loss: 10.1853, Val Loss: 8.1229, F1 Micro: 0.2708, F1 Macro: 0.2065, Accuracy: 0.2708\n","Epoch 83, Train Loss: 6.7038, Val Loss: 5.9043, F1 Micro: 0.2083, F1 Macro: 0.1605, Accuracy: 0.2083\n","Epoch 84, Train Loss: 8.4618, Val Loss: 8.4838, F1 Micro: 0.2812, F1 Macro: 0.2395, Accuracy: 0.2812\n","Epoch 85, Train Loss: 8.8437, Val Loss: 14.0750, F1 Micro: 0.3125, F1 Macro: 0.2013, Accuracy: 0.3125\n","Epoch 86, Train Loss: 11.9226, Val Loss: 10.8876, F1 Micro: 0.3125, F1 Macro: 0.2455, Accuracy: 0.3125\n","Epoch 87, Train Loss: 10.5372, Val Loss: 13.7475, F1 Micro: 0.2292, F1 Macro: 0.0913, Accuracy: 0.2292\n","Epoch 88, Train Loss: 12.6688, Val Loss: 10.8481, F1 Micro: 0.2812, F1 Macro: 0.2287, Accuracy: 0.2812\n","Epoch 89, Train Loss: 11.3895, Val Loss: 9.1662, F1 Micro: 0.3021, F1 Macro: 0.2628, Accuracy: 0.3021\n","Epoch 90, Train Loss: 6.4707, Val Loss: 7.2740, F1 Micro: 0.2812, F1 Macro: 0.2021, Accuracy: 0.2812\n","Epoch 91, Train Loss: 6.1375, Val Loss: 7.7032, F1 Micro: 0.2083, F1 Macro: 0.1863, Accuracy: 0.2083\n","Epoch 92, Train Loss: 10.9764, Val Loss: 14.0362, F1 Micro: 0.3125, F1 Macro: 0.2500, Accuracy: 0.3125\n","Epoch 93, Train Loss: 9.4103, Val Loss: 6.6310, F1 Micro: 0.2812, F1 Macro: 0.2764, Accuracy: 0.2812\n","Epoch 94, Train Loss: 9.3203, Val Loss: 13.7822, F1 Micro: 0.3021, F1 Macro: 0.2581, Accuracy: 0.3021\n","Epoch 95, Train Loss: 9.8184, Val Loss: 13.1432, F1 Micro: 0.3438, F1 Macro: 0.2101, Accuracy: 0.3438\n","Epoch 96, Train Loss: 8.2166, Val Loss: 16.5979, F1 Micro: 0.2188, F1 Macro: 0.1688, Accuracy: 0.2188\n","Epoch 97, Train Loss: 8.5185, Val Loss: 4.4920, F1 Micro: 0.2500, F1 Macro: 0.2189, Accuracy: 0.2500\n","Epoch 98, Train Loss: 8.8854, Val Loss: 12.7438, F1 Micro: 0.1771, F1 Macro: 0.1481, Accuracy: 0.1771\n","Epoch 99, Train Loss: 18.3747, Val Loss: 20.4272, F1 Micro: 0.3021, F1 Macro: 0.2138, Accuracy: 0.3021\n","Epoch 100, Train Loss: 13.5925, Val Loss: 11.0423, F1 Micro: 0.3854, F1 Macro: 0.3310, Accuracy: 0.3854\n","Epoch 101, Train Loss: 11.5554, Val Loss: 8.0807, F1 Micro: 0.3646, F1 Macro: 0.2578, Accuracy: 0.3646\n","Epoch 102, Train Loss: 7.8403, Val Loss: 6.4271, F1 Micro: 0.2917, F1 Macro: 0.1849, Accuracy: 0.2917\n","Epoch 103, Train Loss: 12.2306, Val Loss: 8.4288, F1 Micro: 0.3750, F1 Macro: 0.3189, Accuracy: 0.3750\n","Epoch 104, Train Loss: 9.3256, Val Loss: 9.4476, F1 Micro: 0.2396, F1 Macro: 0.1886, Accuracy: 0.2396\n","Epoch 105, Train Loss: 7.1691, Val Loss: 13.5809, F1 Micro: 0.3542, F1 Macro: 0.2680, Accuracy: 0.3542\n","Epoch 106, Train Loss: 10.9961, Val Loss: 15.5715, F1 Micro: 0.2083, F1 Macro: 0.1239, Accuracy: 0.2083\n","Epoch 107, Train Loss: 10.0755, Val Loss: 5.7371, F1 Micro: 0.3229, F1 Macro: 0.2823, Accuracy: 0.3229\n","Epoch 108, Train Loss: 6.6018, Val Loss: 4.2958, F1 Micro: 0.3646, F1 Macro: 0.3431, Accuracy: 0.3646\n","Epoch 109, Train Loss: 6.9595, Val Loss: 7.2740, F1 Micro: 0.1771, F1 Macro: 0.1523, Accuracy: 0.1771\n","Epoch 110, Train Loss: 7.8465, Val Loss: 8.1562, F1 Micro: 0.2188, F1 Macro: 0.1725, Accuracy: 0.2188\n","Epoch 111, Train Loss: 5.1403, Val Loss: 5.0538, F1 Micro: 0.2917, F1 Macro: 0.2589, Accuracy: 0.2917\n","Epoch 112, Train Loss: 8.5949, Val Loss: 14.0138, F1 Micro: 0.2812, F1 Macro: 0.2377, Accuracy: 0.2812\n","Epoch 113, Train Loss: 8.6173, Val Loss: 11.5421, F1 Micro: 0.2708, F1 Macro: 0.2486, Accuracy: 0.2708\n","Epoch 114, Train Loss: 13.3666, Val Loss: 11.9872, F1 Micro: 0.3125, F1 Macro: 0.2395, Accuracy: 0.3125\n","Epoch 115, Train Loss: 10.9319, Val Loss: 11.6818, F1 Micro: 0.1875, F1 Macro: 0.1247, Accuracy: 0.1875\n","Epoch 116, Train Loss: 7.5376, Val Loss: 10.8226, F1 Micro: 0.1875, F1 Macro: 0.1209, Accuracy: 0.1875\n","Epoch 117, Train Loss: 7.5116, Val Loss: 6.9448, F1 Micro: 0.2604, F1 Macro: 0.1869, Accuracy: 0.2604\n","Epoch 118, Train Loss: 8.4900, Val Loss: 10.0145, F1 Micro: 0.3854, F1 Macro: 0.3184, Accuracy: 0.3854\n","Epoch 119, Train Loss: 6.6196, Val Loss: 17.5610, F1 Micro: 0.1562, F1 Macro: 0.0879, Accuracy: 0.1562\n","Epoch 120, Train Loss: 11.7997, Val Loss: 9.4042, F1 Micro: 0.2396, F1 Macro: 0.1939, Accuracy: 0.2396\n","Epoch 121, Train Loss: 7.5701, Val Loss: 9.2627, F1 Micro: 0.2604, F1 Macro: 0.2243, Accuracy: 0.2604\n","Epoch 122, Train Loss: 9.7697, Val Loss: 17.5770, F1 Micro: 0.2292, F1 Macro: 0.1671, Accuracy: 0.2292\n","Epoch 123, Train Loss: 10.0527, Val Loss: 8.3839, F1 Micro: 0.3229, F1 Macro: 0.2796, Accuracy: 0.3229\n","Epoch 124, Train Loss: 6.9328, Val Loss: 10.0334, F1 Micro: 0.2604, F1 Macro: 0.1841, Accuracy: 0.2604\n","Epoch 125, Train Loss: 7.2047, Val Loss: 7.0781, F1 Micro: 0.2604, F1 Macro: 0.1795, Accuracy: 0.2604\n","Epoch 126, Train Loss: 6.1648, Val Loss: 8.5876, F1 Micro: 0.2708, F1 Macro: 0.1982, Accuracy: 0.2708\n","Epoch 127, Train Loss: 5.8396, Val Loss: 11.7056, F1 Micro: 0.2396, F1 Macro: 0.2176, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 77.2871, Val Loss: 30.1872, F1 Micro: 0.1146, F1 Macro: 0.0493, Accuracy: 0.1146\n","Epoch 2, Train Loss: 26.0258, Val Loss: 24.6595, F1 Micro: 0.0938, F1 Macro: 0.0341, Accuracy: 0.0938\n","Epoch 3, Train Loss: 23.4127, Val Loss: 11.4593, F1 Micro: 0.1667, F1 Macro: 0.1034, Accuracy: 0.1667\n","Epoch 4, Train Loss: 11.7813, Val Loss: 17.1236, F1 Micro: 0.1875, F1 Macro: 0.1318, Accuracy: 0.1875\n","Epoch 5, Train Loss: 26.5213, Val Loss: 36.7325, F1 Micro: 0.0833, F1 Macro: 0.0437, Accuracy: 0.0833\n","Epoch 6, Train Loss: 20.8552, Val Loss: 13.7663, F1 Micro: 0.2396, F1 Macro: 0.1198, Accuracy: 0.2396\n","Epoch 7, Train Loss: 19.5333, Val Loss: 16.5091, F1 Micro: 0.2396, F1 Macro: 0.1602, Accuracy: 0.2396\n","Epoch 8, Train Loss: 15.7086, Val Loss: 9.7947, F1 Micro: 0.2083, F1 Macro: 0.1496, Accuracy: 0.2083\n","Epoch 9, Train Loss: 17.7099, Val Loss: 13.9947, F1 Micro: 0.1979, F1 Macro: 0.1085, Accuracy: 0.1979\n","Epoch 10, Train Loss: 19.3062, Val Loss: 24.6439, F1 Micro: 0.2083, F1 Macro: 0.1313, Accuracy: 0.2083\n","Epoch 11, Train Loss: 16.4575, Val Loss: 15.9089, F1 Micro: 0.1458, F1 Macro: 0.0838, Accuracy: 0.1458\n","Epoch 12, Train Loss: 19.3590, Val Loss: 9.3393, F1 Micro: 0.2708, F1 Macro: 0.2068, Accuracy: 0.2708\n","Epoch 13, Train Loss: 22.1403, Val Loss: 13.4062, F1 Micro: 0.1979, F1 Macro: 0.1413, Accuracy: 0.1979\n","Epoch 14, Train Loss: 19.1948, Val Loss: 14.6286, F1 Micro: 0.1667, F1 Macro: 0.1042, Accuracy: 0.1667\n","Epoch 15, Train Loss: 21.7667, Val Loss: 16.1866, F1 Micro: 0.2083, F1 Macro: 0.1068, Accuracy: 0.2083\n","Epoch 16, Train Loss: 18.5422, Val Loss: 19.3424, F1 Micro: 0.1250, F1 Macro: 0.0894, Accuracy: 0.1250\n","Epoch 17, Train Loss: 16.6922, Val Loss: 11.2964, F1 Micro: 0.2500, F1 Macro: 0.1515, Accuracy: 0.2500\n","Epoch 18, Train Loss: 17.5261, Val Loss: 12.5671, F1 Micro: 0.2083, F1 Macro: 0.1759, Accuracy: 0.2083\n","Epoch 19, Train Loss: 15.4801, Val Loss: 17.2073, F1 Micro: 0.2188, F1 Macro: 0.1669, Accuracy: 0.2188\n","Epoch 20, Train Loss: 15.1244, Val Loss: 15.8454, F1 Micro: 0.2708, F1 Macro: 0.1615, Accuracy: 0.2708\n","Epoch 21, Train Loss: 17.8031, Val Loss: 16.3010, F1 Micro: 0.2292, F1 Macro: 0.1374, Accuracy: 0.2292\n","Epoch 22, Train Loss: 21.9206, Val Loss: 12.8062, F1 Micro: 0.3438, F1 Macro: 0.2620, Accuracy: 0.3438\n","Epoch 23, Train Loss: 24.8807, Val Loss: 18.7804, F1 Micro: 0.3125, F1 Macro: 0.2307, Accuracy: 0.3125\n","Epoch 24, Train Loss: 32.6139, Val Loss: 10.3328, F1 Micro: 0.2604, F1 Macro: 0.2379, Accuracy: 0.2604\n","Epoch 25, Train Loss: 22.5181, Val Loss: 29.2406, F1 Micro: 0.1875, F1 Macro: 0.1101, Accuracy: 0.1875\n","Epoch 26, Train Loss: 18.0473, Val Loss: 16.6311, F1 Micro: 0.1979, F1 Macro: 0.1541, Accuracy: 0.1979\n","Epoch 27, Train Loss: 20.4335, Val Loss: 14.2857, F1 Micro: 0.2292, F1 Macro: 0.1694, Accuracy: 0.2292\n","Epoch 28, Train Loss: 18.0104, Val Loss: 23.2219, F1 Micro: 0.1771, F1 Macro: 0.0805, Accuracy: 0.1771\n","Epoch 29, Train Loss: 26.8591, Val Loss: 14.6352, F1 Micro: 0.1667, F1 Macro: 0.0997, Accuracy: 0.1667\n","Epoch 30, Train Loss: 16.2316, Val Loss: 10.6263, F1 Micro: 0.1875, F1 Macro: 0.1336, Accuracy: 0.1875\n","Epoch 31, Train Loss: 15.5490, Val Loss: 18.0320, F1 Micro: 0.2083, F1 Macro: 0.1533, Accuracy: 0.2083\n","Epoch 32, Train Loss: 25.7889, Val Loss: 16.4751, F1 Micro: 0.1458, F1 Macro: 0.1208, Accuracy: 0.1458\n","Epoch 33, Train Loss: 17.0896, Val Loss: 12.3161, F1 Micro: 0.2604, F1 Macro: 0.1827, Accuracy: 0.2604\n","Epoch 34, Train Loss: 13.5595, Val Loss: 7.6927, F1 Micro: 0.3333, F1 Macro: 0.2450, Accuracy: 0.3333\n","Epoch 35, Train Loss: 15.3668, Val Loss: 10.8945, F1 Micro: 0.2292, F1 Macro: 0.1690, Accuracy: 0.2292\n","Epoch 36, Train Loss: 7.7978, Val Loss: 7.0156, F1 Micro: 0.2812, F1 Macro: 0.2033, Accuracy: 0.2812\n","Epoch 37, Train Loss: 11.8340, Val Loss: 19.4568, F1 Micro: 0.2812, F1 Macro: 0.1420, Accuracy: 0.2812\n","Epoch 38, Train Loss: 15.3468, Val Loss: 10.2916, F1 Micro: 0.2604, F1 Macro: 0.1627, Accuracy: 0.2604\n","Epoch 39, Train Loss: 8.5709, Val Loss: 7.9139, F1 Micro: 0.1562, F1 Macro: 0.0994, Accuracy: 0.1562\n","Epoch 40, Train Loss: 15.7589, Val Loss: 9.8567, F1 Micro: 0.2708, F1 Macro: 0.2170, Accuracy: 0.2708\n","Epoch 41, Train Loss: 17.7256, Val Loss: 23.6116, F1 Micro: 0.2396, F1 Macro: 0.1236, Accuracy: 0.2396\n","Epoch 42, Train Loss: 15.3853, Val Loss: 9.1412, F1 Micro: 0.3229, F1 Macro: 0.2290, Accuracy: 0.3229\n","Epoch 43, Train Loss: 12.2694, Val Loss: 10.6678, F1 Micro: 0.3542, F1 Macro: 0.2656, Accuracy: 0.3542\n","Epoch 44, Train Loss: 10.4023, Val Loss: 5.4863, F1 Micro: 0.2917, F1 Macro: 0.2034, Accuracy: 0.2917\n","Epoch 45, Train Loss: 9.6089, Val Loss: 11.0155, F1 Micro: 0.2188, F1 Macro: 0.1497, Accuracy: 0.2188\n","Epoch 46, Train Loss: 16.6270, Val Loss: 14.5835, F1 Micro: 0.1771, F1 Macro: 0.1189, Accuracy: 0.1771\n","Epoch 47, Train Loss: 10.7343, Val Loss: 14.7806, F1 Micro: 0.1667, F1 Macro: 0.1091, Accuracy: 0.1667\n","Epoch 48, Train Loss: 11.4482, Val Loss: 6.7726, F1 Micro: 0.1875, F1 Macro: 0.1430, Accuracy: 0.1875\n","Epoch 49, Train Loss: 10.7667, Val Loss: 16.6062, F1 Micro: 0.1875, F1 Macro: 0.1212, Accuracy: 0.1875\n","Epoch 50, Train Loss: 15.8154, Val Loss: 14.7311, F1 Micro: 0.2292, F1 Macro: 0.1535, Accuracy: 0.2292\n","Epoch 51, Train Loss: 16.1829, Val Loss: 6.0438, F1 Micro: 0.3854, F1 Macro: 0.3072, Accuracy: 0.3854\n","Epoch 52, Train Loss: 15.1026, Val Loss: 14.2992, F1 Micro: 0.1458, F1 Macro: 0.1046, Accuracy: 0.1458\n","Epoch 53, Train Loss: 14.5398, Val Loss: 15.0044, F1 Micro: 0.2396, F1 Macro: 0.1449, Accuracy: 0.2396\n","Epoch 54, Train Loss: 13.3468, Val Loss: 10.4741, F1 Micro: 0.3333, F1 Macro: 0.1862, Accuracy: 0.3333\n","Epoch 55, Train Loss: 14.7592, Val Loss: 9.8427, F1 Micro: 0.3125, F1 Macro: 0.2270, Accuracy: 0.3125\n","Epoch 56, Train Loss: 15.4439, Val Loss: 9.3935, F1 Micro: 0.1771, F1 Macro: 0.1382, Accuracy: 0.1771\n","Epoch 57, Train Loss: 13.7435, Val Loss: 9.1624, F1 Micro: 0.2708, F1 Macro: 0.2169, Accuracy: 0.2708\n","Epoch 58, Train Loss: 8.9813, Val Loss: 10.9406, F1 Micro: 0.1562, F1 Macro: 0.0827, Accuracy: 0.1562\n","Epoch 59, Train Loss: 10.4247, Val Loss: 11.0698, F1 Micro: 0.3229, F1 Macro: 0.2476, Accuracy: 0.3229\n","Epoch 60, Train Loss: 11.7955, Val Loss: 7.7987, F1 Micro: 0.2083, F1 Macro: 0.1623, Accuracy: 0.2083\n","Epoch 61, Train Loss: 14.7899, Val Loss: 6.4753, F1 Micro: 0.2292, F1 Macro: 0.1537, Accuracy: 0.2292\n","Epoch 62, Train Loss: 11.5802, Val Loss: 12.3133, F1 Micro: 0.2500, F1 Macro: 0.1880, Accuracy: 0.2500\n","Epoch 63, Train Loss: 8.5253, Val Loss: 7.6056, F1 Micro: 0.3125, F1 Macro: 0.2527, Accuracy: 0.3125\n","Epoch 64, Train Loss: 15.4992, Val Loss: 20.0703, F1 Micro: 0.1562, F1 Macro: 0.1093, Accuracy: 0.1562\n","Epoch 65, Train Loss: 11.7483, Val Loss: 7.2650, F1 Micro: 0.2708, F1 Macro: 0.1779, Accuracy: 0.2708\n","Epoch 66, Train Loss: 10.0126, Val Loss: 8.3118, F1 Micro: 0.2083, F1 Macro: 0.1398, Accuracy: 0.2083\n","Epoch 67, Train Loss: 16.5716, Val Loss: 19.1687, F1 Micro: 0.1875, F1 Macro: 0.0906, Accuracy: 0.1875\n","Epoch 68, Train Loss: 16.9205, Val Loss: 7.5032, F1 Micro: 0.3646, F1 Macro: 0.2805, Accuracy: 0.3646\n","Epoch 69, Train Loss: 11.0521, Val Loss: 10.5979, F1 Micro: 0.2188, F1 Macro: 0.1674, Accuracy: 0.2188\n","Epoch 70, Train Loss: 12.3462, Val Loss: 11.2479, F1 Micro: 0.2396, F1 Macro: 0.1320, Accuracy: 0.2396\n","Epoch 71, Train Loss: 13.0610, Val Loss: 13.4700, F1 Micro: 0.2500, F1 Macro: 0.2043, Accuracy: 0.2500\n","Epoch 72, Train Loss: 15.5111, Val Loss: 7.9766, F1 Micro: 0.2500, F1 Macro: 0.2116, Accuracy: 0.2500\n","Epoch 73, Train Loss: 12.7059, Val Loss: 8.7496, F1 Micro: 0.3021, F1 Macro: 0.1889, Accuracy: 0.3021\n","Epoch 74, Train Loss: 11.3107, Val Loss: 4.6838, F1 Micro: 0.3229, F1 Macro: 0.2584, Accuracy: 0.3229\n","Epoch 75, Train Loss: 9.3374, Val Loss: 9.0296, F1 Micro: 0.2292, F1 Macro: 0.1530, Accuracy: 0.2292\n","Epoch 76, Train Loss: 19.4944, Val Loss: 11.6494, F1 Micro: 0.2500, F1 Macro: 0.2119, Accuracy: 0.2500\n","Epoch 77, Train Loss: 9.6636, Val Loss: 5.9043, F1 Micro: 0.2917, F1 Macro: 0.2609, Accuracy: 0.2917\n","Epoch 78, Train Loss: 12.9514, Val Loss: 7.2786, F1 Micro: 0.2812, F1 Macro: 0.1835, Accuracy: 0.2812\n","Epoch 79, Train Loss: 11.9800, Val Loss: 9.6391, F1 Micro: 0.2708, F1 Macro: 0.2263, Accuracy: 0.2708\n","Epoch 80, Train Loss: 11.0904, Val Loss: 11.7947, F1 Micro: 0.2604, F1 Macro: 0.2032, Accuracy: 0.2604\n","Epoch 81, Train Loss: 11.4101, Val Loss: 4.3846, F1 Micro: 0.3854, F1 Macro: 0.2959, Accuracy: 0.3854\n","Epoch 82, Train Loss: 11.0480, Val Loss: 6.3506, F1 Micro: 0.3125, F1 Macro: 0.2592, Accuracy: 0.3125\n","Epoch 83, Train Loss: 7.8424, Val Loss: 8.7915, F1 Micro: 0.2083, F1 Macro: 0.1277, Accuracy: 0.2083\n","Epoch 84, Train Loss: 7.9888, Val Loss: 10.5154, F1 Micro: 0.2396, F1 Macro: 0.1398, Accuracy: 0.2396\n","Epoch 85, Train Loss: 10.4620, Val Loss: 13.0345, F1 Micro: 0.1562, F1 Macro: 0.1095, Accuracy: 0.1562\n","Epoch 86, Train Loss: 12.3311, Val Loss: 17.9934, F1 Micro: 0.2292, F1 Macro: 0.1567, Accuracy: 0.2292\n","Epoch 87, Train Loss: 13.5993, Val Loss: 14.8184, F1 Micro: 0.1875, F1 Macro: 0.1394, Accuracy: 0.1875\n","Epoch 88, Train Loss: 10.6889, Val Loss: 16.8481, F1 Micro: 0.1875, F1 Macro: 0.1249, Accuracy: 0.1875\n","Epoch 89, Train Loss: 10.4811, Val Loss: 5.6014, F1 Micro: 0.2396, F1 Macro: 0.1813, Accuracy: 0.2396\n","Epoch 90, Train Loss: 7.8396, Val Loss: 12.6735, F1 Micro: 0.1979, F1 Macro: 0.1261, Accuracy: 0.1979\n","Epoch 91, Train Loss: 26.0749, Val Loss: 14.1638, F1 Micro: 0.2917, F1 Macro: 0.2167, Accuracy: 0.2917\n","Epoch 92, Train Loss: 18.3564, Val Loss: 5.9348, F1 Micro: 0.3438, F1 Macro: 0.2748, Accuracy: 0.3438\n","Epoch 93, Train Loss: 6.9625, Val Loss: 7.9725, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 94, Train Loss: 6.7678, Val Loss: 5.7648, F1 Micro: 0.2083, F1 Macro: 0.1746, Accuracy: 0.2083\n","Epoch 95, Train Loss: 10.9731, Val Loss: 20.5683, F1 Micro: 0.1979, F1 Macro: 0.1158, Accuracy: 0.1979\n","Epoch 96, Train Loss: 18.2490, Val Loss: 12.3683, F1 Micro: 0.2500, F1 Macro: 0.1825, Accuracy: 0.2500\n","Epoch 97, Train Loss: 17.2208, Val Loss: 9.7128, F1 Micro: 0.3021, F1 Macro: 0.2538, Accuracy: 0.3021\n","Epoch 98, Train Loss: 11.9961, Val Loss: 9.3098, F1 Micro: 0.2708, F1 Macro: 0.2368, Accuracy: 0.2708\n","Epoch 99, Train Loss: 8.5612, Val Loss: 10.4437, F1 Micro: 0.1771, F1 Macro: 0.1358, Accuracy: 0.1771\n","Epoch 100, Train Loss: 12.7120, Val Loss: 15.4755, F1 Micro: 0.1875, F1 Macro: 0.1064, Accuracy: 0.1875\n","Epoch 101, Train Loss: 12.4232, Val Loss: 6.6769, F1 Micro: 0.3021, F1 Macro: 0.2053, Accuracy: 0.3021\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 77.4097, Val Loss: 77.2590, F1 Micro: 0.1562, F1 Macro: 0.0603, Accuracy: 0.1562\n","Epoch 2, Train Loss: 30.7563, Val Loss: 12.4296, F1 Micro: 0.1771, F1 Macro: 0.0966, Accuracy: 0.1771\n","Epoch 3, Train Loss: 18.7715, Val Loss: 37.3248, F1 Micro: 0.2188, F1 Macro: 0.1192, Accuracy: 0.2188\n","Epoch 4, Train Loss: 20.7263, Val Loss: 25.3278, F1 Micro: 0.1354, F1 Macro: 0.0990, Accuracy: 0.1354\n","Epoch 5, Train Loss: 22.7449, Val Loss: 15.5946, F1 Micro: 0.1979, F1 Macro: 0.0565, Accuracy: 0.1979\n","Epoch 6, Train Loss: 18.6457, Val Loss: 23.8026, F1 Micro: 0.1979, F1 Macro: 0.1417, Accuracy: 0.1979\n","Epoch 7, Train Loss: 19.4364, Val Loss: 20.3430, F1 Micro: 0.2292, F1 Macro: 0.2025, Accuracy: 0.2292\n","Epoch 8, Train Loss: 19.5485, Val Loss: 16.3778, F1 Micro: 0.2292, F1 Macro: 0.1482, Accuracy: 0.2292\n","Epoch 9, Train Loss: 20.3081, Val Loss: 20.0835, F1 Micro: 0.2500, F1 Macro: 0.1193, Accuracy: 0.2500\n","Epoch 10, Train Loss: 17.0379, Val Loss: 12.6745, F1 Micro: 0.2188, F1 Macro: 0.1476, Accuracy: 0.2188\n","Epoch 11, Train Loss: 19.2906, Val Loss: 8.7993, F1 Micro: 0.2292, F1 Macro: 0.1815, Accuracy: 0.2292\n","Epoch 12, Train Loss: 18.4540, Val Loss: 31.8422, F1 Micro: 0.1979, F1 Macro: 0.1001, Accuracy: 0.1979\n","Epoch 13, Train Loss: 23.2840, Val Loss: 18.3255, F1 Micro: 0.2292, F1 Macro: 0.1284, Accuracy: 0.2292\n","Epoch 14, Train Loss: 15.0570, Val Loss: 17.7933, F1 Micro: 0.1875, F1 Macro: 0.1064, Accuracy: 0.1875\n","Epoch 15, Train Loss: 15.8297, Val Loss: 13.3767, F1 Micro: 0.3021, F1 Macro: 0.2222, Accuracy: 0.3021\n","Epoch 16, Train Loss: 14.0566, Val Loss: 19.2487, F1 Micro: 0.2188, F1 Macro: 0.1227, Accuracy: 0.2188\n","Epoch 17, Train Loss: 14.3084, Val Loss: 12.6523, F1 Micro: 0.1875, F1 Macro: 0.1500, Accuracy: 0.1875\n","Epoch 18, Train Loss: 12.7588, Val Loss: 19.3338, F1 Micro: 0.2604, F1 Macro: 0.1640, Accuracy: 0.2604\n","Epoch 19, Train Loss: 14.3356, Val Loss: 12.2563, F1 Micro: 0.2500, F1 Macro: 0.1703, Accuracy: 0.2500\n","Epoch 20, Train Loss: 11.9297, Val Loss: 11.2105, F1 Micro: 0.2604, F1 Macro: 0.1548, Accuracy: 0.2604\n","Epoch 21, Train Loss: 11.5957, Val Loss: 14.7949, F1 Micro: 0.1875, F1 Macro: 0.0982, Accuracy: 0.1875\n","Epoch 22, Train Loss: 18.0576, Val Loss: 38.8926, F1 Micro: 0.1354, F1 Macro: 0.0925, Accuracy: 0.1354\n","Epoch 23, Train Loss: 19.5397, Val Loss: 19.1500, F1 Micro: 0.1979, F1 Macro: 0.1537, Accuracy: 0.1979\n","Epoch 24, Train Loss: 13.9098, Val Loss: 17.2520, F1 Micro: 0.3125, F1 Macro: 0.2349, Accuracy: 0.3125\n","Epoch 25, Train Loss: 13.1252, Val Loss: 9.5156, F1 Micro: 0.3333, F1 Macro: 0.2630, Accuracy: 0.3333\n","Epoch 26, Train Loss: 11.3656, Val Loss: 14.0184, F1 Micro: 0.1771, F1 Macro: 0.1082, Accuracy: 0.1771\n","Epoch 27, Train Loss: 9.2327, Val Loss: 17.5602, F1 Micro: 0.1875, F1 Macro: 0.0986, Accuracy: 0.1875\n","Epoch 28, Train Loss: 13.1540, Val Loss: 20.5981, F1 Micro: 0.2604, F1 Macro: 0.2070, Accuracy: 0.2604\n","Epoch 29, Train Loss: 14.4311, Val Loss: 16.1570, F1 Micro: 0.1979, F1 Macro: 0.1586, Accuracy: 0.1979\n","Epoch 30, Train Loss: 13.1505, Val Loss: 6.2130, F1 Micro: 0.3646, F1 Macro: 0.3209, Accuracy: 0.3646\n","Epoch 31, Train Loss: 11.4390, Val Loss: 8.7367, F1 Micro: 0.2708, F1 Macro: 0.1874, Accuracy: 0.2708\n","Epoch 32, Train Loss: 11.8955, Val Loss: 13.4552, F1 Micro: 0.1042, F1 Macro: 0.0535, Accuracy: 0.1042\n","Epoch 33, Train Loss: 17.3080, Val Loss: 16.3662, F1 Micro: 0.2604, F1 Macro: 0.2083, Accuracy: 0.2604\n","Epoch 34, Train Loss: 22.2290, Val Loss: 20.6412, F1 Micro: 0.3125, F1 Macro: 0.2422, Accuracy: 0.3125\n","Epoch 35, Train Loss: 18.6750, Val Loss: 9.4139, F1 Micro: 0.2708, F1 Macro: 0.2329, Accuracy: 0.2708\n","Epoch 36, Train Loss: 11.8227, Val Loss: 8.9427, F1 Micro: 0.2083, F1 Macro: 0.1839, Accuracy: 0.2083\n","Epoch 37, Train Loss: 9.9573, Val Loss: 4.7721, F1 Micro: 0.2917, F1 Macro: 0.2517, Accuracy: 0.2917\n","Epoch 38, Train Loss: 12.9939, Val Loss: 26.1659, F1 Micro: 0.2083, F1 Macro: 0.1487, Accuracy: 0.2083\n","Epoch 39, Train Loss: 14.1963, Val Loss: 6.2695, F1 Micro: 0.2917, F1 Macro: 0.1720, Accuracy: 0.2917\n","Epoch 40, Train Loss: 10.5682, Val Loss: 8.5926, F1 Micro: 0.2917, F1 Macro: 0.1939, Accuracy: 0.2917\n","Epoch 41, Train Loss: 13.2643, Val Loss: 13.7474, F1 Micro: 0.2708, F1 Macro: 0.1352, Accuracy: 0.2708\n","Epoch 42, Train Loss: 11.3612, Val Loss: 12.5405, F1 Micro: 0.3125, F1 Macro: 0.1892, Accuracy: 0.3125\n","Epoch 43, Train Loss: 12.6168, Val Loss: 10.8314, F1 Micro: 0.3229, F1 Macro: 0.2171, Accuracy: 0.3229\n","Epoch 44, Train Loss: 17.2557, Val Loss: 12.8138, F1 Micro: 0.2396, F1 Macro: 0.1465, Accuracy: 0.2396\n","Epoch 45, Train Loss: 14.6021, Val Loss: 22.3237, F1 Micro: 0.1979, F1 Macro: 0.1292, Accuracy: 0.1979\n","Epoch 46, Train Loss: 15.6943, Val Loss: 20.4007, F1 Micro: 0.2292, F1 Macro: 0.1694, Accuracy: 0.2292\n","Epoch 47, Train Loss: 11.3837, Val Loss: 7.1721, F1 Micro: 0.2500, F1 Macro: 0.1705, Accuracy: 0.2500\n","Epoch 48, Train Loss: 9.4460, Val Loss: 11.0333, F1 Micro: 0.2500, F1 Macro: 0.1751, Accuracy: 0.2500\n","Epoch 49, Train Loss: 9.9062, Val Loss: 20.8050, F1 Micro: 0.1042, F1 Macro: 0.0790, Accuracy: 0.1042\n","Epoch 50, Train Loss: 12.3656, Val Loss: 8.9200, F1 Micro: 0.2708, F1 Macro: 0.1900, Accuracy: 0.2708\n","Epoch 51, Train Loss: 9.2618, Val Loss: 9.8612, F1 Micro: 0.2083, F1 Macro: 0.1971, Accuracy: 0.2083\n","Epoch 52, Train Loss: 9.6794, Val Loss: 9.2091, F1 Micro: 0.2500, F1 Macro: 0.1306, Accuracy: 0.2500\n","Epoch 53, Train Loss: 14.2143, Val Loss: 12.7952, F1 Micro: 0.2812, F1 Macro: 0.2148, Accuracy: 0.2812\n","Epoch 54, Train Loss: 8.4861, Val Loss: 7.8126, F1 Micro: 0.2396, F1 Macro: 0.1811, Accuracy: 0.2396\n","Epoch 55, Train Loss: 10.2522, Val Loss: 5.2384, F1 Micro: 0.3333, F1 Macro: 0.3192, Accuracy: 0.3333\n","Epoch 56, Train Loss: 8.7864, Val Loss: 13.0683, F1 Micro: 0.3021, F1 Macro: 0.2335, Accuracy: 0.3021\n","Epoch 57, Train Loss: 8.2224, Val Loss: 7.1112, F1 Micro: 0.2917, F1 Macro: 0.1939, Accuracy: 0.2917\n","Epoch 58, Train Loss: 8.1370, Val Loss: 7.8259, F1 Micro: 0.2292, F1 Macro: 0.2015, Accuracy: 0.2292\n","Epoch 59, Train Loss: 7.6225, Val Loss: 8.8679, F1 Micro: 0.3021, F1 Macro: 0.2070, Accuracy: 0.3021\n","Epoch 60, Train Loss: 7.3152, Val Loss: 7.2203, F1 Micro: 0.3229, F1 Macro: 0.2753, Accuracy: 0.3229\n","Epoch 61, Train Loss: 13.6391, Val Loss: 23.8687, F1 Micro: 0.2708, F1 Macro: 0.1960, Accuracy: 0.2708\n","Epoch 62, Train Loss: 13.8024, Val Loss: 17.2934, F1 Micro: 0.2708, F1 Macro: 0.1760, Accuracy: 0.2708\n","Epoch 63, Train Loss: 15.0564, Val Loss: 24.1850, F1 Micro: 0.2604, F1 Macro: 0.1346, Accuracy: 0.2604\n","Epoch 64, Train Loss: 11.8322, Val Loss: 16.6757, F1 Micro: 0.1979, F1 Macro: 0.1253, Accuracy: 0.1979\n","Epoch 65, Train Loss: 10.9518, Val Loss: 5.5615, F1 Micro: 0.2708, F1 Macro: 0.2501, Accuracy: 0.2708\n","Epoch 66, Train Loss: 7.9477, Val Loss: 9.9541, F1 Micro: 0.2292, F1 Macro: 0.1853, Accuracy: 0.2292\n","Epoch 67, Train Loss: 8.8238, Val Loss: 7.3848, F1 Micro: 0.3021, F1 Macro: 0.2471, Accuracy: 0.3021\n","Epoch 68, Train Loss: 8.3272, Val Loss: 11.1045, F1 Micro: 0.3125, F1 Macro: 0.2382, Accuracy: 0.3125\n","Epoch 69, Train Loss: 13.7763, Val Loss: 10.5634, F1 Micro: 0.2708, F1 Macro: 0.2049, Accuracy: 0.2708\n","Epoch 70, Train Loss: 8.3303, Val Loss: 11.1334, F1 Micro: 0.2292, F1 Macro: 0.1622, Accuracy: 0.2292\n","Epoch 71, Train Loss: 8.8629, Val Loss: 18.4386, F1 Micro: 0.2083, F1 Macro: 0.1258, Accuracy: 0.2083\n","Epoch 72, Train Loss: 13.4482, Val Loss: 6.8863, F1 Micro: 0.3125, F1 Macro: 0.2536, Accuracy: 0.3125\n","Epoch 73, Train Loss: 11.3820, Val Loss: 9.3348, F1 Micro: 0.2604, F1 Macro: 0.2289, Accuracy: 0.2604\n","Epoch 74, Train Loss: 8.8176, Val Loss: 13.8227, F1 Micro: 0.2708, F1 Macro: 0.2059, Accuracy: 0.2708\n","Epoch 75, Train Loss: 8.3163, Val Loss: 10.3120, F1 Micro: 0.2500, F1 Macro: 0.1094, Accuracy: 0.2500\n","Epoch 76, Train Loss: 9.8306, Val Loss: 9.0336, F1 Micro: 0.3438, F1 Macro: 0.2731, Accuracy: 0.3438\n","Epoch 77, Train Loss: 8.0992, Val Loss: 10.5912, F1 Micro: 0.2396, F1 Macro: 0.2036, Accuracy: 0.2396\n","Epoch 78, Train Loss: 14.7674, Val Loss: 21.7817, F1 Micro: 0.2500, F1 Macro: 0.1552, Accuracy: 0.2500\n","Epoch 79, Train Loss: 12.9477, Val Loss: 10.8417, F1 Micro: 0.3438, F1 Macro: 0.2552, Accuracy: 0.3438\n","Epoch 80, Train Loss: 11.8402, Val Loss: 17.0833, F1 Micro: 0.2396, F1 Macro: 0.1106, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 74.1872, Val Loss: 47.9950, F1 Micro: 0.1562, F1 Macro: 0.0735, Accuracy: 0.1562\n","Epoch 2, Train Loss: 34.8261, Val Loss: 30.9699, F1 Micro: 0.2500, F1 Macro: 0.1740, Accuracy: 0.2500\n","Epoch 3, Train Loss: 18.1002, Val Loss: 8.8468, F1 Micro: 0.2188, F1 Macro: 0.1793, Accuracy: 0.2188\n","Epoch 4, Train Loss: 15.4591, Val Loss: 21.2527, F1 Micro: 0.1771, F1 Macro: 0.0917, Accuracy: 0.1771\n","Epoch 5, Train Loss: 19.1617, Val Loss: 20.7023, F1 Micro: 0.1354, F1 Macro: 0.0575, Accuracy: 0.1354\n","Epoch 6, Train Loss: 23.8301, Val Loss: 11.1155, F1 Micro: 0.2396, F1 Macro: 0.1636, Accuracy: 0.2396\n","Epoch 7, Train Loss: 19.4338, Val Loss: 17.7989, F1 Micro: 0.1979, F1 Macro: 0.1008, Accuracy: 0.1979\n","Epoch 8, Train Loss: 14.4527, Val Loss: 12.7707, F1 Micro: 0.1354, F1 Macro: 0.0732, Accuracy: 0.1354\n","Epoch 9, Train Loss: 20.4813, Val Loss: 36.1552, F1 Micro: 0.2188, F1 Macro: 0.1176, Accuracy: 0.2188\n","Epoch 10, Train Loss: 19.0915, Val Loss: 14.3094, F1 Micro: 0.2292, F1 Macro: 0.1400, Accuracy: 0.2292\n","Epoch 11, Train Loss: 13.7306, Val Loss: 7.3288, F1 Micro: 0.1354, F1 Macro: 0.0793, Accuracy: 0.1354\n","Epoch 12, Train Loss: 11.6662, Val Loss: 17.5175, F1 Micro: 0.1875, F1 Macro: 0.0531, Accuracy: 0.1875\n","Epoch 13, Train Loss: 14.4640, Val Loss: 13.8350, F1 Micro: 0.2812, F1 Macro: 0.2105, Accuracy: 0.2812\n","Epoch 14, Train Loss: 9.6118, Val Loss: 10.1989, F1 Micro: 0.2396, F1 Macro: 0.1772, Accuracy: 0.2396\n","Epoch 15, Train Loss: 15.9124, Val Loss: 9.4234, F1 Micro: 0.1562, F1 Macro: 0.0762, Accuracy: 0.1562\n","Epoch 16, Train Loss: 23.3101, Val Loss: 23.5536, F1 Micro: 0.1354, F1 Macro: 0.0405, Accuracy: 0.1354\n","Epoch 17, Train Loss: 16.5870, Val Loss: 17.7291, F1 Micro: 0.1354, F1 Macro: 0.0523, Accuracy: 0.1354\n","Epoch 18, Train Loss: 19.0257, Val Loss: 26.9203, F1 Micro: 0.2188, F1 Macro: 0.1299, Accuracy: 0.2188\n","Epoch 19, Train Loss: 13.1512, Val Loss: 11.0821, F1 Micro: 0.1771, F1 Macro: 0.1119, Accuracy: 0.1771\n","Epoch 20, Train Loss: 11.2558, Val Loss: 10.3926, F1 Micro: 0.1875, F1 Macro: 0.1173, Accuracy: 0.1875\n","Epoch 21, Train Loss: 11.4222, Val Loss: 13.6590, F1 Micro: 0.2500, F1 Macro: 0.1645, Accuracy: 0.2500\n","Epoch 22, Train Loss: 20.3277, Val Loss: 19.5746, F1 Micro: 0.1667, F1 Macro: 0.0864, Accuracy: 0.1667\n","Epoch 23, Train Loss: 21.7776, Val Loss: 28.6068, F1 Micro: 0.2188, F1 Macro: 0.1542, Accuracy: 0.2188\n","Epoch 24, Train Loss: 18.4594, Val Loss: 11.3706, F1 Micro: 0.2708, F1 Macro: 0.1685, Accuracy: 0.2708\n","Epoch 25, Train Loss: 11.5444, Val Loss: 9.2458, F1 Micro: 0.3021, F1 Macro: 0.2439, Accuracy: 0.3021\n","Epoch 26, Train Loss: 11.3959, Val Loss: 11.4352, F1 Micro: 0.2188, F1 Macro: 0.1253, Accuracy: 0.2188\n","Epoch 27, Train Loss: 16.0405, Val Loss: 12.0179, F1 Micro: 0.2917, F1 Macro: 0.1589, Accuracy: 0.2917\n","Epoch 28, Train Loss: 18.9313, Val Loss: 15.7803, F1 Micro: 0.2188, F1 Macro: 0.1288, Accuracy: 0.2188\n","Epoch 29, Train Loss: 19.3367, Val Loss: 12.4233, F1 Micro: 0.2604, F1 Macro: 0.1877, Accuracy: 0.2604\n","Epoch 30, Train Loss: 16.8131, Val Loss: 12.1553, F1 Micro: 0.2500, F1 Macro: 0.1758, Accuracy: 0.2500\n","Epoch 31, Train Loss: 10.4258, Val Loss: 9.9949, F1 Micro: 0.2292, F1 Macro: 0.1837, Accuracy: 0.2292\n","Epoch 32, Train Loss: 10.0760, Val Loss: 9.8081, F1 Micro: 0.2500, F1 Macro: 0.1667, Accuracy: 0.2500\n","Epoch 33, Train Loss: 12.9380, Val Loss: 12.9777, F1 Micro: 0.2604, F1 Macro: 0.1989, Accuracy: 0.2604\n","Epoch 34, Train Loss: 25.0812, Val Loss: 23.1689, F1 Micro: 0.2292, F1 Macro: 0.1246, Accuracy: 0.2292\n","Epoch 35, Train Loss: 19.3334, Val Loss: 33.9041, F1 Micro: 0.2188, F1 Macro: 0.1182, Accuracy: 0.2188\n","Epoch 36, Train Loss: 17.0154, Val Loss: 22.0750, F1 Micro: 0.1875, F1 Macro: 0.0937, Accuracy: 0.1875\n","Epoch 37, Train Loss: 14.2868, Val Loss: 23.7439, F1 Micro: 0.1979, F1 Macro: 0.0697, Accuracy: 0.1979\n","Epoch 38, Train Loss: 26.7802, Val Loss: 27.0629, F1 Micro: 0.2812, F1 Macro: 0.1754, Accuracy: 0.2812\n","Epoch 39, Train Loss: 18.5452, Val Loss: 15.6491, F1 Micro: 0.2188, F1 Macro: 0.1647, Accuracy: 0.2188\n","Epoch 40, Train Loss: 22.8964, Val Loss: 21.1085, F1 Micro: 0.2292, F1 Macro: 0.1367, Accuracy: 0.2292\n","Epoch 41, Train Loss: 16.6586, Val Loss: 21.5829, F1 Micro: 0.2500, F1 Macro: 0.1472, Accuracy: 0.2500\n","Epoch 42, Train Loss: 14.5759, Val Loss: 13.0949, F1 Micro: 0.1979, F1 Macro: 0.1179, Accuracy: 0.1979\n","Epoch 43, Train Loss: 10.8458, Val Loss: 9.4827, F1 Micro: 0.2812, F1 Macro: 0.1876, Accuracy: 0.2812\n","Epoch 44, Train Loss: 10.4239, Val Loss: 15.8049, F1 Micro: 0.2812, F1 Macro: 0.1573, Accuracy: 0.2812\n","Epoch 45, Train Loss: 9.6529, Val Loss: 9.4210, F1 Micro: 0.3438, F1 Macro: 0.2401, Accuracy: 0.3438\n","Epoch 46, Train Loss: 10.2404, Val Loss: 10.2551, F1 Micro: 0.2292, F1 Macro: 0.1417, Accuracy: 0.2292\n","Epoch 47, Train Loss: 12.1878, Val Loss: 15.2325, F1 Micro: 0.2812, F1 Macro: 0.2078, Accuracy: 0.2812\n","Epoch 48, Train Loss: 12.6983, Val Loss: 17.0678, F1 Micro: 0.2708, F1 Macro: 0.1508, Accuracy: 0.2708\n","Epoch 49, Train Loss: 15.0097, Val Loss: 17.5259, F1 Micro: 0.2604, F1 Macro: 0.1802, Accuracy: 0.2604\n","Epoch 50, Train Loss: 15.3814, Val Loss: 14.8436, F1 Micro: 0.2188, F1 Macro: 0.1479, Accuracy: 0.2188\n","Epoch 51, Train Loss: 15.6373, Val Loss: 10.6689, F1 Micro: 0.2917, F1 Macro: 0.2231, Accuracy: 0.2917\n","Epoch 52, Train Loss: 10.7292, Val Loss: 11.6457, F1 Micro: 0.2292, F1 Macro: 0.1750, Accuracy: 0.2292\n","Epoch 53, Train Loss: 12.9433, Val Loss: 10.0866, F1 Micro: 0.2292, F1 Macro: 0.1541, Accuracy: 0.2292\n","Epoch 54, Train Loss: 10.7235, Val Loss: 10.9528, F1 Micro: 0.2708, F1 Macro: 0.2560, Accuracy: 0.2708\n","Epoch 55, Train Loss: 14.6721, Val Loss: 15.6615, F1 Micro: 0.2708, F1 Macro: 0.1674, Accuracy: 0.2708\n","Epoch 56, Train Loss: 13.7786, Val Loss: 13.3717, F1 Micro: 0.2604, F1 Macro: 0.1847, Accuracy: 0.2604\n","Epoch 57, Train Loss: 10.4649, Val Loss: 17.7738, F1 Micro: 0.2292, F1 Macro: 0.1563, Accuracy: 0.2292\n","Epoch 58, Train Loss: 12.4609, Val Loss: 13.2552, F1 Micro: 0.3021, F1 Macro: 0.2099, Accuracy: 0.3021\n","Epoch 59, Train Loss: 14.6446, Val Loss: 13.9350, F1 Micro: 0.2292, F1 Macro: 0.1723, Accuracy: 0.2292\n","Epoch 60, Train Loss: 8.7363, Val Loss: 12.7634, F1 Micro: 0.1979, F1 Macro: 0.1329, Accuracy: 0.1979\n","Epoch 61, Train Loss: 9.4389, Val Loss: 8.1761, F1 Micro: 0.3021, F1 Macro: 0.2006, Accuracy: 0.3021\n","Epoch 62, Train Loss: 10.1607, Val Loss: 18.1850, F1 Micro: 0.2396, F1 Macro: 0.1340, Accuracy: 0.2396\n","Epoch 63, Train Loss: 8.5148, Val Loss: 19.9725, F1 Micro: 0.1771, F1 Macro: 0.0961, Accuracy: 0.1771\n","Epoch 64, Train Loss: 13.8223, Val Loss: 16.8198, F1 Micro: 0.2604, F1 Macro: 0.1795, Accuracy: 0.2604\n","Epoch 65, Train Loss: 10.8470, Val Loss: 8.8429, F1 Micro: 0.2708, F1 Macro: 0.1901, Accuracy: 0.2708\n","Epoch 66, Train Loss: 9.5375, Val Loss: 5.8088, F1 Micro: 0.2917, F1 Macro: 0.2031, Accuracy: 0.2917\n","Epoch 67, Train Loss: 8.2348, Val Loss: 19.8261, F1 Micro: 0.2708, F1 Macro: 0.1553, Accuracy: 0.2708\n","Epoch 68, Train Loss: 12.8566, Val Loss: 19.2782, F1 Micro: 0.2604, F1 Macro: 0.1693, Accuracy: 0.2604\n","Epoch 69, Train Loss: 13.1898, Val Loss: 14.3220, F1 Micro: 0.1562, F1 Macro: 0.0798, Accuracy: 0.1562\n","Epoch 70, Train Loss: 10.9973, Val Loss: 11.8257, F1 Micro: 0.2604, F1 Macro: 0.1780, Accuracy: 0.2604\n","Epoch 71, Train Loss: 12.5944, Val Loss: 15.2462, F1 Micro: 0.2083, F1 Macro: 0.1385, Accuracy: 0.2083\n","Epoch 72, Train Loss: 12.6442, Val Loss: 19.9144, F1 Micro: 0.1979, F1 Macro: 0.0930, Accuracy: 0.1979\n","Epoch 73, Train Loss: 9.4359, Val Loss: 9.7128, F1 Micro: 0.2396, F1 Macro: 0.1893, Accuracy: 0.2396\n","Epoch 74, Train Loss: 9.3863, Val Loss: 10.0517, F1 Micro: 0.2188, F1 Macro: 0.1501, Accuracy: 0.2188\n","Epoch 75, Train Loss: 9.6061, Val Loss: 11.6485, F1 Micro: 0.2500, F1 Macro: 0.1925, Accuracy: 0.2500\n","Epoch 76, Train Loss: 9.7954, Val Loss: 10.0345, F1 Micro: 0.2708, F1 Macro: 0.1773, Accuracy: 0.2708\n","Epoch 77, Train Loss: 11.6823, Val Loss: 14.8550, F1 Micro: 0.2188, F1 Macro: 0.1462, Accuracy: 0.2188\n","Epoch 78, Train Loss: 7.7536, Val Loss: 4.9909, F1 Micro: 0.2708, F1 Macro: 0.2295, Accuracy: 0.2708\n","Epoch 79, Train Loss: 8.6346, Val Loss: 10.7248, F1 Micro: 0.2708, F1 Macro: 0.1975, Accuracy: 0.2708\n","Epoch 80, Train Loss: 11.0960, Val Loss: 11.0806, F1 Micro: 0.2188, F1 Macro: 0.1235, Accuracy: 0.2188\n","Epoch 81, Train Loss: 14.2146, Val Loss: 17.3379, F1 Micro: 0.1562, F1 Macro: 0.0995, Accuracy: 0.1562\n","Epoch 82, Train Loss: 9.4898, Val Loss: 18.3953, F1 Micro: 0.2292, F1 Macro: 0.1634, Accuracy: 0.2292\n","Epoch 83, Train Loss: 8.1973, Val Loss: 11.2792, F1 Micro: 0.2083, F1 Macro: 0.1289, Accuracy: 0.2083\n","Epoch 84, Train Loss: 9.4038, Val Loss: 8.8688, F1 Micro: 0.2812, F1 Macro: 0.2274, Accuracy: 0.2812\n","Epoch 85, Train Loss: 8.4153, Val Loss: 14.8153, F1 Micro: 0.2083, F1 Macro: 0.1217, Accuracy: 0.2083\n","Epoch 86, Train Loss: 8.5520, Val Loss: 8.5043, F1 Micro: 0.2812, F1 Macro: 0.2102, Accuracy: 0.2812\n","Epoch 87, Train Loss: 9.4702, Val Loss: 8.3812, F1 Micro: 0.2500, F1 Macro: 0.1615, Accuracy: 0.2500\n","Epoch 88, Train Loss: 7.6813, Val Loss: 7.1531, F1 Micro: 0.3125, F1 Macro: 0.2720, Accuracy: 0.3125\n","Epoch 89, Train Loss: 10.7153, Val Loss: 16.5847, F1 Micro: 0.2500, F1 Macro: 0.1602, Accuracy: 0.2500\n","Epoch 90, Train Loss: 9.3129, Val Loss: 9.5707, F1 Micro: 0.2500, F1 Macro: 0.1764, Accuracy: 0.2500\n","Epoch 91, Train Loss: 8.9904, Val Loss: 10.4214, F1 Micro: 0.2188, F1 Macro: 0.1965, Accuracy: 0.2188\n","Epoch 92, Train Loss: 8.2089, Val Loss: 9.6575, F1 Micro: 0.2812, F1 Macro: 0.2453, Accuracy: 0.2812\n","Epoch 93, Train Loss: 6.8656, Val Loss: 6.8723, F1 Micro: 0.2604, F1 Macro: 0.1901, Accuracy: 0.2604\n","Epoch 94, Train Loss: 7.6320, Val Loss: 7.6379, F1 Micro: 0.2917, F1 Macro: 0.2406, Accuracy: 0.2917\n","Epoch 95, Train Loss: 7.8450, Val Loss: 11.1334, F1 Micro: 0.2708, F1 Macro: 0.2019, Accuracy: 0.2708\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 78.9119, Val Loss: 21.9027, F1 Micro: 0.1771, F1 Macro: 0.1207, Accuracy: 0.1771\n","Epoch 2, Train Loss: 17.8623, Val Loss: 20.0537, F1 Micro: 0.2708, F1 Macro: 0.2385, Accuracy: 0.2708\n","Epoch 3, Train Loss: 19.5027, Val Loss: 33.9484, F1 Micro: 0.2188, F1 Macro: 0.1283, Accuracy: 0.2188\n","Epoch 4, Train Loss: 27.0575, Val Loss: 11.3164, F1 Micro: 0.2708, F1 Macro: 0.2311, Accuracy: 0.2708\n","Epoch 5, Train Loss: 15.3496, Val Loss: 17.4629, F1 Micro: 0.2396, F1 Macro: 0.1656, Accuracy: 0.2396\n","Epoch 6, Train Loss: 22.1856, Val Loss: 25.2688, F1 Micro: 0.2083, F1 Macro: 0.1098, Accuracy: 0.2083\n","Epoch 7, Train Loss: 28.8830, Val Loss: 15.5500, F1 Micro: 0.2604, F1 Macro: 0.1971, Accuracy: 0.2604\n","Epoch 8, Train Loss: 14.7436, Val Loss: 28.8995, F1 Micro: 0.1667, F1 Macro: 0.0722, Accuracy: 0.1667\n","Epoch 9, Train Loss: 33.4730, Val Loss: 48.2014, F1 Micro: 0.2083, F1 Macro: 0.1136, Accuracy: 0.2083\n","Epoch 10, Train Loss: 26.6807, Val Loss: 13.3500, F1 Micro: 0.2604, F1 Macro: 0.1657, Accuracy: 0.2604\n","Epoch 11, Train Loss: 11.5731, Val Loss: 20.0037, F1 Micro: 0.2708, F1 Macro: 0.1275, Accuracy: 0.2708\n","Epoch 12, Train Loss: 25.6667, Val Loss: 37.1051, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 13, Train Loss: 24.8945, Val Loss: 19.1117, F1 Micro: 0.1979, F1 Macro: 0.1079, Accuracy: 0.1979\n","Epoch 14, Train Loss: 9.0854, Val Loss: 13.1632, F1 Micro: 0.2188, F1 Macro: 0.1413, Accuracy: 0.2188\n","Epoch 15, Train Loss: 13.6064, Val Loss: 13.1072, F1 Micro: 0.3125, F1 Macro: 0.2324, Accuracy: 0.3125\n","Epoch 16, Train Loss: 15.8105, Val Loss: 23.1779, F1 Micro: 0.2604, F1 Macro: 0.1789, Accuracy: 0.2604\n","Epoch 17, Train Loss: 23.7369, Val Loss: 14.6909, F1 Micro: 0.2500, F1 Macro: 0.1678, Accuracy: 0.2500\n","Epoch 18, Train Loss: 27.3992, Val Loss: 35.6087, F1 Micro: 0.2396, F1 Macro: 0.1626, Accuracy: 0.2396\n","Epoch 19, Train Loss: 23.2588, Val Loss: 20.4723, F1 Micro: 0.2188, F1 Macro: 0.1343, Accuracy: 0.2188\n","Epoch 20, Train Loss: 26.0159, Val Loss: 15.0066, F1 Micro: 0.1979, F1 Macro: 0.1026, Accuracy: 0.1979\n","Epoch 21, Train Loss: 16.5631, Val Loss: 24.4341, F1 Micro: 0.2292, F1 Macro: 0.1865, Accuracy: 0.2292\n","Epoch 22, Train Loss: 16.8510, Val Loss: 11.6246, F1 Micro: 0.3229, F1 Macro: 0.2137, Accuracy: 0.3229\n","Epoch 23, Train Loss: 12.7632, Val Loss: 17.3157, F1 Micro: 0.2188, F1 Macro: 0.1534, Accuracy: 0.2188\n","Epoch 24, Train Loss: 15.9715, Val Loss: 23.0938, F1 Micro: 0.2083, F1 Macro: 0.1112, Accuracy: 0.2083\n","Epoch 25, Train Loss: 28.2859, Val Loss: 27.2096, F1 Micro: 0.2292, F1 Macro: 0.1589, Accuracy: 0.2292\n","Epoch 26, Train Loss: 23.9491, Val Loss: 39.9372, F1 Micro: 0.2500, F1 Macro: 0.1601, Accuracy: 0.2500\n","Epoch 27, Train Loss: 22.5996, Val Loss: 9.7940, F1 Micro: 0.2188, F1 Macro: 0.1658, Accuracy: 0.2188\n","Epoch 28, Train Loss: 14.3650, Val Loss: 18.3052, F1 Micro: 0.2500, F1 Macro: 0.1877, Accuracy: 0.2500\n","Epoch 29, Train Loss: 23.3953, Val Loss: 28.7089, F1 Micro: 0.2083, F1 Macro: 0.1314, Accuracy: 0.2083\n","Epoch 30, Train Loss: 19.4727, Val Loss: 20.2642, F1 Micro: 0.2708, F1 Macro: 0.2039, Accuracy: 0.2708\n","Epoch 31, Train Loss: 14.2654, Val Loss: 8.2686, F1 Micro: 0.2812, F1 Macro: 0.2303, Accuracy: 0.2812\n","Epoch 32, Train Loss: 12.1755, Val Loss: 12.9489, F1 Micro: 0.2500, F1 Macro: 0.1235, Accuracy: 0.2500\n","Epoch 33, Train Loss: 11.5779, Val Loss: 13.0610, F1 Micro: 0.1979, F1 Macro: 0.1165, Accuracy: 0.1979\n","Epoch 34, Train Loss: 16.5639, Val Loss: 18.9043, F1 Micro: 0.2604, F1 Macro: 0.2047, Accuracy: 0.2604\n","Epoch 35, Train Loss: 14.4108, Val Loss: 17.6015, F1 Micro: 0.2708, F1 Macro: 0.1664, Accuracy: 0.2708\n","Epoch 36, Train Loss: 12.8700, Val Loss: 14.2918, F1 Micro: 0.3958, F1 Macro: 0.3369, Accuracy: 0.3958\n","Epoch 37, Train Loss: 11.3442, Val Loss: 9.2640, F1 Micro: 0.3646, F1 Macro: 0.3504, Accuracy: 0.3646\n","Epoch 38, Train Loss: 18.3588, Val Loss: 24.8310, F1 Micro: 0.2188, F1 Macro: 0.1384, Accuracy: 0.2188\n","Epoch 39, Train Loss: 17.3291, Val Loss: 16.5565, F1 Micro: 0.2604, F1 Macro: 0.1983, Accuracy: 0.2604\n","Epoch 40, Train Loss: 14.8487, Val Loss: 17.1016, F1 Micro: 0.2708, F1 Macro: 0.1876, Accuracy: 0.2708\n","Epoch 41, Train Loss: 16.1028, Val Loss: 7.9077, F1 Micro: 0.3021, F1 Macro: 0.2724, Accuracy: 0.3021\n","Epoch 42, Train Loss: 12.7342, Val Loss: 15.8691, F1 Micro: 0.3854, F1 Macro: 0.2957, Accuracy: 0.3854\n","Epoch 43, Train Loss: 12.5665, Val Loss: 11.1270, F1 Micro: 0.2188, F1 Macro: 0.1323, Accuracy: 0.2188\n","Epoch 44, Train Loss: 11.5564, Val Loss: 17.8004, F1 Micro: 0.2917, F1 Macro: 0.1893, Accuracy: 0.2917\n","Epoch 45, Train Loss: 18.8118, Val Loss: 12.8045, F1 Micro: 0.2604, F1 Macro: 0.2147, Accuracy: 0.2604\n","Epoch 46, Train Loss: 14.6097, Val Loss: 12.3274, F1 Micro: 0.2500, F1 Macro: 0.1412, Accuracy: 0.2500\n","Epoch 47, Train Loss: 9.8173, Val Loss: 10.6325, F1 Micro: 0.2917, F1 Macro: 0.2103, Accuracy: 0.2917\n","Epoch 48, Train Loss: 12.1768, Val Loss: 6.6175, F1 Micro: 0.2708, F1 Macro: 0.2216, Accuracy: 0.2708\n","Epoch 49, Train Loss: 10.7241, Val Loss: 16.1027, F1 Micro: 0.2500, F1 Macro: 0.2118, Accuracy: 0.2500\n","Epoch 50, Train Loss: 11.7844, Val Loss: 9.7505, F1 Micro: 0.2604, F1 Macro: 0.2106, Accuracy: 0.2604\n","Epoch 51, Train Loss: 10.1392, Val Loss: 16.7113, F1 Micro: 0.2500, F1 Macro: 0.1633, Accuracy: 0.2500\n","Epoch 52, Train Loss: 14.6419, Val Loss: 26.0176, F1 Micro: 0.1979, F1 Macro: 0.0975, Accuracy: 0.1979\n","Epoch 53, Train Loss: 11.7176, Val Loss: 7.6650, F1 Micro: 0.2500, F1 Macro: 0.1892, Accuracy: 0.2500\n","Epoch 54, Train Loss: 10.0092, Val Loss: 8.9465, F1 Micro: 0.2812, F1 Macro: 0.2223, Accuracy: 0.2812\n","Epoch 55, Train Loss: 16.5849, Val Loss: 31.7105, F1 Micro: 0.2604, F1 Macro: 0.1826, Accuracy: 0.2604\n","Epoch 56, Train Loss: 19.0076, Val Loss: 17.0310, F1 Micro: 0.2708, F1 Macro: 0.2212, Accuracy: 0.2708\n","Epoch 57, Train Loss: 14.1287, Val Loss: 17.4988, F1 Micro: 0.2708, F1 Macro: 0.1747, Accuracy: 0.2708\n","Epoch 58, Train Loss: 11.5178, Val Loss: 6.1609, F1 Micro: 0.2708, F1 Macro: 0.2382, Accuracy: 0.2708\n","Epoch 59, Train Loss: 7.5914, Val Loss: 12.3863, F1 Micro: 0.2917, F1 Macro: 0.1908, Accuracy: 0.2917\n","Epoch 60, Train Loss: 11.7141, Val Loss: 10.1473, F1 Micro: 0.2812, F1 Macro: 0.2090, Accuracy: 0.2812\n","Epoch 61, Train Loss: 14.5683, Val Loss: 7.4929, F1 Micro: 0.3125, F1 Macro: 0.2439, Accuracy: 0.3125\n","Epoch 62, Train Loss: 8.6568, Val Loss: 18.1788, F1 Micro: 0.2396, F1 Macro: 0.1710, Accuracy: 0.2396\n","Epoch 63, Train Loss: 13.7692, Val Loss: 8.0219, F1 Micro: 0.2812, F1 Macro: 0.2042, Accuracy: 0.2812\n","Epoch 64, Train Loss: 15.2449, Val Loss: 26.9907, F1 Micro: 0.2188, F1 Macro: 0.1281, Accuracy: 0.2188\n","Epoch 65, Train Loss: 18.1438, Val Loss: 15.7204, F1 Micro: 0.2604, F1 Macro: 0.2134, Accuracy: 0.2604\n","Epoch 66, Train Loss: 11.6611, Val Loss: 9.1951, F1 Micro: 0.2604, F1 Macro: 0.1819, Accuracy: 0.2604\n","Epoch 67, Train Loss: 15.3251, Val Loss: 23.7229, F1 Micro: 0.1979, F1 Macro: 0.1034, Accuracy: 0.1979\n","Epoch 68, Train Loss: 19.6585, Val Loss: 7.8950, F1 Micro: 0.3333, F1 Macro: 0.2834, Accuracy: 0.3333\n","Epoch 69, Train Loss: 15.1017, Val Loss: 34.9609, F1 Micro: 0.2188, F1 Macro: 0.1414, Accuracy: 0.2188\n","Epoch 70, Train Loss: 18.1001, Val Loss: 9.7692, F1 Micro: 0.3229, F1 Macro: 0.3146, Accuracy: 0.3229\n","Epoch 71, Train Loss: 8.7781, Val Loss: 8.3313, F1 Micro: 0.2917, F1 Macro: 0.2326, Accuracy: 0.2917\n","Epoch 72, Train Loss: 8.2121, Val Loss: 10.9530, F1 Micro: 0.2708, F1 Macro: 0.2203, Accuracy: 0.2708\n","Epoch 73, Train Loss: 13.8443, Val Loss: 16.8578, F1 Micro: 0.2292, F1 Macro: 0.1749, Accuracy: 0.2292\n","Epoch 74, Train Loss: 14.0131, Val Loss: 15.4278, F1 Micro: 0.2500, F1 Macro: 0.1740, Accuracy: 0.2500\n","Epoch 75, Train Loss: 13.3407, Val Loss: 14.9036, F1 Micro: 0.3333, F1 Macro: 0.2518, Accuracy: 0.3333\n","Epoch 76, Train Loss: 10.4155, Val Loss: 9.8153, F1 Micro: 0.2812, F1 Macro: 0.2124, Accuracy: 0.2812\n","Epoch 77, Train Loss: 11.9133, Val Loss: 20.2753, F1 Micro: 0.2604, F1 Macro: 0.1761, Accuracy: 0.2604\n","Epoch 78, Train Loss: 14.8647, Val Loss: 9.1165, F1 Micro: 0.2917, F1 Macro: 0.2415, Accuracy: 0.2917\n","Epoch 79, Train Loss: 15.8378, Val Loss: 11.8139, F1 Micro: 0.3021, F1 Macro: 0.2777, Accuracy: 0.3021\n","Epoch 80, Train Loss: 13.2009, Val Loss: 24.1135, F1 Micro: 0.2917, F1 Macro: 0.2053, Accuracy: 0.2917\n","Epoch 81, Train Loss: 15.7596, Val Loss: 9.6579, F1 Micro: 0.2812, F1 Macro: 0.2061, Accuracy: 0.2812\n","Epoch 82, Train Loss: 7.2796, Val Loss: 4.8495, F1 Micro: 0.3021, F1 Macro: 0.2248, Accuracy: 0.3021\n","Epoch 83, Train Loss: 5.2091, Val Loss: 4.8271, F1 Micro: 0.2292, F1 Macro: 0.1829, Accuracy: 0.2292\n","Epoch 84, Train Loss: 6.7634, Val Loss: 9.6950, F1 Micro: 0.2812, F1 Macro: 0.2374, Accuracy: 0.2812\n","Epoch 85, Train Loss: 11.4434, Val Loss: 9.0970, F1 Micro: 0.1979, F1 Macro: 0.1231, Accuracy: 0.1979\n","Epoch 86, Train Loss: 8.0524, Val Loss: 7.6411, F1 Micro: 0.1979, F1 Macro: 0.1260, Accuracy: 0.1979\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.38125\n","Best hyperparameters for Outer FOLD 3: (0.01, 16, 50) with score 0.425\n","Epoch 1, Train Loss: 437.8119, Val Loss: 99.7486, F1 Micro: 0.2583, F1 Macro: 0.1978, Accuracy: 0.2583\n","Epoch 2, Train Loss: 66.1575, Val Loss: 37.5132, F1 Micro: 0.1917, F1 Macro: 0.1265, Accuracy: 0.1917\n","Epoch 3, Train Loss: 21.9474, Val Loss: 9.8675, F1 Micro: 0.2583, F1 Macro: 0.2136, Accuracy: 0.2583\n","Epoch 4, Train Loss: 8.9485, Val Loss: 7.4646, F1 Micro: 0.2333, F1 Macro: 0.1586, Accuracy: 0.2333\n","Epoch 5, Train Loss: 8.9294, Val Loss: 8.7216, F1 Micro: 0.2417, F1 Macro: 0.1508, Accuracy: 0.2417\n","Epoch 6, Train Loss: 7.3420, Val Loss: 6.4560, F1 Micro: 0.2083, F1 Macro: 0.1820, Accuracy: 0.2083\n","Epoch 7, Train Loss: 4.9763, Val Loss: 6.5363, F1 Micro: 0.2667, F1 Macro: 0.2504, Accuracy: 0.2667\n","Epoch 8, Train Loss: 6.2239, Val Loss: 5.7536, F1 Micro: 0.3500, F1 Macro: 0.2910, Accuracy: 0.3500\n","Epoch 9, Train Loss: 5.5743, Val Loss: 7.6032, F1 Micro: 0.2250, F1 Macro: 0.1633, Accuracy: 0.2250\n","Epoch 10, Train Loss: 7.3623, Val Loss: 8.5003, F1 Micro: 0.2000, F1 Macro: 0.1524, Accuracy: 0.2000\n","Epoch 11, Train Loss: 7.0304, Val Loss: 6.9330, F1 Micro: 0.1917, F1 Macro: 0.1537, Accuracy: 0.1917\n","Epoch 12, Train Loss: 6.5687, Val Loss: 6.7938, F1 Micro: 0.1667, F1 Macro: 0.1364, Accuracy: 0.1667\n","Epoch 13, Train Loss: 4.8193, Val Loss: 4.2281, F1 Micro: 0.2833, F1 Macro: 0.2299, Accuracy: 0.2833\n","Epoch 14, Train Loss: 4.2133, Val Loss: 5.4909, F1 Micro: 0.2917, F1 Macro: 0.2975, Accuracy: 0.2917\n","Epoch 15, Train Loss: 3.8283, Val Loss: 3.7461, F1 Micro: 0.2000, F1 Macro: 0.1638, Accuracy: 0.2000\n","Epoch 16, Train Loss: 3.6980, Val Loss: 4.2509, F1 Micro: 0.2583, F1 Macro: 0.2421, Accuracy: 0.2583\n","Epoch 17, Train Loss: 3.9204, Val Loss: 3.4077, F1 Micro: 0.3000, F1 Macro: 0.3029, Accuracy: 0.3000\n","Epoch 18, Train Loss: 3.9195, Val Loss: 4.4659, F1 Micro: 0.3417, F1 Macro: 0.2732, Accuracy: 0.3417\n","Epoch 19, Train Loss: 4.1177, Val Loss: 5.0018, F1 Micro: 0.2583, F1 Macro: 0.2282, Accuracy: 0.2583\n","Epoch 20, Train Loss: 2.9687, Val Loss: 2.8968, F1 Micro: 0.3167, F1 Macro: 0.2722, Accuracy: 0.3167\n","Epoch 21, Train Loss: 2.7604, Val Loss: 2.9155, F1 Micro: 0.3083, F1 Macro: 0.2617, Accuracy: 0.3083\n","Epoch 22, Train Loss: 3.5198, Val Loss: 5.6643, F1 Micro: 0.2333, F1 Macro: 0.1654, Accuracy: 0.2333\n","Epoch 23, Train Loss: 4.1243, Val Loss: 7.3163, F1 Micro: 0.2000, F1 Macro: 0.1739, Accuracy: 0.2000\n","Epoch 24, Train Loss: 3.5563, Val Loss: 2.4443, F1 Micro: 0.3500, F1 Macro: 0.3286, Accuracy: 0.3500\n","Epoch 25, Train Loss: 2.7716, Val Loss: 3.2871, F1 Micro: 0.3083, F1 Macro: 0.2505, Accuracy: 0.3083\n","Epoch 26, Train Loss: 2.8157, Val Loss: 3.2965, F1 Micro: 0.2333, F1 Macro: 0.1937, Accuracy: 0.2333\n","Epoch 27, Train Loss: 2.8977, Val Loss: 5.1618, F1 Micro: 0.2083, F1 Macro: 0.1007, Accuracy: 0.2083\n","Epoch 28, Train Loss: 4.3794, Val Loss: 5.6178, F1 Micro: 0.2500, F1 Macro: 0.2281, Accuracy: 0.2500\n","Epoch 29, Train Loss: 5.1316, Val Loss: 4.9972, F1 Micro: 0.2333, F1 Macro: 0.1548, Accuracy: 0.2333\n","Epoch 30, Train Loss: 3.6402, Val Loss: 3.6243, F1 Micro: 0.3917, F1 Macro: 0.3609, Accuracy: 0.3917\n","Epoch 31, Train Loss: 3.1203, Val Loss: 4.7744, F1 Micro: 0.2583, F1 Macro: 0.1950, Accuracy: 0.2583\n","Epoch 32, Train Loss: 3.2658, Val Loss: 2.4492, F1 Micro: 0.2583, F1 Macro: 0.2574, Accuracy: 0.2583\n","Epoch 33, Train Loss: 2.9876, Val Loss: 4.4390, F1 Micro: 0.2417, F1 Macro: 0.1467, Accuracy: 0.2417\n","Epoch 34, Train Loss: 4.7167, Val Loss: 5.1984, F1 Micro: 0.1167, F1 Macro: 0.0830, Accuracy: 0.1167\n","Epoch 35, Train Loss: 4.8928, Val Loss: 6.2135, F1 Micro: 0.2000, F1 Macro: 0.1117, Accuracy: 0.2000\n","Epoch 36, Train Loss: 5.3201, Val Loss: 4.7187, F1 Micro: 0.2333, F1 Macro: 0.1932, Accuracy: 0.2333\n","Epoch 37, Train Loss: 5.3514, Val Loss: 6.4065, F1 Micro: 0.1833, F1 Macro: 0.1374, Accuracy: 0.1833\n","Epoch 38, Train Loss: 5.9967, Val Loss: 8.1365, F1 Micro: 0.2167, F1 Macro: 0.1209, Accuracy: 0.2167\n","Epoch 39, Train Loss: 6.2551, Val Loss: 6.3173, F1 Micro: 0.1667, F1 Macro: 0.0796, Accuracy: 0.1667\n","Epoch 40, Train Loss: 4.3562, Val Loss: 4.0996, F1 Micro: 0.1833, F1 Macro: 0.1218, Accuracy: 0.1833\n","Epoch 41, Train Loss: 3.7294, Val Loss: 4.1064, F1 Micro: 0.2333, F1 Macro: 0.1949, Accuracy: 0.2333\n","Epoch 42, Train Loss: 2.7074, Val Loss: 2.4399, F1 Micro: 0.2667, F1 Macro: 0.2313, Accuracy: 0.2667\n","Epoch 43, Train Loss: 2.6346, Val Loss: 3.0401, F1 Micro: 0.3083, F1 Macro: 0.2496, Accuracy: 0.3083\n","Epoch 44, Train Loss: 3.2150, Val Loss: 4.3387, F1 Micro: 0.1833, F1 Macro: 0.1346, Accuracy: 0.1833\n","Epoch 45, Train Loss: 3.2716, Val Loss: 2.9881, F1 Micro: 0.2167, F1 Macro: 0.1565, Accuracy: 0.2167\n","Epoch 46, Train Loss: 2.8391, Val Loss: 2.8538, F1 Micro: 0.2333, F1 Macro: 0.1780, Accuracy: 0.2333\n","Epoch 47, Train Loss: 2.3051, Val Loss: 2.0571, F1 Micro: 0.3833, F1 Macro: 0.3654, Accuracy: 0.3833\n","Epoch 48, Train Loss: 3.3324, Val Loss: 7.2024, F1 Micro: 0.1583, F1 Macro: 0.1200, Accuracy: 0.1583\n","Epoch 49, Train Loss: 6.8142, Val Loss: 9.5792, F1 Micro: 0.2250, F1 Macro: 0.1483, Accuracy: 0.2250\n","Epoch 50, Train Loss: 12.0658, Val Loss: 7.6402, F1 Micro: 0.3083, F1 Macro: 0.2085, Accuracy: 0.3083\n","Epoch 51, Train Loss: 24.4681, Val Loss: 22.4613, F1 Micro: 0.2250, F1 Macro: 0.1517, Accuracy: 0.2250\n","Epoch 52, Train Loss: 110.7408, Val Loss: 264.1373, F1 Micro: 0.1917, F1 Macro: 0.0536, Accuracy: 0.1917\n","Epoch 53, Train Loss: 137.7593, Val Loss: 304.6883, F1 Micro: 0.2333, F1 Macro: 0.1339, Accuracy: 0.2333\n","Epoch 54, Train Loss: 304.1776, Val Loss: 254.8758, F1 Micro: 0.1583, F1 Macro: 0.0456, Accuracy: 0.1583\n","Epoch 55, Train Loss: 331.1449, Val Loss: 340.9376, F1 Micro: 0.1583, F1 Macro: 0.0459, Accuracy: 0.1583\n","Epoch 56, Train Loss: 266.8441, Val Loss: 168.7423, F1 Micro: 0.1583, F1 Macro: 0.0994, Accuracy: 0.1583\n","Epoch 57, Train Loss: 80.1714, Val Loss: 87.6937, F1 Micro: 0.2000, F1 Macro: 0.0740, Accuracy: 0.2000\n","Epoch 58, Train Loss: 51.6787, Val Loss: 39.4733, F1 Micro: 0.1167, F1 Macro: 0.0601, Accuracy: 0.1167\n","Epoch 59, Train Loss: 19.2006, Val Loss: 15.8187, F1 Micro: 0.2667, F1 Macro: 0.1808, Accuracy: 0.2667\n","Epoch 60, Train Loss: 9.4510, Val Loss: 9.1846, F1 Micro: 0.2833, F1 Macro: 0.2361, Accuracy: 0.2833\n","Epoch 61, Train Loss: 4.3917, Val Loss: 2.9829, F1 Micro: 0.3417, F1 Macro: 0.2969, Accuracy: 0.3417\n","Epoch 62, Train Loss: 2.1834, Val Loss: 2.4627, F1 Micro: 0.4083, F1 Macro: 0.3692, Accuracy: 0.4083\n","Epoch 63, Train Loss: 2.0419, Val Loss: 2.4769, F1 Micro: 0.3000, F1 Macro: 0.2780, Accuracy: 0.3000\n","Epoch 64, Train Loss: 2.0305, Val Loss: 2.1167, F1 Micro: 0.2750, F1 Macro: 0.2443, Accuracy: 0.2750\n","Epoch 65, Train Loss: 2.3605, Val Loss: 2.5639, F1 Micro: 0.3500, F1 Macro: 0.3461, Accuracy: 0.3500\n","Epoch 66, Train Loss: 1.9185, Val Loss: 1.9629, F1 Micro: 0.3833, F1 Macro: 0.3520, Accuracy: 0.3833\n","Epoch 67, Train Loss: 1.7226, Val Loss: 1.9573, F1 Micro: 0.3083, F1 Macro: 0.2721, Accuracy: 0.3083\n","Epoch 68, Train Loss: 1.9283, Val Loss: 2.1771, F1 Micro: 0.3333, F1 Macro: 0.3052, Accuracy: 0.3333\n","Epoch 69, Train Loss: 1.9892, Val Loss: 2.4224, F1 Micro: 0.3083, F1 Macro: 0.2960, Accuracy: 0.3083\n","Epoch 70, Train Loss: 1.8630, Val Loss: 2.3455, F1 Micro: 0.2750, F1 Macro: 0.2779, Accuracy: 0.2750\n","Epoch 71, Train Loss: 1.8691, Val Loss: 2.2376, F1 Micro: 0.3000, F1 Macro: 0.2510, Accuracy: 0.3000\n","Epoch 72, Train Loss: 1.7702, Val Loss: 1.9910, F1 Micro: 0.3083, F1 Macro: 0.2779, Accuracy: 0.3083\n","Epoch 73, Train Loss: 1.9539, Val Loss: 3.3035, F1 Micro: 0.2417, F1 Macro: 0.1871, Accuracy: 0.2417\n","Epoch 74, Train Loss: 2.0830, Val Loss: 2.0973, F1 Micro: 0.3833, F1 Macro: 0.3661, Accuracy: 0.3833\n","Epoch 75, Train Loss: 1.9010, Val Loss: 2.0462, F1 Micro: 0.3500, F1 Macro: 0.3314, Accuracy: 0.3500\n","Epoch 76, Train Loss: 2.0401, Val Loss: 2.1742, F1 Micro: 0.3000, F1 Macro: 0.2520, Accuracy: 0.3000\n","Epoch 77, Train Loss: 2.0789, Val Loss: 2.4884, F1 Micro: 0.2917, F1 Macro: 0.2815, Accuracy: 0.2917\n","Epoch 78, Train Loss: 2.4638, Val Loss: 2.1624, F1 Micro: 0.2833, F1 Macro: 0.2779, Accuracy: 0.2833\n","Epoch 79, Train Loss: 1.8511, Val Loss: 2.2435, F1 Micro: 0.3167, F1 Macro: 0.2702, Accuracy: 0.3167\n","Epoch 80, Train Loss: 1.8411, Val Loss: 2.2057, F1 Micro: 0.2833, F1 Macro: 0.2476, Accuracy: 0.2833\n","Epoch 81, Train Loss: 1.8334, Val Loss: 2.4107, F1 Micro: 0.2250, F1 Macro: 0.2322, Accuracy: 0.2250\n","Epoch 82, Train Loss: 2.1422, Val Loss: 2.4400, F1 Micro: 0.3000, F1 Macro: 0.2541, Accuracy: 0.3000\n","Epoch 83, Train Loss: 2.3286, Val Loss: 2.8723, F1 Micro: 0.2167, F1 Macro: 0.1848, Accuracy: 0.2167\n","Epoch 84, Train Loss: 2.1571, Val Loss: 2.4624, F1 Micro: 0.2833, F1 Macro: 0.2670, Accuracy: 0.2833\n","Epoch 85, Train Loss: 2.2378, Val Loss: 2.2357, F1 Micro: 0.3500, F1 Macro: 0.3131, Accuracy: 0.3500\n","Epoch 86, Train Loss: 2.6541, Val Loss: 2.2484, F1 Micro: 0.3667, F1 Macro: 0.3512, Accuracy: 0.3667\n","Epoch 87, Train Loss: 2.2985, Val Loss: 2.8803, F1 Micro: 0.3417, F1 Macro: 0.3164, Accuracy: 0.3417\n","Epoch 88, Train Loss: 2.0747, Val Loss: 2.2941, F1 Micro: 0.2917, F1 Macro: 0.3124, Accuracy: 0.2917\n","Epoch 89, Train Loss: 2.1308, Val Loss: 2.4324, F1 Micro: 0.3000, F1 Macro: 0.2796, Accuracy: 0.3000\n","Epoch 90, Train Loss: 2.0420, Val Loss: 1.9947, F1 Micro: 0.3250, F1 Macro: 0.3060, Accuracy: 0.3250\n","Epoch 91, Train Loss: 1.9698, Val Loss: 2.1079, F1 Micro: 0.3417, F1 Macro: 0.3240, Accuracy: 0.3417\n","Epoch 92, Train Loss: 1.8889, Val Loss: 2.3889, F1 Micro: 0.2333, F1 Macro: 0.2146, Accuracy: 0.2333\n","Epoch 93, Train Loss: 1.9484, Val Loss: 2.1967, F1 Micro: 0.3167, F1 Macro: 0.2971, Accuracy: 0.3167\n","Epoch 94, Train Loss: 1.9902, Val Loss: 2.1953, F1 Micro: 0.3583, F1 Macro: 0.2970, Accuracy: 0.3583\n","Epoch 95, Train Loss: 2.0103, Val Loss: 2.2862, F1 Micro: 0.3750, F1 Macro: 0.3351, Accuracy: 0.3750\n","Epoch 96, Train Loss: 2.0005, Val Loss: 2.3214, F1 Micro: 0.3250, F1 Macro: 0.3075, Accuracy: 0.3250\n","Epoch 97, Train Loss: 2.0659, Val Loss: 1.9261, F1 Micro: 0.3833, F1 Macro: 0.3837, Accuracy: 0.3833\n","Epoch 98, Train Loss: 2.0020, Val Loss: 2.3724, F1 Micro: 0.2250, F1 Macro: 0.1976, Accuracy: 0.2250\n","Epoch 99, Train Loss: 2.0628, Val Loss: 2.1123, F1 Micro: 0.3000, F1 Macro: 0.2292, Accuracy: 0.3000\n","Epoch 100, Train Loss: 2.0256, Val Loss: 2.4052, F1 Micro: 0.3000, F1 Macro: 0.2384, Accuracy: 0.3000\n","Epoch 101, Train Loss: 1.9738, Val Loss: 2.2163, F1 Micro: 0.3333, F1 Macro: 0.3290, Accuracy: 0.3333\n","Epoch 102, Train Loss: 1.9978, Val Loss: 1.8854, F1 Micro: 0.3750, F1 Macro: 0.3878, Accuracy: 0.3750\n","Epoch 103, Train Loss: 2.0221, Val Loss: 2.2956, F1 Micro: 0.2917, F1 Macro: 0.2715, Accuracy: 0.2917\n","Epoch 104, Train Loss: 2.0254, Val Loss: 1.9013, F1 Micro: 0.3167, F1 Macro: 0.3169, Accuracy: 0.3167\n","Epoch 105, Train Loss: 2.0005, Val Loss: 2.6794, F1 Micro: 0.2917, F1 Macro: 0.2600, Accuracy: 0.2917\n","Epoch 106, Train Loss: 2.1212, Val Loss: 2.0802, F1 Micro: 0.3417, F1 Macro: 0.2866, Accuracy: 0.3417\n","Epoch 107, Train Loss: 1.8045, Val Loss: 2.2127, F1 Micro: 0.3250, F1 Macro: 0.2894, Accuracy: 0.3250\n","Epoch 108, Train Loss: 1.7708, Val Loss: 1.7601, F1 Micro: 0.3583, F1 Macro: 0.3330, Accuracy: 0.3583\n","Epoch 109, Train Loss: 1.7397, Val Loss: 2.7019, F1 Micro: 0.3917, F1 Macro: 0.3403, Accuracy: 0.3917\n","Epoch 110, Train Loss: 2.0583, Val Loss: 2.4753, F1 Micro: 0.3167, F1 Macro: 0.3032, Accuracy: 0.3167\n","Epoch 111, Train Loss: 1.8900, Val Loss: 2.6483, F1 Micro: 0.2917, F1 Macro: 0.2435, Accuracy: 0.2917\n","Epoch 112, Train Loss: 2.1697, Val Loss: 2.8745, F1 Micro: 0.2750, F1 Macro: 0.1989, Accuracy: 0.2750\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.2750, F1 Macro: 0.1989, Accuracy: 0.2750\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 334.6504, Val Loss: 65.3833, F1 Micro: 0.2396, F1 Macro: 0.1661, Accuracy: 0.2396\n","Epoch 2, Train Loss: 47.4794, Val Loss: 27.1595, F1 Micro: 0.2708, F1 Macro: 0.1992, Accuracy: 0.2708\n","Epoch 3, Train Loss: 17.3960, Val Loss: 25.0066, F1 Micro: 0.1250, F1 Macro: 0.0548, Accuracy: 0.1250\n","Epoch 4, Train Loss: 14.6055, Val Loss: 8.4052, F1 Micro: 0.2500, F1 Macro: 0.2525, Accuracy: 0.2500\n","Epoch 5, Train Loss: 9.0635, Val Loss: 6.4343, F1 Micro: 0.2917, F1 Macro: 0.2983, Accuracy: 0.2917\n","Epoch 6, Train Loss: 7.8997, Val Loss: 11.8498, F1 Micro: 0.1875, F1 Macro: 0.1369, Accuracy: 0.1875\n","Epoch 7, Train Loss: 10.3030, Val Loss: 13.9754, F1 Micro: 0.1979, F1 Macro: 0.1033, Accuracy: 0.1979\n","Epoch 8, Train Loss: 9.5178, Val Loss: 10.2002, F1 Micro: 0.1979, F1 Macro: 0.1679, Accuracy: 0.1979\n","Epoch 9, Train Loss: 7.3475, Val Loss: 7.0589, F1 Micro: 0.2500, F1 Macro: 0.1970, Accuracy: 0.2500\n","Epoch 10, Train Loss: 6.8295, Val Loss: 7.5367, F1 Micro: 0.2083, F1 Macro: 0.1609, Accuracy: 0.2083\n","Epoch 11, Train Loss: 7.3451, Val Loss: 10.5043, F1 Micro: 0.2396, F1 Macro: 0.1874, Accuracy: 0.2396\n","Epoch 12, Train Loss: 5.6664, Val Loss: 2.9630, F1 Micro: 0.3229, F1 Macro: 0.3195, Accuracy: 0.3229\n","Epoch 13, Train Loss: 6.0560, Val Loss: 10.4355, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 14, Train Loss: 13.0359, Val Loss: 8.5798, F1 Micro: 0.1667, F1 Macro: 0.1431, Accuracy: 0.1667\n","Epoch 15, Train Loss: 10.9835, Val Loss: 8.9944, F1 Micro: 0.2604, F1 Macro: 0.1703, Accuracy: 0.2604\n","Epoch 16, Train Loss: 7.5788, Val Loss: 9.8613, F1 Micro: 0.2292, F1 Macro: 0.1512, Accuracy: 0.2292\n","Epoch 17, Train Loss: 6.3746, Val Loss: 9.1400, F1 Micro: 0.2083, F1 Macro: 0.1478, Accuracy: 0.2083\n","Epoch 18, Train Loss: 6.7618, Val Loss: 6.9643, F1 Micro: 0.2083, F1 Macro: 0.1165, Accuracy: 0.2083\n","Epoch 19, Train Loss: 10.3762, Val Loss: 13.7814, F1 Micro: 0.2708, F1 Macro: 0.1647, Accuracy: 0.2708\n","Epoch 20, Train Loss: 10.4658, Val Loss: 13.4304, F1 Micro: 0.1667, F1 Macro: 0.0890, Accuracy: 0.1667\n","Epoch 21, Train Loss: 9.2258, Val Loss: 26.4156, F1 Micro: 0.2604, F1 Macro: 0.1411, Accuracy: 0.2604\n","Epoch 22, Train Loss: 20.3475, Val Loss: 25.7918, F1 Micro: 0.2604, F1 Macro: 0.1364, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 326.9625, Val Loss: 91.0022, F1 Micro: 0.2292, F1 Macro: 0.1381, Accuracy: 0.2292\n","Epoch 2, Train Loss: 40.4967, Val Loss: 14.5699, F1 Micro: 0.2292, F1 Macro: 0.1689, Accuracy: 0.2292\n","Epoch 3, Train Loss: 11.4304, Val Loss: 19.9843, F1 Micro: 0.1979, F1 Macro: 0.1050, Accuracy: 0.1979\n","Epoch 4, Train Loss: 13.7755, Val Loss: 10.7998, F1 Micro: 0.2917, F1 Macro: 0.2404, Accuracy: 0.2917\n","Epoch 5, Train Loss: 6.9788, Val Loss: 4.8015, F1 Micro: 0.2604, F1 Macro: 0.1912, Accuracy: 0.2604\n","Epoch 6, Train Loss: 7.8423, Val Loss: 14.7634, F1 Micro: 0.2604, F1 Macro: 0.2111, Accuracy: 0.2604\n","Epoch 7, Train Loss: 9.6013, Val Loss: 10.5888, F1 Micro: 0.2292, F1 Macro: 0.1561, Accuracy: 0.2292\n","Epoch 8, Train Loss: 8.0475, Val Loss: 5.7700, F1 Micro: 0.2188, F1 Macro: 0.1692, Accuracy: 0.2188\n","Epoch 9, Train Loss: 7.0494, Val Loss: 8.1242, F1 Micro: 0.2083, F1 Macro: 0.1636, Accuracy: 0.2083\n","Epoch 10, Train Loss: 6.2944, Val Loss: 8.4661, F1 Micro: 0.1979, F1 Macro: 0.1679, Accuracy: 0.1979\n","Epoch 11, Train Loss: 5.9083, Val Loss: 3.4912, F1 Micro: 0.2708, F1 Macro: 0.2700, Accuracy: 0.2708\n","Epoch 12, Train Loss: 4.2812, Val Loss: 3.7509, F1 Micro: 0.2292, F1 Macro: 0.2199, Accuracy: 0.2292\n","Epoch 13, Train Loss: 5.5381, Val Loss: 6.5566, F1 Micro: 0.3333, F1 Macro: 0.2848, Accuracy: 0.3333\n","Epoch 14, Train Loss: 9.0653, Val Loss: 7.4999, F1 Micro: 0.3021, F1 Macro: 0.2086, Accuracy: 0.3021\n","Epoch 15, Train Loss: 9.8097, Val Loss: 6.6385, F1 Micro: 0.2188, F1 Macro: 0.0967, Accuracy: 0.2188\n","Epoch 16, Train Loss: 4.2911, Val Loss: 4.8749, F1 Micro: 0.1771, F1 Macro: 0.1658, Accuracy: 0.1771\n","Epoch 17, Train Loss: 4.6723, Val Loss: 7.2615, F1 Micro: 0.2083, F1 Macro: 0.1610, Accuracy: 0.2083\n","Epoch 18, Train Loss: 14.2587, Val Loss: 6.8151, F1 Micro: 0.3646, F1 Macro: 0.2989, Accuracy: 0.3646\n","Epoch 19, Train Loss: 26.7989, Val Loss: 40.1849, F1 Micro: 0.2083, F1 Macro: 0.0601, Accuracy: 0.2083\n","Epoch 20, Train Loss: 30.8354, Val Loss: 20.6139, F1 Micro: 0.1875, F1 Macro: 0.1270, Accuracy: 0.1875\n","Epoch 21, Train Loss: 8.6901, Val Loss: 5.1712, F1 Micro: 0.1875, F1 Macro: 0.1761, Accuracy: 0.1875\n","Epoch 22, Train Loss: 4.8822, Val Loss: 4.8492, F1 Micro: 0.1875, F1 Macro: 0.1261, Accuracy: 0.1875\n","Epoch 23, Train Loss: 5.4455, Val Loss: 7.5332, F1 Micro: 0.2604, F1 Macro: 0.1993, Accuracy: 0.2604\n","Epoch 24, Train Loss: 7.5028, Val Loss: 8.7564, F1 Micro: 0.1979, F1 Macro: 0.1547, Accuracy: 0.1979\n","Epoch 25, Train Loss: 6.0644, Val Loss: 4.3701, F1 Micro: 0.2917, F1 Macro: 0.2262, Accuracy: 0.2917\n","Epoch 26, Train Loss: 5.8351, Val Loss: 5.6082, F1 Micro: 0.2812, F1 Macro: 0.1601, Accuracy: 0.2812\n","Epoch 27, Train Loss: 7.1696, Val Loss: 6.8126, F1 Micro: 0.3333, F1 Macro: 0.2245, Accuracy: 0.3333\n","Epoch 28, Train Loss: 6.1840, Val Loss: 3.4996, F1 Micro: 0.2917, F1 Macro: 0.2142, Accuracy: 0.2917\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 434.7727, Val Loss: 34.6972, F1 Micro: 0.2500, F1 Macro: 0.1793, Accuracy: 0.2500\n","Epoch 2, Train Loss: 45.9290, Val Loss: 38.0695, F1 Micro: 0.2604, F1 Macro: 0.1644, Accuracy: 0.2604\n","Epoch 3, Train Loss: 25.8224, Val Loss: 25.3727, F1 Micro: 0.1667, F1 Macro: 0.0823, Accuracy: 0.1667\n","Epoch 4, Train Loss: 15.7717, Val Loss: 12.8387, F1 Micro: 0.2604, F1 Macro: 0.2257, Accuracy: 0.2604\n","Epoch 5, Train Loss: 9.2189, Val Loss: 8.3110, F1 Micro: 0.2292, F1 Macro: 0.1433, Accuracy: 0.2292\n","Epoch 6, Train Loss: 9.0862, Val Loss: 10.3936, F1 Micro: 0.2708, F1 Macro: 0.2011, Accuracy: 0.2708\n","Epoch 7, Train Loss: 7.1373, Val Loss: 8.9079, F1 Micro: 0.2083, F1 Macro: 0.1681, Accuracy: 0.2083\n","Epoch 8, Train Loss: 7.5152, Val Loss: 8.8187, F1 Micro: 0.1979, F1 Macro: 0.1455, Accuracy: 0.1979\n","Epoch 9, Train Loss: 6.5428, Val Loss: 4.6148, F1 Micro: 0.2396, F1 Macro: 0.1393, Accuracy: 0.2396\n","Epoch 10, Train Loss: 5.5416, Val Loss: 4.6919, F1 Micro: 0.2708, F1 Macro: 0.2441, Accuracy: 0.2708\n","Epoch 11, Train Loss: 5.8996, Val Loss: 6.0481, F1 Micro: 0.3229, F1 Macro: 0.2524, Accuracy: 0.3229\n","Epoch 12, Train Loss: 8.0344, Val Loss: 5.3811, F1 Micro: 0.2188, F1 Macro: 0.1713, Accuracy: 0.2188\n","Epoch 13, Train Loss: 6.9306, Val Loss: 5.4910, F1 Micro: 0.2083, F1 Macro: 0.1247, Accuracy: 0.2083\n","Epoch 14, Train Loss: 7.6642, Val Loss: 8.1431, F1 Micro: 0.1979, F1 Macro: 0.1377, Accuracy: 0.1979\n","Epoch 15, Train Loss: 5.5991, Val Loss: 8.0905, F1 Micro: 0.2500, F1 Macro: 0.1908, Accuracy: 0.2500\n","Epoch 16, Train Loss: 6.6840, Val Loss: 6.2524, F1 Micro: 0.2188, F1 Macro: 0.1454, Accuracy: 0.2188\n","Epoch 17, Train Loss: 8.1591, Val Loss: 15.7214, F1 Micro: 0.1042, F1 Macro: 0.0664, Accuracy: 0.1042\n","Epoch 18, Train Loss: 11.3283, Val Loss: 16.1360, F1 Micro: 0.0729, F1 Macro: 0.0376, Accuracy: 0.0729\n","Epoch 19, Train Loss: 10.5834, Val Loss: 7.6378, F1 Micro: 0.1875, F1 Macro: 0.1683, Accuracy: 0.1875\n","Epoch 20, Train Loss: 7.3048, Val Loss: 4.6044, F1 Micro: 0.3333, F1 Macro: 0.2083, Accuracy: 0.3333\n","Epoch 21, Train Loss: 4.7924, Val Loss: 3.8859, F1 Micro: 0.2812, F1 Macro: 0.2122, Accuracy: 0.2812\n","Epoch 22, Train Loss: 4.6624, Val Loss: 5.5555, F1 Micro: 0.1354, F1 Macro: 0.1194, Accuracy: 0.1354\n","Epoch 23, Train Loss: 15.7671, Val Loss: 15.0322, F1 Micro: 0.1875, F1 Macro: 0.1160, Accuracy: 0.1875\n","Epoch 24, Train Loss: 28.6168, Val Loss: 85.4109, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 25, Train Loss: 68.9276, Val Loss: 73.5523, F1 Micro: 0.1562, F1 Macro: 0.0941, Accuracy: 0.1562\n","Epoch 26, Train Loss: 47.8824, Val Loss: 12.6379, F1 Micro: 0.1562, F1 Macro: 0.1116, Accuracy: 0.1562\n","Epoch 27, Train Loss: 13.3963, Val Loss: 13.8683, F1 Micro: 0.2292, F1 Macro: 0.1212, Accuracy: 0.2292\n","Epoch 28, Train Loss: 8.4419, Val Loss: 9.3294, F1 Micro: 0.2917, F1 Macro: 0.1921, Accuracy: 0.2917\n","Epoch 29, Train Loss: 9.8601, Val Loss: 15.5196, F1 Micro: 0.1979, F1 Macro: 0.1004, Accuracy: 0.1979\n","Epoch 30, Train Loss: 9.9351, Val Loss: 6.0324, F1 Micro: 0.2083, F1 Macro: 0.1360, Accuracy: 0.2083\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 391.1490, Val Loss: 90.4112, F1 Micro: 0.1875, F1 Macro: 0.0893, Accuracy: 0.1875\n","Epoch 2, Train Loss: 48.5953, Val Loss: 25.6345, F1 Micro: 0.3021, F1 Macro: 0.2297, Accuracy: 0.3021\n","Epoch 3, Train Loss: 20.8533, Val Loss: 14.3625, F1 Micro: 0.1979, F1 Macro: 0.1586, Accuracy: 0.1979\n","Epoch 4, Train Loss: 9.6033, Val Loss: 9.6825, F1 Micro: 0.2396, F1 Macro: 0.2223, Accuracy: 0.2396\n","Epoch 5, Train Loss: 13.3057, Val Loss: 7.5084, F1 Micro: 0.1979, F1 Macro: 0.1707, Accuracy: 0.1979\n","Epoch 6, Train Loss: 11.9948, Val Loss: 6.6527, F1 Micro: 0.1771, F1 Macro: 0.1561, Accuracy: 0.1771\n","Epoch 7, Train Loss: 7.4089, Val Loss: 5.7231, F1 Micro: 0.3646, F1 Macro: 0.3428, Accuracy: 0.3646\n","Epoch 8, Train Loss: 9.6707, Val Loss: 5.1419, F1 Micro: 0.1667, F1 Macro: 0.1550, Accuracy: 0.1667\n","Epoch 9, Train Loss: 6.0333, Val Loss: 6.5306, F1 Micro: 0.2396, F1 Macro: 0.2225, Accuracy: 0.2396\n","Epoch 10, Train Loss: 6.9089, Val Loss: 5.6549, F1 Micro: 0.3542, F1 Macro: 0.3083, Accuracy: 0.3542\n","Epoch 11, Train Loss: 5.8767, Val Loss: 5.4299, F1 Micro: 0.2292, F1 Macro: 0.2218, Accuracy: 0.2292\n","Epoch 12, Train Loss: 7.4822, Val Loss: 6.7921, F1 Micro: 0.2500, F1 Macro: 0.1997, Accuracy: 0.2500\n","Epoch 13, Train Loss: 4.2621, Val Loss: 4.6235, F1 Micro: 0.1875, F1 Macro: 0.1310, Accuracy: 0.1875\n","Epoch 14, Train Loss: 6.6296, Val Loss: 6.1418, F1 Micro: 0.1562, F1 Macro: 0.1077, Accuracy: 0.1562\n","Epoch 15, Train Loss: 8.7143, Val Loss: 12.2636, F1 Micro: 0.2500, F1 Macro: 0.1807, Accuracy: 0.2500\n","Epoch 16, Train Loss: 14.4603, Val Loss: 28.1748, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 17, Train Loss: 21.4695, Val Loss: 43.3771, F1 Micro: 0.1771, F1 Macro: 0.0660, Accuracy: 0.1771\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 284.8521, Val Loss: 54.1677, F1 Micro: 0.2083, F1 Macro: 0.1087, Accuracy: 0.2083\n","Epoch 2, Train Loss: 37.2241, Val Loss: 30.6621, F1 Micro: 0.2604, F1 Macro: 0.1728, Accuracy: 0.2604\n","Epoch 3, Train Loss: 23.6209, Val Loss: 11.9769, F1 Micro: 0.2188, F1 Macro: 0.1933, Accuracy: 0.2188\n","Epoch 4, Train Loss: 13.0523, Val Loss: 10.1503, F1 Micro: 0.2500, F1 Macro: 0.2232, Accuracy: 0.2500\n","Epoch 5, Train Loss: 9.7032, Val Loss: 10.6227, F1 Micro: 0.0938, F1 Macro: 0.0574, Accuracy: 0.0938\n","Epoch 6, Train Loss: 10.1683, Val Loss: 7.0082, F1 Micro: 0.2083, F1 Macro: 0.1552, Accuracy: 0.2083\n","Epoch 7, Train Loss: 8.4252, Val Loss: 5.1338, F1 Micro: 0.2292, F1 Macro: 0.1970, Accuracy: 0.2292\n","Epoch 8, Train Loss: 6.9653, Val Loss: 11.2485, F1 Micro: 0.1771, F1 Macro: 0.0872, Accuracy: 0.1771\n","Epoch 9, Train Loss: 8.2361, Val Loss: 5.1983, F1 Micro: 0.2396, F1 Macro: 0.2046, Accuracy: 0.2396\n","Epoch 10, Train Loss: 5.8463, Val Loss: 3.5511, F1 Micro: 0.2292, F1 Macro: 0.1846, Accuracy: 0.2292\n","Epoch 11, Train Loss: 7.0719, Val Loss: 5.9101, F1 Micro: 0.2083, F1 Macro: 0.1572, Accuracy: 0.2083\n","Epoch 12, Train Loss: 4.3065, Val Loss: 3.6429, F1 Micro: 0.2083, F1 Macro: 0.1906, Accuracy: 0.2083\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.32916666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 400.9157, Val Loss: 38.5475, F1 Micro: 0.2604, F1 Macro: 0.1872, Accuracy: 0.2604\n","Epoch 2, Train Loss: 33.3254, Val Loss: 18.4371, F1 Micro: 0.1354, F1 Macro: 0.1065, Accuracy: 0.1354\n","Epoch 3, Train Loss: 17.1564, Val Loss: 20.9533, F1 Micro: 0.2188, F1 Macro: 0.1531, Accuracy: 0.2188\n","Epoch 4, Train Loss: 12.6298, Val Loss: 9.5697, F1 Micro: 0.2083, F1 Macro: 0.1592, Accuracy: 0.2083\n","Epoch 5, Train Loss: 8.3703, Val Loss: 7.8894, F1 Micro: 0.2500, F1 Macro: 0.2483, Accuracy: 0.2500\n","Epoch 6, Train Loss: 6.5094, Val Loss: 4.6519, F1 Micro: 0.1979, F1 Macro: 0.1949, Accuracy: 0.1979\n","Epoch 7, Train Loss: 7.2207, Val Loss: 10.6857, F1 Micro: 0.1667, F1 Macro: 0.1473, Accuracy: 0.1667\n","Epoch 8, Train Loss: 7.0405, Val Loss: 4.8619, F1 Micro: 0.2396, F1 Macro: 0.2295, Accuracy: 0.2396\n","Epoch 9, Train Loss: 7.8681, Val Loss: 14.3815, F1 Micro: 0.1354, F1 Macro: 0.1202, Accuracy: 0.1354\n","Epoch 10, Train Loss: 8.5955, Val Loss: 6.5301, F1 Micro: 0.2708, F1 Macro: 0.2311, Accuracy: 0.2708\n","Epoch 11, Train Loss: 6.7504, Val Loss: 5.9271, F1 Micro: 0.3021, F1 Macro: 0.2586, Accuracy: 0.3021\n","Epoch 12, Train Loss: 9.1183, Val Loss: 10.5184, F1 Micro: 0.2083, F1 Macro: 0.1283, Accuracy: 0.2083\n","Epoch 13, Train Loss: 10.9931, Val Loss: 9.2104, F1 Micro: 0.1562, F1 Macro: 0.0945, Accuracy: 0.1562\n","Epoch 14, Train Loss: 7.8922, Val Loss: 12.0813, F1 Micro: 0.1771, F1 Macro: 0.1462, Accuracy: 0.1771\n","Epoch 15, Train Loss: 7.6111, Val Loss: 7.7691, F1 Micro: 0.2604, F1 Macro: 0.1649, Accuracy: 0.2604\n","Epoch 16, Train Loss: 5.6599, Val Loss: 4.4571, F1 Micro: 0.2917, F1 Macro: 0.2260, Accuracy: 0.2917\n","Epoch 17, Train Loss: 11.3615, Val Loss: 10.2867, F1 Micro: 0.1875, F1 Macro: 0.1028, Accuracy: 0.1875\n","Epoch 18, Train Loss: 11.0358, Val Loss: 8.2681, F1 Micro: 0.1771, F1 Macro: 0.1089, Accuracy: 0.1771\n","Epoch 19, Train Loss: 12.5332, Val Loss: 6.4614, F1 Micro: 0.1875, F1 Macro: 0.1407, Accuracy: 0.1875\n","Epoch 20, Train Loss: 7.0271, Val Loss: 5.9962, F1 Micro: 0.1562, F1 Macro: 0.1126, Accuracy: 0.1562\n","Epoch 21, Train Loss: 5.5171, Val Loss: 8.6520, F1 Micro: 0.2708, F1 Macro: 0.1804, Accuracy: 0.2708\n","Epoch 22, Train Loss: 6.8558, Val Loss: 7.3292, F1 Micro: 0.2708, F1 Macro: 0.2299, Accuracy: 0.2708\n","Epoch 23, Train Loss: 8.5912, Val Loss: 3.3590, F1 Micro: 0.2396, F1 Macro: 0.1690, Accuracy: 0.2396\n","Epoch 24, Train Loss: 6.9796, Val Loss: 7.3305, F1 Micro: 0.1771, F1 Macro: 0.1260, Accuracy: 0.1771\n","Epoch 25, Train Loss: 12.2768, Val Loss: 23.5663, F1 Micro: 0.1875, F1 Macro: 0.1218, Accuracy: 0.1875\n","Epoch 26, Train Loss: 42.0568, Val Loss: 71.0481, F1 Micro: 0.2500, F1 Macro: 0.2286, Accuracy: 0.2500\n","Epoch 27, Train Loss: 80.3322, Val Loss: 93.9151, F1 Micro: 0.2604, F1 Macro: 0.1400, Accuracy: 0.2604\n","Epoch 28, Train Loss: 47.1636, Val Loss: 31.4632, F1 Micro: 0.2083, F1 Macro: 0.1117, Accuracy: 0.2083\n","Epoch 29, Train Loss: 44.7105, Val Loss: 15.9862, F1 Micro: 0.1771, F1 Macro: 0.1112, Accuracy: 0.1771\n","Epoch 30, Train Loss: 15.5613, Val Loss: 14.3511, F1 Micro: 0.1771, F1 Macro: 0.1145, Accuracy: 0.1771\n","Epoch 31, Train Loss: 7.3961, Val Loss: 3.1482, F1 Micro: 0.3125, F1 Macro: 0.2826, Accuracy: 0.3125\n","Epoch 32, Train Loss: 3.5567, Val Loss: 2.7128, F1 Micro: 0.2396, F1 Macro: 0.1834, Accuracy: 0.2396\n","Epoch 33, Train Loss: 3.6449, Val Loss: 4.8875, F1 Micro: 0.1354, F1 Macro: 0.0634, Accuracy: 0.1354\n","Epoch 34, Train Loss: 3.1206, Val Loss: 4.2355, F1 Micro: 0.3333, F1 Macro: 0.2632, Accuracy: 0.3333\n","Epoch 35, Train Loss: 4.7943, Val Loss: 7.3424, F1 Micro: 0.2188, F1 Macro: 0.1137, Accuracy: 0.2188\n","Epoch 36, Train Loss: 4.8185, Val Loss: 6.8595, F1 Micro: 0.2188, F1 Macro: 0.1698, Accuracy: 0.2188\n","Epoch 37, Train Loss: 4.2867, Val Loss: 3.7729, F1 Micro: 0.2292, F1 Macro: 0.1324, Accuracy: 0.2292\n","Epoch 38, Train Loss: 4.9963, Val Loss: 3.7087, F1 Micro: 0.1979, F1 Macro: 0.1632, Accuracy: 0.1979\n","Epoch 39, Train Loss: 3.5899, Val Loss: 3.4521, F1 Micro: 0.2292, F1 Macro: 0.1204, Accuracy: 0.2292\n","Epoch 40, Train Loss: 8.3406, Val Loss: 17.0032, F1 Micro: 0.2396, F1 Macro: 0.1883, Accuracy: 0.2396\n","Epoch 41, Train Loss: 10.5510, Val Loss: 17.3591, F1 Micro: 0.2292, F1 Macro: 0.1777, Accuracy: 0.2292\n","Epoch 42, Train Loss: 13.0772, Val Loss: 10.8894, F1 Micro: 0.2917, F1 Macro: 0.1702, Accuracy: 0.2917\n","Epoch 43, Train Loss: 22.3701, Val Loss: 27.8805, F1 Micro: 0.2083, F1 Macro: 0.1426, Accuracy: 0.2083\n","Epoch 44, Train Loss: 60.4392, Val Loss: 184.6232, F1 Micro: 0.1354, F1 Macro: 0.0401, Accuracy: 0.1354\n","Epoch 45, Train Loss: 126.0150, Val Loss: 45.2809, F1 Micro: 0.2292, F1 Macro: 0.1109, Accuracy: 0.2292\n","Epoch 46, Train Loss: 50.1761, Val Loss: 64.6251, F1 Micro: 0.1667, F1 Macro: 0.0697, Accuracy: 0.1667\n","Epoch 47, Train Loss: 21.5480, Val Loss: 7.4033, F1 Micro: 0.3021, F1 Macro: 0.2532, Accuracy: 0.3021\n","Epoch 48, Train Loss: 8.7125, Val Loss: 4.3627, F1 Micro: 0.3125, F1 Macro: 0.2523, Accuracy: 0.3125\n","Epoch 49, Train Loss: 11.8918, Val Loss: 22.8491, F1 Micro: 0.1875, F1 Macro: 0.0782, Accuracy: 0.1875\n","Epoch 50, Train Loss: 35.5352, Val Loss: 17.5368, F1 Micro: 0.2396, F1 Macro: 0.1072, Accuracy: 0.2396\n","Epoch 51, Train Loss: 23.5253, Val Loss: 27.1112, F1 Micro: 0.1354, F1 Macro: 0.0634, Accuracy: 0.1354\n","Epoch 52, Train Loss: 24.6893, Val Loss: 67.0224, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 53, Train Loss: 29.4904, Val Loss: 11.4037, F1 Micro: 0.2917, F1 Macro: 0.1473, Accuracy: 0.2917\n","Epoch 54, Train Loss: 13.9628, Val Loss: 17.2284, F1 Micro: 0.2188, F1 Macro: 0.1521, Accuracy: 0.2188\n","Epoch 55, Train Loss: 13.2262, Val Loss: 9.1654, F1 Micro: 0.2708, F1 Macro: 0.2242, Accuracy: 0.2708\n","Epoch 56, Train Loss: 5.7890, Val Loss: 6.3501, F1 Micro: 0.3229, F1 Macro: 0.2441, Accuracy: 0.3229\n","Epoch 57, Train Loss: 6.8881, Val Loss: 8.1038, F1 Micro: 0.3021, F1 Macro: 0.2326, Accuracy: 0.3021\n","Epoch 58, Train Loss: 6.5605, Val Loss: 6.5881, F1 Micro: 0.3229, F1 Macro: 0.2304, Accuracy: 0.3229\n","Epoch 59, Train Loss: 6.9434, Val Loss: 5.2951, F1 Micro: 0.3125, F1 Macro: 0.2494, Accuracy: 0.3125\n","Epoch 60, Train Loss: 4.0366, Val Loss: 4.2612, F1 Micro: 0.1979, F1 Macro: 0.1742, Accuracy: 0.1979\n","Epoch 61, Train Loss: 2.8957, Val Loss: 3.2676, F1 Micro: 0.3854, F1 Macro: 0.3036, Accuracy: 0.3854\n","Epoch 62, Train Loss: 2.4350, Val Loss: 2.6051, F1 Micro: 0.2396, F1 Macro: 0.2214, Accuracy: 0.2396\n","Epoch 63, Train Loss: 3.0147, Val Loss: 2.9132, F1 Micro: 0.1979, F1 Macro: 0.1622, Accuracy: 0.1979\n","Epoch 64, Train Loss: 3.3485, Val Loss: 2.5509, F1 Micro: 0.2396, F1 Macro: 0.1833, Accuracy: 0.2396\n","Epoch 65, Train Loss: 3.5448, Val Loss: 9.3865, F1 Micro: 0.3125, F1 Macro: 0.2115, Accuracy: 0.3125\n","Epoch 66, Train Loss: 8.1572, Val Loss: 8.7327, F1 Micro: 0.1771, F1 Macro: 0.1365, Accuracy: 0.1771\n","Epoch 67, Train Loss: 6.1145, Val Loss: 4.4437, F1 Micro: 0.2292, F1 Macro: 0.1864, Accuracy: 0.2292\n","Epoch 68, Train Loss: 23.4642, Val Loss: 76.3372, F1 Micro: 0.2708, F1 Macro: 0.1424, Accuracy: 0.2708\n","Epoch 69, Train Loss: 124.9556, Val Loss: 144.8725, F1 Micro: 0.2604, F1 Macro: 0.1400, Accuracy: 0.2604\n","Epoch 70, Train Loss: 252.0778, Val Loss: 73.6016, F1 Micro: 0.2604, F1 Macro: 0.1590, Accuracy: 0.2604\n","Epoch 71, Train Loss: 76.9789, Val Loss: 89.1913, F1 Micro: 0.2188, F1 Macro: 0.1057, Accuracy: 0.2188\n","Epoch 72, Train Loss: 66.9604, Val Loss: 38.8450, F1 Micro: 0.1562, F1 Macro: 0.0707, Accuracy: 0.1562\n","Epoch 73, Train Loss: 34.1458, Val Loss: 67.2758, F1 Micro: 0.2188, F1 Macro: 0.1714, Accuracy: 0.2188\n","Epoch 74, Train Loss: 67.2980, Val Loss: 148.1575, F1 Micro: 0.1667, F1 Macro: 0.0724, Accuracy: 0.1667\n","Epoch 75, Train Loss: 80.7846, Val Loss: 22.0370, F1 Micro: 0.2500, F1 Macro: 0.1643, Accuracy: 0.2500\n","Epoch 76, Train Loss: 30.5666, Val Loss: 47.1941, F1 Micro: 0.2083, F1 Macro: 0.1241, Accuracy: 0.2083\n","Epoch 77, Train Loss: 22.6969, Val Loss: 12.0551, F1 Micro: 0.2500, F1 Macro: 0.1862, Accuracy: 0.2500\n","Epoch 78, Train Loss: 9.0028, Val Loss: 4.1399, F1 Micro: 0.2708, F1 Macro: 0.1890, Accuracy: 0.2708\n","Epoch 79, Train Loss: 5.1758, Val Loss: 5.3116, F1 Micro: 0.2396, F1 Macro: 0.1972, Accuracy: 0.2396\n","Epoch 80, Train Loss: 6.1853, Val Loss: 7.3391, F1 Micro: 0.2083, F1 Macro: 0.2003, Accuracy: 0.2083\n","Epoch 81, Train Loss: 5.5993, Val Loss: 5.7171, F1 Micro: 0.2396, F1 Macro: 0.1803, Accuracy: 0.2396\n","Epoch 82, Train Loss: 4.9744, Val Loss: 6.2202, F1 Micro: 0.1562, F1 Macro: 0.0729, Accuracy: 0.1562\n","Epoch 83, Train Loss: 3.3426, Val Loss: 2.7751, F1 Micro: 0.2708, F1 Macro: 0.2534, Accuracy: 0.2708\n","Epoch 84, Train Loss: 3.2091, Val Loss: 3.3403, F1 Micro: 0.2500, F1 Macro: 0.2370, Accuracy: 0.2500\n","Epoch 85, Train Loss: 2.4988, Val Loss: 2.5260, F1 Micro: 0.3125, F1 Macro: 0.2436, Accuracy: 0.3125\n","Epoch 86, Train Loss: 2.5185, Val Loss: 2.4108, F1 Micro: 0.2604, F1 Macro: 0.2183, Accuracy: 0.2604\n","Epoch 87, Train Loss: 2.5994, Val Loss: 3.2813, F1 Micro: 0.2812, F1 Macro: 0.2187, Accuracy: 0.2812\n","Epoch 88, Train Loss: 2.4450, Val Loss: 3.0216, F1 Micro: 0.2083, F1 Macro: 0.1536, Accuracy: 0.2083\n","Epoch 89, Train Loss: 2.5520, Val Loss: 2.3071, F1 Micro: 0.2812, F1 Macro: 0.2646, Accuracy: 0.2812\n","Epoch 90, Train Loss: 2.7599, Val Loss: 3.2728, F1 Micro: 0.1771, F1 Macro: 0.1606, Accuracy: 0.1771\n","Epoch 91, Train Loss: 2.7839, Val Loss: 3.3014, F1 Micro: 0.2604, F1 Macro: 0.2210, Accuracy: 0.2604\n","Epoch 92, Train Loss: 3.6349, Val Loss: 3.4967, F1 Micro: 0.2500, F1 Macro: 0.2022, Accuracy: 0.2500\n","Epoch 93, Train Loss: 4.5636, Val Loss: 4.8203, F1 Micro: 0.2604, F1 Macro: 0.1925, Accuracy: 0.2604\n","Epoch 94, Train Loss: 5.2923, Val Loss: 8.5772, F1 Micro: 0.2083, F1 Macro: 0.1476, Accuracy: 0.2083\n","Epoch 95, Train Loss: 5.6384, Val Loss: 6.9571, F1 Micro: 0.1875, F1 Macro: 0.1129, Accuracy: 0.1875\n","Epoch 96, Train Loss: 5.4983, Val Loss: 8.3397, F1 Micro: 0.1875, F1 Macro: 0.1229, Accuracy: 0.1875\n","Epoch 97, Train Loss: 9.4433, Val Loss: 14.6045, F1 Micro: 0.1458, F1 Macro: 0.0436, Accuracy: 0.1458\n","Epoch 98, Train Loss: 12.6150, Val Loss: 36.2340, F1 Micro: 0.1875, F1 Macro: 0.1218, Accuracy: 0.1875\n","Epoch 99, Train Loss: 59.9929, Val Loss: 106.6598, F1 Micro: 0.2083, F1 Macro: 0.0606, Accuracy: 0.2083\n","Epoch 100, Train Loss: 233.2710, Val Loss: 337.6468, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 101, Train Loss: 147.1827, Val Loss: 32.8847, F1 Micro: 0.2500, F1 Macro: 0.2038, Accuracy: 0.2500\n","Epoch 102, Train Loss: 46.3650, Val Loss: 29.3694, F1 Micro: 0.2604, F1 Macro: 0.2047, Accuracy: 0.2604\n","Epoch 103, Train Loss: 27.9457, Val Loss: 15.9765, F1 Micro: 0.2604, F1 Macro: 0.1559, Accuracy: 0.2604\n","Epoch 104, Train Loss: 6.7565, Val Loss: 8.1182, F1 Micro: 0.1875, F1 Macro: 0.1257, Accuracy: 0.1875\n","Epoch 105, Train Loss: 4.5361, Val Loss: 4.8225, F1 Micro: 0.2917, F1 Macro: 0.2085, Accuracy: 0.2917\n","Epoch 106, Train Loss: 3.4452, Val Loss: 3.2049, F1 Micro: 0.2292, F1 Macro: 0.2074, Accuracy: 0.2292\n","Epoch 107, Train Loss: 2.7552, Val Loss: 2.8862, F1 Micro: 0.3229, F1 Macro: 0.2867, Accuracy: 0.3229\n","Epoch 108, Train Loss: 2.7265, Val Loss: 2.5510, F1 Micro: 0.2500, F1 Macro: 0.2127, Accuracy: 0.2500\n","Epoch 109, Train Loss: 2.7069, Val Loss: 4.5833, F1 Micro: 0.2292, F1 Macro: 0.2002, Accuracy: 0.2292\n","Epoch 110, Train Loss: 3.5064, Val Loss: 4.3608, F1 Micro: 0.1667, F1 Macro: 0.0877, Accuracy: 0.1667\n","Epoch 111, Train Loss: 4.5261, Val Loss: 4.7719, F1 Micro: 0.2917, F1 Macro: 0.2203, Accuracy: 0.2917\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 352.5255, Val Loss: 59.9052, F1 Micro: 0.2917, F1 Macro: 0.2178, Accuracy: 0.2917\n","Epoch 2, Train Loss: 35.1616, Val Loss: 21.1039, F1 Micro: 0.2708, F1 Macro: 0.1795, Accuracy: 0.2708\n","Epoch 3, Train Loss: 15.7309, Val Loss: 10.4550, F1 Micro: 0.3438, F1 Macro: 0.2887, Accuracy: 0.3438\n","Epoch 4, Train Loss: 10.1294, Val Loss: 10.3592, F1 Micro: 0.3229, F1 Macro: 0.2682, Accuracy: 0.3229\n","Epoch 5, Train Loss: 8.2830, Val Loss: 7.9795, F1 Micro: 0.2708, F1 Macro: 0.2153, Accuracy: 0.2708\n","Epoch 6, Train Loss: 7.0673, Val Loss: 10.5836, F1 Micro: 0.3333, F1 Macro: 0.2603, Accuracy: 0.3333\n","Epoch 7, Train Loss: 7.4238, Val Loss: 4.8512, F1 Micro: 0.2188, F1 Macro: 0.1966, Accuracy: 0.2188\n","Epoch 8, Train Loss: 5.1608, Val Loss: 7.8833, F1 Micro: 0.2812, F1 Macro: 0.2360, Accuracy: 0.2812\n","Epoch 9, Train Loss: 6.9762, Val Loss: 5.5453, F1 Micro: 0.1979, F1 Macro: 0.1383, Accuracy: 0.1979\n","Epoch 10, Train Loss: 4.8546, Val Loss: 11.8310, F1 Micro: 0.3021, F1 Macro: 0.3059, Accuracy: 0.3021\n","Epoch 11, Train Loss: 6.1181, Val Loss: 4.8971, F1 Micro: 0.2812, F1 Macro: 0.2112, Accuracy: 0.2812\n","Epoch 12, Train Loss: 4.3379, Val Loss: 5.7199, F1 Micro: 0.3125, F1 Macro: 0.2814, Accuracy: 0.3125\n","Epoch 13, Train Loss: 4.1933, Val Loss: 4.2908, F1 Micro: 0.1875, F1 Macro: 0.1301, Accuracy: 0.1875\n","Epoch 14, Train Loss: 4.3304, Val Loss: 5.8585, F1 Micro: 0.3021, F1 Macro: 0.2632, Accuracy: 0.3021\n","Epoch 15, Train Loss: 10.9863, Val Loss: 8.8938, F1 Micro: 0.2500, F1 Macro: 0.2189, Accuracy: 0.2500\n","Epoch 16, Train Loss: 7.7286, Val Loss: 7.7051, F1 Micro: 0.1562, F1 Macro: 0.1023, Accuracy: 0.1562\n","Epoch 17, Train Loss: 6.4014, Val Loss: 5.6530, F1 Micro: 0.2292, F1 Macro: 0.1141, Accuracy: 0.2292\n","Epoch 18, Train Loss: 5.0242, Val Loss: 9.1518, F1 Micro: 0.2292, F1 Macro: 0.1634, Accuracy: 0.2292\n","Epoch 19, Train Loss: 7.2263, Val Loss: 6.9465, F1 Micro: 0.1042, F1 Macro: 0.0351, Accuracy: 0.1042\n","Epoch 20, Train Loss: 4.7334, Val Loss: 9.8129, F1 Micro: 0.1458, F1 Macro: 0.0934, Accuracy: 0.1458\n","Epoch 21, Train Loss: 12.3059, Val Loss: 16.3712, F1 Micro: 0.1562, F1 Macro: 0.1541, Accuracy: 0.1562\n","Epoch 22, Train Loss: 5.9253, Val Loss: 2.7263, F1 Micro: 0.2292, F1 Macro: 0.1312, Accuracy: 0.2292\n","Epoch 23, Train Loss: 4.7494, Val Loss: 12.5096, F1 Micro: 0.1042, F1 Macro: 0.0321, Accuracy: 0.1042\n","Epoch 24, Train Loss: 11.0905, Val Loss: 36.9261, F1 Micro: 0.2396, F1 Macro: 0.1304, Accuracy: 0.2396\n","Epoch 25, Train Loss: 62.0113, Val Loss: 16.8408, F1 Micro: 0.2812, F1 Macro: 0.1768, Accuracy: 0.2812\n","Epoch 26, Train Loss: 37.6385, Val Loss: 50.9278, F1 Micro: 0.0729, F1 Macro: 0.0233, Accuracy: 0.0729\n","Epoch 27, Train Loss: 41.4020, Val Loss: 45.4380, F1 Micro: 0.2083, F1 Macro: 0.1206, Accuracy: 0.2083\n","Epoch 28, Train Loss: 42.3029, Val Loss: 47.8665, F1 Micro: 0.2188, F1 Macro: 0.0948, Accuracy: 0.2188\n","Epoch 29, Train Loss: 109.3140, Val Loss: 76.5626, F1 Micro: 0.2604, F1 Macro: 0.1660, Accuracy: 0.2604\n","Epoch 30, Train Loss: 48.9964, Val Loss: 57.6972, F1 Micro: 0.1667, F1 Macro: 0.1079, Accuracy: 0.1667\n","Epoch 31, Train Loss: 50.8379, Val Loss: 22.9357, F1 Micro: 0.2188, F1 Macro: 0.1158, Accuracy: 0.2188\n","Epoch 32, Train Loss: 24.7052, Val Loss: 6.8633, F1 Micro: 0.2396, F1 Macro: 0.2119, Accuracy: 0.2396\n","Epoch 33, Train Loss: 6.5956, Val Loss: 2.7216, F1 Micro: 0.3125, F1 Macro: 0.2383, Accuracy: 0.3125\n","Epoch 34, Train Loss: 4.2069, Val Loss: 5.9903, F1 Micro: 0.2604, F1 Macro: 0.2141, Accuracy: 0.2604\n","Epoch 35, Train Loss: 3.6596, Val Loss: 2.9353, F1 Micro: 0.2917, F1 Macro: 0.2358, Accuracy: 0.2917\n","Epoch 36, Train Loss: 2.8003, Val Loss: 3.7642, F1 Micro: 0.2708, F1 Macro: 0.1774, Accuracy: 0.2708\n","Epoch 37, Train Loss: 3.5581, Val Loss: 6.5009, F1 Micro: 0.2292, F1 Macro: 0.1446, Accuracy: 0.2292\n","Epoch 38, Train Loss: 3.5384, Val Loss: 3.3281, F1 Micro: 0.2604, F1 Macro: 0.1778, Accuracy: 0.2604\n","Epoch 39, Train Loss: 2.4477, Val Loss: 2.7580, F1 Micro: 0.3125, F1 Macro: 0.2521, Accuracy: 0.3125\n","Epoch 40, Train Loss: 2.8703, Val Loss: 3.5013, F1 Micro: 0.3854, F1 Macro: 0.3064, Accuracy: 0.3854\n","Epoch 41, Train Loss: 2.7604, Val Loss: 3.4615, F1 Micro: 0.2708, F1 Macro: 0.2825, Accuracy: 0.2708\n","Epoch 42, Train Loss: 2.9800, Val Loss: 3.0978, F1 Micro: 0.2917, F1 Macro: 0.2168, Accuracy: 0.2917\n","Epoch 43, Train Loss: 4.4847, Val Loss: 4.2089, F1 Micro: 0.2604, F1 Macro: 0.1764, Accuracy: 0.2604\n","Epoch 44, Train Loss: 3.4236, Val Loss: 3.8215, F1 Micro: 0.2292, F1 Macro: 0.1466, Accuracy: 0.2292\n","Epoch 45, Train Loss: 4.9155, Val Loss: 5.2642, F1 Micro: 0.2500, F1 Macro: 0.2422, Accuracy: 0.2500\n","Epoch 46, Train Loss: 10.3180, Val Loss: 9.6953, F1 Micro: 0.2396, F1 Macro: 0.1716, Accuracy: 0.2396\n","Epoch 47, Train Loss: 29.7078, Val Loss: 41.4580, F1 Micro: 0.2292, F1 Macro: 0.1097, Accuracy: 0.2292\n","Epoch 48, Train Loss: 79.8263, Val Loss: 41.1236, F1 Micro: 0.0833, F1 Macro: 0.0530, Accuracy: 0.0833\n","Epoch 49, Train Loss: 184.8097, Val Loss: 271.3386, F1 Micro: 0.1667, F1 Macro: 0.1075, Accuracy: 0.1667\n","Epoch 50, Train Loss: 128.5104, Val Loss: 17.2015, F1 Micro: 0.2500, F1 Macro: 0.1635, Accuracy: 0.2500\n","Epoch 51, Train Loss: 20.1403, Val Loss: 11.9701, F1 Micro: 0.3333, F1 Macro: 0.2369, Accuracy: 0.3333\n","Epoch 52, Train Loss: 10.0502, Val Loss: 6.1379, F1 Micro: 0.2708, F1 Macro: 0.2418, Accuracy: 0.2708\n","Epoch 53, Train Loss: 5.1882, Val Loss: 7.8744, F1 Micro: 0.2188, F1 Macro: 0.1394, Accuracy: 0.2188\n","Epoch 54, Train Loss: 3.8569, Val Loss: 2.2552, F1 Micro: 0.3125, F1 Macro: 0.2945, Accuracy: 0.3125\n","Epoch 55, Train Loss: 2.4349, Val Loss: 3.5483, F1 Micro: 0.2708, F1 Macro: 0.1757, Accuracy: 0.2708\n","Epoch 56, Train Loss: 2.3573, Val Loss: 2.1282, F1 Micro: 0.2708, F1 Macro: 0.2204, Accuracy: 0.2708\n","Epoch 57, Train Loss: 2.4286, Val Loss: 4.0596, F1 Micro: 0.2708, F1 Macro: 0.2052, Accuracy: 0.2708\n","Epoch 58, Train Loss: 2.5837, Val Loss: 3.3330, F1 Micro: 0.1562, F1 Macro: 0.1148, Accuracy: 0.1562\n","Epoch 59, Train Loss: 2.5312, Val Loss: 4.4298, F1 Micro: 0.1771, F1 Macro: 0.1515, Accuracy: 0.1771\n","Epoch 60, Train Loss: 3.7835, Val Loss: 5.2036, F1 Micro: 0.2188, F1 Macro: 0.1774, Accuracy: 0.2188\n","Epoch 61, Train Loss: 3.8984, Val Loss: 3.3892, F1 Micro: 0.3542, F1 Macro: 0.2589, Accuracy: 0.3542\n","Epoch 62, Train Loss: 3.4905, Val Loss: 5.4068, F1 Micro: 0.2604, F1 Macro: 0.2116, Accuracy: 0.2604\n","Epoch 63, Train Loss: 5.4976, Val Loss: 10.0095, F1 Micro: 0.1562, F1 Macro: 0.1055, Accuracy: 0.1562\n","Epoch 64, Train Loss: 13.4036, Val Loss: 63.7828, F1 Micro: 0.1042, F1 Macro: 0.0314, Accuracy: 0.1042\n","Epoch 65, Train Loss: 43.5057, Val Loss: 121.8252, F1 Micro: 0.1667, F1 Macro: 0.1075, Accuracy: 0.1667\n","Epoch 66, Train Loss: 71.6933, Val Loss: 162.0910, F1 Micro: 0.2292, F1 Macro: 0.1071, Accuracy: 0.2292\n","Epoch 67, Train Loss: 140.4385, Val Loss: 63.6031, F1 Micro: 0.2604, F1 Macro: 0.1680, Accuracy: 0.2604\n","Epoch 68, Train Loss: 97.6307, Val Loss: 51.7126, F1 Micro: 0.1771, F1 Macro: 0.1226, Accuracy: 0.1771\n","Epoch 69, Train Loss: 63.5618, Val Loss: 73.9938, F1 Micro: 0.1562, F1 Macro: 0.1048, Accuracy: 0.1562\n","Epoch 70, Train Loss: 49.6761, Val Loss: 21.1537, F1 Micro: 0.2812, F1 Macro: 0.1482, Accuracy: 0.2812\n","Epoch 71, Train Loss: 23.1797, Val Loss: 27.0447, F1 Micro: 0.2083, F1 Macro: 0.1540, Accuracy: 0.2083\n","Epoch 72, Train Loss: 12.5103, Val Loss: 7.2694, F1 Micro: 0.2083, F1 Macro: 0.1679, Accuracy: 0.2083\n","Epoch 73, Train Loss: 3.8827, Val Loss: 3.7563, F1 Micro: 0.2396, F1 Macro: 0.1337, Accuracy: 0.2396\n","Epoch 74, Train Loss: 2.8379, Val Loss: 4.0343, F1 Micro: 0.2500, F1 Macro: 0.1920, Accuracy: 0.2500\n","Epoch 75, Train Loss: 3.7406, Val Loss: 4.5478, F1 Micro: 0.2917, F1 Macro: 0.2442, Accuracy: 0.2917\n","Epoch 76, Train Loss: 2.8951, Val Loss: 4.3899, F1 Micro: 0.1875, F1 Macro: 0.1380, Accuracy: 0.1875\n","Epoch 77, Train Loss: 3.1767, Val Loss: 3.8158, F1 Micro: 0.2708, F1 Macro: 0.2147, Accuracy: 0.2708\n","Epoch 78, Train Loss: 3.0237, Val Loss: 2.6455, F1 Micro: 0.3125, F1 Macro: 0.2560, Accuracy: 0.3125\n","Epoch 79, Train Loss: 2.7252, Val Loss: 3.9732, F1 Micro: 0.3438, F1 Macro: 0.2415, Accuracy: 0.3438\n","Epoch 80, Train Loss: 2.9733, Val Loss: 2.9100, F1 Micro: 0.3333, F1 Macro: 0.2561, Accuracy: 0.3333\n","Epoch 81, Train Loss: 2.5037, Val Loss: 3.8635, F1 Micro: 0.1458, F1 Macro: 0.1233, Accuracy: 0.1458\n","Epoch 82, Train Loss: 2.1937, Val Loss: 2.7327, F1 Micro: 0.3333, F1 Macro: 0.2785, Accuracy: 0.3333\n","Epoch 83, Train Loss: 2.4751, Val Loss: 2.2414, F1 Micro: 0.2708, F1 Macro: 0.1892, Accuracy: 0.2708\n","Epoch 84, Train Loss: 2.9115, Val Loss: 3.7613, F1 Micro: 0.1667, F1 Macro: 0.1514, Accuracy: 0.1667\n","Epoch 85, Train Loss: 2.7186, Val Loss: 3.3501, F1 Micro: 0.2917, F1 Macro: 0.2205, Accuracy: 0.2917\n","Epoch 86, Train Loss: 3.0186, Val Loss: 3.1544, F1 Micro: 0.1771, F1 Macro: 0.1280, Accuracy: 0.1771\n","Epoch 87, Train Loss: 3.3362, Val Loss: 7.7345, F1 Micro: 0.2604, F1 Macro: 0.2463, Accuracy: 0.2604\n","Epoch 88, Train Loss: 8.4194, Val Loss: 8.1570, F1 Micro: 0.2917, F1 Macro: 0.2149, Accuracy: 0.2917\n","Epoch 89, Train Loss: 21.1044, Val Loss: 45.3002, F1 Micro: 0.2604, F1 Macro: 0.1562, Accuracy: 0.2604\n","Epoch 90, Train Loss: 137.8139, Val Loss: 284.2780, F1 Micro: 0.1042, F1 Macro: 0.0475, Accuracy: 0.1042\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 279.1346, Val Loss: 45.0631, F1 Micro: 0.2083, F1 Macro: 0.1479, Accuracy: 0.2083\n","Epoch 2, Train Loss: 30.4514, Val Loss: 16.6364, F1 Micro: 0.2604, F1 Macro: 0.1628, Accuracy: 0.2604\n","Epoch 3, Train Loss: 14.7102, Val Loss: 18.0304, F1 Micro: 0.1354, F1 Macro: 0.1217, Accuracy: 0.1354\n","Epoch 4, Train Loss: 18.3450, Val Loss: 15.3530, F1 Micro: 0.1771, F1 Macro: 0.1391, Accuracy: 0.1771\n","Epoch 5, Train Loss: 11.8548, Val Loss: 11.0884, F1 Micro: 0.2812, F1 Macro: 0.1775, Accuracy: 0.2812\n","Epoch 6, Train Loss: 9.6466, Val Loss: 10.2664, F1 Micro: 0.2292, F1 Macro: 0.2014, Accuracy: 0.2292\n","Epoch 7, Train Loss: 10.3773, Val Loss: 10.9004, F1 Micro: 0.2917, F1 Macro: 0.1878, Accuracy: 0.2917\n","Epoch 8, Train Loss: 10.0584, Val Loss: 7.9503, F1 Micro: 0.2500, F1 Macro: 0.1458, Accuracy: 0.2500\n","Epoch 9, Train Loss: 10.1294, Val Loss: 16.2625, F1 Micro: 0.2292, F1 Macro: 0.1204, Accuracy: 0.2292\n","Epoch 10, Train Loss: 11.0776, Val Loss: 8.0379, F1 Micro: 0.1771, F1 Macro: 0.1299, Accuracy: 0.1771\n","Epoch 11, Train Loss: 25.3424, Val Loss: 40.2536, F1 Micro: 0.0729, F1 Macro: 0.0433, Accuracy: 0.0729\n","Epoch 12, Train Loss: 13.5425, Val Loss: 10.9924, F1 Micro: 0.2708, F1 Macro: 0.1716, Accuracy: 0.2708\n","Epoch 13, Train Loss: 13.2426, Val Loss: 7.2493, F1 Micro: 0.2083, F1 Macro: 0.1806, Accuracy: 0.2083\n","Epoch 14, Train Loss: 7.2123, Val Loss: 8.4864, F1 Micro: 0.2500, F1 Macro: 0.1912, Accuracy: 0.2500\n","Epoch 15, Train Loss: 6.7988, Val Loss: 6.6791, F1 Micro: 0.2708, F1 Macro: 0.1863, Accuracy: 0.2708\n","Epoch 16, Train Loss: 4.7439, Val Loss: 3.1548, F1 Micro: 0.3125, F1 Macro: 0.2685, Accuracy: 0.3125\n","Epoch 17, Train Loss: 4.3762, Val Loss: 9.0330, F1 Micro: 0.1562, F1 Macro: 0.1190, Accuracy: 0.1562\n","Epoch 18, Train Loss: 8.1151, Val Loss: 6.1906, F1 Micro: 0.2500, F1 Macro: 0.1649, Accuracy: 0.2500\n","Epoch 19, Train Loss: 6.6119, Val Loss: 9.1336, F1 Micro: 0.1771, F1 Macro: 0.0992, Accuracy: 0.1771\n","Epoch 20, Train Loss: 5.7203, Val Loss: 3.4101, F1 Micro: 0.3229, F1 Macro: 0.2562, Accuracy: 0.3229\n","Epoch 21, Train Loss: 5.3925, Val Loss: 3.9142, F1 Micro: 0.2812, F1 Macro: 0.2339, Accuracy: 0.2812\n","Epoch 22, Train Loss: 4.1601, Val Loss: 5.9403, F1 Micro: 0.1562, F1 Macro: 0.1211, Accuracy: 0.1562\n","Epoch 23, Train Loss: 9.8939, Val Loss: 22.9272, F1 Micro: 0.1354, F1 Macro: 0.0856, Accuracy: 0.1354\n","Epoch 24, Train Loss: 46.0009, Val Loss: 65.1471, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 25, Train Loss: 31.2880, Val Loss: 52.2433, F1 Micro: 0.1875, F1 Macro: 0.1101, Accuracy: 0.1875\n","Epoch 26, Train Loss: 39.7865, Val Loss: 13.9815, F1 Micro: 0.2604, F1 Macro: 0.1333, Accuracy: 0.2604\n","Epoch 27, Train Loss: 36.1953, Val Loss: 31.3251, F1 Micro: 0.2188, F1 Macro: 0.0979, Accuracy: 0.2188\n","Epoch 28, Train Loss: 16.9364, Val Loss: 5.3676, F1 Micro: 0.1979, F1 Macro: 0.1475, Accuracy: 0.1979\n","Epoch 29, Train Loss: 7.5896, Val Loss: 6.2561, F1 Micro: 0.2500, F1 Macro: 0.1896, Accuracy: 0.2500\n","Epoch 30, Train Loss: 9.3245, Val Loss: 6.5126, F1 Micro: 0.2292, F1 Macro: 0.1491, Accuracy: 0.2292\n","Epoch 31, Train Loss: 9.4900, Val Loss: 9.8363, F1 Micro: 0.2188, F1 Macro: 0.1542, Accuracy: 0.2188\n","Epoch 32, Train Loss: 7.7215, Val Loss: 5.6804, F1 Micro: 0.3438, F1 Macro: 0.1931, Accuracy: 0.3438\n","Epoch 33, Train Loss: 6.5944, Val Loss: 7.8057, F1 Micro: 0.2917, F1 Macro: 0.2288, Accuracy: 0.2917\n","Epoch 34, Train Loss: 4.1994, Val Loss: 5.3973, F1 Micro: 0.2188, F1 Macro: 0.1038, Accuracy: 0.2188\n","Epoch 35, Train Loss: 4.6638, Val Loss: 3.9830, F1 Micro: 0.1562, F1 Macro: 0.1273, Accuracy: 0.1562\n","Epoch 36, Train Loss: 5.5407, Val Loss: 3.8610, F1 Micro: 0.2500, F1 Macro: 0.1847, Accuracy: 0.2500\n","Epoch 37, Train Loss: 6.3482, Val Loss: 11.8554, F1 Micro: 0.2083, F1 Macro: 0.1125, Accuracy: 0.2083\n","Epoch 38, Train Loss: 9.3718, Val Loss: 10.0134, F1 Micro: 0.2708, F1 Macro: 0.1363, Accuracy: 0.2708\n","Epoch 39, Train Loss: 11.4203, Val Loss: 7.2886, F1 Micro: 0.1771, F1 Macro: 0.1026, Accuracy: 0.1771\n","Epoch 40, Train Loss: 80.7567, Val Loss: 145.3960, F1 Micro: 0.1979, F1 Macro: 0.1001, Accuracy: 0.1979\n","Epoch 41, Train Loss: 133.8030, Val Loss: 184.3552, F1 Micro: 0.1979, F1 Macro: 0.0556, Accuracy: 0.1979\n","Epoch 42, Train Loss: 227.7525, Val Loss: 211.5789, F1 Micro: 0.1979, F1 Macro: 0.0985, Accuracy: 0.1979\n","Epoch 43, Train Loss: 174.1922, Val Loss: 66.9787, F1 Micro: 0.1771, F1 Macro: 0.0788, Accuracy: 0.1771\n","Epoch 44, Train Loss: 94.6506, Val Loss: 36.7851, F1 Micro: 0.3125, F1 Macro: 0.2535, Accuracy: 0.3125\n","Epoch 45, Train Loss: 32.7979, Val Loss: 9.4195, F1 Micro: 0.2396, F1 Macro: 0.2020, Accuracy: 0.2396\n","Epoch 46, Train Loss: 9.3356, Val Loss: 7.0770, F1 Micro: 0.2500, F1 Macro: 0.1947, Accuracy: 0.2500\n","Epoch 47, Train Loss: 5.9625, Val Loss: 7.2006, F1 Micro: 0.3125, F1 Macro: 0.2726, Accuracy: 0.3125\n","Epoch 48, Train Loss: 5.0324, Val Loss: 5.8021, F1 Micro: 0.2500, F1 Macro: 0.1724, Accuracy: 0.2500\n","Epoch 49, Train Loss: 3.4929, Val Loss: 3.2349, F1 Micro: 0.2292, F1 Macro: 0.1873, Accuracy: 0.2292\n","Epoch 50, Train Loss: 2.8051, Val Loss: 2.8074, F1 Micro: 0.3646, F1 Macro: 0.2602, Accuracy: 0.3646\n","Epoch 51, Train Loss: 3.8360, Val Loss: 4.4320, F1 Micro: 0.2708, F1 Macro: 0.2178, Accuracy: 0.2708\n","Epoch 52, Train Loss: 2.9421, Val Loss: 2.5003, F1 Micro: 0.3854, F1 Macro: 0.3093, Accuracy: 0.3854\n","Epoch 53, Train Loss: 2.5844, Val Loss: 2.3920, F1 Micro: 0.3125, F1 Macro: 0.2626, Accuracy: 0.3125\n","Epoch 54, Train Loss: 4.6742, Val Loss: 7.4720, F1 Micro: 0.1667, F1 Macro: 0.1399, Accuracy: 0.1667\n","Epoch 55, Train Loss: 4.8670, Val Loss: 3.0604, F1 Micro: 0.3438, F1 Macro: 0.3239, Accuracy: 0.3438\n","Epoch 56, Train Loss: 3.5383, Val Loss: 3.5030, F1 Micro: 0.2604, F1 Macro: 0.2148, Accuracy: 0.2604\n","Epoch 57, Train Loss: 2.6418, Val Loss: 2.3869, F1 Micro: 0.3229, F1 Macro: 0.2948, Accuracy: 0.3229\n","Epoch 58, Train Loss: 3.1002, Val Loss: 5.3450, F1 Micro: 0.2500, F1 Macro: 0.1598, Accuracy: 0.2500\n","Epoch 59, Train Loss: 3.5213, Val Loss: 3.6334, F1 Micro: 0.3125, F1 Macro: 0.2374, Accuracy: 0.3125\n","Epoch 60, Train Loss: 3.3839, Val Loss: 3.9842, F1 Micro: 0.2708, F1 Macro: 0.1778, Accuracy: 0.2708\n","Epoch 61, Train Loss: 2.8044, Val Loss: 2.5793, F1 Micro: 0.3333, F1 Macro: 0.2110, Accuracy: 0.3333\n","Epoch 62, Train Loss: 2.7483, Val Loss: 3.0710, F1 Micro: 0.3125, F1 Macro: 0.2476, Accuracy: 0.3125\n","Epoch 63, Train Loss: 3.7558, Val Loss: 7.3717, F1 Micro: 0.2396, F1 Macro: 0.1409, Accuracy: 0.2396\n","Epoch 64, Train Loss: 3.4495, Val Loss: 3.0153, F1 Micro: 0.2188, F1 Macro: 0.1971, Accuracy: 0.2188\n","Epoch 65, Train Loss: 4.0677, Val Loss: 3.8835, F1 Micro: 0.2500, F1 Macro: 0.1845, Accuracy: 0.2500\n","Epoch 66, Train Loss: 3.7986, Val Loss: 5.1759, F1 Micro: 0.2708, F1 Macro: 0.1631, Accuracy: 0.2708\n","Epoch 67, Train Loss: 2.8034, Val Loss: 2.9325, F1 Micro: 0.2708, F1 Macro: 0.2769, Accuracy: 0.2708\n","Epoch 68, Train Loss: 3.1626, Val Loss: 3.0504, F1 Micro: 0.2500, F1 Macro: 0.1859, Accuracy: 0.2500\n","Epoch 69, Train Loss: 5.7635, Val Loss: 10.0072, F1 Micro: 0.2604, F1 Macro: 0.1660, Accuracy: 0.2604\n","Epoch 70, Train Loss: 21.0750, Val Loss: 31.7525, F1 Micro: 0.1771, F1 Macro: 0.0934, Accuracy: 0.1771\n","Epoch 71, Train Loss: 45.0544, Val Loss: 78.6146, F1 Micro: 0.1562, F1 Macro: 0.1275, Accuracy: 0.1562\n","Epoch 72, Train Loss: 261.1046, Val Loss: 790.1018, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 73, Train Loss: 454.9170, Val Loss: 451.6835, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 74, Train Loss: 271.4182, Val Loss: 120.6623, F1 Micro: 0.1771, F1 Macro: 0.1111, Accuracy: 0.1771\n","Epoch 75, Train Loss: 70.3806, Val Loss: 42.8484, F1 Micro: 0.2083, F1 Macro: 0.1448, Accuracy: 0.2083\n","Epoch 76, Train Loss: 20.9026, Val Loss: 9.7992, F1 Micro: 0.2396, F1 Macro: 0.1655, Accuracy: 0.2396\n","Epoch 77, Train Loss: 5.6877, Val Loss: 5.6999, F1 Micro: 0.1875, F1 Macro: 0.1314, Accuracy: 0.1875\n","Epoch 78, Train Loss: 3.3774, Val Loss: 3.9662, F1 Micro: 0.3646, F1 Macro: 0.2568, Accuracy: 0.3646\n","Epoch 79, Train Loss: 2.8000, Val Loss: 2.5059, F1 Micro: 0.3229, F1 Macro: 0.3039, Accuracy: 0.3229\n","Epoch 80, Train Loss: 2.4985, Val Loss: 2.8858, F1 Micro: 0.2604, F1 Macro: 0.2325, Accuracy: 0.2604\n","Epoch 81, Train Loss: 3.7777, Val Loss: 4.3015, F1 Micro: 0.3229, F1 Macro: 0.2392, Accuracy: 0.3229\n","Epoch 82, Train Loss: 2.9569, Val Loss: 3.3856, F1 Micro: 0.2708, F1 Macro: 0.2623, Accuracy: 0.2708\n","Epoch 83, Train Loss: 3.0101, Val Loss: 3.2731, F1 Micro: 0.2396, F1 Macro: 0.1813, Accuracy: 0.2396\n","Epoch 84, Train Loss: 3.2203, Val Loss: 3.1634, F1 Micro: 0.3229, F1 Macro: 0.2324, Accuracy: 0.3229\n","Epoch 85, Train Loss: 3.5152, Val Loss: 4.6652, F1 Micro: 0.3229, F1 Macro: 0.2774, Accuracy: 0.3229\n","Epoch 86, Train Loss: 2.6467, Val Loss: 2.7834, F1 Micro: 0.1979, F1 Macro: 0.1482, Accuracy: 0.1979\n","Epoch 87, Train Loss: 3.1914, Val Loss: 2.6001, F1 Micro: 0.2812, F1 Macro: 0.2288, Accuracy: 0.2812\n","Epoch 88, Train Loss: 2.2237, Val Loss: 3.5615, F1 Micro: 0.3021, F1 Macro: 0.2773, Accuracy: 0.3021\n","Epoch 89, Train Loss: 2.4728, Val Loss: 2.2599, F1 Micro: 0.2083, F1 Macro: 0.1927, Accuracy: 0.2083\n","Epoch 90, Train Loss: 1.8911, Val Loss: 2.3193, F1 Micro: 0.3750, F1 Macro: 0.2821, Accuracy: 0.3750\n","Epoch 91, Train Loss: 2.4303, Val Loss: 3.0250, F1 Micro: 0.2292, F1 Macro: 0.1578, Accuracy: 0.2292\n","Epoch 92, Train Loss: 2.2290, Val Loss: 2.8602, F1 Micro: 0.1979, F1 Macro: 0.1337, Accuracy: 0.1979\n","Epoch 93, Train Loss: 2.3706, Val Loss: 2.8244, F1 Micro: 0.3333, F1 Macro: 0.3246, Accuracy: 0.3333\n","Epoch 94, Train Loss: 4.3400, Val Loss: 4.0224, F1 Micro: 0.2604, F1 Macro: 0.1967, Accuracy: 0.2604\n","Epoch 95, Train Loss: 3.2022, Val Loss: 2.9407, F1 Micro: 0.2500, F1 Macro: 0.2073, Accuracy: 0.2500\n","Epoch 96, Train Loss: 2.9568, Val Loss: 2.7983, F1 Micro: 0.3021, F1 Macro: 0.2492, Accuracy: 0.3021\n","Epoch 97, Train Loss: 2.3840, Val Loss: 3.5347, F1 Micro: 0.3542, F1 Macro: 0.2161, Accuracy: 0.3542\n","Epoch 98, Train Loss: 2.7690, Val Loss: 2.7989, F1 Micro: 0.3125, F1 Macro: 0.2305, Accuracy: 0.3125\n","Epoch 99, Train Loss: 2.7188, Val Loss: 2.7627, F1 Micro: 0.2604, F1 Macro: 0.2058, Accuracy: 0.2604\n","Epoch 100, Train Loss: 2.2941, Val Loss: 2.5637, F1 Micro: 0.3229, F1 Macro: 0.2638, Accuracy: 0.3229\n","Epoch 101, Train Loss: 2.2974, Val Loss: 2.2444, F1 Micro: 0.3854, F1 Macro: 0.2978, Accuracy: 0.3854\n","Epoch 102, Train Loss: 2.6361, Val Loss: 3.9090, F1 Micro: 0.2917, F1 Macro: 0.2027, Accuracy: 0.2917\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 276.2854, Val Loss: 66.9636, F1 Micro: 0.1354, F1 Macro: 0.0764, Accuracy: 0.1354\n","Epoch 2, Train Loss: 36.9158, Val Loss: 32.1956, F1 Micro: 0.2812, F1 Macro: 0.2099, Accuracy: 0.2812\n","Epoch 3, Train Loss: 21.2534, Val Loss: 11.2200, F1 Micro: 0.2292, F1 Macro: 0.1540, Accuracy: 0.2292\n","Epoch 4, Train Loss: 10.9526, Val Loss: 15.3436, F1 Micro: 0.3333, F1 Macro: 0.2662, Accuracy: 0.3333\n","Epoch 5, Train Loss: 9.5162, Val Loss: 6.3848, F1 Micro: 0.2500, F1 Macro: 0.2140, Accuracy: 0.2500\n","Epoch 6, Train Loss: 10.8308, Val Loss: 12.9871, F1 Micro: 0.2604, F1 Macro: 0.1671, Accuracy: 0.2604\n","Epoch 7, Train Loss: 17.6961, Val Loss: 14.3415, F1 Micro: 0.2083, F1 Macro: 0.1299, Accuracy: 0.2083\n","Epoch 8, Train Loss: 13.8298, Val Loss: 25.9272, F1 Micro: 0.1875, F1 Macro: 0.0976, Accuracy: 0.1875\n","Epoch 9, Train Loss: 11.5195, Val Loss: 9.5064, F1 Micro: 0.2708, F1 Macro: 0.2186, Accuracy: 0.2708\n","Epoch 10, Train Loss: 8.9171, Val Loss: 7.3108, F1 Micro: 0.2396, F1 Macro: 0.1832, Accuracy: 0.2396\n","Epoch 11, Train Loss: 8.5776, Val Loss: 6.6679, F1 Micro: 0.2188, F1 Macro: 0.1502, Accuracy: 0.2188\n","Epoch 12, Train Loss: 5.1973, Val Loss: 11.1319, F1 Micro: 0.1667, F1 Macro: 0.0518, Accuracy: 0.1667\n","Epoch 13, Train Loss: 6.0387, Val Loss: 4.9434, F1 Micro: 0.1979, F1 Macro: 0.1223, Accuracy: 0.1979\n","Epoch 14, Train Loss: 7.7287, Val Loss: 11.5038, F1 Micro: 0.2188, F1 Macro: 0.1449, Accuracy: 0.2188\n","Epoch 15, Train Loss: 7.0048, Val Loss: 8.4079, F1 Micro: 0.1979, F1 Macro: 0.1432, Accuracy: 0.1979\n","Epoch 16, Train Loss: 8.4577, Val Loss: 8.2824, F1 Micro: 0.2396, F1 Macro: 0.1569, Accuracy: 0.2396\n","Epoch 17, Train Loss: 8.3996, Val Loss: 6.7287, F1 Micro: 0.2188, F1 Macro: 0.1376, Accuracy: 0.2188\n","Epoch 18, Train Loss: 6.3900, Val Loss: 10.5854, F1 Micro: 0.1979, F1 Macro: 0.1024, Accuracy: 0.1979\n","Epoch 19, Train Loss: 6.9050, Val Loss: 6.2041, F1 Micro: 0.2292, F1 Macro: 0.1612, Accuracy: 0.2292\n","Epoch 20, Train Loss: 8.3136, Val Loss: 4.7339, F1 Micro: 0.2083, F1 Macro: 0.1489, Accuracy: 0.2083\n","Epoch 21, Train Loss: 5.6402, Val Loss: 4.9817, F1 Micro: 0.2500, F1 Macro: 0.1884, Accuracy: 0.2500\n","Epoch 22, Train Loss: 5.4687, Val Loss: 6.9175, F1 Micro: 0.2188, F1 Macro: 0.1361, Accuracy: 0.2188\n","Epoch 23, Train Loss: 12.2486, Val Loss: 13.2302, F1 Micro: 0.2188, F1 Macro: 0.1026, Accuracy: 0.2188\n","Epoch 24, Train Loss: 38.6220, Val Loss: 56.9658, F1 Micro: 0.1771, F1 Macro: 0.0520, Accuracy: 0.1771\n","Epoch 25, Train Loss: 94.8429, Val Loss: 161.7575, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 26, Train Loss: 179.4885, Val Loss: 146.0294, F1 Micro: 0.1354, F1 Macro: 0.0401, Accuracy: 0.1354\n","Epoch 27, Train Loss: 85.7822, Val Loss: 145.2665, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 28, Train Loss: 58.5843, Val Loss: 31.6511, F1 Micro: 0.1667, F1 Macro: 0.1034, Accuracy: 0.1667\n","Epoch 29, Train Loss: 13.5156, Val Loss: 7.2867, F1 Micro: 0.3125, F1 Macro: 0.2215, Accuracy: 0.3125\n","Epoch 30, Train Loss: 4.2091, Val Loss: 3.1829, F1 Micro: 0.2604, F1 Macro: 0.2177, Accuracy: 0.2604\n","Epoch 31, Train Loss: 2.4037, Val Loss: 2.5749, F1 Micro: 0.3542, F1 Macro: 0.3019, Accuracy: 0.3542\n","Epoch 32, Train Loss: 2.6863, Val Loss: 3.2640, F1 Micro: 0.3229, F1 Macro: 0.2921, Accuracy: 0.3229\n","Epoch 33, Train Loss: 2.6960, Val Loss: 1.9047, F1 Micro: 0.3021, F1 Macro: 0.2889, Accuracy: 0.3021\n","Epoch 34, Train Loss: 2.2632, Val Loss: 2.4179, F1 Micro: 0.2500, F1 Macro: 0.2014, Accuracy: 0.2500\n","Epoch 35, Train Loss: 3.8356, Val Loss: 6.9316, F1 Micro: 0.1979, F1 Macro: 0.1307, Accuracy: 0.1979\n","Epoch 36, Train Loss: 5.5998, Val Loss: 8.2770, F1 Micro: 0.1562, F1 Macro: 0.0455, Accuracy: 0.1562\n","Epoch 37, Train Loss: 6.0211, Val Loss: 4.6184, F1 Micro: 0.2604, F1 Macro: 0.1730, Accuracy: 0.2604\n","Epoch 38, Train Loss: 3.0289, Val Loss: 4.4870, F1 Micro: 0.1771, F1 Macro: 0.0827, Accuracy: 0.1771\n","Epoch 39, Train Loss: 3.1481, Val Loss: 3.9432, F1 Micro: 0.2083, F1 Macro: 0.1638, Accuracy: 0.2083\n","Epoch 40, Train Loss: 3.3526, Val Loss: 4.4898, F1 Micro: 0.2292, F1 Macro: 0.1407, Accuracy: 0.2292\n","Epoch 41, Train Loss: 4.2652, Val Loss: 3.8316, F1 Micro: 0.2604, F1 Macro: 0.2084, Accuracy: 0.2604\n","Epoch 42, Train Loss: 3.5848, Val Loss: 3.1500, F1 Micro: 0.2500, F1 Macro: 0.2220, Accuracy: 0.2500\n","Epoch 43, Train Loss: 2.5828, Val Loss: 1.9386, F1 Micro: 0.3646, F1 Macro: 0.2938, Accuracy: 0.3646\n","Epoch 44, Train Loss: 3.6794, Val Loss: 3.1868, F1 Micro: 0.2083, F1 Macro: 0.1392, Accuracy: 0.2083\n","Epoch 45, Train Loss: 4.7683, Val Loss: 6.7063, F1 Micro: 0.1771, F1 Macro: 0.1267, Accuracy: 0.1771\n","Epoch 46, Train Loss: 9.4066, Val Loss: 4.9611, F1 Micro: 0.1667, F1 Macro: 0.1140, Accuracy: 0.1667\n","Epoch 47, Train Loss: 4.8638, Val Loss: 4.6769, F1 Micro: 0.2083, F1 Macro: 0.0998, Accuracy: 0.2083\n","Epoch 48, Train Loss: 7.4905, Val Loss: 13.4522, F1 Micro: 0.2292, F1 Macro: 0.1163, Accuracy: 0.2292\n","Epoch 49, Train Loss: 19.2207, Val Loss: 22.3716, F1 Micro: 0.1979, F1 Macro: 0.0915, Accuracy: 0.1979\n","Epoch 50, Train Loss: 55.1053, Val Loss: 85.6087, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 51, Train Loss: 120.4048, Val Loss: 65.7508, F1 Micro: 0.1667, F1 Macro: 0.0821, Accuracy: 0.1667\n","Epoch 52, Train Loss: 127.7020, Val Loss: 264.7875, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 53, Train Loss: 122.3787, Val Loss: 73.0309, F1 Micro: 0.1875, F1 Macro: 0.0696, Accuracy: 0.1875\n","Epoch 54, Train Loss: 78.5274, Val Loss: 35.7262, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 55, Train Loss: 13.9376, Val Loss: 8.4458, F1 Micro: 0.2083, F1 Macro: 0.1427, Accuracy: 0.2083\n","Epoch 56, Train Loss: 5.5935, Val Loss: 5.5304, F1 Micro: 0.1667, F1 Macro: 0.0896, Accuracy: 0.1667\n","Epoch 57, Train Loss: 4.0657, Val Loss: 3.2428, F1 Micro: 0.1979, F1 Macro: 0.1664, Accuracy: 0.1979\n","Epoch 58, Train Loss: 3.2177, Val Loss: 2.8502, F1 Micro: 0.2500, F1 Macro: 0.1970, Accuracy: 0.2500\n","Epoch 59, Train Loss: 2.9691, Val Loss: 3.5660, F1 Micro: 0.2917, F1 Macro: 0.2395, Accuracy: 0.2917\n","Epoch 60, Train Loss: 2.3915, Val Loss: 2.2228, F1 Micro: 0.3438, F1 Macro: 0.2997, Accuracy: 0.3438\n","Epoch 61, Train Loss: 2.5778, Val Loss: 2.8871, F1 Micro: 0.2500, F1 Macro: 0.2026, Accuracy: 0.2500\n","Epoch 62, Train Loss: 2.6535, Val Loss: 2.6695, F1 Micro: 0.2396, F1 Macro: 0.2069, Accuracy: 0.2396\n","Epoch 63, Train Loss: 2.7761, Val Loss: 3.7213, F1 Micro: 0.2708, F1 Macro: 0.2516, Accuracy: 0.2708\n","Epoch 64, Train Loss: 2.3515, Val Loss: 2.0474, F1 Micro: 0.2917, F1 Macro: 0.2322, Accuracy: 0.2917\n","Epoch 65, Train Loss: 2.4271, Val Loss: 2.1455, F1 Micro: 0.2708, F1 Macro: 0.2324, Accuracy: 0.2708\n","Epoch 66, Train Loss: 2.9153, Val Loss: 5.0051, F1 Micro: 0.2396, F1 Macro: 0.1797, Accuracy: 0.2396\n","Epoch 67, Train Loss: 4.8623, Val Loss: 4.0182, F1 Micro: 0.2708, F1 Macro: 0.1796, Accuracy: 0.2708\n","Epoch 68, Train Loss: 5.8328, Val Loss: 5.6291, F1 Micro: 0.2188, F1 Macro: 0.1384, Accuracy: 0.2188\n","Epoch 69, Train Loss: 6.0706, Val Loss: 6.8010, F1 Micro: 0.2292, F1 Macro: 0.1395, Accuracy: 0.2292\n","Epoch 70, Train Loss: 6.3736, Val Loss: 4.1497, F1 Micro: 0.2292, F1 Macro: 0.1773, Accuracy: 0.2292\n","Epoch 71, Train Loss: 4.1989, Val Loss: 3.4530, F1 Micro: 0.3542, F1 Macro: 0.3126, Accuracy: 0.3542\n","Epoch 72, Train Loss: 3.5921, Val Loss: 3.2016, F1 Micro: 0.2188, F1 Macro: 0.1378, Accuracy: 0.2188\n","Epoch 73, Train Loss: 3.7347, Val Loss: 4.5610, F1 Micro: 0.2500, F1 Macro: 0.1592, Accuracy: 0.2500\n","Epoch 74, Train Loss: 6.9288, Val Loss: 8.0380, F1 Micro: 0.2188, F1 Macro: 0.1075, Accuracy: 0.2188\n","Epoch 75, Train Loss: 21.1804, Val Loss: 98.1945, F1 Micro: 0.1667, F1 Macro: 0.0663, Accuracy: 0.1667\n","Epoch 76, Train Loss: 181.1390, Val Loss: 115.7756, F1 Micro: 0.1562, F1 Macro: 0.0794, Accuracy: 0.1562\n","Epoch 77, Train Loss: 202.4844, Val Loss: 203.0464, F1 Micro: 0.1771, F1 Macro: 0.0506, Accuracy: 0.1771\n","Epoch 78, Train Loss: 133.0749, Val Loss: 52.2885, F1 Micro: 0.1771, F1 Macro: 0.0861, Accuracy: 0.1771\n","Epoch 79, Train Loss: 41.5605, Val Loss: 24.3748, F1 Micro: 0.1667, F1 Macro: 0.0782, Accuracy: 0.1667\n","Epoch 80, Train Loss: 40.0508, Val Loss: 67.9801, F1 Micro: 0.1771, F1 Macro: 0.0785, Accuracy: 0.1771\n","Epoch 81, Train Loss: 21.2357, Val Loss: 7.8692, F1 Micro: 0.2917, F1 Macro: 0.2362, Accuracy: 0.2917\n","Epoch 82, Train Loss: 5.3646, Val Loss: 9.2102, F1 Micro: 0.1875, F1 Macro: 0.1049, Accuracy: 0.1875\n","Epoch 83, Train Loss: 4.0687, Val Loss: 3.5764, F1 Micro: 0.2812, F1 Macro: 0.2584, Accuracy: 0.2812\n","Epoch 84, Train Loss: 3.0956, Val Loss: 2.9863, F1 Micro: 0.2500, F1 Macro: 0.1809, Accuracy: 0.2500\n","Epoch 85, Train Loss: 2.6813, Val Loss: 2.4139, F1 Micro: 0.3229, F1 Macro: 0.3015, Accuracy: 0.3229\n","Epoch 86, Train Loss: 2.6250, Val Loss: 2.1796, F1 Micro: 0.3021, F1 Macro: 0.2483, Accuracy: 0.3021\n","Epoch 87, Train Loss: 3.0428, Val Loss: 3.7560, F1 Micro: 0.2812, F1 Macro: 0.2056, Accuracy: 0.2812\n","Epoch 88, Train Loss: 3.7093, Val Loss: 3.2707, F1 Micro: 0.3854, F1 Macro: 0.3140, Accuracy: 0.3854\n","Epoch 89, Train Loss: 3.1490, Val Loss: 2.9378, F1 Micro: 0.2708, F1 Macro: 0.2529, Accuracy: 0.2708\n","Epoch 90, Train Loss: 2.2737, Val Loss: 2.5539, F1 Micro: 0.2812, F1 Macro: 0.2159, Accuracy: 0.2812\n","Epoch 91, Train Loss: 3.2501, Val Loss: 4.8866, F1 Micro: 0.2396, F1 Macro: 0.1637, Accuracy: 0.2396\n","Epoch 92, Train Loss: 3.6246, Val Loss: 3.2928, F1 Micro: 0.2812, F1 Macro: 0.1960, Accuracy: 0.2812\n","Epoch 93, Train Loss: 3.0401, Val Loss: 2.9843, F1 Micro: 0.2188, F1 Macro: 0.1500, Accuracy: 0.2188\n","Epoch 94, Train Loss: 3.2563, Val Loss: 2.7585, F1 Micro: 0.2188, F1 Macro: 0.2007, Accuracy: 0.2188\n","Epoch 95, Train Loss: 3.1716, Val Loss: 2.3622, F1 Micro: 0.3125, F1 Macro: 0.2697, Accuracy: 0.3125\n","Epoch 96, Train Loss: 2.5057, Val Loss: 3.4432, F1 Micro: 0.2812, F1 Macro: 0.2168, Accuracy: 0.2812\n","Epoch 97, Train Loss: 2.7976, Val Loss: 2.7965, F1 Micro: 0.3125, F1 Macro: 0.2958, Accuracy: 0.3125\n","Epoch 98, Train Loss: 2.4697, Val Loss: 2.6748, F1 Micro: 0.1979, F1 Macro: 0.1399, Accuracy: 0.1979\n","Epoch 99, Train Loss: 2.5219, Val Loss: 4.0592, F1 Micro: 0.2396, F1 Macro: 0.1750, Accuracy: 0.2396\n","Epoch 100, Train Loss: 4.0128, Val Loss: 4.1850, F1 Micro: 0.3125, F1 Macro: 0.2330, Accuracy: 0.3125\n","Epoch 101, Train Loss: 5.5156, Val Loss: 7.5825, F1 Micro: 0.2500, F1 Macro: 0.1754, Accuracy: 0.2500\n","Epoch 102, Train Loss: 4.8210, Val Loss: 7.2280, F1 Micro: 0.3229, F1 Macro: 0.2263, Accuracy: 0.3229\n","Epoch 103, Train Loss: 4.8866, Val Loss: 4.6714, F1 Micro: 0.2292, F1 Macro: 0.1526, Accuracy: 0.2292\n","Epoch 104, Train Loss: 13.5715, Val Loss: 17.8917, F1 Micro: 0.1250, F1 Macro: 0.0591, Accuracy: 0.1250\n","Epoch 105, Train Loss: 88.2887, Val Loss: 80.0941, F1 Micro: 0.2188, F1 Macro: 0.1178, Accuracy: 0.2188\n","Epoch 106, Train Loss: 392.0991, Val Loss: 693.2390, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 107, Train Loss: 410.7920, Val Loss: 365.9042, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 108, Train Loss: 111.8474, Val Loss: 45.2357, F1 Micro: 0.1979, F1 Macro: 0.0906, Accuracy: 0.1979\n","Epoch 109, Train Loss: 28.0825, Val Loss: 13.1933, F1 Micro: 0.2396, F1 Macro: 0.1759, Accuracy: 0.2396\n","Epoch 110, Train Loss: 8.9403, Val Loss: 6.3027, F1 Micro: 0.2188, F1 Macro: 0.1633, Accuracy: 0.2188\n","Epoch 111, Train Loss: 4.6076, Val Loss: 3.6929, F1 Micro: 0.3750, F1 Macro: 0.3233, Accuracy: 0.3750\n","Epoch 112, Train Loss: 3.0181, Val Loss: 3.2237, F1 Micro: 0.1667, F1 Macro: 0.1448, Accuracy: 0.1667\n","Epoch 113, Train Loss: 3.8224, Val Loss: 3.9650, F1 Micro: 0.2812, F1 Macro: 0.2139, Accuracy: 0.2812\n","Epoch 114, Train Loss: 2.8195, Val Loss: 3.5082, F1 Micro: 0.2708, F1 Macro: 0.2065, Accuracy: 0.2708\n","Epoch 115, Train Loss: 2.3929, Val Loss: 2.3403, F1 Micro: 0.3333, F1 Macro: 0.3055, Accuracy: 0.3333\n","Epoch 116, Train Loss: 2.2958, Val Loss: 2.4897, F1 Micro: 0.2500, F1 Macro: 0.2325, Accuracy: 0.2500\n","Epoch 117, Train Loss: 2.5149, Val Loss: 3.1308, F1 Micro: 0.2917, F1 Macro: 0.2588, Accuracy: 0.2917\n","Epoch 118, Train Loss: 3.1055, Val Loss: 2.5843, F1 Micro: 0.3542, F1 Macro: 0.3323, Accuracy: 0.3542\n","Epoch 119, Train Loss: 2.3846, Val Loss: 2.8330, F1 Micro: 0.3125, F1 Macro: 0.2354, Accuracy: 0.3125\n","Epoch 120, Train Loss: 3.0222, Val Loss: 10.0600, F1 Micro: 0.2083, F1 Macro: 0.1239, Accuracy: 0.2083\n","Epoch 121, Train Loss: 4.6763, Val Loss: 3.7495, F1 Micro: 0.2292, F1 Macro: 0.1878, Accuracy: 0.2292\n","Epoch 122, Train Loss: 3.1652, Val Loss: 3.8424, F1 Micro: 0.2917, F1 Macro: 0.2009, Accuracy: 0.2917\n","Epoch 123, Train Loss: 2.6373, Val Loss: 2.2161, F1 Micro: 0.3750, F1 Macro: 0.3344, Accuracy: 0.3750\n","Epoch 124, Train Loss: 2.7581, Val Loss: 2.7607, F1 Micro: 0.2188, F1 Macro: 0.1458, Accuracy: 0.2188\n","Epoch 125, Train Loss: 2.2312, Val Loss: 2.5462, F1 Micro: 0.2292, F1 Macro: 0.1608, Accuracy: 0.2292\n","Epoch 126, Train Loss: 3.2336, Val Loss: 3.8103, F1 Micro: 0.2604, F1 Macro: 0.2290, Accuracy: 0.2604\n","Epoch 127, Train Loss: 2.8776, Val Loss: 2.7643, F1 Micro: 0.3021, F1 Macro: 0.2253, Accuracy: 0.3021\n","Epoch 128, Train Loss: 2.8327, Val Loss: 2.3986, F1 Micro: 0.3229, F1 Macro: 0.2879, Accuracy: 0.3229\n","Epoch 129, Train Loss: 2.7344, Val Loss: 3.4676, F1 Micro: 0.3333, F1 Macro: 0.2931, Accuracy: 0.3333\n","Epoch 130, Train Loss: 2.6416, Val Loss: 2.4582, F1 Micro: 0.3438, F1 Macro: 0.2874, Accuracy: 0.3438\n","Epoch 131, Train Loss: 3.0245, Val Loss: 2.7876, F1 Micro: 0.2708, F1 Macro: 0.2176, Accuracy: 0.2708\n","Epoch 132, Train Loss: 3.0422, Val Loss: 6.0414, F1 Micro: 0.1979, F1 Macro: 0.0974, Accuracy: 0.1979\n","Epoch 133, Train Loss: 9.2559, Val Loss: 20.2349, F1 Micro: 0.1771, F1 Macro: 0.1028, Accuracy: 0.1771\n","Epoch 134, Train Loss: 38.9262, Val Loss: 71.7819, F1 Micro: 0.1875, F1 Macro: 0.0873, Accuracy: 0.1875\n","Epoch 135, Train Loss: 99.9437, Val Loss: 129.8535, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 136, Train Loss: 108.3940, Val Loss: 60.7043, F1 Micro: 0.1979, F1 Macro: 0.1172, Accuracy: 0.1979\n","Epoch 137, Train Loss: 38.2818, Val Loss: 31.0980, F1 Micro: 0.2083, F1 Macro: 0.0957, Accuracy: 0.2083\n","Epoch 138, Train Loss: 27.9288, Val Loss: 42.4254, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 351.2787, Val Loss: 38.8883, F1 Micro: 0.1875, F1 Macro: 0.1111, Accuracy: 0.1875\n","Epoch 2, Train Loss: 39.3651, Val Loss: 20.8679, F1 Micro: 0.2604, F1 Macro: 0.1955, Accuracy: 0.2604\n","Epoch 3, Train Loss: 18.7445, Val Loss: 18.5411, F1 Micro: 0.3021, F1 Macro: 0.2169, Accuracy: 0.3021\n","Epoch 4, Train Loss: 14.4978, Val Loss: 8.7275, F1 Micro: 0.1875, F1 Macro: 0.1735, Accuracy: 0.1875\n","Epoch 5, Train Loss: 10.3451, Val Loss: 13.5876, F1 Micro: 0.1458, F1 Macro: 0.1045, Accuracy: 0.1458\n","Epoch 6, Train Loss: 8.3791, Val Loss: 7.9128, F1 Micro: 0.1667, F1 Macro: 0.1465, Accuracy: 0.1667\n","Epoch 7, Train Loss: 11.3833, Val Loss: 13.0279, F1 Micro: 0.1667, F1 Macro: 0.0756, Accuracy: 0.1667\n","Epoch 8, Train Loss: 8.2085, Val Loss: 7.0681, F1 Micro: 0.1667, F1 Macro: 0.1147, Accuracy: 0.1667\n","Epoch 9, Train Loss: 7.9711, Val Loss: 7.6927, F1 Micro: 0.3229, F1 Macro: 0.2878, Accuracy: 0.3229\n","Epoch 10, Train Loss: 8.4587, Val Loss: 5.6022, F1 Micro: 0.2396, F1 Macro: 0.1749, Accuracy: 0.2396\n","Epoch 11, Train Loss: 8.2374, Val Loss: 11.8326, F1 Micro: 0.3021, F1 Macro: 0.2484, Accuracy: 0.3021\n","Epoch 12, Train Loss: 16.7099, Val Loss: 9.7533, F1 Micro: 0.2500, F1 Macro: 0.1763, Accuracy: 0.2500\n","Epoch 13, Train Loss: 10.1638, Val Loss: 8.3954, F1 Micro: 0.2292, F1 Macro: 0.1537, Accuracy: 0.2292\n","Epoch 14, Train Loss: 6.9950, Val Loss: 4.1334, F1 Micro: 0.3125, F1 Macro: 0.2389, Accuracy: 0.3125\n","Epoch 15, Train Loss: 8.7408, Val Loss: 14.7189, F1 Micro: 0.1875, F1 Macro: 0.1147, Accuracy: 0.1875\n","Epoch 16, Train Loss: 8.8378, Val Loss: 6.5018, F1 Micro: 0.2292, F1 Macro: 0.1282, Accuracy: 0.2292\n","Epoch 17, Train Loss: 7.8708, Val Loss: 5.6810, F1 Micro: 0.1562, F1 Macro: 0.0864, Accuracy: 0.1562\n","Epoch 18, Train Loss: 6.5232, Val Loss: 4.3053, F1 Micro: 0.1771, F1 Macro: 0.1289, Accuracy: 0.1771\n","Epoch 19, Train Loss: 7.8853, Val Loss: 13.0170, F1 Micro: 0.2500, F1 Macro: 0.1673, Accuracy: 0.2500\n","Epoch 20, Train Loss: 12.9357, Val Loss: 11.8337, F1 Micro: 0.1875, F1 Macro: 0.1231, Accuracy: 0.1875\n","Epoch 21, Train Loss: 6.8875, Val Loss: 5.5093, F1 Micro: 0.2396, F1 Macro: 0.1618, Accuracy: 0.2396\n","Epoch 22, Train Loss: 4.1595, Val Loss: 3.2379, F1 Micro: 0.2188, F1 Macro: 0.1812, Accuracy: 0.2188\n","Epoch 23, Train Loss: 4.3734, Val Loss: 5.2017, F1 Micro: 0.1875, F1 Macro: 0.1250, Accuracy: 0.1875\n","Epoch 24, Train Loss: 4.7508, Val Loss: 2.5149, F1 Micro: 0.2708, F1 Macro: 0.2628, Accuracy: 0.2708\n","Epoch 25, Train Loss: 3.8198, Val Loss: 7.4682, F1 Micro: 0.2396, F1 Macro: 0.1371, Accuracy: 0.2396\n","Epoch 26, Train Loss: 5.4697, Val Loss: 8.2036, F1 Micro: 0.2396, F1 Macro: 0.1286, Accuracy: 0.2396\n","Epoch 27, Train Loss: 10.5040, Val Loss: 8.1797, F1 Micro: 0.1771, F1 Macro: 0.1052, Accuracy: 0.1771\n","Epoch 28, Train Loss: 6.9359, Val Loss: 10.4246, F1 Micro: 0.2292, F1 Macro: 0.0945, Accuracy: 0.2292\n","Epoch 29, Train Loss: 19.3157, Val Loss: 27.6862, F1 Micro: 0.1562, F1 Macro: 0.0648, Accuracy: 0.1562\n","Epoch 30, Train Loss: 69.5185, Val Loss: 23.3524, F1 Micro: 0.2604, F1 Macro: 0.1275, Accuracy: 0.2604\n","Epoch 31, Train Loss: 113.2298, Val Loss: 261.4109, F1 Micro: 0.1875, F1 Macro: 0.1094, Accuracy: 0.1875\n","Epoch 32, Train Loss: 469.6376, Val Loss: 325.4168, F1 Micro: 0.1771, F1 Macro: 0.0897, Accuracy: 0.1771\n","Epoch 33, Train Loss: 455.2624, Val Loss: 99.6800, F1 Micro: 0.1562, F1 Macro: 0.0922, Accuracy: 0.1562\n","Epoch 34, Train Loss: 137.4669, Val Loss: 80.4890, F1 Micro: 0.2396, F1 Macro: 0.1622, Accuracy: 0.2396\n","Epoch 35, Train Loss: 58.4622, Val Loss: 17.6558, F1 Micro: 0.2812, F1 Macro: 0.2371, Accuracy: 0.2812\n","Epoch 36, Train Loss: 17.3987, Val Loss: 8.4263, F1 Micro: 0.2604, F1 Macro: 0.2101, Accuracy: 0.2604\n","Epoch 37, Train Loss: 7.2276, Val Loss: 7.1807, F1 Micro: 0.1875, F1 Macro: 0.1136, Accuracy: 0.1875\n","Epoch 38, Train Loss: 3.9713, Val Loss: 2.8513, F1 Micro: 0.2604, F1 Macro: 0.2151, Accuracy: 0.2604\n","Epoch 39, Train Loss: 3.0709, Val Loss: 2.3917, F1 Micro: 0.2917, F1 Macro: 0.2654, Accuracy: 0.2917\n","Epoch 40, Train Loss: 2.9285, Val Loss: 2.7574, F1 Micro: 0.2604, F1 Macro: 0.2145, Accuracy: 0.2604\n","Epoch 41, Train Loss: 2.7430, Val Loss: 3.9794, F1 Micro: 0.1979, F1 Macro: 0.1374, Accuracy: 0.1979\n","Epoch 42, Train Loss: 3.2854, Val Loss: 3.5800, F1 Micro: 0.2604, F1 Macro: 0.2180, Accuracy: 0.2604\n","Epoch 43, Train Loss: 3.5803, Val Loss: 3.6469, F1 Micro: 0.2812, F1 Macro: 0.2156, Accuracy: 0.2812\n","Epoch 44, Train Loss: 2.7408, Val Loss: 2.5769, F1 Micro: 0.2396, F1 Macro: 0.2141, Accuracy: 0.2396\n","Epoch 45, Train Loss: 2.4209, Val Loss: 2.2130, F1 Micro: 0.2812, F1 Macro: 0.1917, Accuracy: 0.2812\n","Epoch 46, Train Loss: 2.5267, Val Loss: 3.6418, F1 Micro: 0.1875, F1 Macro: 0.1575, Accuracy: 0.1875\n","Epoch 47, Train Loss: 3.0451, Val Loss: 2.5154, F1 Micro: 0.2708, F1 Macro: 0.2212, Accuracy: 0.2708\n","Epoch 48, Train Loss: 2.8341, Val Loss: 3.0210, F1 Micro: 0.3438, F1 Macro: 0.3096, Accuracy: 0.3438\n","Epoch 49, Train Loss: 2.4915, Val Loss: 2.1383, F1 Micro: 0.2812, F1 Macro: 0.2603, Accuracy: 0.2812\n","Epoch 50, Train Loss: 2.3529, Val Loss: 2.3146, F1 Micro: 0.3125, F1 Macro: 0.3057, Accuracy: 0.3125\n","Epoch 51, Train Loss: 2.5064, Val Loss: 3.1023, F1 Micro: 0.1979, F1 Macro: 0.1464, Accuracy: 0.1979\n","Epoch 52, Train Loss: 3.0050, Val Loss: 2.3467, F1 Micro: 0.2604, F1 Macro: 0.2189, Accuracy: 0.2604\n","Epoch 53, Train Loss: 3.3694, Val Loss: 9.1359, F1 Micro: 0.1562, F1 Macro: 0.0481, Accuracy: 0.1562\n","Epoch 54, Train Loss: 3.5685, Val Loss: 3.7979, F1 Micro: 0.1667, F1 Macro: 0.1206, Accuracy: 0.1667\n","Epoch 55, Train Loss: 2.7554, Val Loss: 2.6524, F1 Micro: 0.1875, F1 Macro: 0.1455, Accuracy: 0.1875\n","Epoch 56, Train Loss: 3.6927, Val Loss: 2.7101, F1 Micro: 0.2917, F1 Macro: 0.2428, Accuracy: 0.2917\n","Epoch 57, Train Loss: 3.2123, Val Loss: 2.8847, F1 Micro: 0.2292, F1 Macro: 0.2098, Accuracy: 0.2292\n","Epoch 58, Train Loss: 2.5653, Val Loss: 2.5515, F1 Micro: 0.2812, F1 Macro: 0.2232, Accuracy: 0.2812\n","Epoch 59, Train Loss: 2.3932, Val Loss: 1.7252, F1 Micro: 0.3229, F1 Macro: 0.3253, Accuracy: 0.3229\n","Epoch 60, Train Loss: 2.4961, Val Loss: 2.3420, F1 Micro: 0.3229, F1 Macro: 0.2760, Accuracy: 0.3229\n","Epoch 61, Train Loss: 2.6051, Val Loss: 2.5721, F1 Micro: 0.2604, F1 Macro: 0.1705, Accuracy: 0.2604\n","Epoch 62, Train Loss: 2.3600, Val Loss: 2.2499, F1 Micro: 0.2500, F1 Macro: 0.1913, Accuracy: 0.2500\n","Epoch 63, Train Loss: 2.3238, Val Loss: 2.6971, F1 Micro: 0.2812, F1 Macro: 0.2662, Accuracy: 0.2812\n","Epoch 64, Train Loss: 3.4867, Val Loss: 3.5497, F1 Micro: 0.2083, F1 Macro: 0.1449, Accuracy: 0.2083\n","Epoch 65, Train Loss: 4.5986, Val Loss: 4.4397, F1 Micro: 0.2917, F1 Macro: 0.2405, Accuracy: 0.2917\n","Epoch 66, Train Loss: 3.7776, Val Loss: 3.3518, F1 Micro: 0.3229, F1 Macro: 0.2342, Accuracy: 0.3229\n","Epoch 67, Train Loss: 4.2092, Val Loss: 3.8513, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 68, Train Loss: 2.9571, Val Loss: 2.8824, F1 Micro: 0.2708, F1 Macro: 0.1808, Accuracy: 0.2708\n","Epoch 69, Train Loss: 3.4297, Val Loss: 2.6423, F1 Micro: 0.2396, F1 Macro: 0.2185, Accuracy: 0.2396\n","Epoch 70, Train Loss: 2.7266, Val Loss: 3.0390, F1 Micro: 0.2917, F1 Macro: 0.2448, Accuracy: 0.2917\n","Epoch 71, Train Loss: 3.3498, Val Loss: 4.5051, F1 Micro: 0.2083, F1 Macro: 0.1244, Accuracy: 0.2083\n","Epoch 72, Train Loss: 4.8035, Val Loss: 3.2473, F1 Micro: 0.3125, F1 Macro: 0.2561, Accuracy: 0.3125\n","Epoch 73, Train Loss: 16.2036, Val Loss: 16.8493, F1 Micro: 0.2083, F1 Macro: 0.1131, Accuracy: 0.2083\n","Epoch 74, Train Loss: 122.0020, Val Loss: 236.1216, F1 Micro: 0.1458, F1 Macro: 0.0428, Accuracy: 0.1458\n","Epoch 75, Train Loss: 197.0084, Val Loss: 164.9159, F1 Micro: 0.1562, F1 Macro: 0.0633, Accuracy: 0.1562\n","Epoch 76, Train Loss: 91.3236, Val Loss: 117.1053, F1 Micro: 0.1562, F1 Macro: 0.0595, Accuracy: 0.1562\n","Epoch 77, Train Loss: 65.0498, Val Loss: 16.4534, F1 Micro: 0.2396, F1 Macro: 0.1916, Accuracy: 0.2396\n","Epoch 78, Train Loss: 33.0924, Val Loss: 14.3075, F1 Micro: 0.1771, F1 Macro: 0.1326, Accuracy: 0.1771\n","Epoch 79, Train Loss: 13.6619, Val Loss: 9.5072, F1 Micro: 0.2500, F1 Macro: 0.1661, Accuracy: 0.2500\n","Epoch 80, Train Loss: 9.6940, Val Loss: 6.7961, F1 Micro: 0.1979, F1 Macro: 0.1693, Accuracy: 0.1979\n","Epoch 81, Train Loss: 6.8704, Val Loss: 4.5190, F1 Micro: 0.2083, F1 Macro: 0.1785, Accuracy: 0.2083\n","Epoch 82, Train Loss: 7.4558, Val Loss: 6.6801, F1 Micro: 0.1979, F1 Macro: 0.0978, Accuracy: 0.1979\n","Epoch 83, Train Loss: 6.8198, Val Loss: 6.2735, F1 Micro: 0.2188, F1 Macro: 0.1264, Accuracy: 0.2188\n","Epoch 84, Train Loss: 4.4274, Val Loss: 2.5455, F1 Micro: 0.3125, F1 Macro: 0.2454, Accuracy: 0.3125\n","Epoch 85, Train Loss: 2.5300, Val Loss: 3.1022, F1 Micro: 0.2083, F1 Macro: 0.1465, Accuracy: 0.2083\n","Epoch 86, Train Loss: 4.2514, Val Loss: 2.9838, F1 Micro: 0.3021, F1 Macro: 0.2787, Accuracy: 0.3021\n","Epoch 87, Train Loss: 3.2602, Val Loss: 4.1026, F1 Micro: 0.2292, F1 Macro: 0.1736, Accuracy: 0.2292\n","Epoch 88, Train Loss: 3.8135, Val Loss: 5.4319, F1 Micro: 0.2500, F1 Macro: 0.1727, Accuracy: 0.2500\n","Epoch 89, Train Loss: 3.9715, Val Loss: 3.4209, F1 Micro: 0.2812, F1 Macro: 0.2217, Accuracy: 0.2812\n","Epoch 90, Train Loss: 4.5186, Val Loss: 4.4112, F1 Micro: 0.1667, F1 Macro: 0.0946, Accuracy: 0.1667\n","Epoch 91, Train Loss: 6.8085, Val Loss: 3.3662, F1 Micro: 0.3125, F1 Macro: 0.2579, Accuracy: 0.3125\n","Epoch 92, Train Loss: 9.4957, Val Loss: 16.9312, F1 Micro: 0.1562, F1 Macro: 0.0601, Accuracy: 0.1562\n","Epoch 93, Train Loss: 23.9542, Val Loss: 40.0876, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 94, Train Loss: 18.2730, Val Loss: 20.9291, F1 Micro: 0.1667, F1 Macro: 0.0793, Accuracy: 0.1667\n","Epoch 95, Train Loss: 19.0992, Val Loss: 48.1129, F1 Micro: 0.1562, F1 Macro: 0.0669, Accuracy: 0.1562\n","Epoch 96, Train Loss: 21.5133, Val Loss: 26.3304, F1 Micro: 0.2083, F1 Macro: 0.1402, Accuracy: 0.2083\n","Epoch 97, Train Loss: 36.5696, Val Loss: 35.5459, F1 Micro: 0.1458, F1 Macro: 0.0471, Accuracy: 0.1458\n","Epoch 98, Train Loss: 34.1787, Val Loss: 10.4671, F1 Micro: 0.2292, F1 Macro: 0.1761, Accuracy: 0.2292\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.3770833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 483.3005, Val Loss: 172.7640, F1 Micro: 0.1979, F1 Macro: 0.0954, Accuracy: 0.1979\n","Epoch 2, Train Loss: 82.3904, Val Loss: 50.5688, F1 Micro: 0.1667, F1 Macro: 0.0977, Accuracy: 0.1667\n","Epoch 3, Train Loss: 37.3993, Val Loss: 20.6653, F1 Micro: 0.2812, F1 Macro: 0.2421, Accuracy: 0.2812\n","Epoch 4, Train Loss: 15.6760, Val Loss: 13.7868, F1 Micro: 0.2708, F1 Macro: 0.1711, Accuracy: 0.2708\n","Epoch 5, Train Loss: 15.2571, Val Loss: 14.8344, F1 Micro: 0.2917, F1 Macro: 0.2387, Accuracy: 0.2917\n","Epoch 6, Train Loss: 13.9530, Val Loss: 11.3900, F1 Micro: 0.2917, F1 Macro: 0.2306, Accuracy: 0.2917\n","Epoch 7, Train Loss: 8.9870, Val Loss: 10.4451, F1 Micro: 0.1562, F1 Macro: 0.0995, Accuracy: 0.1562\n","Epoch 8, Train Loss: 7.5160, Val Loss: 5.7914, F1 Micro: 0.2812, F1 Macro: 0.2910, Accuracy: 0.2812\n","Epoch 9, Train Loss: 6.1595, Val Loss: 4.9359, F1 Micro: 0.2917, F1 Macro: 0.2402, Accuracy: 0.2917\n","Epoch 10, Train Loss: 5.0954, Val Loss: 5.9986, F1 Micro: 0.1875, F1 Macro: 0.1686, Accuracy: 0.1875\n","Epoch 11, Train Loss: 3.7521, Val Loss: 4.8893, F1 Micro: 0.2604, F1 Macro: 0.2379, Accuracy: 0.2604\n","Epoch 12, Train Loss: 4.9614, Val Loss: 4.8568, F1 Micro: 0.1979, F1 Macro: 0.1403, Accuracy: 0.1979\n","Epoch 13, Train Loss: 5.5947, Val Loss: 7.1928, F1 Micro: 0.2292, F1 Macro: 0.1976, Accuracy: 0.2292\n","Epoch 14, Train Loss: 4.7700, Val Loss: 8.2982, F1 Micro: 0.2083, F1 Macro: 0.1892, Accuracy: 0.2083\n","Epoch 15, Train Loss: 6.3016, Val Loss: 5.8950, F1 Micro: 0.2917, F1 Macro: 0.2628, Accuracy: 0.2917\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 416.1507, Val Loss: 112.9325, F1 Micro: 0.2188, F1 Macro: 0.1122, Accuracy: 0.2188\n","Epoch 2, Train Loss: 83.9605, Val Loss: 36.0640, F1 Micro: 0.3229, F1 Macro: 0.2162, Accuracy: 0.3229\n","Epoch 3, Train Loss: 33.5269, Val Loss: 43.8215, F1 Micro: 0.1250, F1 Macro: 0.1012, Accuracy: 0.1250\n","Epoch 4, Train Loss: 18.7592, Val Loss: 19.6695, F1 Micro: 0.1667, F1 Macro: 0.1058, Accuracy: 0.1667\n","Epoch 5, Train Loss: 14.0568, Val Loss: 19.0420, F1 Micro: 0.2292, F1 Macro: 0.1323, Accuracy: 0.2292\n","Epoch 6, Train Loss: 11.2277, Val Loss: 13.3184, F1 Micro: 0.1667, F1 Macro: 0.1716, Accuracy: 0.1667\n","Epoch 7, Train Loss: 14.3628, Val Loss: 15.9027, F1 Micro: 0.1354, F1 Macro: 0.1031, Accuracy: 0.1354\n","Epoch 8, Train Loss: 7.1956, Val Loss: 6.4393, F1 Micro: 0.2604, F1 Macro: 0.2147, Accuracy: 0.2604\n","Epoch 9, Train Loss: 6.3780, Val Loss: 11.8883, F1 Micro: 0.2396, F1 Macro: 0.1730, Accuracy: 0.2396\n","Epoch 10, Train Loss: 7.1372, Val Loss: 8.0357, F1 Micro: 0.2500, F1 Macro: 0.2367, Accuracy: 0.2500\n","Epoch 11, Train Loss: 5.2357, Val Loss: 6.3645, F1 Micro: 0.3542, F1 Macro: 0.3133, Accuracy: 0.3542\n","Epoch 12, Train Loss: 4.0679, Val Loss: 3.8500, F1 Micro: 0.2396, F1 Macro: 0.2477, Accuracy: 0.2396\n","Epoch 13, Train Loss: 3.7666, Val Loss: 5.1352, F1 Micro: 0.4167, F1 Macro: 0.3749, Accuracy: 0.4167\n","Epoch 14, Train Loss: 3.9013, Val Loss: 8.8544, F1 Micro: 0.2083, F1 Macro: 0.1638, Accuracy: 0.2083\n","Epoch 15, Train Loss: 3.1049, Val Loss: 3.9854, F1 Micro: 0.1667, F1 Macro: 0.1530, Accuracy: 0.1667\n","Epoch 16, Train Loss: 3.5960, Val Loss: 5.3936, F1 Micro: 0.2708, F1 Macro: 0.2343, Accuracy: 0.2708\n","Epoch 17, Train Loss: 3.6007, Val Loss: 3.5594, F1 Micro: 0.2500, F1 Macro: 0.1744, Accuracy: 0.2500\n","Epoch 18, Train Loss: 3.5977, Val Loss: 6.9439, F1 Micro: 0.3854, F1 Macro: 0.3358, Accuracy: 0.3854\n","Epoch 19, Train Loss: 3.6576, Val Loss: 4.0699, F1 Micro: 0.2083, F1 Macro: 0.1803, Accuracy: 0.2083\n","Epoch 20, Train Loss: 3.5159, Val Loss: 3.5215, F1 Micro: 0.2708, F1 Macro: 0.2433, Accuracy: 0.2708\n","Epoch 21, Train Loss: 4.6985, Val Loss: 8.5922, F1 Micro: 0.1042, F1 Macro: 0.0805, Accuracy: 0.1042\n","Epoch 22, Train Loss: 4.9111, Val Loss: 3.1617, F1 Micro: 0.2292, F1 Macro: 0.1991, Accuracy: 0.2292\n","Epoch 23, Train Loss: 4.2143, Val Loss: 3.5133, F1 Micro: 0.3021, F1 Macro: 0.2740, Accuracy: 0.3021\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 576.9435, Val Loss: 177.5512, F1 Micro: 0.1667, F1 Macro: 0.0726, Accuracy: 0.1667\n","Epoch 2, Train Loss: 104.5601, Val Loss: 42.6587, F1 Micro: 0.1771, F1 Macro: 0.1221, Accuracy: 0.1771\n","Epoch 3, Train Loss: 32.3275, Val Loss: 18.5115, F1 Micro: 0.2812, F1 Macro: 0.1681, Accuracy: 0.2812\n","Epoch 4, Train Loss: 18.1983, Val Loss: 11.3259, F1 Micro: 0.1771, F1 Macro: 0.1390, Accuracy: 0.1771\n","Epoch 5, Train Loss: 11.5482, Val Loss: 10.5326, F1 Micro: 0.2708, F1 Macro: 0.1917, Accuracy: 0.2708\n","Epoch 6, Train Loss: 10.3906, Val Loss: 20.2568, F1 Micro: 0.2500, F1 Macro: 0.1185, Accuracy: 0.2500\n","Epoch 7, Train Loss: 10.6581, Val Loss: 19.3037, F1 Micro: 0.1771, F1 Macro: 0.1238, Accuracy: 0.1771\n","Epoch 8, Train Loss: 9.5674, Val Loss: 6.3239, F1 Micro: 0.2083, F1 Macro: 0.1716, Accuracy: 0.2083\n","Epoch 9, Train Loss: 8.4831, Val Loss: 8.5840, F1 Micro: 0.2708, F1 Macro: 0.2564, Accuracy: 0.2708\n","Epoch 10, Train Loss: 5.1270, Val Loss: 4.8321, F1 Micro: 0.2604, F1 Macro: 0.2409, Accuracy: 0.2604\n","Epoch 11, Train Loss: 6.2879, Val Loss: 4.9177, F1 Micro: 0.2812, F1 Macro: 0.2583, Accuracy: 0.2812\n","Epoch 12, Train Loss: 5.9074, Val Loss: 6.2290, F1 Micro: 0.2500, F1 Macro: 0.2157, Accuracy: 0.2500\n","Epoch 13, Train Loss: 5.7501, Val Loss: 11.5845, F1 Micro: 0.1250, F1 Macro: 0.0675, Accuracy: 0.1250\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 544.9280, Val Loss: 125.6397, F1 Micro: 0.1354, F1 Macro: 0.0528, Accuracy: 0.1354\n","Epoch 2, Train Loss: 91.9260, Val Loss: 48.0937, F1 Micro: 0.1875, F1 Macro: 0.1144, Accuracy: 0.1875\n","Epoch 3, Train Loss: 35.9304, Val Loss: 14.7934, F1 Micro: 0.1979, F1 Macro: 0.1321, Accuracy: 0.1979\n","Epoch 4, Train Loss: 13.0389, Val Loss: 19.8576, F1 Micro: 0.2500, F1 Macro: 0.1951, Accuracy: 0.2500\n","Epoch 5, Train Loss: 13.1116, Val Loss: 9.2536, F1 Micro: 0.2917, F1 Macro: 0.2202, Accuracy: 0.2917\n","Epoch 6, Train Loss: 9.0028, Val Loss: 8.7524, F1 Micro: 0.2708, F1 Macro: 0.2026, Accuracy: 0.2708\n","Epoch 7, Train Loss: 8.8571, Val Loss: 20.0162, F1 Micro: 0.1458, F1 Macro: 0.0898, Accuracy: 0.1458\n","Epoch 8, Train Loss: 8.8164, Val Loss: 7.1362, F1 Micro: 0.2292, F1 Macro: 0.1681, Accuracy: 0.2292\n","Epoch 9, Train Loss: 5.9639, Val Loss: 3.6943, F1 Micro: 0.3542, F1 Macro: 0.3041, Accuracy: 0.3542\n","Epoch 10, Train Loss: 5.4533, Val Loss: 5.8972, F1 Micro: 0.2917, F1 Macro: 0.2735, Accuracy: 0.2917\n","Epoch 11, Train Loss: 5.1718, Val Loss: 5.0010, F1 Micro: 0.1979, F1 Macro: 0.1357, Accuracy: 0.1979\n","Epoch 12, Train Loss: 5.3617, Val Loss: 5.3563, F1 Micro: 0.3229, F1 Macro: 0.2634, Accuracy: 0.3229\n","Epoch 13, Train Loss: 4.7117, Val Loss: 4.1040, F1 Micro: 0.3021, F1 Macro: 0.2506, Accuracy: 0.3021\n","Epoch 14, Train Loss: 5.3460, Val Loss: 5.8619, F1 Micro: 0.3021, F1 Macro: 0.2984, Accuracy: 0.3021\n","Epoch 15, Train Loss: 4.9023, Val Loss: 7.6149, F1 Micro: 0.2604, F1 Macro: 0.2264, Accuracy: 0.2604\n","Epoch 16, Train Loss: 5.0464, Val Loss: 4.9863, F1 Micro: 0.3333, F1 Macro: 0.3202, Accuracy: 0.3333\n","Epoch 17, Train Loss: 4.6628, Val Loss: 4.5118, F1 Micro: 0.2708, F1 Macro: 0.2259, Accuracy: 0.2708\n","Epoch 18, Train Loss: 5.2321, Val Loss: 7.5146, F1 Micro: 0.2812, F1 Macro: 0.2173, Accuracy: 0.2812\n","Epoch 19, Train Loss: 5.4334, Val Loss: 4.1298, F1 Micro: 0.1667, F1 Macro: 0.1027, Accuracy: 0.1667\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 556.4062, Val Loss: 215.0730, F1 Micro: 0.1979, F1 Macro: 0.1028, Accuracy: 0.1979\n","Epoch 2, Train Loss: 88.1805, Val Loss: 47.1358, F1 Micro: 0.1562, F1 Macro: 0.0495, Accuracy: 0.1562\n","Epoch 3, Train Loss: 24.2653, Val Loss: 35.4429, F1 Micro: 0.1667, F1 Macro: 0.0544, Accuracy: 0.1667\n","Epoch 4, Train Loss: 23.8933, Val Loss: 19.2413, F1 Micro: 0.2188, F1 Macro: 0.1370, Accuracy: 0.2188\n","Epoch 5, Train Loss: 14.6230, Val Loss: 15.1932, F1 Micro: 0.1458, F1 Macro: 0.0995, Accuracy: 0.1458\n","Epoch 6, Train Loss: 10.5766, Val Loss: 9.9218, F1 Micro: 0.1562, F1 Macro: 0.1211, Accuracy: 0.1562\n","Epoch 7, Train Loss: 12.1529, Val Loss: 9.0740, F1 Micro: 0.2917, F1 Macro: 0.2139, Accuracy: 0.2917\n","Epoch 8, Train Loss: 8.4121, Val Loss: 4.9081, F1 Micro: 0.2708, F1 Macro: 0.2157, Accuracy: 0.2708\n","Epoch 9, Train Loss: 5.3519, Val Loss: 5.3115, F1 Micro: 0.2188, F1 Macro: 0.1400, Accuracy: 0.2188\n","Epoch 10, Train Loss: 4.2214, Val Loss: 2.3661, F1 Micro: 0.3854, F1 Macro: 0.3489, Accuracy: 0.3854\n","Epoch 11, Train Loss: 4.3461, Val Loss: 3.6128, F1 Micro: 0.3542, F1 Macro: 0.3086, Accuracy: 0.3542\n","Epoch 12, Train Loss: 3.4269, Val Loss: 3.2832, F1 Micro: 0.2292, F1 Macro: 0.1890, Accuracy: 0.2292\n","Epoch 13, Train Loss: 4.9876, Val Loss: 3.5315, F1 Micro: 0.2292, F1 Macro: 0.2203, Accuracy: 0.2292\n","Epoch 14, Train Loss: 4.5717, Val Loss: 6.3559, F1 Micro: 0.2188, F1 Macro: 0.1760, Accuracy: 0.2188\n","Epoch 15, Train Loss: 6.5863, Val Loss: 4.3021, F1 Micro: 0.2604, F1 Macro: 0.2334, Accuracy: 0.2604\n","Epoch 16, Train Loss: 5.8524, Val Loss: 7.5398, F1 Micro: 0.2292, F1 Macro: 0.1473, Accuracy: 0.2292\n","Epoch 17, Train Loss: 5.3150, Val Loss: 3.5034, F1 Micro: 0.2292, F1 Macro: 0.1687, Accuracy: 0.2292\n","Epoch 18, Train Loss: 4.8966, Val Loss: 4.2607, F1 Micro: 0.2708, F1 Macro: 0.2389, Accuracy: 0.2708\n","Epoch 19, Train Loss: 4.3872, Val Loss: 4.6584, F1 Micro: 0.2812, F1 Macro: 0.1998, Accuracy: 0.2812\n","Epoch 20, Train Loss: 3.3461, Val Loss: 2.1763, F1 Micro: 0.3021, F1 Macro: 0.2569, Accuracy: 0.3021\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.3458333333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 562.6174, Val Loss: 181.0113, F1 Micro: 0.2292, F1 Macro: 0.0951, Accuracy: 0.2292\n","Epoch 2, Train Loss: 91.8804, Val Loss: 34.1902, F1 Micro: 0.2500, F1 Macro: 0.1962, Accuracy: 0.2500\n","Epoch 3, Train Loss: 23.9820, Val Loss: 23.3745, F1 Micro: 0.2396, F1 Macro: 0.1902, Accuracy: 0.2396\n","Epoch 4, Train Loss: 18.4815, Val Loss: 15.8581, F1 Micro: 0.2500, F1 Macro: 0.1946, Accuracy: 0.2500\n","Epoch 5, Train Loss: 12.9709, Val Loss: 13.0908, F1 Micro: 0.1771, F1 Macro: 0.1583, Accuracy: 0.1771\n","Epoch 6, Train Loss: 8.1805, Val Loss: 12.3588, F1 Micro: 0.2812, F1 Macro: 0.2373, Accuracy: 0.2812\n","Epoch 7, Train Loss: 8.4666, Val Loss: 16.1552, F1 Micro: 0.1562, F1 Macro: 0.1054, Accuracy: 0.1562\n","Epoch 8, Train Loss: 8.6602, Val Loss: 11.4161, F1 Micro: 0.2708, F1 Macro: 0.2114, Accuracy: 0.2708\n","Epoch 9, Train Loss: 8.3872, Val Loss: 9.0415, F1 Micro: 0.2292, F1 Macro: 0.1534, Accuracy: 0.2292\n","Epoch 10, Train Loss: 6.0740, Val Loss: 7.1901, F1 Micro: 0.2292, F1 Macro: 0.1848, Accuracy: 0.2292\n","Epoch 11, Train Loss: 5.8026, Val Loss: 5.2826, F1 Micro: 0.2083, F1 Macro: 0.1627, Accuracy: 0.2083\n","Epoch 12, Train Loss: 5.5092, Val Loss: 6.7714, F1 Micro: 0.1875, F1 Macro: 0.1584, Accuracy: 0.1875\n","Epoch 13, Train Loss: 5.7331, Val Loss: 5.8464, F1 Micro: 0.3229, F1 Macro: 0.2718, Accuracy: 0.3229\n","Epoch 14, Train Loss: 4.6082, Val Loss: 3.9435, F1 Micro: 0.2188, F1 Macro: 0.2127, Accuracy: 0.2188\n","Epoch 15, Train Loss: 4.3794, Val Loss: 4.7632, F1 Micro: 0.2604, F1 Macro: 0.2397, Accuracy: 0.2604\n","Epoch 16, Train Loss: 4.1325, Val Loss: 6.8209, F1 Micro: 0.2708, F1 Macro: 0.2116, Accuracy: 0.2708\n","Epoch 17, Train Loss: 5.5045, Val Loss: 5.7439, F1 Micro: 0.1667, F1 Macro: 0.1181, Accuracy: 0.1667\n","Epoch 18, Train Loss: 5.4911, Val Loss: 3.8834, F1 Micro: 0.3125, F1 Macro: 0.2738, Accuracy: 0.3125\n","Epoch 19, Train Loss: 5.7894, Val Loss: 7.6387, F1 Micro: 0.2812, F1 Macro: 0.2257, Accuracy: 0.2812\n","Epoch 20, Train Loss: 5.7049, Val Loss: 6.2676, F1 Micro: 0.2396, F1 Macro: 0.1613, Accuracy: 0.2396\n","Epoch 21, Train Loss: 5.9809, Val Loss: 4.3691, F1 Micro: 0.2708, F1 Macro: 0.2236, Accuracy: 0.2708\n","Epoch 22, Train Loss: 5.2063, Val Loss: 3.8850, F1 Micro: 0.2500, F1 Macro: 0.2126, Accuracy: 0.2500\n","Epoch 23, Train Loss: 5.8553, Val Loss: 5.8458, F1 Micro: 0.3021, F1 Macro: 0.2442, Accuracy: 0.3021\n","Epoch 24, Train Loss: 5.4308, Val Loss: 6.3401, F1 Micro: 0.2812, F1 Macro: 0.1947, Accuracy: 0.2812\n","Epoch 25, Train Loss: 4.2610, Val Loss: 3.7495, F1 Micro: 0.3542, F1 Macro: 0.3417, Accuracy: 0.3542\n","Epoch 26, Train Loss: 3.2211, Val Loss: 4.2940, F1 Micro: 0.2292, F1 Macro: 0.2185, Accuracy: 0.2292\n","Epoch 27, Train Loss: 2.9625, Val Loss: 3.3151, F1 Micro: 0.2708, F1 Macro: 0.2669, Accuracy: 0.2708\n","Epoch 28, Train Loss: 2.8944, Val Loss: 3.3037, F1 Micro: 0.2812, F1 Macro: 0.2734, Accuracy: 0.2812\n","Epoch 29, Train Loss: 4.0159, Val Loss: 4.0940, F1 Micro: 0.2188, F1 Macro: 0.1631, Accuracy: 0.2188\n","Epoch 30, Train Loss: 3.1852, Val Loss: 3.2761, F1 Micro: 0.2396, F1 Macro: 0.2156, Accuracy: 0.2396\n","Epoch 31, Train Loss: 2.8657, Val Loss: 3.7643, F1 Micro: 0.2604, F1 Macro: 0.2400, Accuracy: 0.2604\n","Epoch 32, Train Loss: 2.6281, Val Loss: 2.3144, F1 Micro: 0.3229, F1 Macro: 0.2900, Accuracy: 0.3229\n","Epoch 33, Train Loss: 2.7785, Val Loss: 3.7360, F1 Micro: 0.2500, F1 Macro: 0.2134, Accuracy: 0.2500\n","Epoch 34, Train Loss: 3.5841, Val Loss: 6.2760, F1 Micro: 0.2188, F1 Macro: 0.1253, Accuracy: 0.2188\n","Epoch 35, Train Loss: 3.6477, Val Loss: 2.9866, F1 Micro: 0.2604, F1 Macro: 0.2243, Accuracy: 0.2604\n","Epoch 36, Train Loss: 2.6943, Val Loss: 3.5998, F1 Micro: 0.2083, F1 Macro: 0.2081, Accuracy: 0.2083\n","Epoch 37, Train Loss: 3.2215, Val Loss: 3.4044, F1 Micro: 0.1771, F1 Macro: 0.1602, Accuracy: 0.1771\n","Epoch 38, Train Loss: 2.4917, Val Loss: 2.3133, F1 Micro: 0.3750, F1 Macro: 0.3514, Accuracy: 0.3750\n","Epoch 39, Train Loss: 2.7011, Val Loss: 3.1391, F1 Micro: 0.2604, F1 Macro: 0.2128, Accuracy: 0.2604\n","Epoch 40, Train Loss: 3.4455, Val Loss: 4.5721, F1 Micro: 0.1875, F1 Macro: 0.1211, Accuracy: 0.1875\n","Epoch 41, Train Loss: 3.0444, Val Loss: 3.5458, F1 Micro: 0.1979, F1 Macro: 0.1391, Accuracy: 0.1979\n","Epoch 42, Train Loss: 4.4861, Val Loss: 3.3064, F1 Micro: 0.2917, F1 Macro: 0.2064, Accuracy: 0.2917\n","Epoch 43, Train Loss: 2.9877, Val Loss: 3.4382, F1 Micro: 0.2396, F1 Macro: 0.1988, Accuracy: 0.2396\n","Epoch 44, Train Loss: 3.6514, Val Loss: 5.7837, F1 Micro: 0.2396, F1 Macro: 0.1878, Accuracy: 0.2396\n","Epoch 45, Train Loss: 3.3429, Val Loss: 2.1613, F1 Micro: 0.3333, F1 Macro: 0.3298, Accuracy: 0.3333\n","Epoch 46, Train Loss: 3.1260, Val Loss: 3.9660, F1 Micro: 0.3750, F1 Macro: 0.3119, Accuracy: 0.3750\n","Epoch 47, Train Loss: 4.5672, Val Loss: 4.1350, F1 Micro: 0.2500, F1 Macro: 0.2331, Accuracy: 0.2500\n","Epoch 48, Train Loss: 3.7626, Val Loss: 4.4666, F1 Micro: 0.3021, F1 Macro: 0.2016, Accuracy: 0.3021\n","Epoch 49, Train Loss: 4.0935, Val Loss: 3.7752, F1 Micro: 0.3021, F1 Macro: 0.2107, Accuracy: 0.3021\n","Epoch 50, Train Loss: 3.6364, Val Loss: 2.7020, F1 Micro: 0.2292, F1 Macro: 0.2207, Accuracy: 0.2292\n","Epoch 51, Train Loss: 14.7923, Val Loss: 35.2996, F1 Micro: 0.1354, F1 Macro: 0.0570, Accuracy: 0.1354\n","Epoch 52, Train Loss: 42.1195, Val Loss: 77.0402, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 53, Train Loss: 52.6064, Val Loss: 57.0688, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 54, Train Loss: 66.1397, Val Loss: 147.5534, F1 Micro: 0.1562, F1 Macro: 0.0612, Accuracy: 0.1562\n","Epoch 55, Train Loss: 166.4497, Val Loss: 362.7943, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 56, Train Loss: 377.2181, Val Loss: 335.1857, F1 Micro: 0.2083, F1 Macro: 0.0580, Accuracy: 0.2083\n","Epoch 57, Train Loss: 394.5116, Val Loss: 505.4464, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 58, Train Loss: 258.9956, Val Loss: 198.3738, F1 Micro: 0.1250, F1 Macro: 0.0629, Accuracy: 0.1250\n","Epoch 59, Train Loss: 148.4584, Val Loss: 82.6280, F1 Micro: 0.1979, F1 Macro: 0.0949, Accuracy: 0.1979\n","Epoch 60, Train Loss: 91.2973, Val Loss: 33.0483, F1 Micro: 0.2708, F1 Macro: 0.2180, Accuracy: 0.2708\n","Epoch 61, Train Loss: 34.2114, Val Loss: 31.9324, F1 Micro: 0.1562, F1 Macro: 0.0589, Accuracy: 0.1562\n","Epoch 62, Train Loss: 19.6823, Val Loss: 23.9963, F1 Micro: 0.2292, F1 Macro: 0.1118, Accuracy: 0.2292\n","Epoch 63, Train Loss: 14.0214, Val Loss: 13.6892, F1 Micro: 0.2396, F1 Macro: 0.1627, Accuracy: 0.2396\n","Epoch 64, Train Loss: 6.0721, Val Loss: 3.6716, F1 Micro: 0.2500, F1 Macro: 0.2526, Accuracy: 0.2500\n","Epoch 65, Train Loss: 2.4722, Val Loss: 3.1210, F1 Micro: 0.1979, F1 Macro: 0.1480, Accuracy: 0.1979\n","Epoch 66, Train Loss: 2.7084, Val Loss: 2.9443, F1 Micro: 0.2083, F1 Macro: 0.1709, Accuracy: 0.2083\n","Epoch 67, Train Loss: 2.2988, Val Loss: 2.1791, F1 Micro: 0.3333, F1 Macro: 0.2949, Accuracy: 0.3333\n","Epoch 68, Train Loss: 2.1576, Val Loss: 2.4718, F1 Micro: 0.1771, F1 Macro: 0.1573, Accuracy: 0.1771\n","Epoch 69, Train Loss: 1.9934, Val Loss: 2.0419, F1 Micro: 0.2708, F1 Macro: 0.2685, Accuracy: 0.2708\n","Epoch 70, Train Loss: 2.2170, Val Loss: 2.7859, F1 Micro: 0.2500, F1 Macro: 0.2027, Accuracy: 0.2500\n","Epoch 71, Train Loss: 2.2655, Val Loss: 2.2840, F1 Micro: 0.3229, F1 Macro: 0.2718, Accuracy: 0.3229\n","Epoch 72, Train Loss: 2.3903, Val Loss: 2.1309, F1 Micro: 0.3438, F1 Macro: 0.2946, Accuracy: 0.3438\n","Epoch 73, Train Loss: 2.2989, Val Loss: 2.3036, F1 Micro: 0.2708, F1 Macro: 0.2326, Accuracy: 0.2708\n","Epoch 74, Train Loss: 2.1710, Val Loss: 2.2604, F1 Micro: 0.2083, F1 Macro: 0.1899, Accuracy: 0.2083\n","Epoch 75, Train Loss: 2.0449, Val Loss: 2.2690, F1 Micro: 0.2917, F1 Macro: 0.2661, Accuracy: 0.2917\n","Epoch 76, Train Loss: 2.2949, Val Loss: 2.9758, F1 Micro: 0.2188, F1 Macro: 0.1904, Accuracy: 0.2188\n","Epoch 77, Train Loss: 2.0238, Val Loss: 2.4920, F1 Micro: 0.2083, F1 Macro: 0.1905, Accuracy: 0.2083\n","Epoch 78, Train Loss: 1.8167, Val Loss: 1.9747, F1 Micro: 0.3333, F1 Macro: 0.2636, Accuracy: 0.3333\n","Epoch 79, Train Loss: 2.0072, Val Loss: 2.1860, F1 Micro: 0.2708, F1 Macro: 0.2417, Accuracy: 0.2708\n","Epoch 80, Train Loss: 1.9013, Val Loss: 2.0764, F1 Micro: 0.3125, F1 Macro: 0.3016, Accuracy: 0.3125\n","Epoch 81, Train Loss: 1.9304, Val Loss: 2.3096, F1 Micro: 0.3021, F1 Macro: 0.2858, Accuracy: 0.3021\n","Epoch 82, Train Loss: 1.8329, Val Loss: 2.6567, F1 Micro: 0.2396, F1 Macro: 0.2086, Accuracy: 0.2396\n","Epoch 83, Train Loss: 1.9753, Val Loss: 2.3655, F1 Micro: 0.3438, F1 Macro: 0.3127, Accuracy: 0.3438\n","Epoch 84, Train Loss: 2.1185, Val Loss: 1.8773, F1 Micro: 0.3229, F1 Macro: 0.3147, Accuracy: 0.3229\n","Epoch 85, Train Loss: 1.8361, Val Loss: 1.8213, F1 Micro: 0.3542, F1 Macro: 0.3347, Accuracy: 0.3542\n","Epoch 86, Train Loss: 1.7817, Val Loss: 2.0641, F1 Micro: 0.2812, F1 Macro: 0.2691, Accuracy: 0.2812\n","Epoch 87, Train Loss: 2.0463, Val Loss: 2.6278, F1 Micro: 0.2812, F1 Macro: 0.2649, Accuracy: 0.2812\n","Epoch 88, Train Loss: 2.3148, Val Loss: 2.7432, F1 Micro: 0.2917, F1 Macro: 0.2879, Accuracy: 0.2917\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 547.5396, Val Loss: 167.3653, F1 Micro: 0.2500, F1 Macro: 0.1560, Accuracy: 0.2500\n","Epoch 2, Train Loss: 94.8416, Val Loss: 48.7308, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 3, Train Loss: 33.8153, Val Loss: 34.0976, F1 Micro: 0.2188, F1 Macro: 0.1183, Accuracy: 0.2188\n","Epoch 4, Train Loss: 18.5415, Val Loss: 17.3184, F1 Micro: 0.2292, F1 Macro: 0.1251, Accuracy: 0.2292\n","Epoch 5, Train Loss: 12.8843, Val Loss: 12.4934, F1 Micro: 0.3333, F1 Macro: 0.2482, Accuracy: 0.3333\n","Epoch 6, Train Loss: 10.8981, Val Loss: 14.3277, F1 Micro: 0.1042, F1 Macro: 0.0799, Accuracy: 0.1042\n","Epoch 7, Train Loss: 8.6146, Val Loss: 6.1321, F1 Micro: 0.2500, F1 Macro: 0.2317, Accuracy: 0.2500\n","Epoch 8, Train Loss: 7.6212, Val Loss: 10.1177, F1 Micro: 0.2396, F1 Macro: 0.1422, Accuracy: 0.2396\n","Epoch 9, Train Loss: 11.4824, Val Loss: 7.1855, F1 Micro: 0.2292, F1 Macro: 0.1536, Accuracy: 0.2292\n","Epoch 10, Train Loss: 5.2019, Val Loss: 5.5978, F1 Micro: 0.3125, F1 Macro: 0.2292, Accuracy: 0.3125\n","Epoch 11, Train Loss: 6.3423, Val Loss: 8.7222, F1 Micro: 0.2083, F1 Macro: 0.1906, Accuracy: 0.2083\n","Epoch 12, Train Loss: 5.9561, Val Loss: 6.6253, F1 Micro: 0.2917, F1 Macro: 0.1813, Accuracy: 0.2917\n","Epoch 13, Train Loss: 7.1278, Val Loss: 8.0321, F1 Micro: 0.2708, F1 Macro: 0.2661, Accuracy: 0.2708\n","Epoch 14, Train Loss: 4.8634, Val Loss: 6.7873, F1 Micro: 0.2708, F1 Macro: 0.2256, Accuracy: 0.2708\n","Epoch 15, Train Loss: 4.4591, Val Loss: 4.7073, F1 Micro: 0.3229, F1 Macro: 0.2480, Accuracy: 0.3229\n","Epoch 16, Train Loss: 5.6021, Val Loss: 6.9925, F1 Micro: 0.3125, F1 Macro: 0.2574, Accuracy: 0.3125\n","Epoch 17, Train Loss: 5.9312, Val Loss: 8.5669, F1 Micro: 0.2500, F1 Macro: 0.2097, Accuracy: 0.2500\n","Epoch 18, Train Loss: 3.8102, Val Loss: 3.9877, F1 Micro: 0.3333, F1 Macro: 0.2954, Accuracy: 0.3333\n","Epoch 19, Train Loss: 3.1972, Val Loss: 5.2205, F1 Micro: 0.2812, F1 Macro: 0.2274, Accuracy: 0.2812\n","Epoch 20, Train Loss: 3.7542, Val Loss: 3.1497, F1 Micro: 0.3125, F1 Macro: 0.2260, Accuracy: 0.3125\n","Epoch 21, Train Loss: 3.3157, Val Loss: 3.9319, F1 Micro: 0.2812, F1 Macro: 0.2223, Accuracy: 0.2812\n","Epoch 22, Train Loss: 3.0555, Val Loss: 3.1401, F1 Micro: 0.3021, F1 Macro: 0.1962, Accuracy: 0.3021\n","Epoch 23, Train Loss: 4.5044, Val Loss: 7.6285, F1 Micro: 0.2708, F1 Macro: 0.2652, Accuracy: 0.2708\n","Epoch 24, Train Loss: 4.1979, Val Loss: 3.3075, F1 Micro: 0.2292, F1 Macro: 0.2104, Accuracy: 0.2292\n","Epoch 25, Train Loss: 3.0752, Val Loss: 5.5045, F1 Micro: 0.2708, F1 Macro: 0.1942, Accuracy: 0.2708\n","Epoch 26, Train Loss: 3.7551, Val Loss: 5.9347, F1 Micro: 0.1979, F1 Macro: 0.1878, Accuracy: 0.1979\n","Epoch 27, Train Loss: 3.4246, Val Loss: 4.1710, F1 Micro: 0.2396, F1 Macro: 0.1971, Accuracy: 0.2396\n","Epoch 28, Train Loss: 2.8220, Val Loss: 3.0095, F1 Micro: 0.2708, F1 Macro: 0.2121, Accuracy: 0.2708\n","Epoch 29, Train Loss: 2.7702, Val Loss: 3.8155, F1 Micro: 0.3021, F1 Macro: 0.2206, Accuracy: 0.3021\n","Epoch 30, Train Loss: 3.2711, Val Loss: 5.4008, F1 Micro: 0.2500, F1 Macro: 0.2191, Accuracy: 0.2500\n","Epoch 31, Train Loss: 3.2016, Val Loss: 5.5653, F1 Micro: 0.3229, F1 Macro: 0.2556, Accuracy: 0.3229\n","Epoch 32, Train Loss: 2.9818, Val Loss: 4.2661, F1 Micro: 0.2917, F1 Macro: 0.2377, Accuracy: 0.2917\n","Epoch 33, Train Loss: 3.0862, Val Loss: 3.5868, F1 Micro: 0.3229, F1 Macro: 0.3085, Accuracy: 0.3229\n","Epoch 34, Train Loss: 2.7177, Val Loss: 3.1561, F1 Micro: 0.2812, F1 Macro: 0.2601, Accuracy: 0.2812\n","Epoch 35, Train Loss: 2.1253, Val Loss: 3.0821, F1 Micro: 0.4062, F1 Macro: 0.3877, Accuracy: 0.4062\n","Epoch 36, Train Loss: 2.2873, Val Loss: 2.2809, F1 Micro: 0.2292, F1 Macro: 0.1968, Accuracy: 0.2292\n","Epoch 37, Train Loss: 2.2184, Val Loss: 2.6303, F1 Micro: 0.3125, F1 Macro: 0.2480, Accuracy: 0.3125\n","Epoch 38, Train Loss: 2.6208, Val Loss: 4.3686, F1 Micro: 0.2812, F1 Macro: 0.2052, Accuracy: 0.2812\n","Epoch 39, Train Loss: 2.9398, Val Loss: 4.7181, F1 Micro: 0.2708, F1 Macro: 0.2541, Accuracy: 0.2708\n","Epoch 40, Train Loss: 2.4248, Val Loss: 4.6108, F1 Micro: 0.2188, F1 Macro: 0.2251, Accuracy: 0.2188\n","Epoch 41, Train Loss: 2.8344, Val Loss: 3.9852, F1 Micro: 0.2292, F1 Macro: 0.1904, Accuracy: 0.2292\n","Epoch 42, Train Loss: 3.2362, Val Loss: 4.1196, F1 Micro: 0.1771, F1 Macro: 0.1136, Accuracy: 0.1771\n","Epoch 43, Train Loss: 3.2877, Val Loss: 4.0531, F1 Micro: 0.3333, F1 Macro: 0.3022, Accuracy: 0.3333\n","Epoch 44, Train Loss: 2.6432, Val Loss: 2.6967, F1 Micro: 0.3438, F1 Macro: 0.3065, Accuracy: 0.3438\n","Epoch 45, Train Loss: 2.2722, Val Loss: 2.2251, F1 Micro: 0.3333, F1 Macro: 0.3117, Accuracy: 0.3333\n","Epoch 46, Train Loss: 2.0476, Val Loss: 2.9163, F1 Micro: 0.2396, F1 Macro: 0.1811, Accuracy: 0.2396\n","Epoch 47, Train Loss: 2.3732, Val Loss: 3.3661, F1 Micro: 0.4271, F1 Macro: 0.3939, Accuracy: 0.4271\n","Epoch 48, Train Loss: 2.2392, Val Loss: 2.7793, F1 Micro: 0.3333, F1 Macro: 0.3012, Accuracy: 0.3333\n","Epoch 49, Train Loss: 2.4697, Val Loss: 3.3410, F1 Micro: 0.2083, F1 Macro: 0.2295, Accuracy: 0.2083\n","Epoch 50, Train Loss: 2.0589, Val Loss: 2.7181, F1 Micro: 0.3333, F1 Macro: 0.2480, Accuracy: 0.3333\n","Epoch 51, Train Loss: 2.0533, Val Loss: 2.8922, F1 Micro: 0.2083, F1 Macro: 0.2077, Accuracy: 0.2083\n","Epoch 52, Train Loss: 1.9690, Val Loss: 2.5028, F1 Micro: 0.2812, F1 Macro: 0.2027, Accuracy: 0.2812\n","Epoch 53, Train Loss: 2.1748, Val Loss: 3.0485, F1 Micro: 0.3438, F1 Macro: 0.2338, Accuracy: 0.3438\n","Epoch 54, Train Loss: 2.2632, Val Loss: 3.9801, F1 Micro: 0.3125, F1 Macro: 0.2530, Accuracy: 0.3125\n","Epoch 55, Train Loss: 2.8516, Val Loss: 4.1782, F1 Micro: 0.3125, F1 Macro: 0.2254, Accuracy: 0.3125\n","Epoch 56, Train Loss: 3.1351, Val Loss: 6.4763, F1 Micro: 0.2292, F1 Macro: 0.1124, Accuracy: 0.2292\n","Epoch 57, Train Loss: 3.2820, Val Loss: 3.3825, F1 Micro: 0.2708, F1 Macro: 0.2186, Accuracy: 0.2708\n","Epoch 58, Train Loss: 2.7466, Val Loss: 3.6245, F1 Micro: 0.1979, F1 Macro: 0.1385, Accuracy: 0.1979\n","Epoch 59, Train Loss: 2.7397, Val Loss: 3.3245, F1 Micro: 0.2500, F1 Macro: 0.1871, Accuracy: 0.2500\n","Epoch 60, Train Loss: 5.8396, Val Loss: 14.8286, F1 Micro: 0.2604, F1 Macro: 0.1715, Accuracy: 0.2604\n","Epoch 61, Train Loss: 41.3754, Val Loss: 28.1588, F1 Micro: 0.1146, F1 Macro: 0.0492, Accuracy: 0.1146\n","Epoch 62, Train Loss: 63.4897, Val Loss: 174.5223, F1 Micro: 0.2292, F1 Macro: 0.1242, Accuracy: 0.2292\n","Epoch 63, Train Loss: 148.7354, Val Loss: 307.5126, F1 Micro: 0.1354, F1 Macro: 0.0398, Accuracy: 0.1354\n","Epoch 64, Train Loss: 204.1776, Val Loss: 110.5548, F1 Micro: 0.2292, F1 Macro: 0.1628, Accuracy: 0.2292\n","Epoch 65, Train Loss: 87.2428, Val Loss: 79.4373, F1 Micro: 0.0729, F1 Macro: 0.0238, Accuracy: 0.0729\n","Epoch 66, Train Loss: 53.7500, Val Loss: 18.7444, F1 Micro: 0.1667, F1 Macro: 0.0964, Accuracy: 0.1667\n","Epoch 67, Train Loss: 25.4749, Val Loss: 27.6122, F1 Micro: 0.1146, F1 Macro: 0.0732, Accuracy: 0.1146\n","Epoch 68, Train Loss: 18.5530, Val Loss: 7.4110, F1 Micro: 0.3438, F1 Macro: 0.2484, Accuracy: 0.3438\n","Epoch 69, Train Loss: 8.8420, Val Loss: 8.7357, F1 Micro: 0.2188, F1 Macro: 0.1949, Accuracy: 0.2188\n","Epoch 70, Train Loss: 5.9036, Val Loss: 4.0101, F1 Micro: 0.3021, F1 Macro: 0.2467, Accuracy: 0.3021\n","Epoch 71, Train Loss: 3.2651, Val Loss: 2.9541, F1 Micro: 0.3542, F1 Macro: 0.2749, Accuracy: 0.3542\n","Epoch 72, Train Loss: 2.5184, Val Loss: 2.7024, F1 Micro: 0.2500, F1 Macro: 0.1945, Accuracy: 0.2500\n","Epoch 73, Train Loss: 2.4312, Val Loss: 2.5848, F1 Micro: 0.2292, F1 Macro: 0.2044, Accuracy: 0.2292\n","Epoch 74, Train Loss: 2.3793, Val Loss: 2.8353, F1 Micro: 0.1979, F1 Macro: 0.1555, Accuracy: 0.1979\n","Epoch 75, Train Loss: 2.4276, Val Loss: 2.6867, F1 Micro: 0.3646, F1 Macro: 0.2987, Accuracy: 0.3646\n","Epoch 76, Train Loss: 2.0101, Val Loss: 2.1817, F1 Micro: 0.3750, F1 Macro: 0.3230, Accuracy: 0.3750\n","Epoch 77, Train Loss: 2.0802, Val Loss: 2.7691, F1 Micro: 0.3646, F1 Macro: 0.3119, Accuracy: 0.3646\n","Epoch 78, Train Loss: 2.0636, Val Loss: 3.5767, F1 Micro: 0.2188, F1 Macro: 0.1987, Accuracy: 0.2188\n","Epoch 79, Train Loss: 2.1251, Val Loss: 2.7375, F1 Micro: 0.2188, F1 Macro: 0.2157, Accuracy: 0.2188\n","Epoch 80, Train Loss: 2.0838, Val Loss: 2.2125, F1 Micro: 0.3229, F1 Macro: 0.3131, Accuracy: 0.3229\n","Epoch 81, Train Loss: 2.0841, Val Loss: 2.8859, F1 Micro: 0.4479, F1 Macro: 0.4067, Accuracy: 0.4479\n","Epoch 82, Train Loss: 2.1052, Val Loss: 1.9198, F1 Micro: 0.2708, F1 Macro: 0.2249, Accuracy: 0.2708\n","Epoch 83, Train Loss: 1.8444, Val Loss: 2.6355, F1 Micro: 0.2917, F1 Macro: 0.2369, Accuracy: 0.2917\n","Epoch 84, Train Loss: 1.9152, Val Loss: 1.7526, F1 Micro: 0.3125, F1 Macro: 0.2307, Accuracy: 0.3125\n","Epoch 85, Train Loss: 1.9252, Val Loss: 2.6666, F1 Micro: 0.2812, F1 Macro: 0.2454, Accuracy: 0.2812\n","Epoch 86, Train Loss: 1.9368, Val Loss: 2.4988, F1 Micro: 0.3125, F1 Macro: 0.2398, Accuracy: 0.3125\n","Epoch 87, Train Loss: 1.7509, Val Loss: 1.8871, F1 Micro: 0.3750, F1 Macro: 0.3330, Accuracy: 0.3750\n","Epoch 88, Train Loss: 1.8322, Val Loss: 2.2553, F1 Micro: 0.3438, F1 Macro: 0.3366, Accuracy: 0.3438\n","Epoch 89, Train Loss: 1.8056, Val Loss: 2.7405, F1 Micro: 0.3854, F1 Macro: 0.3399, Accuracy: 0.3854\n","Epoch 90, Train Loss: 1.7754, Val Loss: 2.3403, F1 Micro: 0.3542, F1 Macro: 0.3524, Accuracy: 0.3542\n","Epoch 91, Train Loss: 1.9372, Val Loss: 2.7777, F1 Micro: 0.2917, F1 Macro: 0.2044, Accuracy: 0.2917\n","Epoch 92, Train Loss: 2.1359, Val Loss: 3.1497, F1 Micro: 0.3438, F1 Macro: 0.2843, Accuracy: 0.3438\n","Epoch 93, Train Loss: 2.0253, Val Loss: 2.3662, F1 Micro: 0.3438, F1 Macro: 0.2902, Accuracy: 0.3438\n","Epoch 94, Train Loss: 1.8680, Val Loss: 2.0422, F1 Micro: 0.3542, F1 Macro: 0.3166, Accuracy: 0.3542\n","Epoch 95, Train Loss: 2.0900, Val Loss: 2.2502, F1 Micro: 0.2917, F1 Macro: 0.2884, Accuracy: 0.2917\n","Epoch 96, Train Loss: 1.9986, Val Loss: 2.7139, F1 Micro: 0.2604, F1 Macro: 0.2177, Accuracy: 0.2604\n","Epoch 97, Train Loss: 2.0471, Val Loss: 2.4231, F1 Micro: 0.3125, F1 Macro: 0.2666, Accuracy: 0.3125\n","Epoch 98, Train Loss: 2.2453, Val Loss: 2.2167, F1 Micro: 0.2917, F1 Macro: 0.2632, Accuracy: 0.2917\n","Epoch 99, Train Loss: 2.2700, Val Loss: 2.9094, F1 Micro: 0.1875, F1 Macro: 0.1369, Accuracy: 0.1875\n","Epoch 100, Train Loss: 2.0178, Val Loss: 2.7573, F1 Micro: 0.1667, F1 Macro: 0.1493, Accuracy: 0.1667\n","Epoch 101, Train Loss: 2.2303, Val Loss: 2.2507, F1 Micro: 0.3333, F1 Macro: 0.2745, Accuracy: 0.3333\n","Epoch 102, Train Loss: 2.0589, Val Loss: 1.9760, F1 Micro: 0.3750, F1 Macro: 0.3328, Accuracy: 0.3750\n","Epoch 103, Train Loss: 2.0418, Val Loss: 2.3877, F1 Micro: 0.3542, F1 Macro: 0.3418, Accuracy: 0.3542\n","Epoch 104, Train Loss: 1.8086, Val Loss: 2.5282, F1 Micro: 0.3646, F1 Macro: 0.2692, Accuracy: 0.3646\n","Epoch 105, Train Loss: 1.9416, Val Loss: 1.9371, F1 Micro: 0.3646, F1 Macro: 0.3361, Accuracy: 0.3646\n","Epoch 106, Train Loss: 1.8245, Val Loss: 2.5324, F1 Micro: 0.3958, F1 Macro: 0.3039, Accuracy: 0.3958\n","Epoch 107, Train Loss: 2.2340, Val Loss: 2.5656, F1 Micro: 0.3438, F1 Macro: 0.2816, Accuracy: 0.3438\n","Epoch 108, Train Loss: 2.4380, Val Loss: 2.7330, F1 Micro: 0.3021, F1 Macro: 0.2106, Accuracy: 0.3021\n","Epoch 109, Train Loss: 2.1020, Val Loss: 3.2234, F1 Micro: 0.2917, F1 Macro: 0.2292, Accuracy: 0.2917\n","Epoch 110, Train Loss: 2.2727, Val Loss: 2.1499, F1 Micro: 0.4062, F1 Macro: 0.3100, Accuracy: 0.4062\n","Epoch 111, Train Loss: 2.5908, Val Loss: 2.9429, F1 Micro: 0.2500, F1 Macro: 0.2034, Accuracy: 0.2500\n","Epoch 112, Train Loss: 2.8885, Val Loss: 2.5844, F1 Micro: 0.3229, F1 Macro: 0.2985, Accuracy: 0.3229\n","Epoch 113, Train Loss: 2.3347, Val Loss: 2.4119, F1 Micro: 0.2396, F1 Macro: 0.2244, Accuracy: 0.2396\n","Epoch 114, Train Loss: 2.0803, Val Loss: 2.7426, F1 Micro: 0.2396, F1 Macro: 0.2398, Accuracy: 0.2396\n","Epoch 115, Train Loss: 2.3195, Val Loss: 3.4472, F1 Micro: 0.2292, F1 Macro: 0.1737, Accuracy: 0.2292\n","Epoch 116, Train Loss: 2.3196, Val Loss: 3.0399, F1 Micro: 0.2083, F1 Macro: 0.1731, Accuracy: 0.2083\n","Epoch 117, Train Loss: 2.2544, Val Loss: 3.3285, F1 Micro: 0.1354, F1 Macro: 0.0843, Accuracy: 0.1354\n","Epoch 118, Train Loss: 2.5271, Val Loss: 5.0186, F1 Micro: 0.1771, F1 Macro: 0.1194, Accuracy: 0.1771\n","Epoch 119, Train Loss: 3.9929, Val Loss: 5.0001, F1 Micro: 0.1771, F1 Macro: 0.1315, Accuracy: 0.1771\n","Epoch 120, Train Loss: 4.6983, Val Loss: 2.9533, F1 Micro: 0.2917, F1 Macro: 0.2569, Accuracy: 0.2917\n","Epoch 121, Train Loss: 4.0261, Val Loss: 4.4954, F1 Micro: 0.1458, F1 Macro: 0.0883, Accuracy: 0.1458\n","Epoch 122, Train Loss: 3.8022, Val Loss: 4.5484, F1 Micro: 0.0938, F1 Macro: 0.0528, Accuracy: 0.0938\n","Epoch 123, Train Loss: 5.6643, Val Loss: 14.6034, F1 Micro: 0.2188, F1 Macro: 0.1222, Accuracy: 0.2188\n","Epoch 124, Train Loss: 12.5893, Val Loss: 21.2249, F1 Micro: 0.2396, F1 Macro: 0.1273, Accuracy: 0.2396\n","Epoch 125, Train Loss: 18.9351, Val Loss: 8.1497, F1 Micro: 0.2396, F1 Macro: 0.2025, Accuracy: 0.2396\n","Epoch 126, Train Loss: 15.5695, Val Loss: 44.5460, F1 Micro: 0.2188, F1 Macro: 0.1217, Accuracy: 0.2188\n","Epoch 127, Train Loss: 80.0085, Val Loss: 187.3342, F1 Micro: 0.1562, F1 Macro: 0.0885, Accuracy: 0.1562\n","Epoch 128, Train Loss: 170.4681, Val Loss: 54.1820, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 129, Train Loss: 212.6586, Val Loss: 60.7098, F1 Micro: 0.2292, F1 Macro: 0.1085, Accuracy: 0.2292\n","Epoch 130, Train Loss: 207.2862, Val Loss: 138.7162, F1 Micro: 0.2188, F1 Macro: 0.1217, Accuracy: 0.2188\n","Epoch 131, Train Loss: 94.2641, Val Loss: 20.5658, F1 Micro: 0.2708, F1 Macro: 0.1626, Accuracy: 0.2708\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 605.9962, Val Loss: 211.1647, F1 Micro: 0.2396, F1 Macro: 0.1080, Accuracy: 0.2396\n","Epoch 2, Train Loss: 83.3891, Val Loss: 18.6438, F1 Micro: 0.2604, F1 Macro: 0.1559, Accuracy: 0.2604\n","Epoch 3, Train Loss: 28.0492, Val Loss: 16.8520, F1 Micro: 0.3333, F1 Macro: 0.1957, Accuracy: 0.3333\n","Epoch 4, Train Loss: 16.1338, Val Loss: 14.4396, F1 Micro: 0.2396, F1 Macro: 0.1977, Accuracy: 0.2396\n","Epoch 5, Train Loss: 12.1703, Val Loss: 6.7391, F1 Micro: 0.3333, F1 Macro: 0.2860, Accuracy: 0.3333\n","Epoch 6, Train Loss: 9.3749, Val Loss: 16.4868, F1 Micro: 0.1667, F1 Macro: 0.1515, Accuracy: 0.1667\n","Epoch 7, Train Loss: 9.7994, Val Loss: 8.4525, F1 Micro: 0.2812, F1 Macro: 0.2000, Accuracy: 0.2812\n","Epoch 8, Train Loss: 9.5420, Val Loss: 9.0177, F1 Micro: 0.2708, F1 Macro: 0.1858, Accuracy: 0.2708\n","Epoch 9, Train Loss: 7.5675, Val Loss: 6.2999, F1 Micro: 0.1667, F1 Macro: 0.1403, Accuracy: 0.1667\n","Epoch 10, Train Loss: 5.7162, Val Loss: 5.8328, F1 Micro: 0.2500, F1 Macro: 0.2269, Accuracy: 0.2500\n","Epoch 11, Train Loss: 5.8041, Val Loss: 5.8630, F1 Micro: 0.2500, F1 Macro: 0.2384, Accuracy: 0.2500\n","Epoch 12, Train Loss: 4.7784, Val Loss: 3.6217, F1 Micro: 0.3438, F1 Macro: 0.2609, Accuracy: 0.3438\n","Epoch 13, Train Loss: 3.5208, Val Loss: 4.0488, F1 Micro: 0.3438, F1 Macro: 0.2745, Accuracy: 0.3438\n","Epoch 14, Train Loss: 5.0445, Val Loss: 3.9439, F1 Micro: 0.3438, F1 Macro: 0.2956, Accuracy: 0.3438\n","Epoch 15, Train Loss: 5.6431, Val Loss: 5.6985, F1 Micro: 0.3021, F1 Macro: 0.2137, Accuracy: 0.3021\n","Epoch 16, Train Loss: 5.0973, Val Loss: 8.5396, F1 Micro: 0.2396, F1 Macro: 0.2205, Accuracy: 0.2396\n","Epoch 17, Train Loss: 6.1526, Val Loss: 5.6974, F1 Micro: 0.2188, F1 Macro: 0.2120, Accuracy: 0.2188\n","Epoch 18, Train Loss: 5.4398, Val Loss: 6.1278, F1 Micro: 0.2708, F1 Macro: 0.2037, Accuracy: 0.2708\n","Epoch 19, Train Loss: 5.4594, Val Loss: 5.0996, F1 Micro: 0.3021, F1 Macro: 0.1940, Accuracy: 0.3021\n","Epoch 20, Train Loss: 5.0553, Val Loss: 6.3918, F1 Micro: 0.1354, F1 Macro: 0.0734, Accuracy: 0.1354\n","Epoch 21, Train Loss: 4.4517, Val Loss: 4.0083, F1 Micro: 0.3229, F1 Macro: 0.2999, Accuracy: 0.3229\n","Epoch 22, Train Loss: 3.7040, Val Loss: 3.4535, F1 Micro: 0.1875, F1 Macro: 0.1567, Accuracy: 0.1875\n","Epoch 23, Train Loss: 3.2744, Val Loss: 3.6639, F1 Micro: 0.2188, F1 Macro: 0.1858, Accuracy: 0.2188\n","Epoch 24, Train Loss: 4.4075, Val Loss: 5.1157, F1 Micro: 0.1979, F1 Macro: 0.1537, Accuracy: 0.1979\n","Epoch 25, Train Loss: 3.5965, Val Loss: 3.7515, F1 Micro: 0.1562, F1 Macro: 0.1462, Accuracy: 0.1562\n","Epoch 26, Train Loss: 4.4000, Val Loss: 3.0501, F1 Micro: 0.2708, F1 Macro: 0.2673, Accuracy: 0.2708\n","Epoch 27, Train Loss: 3.7322, Val Loss: 3.1713, F1 Micro: 0.3333, F1 Macro: 0.2570, Accuracy: 0.3333\n","Epoch 28, Train Loss: 3.1465, Val Loss: 4.4748, F1 Micro: 0.2500, F1 Macro: 0.2153, Accuracy: 0.2500\n","Epoch 29, Train Loss: 3.5822, Val Loss: 3.3879, F1 Micro: 0.2604, F1 Macro: 0.2085, Accuracy: 0.2604\n","Epoch 30, Train Loss: 3.2149, Val Loss: 2.8489, F1 Micro: 0.2917, F1 Macro: 0.2690, Accuracy: 0.2917\n","Epoch 31, Train Loss: 2.6663, Val Loss: 2.9299, F1 Micro: 0.3438, F1 Macro: 0.2823, Accuracy: 0.3438\n","Epoch 32, Train Loss: 2.5154, Val Loss: 2.7376, F1 Micro: 0.3229, F1 Macro: 0.2457, Accuracy: 0.3229\n","Epoch 33, Train Loss: 2.8691, Val Loss: 3.1753, F1 Micro: 0.2083, F1 Macro: 0.1511, Accuracy: 0.2083\n","Epoch 34, Train Loss: 3.0239, Val Loss: 2.6125, F1 Micro: 0.2708, F1 Macro: 0.1908, Accuracy: 0.2708\n","Epoch 35, Train Loss: 3.8876, Val Loss: 3.4658, F1 Micro: 0.2604, F1 Macro: 0.2555, Accuracy: 0.2604\n","Epoch 36, Train Loss: 2.9185, Val Loss: 2.4143, F1 Micro: 0.2917, F1 Macro: 0.1665, Accuracy: 0.2917\n","Epoch 37, Train Loss: 2.9431, Val Loss: 2.7902, F1 Micro: 0.2917, F1 Macro: 0.2516, Accuracy: 0.2917\n","Epoch 38, Train Loss: 2.6592, Val Loss: 3.1416, F1 Micro: 0.3021, F1 Macro: 0.2906, Accuracy: 0.3021\n","Epoch 39, Train Loss: 3.6794, Val Loss: 3.4550, F1 Micro: 0.3438, F1 Macro: 0.2616, Accuracy: 0.3438\n","Epoch 40, Train Loss: 3.8939, Val Loss: 4.5041, F1 Micro: 0.2500, F1 Macro: 0.1861, Accuracy: 0.2500\n","Epoch 41, Train Loss: 5.4546, Val Loss: 7.4832, F1 Micro: 0.1875, F1 Macro: 0.1547, Accuracy: 0.1875\n","Epoch 42, Train Loss: 6.2547, Val Loss: 6.8078, F1 Micro: 0.2917, F1 Macro: 0.2163, Accuracy: 0.2917\n","Epoch 43, Train Loss: 3.4054, Val Loss: 3.3023, F1 Micro: 0.2917, F1 Macro: 0.1680, Accuracy: 0.2917\n","Epoch 44, Train Loss: 3.2176, Val Loss: 3.9073, F1 Micro: 0.2083, F1 Macro: 0.1770, Accuracy: 0.2083\n","Epoch 45, Train Loss: 5.4567, Val Loss: 20.8597, F1 Micro: 0.2292, F1 Macro: 0.0987, Accuracy: 0.2292\n","Epoch 46, Train Loss: 47.8604, Val Loss: 24.2317, F1 Micro: 0.2292, F1 Macro: 0.1072, Accuracy: 0.2292\n","Epoch 47, Train Loss: 109.2550, Val Loss: 265.2876, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 48, Train Loss: 364.4018, Val Loss: 319.1335, F1 Micro: 0.2292, F1 Macro: 0.0903, Accuracy: 0.2292\n","Epoch 49, Train Loss: 330.4796, Val Loss: 344.6677, F1 Micro: 0.1458, F1 Macro: 0.0702, Accuracy: 0.1458\n","Epoch 50, Train Loss: 263.5598, Val Loss: 99.8164, F1 Micro: 0.2292, F1 Macro: 0.1050, Accuracy: 0.2292\n","Epoch 51, Train Loss: 66.1527, Val Loss: 49.5758, F1 Micro: 0.2708, F1 Macro: 0.1468, Accuracy: 0.2708\n","Epoch 52, Train Loss: 46.4018, Val Loss: 16.2773, F1 Micro: 0.1562, F1 Macro: 0.1357, Accuracy: 0.1562\n","Epoch 53, Train Loss: 17.7721, Val Loss: 13.8685, F1 Micro: 0.2396, F1 Macro: 0.1132, Accuracy: 0.2396\n","Epoch 54, Train Loss: 9.5342, Val Loss: 5.6559, F1 Micro: 0.2812, F1 Macro: 0.2075, Accuracy: 0.2812\n","Epoch 55, Train Loss: 3.5136, Val Loss: 4.0628, F1 Micro: 0.1875, F1 Macro: 0.1727, Accuracy: 0.1875\n","Epoch 56, Train Loss: 2.9189, Val Loss: 2.5771, F1 Micro: 0.2500, F1 Macro: 0.1620, Accuracy: 0.2500\n","Epoch 57, Train Loss: 2.3646, Val Loss: 2.6286, F1 Micro: 0.3438, F1 Macro: 0.2694, Accuracy: 0.3438\n","Epoch 58, Train Loss: 2.4468, Val Loss: 2.3952, F1 Micro: 0.2604, F1 Macro: 0.2335, Accuracy: 0.2604\n","Epoch 59, Train Loss: 2.2572, Val Loss: 2.8672, F1 Micro: 0.2708, F1 Macro: 0.2595, Accuracy: 0.2708\n","Epoch 60, Train Loss: 2.2734, Val Loss: 2.4183, F1 Micro: 0.3646, F1 Macro: 0.3204, Accuracy: 0.3646\n","Epoch 61, Train Loss: 2.2118, Val Loss: 2.7629, F1 Micro: 0.2604, F1 Macro: 0.2378, Accuracy: 0.2604\n","Epoch 62, Train Loss: 1.9983, Val Loss: 2.1137, F1 Micro: 0.3750, F1 Macro: 0.3330, Accuracy: 0.3750\n","Epoch 63, Train Loss: 1.9526, Val Loss: 1.8779, F1 Micro: 0.4062, F1 Macro: 0.3578, Accuracy: 0.4062\n","Epoch 64, Train Loss: 1.8142, Val Loss: 2.2101, F1 Micro: 0.3854, F1 Macro: 0.2871, Accuracy: 0.3854\n","Epoch 65, Train Loss: 1.9172, Val Loss: 1.9657, F1 Micro: 0.3958, F1 Macro: 0.3506, Accuracy: 0.3958\n","Epoch 66, Train Loss: 2.1790, Val Loss: 2.0146, F1 Micro: 0.3958, F1 Macro: 0.3310, Accuracy: 0.3958\n","Epoch 67, Train Loss: 1.9480, Val Loss: 2.1662, F1 Micro: 0.2188, F1 Macro: 0.1932, Accuracy: 0.2188\n","Epoch 68, Train Loss: 1.7740, Val Loss: 2.3339, F1 Micro: 0.3646, F1 Macro: 0.3110, Accuracy: 0.3646\n","Epoch 69, Train Loss: 1.9095, Val Loss: 2.4636, F1 Micro: 0.3646, F1 Macro: 0.3086, Accuracy: 0.3646\n","Epoch 70, Train Loss: 1.8095, Val Loss: 1.9199, F1 Micro: 0.3229, F1 Macro: 0.2806, Accuracy: 0.3229\n","Epoch 71, Train Loss: 2.0436, Val Loss: 2.4235, F1 Micro: 0.3125, F1 Macro: 0.2933, Accuracy: 0.3125\n","Epoch 72, Train Loss: 2.0452, Val Loss: 2.3489, F1 Micro: 0.3333, F1 Macro: 0.2850, Accuracy: 0.3333\n","Epoch 73, Train Loss: 1.8498, Val Loss: 2.3709, F1 Micro: 0.3854, F1 Macro: 0.3768, Accuracy: 0.3854\n","Epoch 74, Train Loss: 2.0362, Val Loss: 2.1606, F1 Micro: 0.2396, F1 Macro: 0.2403, Accuracy: 0.2396\n","Epoch 75, Train Loss: 2.2142, Val Loss: 2.0497, F1 Micro: 0.3750, F1 Macro: 0.2494, Accuracy: 0.3750\n","Epoch 76, Train Loss: 2.2261, Val Loss: 2.5044, F1 Micro: 0.3333, F1 Macro: 0.2593, Accuracy: 0.3333\n","Epoch 77, Train Loss: 2.4910, Val Loss: 2.7253, F1 Micro: 0.3021, F1 Macro: 0.3037, Accuracy: 0.3021\n","Epoch 78, Train Loss: 1.8435, Val Loss: 2.5276, F1 Micro: 0.2917, F1 Macro: 0.2399, Accuracy: 0.2917\n","Epoch 79, Train Loss: 1.9225, Val Loss: 2.1341, F1 Micro: 0.3333, F1 Macro: 0.2757, Accuracy: 0.3333\n","Epoch 80, Train Loss: 1.9981, Val Loss: 2.2322, F1 Micro: 0.3125, F1 Macro: 0.2369, Accuracy: 0.3125\n","Epoch 81, Train Loss: 1.9745, Val Loss: 2.1023, F1 Micro: 0.3854, F1 Macro: 0.3275, Accuracy: 0.3854\n","Epoch 82, Train Loss: 1.7390, Val Loss: 1.8756, F1 Micro: 0.3542, F1 Macro: 0.3452, Accuracy: 0.3542\n","Epoch 83, Train Loss: 1.7323, Val Loss: 1.9390, F1 Micro: 0.2500, F1 Macro: 0.2617, Accuracy: 0.2500\n","Epoch 84, Train Loss: 2.1308, Val Loss: 1.9038, F1 Micro: 0.3854, F1 Macro: 0.3167, Accuracy: 0.3854\n","Epoch 85, Train Loss: 1.9283, Val Loss: 1.8178, F1 Micro: 0.3438, F1 Macro: 0.2459, Accuracy: 0.3438\n","Epoch 86, Train Loss: 2.0382, Val Loss: 2.5245, F1 Micro: 0.2917, F1 Macro: 0.2708, Accuracy: 0.2917\n","Epoch 87, Train Loss: 1.9025, Val Loss: 2.2576, F1 Micro: 0.2708, F1 Macro: 0.2547, Accuracy: 0.2708\n","Epoch 88, Train Loss: 1.7863, Val Loss: 2.2920, F1 Micro: 0.2604, F1 Macro: 0.2308, Accuracy: 0.2604\n","Epoch 89, Train Loss: 1.7740, Val Loss: 2.0439, F1 Micro: 0.4062, F1 Macro: 0.3422, Accuracy: 0.4062\n","Epoch 90, Train Loss: 2.1333, Val Loss: 2.4641, F1 Micro: 0.3229, F1 Macro: 0.2598, Accuracy: 0.3229\n","Epoch 91, Train Loss: 2.0243, Val Loss: 2.3438, F1 Micro: 0.3229, F1 Macro: 0.2842, Accuracy: 0.3229\n","Epoch 92, Train Loss: 2.0381, Val Loss: 2.5267, F1 Micro: 0.2396, F1 Macro: 0.2178, Accuracy: 0.2396\n","Epoch 93, Train Loss: 2.0361, Val Loss: 3.2971, F1 Micro: 0.2188, F1 Macro: 0.1410, Accuracy: 0.2188\n","Epoch 94, Train Loss: 2.0593, Val Loss: 2.4174, F1 Micro: 0.3021, F1 Macro: 0.2180, Accuracy: 0.3021\n","Epoch 95, Train Loss: 2.0898, Val Loss: 2.1800, F1 Micro: 0.3542, F1 Macro: 0.2665, Accuracy: 0.3542\n","Epoch 96, Train Loss: 1.8880, Val Loss: 2.5134, F1 Micro: 0.3021, F1 Macro: 0.2425, Accuracy: 0.3021\n","Epoch 97, Train Loss: 1.9937, Val Loss: 2.0330, F1 Micro: 0.2917, F1 Macro: 0.2537, Accuracy: 0.2917\n","Epoch 98, Train Loss: 1.9791, Val Loss: 1.7631, F1 Micro: 0.3542, F1 Macro: 0.3099, Accuracy: 0.3542\n","Epoch 99, Train Loss: 1.8350, Val Loss: 1.9767, F1 Micro: 0.3125, F1 Macro: 0.2672, Accuracy: 0.3125\n","Epoch 100, Train Loss: 1.9390, Val Loss: 1.8526, F1 Micro: 0.3438, F1 Macro: 0.3244, Accuracy: 0.3438\n","Epoch 101, Train Loss: 1.8004, Val Loss: 2.3231, F1 Micro: 0.2812, F1 Macro: 0.2126, Accuracy: 0.2812\n","Epoch 102, Train Loss: 1.8008, Val Loss: 2.0482, F1 Micro: 0.3438, F1 Macro: 0.3106, Accuracy: 0.3438\n","Epoch 103, Train Loss: 1.8792, Val Loss: 2.2799, F1 Micro: 0.3125, F1 Macro: 0.2959, Accuracy: 0.3125\n","Epoch 104, Train Loss: 1.9524, Val Loss: 3.0847, F1 Micro: 0.2917, F1 Macro: 0.2791, Accuracy: 0.2917\n","Epoch 105, Train Loss: 1.9605, Val Loss: 2.3607, F1 Micro: 0.2812, F1 Macro: 0.1830, Accuracy: 0.2812\n","Epoch 106, Train Loss: 1.8240, Val Loss: 1.7946, F1 Micro: 0.1979, F1 Macro: 0.1693, Accuracy: 0.1979\n","Epoch 107, Train Loss: 1.9007, Val Loss: 2.1294, F1 Micro: 0.3333, F1 Macro: 0.2877, Accuracy: 0.3333\n","Epoch 108, Train Loss: 1.8175, Val Loss: 1.9769, F1 Micro: 0.3333, F1 Macro: 0.2966, Accuracy: 0.3333\n","Epoch 109, Train Loss: 1.8119, Val Loss: 1.9799, F1 Micro: 0.3958, F1 Macro: 0.3058, Accuracy: 0.3958\n","Epoch 110, Train Loss: 2.0139, Val Loss: 2.7346, F1 Micro: 0.3125, F1 Macro: 0.2400, Accuracy: 0.3125\n","Epoch 111, Train Loss: 2.5489, Val Loss: 3.2702, F1 Micro: 0.3229, F1 Macro: 0.2249, Accuracy: 0.3229\n","Epoch 112, Train Loss: 2.2681, Val Loss: 3.0540, F1 Micro: 0.2604, F1 Macro: 0.1854, Accuracy: 0.2604\n","Epoch 113, Train Loss: 2.7268, Val Loss: 3.1658, F1 Micro: 0.2604, F1 Macro: 0.1834, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 490.9319, Val Loss: 219.8837, F1 Micro: 0.2292, F1 Macro: 0.1354, Accuracy: 0.2292\n","Epoch 2, Train Loss: 90.0343, Val Loss: 93.9124, F1 Micro: 0.2188, F1 Macro: 0.1443, Accuracy: 0.2188\n","Epoch 3, Train Loss: 31.9541, Val Loss: 21.1762, F1 Micro: 0.2292, F1 Macro: 0.1330, Accuracy: 0.2292\n","Epoch 4, Train Loss: 14.4758, Val Loss: 11.2206, F1 Micro: 0.2708, F1 Macro: 0.1997, Accuracy: 0.2708\n","Epoch 5, Train Loss: 11.6432, Val Loss: 17.6821, F1 Micro: 0.2292, F1 Macro: 0.1293, Accuracy: 0.2292\n","Epoch 6, Train Loss: 13.2350, Val Loss: 12.8085, F1 Micro: 0.1979, F1 Macro: 0.1241, Accuracy: 0.1979\n","Epoch 7, Train Loss: 16.9330, Val Loss: 12.1858, F1 Micro: 0.2708, F1 Macro: 0.2158, Accuracy: 0.2708\n","Epoch 8, Train Loss: 11.3657, Val Loss: 20.1768, F1 Micro: 0.1771, F1 Macro: 0.0699, Accuracy: 0.1771\n","Epoch 9, Train Loss: 10.5218, Val Loss: 7.9248, F1 Micro: 0.1979, F1 Macro: 0.1501, Accuracy: 0.1979\n","Epoch 10, Train Loss: 7.6223, Val Loss: 8.6946, F1 Micro: 0.3125, F1 Macro: 0.2371, Accuracy: 0.3125\n","Epoch 11, Train Loss: 4.9561, Val Loss: 3.9477, F1 Micro: 0.3646, F1 Macro: 0.3160, Accuracy: 0.3646\n","Epoch 12, Train Loss: 4.5131, Val Loss: 4.4458, F1 Micro: 0.2604, F1 Macro: 0.2129, Accuracy: 0.2604\n","Epoch 13, Train Loss: 4.6114, Val Loss: 4.0266, F1 Micro: 0.3021, F1 Macro: 0.2720, Accuracy: 0.3021\n","Epoch 14, Train Loss: 5.3947, Val Loss: 5.1713, F1 Micro: 0.3229, F1 Macro: 0.2850, Accuracy: 0.3229\n","Epoch 15, Train Loss: 5.5473, Val Loss: 5.0934, F1 Micro: 0.2917, F1 Macro: 0.2777, Accuracy: 0.2917\n","Epoch 16, Train Loss: 3.9140, Val Loss: 4.2148, F1 Micro: 0.2708, F1 Macro: 0.2279, Accuracy: 0.2708\n","Epoch 17, Train Loss: 5.1942, Val Loss: 4.0739, F1 Micro: 0.1979, F1 Macro: 0.1821, Accuracy: 0.1979\n","Epoch 18, Train Loss: 3.9173, Val Loss: 4.5693, F1 Micro: 0.2083, F1 Macro: 0.1877, Accuracy: 0.2083\n","Epoch 19, Train Loss: 4.7417, Val Loss: 5.5278, F1 Micro: 0.1875, F1 Macro: 0.1565, Accuracy: 0.1875\n","Epoch 20, Train Loss: 4.6568, Val Loss: 4.0957, F1 Micro: 0.2396, F1 Macro: 0.1994, Accuracy: 0.2396\n","Epoch 21, Train Loss: 4.3632, Val Loss: 4.6569, F1 Micro: 0.2083, F1 Macro: 0.1962, Accuracy: 0.2083\n","Epoch 22, Train Loss: 3.9070, Val Loss: 3.4692, F1 Micro: 0.2708, F1 Macro: 0.2237, Accuracy: 0.2708\n","Epoch 23, Train Loss: 4.5884, Val Loss: 9.7798, F1 Micro: 0.2292, F1 Macro: 0.1769, Accuracy: 0.2292\n","Epoch 24, Train Loss: 6.1136, Val Loss: 3.6523, F1 Micro: 0.3229, F1 Macro: 0.2812, Accuracy: 0.3229\n","Epoch 25, Train Loss: 4.1036, Val Loss: 4.6099, F1 Micro: 0.1979, F1 Macro: 0.1631, Accuracy: 0.1979\n","Epoch 26, Train Loss: 3.8734, Val Loss: 3.8535, F1 Micro: 0.2292, F1 Macro: 0.1923, Accuracy: 0.2292\n","Epoch 27, Train Loss: 3.5468, Val Loss: 3.9367, F1 Micro: 0.3021, F1 Macro: 0.2462, Accuracy: 0.3021\n","Epoch 28, Train Loss: 3.4627, Val Loss: 4.5172, F1 Micro: 0.2500, F1 Macro: 0.2010, Accuracy: 0.2500\n","Epoch 29, Train Loss: 3.0996, Val Loss: 4.9311, F1 Micro: 0.2396, F1 Macro: 0.1961, Accuracy: 0.2396\n","Epoch 30, Train Loss: 3.2629, Val Loss: 4.0716, F1 Micro: 0.2292, F1 Macro: 0.1966, Accuracy: 0.2292\n","Epoch 31, Train Loss: 3.8451, Val Loss: 3.5077, F1 Micro: 0.3021, F1 Macro: 0.2555, Accuracy: 0.3021\n","Epoch 32, Train Loss: 3.5325, Val Loss: 3.1608, F1 Micro: 0.2083, F1 Macro: 0.1676, Accuracy: 0.2083\n","Epoch 33, Train Loss: 3.2354, Val Loss: 3.3081, F1 Micro: 0.2083, F1 Macro: 0.1360, Accuracy: 0.2083\n","Epoch 34, Train Loss: 2.7137, Val Loss: 4.1232, F1 Micro: 0.2292, F1 Macro: 0.1717, Accuracy: 0.2292\n","Epoch 35, Train Loss: 3.2382, Val Loss: 7.3283, F1 Micro: 0.2396, F1 Macro: 0.1771, Accuracy: 0.2396\n","Epoch 36, Train Loss: 3.5285, Val Loss: 2.9724, F1 Micro: 0.2292, F1 Macro: 0.1646, Accuracy: 0.2292\n","Epoch 37, Train Loss: 3.1640, Val Loss: 2.7402, F1 Micro: 0.2396, F1 Macro: 0.1732, Accuracy: 0.2396\n","Epoch 38, Train Loss: 3.1603, Val Loss: 3.1912, F1 Micro: 0.2292, F1 Macro: 0.1809, Accuracy: 0.2292\n","Epoch 39, Train Loss: 3.1909, Val Loss: 3.1850, F1 Micro: 0.3021, F1 Macro: 0.2350, Accuracy: 0.3021\n","Epoch 40, Train Loss: 2.6165, Val Loss: 2.7219, F1 Micro: 0.2917, F1 Macro: 0.2291, Accuracy: 0.2917\n","Epoch 41, Train Loss: 2.8416, Val Loss: 4.0391, F1 Micro: 0.2812, F1 Macro: 0.1901, Accuracy: 0.2812\n","Epoch 42, Train Loss: 4.3960, Val Loss: 7.1218, F1 Micro: 0.1875, F1 Macro: 0.1092, Accuracy: 0.1875\n","Epoch 43, Train Loss: 8.6897, Val Loss: 14.9730, F1 Micro: 0.1458, F1 Macro: 0.0646, Accuracy: 0.1458\n","Epoch 44, Train Loss: 21.5561, Val Loss: 16.8117, F1 Micro: 0.1667, F1 Macro: 0.0639, Accuracy: 0.1667\n","Epoch 45, Train Loss: 32.5015, Val Loss: 87.1440, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 46, Train Loss: 78.9095, Val Loss: 96.6655, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 47, Train Loss: 94.9745, Val Loss: 45.1588, F1 Micro: 0.2396, F1 Macro: 0.1406, Accuracy: 0.2396\n","Epoch 48, Train Loss: 68.8096, Val Loss: 58.2880, F1 Micro: 0.1875, F1 Macro: 0.0714, Accuracy: 0.1875\n","Epoch 49, Train Loss: 42.7909, Val Loss: 22.0827, F1 Micro: 0.1979, F1 Macro: 0.1257, Accuracy: 0.1979\n","Epoch 50, Train Loss: 22.4873, Val Loss: 13.1600, F1 Micro: 0.2708, F1 Macro: 0.1887, Accuracy: 0.2708\n","Epoch 51, Train Loss: 6.5896, Val Loss: 5.6539, F1 Micro: 0.2500, F1 Macro: 0.1782, Accuracy: 0.2500\n","Epoch 52, Train Loss: 5.1028, Val Loss: 5.3869, F1 Micro: 0.2604, F1 Macro: 0.1984, Accuracy: 0.2604\n","Epoch 53, Train Loss: 4.2319, Val Loss: 3.7190, F1 Micro: 0.1562, F1 Macro: 0.0861, Accuracy: 0.1562\n","Epoch 54, Train Loss: 3.2069, Val Loss: 4.0987, F1 Micro: 0.2500, F1 Macro: 0.1662, Accuracy: 0.2500\n","Epoch 55, Train Loss: 2.6523, Val Loss: 2.3898, F1 Micro: 0.2917, F1 Macro: 0.2785, Accuracy: 0.2917\n","Epoch 56, Train Loss: 2.2365, Val Loss: 2.6279, F1 Micro: 0.2292, F1 Macro: 0.1737, Accuracy: 0.2292\n","Epoch 57, Train Loss: 2.5604, Val Loss: 2.4232, F1 Micro: 0.3021, F1 Macro: 0.2797, Accuracy: 0.3021\n","Epoch 58, Train Loss: 2.0600, Val Loss: 2.2858, F1 Micro: 0.2604, F1 Macro: 0.1840, Accuracy: 0.2604\n","Epoch 59, Train Loss: 1.9632, Val Loss: 2.2569, F1 Micro: 0.2292, F1 Macro: 0.1941, Accuracy: 0.2292\n","Epoch 60, Train Loss: 1.9534, Val Loss: 1.8173, F1 Micro: 0.3646, F1 Macro: 0.3598, Accuracy: 0.3646\n","Epoch 61, Train Loss: 2.1504, Val Loss: 2.9935, F1 Micro: 0.2604, F1 Macro: 0.2386, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 389.5752, Val Loss: 174.7386, F1 Micro: 0.1979, F1 Macro: 0.0978, Accuracy: 0.1979\n","Epoch 2, Train Loss: 83.1492, Val Loss: 73.2871, F1 Micro: 0.1979, F1 Macro: 0.1112, Accuracy: 0.1979\n","Epoch 3, Train Loss: 34.4090, Val Loss: 14.9194, F1 Micro: 0.2917, F1 Macro: 0.2434, Accuracy: 0.2917\n","Epoch 4, Train Loss: 23.0092, Val Loss: 11.3466, F1 Micro: 0.3438, F1 Macro: 0.2717, Accuracy: 0.3438\n","Epoch 5, Train Loss: 19.0685, Val Loss: 20.6059, F1 Micro: 0.1979, F1 Macro: 0.1244, Accuracy: 0.1979\n","Epoch 6, Train Loss: 15.0495, Val Loss: 13.7213, F1 Micro: 0.3021, F1 Macro: 0.2358, Accuracy: 0.3021\n","Epoch 7, Train Loss: 10.9951, Val Loss: 7.4633, F1 Micro: 0.2917, F1 Macro: 0.2502, Accuracy: 0.2917\n","Epoch 8, Train Loss: 9.3941, Val Loss: 10.2291, F1 Micro: 0.2500, F1 Macro: 0.2226, Accuracy: 0.2500\n","Epoch 9, Train Loss: 8.1698, Val Loss: 6.6686, F1 Micro: 0.1771, F1 Macro: 0.1476, Accuracy: 0.1771\n","Epoch 10, Train Loss: 5.7783, Val Loss: 5.0799, F1 Micro: 0.3229, F1 Macro: 0.2714, Accuracy: 0.3229\n","Epoch 11, Train Loss: 5.0089, Val Loss: 4.5178, F1 Micro: 0.3021, F1 Macro: 0.2892, Accuracy: 0.3021\n","Epoch 12, Train Loss: 5.4237, Val Loss: 4.2572, F1 Micro: 0.3438, F1 Macro: 0.3109, Accuracy: 0.3438\n","Epoch 13, Train Loss: 5.6655, Val Loss: 6.7387, F1 Micro: 0.2708, F1 Macro: 0.2094, Accuracy: 0.2708\n","Epoch 14, Train Loss: 7.5289, Val Loss: 4.7740, F1 Micro: 0.2396, F1 Macro: 0.2063, Accuracy: 0.2396\n","Epoch 15, Train Loss: 5.0153, Val Loss: 3.7931, F1 Micro: 0.2812, F1 Macro: 0.2214, Accuracy: 0.2812\n","Epoch 16, Train Loss: 3.8478, Val Loss: 4.7857, F1 Micro: 0.1979, F1 Macro: 0.1681, Accuracy: 0.1979\n","Epoch 17, Train Loss: 4.8457, Val Loss: 4.9715, F1 Micro: 0.1979, F1 Macro: 0.1732, Accuracy: 0.1979\n","Epoch 18, Train Loss: 6.0173, Val Loss: 5.6259, F1 Micro: 0.2812, F1 Macro: 0.2276, Accuracy: 0.2812\n","Epoch 19, Train Loss: 7.0292, Val Loss: 5.7699, F1 Micro: 0.1979, F1 Macro: 0.1459, Accuracy: 0.1979\n","Epoch 20, Train Loss: 5.8674, Val Loss: 3.6188, F1 Micro: 0.3542, F1 Macro: 0.2952, Accuracy: 0.3542\n","Epoch 21, Train Loss: 3.6003, Val Loss: 3.6776, F1 Micro: 0.1979, F1 Macro: 0.1298, Accuracy: 0.1979\n","Epoch 22, Train Loss: 4.3293, Val Loss: 5.0314, F1 Micro: 0.2083, F1 Macro: 0.1744, Accuracy: 0.2083\n","Epoch 23, Train Loss: 3.7957, Val Loss: 2.9159, F1 Micro: 0.2292, F1 Macro: 0.1803, Accuracy: 0.2292\n","Epoch 24, Train Loss: 3.7598, Val Loss: 3.1724, F1 Micro: 0.2917, F1 Macro: 0.2219, Accuracy: 0.2917\n","Epoch 25, Train Loss: 5.0999, Val Loss: 4.0416, F1 Micro: 0.2083, F1 Macro: 0.1378, Accuracy: 0.2083\n","Epoch 26, Train Loss: 3.8343, Val Loss: 3.6947, F1 Micro: 0.3125, F1 Macro: 0.3005, Accuracy: 0.3125\n","Epoch 27, Train Loss: 3.5325, Val Loss: 3.2709, F1 Micro: 0.2604, F1 Macro: 0.1896, Accuracy: 0.2604\n","Epoch 28, Train Loss: 2.8817, Val Loss: 2.1073, F1 Micro: 0.3125, F1 Macro: 0.2941, Accuracy: 0.3125\n","Epoch 29, Train Loss: 2.9720, Val Loss: 2.8452, F1 Micro: 0.2917, F1 Macro: 0.2578, Accuracy: 0.2917\n","Epoch 30, Train Loss: 3.8887, Val Loss: 2.4975, F1 Micro: 0.2500, F1 Macro: 0.2042, Accuracy: 0.2500\n","Epoch 31, Train Loss: 4.0359, Val Loss: 3.1692, F1 Micro: 0.3125, F1 Macro: 0.2318, Accuracy: 0.3125\n","Epoch 32, Train Loss: 3.1331, Val Loss: 4.8835, F1 Micro: 0.2604, F1 Macro: 0.1505, Accuracy: 0.2604\n","Epoch 33, Train Loss: 4.3062, Val Loss: 3.3885, F1 Micro: 0.1458, F1 Macro: 0.1134, Accuracy: 0.1458\n","Epoch 34, Train Loss: 3.3787, Val Loss: 4.1044, F1 Micro: 0.3333, F1 Macro: 0.2605, Accuracy: 0.3333\n","Epoch 35, Train Loss: 5.3434, Val Loss: 5.4348, F1 Micro: 0.2812, F1 Macro: 0.2314, Accuracy: 0.2812\n","Epoch 36, Train Loss: 6.8274, Val Loss: 5.3973, F1 Micro: 0.2917, F1 Macro: 0.1951, Accuracy: 0.2917\n","Epoch 37, Train Loss: 6.6439, Val Loss: 5.6097, F1 Micro: 0.2708, F1 Macro: 0.2070, Accuracy: 0.2708\n","Epoch 38, Train Loss: 4.9602, Val Loss: 4.2947, F1 Micro: 0.2292, F1 Macro: 0.1513, Accuracy: 0.2292\n","Epoch 39, Train Loss: 5.2188, Val Loss: 14.3894, F1 Micro: 0.1667, F1 Macro: 0.0476, Accuracy: 0.1667\n","Epoch 40, Train Loss: 9.7663, Val Loss: 4.9226, F1 Micro: 0.2812, F1 Macro: 0.2269, Accuracy: 0.2812\n","Epoch 41, Train Loss: 9.4145, Val Loss: 18.7094, F1 Micro: 0.2292, F1 Macro: 0.1324, Accuracy: 0.2292\n","Epoch 42, Train Loss: 11.4961, Val Loss: 9.3299, F1 Micro: 0.2500, F1 Macro: 0.1117, Accuracy: 0.2500\n","Epoch 43, Train Loss: 7.7882, Val Loss: 6.1327, F1 Micro: 0.2083, F1 Macro: 0.1100, Accuracy: 0.2083\n","Epoch 44, Train Loss: 4.8233, Val Loss: 2.9227, F1 Micro: 0.3333, F1 Macro: 0.2949, Accuracy: 0.3333\n","Epoch 45, Train Loss: 3.6710, Val Loss: 3.0414, F1 Micro: 0.3542, F1 Macro: 0.2870, Accuracy: 0.3542\n","Epoch 46, Train Loss: 2.9614, Val Loss: 3.6197, F1 Micro: 0.2292, F1 Macro: 0.0813, Accuracy: 0.2292\n","Epoch 47, Train Loss: 3.1450, Val Loss: 3.1401, F1 Micro: 0.2292, F1 Macro: 0.1554, Accuracy: 0.2292\n","Epoch 48, Train Loss: 2.8868, Val Loss: 3.1904, F1 Micro: 0.3646, F1 Macro: 0.2849, Accuracy: 0.3646\n","Epoch 49, Train Loss: 2.8307, Val Loss: 2.1473, F1 Micro: 0.2917, F1 Macro: 0.2958, Accuracy: 0.2917\n","Epoch 50, Train Loss: 3.0119, Val Loss: 2.5909, F1 Micro: 0.3333, F1 Macro: 0.2754, Accuracy: 0.3333\n","Epoch 51, Train Loss: 2.2423, Val Loss: 2.0538, F1 Micro: 0.3333, F1 Macro: 0.3448, Accuracy: 0.3333\n","Epoch 52, Train Loss: 2.0896, Val Loss: 2.5194, F1 Micro: 0.2188, F1 Macro: 0.1822, Accuracy: 0.2188\n","Epoch 53, Train Loss: 2.1581, Val Loss: 2.0922, F1 Micro: 0.2292, F1 Macro: 0.2291, Accuracy: 0.2292\n","Epoch 54, Train Loss: 2.3540, Val Loss: 2.7758, F1 Micro: 0.2188, F1 Macro: 0.1581, Accuracy: 0.2188\n","Epoch 55, Train Loss: 2.4600, Val Loss: 2.6338, F1 Micro: 0.2292, F1 Macro: 0.1263, Accuracy: 0.2292\n","Epoch 56, Train Loss: 3.2384, Val Loss: 2.8595, F1 Micro: 0.2292, F1 Macro: 0.1660, Accuracy: 0.2292\n","Epoch 57, Train Loss: 3.5408, Val Loss: 5.0712, F1 Micro: 0.2188, F1 Macro: 0.1465, Accuracy: 0.2188\n","Epoch 58, Train Loss: 2.4025, Val Loss: 2.4566, F1 Micro: 0.2396, F1 Macro: 0.1891, Accuracy: 0.2396\n","Epoch 59, Train Loss: 2.5940, Val Loss: 3.9525, F1 Micro: 0.2917, F1 Macro: 0.1916, Accuracy: 0.2917\n","Epoch 60, Train Loss: 2.8026, Val Loss: 2.8333, F1 Micro: 0.2083, F1 Macro: 0.1589, Accuracy: 0.2083\n","Epoch 61, Train Loss: 2.9145, Val Loss: 2.5362, F1 Micro: 0.2708, F1 Macro: 0.2273, Accuracy: 0.2708\n","Epoch 62, Train Loss: 2.7495, Val Loss: 2.8981, F1 Micro: 0.2812, F1 Macro: 0.2055, Accuracy: 0.2812\n","Epoch 63, Train Loss: 2.5734, Val Loss: 1.9633, F1 Micro: 0.3333, F1 Macro: 0.2945, Accuracy: 0.3333\n","Epoch 64, Train Loss: 2.3831, Val Loss: 2.4417, F1 Micro: 0.2500, F1 Macro: 0.2015, Accuracy: 0.2500\n","Epoch 65, Train Loss: 3.0566, Val Loss: 4.4497, F1 Micro: 0.2708, F1 Macro: 0.1861, Accuracy: 0.2708\n","Epoch 66, Train Loss: 8.7981, Val Loss: 25.3697, F1 Micro: 0.2188, F1 Macro: 0.1200, Accuracy: 0.2188\n","Epoch 67, Train Loss: 79.4217, Val Loss: 80.6726, F1 Micro: 0.1562, F1 Macro: 0.0719, Accuracy: 0.1562\n","Epoch 68, Train Loss: 301.3923, Val Loss: 385.8301, F1 Micro: 0.2188, F1 Macro: 0.0762, Accuracy: 0.2188\n","Epoch 69, Train Loss: 548.2518, Val Loss: 319.7532, F1 Micro: 0.2292, F1 Macro: 0.1201, Accuracy: 0.2292\n","Epoch 70, Train Loss: 384.0373, Val Loss: 123.4190, F1 Micro: 0.2188, F1 Macro: 0.0648, Accuracy: 0.2188\n","Epoch 71, Train Loss: 208.6720, Val Loss: 153.9207, F1 Micro: 0.2292, F1 Macro: 0.1253, Accuracy: 0.2292\n","Epoch 72, Train Loss: 119.4223, Val Loss: 62.5969, F1 Micro: 0.1875, F1 Macro: 0.1088, Accuracy: 0.1875\n","Epoch 73, Train Loss: 36.1900, Val Loss: 36.1168, F1 Micro: 0.2292, F1 Macro: 0.1648, Accuracy: 0.2292\n","Epoch 74, Train Loss: 12.6150, Val Loss: 7.6123, F1 Micro: 0.2604, F1 Macro: 0.2481, Accuracy: 0.2604\n","Epoch 75, Train Loss: 6.2855, Val Loss: 4.0059, F1 Micro: 0.2396, F1 Macro: 0.1891, Accuracy: 0.2396\n","Epoch 76, Train Loss: 3.5189, Val Loss: 2.6381, F1 Micro: 0.2396, F1 Macro: 0.2066, Accuracy: 0.2396\n","Epoch 77, Train Loss: 2.9973, Val Loss: 2.4806, F1 Micro: 0.3021, F1 Macro: 0.2243, Accuracy: 0.3021\n","Epoch 78, Train Loss: 2.3165, Val Loss: 1.9629, F1 Micro: 0.3021, F1 Macro: 0.2653, Accuracy: 0.3021\n","Epoch 79, Train Loss: 1.9084, Val Loss: 2.0424, F1 Micro: 0.3125, F1 Macro: 0.2976, Accuracy: 0.3125\n","Epoch 80, Train Loss: 2.4376, Val Loss: 2.3932, F1 Micro: 0.3646, F1 Macro: 0.3376, Accuracy: 0.3646\n","Epoch 81, Train Loss: 2.0799, Val Loss: 2.3628, F1 Micro: 0.2396, F1 Macro: 0.2001, Accuracy: 0.2396\n","Epoch 82, Train Loss: 2.1710, Val Loss: 2.6068, F1 Micro: 0.2500, F1 Macro: 0.1932, Accuracy: 0.2500\n","Epoch 83, Train Loss: 2.3356, Val Loss: 1.7974, F1 Micro: 0.3542, F1 Macro: 0.3411, Accuracy: 0.3542\n","Epoch 84, Train Loss: 2.2470, Val Loss: 2.0866, F1 Micro: 0.2604, F1 Macro: 0.2131, Accuracy: 0.2604\n","Epoch 85, Train Loss: 2.0498, Val Loss: 2.1050, F1 Micro: 0.2604, F1 Macro: 0.2588, Accuracy: 0.2604\n","Epoch 86, Train Loss: 1.9050, Val Loss: 1.9146, F1 Micro: 0.3229, F1 Macro: 0.3033, Accuracy: 0.3229\n","Epoch 87, Train Loss: 1.8738, Val Loss: 2.0375, F1 Micro: 0.3854, F1 Macro: 0.3431, Accuracy: 0.3854\n","Epoch 88, Train Loss: 1.7668, Val Loss: 1.7702, F1 Micro: 0.3542, F1 Macro: 0.3295, Accuracy: 0.3542\n","Epoch 89, Train Loss: 1.9798, Val Loss: 1.9665, F1 Micro: 0.3125, F1 Macro: 0.2750, Accuracy: 0.3125\n","Epoch 90, Train Loss: 2.0905, Val Loss: 2.2692, F1 Micro: 0.2917, F1 Macro: 0.2267, Accuracy: 0.2917\n","Epoch 91, Train Loss: 2.2966, Val Loss: 2.0314, F1 Micro: 0.2812, F1 Macro: 0.2512, Accuracy: 0.2812\n","Epoch 92, Train Loss: 2.2398, Val Loss: 1.9503, F1 Micro: 0.2708, F1 Macro: 0.2412, Accuracy: 0.2708\n","Epoch 93, Train Loss: 2.2920, Val Loss: 1.9996, F1 Micro: 0.3333, F1 Macro: 0.3079, Accuracy: 0.3333\n","Epoch 94, Train Loss: 1.8759, Val Loss: 1.8239, F1 Micro: 0.3229, F1 Macro: 0.3142, Accuracy: 0.3229\n","Epoch 95, Train Loss: 1.9154, Val Loss: 1.9221, F1 Micro: 0.1875, F1 Macro: 0.1666, Accuracy: 0.1875\n","Epoch 96, Train Loss: 1.9215, Val Loss: 1.8023, F1 Micro: 0.3333, F1 Macro: 0.3001, Accuracy: 0.3333\n","Epoch 97, Train Loss: 1.6993, Val Loss: 1.7280, F1 Micro: 0.2604, F1 Macro: 0.2740, Accuracy: 0.2604\n","Epoch 98, Train Loss: 1.8194, Val Loss: 1.8376, F1 Micro: 0.3542, F1 Macro: 0.2831, Accuracy: 0.3542\n","Epoch 99, Train Loss: 1.7875, Val Loss: 1.8261, F1 Micro: 0.3229, F1 Macro: 0.3011, Accuracy: 0.3229\n","Epoch 100, Train Loss: 1.7241, Val Loss: 1.9429, F1 Micro: 0.3021, F1 Macro: 0.2917, Accuracy: 0.3021\n","Epoch 101, Train Loss: 1.7752, Val Loss: 1.8435, F1 Micro: 0.2917, F1 Macro: 0.2785, Accuracy: 0.2917\n","Epoch 102, Train Loss: 1.8198, Val Loss: 2.1011, F1 Micro: 0.3229, F1 Macro: 0.3138, Accuracy: 0.3229\n","Epoch 103, Train Loss: 2.0273, Val Loss: 2.2498, F1 Micro: 0.2812, F1 Macro: 0.2264, Accuracy: 0.2812\n","Epoch 104, Train Loss: 2.0322, Val Loss: 1.8923, F1 Micro: 0.2917, F1 Macro: 0.2907, Accuracy: 0.2917\n","Epoch 105, Train Loss: 1.9089, Val Loss: 2.1070, F1 Micro: 0.2396, F1 Macro: 0.2447, Accuracy: 0.2396\n","Epoch 106, Train Loss: 1.8549, Val Loss: 1.9401, F1 Micro: 0.3125, F1 Macro: 0.3007, Accuracy: 0.3125\n","Epoch 107, Train Loss: 1.8697, Val Loss: 1.9265, F1 Micro: 0.1875, F1 Macro: 0.1879, Accuracy: 0.1875\n","Epoch 108, Train Loss: 2.2052, Val Loss: 2.0321, F1 Micro: 0.3646, F1 Macro: 0.3370, Accuracy: 0.3646\n","Epoch 109, Train Loss: 2.1190, Val Loss: 1.7977, F1 Micro: 0.3646, F1 Macro: 0.3324, Accuracy: 0.3646\n","Epoch 110, Train Loss: 1.8201, Val Loss: 1.9976, F1 Micro: 0.3750, F1 Macro: 0.3130, Accuracy: 0.3750\n","Epoch 111, Train Loss: 1.8823, Val Loss: 2.0206, F1 Micro: 0.3542, F1 Macro: 0.3228, Accuracy: 0.3542\n","Epoch 112, Train Loss: 1.8917, Val Loss: 1.8842, F1 Micro: 0.3958, F1 Macro: 0.3781, Accuracy: 0.3958\n","Epoch 113, Train Loss: 1.9496, Val Loss: 1.9355, F1 Micro: 0.2500, F1 Macro: 0.2179, Accuracy: 0.2500\n","Epoch 114, Train Loss: 2.0298, Val Loss: 1.9692, F1 Micro: 0.2917, F1 Macro: 0.2582, Accuracy: 0.2917\n","Epoch 115, Train Loss: 2.1218, Val Loss: 3.2547, F1 Micro: 0.3229, F1 Macro: 0.2217, Accuracy: 0.3229\n","Epoch 116, Train Loss: 2.3696, Val Loss: 2.5848, F1 Micro: 0.3542, F1 Macro: 0.3161, Accuracy: 0.3542\n","Epoch 117, Train Loss: 2.2137, Val Loss: 2.7457, F1 Micro: 0.2708, F1 Macro: 0.2253, Accuracy: 0.2708\n","Epoch 118, Train Loss: 2.2819, Val Loss: 2.1160, F1 Micro: 0.3333, F1 Macro: 0.2951, Accuracy: 0.3333\n","Epoch 119, Train Loss: 1.9924, Val Loss: 2.2122, F1 Micro: 0.1979, F1 Macro: 0.1661, Accuracy: 0.1979\n","Epoch 120, Train Loss: 1.8687, Val Loss: 1.8451, F1 Micro: 0.3750, F1 Macro: 0.3043, Accuracy: 0.3750\n","Epoch 121, Train Loss: 1.7197, Val Loss: 1.6721, F1 Micro: 0.3021, F1 Macro: 0.3166, Accuracy: 0.3021\n","Epoch 122, Train Loss: 1.7180, Val Loss: 2.0330, F1 Micro: 0.2188, F1 Macro: 0.1600, Accuracy: 0.2188\n","Epoch 123, Train Loss: 1.9614, Val Loss: 1.6212, F1 Micro: 0.3750, F1 Macro: 0.3478, Accuracy: 0.3750\n","Epoch 124, Train Loss: 1.8848, Val Loss: 1.9111, F1 Micro: 0.2604, F1 Macro: 0.2275, Accuracy: 0.2604\n","Epoch 125, Train Loss: 1.8737, Val Loss: 1.9732, F1 Micro: 0.3646, F1 Macro: 0.3056, Accuracy: 0.3646\n","Epoch 126, Train Loss: 1.9342, Val Loss: 2.0140, F1 Micro: 0.1979, F1 Macro: 0.1540, Accuracy: 0.1979\n","Epoch 127, Train Loss: 1.9023, Val Loss: 2.3689, F1 Micro: 0.3333, F1 Macro: 0.2595, Accuracy: 0.3333\n","Epoch 128, Train Loss: 2.2670, Val Loss: 2.1909, F1 Micro: 0.2812, F1 Macro: 0.2422, Accuracy: 0.2812\n","Epoch 129, Train Loss: 2.6607, Val Loss: 2.9690, F1 Micro: 0.2500, F1 Macro: 0.1515, Accuracy: 0.2500\n","Epoch 130, Train Loss: 2.4518, Val Loss: 2.1879, F1 Micro: 0.1771, F1 Macro: 0.1183, Accuracy: 0.1771\n","Epoch 131, Train Loss: 2.2706, Val Loss: 2.1497, F1 Micro: 0.3542, F1 Macro: 0.2692, Accuracy: 0.3542\n","Epoch 132, Train Loss: 2.3721, Val Loss: 2.2686, F1 Micro: 0.2292, F1 Macro: 0.1920, Accuracy: 0.2292\n","Epoch 133, Train Loss: 2.1127, Val Loss: 2.1256, F1 Micro: 0.3021, F1 Macro: 0.2842, Accuracy: 0.3021\n","Epoch 134, Train Loss: 1.9450, Val Loss: 2.5432, F1 Micro: 0.2292, F1 Macro: 0.1842, Accuracy: 0.2292\n","Epoch 135, Train Loss: 1.9747, Val Loss: 2.0939, F1 Micro: 0.2708, F1 Macro: 0.2408, Accuracy: 0.2708\n","Epoch 136, Train Loss: 2.0990, Val Loss: 2.2870, F1 Micro: 0.2708, F1 Macro: 0.2290, Accuracy: 0.2708\n","Epoch 137, Train Loss: 2.5315, Val Loss: 2.3543, F1 Micro: 0.2604, F1 Macro: 0.1853, Accuracy: 0.2604\n","Epoch 138, Train Loss: 2.2352, Val Loss: 1.9591, F1 Micro: 0.3021, F1 Macro: 0.2511, Accuracy: 0.3021\n","Epoch 139, Train Loss: 2.4052, Val Loss: 2.9803, F1 Micro: 0.2500, F1 Macro: 0.1854, Accuracy: 0.2500\n","Epoch 140, Train Loss: 2.1962, Val Loss: 1.8637, F1 Micro: 0.3542, F1 Macro: 0.3351, Accuracy: 0.3542\n","Epoch 141, Train Loss: 1.9047, Val Loss: 2.0033, F1 Micro: 0.2917, F1 Macro: 0.2232, Accuracy: 0.2917\n","Epoch 142, Train Loss: 1.8491, Val Loss: 2.1496, F1 Micro: 0.2188, F1 Macro: 0.1868, Accuracy: 0.2188\n","Epoch 143, Train Loss: 2.1937, Val Loss: 2.1009, F1 Micro: 0.3438, F1 Macro: 0.3111, Accuracy: 0.3438\n","Epoch 144, Train Loss: 2.7174, Val Loss: 2.9072, F1 Micro: 0.2917, F1 Macro: 0.2220, Accuracy: 0.2917\n","Epoch 145, Train Loss: 2.5810, Val Loss: 2.3864, F1 Micro: 0.2292, F1 Macro: 0.1368, Accuracy: 0.2292\n","Epoch 146, Train Loss: 2.4488, Val Loss: 2.3151, F1 Micro: 0.3229, F1 Macro: 0.2396, Accuracy: 0.3229\n","Epoch 147, Train Loss: 2.0836, Val Loss: 2.7381, F1 Micro: 0.2708, F1 Macro: 0.2528, Accuracy: 0.2708\n","Epoch 148, Train Loss: 2.8662, Val Loss: 3.5689, F1 Micro: 0.1771, F1 Macro: 0.1566, Accuracy: 0.1771\n","Epoch 149, Train Loss: 7.5942, Val Loss: 7.5415, F1 Micro: 0.1667, F1 Macro: 0.1224, Accuracy: 0.1667\n","Epoch 150, Train Loss: 29.6977, Val Loss: 77.0840, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 151, Train Loss: 202.8854, Val Loss: 141.8551, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 152, Train Loss: 134.2655, Val Loss: 208.3727, F1 Micro: 0.1458, F1 Macro: 0.0458, Accuracy: 0.1458\n","Epoch 153, Train Loss: 167.8903, Val Loss: 222.1345, F1 Micro: 0.2500, F1 Macro: 0.1234, Accuracy: 0.2500\n","Epoch 154, Train Loss: 189.2362, Val Loss: 137.1312, F1 Micro: 0.2292, F1 Macro: 0.1046, Accuracy: 0.2292\n","Epoch 155, Train Loss: 212.1616, Val Loss: 160.8470, F1 Micro: 0.2292, F1 Macro: 0.1414, Accuracy: 0.2292\n","Epoch 156, Train Loss: 120.2442, Val Loss: 30.1525, F1 Micro: 0.1979, F1 Macro: 0.1333, Accuracy: 0.1979\n","Epoch 157, Train Loss: 28.6600, Val Loss: 35.5747, F1 Micro: 0.1875, F1 Macro: 0.1026, Accuracy: 0.1875\n","Epoch 158, Train Loss: 15.6896, Val Loss: 8.8896, F1 Micro: 0.2500, F1 Macro: 0.1921, Accuracy: 0.2500\n","Epoch 159, Train Loss: 11.0253, Val Loss: 10.9946, F1 Micro: 0.2500, F1 Macro: 0.1764, Accuracy: 0.2500\n","Epoch 160, Train Loss: 8.6055, Val Loss: 4.3119, F1 Micro: 0.3021, F1 Macro: 0.2123, Accuracy: 0.3021\n","Epoch 161, Train Loss: 4.6370, Val Loss: 2.6339, F1 Micro: 0.2083, F1 Macro: 0.1887, Accuracy: 0.2083\n","Epoch 162, Train Loss: 2.0680, Val Loss: 2.6539, F1 Micro: 0.2188, F1 Macro: 0.1649, Accuracy: 0.2188\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.39791666666666664\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 51.3583, Val Loss: 23.2483, F1 Micro: 0.1979, F1 Macro: 0.0734, Accuracy: 0.1979\n","Epoch 2, Train Loss: 26.3534, Val Loss: 22.2834, F1 Micro: 0.1667, F1 Macro: 0.1073, Accuracy: 0.1667\n","Epoch 3, Train Loss: 23.4159, Val Loss: 25.0771, F1 Micro: 0.2604, F1 Macro: 0.1863, Accuracy: 0.2604\n","Epoch 4, Train Loss: 27.2107, Val Loss: 36.1770, F1 Micro: 0.2500, F1 Macro: 0.1313, Accuracy: 0.2500\n","Epoch 5, Train Loss: 20.1884, Val Loss: 20.7460, F1 Micro: 0.2292, F1 Macro: 0.1137, Accuracy: 0.2292\n","Epoch 6, Train Loss: 30.6074, Val Loss: 27.0577, F1 Micro: 0.2812, F1 Macro: 0.1709, Accuracy: 0.2812\n","Epoch 7, Train Loss: 21.4794, Val Loss: 33.7969, F1 Micro: 0.1875, F1 Macro: 0.1489, Accuracy: 0.1875\n","Epoch 8, Train Loss: 20.2196, Val Loss: 14.0637, F1 Micro: 0.2708, F1 Macro: 0.1740, Accuracy: 0.2708\n","Epoch 9, Train Loss: 19.3416, Val Loss: 25.3865, F1 Micro: 0.1875, F1 Macro: 0.1241, Accuracy: 0.1875\n","Epoch 10, Train Loss: 30.5610, Val Loss: 26.5648, F1 Micro: 0.2292, F1 Macro: 0.1820, Accuracy: 0.2292\n","Epoch 11, Train Loss: 25.0454, Val Loss: 32.8018, F1 Micro: 0.1875, F1 Macro: 0.0919, Accuracy: 0.1875\n","Epoch 12, Train Loss: 26.5848, Val Loss: 17.8066, F1 Micro: 0.2083, F1 Macro: 0.1337, Accuracy: 0.2083\n","Epoch 13, Train Loss: 25.6848, Val Loss: 52.5975, F1 Micro: 0.1979, F1 Macro: 0.1415, Accuracy: 0.1979\n","Epoch 14, Train Loss: 30.2463, Val Loss: 17.1052, F1 Micro: 0.2604, F1 Macro: 0.2284, Accuracy: 0.2604\n","Epoch 15, Train Loss: 20.7697, Val Loss: 29.1056, F1 Micro: 0.3021, F1 Macro: 0.2039, Accuracy: 0.3021\n","Epoch 16, Train Loss: 24.2506, Val Loss: 24.9661, F1 Micro: 0.2500, F1 Macro: 0.1538, Accuracy: 0.2500\n","Epoch 17, Train Loss: 17.6984, Val Loss: 12.1078, F1 Micro: 0.2812, F1 Macro: 0.1906, Accuracy: 0.2812\n","Epoch 18, Train Loss: 15.6657, Val Loss: 21.7891, F1 Micro: 0.1562, F1 Macro: 0.1112, Accuracy: 0.1562\n","Epoch 19, Train Loss: 24.0332, Val Loss: 19.1159, F1 Micro: 0.2292, F1 Macro: 0.1703, Accuracy: 0.2292\n","Epoch 20, Train Loss: 24.6013, Val Loss: 18.6785, F1 Micro: 0.1875, F1 Macro: 0.1439, Accuracy: 0.1875\n","Epoch 21, Train Loss: 19.2162, Val Loss: 29.0054, F1 Micro: 0.2188, F1 Macro: 0.1381, Accuracy: 0.2188\n","Epoch 22, Train Loss: 25.3745, Val Loss: 13.2848, F1 Micro: 0.3333, F1 Macro: 0.2941, Accuracy: 0.3333\n","Epoch 23, Train Loss: 15.4259, Val Loss: 18.3461, F1 Micro: 0.1875, F1 Macro: 0.0915, Accuracy: 0.1875\n","Epoch 24, Train Loss: 17.6536, Val Loss: 20.3477, F1 Micro: 0.2708, F1 Macro: 0.1622, Accuracy: 0.2708\n","Epoch 25, Train Loss: 17.9207, Val Loss: 8.4864, F1 Micro: 0.2292, F1 Macro: 0.2205, Accuracy: 0.2292\n","Epoch 26, Train Loss: 25.0193, Val Loss: 37.2950, F1 Micro: 0.1979, F1 Macro: 0.1247, Accuracy: 0.1979\n","Epoch 27, Train Loss: 25.6577, Val Loss: 25.0721, F1 Micro: 0.1979, F1 Macro: 0.1556, Accuracy: 0.1979\n","Epoch 28, Train Loss: 21.9010, Val Loss: 35.8680, F1 Micro: 0.1875, F1 Macro: 0.0910, Accuracy: 0.1875\n","Epoch 29, Train Loss: 20.2829, Val Loss: 8.3248, F1 Micro: 0.2083, F1 Macro: 0.1803, Accuracy: 0.2083\n","Epoch 30, Train Loss: 8.7225, Val Loss: 16.3639, F1 Micro: 0.2604, F1 Macro: 0.2119, Accuracy: 0.2604\n","Epoch 31, Train Loss: 14.9104, Val Loss: 15.4286, F1 Micro: 0.3021, F1 Macro: 0.2100, Accuracy: 0.3021\n","Epoch 32, Train Loss: 20.6546, Val Loss: 25.1269, F1 Micro: 0.1875, F1 Macro: 0.1154, Accuracy: 0.1875\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 56.5012, Val Loss: 18.7059, F1 Micro: 0.2604, F1 Macro: 0.1619, Accuracy: 0.2604\n","Epoch 2, Train Loss: 23.7819, Val Loss: 17.6111, F1 Micro: 0.2812, F1 Macro: 0.1993, Accuracy: 0.2812\n","Epoch 3, Train Loss: 28.2687, Val Loss: 30.6251, F1 Micro: 0.3021, F1 Macro: 0.1877, Accuracy: 0.3021\n","Epoch 4, Train Loss: 31.8817, Val Loss: 11.8533, F1 Micro: 0.2917, F1 Macro: 0.1962, Accuracy: 0.2917\n","Epoch 5, Train Loss: 19.7179, Val Loss: 27.9616, F1 Micro: 0.1354, F1 Macro: 0.1160, Accuracy: 0.1354\n","Epoch 6, Train Loss: 25.2857, Val Loss: 31.6533, F1 Micro: 0.1354, F1 Macro: 0.0833, Accuracy: 0.1354\n","Epoch 7, Train Loss: 25.5105, Val Loss: 13.7396, F1 Micro: 0.2604, F1 Macro: 0.1784, Accuracy: 0.2604\n","Epoch 8, Train Loss: 22.5055, Val Loss: 18.6537, F1 Micro: 0.2292, F1 Macro: 0.1095, Accuracy: 0.2292\n","Epoch 9, Train Loss: 22.6958, Val Loss: 13.1405, F1 Micro: 0.1875, F1 Macro: 0.1781, Accuracy: 0.1875\n","Epoch 10, Train Loss: 20.5184, Val Loss: 21.6723, F1 Micro: 0.1354, F1 Macro: 0.0762, Accuracy: 0.1354\n","Epoch 11, Train Loss: 16.9755, Val Loss: 20.2409, F1 Micro: 0.2083, F1 Macro: 0.1398, Accuracy: 0.2083\n","Epoch 12, Train Loss: 21.1363, Val Loss: 9.1539, F1 Micro: 0.1250, F1 Macro: 0.1006, Accuracy: 0.1250\n","Epoch 13, Train Loss: 22.6666, Val Loss: 14.6676, F1 Micro: 0.2812, F1 Macro: 0.2029, Accuracy: 0.2812\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 62.3499, Val Loss: 45.5006, F1 Micro: 0.1667, F1 Macro: 0.1523, Accuracy: 0.1667\n","Epoch 2, Train Loss: 33.4598, Val Loss: 29.1560, F1 Micro: 0.1979, F1 Macro: 0.1005, Accuracy: 0.1979\n","Epoch 3, Train Loss: 27.2203, Val Loss: 78.5392, F1 Micro: 0.1667, F1 Macro: 0.1011, Accuracy: 0.1667\n","Epoch 4, Train Loss: 37.5914, Val Loss: 29.7218, F1 Micro: 0.1875, F1 Macro: 0.0776, Accuracy: 0.1875\n","Epoch 5, Train Loss: 24.6321, Val Loss: 14.4199, F1 Micro: 0.2292, F1 Macro: 0.1629, Accuracy: 0.2292\n","Epoch 6, Train Loss: 21.8540, Val Loss: 15.1361, F1 Micro: 0.3229, F1 Macro: 0.2065, Accuracy: 0.3229\n","Epoch 7, Train Loss: 26.4502, Val Loss: 29.3590, F1 Micro: 0.1042, F1 Macro: 0.0670, Accuracy: 0.1042\n","Epoch 8, Train Loss: 17.4310, Val Loss: 16.0894, F1 Micro: 0.2812, F1 Macro: 0.1324, Accuracy: 0.2812\n","Epoch 9, Train Loss: 23.1561, Val Loss: 30.5706, F1 Micro: 0.2396, F1 Macro: 0.1810, Accuracy: 0.2396\n","Epoch 10, Train Loss: 36.3639, Val Loss: 23.5517, F1 Micro: 0.1667, F1 Macro: 0.1400, Accuracy: 0.1667\n","Epoch 11, Train Loss: 27.0001, Val Loss: 72.4658, F1 Micro: 0.2812, F1 Macro: 0.1364, Accuracy: 0.2812\n","Epoch 12, Train Loss: 25.4936, Val Loss: 20.9685, F1 Micro: 0.2708, F1 Macro: 0.1891, Accuracy: 0.2708\n","Epoch 13, Train Loss: 21.4926, Val Loss: 24.2260, F1 Micro: 0.3646, F1 Macro: 0.2117, Accuracy: 0.3646\n","Epoch 14, Train Loss: 29.7628, Val Loss: 23.8581, F1 Micro: 0.1875, F1 Macro: 0.0979, Accuracy: 0.1875\n","Epoch 15, Train Loss: 17.2177, Val Loss: 16.0539, F1 Micro: 0.2083, F1 Macro: 0.1084, Accuracy: 0.2083\n","Epoch 16, Train Loss: 19.5292, Val Loss: 16.6645, F1 Micro: 0.3333, F1 Macro: 0.1968, Accuracy: 0.3333\n","Epoch 17, Train Loss: 18.5931, Val Loss: 19.3404, F1 Micro: 0.2500, F1 Macro: 0.1767, Accuracy: 0.2500\n","Epoch 18, Train Loss: 17.0648, Val Loss: 13.7855, F1 Micro: 0.2500, F1 Macro: 0.1530, Accuracy: 0.2500\n","Epoch 19, Train Loss: 18.4979, Val Loss: 7.4660, F1 Micro: 0.3438, F1 Macro: 0.2642, Accuracy: 0.3438\n","Epoch 20, Train Loss: 19.8179, Val Loss: 9.8557, F1 Micro: 0.1771, F1 Macro: 0.1180, Accuracy: 0.1771\n","Epoch 21, Train Loss: 12.8669, Val Loss: 20.2635, F1 Micro: 0.2917, F1 Macro: 0.2236, Accuracy: 0.2917\n","Epoch 22, Train Loss: 17.6770, Val Loss: 12.5859, F1 Micro: 0.2604, F1 Macro: 0.2081, Accuracy: 0.2604\n","Epoch 23, Train Loss: 13.9029, Val Loss: 13.2994, F1 Micro: 0.1979, F1 Macro: 0.1400, Accuracy: 0.1979\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 42.2281, Val Loss: 25.3800, F1 Micro: 0.1146, F1 Macro: 0.0691, Accuracy: 0.1146\n","Epoch 2, Train Loss: 35.3393, Val Loss: 13.0103, F1 Micro: 0.1771, F1 Macro: 0.0897, Accuracy: 0.1771\n","Epoch 3, Train Loss: 25.3507, Val Loss: 43.9480, F1 Micro: 0.1875, F1 Macro: 0.0526, Accuracy: 0.1875\n","Epoch 4, Train Loss: 47.3071, Val Loss: 58.3076, F1 Micro: 0.1562, F1 Macro: 0.0636, Accuracy: 0.1562\n","Epoch 5, Train Loss: 36.4875, Val Loss: 33.4923, F1 Micro: 0.1875, F1 Macro: 0.1051, Accuracy: 0.1875\n","Epoch 6, Train Loss: 27.4473, Val Loss: 13.8235, F1 Micro: 0.2083, F1 Macro: 0.1410, Accuracy: 0.2083\n","Epoch 7, Train Loss: 26.0751, Val Loss: 20.6396, F1 Micro: 0.1771, F1 Macro: 0.1231, Accuracy: 0.1771\n","Epoch 8, Train Loss: 17.8912, Val Loss: 27.6664, F1 Micro: 0.1771, F1 Macro: 0.0681, Accuracy: 0.1771\n","Epoch 9, Train Loss: 28.6725, Val Loss: 24.6362, F1 Micro: 0.2500, F1 Macro: 0.1735, Accuracy: 0.2500\n","Epoch 10, Train Loss: 28.2640, Val Loss: 18.5172, F1 Micro: 0.2396, F1 Macro: 0.1495, Accuracy: 0.2396\n","Epoch 11, Train Loss: 15.5261, Val Loss: 13.2305, F1 Micro: 0.2917, F1 Macro: 0.2531, Accuracy: 0.2917\n","Epoch 12, Train Loss: 14.4573, Val Loss: 31.1962, F1 Micro: 0.2188, F1 Macro: 0.1506, Accuracy: 0.2188\n","Epoch 13, Train Loss: 23.0659, Val Loss: 28.2956, F1 Micro: 0.1979, F1 Macro: 0.1106, Accuracy: 0.1979\n","Epoch 14, Train Loss: 24.3309, Val Loss: 17.6550, F1 Micro: 0.2188, F1 Macro: 0.1554, Accuracy: 0.2188\n","Epoch 15, Train Loss: 25.2717, Val Loss: 14.7113, F1 Micro: 0.1562, F1 Macro: 0.0459, Accuracy: 0.1562\n","Epoch 16, Train Loss: 26.7877, Val Loss: 28.3219, F1 Micro: 0.2396, F1 Macro: 0.1810, Accuracy: 0.2396\n","Epoch 17, Train Loss: 23.5743, Val Loss: 25.7890, F1 Micro: 0.1667, F1 Macro: 0.0489, Accuracy: 0.1667\n","Epoch 18, Train Loss: 22.7952, Val Loss: 45.8731, F1 Micro: 0.2500, F1 Macro: 0.1761, Accuracy: 0.2500\n","Epoch 19, Train Loss: 27.1969, Val Loss: 42.1769, F1 Micro: 0.1667, F1 Macro: 0.0946, Accuracy: 0.1667\n","Epoch 20, Train Loss: 23.1439, Val Loss: 17.5511, F1 Micro: 0.2812, F1 Macro: 0.2339, Accuracy: 0.2812\n","Epoch 21, Train Loss: 19.7819, Val Loss: 21.8143, F1 Micro: 0.2500, F1 Macro: 0.1699, Accuracy: 0.2500\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 89.4098, Val Loss: 38.6453, F1 Micro: 0.2188, F1 Macro: 0.0609, Accuracy: 0.2188\n","Epoch 2, Train Loss: 28.0391, Val Loss: 21.6738, F1 Micro: 0.2396, F1 Macro: 0.1768, Accuracy: 0.2396\n","Epoch 3, Train Loss: 22.3815, Val Loss: 20.4646, F1 Micro: 0.1875, F1 Macro: 0.1048, Accuracy: 0.1875\n","Epoch 4, Train Loss: 20.2647, Val Loss: 26.5578, F1 Micro: 0.1667, F1 Macro: 0.0722, Accuracy: 0.1667\n","Epoch 5, Train Loss: 22.3552, Val Loss: 28.6809, F1 Micro: 0.1667, F1 Macro: 0.0781, Accuracy: 0.1667\n","Epoch 6, Train Loss: 29.8591, Val Loss: 40.4084, F1 Micro: 0.1562, F1 Macro: 0.0472, Accuracy: 0.1562\n","Epoch 7, Train Loss: 36.1993, Val Loss: 73.1308, F1 Micro: 0.2083, F1 Macro: 0.1357, Accuracy: 0.2083\n","Epoch 8, Train Loss: 35.4373, Val Loss: 26.0201, F1 Micro: 0.2083, F1 Macro: 0.1126, Accuracy: 0.2083\n","Epoch 9, Train Loss: 19.9081, Val Loss: 16.2123, F1 Micro: 0.2812, F1 Macro: 0.1529, Accuracy: 0.2812\n","Epoch 10, Train Loss: 19.4058, Val Loss: 14.8546, F1 Micro: 0.1875, F1 Macro: 0.1140, Accuracy: 0.1875\n","Epoch 11, Train Loss: 15.6128, Val Loss: 13.2493, F1 Micro: 0.2500, F1 Macro: 0.1823, Accuracy: 0.2500\n","Epoch 12, Train Loss: 23.8765, Val Loss: 14.9066, F1 Micro: 0.1979, F1 Macro: 0.1150, Accuracy: 0.1979\n","Epoch 13, Train Loss: 18.3800, Val Loss: 27.1307, F1 Micro: 0.2396, F1 Macro: 0.1599, Accuracy: 0.2396\n","Epoch 14, Train Loss: 23.7695, Val Loss: 16.3766, F1 Micro: 0.2188, F1 Macro: 0.1089, Accuracy: 0.2188\n","Epoch 15, Train Loss: 22.7452, Val Loss: 17.0069, F1 Micro: 0.1875, F1 Macro: 0.1330, Accuracy: 0.1875\n","Epoch 16, Train Loss: 21.2390, Val Loss: 33.0815, F1 Micro: 0.1667, F1 Macro: 0.0846, Accuracy: 0.1667\n","Epoch 17, Train Loss: 31.9879, Val Loss: 20.1859, F1 Micro: 0.2500, F1 Macro: 0.1621, Accuracy: 0.2500\n","Epoch 18, Train Loss: 17.0027, Val Loss: 9.0773, F1 Micro: 0.2917, F1 Macro: 0.2198, Accuracy: 0.2917\n","Epoch 19, Train Loss: 17.9971, Val Loss: 18.4712, F1 Micro: 0.2812, F1 Macro: 0.1972, Accuracy: 0.2812\n","Epoch 20, Train Loss: 19.9981, Val Loss: 21.6961, F1 Micro: 0.2188, F1 Macro: 0.1240, Accuracy: 0.2188\n","Epoch 21, Train Loss: 23.0445, Val Loss: 7.0902, F1 Micro: 0.3542, F1 Macro: 0.3245, Accuracy: 0.3542\n","Epoch 22, Train Loss: 17.0177, Val Loss: 14.8941, F1 Micro: 0.2188, F1 Macro: 0.1333, Accuracy: 0.2188\n","Epoch 23, Train Loss: 21.9595, Val Loss: 21.3292, F1 Micro: 0.2708, F1 Macro: 0.1546, Accuracy: 0.2708\n","Epoch 24, Train Loss: 15.0370, Val Loss: 11.3031, F1 Micro: 0.2812, F1 Macro: 0.1703, Accuracy: 0.2812\n","Epoch 25, Train Loss: 20.1698, Val Loss: 11.4387, F1 Micro: 0.2292, F1 Macro: 0.1732, Accuracy: 0.2292\n","Epoch 26, Train Loss: 18.2862, Val Loss: 12.1146, F1 Micro: 0.2188, F1 Macro: 0.1419, Accuracy: 0.2188\n","Epoch 27, Train Loss: 17.2849, Val Loss: 18.9659, F1 Micro: 0.3438, F1 Macro: 0.2890, Accuracy: 0.3438\n","Epoch 28, Train Loss: 16.4057, Val Loss: 13.5767, F1 Micro: 0.2292, F1 Macro: 0.1540, Accuracy: 0.2292\n","Epoch 29, Train Loss: 10.5813, Val Loss: 6.5010, F1 Micro: 0.2292, F1 Macro: 0.1952, Accuracy: 0.2292\n","Epoch 30, Train Loss: 16.0683, Val Loss: 15.2345, F1 Micro: 0.2812, F1 Macro: 0.1693, Accuracy: 0.2812\n","Epoch 31, Train Loss: 17.8189, Val Loss: 23.6132, F1 Micro: 0.2500, F1 Macro: 0.1855, Accuracy: 0.2500\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.32916666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 60.0281, Val Loss: 24.5428, F1 Micro: 0.3021, F1 Macro: 0.2038, Accuracy: 0.3021\n","Epoch 2, Train Loss: 25.7000, Val Loss: 10.2203, F1 Micro: 0.2500, F1 Macro: 0.1500, Accuracy: 0.2500\n","Epoch 3, Train Loss: 25.1557, Val Loss: 49.3628, F1 Micro: 0.1979, F1 Macro: 0.1057, Accuracy: 0.1979\n","Epoch 4, Train Loss: 30.5271, Val Loss: 15.3445, F1 Micro: 0.2500, F1 Macro: 0.1193, Accuracy: 0.2500\n","Epoch 5, Train Loss: 29.7285, Val Loss: 44.4286, F1 Micro: 0.1667, F1 Macro: 0.0614, Accuracy: 0.1667\n","Epoch 6, Train Loss: 38.6740, Val Loss: 33.7640, F1 Micro: 0.1562, F1 Macro: 0.0640, Accuracy: 0.1562\n","Epoch 7, Train Loss: 16.4746, Val Loss: 23.8039, F1 Micro: 0.1875, F1 Macro: 0.0818, Accuracy: 0.1875\n","Epoch 8, Train Loss: 22.2931, Val Loss: 24.1743, F1 Micro: 0.2604, F1 Macro: 0.1365, Accuracy: 0.2604\n","Epoch 9, Train Loss: 16.5485, Val Loss: 28.5915, F1 Micro: 0.3021, F1 Macro: 0.2129, Accuracy: 0.3021\n","Epoch 10, Train Loss: 36.9176, Val Loss: 17.9431, F1 Micro: 0.2917, F1 Macro: 0.2287, Accuracy: 0.2917\n","Epoch 11, Train Loss: 27.3290, Val Loss: 21.9585, F1 Micro: 0.2604, F1 Macro: 0.2068, Accuracy: 0.2604\n","Epoch 12, Train Loss: 17.1438, Val Loss: 18.1169, F1 Micro: 0.2708, F1 Macro: 0.2221, Accuracy: 0.2708\n","Epoch 13, Train Loss: 18.3136, Val Loss: 9.2552, F1 Micro: 0.2812, F1 Macro: 0.2334, Accuracy: 0.2812\n","Epoch 14, Train Loss: 20.8356, Val Loss: 22.0350, F1 Micro: 0.1979, F1 Macro: 0.0949, Accuracy: 0.1979\n","Epoch 15, Train Loss: 25.5509, Val Loss: 28.7356, F1 Micro: 0.2396, F1 Macro: 0.1819, Accuracy: 0.2396\n","Epoch 16, Train Loss: 16.8403, Val Loss: 10.0581, F1 Micro: 0.3021, F1 Macro: 0.2342, Accuracy: 0.3021\n","Epoch 17, Train Loss: 15.2012, Val Loss: 10.0826, F1 Micro: 0.2500, F1 Macro: 0.1871, Accuracy: 0.2500\n","Epoch 18, Train Loss: 24.1170, Val Loss: 24.4117, F1 Micro: 0.2292, F1 Macro: 0.2087, Accuracy: 0.2292\n","Epoch 19, Train Loss: 18.1565, Val Loss: 18.1435, F1 Micro: 0.2396, F1 Macro: 0.2017, Accuracy: 0.2396\n","Epoch 20, Train Loss: 16.1049, Val Loss: 10.9239, F1 Micro: 0.3125, F1 Macro: 0.2987, Accuracy: 0.3125\n","Epoch 21, Train Loss: 21.3907, Val Loss: 28.3479, F1 Micro: 0.2083, F1 Macro: 0.1700, Accuracy: 0.2083\n","Epoch 22, Train Loss: 24.8267, Val Loss: 45.5061, F1 Micro: 0.2292, F1 Macro: 0.1695, Accuracy: 0.2292\n","Epoch 23, Train Loss: 14.3377, Val Loss: 15.7211, F1 Micro: 0.3125, F1 Macro: 0.2088, Accuracy: 0.3125\n","Epoch 24, Train Loss: 13.9182, Val Loss: 9.4014, F1 Micro: 0.2812, F1 Macro: 0.2243, Accuracy: 0.2812\n","Epoch 25, Train Loss: 18.8101, Val Loss: 15.9962, F1 Micro: 0.2917, F1 Macro: 0.1900, Accuracy: 0.2917\n","Epoch 26, Train Loss: 15.8690, Val Loss: 35.1088, F1 Micro: 0.2083, F1 Macro: 0.1574, Accuracy: 0.2083\n","Epoch 27, Train Loss: 17.2165, Val Loss: 19.5404, F1 Micro: 0.2292, F1 Macro: 0.1336, Accuracy: 0.2292\n","Epoch 28, Train Loss: 15.4906, Val Loss: 17.2905, F1 Micro: 0.1979, F1 Macro: 0.1697, Accuracy: 0.1979\n","Epoch 29, Train Loss: 13.4776, Val Loss: 11.5495, F1 Micro: 0.2812, F1 Macro: 0.1688, Accuracy: 0.2812\n","Epoch 30, Train Loss: 20.1785, Val Loss: 28.6856, F1 Micro: 0.1667, F1 Macro: 0.1059, Accuracy: 0.1667\n","Epoch 31, Train Loss: 18.4596, Val Loss: 21.0514, F1 Micro: 0.2708, F1 Macro: 0.1655, Accuracy: 0.2708\n","Epoch 32, Train Loss: 19.3574, Val Loss: 15.4971, F1 Micro: 0.1979, F1 Macro: 0.1293, Accuracy: 0.1979\n","Epoch 33, Train Loss: 12.7436, Val Loss: 15.1499, F1 Micro: 0.1771, F1 Macro: 0.1097, Accuracy: 0.1771\n","Epoch 34, Train Loss: 14.8602, Val Loss: 11.4850, F1 Micro: 0.2188, F1 Macro: 0.1894, Accuracy: 0.2188\n","Epoch 35, Train Loss: 16.3340, Val Loss: 23.7722, F1 Micro: 0.2812, F1 Macro: 0.1890, Accuracy: 0.2812\n","Epoch 36, Train Loss: 16.5351, Val Loss: 24.9753, F1 Micro: 0.2188, F1 Macro: 0.1926, Accuracy: 0.2188\n","Epoch 37, Train Loss: 17.8504, Val Loss: 16.5264, F1 Micro: 0.3021, F1 Macro: 0.1973, Accuracy: 0.3021\n","Epoch 38, Train Loss: 20.0903, Val Loss: 42.2635, F1 Micro: 0.1771, F1 Macro: 0.1112, Accuracy: 0.1771\n","Epoch 39, Train Loss: 21.7842, Val Loss: 12.3773, F1 Micro: 0.3229, F1 Macro: 0.2881, Accuracy: 0.3229\n","Epoch 40, Train Loss: 13.0587, Val Loss: 14.6021, F1 Micro: 0.1771, F1 Macro: 0.1238, Accuracy: 0.1771\n","Epoch 41, Train Loss: 12.4052, Val Loss: 12.3241, F1 Micro: 0.2188, F1 Macro: 0.1546, Accuracy: 0.2188\n","Epoch 42, Train Loss: 13.7858, Val Loss: 15.3805, F1 Micro: 0.2812, F1 Macro: 0.1944, Accuracy: 0.2812\n","Epoch 43, Train Loss: 18.0949, Val Loss: 20.9185, F1 Micro: 0.1771, F1 Macro: 0.1168, Accuracy: 0.1771\n","Epoch 44, Train Loss: 15.3442, Val Loss: 13.5233, F1 Micro: 0.2396, F1 Macro: 0.2031, Accuracy: 0.2396\n","Epoch 45, Train Loss: 11.7185, Val Loss: 29.4923, F1 Micro: 0.2292, F1 Macro: 0.1712, Accuracy: 0.2292\n","Epoch 46, Train Loss: 18.3061, Val Loss: 10.2312, F1 Micro: 0.3021, F1 Macro: 0.2226, Accuracy: 0.3021\n","Epoch 47, Train Loss: 15.1623, Val Loss: 20.7283, F1 Micro: 0.2083, F1 Macro: 0.1053, Accuracy: 0.2083\n","Epoch 48, Train Loss: 15.0503, Val Loss: 11.9600, F1 Micro: 0.2604, F1 Macro: 0.2251, Accuracy: 0.2604\n","Epoch 49, Train Loss: 13.4025, Val Loss: 12.5027, F1 Micro: 0.2292, F1 Macro: 0.2029, Accuracy: 0.2292\n","Epoch 50, Train Loss: 10.9442, Val Loss: 8.6767, F1 Micro: 0.2708, F1 Macro: 0.2114, Accuracy: 0.2708\n","Epoch 51, Train Loss: 9.2207, Val Loss: 8.7080, F1 Micro: 0.2812, F1 Macro: 0.2419, Accuracy: 0.2812\n","Epoch 52, Train Loss: 15.3301, Val Loss: 9.5912, F1 Micro: 0.2812, F1 Macro: 0.2025, Accuracy: 0.2812\n","Epoch 53, Train Loss: 13.3196, Val Loss: 10.3777, F1 Micro: 0.1875, F1 Macro: 0.1605, Accuracy: 0.1875\n","Epoch 54, Train Loss: 10.8183, Val Loss: 13.8792, F1 Micro: 0.2396, F1 Macro: 0.1698, Accuracy: 0.2396\n","Epoch 55, Train Loss: 15.4128, Val Loss: 17.3248, F1 Micro: 0.2396, F1 Macro: 0.2187, Accuracy: 0.2396\n","Epoch 56, Train Loss: 10.1285, Val Loss: 14.2239, F1 Micro: 0.2604, F1 Macro: 0.2097, Accuracy: 0.2604\n","Epoch 57, Train Loss: 10.9205, Val Loss: 10.7477, F1 Micro: 0.3229, F1 Macro: 0.2196, Accuracy: 0.3229\n","Epoch 58, Train Loss: 12.1544, Val Loss: 13.9051, F1 Micro: 0.1875, F1 Macro: 0.1145, Accuracy: 0.1875\n","Epoch 59, Train Loss: 11.0114, Val Loss: 8.1543, F1 Micro: 0.3125, F1 Macro: 0.2129, Accuracy: 0.3125\n","Epoch 60, Train Loss: 11.5617, Val Loss: 9.8941, F1 Micro: 0.2396, F1 Macro: 0.1803, Accuracy: 0.2396\n","Epoch 61, Train Loss: 6.8523, Val Loss: 5.1394, F1 Micro: 0.2917, F1 Macro: 0.2352, Accuracy: 0.2917\n","Epoch 62, Train Loss: 8.9954, Val Loss: 11.6768, F1 Micro: 0.1771, F1 Macro: 0.1193, Accuracy: 0.1771\n","Epoch 63, Train Loss: 10.2806, Val Loss: 11.2652, F1 Micro: 0.3542, F1 Macro: 0.3460, Accuracy: 0.3542\n","Epoch 64, Train Loss: 11.5697, Val Loss: 17.8218, F1 Micro: 0.2188, F1 Macro: 0.1129, Accuracy: 0.2188\n","Epoch 65, Train Loss: 17.6482, Val Loss: 26.6014, F1 Micro: 0.2604, F1 Macro: 0.1789, Accuracy: 0.2604\n","Epoch 66, Train Loss: 9.6984, Val Loss: 8.7223, F1 Micro: 0.2083, F1 Macro: 0.1783, Accuracy: 0.2083\n","Epoch 67, Train Loss: 8.8321, Val Loss: 7.0896, F1 Micro: 0.2500, F1 Macro: 0.1873, Accuracy: 0.2500\n","Epoch 68, Train Loss: 9.1034, Val Loss: 16.3182, F1 Micro: 0.2396, F1 Macro: 0.1962, Accuracy: 0.2396\n","Epoch 69, Train Loss: 9.0821, Val Loss: 8.1009, F1 Micro: 0.2083, F1 Macro: 0.1476, Accuracy: 0.2083\n","Epoch 70, Train Loss: 12.1426, Val Loss: 14.2037, F1 Micro: 0.2604, F1 Macro: 0.1977, Accuracy: 0.2604\n","Epoch 71, Train Loss: 9.9906, Val Loss: 4.8835, F1 Micro: 0.3750, F1 Macro: 0.3166, Accuracy: 0.3750\n","Epoch 72, Train Loss: 12.0277, Val Loss: 18.6797, F1 Micro: 0.2292, F1 Macro: 0.1397, Accuracy: 0.2292\n","Epoch 73, Train Loss: 11.3299, Val Loss: 9.7448, F1 Micro: 0.3125, F1 Macro: 0.2082, Accuracy: 0.3125\n","Epoch 74, Train Loss: 8.0059, Val Loss: 15.6033, F1 Micro: 0.2188, F1 Macro: 0.1452, Accuracy: 0.2188\n","Epoch 75, Train Loss: 8.6143, Val Loss: 9.5810, F1 Micro: 0.2396, F1 Macro: 0.1501, Accuracy: 0.2396\n","Epoch 76, Train Loss: 9.2271, Val Loss: 12.8086, F1 Micro: 0.2188, F1 Macro: 0.1751, Accuracy: 0.2188\n","Epoch 77, Train Loss: 11.4148, Val Loss: 22.9769, F1 Micro: 0.1771, F1 Macro: 0.1186, Accuracy: 0.1771\n","Epoch 78, Train Loss: 11.2709, Val Loss: 14.0348, F1 Micro: 0.2083, F1 Macro: 0.1809, Accuracy: 0.2083\n","Epoch 79, Train Loss: 11.1797, Val Loss: 10.9232, F1 Micro: 0.2604, F1 Macro: 0.2209, Accuracy: 0.2604\n","Epoch 80, Train Loss: 7.1014, Val Loss: 8.0482, F1 Micro: 0.3333, F1 Macro: 0.2343, Accuracy: 0.3333\n","Epoch 81, Train Loss: 7.2294, Val Loss: 10.3992, F1 Micro: 0.1979, F1 Macro: 0.1646, Accuracy: 0.1979\n","Epoch 82, Train Loss: 8.0600, Val Loss: 8.6106, F1 Micro: 0.2396, F1 Macro: 0.1555, Accuracy: 0.2396\n","Epoch 83, Train Loss: 11.6576, Val Loss: 9.3459, F1 Micro: 0.3125, F1 Macro: 0.2684, Accuracy: 0.3125\n","Epoch 84, Train Loss: 11.1611, Val Loss: 6.5380, F1 Micro: 0.3125, F1 Macro: 0.2547, Accuracy: 0.3125\n","Epoch 85, Train Loss: 8.0897, Val Loss: 7.1385, F1 Micro: 0.3333, F1 Macro: 0.2986, Accuracy: 0.3333\n","Epoch 86, Train Loss: 7.9642, Val Loss: 7.8754, F1 Micro: 0.2188, F1 Macro: 0.1469, Accuracy: 0.2188\n","Epoch 87, Train Loss: 8.4785, Val Loss: 6.3719, F1 Micro: 0.2396, F1 Macro: 0.1677, Accuracy: 0.2396\n","Epoch 88, Train Loss: 9.2510, Val Loss: 12.2301, F1 Micro: 0.2708, F1 Macro: 0.1784, Accuracy: 0.2708\n","Epoch 89, Train Loss: 8.4943, Val Loss: 8.1566, F1 Micro: 0.3021, F1 Macro: 0.2375, Accuracy: 0.3021\n","Epoch 90, Train Loss: 7.5200, Val Loss: 9.1622, F1 Micro: 0.3229, F1 Macro: 0.2939, Accuracy: 0.3229\n","Epoch 91, Train Loss: 7.2587, Val Loss: 6.2987, F1 Micro: 0.3333, F1 Macro: 0.2820, Accuracy: 0.3333\n","Epoch 92, Train Loss: 8.2438, Val Loss: 6.3238, F1 Micro: 0.2500, F1 Macro: 0.1996, Accuracy: 0.2500\n","Epoch 93, Train Loss: 7.8101, Val Loss: 5.3620, F1 Micro: 0.3333, F1 Macro: 0.3248, Accuracy: 0.3333\n","Epoch 94, Train Loss: 7.0831, Val Loss: 6.6578, F1 Micro: 0.3438, F1 Macro: 0.2697, Accuracy: 0.3438\n","Epoch 95, Train Loss: 9.4545, Val Loss: 10.1670, F1 Micro: 0.2083, F1 Macro: 0.1621, Accuracy: 0.2083\n","Epoch 96, Train Loss: 7.4138, Val Loss: 15.0548, F1 Micro: 0.1875, F1 Macro: 0.1772, Accuracy: 0.1875\n","Epoch 97, Train Loss: 8.1151, Val Loss: 8.9112, F1 Micro: 0.2188, F1 Macro: 0.1648, Accuracy: 0.2188\n","Epoch 98, Train Loss: 9.9056, Val Loss: 8.8392, F1 Micro: 0.3229, F1 Macro: 0.2668, Accuracy: 0.3229\n","Epoch 99, Train Loss: 5.9669, Val Loss: 8.6077, F1 Micro: 0.3854, F1 Macro: 0.3207, Accuracy: 0.3854\n","Epoch 100, Train Loss: 9.0006, Val Loss: 9.0589, F1 Micro: 0.3021, F1 Macro: 0.1916, Accuracy: 0.3021\n","Epoch 101, Train Loss: 11.3073, Val Loss: 6.4456, F1 Micro: 0.2396, F1 Macro: 0.2212, Accuracy: 0.2396\n","Epoch 102, Train Loss: 7.7087, Val Loss: 4.7894, F1 Micro: 0.2708, F1 Macro: 0.2012, Accuracy: 0.2708\n","Epoch 103, Train Loss: 6.0430, Val Loss: 9.4880, F1 Micro: 0.1875, F1 Macro: 0.1488, Accuracy: 0.1875\n","Epoch 104, Train Loss: 5.0294, Val Loss: 6.1302, F1 Micro: 0.2292, F1 Macro: 0.1999, Accuracy: 0.2292\n","Epoch 105, Train Loss: 4.3809, Val Loss: 9.5684, F1 Micro: 0.2708, F1 Macro: 0.1619, Accuracy: 0.2708\n","Epoch 106, Train Loss: 7.1464, Val Loss: 8.5069, F1 Micro: 0.2812, F1 Macro: 0.1472, Accuracy: 0.2812\n","Epoch 107, Train Loss: 10.1632, Val Loss: 15.1686, F1 Micro: 0.1875, F1 Macro: 0.0867, Accuracy: 0.1875\n","Epoch 108, Train Loss: 8.8855, Val Loss: 8.2634, F1 Micro: 0.3125, F1 Macro: 0.2753, Accuracy: 0.3125\n","Epoch 109, Train Loss: 10.0163, Val Loss: 5.4644, F1 Micro: 0.2396, F1 Macro: 0.1947, Accuracy: 0.2396\n","Epoch 110, Train Loss: 4.9940, Val Loss: 5.1284, F1 Micro: 0.2604, F1 Macro: 0.1933, Accuracy: 0.2604\n","Epoch 111, Train Loss: 5.8010, Val Loss: 4.5771, F1 Micro: 0.3333, F1 Macro: 0.2774, Accuracy: 0.3333\n","Epoch 112, Train Loss: 4.7417, Val Loss: 10.2896, F1 Micro: 0.1979, F1 Macro: 0.1042, Accuracy: 0.1979\n","Epoch 113, Train Loss: 6.9493, Val Loss: 4.3732, F1 Micro: 0.3333, F1 Macro: 0.3007, Accuracy: 0.3333\n","Epoch 114, Train Loss: 4.7231, Val Loss: 11.0253, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 115, Train Loss: 8.4243, Val Loss: 6.1638, F1 Micro: 0.2708, F1 Macro: 0.2510, Accuracy: 0.2708\n","Epoch 116, Train Loss: 4.0462, Val Loss: 7.2212, F1 Micro: 0.2500, F1 Macro: 0.1659, Accuracy: 0.2500\n","Epoch 117, Train Loss: 4.9276, Val Loss: 3.8280, F1 Micro: 0.3646, F1 Macro: 0.3523, Accuracy: 0.3646\n","Epoch 118, Train Loss: 6.7075, Val Loss: 8.3699, F1 Micro: 0.2708, F1 Macro: 0.1853, Accuracy: 0.2708\n","Epoch 119, Train Loss: 6.0567, Val Loss: 8.2905, F1 Micro: 0.2083, F1 Macro: 0.1469, Accuracy: 0.2083\n","Epoch 120, Train Loss: 5.0535, Val Loss: 8.0017, F1 Micro: 0.1771, F1 Macro: 0.1410, Accuracy: 0.1771\n","Epoch 121, Train Loss: 6.4782, Val Loss: 4.0639, F1 Micro: 0.3854, F1 Macro: 0.3548, Accuracy: 0.3854\n","Epoch 122, Train Loss: 6.2259, Val Loss: 7.8522, F1 Micro: 0.2292, F1 Macro: 0.1833, Accuracy: 0.2292\n","Epoch 123, Train Loss: 4.7896, Val Loss: 5.3531, F1 Micro: 0.2812, F1 Macro: 0.2148, Accuracy: 0.2812\n","Epoch 124, Train Loss: 5.4439, Val Loss: 7.3622, F1 Micro: 0.2500, F1 Macro: 0.2101, Accuracy: 0.2500\n","Epoch 125, Train Loss: 3.9922, Val Loss: 5.2315, F1 Micro: 0.3125, F1 Macro: 0.2016, Accuracy: 0.3125\n","Epoch 126, Train Loss: 5.0319, Val Loss: 4.9976, F1 Micro: 0.2604, F1 Macro: 0.2046, Accuracy: 0.2604\n","Epoch 127, Train Loss: 5.4862, Val Loss: 5.5559, F1 Micro: 0.1979, F1 Macro: 0.1660, Accuracy: 0.1979\n","Epoch 128, Train Loss: 5.5556, Val Loss: 6.5837, F1 Micro: 0.3229, F1 Macro: 0.2318, Accuracy: 0.3229\n","Epoch 129, Train Loss: 4.8077, Val Loss: 3.7753, F1 Micro: 0.2604, F1 Macro: 0.2532, Accuracy: 0.2604\n","Epoch 130, Train Loss: 4.0144, Val Loss: 5.1102, F1 Micro: 0.3021, F1 Macro: 0.2726, Accuracy: 0.3021\n","Epoch 131, Train Loss: 5.6893, Val Loss: 3.4602, F1 Micro: 0.2917, F1 Macro: 0.2656, Accuracy: 0.2917\n","Epoch 132, Train Loss: 4.2356, Val Loss: 5.4466, F1 Micro: 0.2812, F1 Macro: 0.2475, Accuracy: 0.2812\n","Epoch 133, Train Loss: 4.2709, Val Loss: 7.9931, F1 Micro: 0.1562, F1 Macro: 0.0856, Accuracy: 0.1562\n","Epoch 134, Train Loss: 4.0831, Val Loss: 4.1042, F1 Micro: 0.2188, F1 Macro: 0.2115, Accuracy: 0.2188\n","Epoch 135, Train Loss: 4.3778, Val Loss: 4.2763, F1 Micro: 0.2917, F1 Macro: 0.2685, Accuracy: 0.2917\n","Epoch 136, Train Loss: 6.0824, Val Loss: 10.4279, F1 Micro: 0.3646, F1 Macro: 0.2645, Accuracy: 0.3646\n","Epoch 137, Train Loss: 5.2144, Val Loss: 6.9705, F1 Micro: 0.1979, F1 Macro: 0.1404, Accuracy: 0.1979\n","Epoch 138, Train Loss: 4.3541, Val Loss: 4.1866, F1 Micro: 0.3229, F1 Macro: 0.2413, Accuracy: 0.3229\n","Epoch 139, Train Loss: 5.4757, Val Loss: 6.9647, F1 Micro: 0.3229, F1 Macro: 0.2982, Accuracy: 0.3229\n","Epoch 140, Train Loss: 4.9477, Val Loss: 3.8213, F1 Micro: 0.3021, F1 Macro: 0.2873, Accuracy: 0.3021\n","Epoch 141, Train Loss: 4.0707, Val Loss: 4.5248, F1 Micro: 0.1875, F1 Macro: 0.1622, Accuracy: 0.1875\n","Epoch 142, Train Loss: 4.6979, Val Loss: 7.2417, F1 Micro: 0.2604, F1 Macro: 0.2338, Accuracy: 0.2604\n","Epoch 143, Train Loss: 4.8538, Val Loss: 5.6307, F1 Micro: 0.2500, F1 Macro: 0.1503, Accuracy: 0.2500\n","Epoch 144, Train Loss: 3.1568, Val Loss: 3.7572, F1 Micro: 0.2708, F1 Macro: 0.1982, Accuracy: 0.2708\n","Epoch 145, Train Loss: 3.7394, Val Loss: 3.7405, F1 Micro: 0.3125, F1 Macro: 0.2378, Accuracy: 0.3125\n","Epoch 146, Train Loss: 4.7628, Val Loss: 7.3787, F1 Micro: 0.3542, F1 Macro: 0.2565, Accuracy: 0.3542\n","Epoch 147, Train Loss: 5.5075, Val Loss: 4.2621, F1 Micro: 0.2604, F1 Macro: 0.2343, Accuracy: 0.2604\n","Epoch 148, Train Loss: 3.4896, Val Loss: 5.6550, F1 Micro: 0.2708, F1 Macro: 0.2268, Accuracy: 0.2708\n","Epoch 149, Train Loss: 4.8097, Val Loss: 3.6679, F1 Micro: 0.3750, F1 Macro: 0.3340, Accuracy: 0.3750\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 70.8266, Val Loss: 40.9973, F1 Micro: 0.2188, F1 Macro: 0.1669, Accuracy: 0.2188\n","Epoch 2, Train Loss: 28.1996, Val Loss: 21.3397, F1 Micro: 0.1667, F1 Macro: 0.1223, Accuracy: 0.1667\n","Epoch 3, Train Loss: 23.5170, Val Loss: 25.7482, F1 Micro: 0.3021, F1 Macro: 0.2052, Accuracy: 0.3021\n","Epoch 4, Train Loss: 25.9964, Val Loss: 34.6563, F1 Micro: 0.1146, F1 Macro: 0.0779, Accuracy: 0.1146\n","Epoch 5, Train Loss: 38.7899, Val Loss: 28.7360, F1 Micro: 0.2396, F1 Macro: 0.1292, Accuracy: 0.2396\n","Epoch 6, Train Loss: 28.0040, Val Loss: 17.0641, F1 Micro: 0.2604, F1 Macro: 0.2045, Accuracy: 0.2604\n","Epoch 7, Train Loss: 19.9186, Val Loss: 14.5128, F1 Micro: 0.1354, F1 Macro: 0.1005, Accuracy: 0.1354\n","Epoch 8, Train Loss: 26.5419, Val Loss: 15.4686, F1 Micro: 0.3125, F1 Macro: 0.2451, Accuracy: 0.3125\n","Epoch 9, Train Loss: 18.1352, Val Loss: 16.8659, F1 Micro: 0.3021, F1 Macro: 0.1944, Accuracy: 0.3021\n","Epoch 10, Train Loss: 18.8190, Val Loss: 31.8239, F1 Micro: 0.2083, F1 Macro: 0.1027, Accuracy: 0.2083\n","Epoch 11, Train Loss: 18.3632, Val Loss: 21.8233, F1 Micro: 0.1667, F1 Macro: 0.0932, Accuracy: 0.1667\n","Epoch 12, Train Loss: 20.7727, Val Loss: 27.9784, F1 Micro: 0.1771, F1 Macro: 0.1292, Accuracy: 0.1771\n","Epoch 13, Train Loss: 26.6820, Val Loss: 21.0541, F1 Micro: 0.2292, F1 Macro: 0.1430, Accuracy: 0.2292\n","Epoch 14, Train Loss: 25.7043, Val Loss: 25.0164, F1 Micro: 0.1458, F1 Macro: 0.0910, Accuracy: 0.1458\n","Epoch 15, Train Loss: 21.6327, Val Loss: 31.3820, F1 Micro: 0.2292, F1 Macro: 0.1356, Accuracy: 0.2292\n","Epoch 16, Train Loss: 21.9594, Val Loss: 33.8329, F1 Micro: 0.1354, F1 Macro: 0.0405, Accuracy: 0.1354\n","Epoch 17, Train Loss: 19.5173, Val Loss: 31.6642, F1 Micro: 0.2396, F1 Macro: 0.2017, Accuracy: 0.2396\n","Epoch 18, Train Loss: 20.7650, Val Loss: 11.0223, F1 Micro: 0.2812, F1 Macro: 0.1790, Accuracy: 0.2812\n","Epoch 19, Train Loss: 14.2407, Val Loss: 19.3745, F1 Micro: 0.1979, F1 Macro: 0.1295, Accuracy: 0.1979\n","Epoch 20, Train Loss: 16.1079, Val Loss: 5.8016, F1 Micro: 0.2500, F1 Macro: 0.2352, Accuracy: 0.2500\n","Epoch 21, Train Loss: 16.2843, Val Loss: 20.1360, F1 Micro: 0.1250, F1 Macro: 0.0637, Accuracy: 0.1250\n","Epoch 22, Train Loss: 26.2353, Val Loss: 20.6488, F1 Micro: 0.2396, F1 Macro: 0.1494, Accuracy: 0.2396\n","Epoch 23, Train Loss: 27.1185, Val Loss: 23.0764, F1 Micro: 0.2917, F1 Macro: 0.1462, Accuracy: 0.2917\n","Epoch 24, Train Loss: 18.0278, Val Loss: 19.3006, F1 Micro: 0.2604, F1 Macro: 0.1695, Accuracy: 0.2604\n","Epoch 25, Train Loss: 28.1552, Val Loss: 21.3342, F1 Micro: 0.1562, F1 Macro: 0.1205, Accuracy: 0.1562\n","Epoch 26, Train Loss: 18.1438, Val Loss: 20.8621, F1 Micro: 0.1250, F1 Macro: 0.0640, Accuracy: 0.1250\n","Epoch 27, Train Loss: 18.0120, Val Loss: 36.8116, F1 Micro: 0.2083, F1 Macro: 0.1367, Accuracy: 0.2083\n","Epoch 28, Train Loss: 26.7762, Val Loss: 26.5173, F1 Micro: 0.1771, F1 Macro: 0.1241, Accuracy: 0.1771\n","Epoch 29, Train Loss: 16.4470, Val Loss: 9.0959, F1 Micro: 0.4062, F1 Macro: 0.2861, Accuracy: 0.4062\n","Epoch 30, Train Loss: 14.7528, Val Loss: 16.6281, F1 Micro: 0.3125, F1 Macro: 0.1561, Accuracy: 0.3125\n","Epoch 31, Train Loss: 20.5552, Val Loss: 23.3831, F1 Micro: 0.2917, F1 Macro: 0.2066, Accuracy: 0.2917\n","Epoch 32, Train Loss: 19.7418, Val Loss: 36.5037, F1 Micro: 0.1979, F1 Macro: 0.1604, Accuracy: 0.1979\n","Epoch 33, Train Loss: 22.8521, Val Loss: 9.9540, F1 Micro: 0.3229, F1 Macro: 0.3012, Accuracy: 0.3229\n","Epoch 34, Train Loss: 22.5636, Val Loss: 30.1651, F1 Micro: 0.2292, F1 Macro: 0.1091, Accuracy: 0.2292\n","Epoch 35, Train Loss: 20.5856, Val Loss: 26.5400, F1 Micro: 0.2188, F1 Macro: 0.1687, Accuracy: 0.2188\n","Epoch 36, Train Loss: 25.4677, Val Loss: 17.5877, F1 Micro: 0.4375, F1 Macro: 0.3406, Accuracy: 0.4375\n","Epoch 37, Train Loss: 18.5675, Val Loss: 22.2923, F1 Micro: 0.1771, F1 Macro: 0.1310, Accuracy: 0.1771\n","Epoch 38, Train Loss: 13.8787, Val Loss: 15.0699, F1 Micro: 0.2812, F1 Macro: 0.1968, Accuracy: 0.2812\n","Epoch 39, Train Loss: 12.6997, Val Loss: 11.5729, F1 Micro: 0.2604, F1 Macro: 0.2039, Accuracy: 0.2604\n","Epoch 40, Train Loss: 11.0365, Val Loss: 9.7314, F1 Micro: 0.3438, F1 Macro: 0.2547, Accuracy: 0.3438\n","Epoch 41, Train Loss: 15.7400, Val Loss: 18.9407, F1 Micro: 0.3125, F1 Macro: 0.2782, Accuracy: 0.3125\n","Epoch 42, Train Loss: 16.5412, Val Loss: 12.3432, F1 Micro: 0.2708, F1 Macro: 0.1846, Accuracy: 0.2708\n","Epoch 43, Train Loss: 21.7520, Val Loss: 25.1897, F1 Micro: 0.1562, F1 Macro: 0.1059, Accuracy: 0.1562\n","Epoch 44, Train Loss: 22.6083, Val Loss: 21.3238, F1 Micro: 0.2604, F1 Macro: 0.1963, Accuracy: 0.2604\n","Epoch 45, Train Loss: 18.6358, Val Loss: 15.9855, F1 Micro: 0.2396, F1 Macro: 0.1556, Accuracy: 0.2396\n","Epoch 46, Train Loss: 16.9817, Val Loss: 11.4260, F1 Micro: 0.2812, F1 Macro: 0.1954, Accuracy: 0.2812\n","Epoch 47, Train Loss: 12.6500, Val Loss: 18.7701, F1 Micro: 0.2500, F1 Macro: 0.1382, Accuracy: 0.2500\n","Epoch 48, Train Loss: 11.3823, Val Loss: 14.0096, F1 Micro: 0.2708, F1 Macro: 0.2039, Accuracy: 0.2708\n","Epoch 49, Train Loss: 14.1640, Val Loss: 8.5534, F1 Micro: 0.3229, F1 Macro: 0.2481, Accuracy: 0.3229\n","Epoch 50, Train Loss: 16.7984, Val Loss: 25.4553, F1 Micro: 0.1875, F1 Macro: 0.1472, Accuracy: 0.1875\n","Epoch 51, Train Loss: 16.1879, Val Loss: 15.9863, F1 Micro: 0.2396, F1 Macro: 0.1459, Accuracy: 0.2396\n","Epoch 52, Train Loss: 14.3877, Val Loss: 20.8311, F1 Micro: 0.2917, F1 Macro: 0.2377, Accuracy: 0.2917\n","Epoch 53, Train Loss: 14.9923, Val Loss: 15.3955, F1 Micro: 0.3021, F1 Macro: 0.2052, Accuracy: 0.3021\n","Epoch 54, Train Loss: 12.7335, Val Loss: 4.8891, F1 Micro: 0.4479, F1 Macro: 0.3803, Accuracy: 0.4479\n","Epoch 55, Train Loss: 12.8170, Val Loss: 15.6003, F1 Micro: 0.3750, F1 Macro: 0.3148, Accuracy: 0.3750\n","Epoch 56, Train Loss: 12.6062, Val Loss: 16.7667, F1 Micro: 0.1562, F1 Macro: 0.0794, Accuracy: 0.1562\n","Epoch 57, Train Loss: 9.9063, Val Loss: 12.1807, F1 Micro: 0.2188, F1 Macro: 0.1097, Accuracy: 0.2188\n","Epoch 58, Train Loss: 13.9928, Val Loss: 14.6738, F1 Micro: 0.2396, F1 Macro: 0.1623, Accuracy: 0.2396\n","Epoch 59, Train Loss: 11.6874, Val Loss: 9.0786, F1 Micro: 0.4375, F1 Macro: 0.3702, Accuracy: 0.4375\n","Epoch 60, Train Loss: 12.7611, Val Loss: 14.9392, F1 Micro: 0.1354, F1 Macro: 0.0851, Accuracy: 0.1354\n","Epoch 61, Train Loss: 8.2570, Val Loss: 8.6616, F1 Micro: 0.2083, F1 Macro: 0.1566, Accuracy: 0.2083\n","Epoch 62, Train Loss: 8.1983, Val Loss: 13.2020, F1 Micro: 0.1667, F1 Macro: 0.1308, Accuracy: 0.1667\n","Epoch 63, Train Loss: 11.4814, Val Loss: 15.1398, F1 Micro: 0.3438, F1 Macro: 0.2867, Accuracy: 0.3438\n","Epoch 64, Train Loss: 8.5684, Val Loss: 8.1305, F1 Micro: 0.2917, F1 Macro: 0.2076, Accuracy: 0.2917\n","Epoch 65, Train Loss: 12.6213, Val Loss: 9.0940, F1 Micro: 0.2708, F1 Macro: 0.2217, Accuracy: 0.2708\n","Epoch 66, Train Loss: 8.1912, Val Loss: 9.4824, F1 Micro: 0.2812, F1 Macro: 0.2495, Accuracy: 0.2812\n","Epoch 67, Train Loss: 8.7907, Val Loss: 7.1207, F1 Micro: 0.3958, F1 Macro: 0.3009, Accuracy: 0.3958\n","Epoch 68, Train Loss: 8.7097, Val Loss: 10.0543, F1 Micro: 0.3021, F1 Macro: 0.2497, Accuracy: 0.3021\n","Epoch 69, Train Loss: 10.6025, Val Loss: 12.6334, F1 Micro: 0.2292, F1 Macro: 0.1196, Accuracy: 0.2292\n","Epoch 70, Train Loss: 9.2184, Val Loss: 6.9261, F1 Micro: 0.3021, F1 Macro: 0.1846, Accuracy: 0.3021\n","Epoch 71, Train Loss: 8.6982, Val Loss: 15.2105, F1 Micro: 0.1771, F1 Macro: 0.1321, Accuracy: 0.1771\n","Epoch 72, Train Loss: 10.6735, Val Loss: 8.4624, F1 Micro: 0.3958, F1 Macro: 0.2937, Accuracy: 0.3958\n","Epoch 73, Train Loss: 11.5137, Val Loss: 9.0869, F1 Micro: 0.3438, F1 Macro: 0.1965, Accuracy: 0.3438\n","Epoch 74, Train Loss: 11.6388, Val Loss: 7.7602, F1 Micro: 0.2604, F1 Macro: 0.2370, Accuracy: 0.2604\n","Epoch 75, Train Loss: 5.9958, Val Loss: 8.4903, F1 Micro: 0.2708, F1 Macro: 0.1913, Accuracy: 0.2708\n","Epoch 76, Train Loss: 12.0986, Val Loss: 13.9853, F1 Micro: 0.3125, F1 Macro: 0.2018, Accuracy: 0.3125\n","Epoch 77, Train Loss: 8.6167, Val Loss: 14.0848, F1 Micro: 0.3229, F1 Macro: 0.2030, Accuracy: 0.3229\n","Epoch 78, Train Loss: 9.0355, Val Loss: 4.9706, F1 Micro: 0.3854, F1 Macro: 0.3185, Accuracy: 0.3854\n","Epoch 79, Train Loss: 10.9957, Val Loss: 9.7933, F1 Micro: 0.2812, F1 Macro: 0.2454, Accuracy: 0.2812\n","Epoch 80, Train Loss: 11.2951, Val Loss: 8.7328, F1 Micro: 0.3229, F1 Macro: 0.2281, Accuracy: 0.3229\n","Epoch 81, Train Loss: 9.0084, Val Loss: 10.0072, F1 Micro: 0.2604, F1 Macro: 0.2162, Accuracy: 0.2604\n","Epoch 82, Train Loss: 7.3057, Val Loss: 13.0561, F1 Micro: 0.3958, F1 Macro: 0.3291, Accuracy: 0.3958\n","Epoch 83, Train Loss: 7.3356, Val Loss: 9.6912, F1 Micro: 0.2396, F1 Macro: 0.1980, Accuracy: 0.2396\n","Epoch 84, Train Loss: 9.2883, Val Loss: 12.7590, F1 Micro: 0.2396, F1 Macro: 0.1904, Accuracy: 0.2396\n","Epoch 85, Train Loss: 6.1031, Val Loss: 5.7997, F1 Micro: 0.2500, F1 Macro: 0.2261, Accuracy: 0.2500\n","Epoch 86, Train Loss: 7.9144, Val Loss: 7.1704, F1 Micro: 0.3438, F1 Macro: 0.2407, Accuracy: 0.3438\n","Epoch 87, Train Loss: 9.5233, Val Loss: 18.8895, F1 Micro: 0.2188, F1 Macro: 0.1238, Accuracy: 0.2188\n","Epoch 88, Train Loss: 7.1560, Val Loss: 8.2033, F1 Micro: 0.2604, F1 Macro: 0.1920, Accuracy: 0.2604\n","Epoch 89, Train Loss: 11.7045, Val Loss: 14.9774, F1 Micro: 0.3333, F1 Macro: 0.1930, Accuracy: 0.3333\n","Epoch 90, Train Loss: 12.4172, Val Loss: 6.4355, F1 Micro: 0.3750, F1 Macro: 0.2882, Accuracy: 0.3750\n","Epoch 91, Train Loss: 6.8096, Val Loss: 7.5942, F1 Micro: 0.3021, F1 Macro: 0.2245, Accuracy: 0.3021\n","Epoch 92, Train Loss: 7.9656, Val Loss: 8.5099, F1 Micro: 0.2812, F1 Macro: 0.2047, Accuracy: 0.2812\n","Epoch 93, Train Loss: 6.6549, Val Loss: 11.4499, F1 Micro: 0.1667, F1 Macro: 0.1516, Accuracy: 0.1667\n","Epoch 94, Train Loss: 8.6545, Val Loss: 5.6404, F1 Micro: 0.4062, F1 Macro: 0.3364, Accuracy: 0.4062\n","Epoch 95, Train Loss: 7.0030, Val Loss: 10.2972, F1 Micro: 0.2917, F1 Macro: 0.2395, Accuracy: 0.2917\n","Epoch 96, Train Loss: 6.0598, Val Loss: 7.4882, F1 Micro: 0.1667, F1 Macro: 0.1443, Accuracy: 0.1667\n","Epoch 97, Train Loss: 7.2592, Val Loss: 7.0293, F1 Micro: 0.2604, F1 Macro: 0.2714, Accuracy: 0.2604\n","Epoch 98, Train Loss: 8.9385, Val Loss: 8.9059, F1 Micro: 0.2812, F1 Macro: 0.1884, Accuracy: 0.2812\n","Epoch 99, Train Loss: 5.9607, Val Loss: 5.3643, F1 Micro: 0.3958, F1 Macro: 0.2928, Accuracy: 0.3958\n","Epoch 100, Train Loss: 6.3162, Val Loss: 9.2171, F1 Micro: 0.2396, F1 Macro: 0.2289, Accuracy: 0.2396\n","Epoch 101, Train Loss: 5.7823, Val Loss: 5.7290, F1 Micro: 0.2604, F1 Macro: 0.2141, Accuracy: 0.2604\n","Epoch 102, Train Loss: 5.5246, Val Loss: 7.9588, F1 Micro: 0.3021, F1 Macro: 0.2044, Accuracy: 0.3021\n","Epoch 103, Train Loss: 5.4295, Val Loss: 6.0922, F1 Micro: 0.3854, F1 Macro: 0.3847, Accuracy: 0.3854\n","Epoch 104, Train Loss: 8.2961, Val Loss: 10.7136, F1 Micro: 0.2188, F1 Macro: 0.1575, Accuracy: 0.2188\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 74.3018, Val Loss: 31.3017, F1 Micro: 0.1354, F1 Macro: 0.0793, Accuracy: 0.1354\n","Epoch 2, Train Loss: 30.2132, Val Loss: 14.5996, F1 Micro: 0.1667, F1 Macro: 0.1366, Accuracy: 0.1667\n","Epoch 3, Train Loss: 28.5142, Val Loss: 20.2108, F1 Micro: 0.2396, F1 Macro: 0.1436, Accuracy: 0.2396\n","Epoch 4, Train Loss: 21.7846, Val Loss: 20.0252, F1 Micro: 0.2500, F1 Macro: 0.1518, Accuracy: 0.2500\n","Epoch 5, Train Loss: 29.9466, Val Loss: 18.7980, F1 Micro: 0.2292, F1 Macro: 0.1586, Accuracy: 0.2292\n","Epoch 6, Train Loss: 23.2269, Val Loss: 24.2449, F1 Micro: 0.2292, F1 Macro: 0.0954, Accuracy: 0.2292\n","Epoch 7, Train Loss: 33.3445, Val Loss: 32.2182, F1 Micro: 0.2292, F1 Macro: 0.1813, Accuracy: 0.2292\n","Epoch 8, Train Loss: 29.0628, Val Loss: 28.7531, F1 Micro: 0.1667, F1 Macro: 0.0984, Accuracy: 0.1667\n","Epoch 9, Train Loss: 20.7285, Val Loss: 25.7536, F1 Micro: 0.1771, F1 Macro: 0.0917, Accuracy: 0.1771\n","Epoch 10, Train Loss: 16.1099, Val Loss: 22.4402, F1 Micro: 0.1875, F1 Macro: 0.0931, Accuracy: 0.1875\n","Epoch 11, Train Loss: 13.6744, Val Loss: 47.1040, F1 Micro: 0.2188, F1 Macro: 0.0866, Accuracy: 0.2188\n","Epoch 12, Train Loss: 22.6308, Val Loss: 31.0546, F1 Micro: 0.1771, F1 Macro: 0.1339, Accuracy: 0.1771\n","Epoch 13, Train Loss: 18.2244, Val Loss: 22.6338, F1 Micro: 0.1667, F1 Macro: 0.1617, Accuracy: 0.1667\n","Epoch 14, Train Loss: 21.0238, Val Loss: 14.1795, F1 Micro: 0.2083, F1 Macro: 0.1553, Accuracy: 0.2083\n","Epoch 15, Train Loss: 15.1162, Val Loss: 25.1178, F1 Micro: 0.1562, F1 Macro: 0.1158, Accuracy: 0.1562\n","Epoch 16, Train Loss: 13.6555, Val Loss: 11.5085, F1 Micro: 0.3438, F1 Macro: 0.2643, Accuracy: 0.3438\n","Epoch 17, Train Loss: 14.5667, Val Loss: 6.8448, F1 Micro: 0.3854, F1 Macro: 0.2643, Accuracy: 0.3854\n","Epoch 18, Train Loss: 16.6071, Val Loss: 15.5755, F1 Micro: 0.3125, F1 Macro: 0.1754, Accuracy: 0.3125\n","Epoch 19, Train Loss: 14.9066, Val Loss: 24.6501, F1 Micro: 0.2812, F1 Macro: 0.1731, Accuracy: 0.2812\n","Epoch 20, Train Loss: 19.8301, Val Loss: 32.5543, F1 Micro: 0.3021, F1 Macro: 0.1801, Accuracy: 0.3021\n","Epoch 21, Train Loss: 19.6332, Val Loss: 18.1832, F1 Micro: 0.2292, F1 Macro: 0.1656, Accuracy: 0.2292\n","Epoch 22, Train Loss: 21.3870, Val Loss: 9.8776, F1 Micro: 0.3229, F1 Macro: 0.2936, Accuracy: 0.3229\n","Epoch 23, Train Loss: 15.3491, Val Loss: 16.0711, F1 Micro: 0.1875, F1 Macro: 0.0943, Accuracy: 0.1875\n","Epoch 24, Train Loss: 15.2816, Val Loss: 13.6568, F1 Micro: 0.2604, F1 Macro: 0.1962, Accuracy: 0.2604\n","Epoch 25, Train Loss: 16.7852, Val Loss: 21.6848, F1 Micro: 0.1667, F1 Macro: 0.0932, Accuracy: 0.1667\n","Epoch 26, Train Loss: 16.2524, Val Loss: 19.0445, F1 Micro: 0.2812, F1 Macro: 0.1705, Accuracy: 0.2812\n","Epoch 27, Train Loss: 15.2360, Val Loss: 11.2960, F1 Micro: 0.2604, F1 Macro: 0.2358, Accuracy: 0.2604\n","Epoch 28, Train Loss: 13.5227, Val Loss: 4.1134, F1 Micro: 0.3229, F1 Macro: 0.2516, Accuracy: 0.3229\n","Epoch 29, Train Loss: 12.6053, Val Loss: 27.8190, F1 Micro: 0.1771, F1 Macro: 0.0771, Accuracy: 0.1771\n","Epoch 30, Train Loss: 18.4909, Val Loss: 21.9421, F1 Micro: 0.2396, F1 Macro: 0.1334, Accuracy: 0.2396\n","Epoch 31, Train Loss: 20.4610, Val Loss: 20.7227, F1 Micro: 0.3229, F1 Macro: 0.2002, Accuracy: 0.3229\n","Epoch 32, Train Loss: 15.6360, Val Loss: 12.1271, F1 Micro: 0.2708, F1 Macro: 0.1670, Accuracy: 0.2708\n","Epoch 33, Train Loss: 12.4967, Val Loss: 10.5760, F1 Micro: 0.2292, F1 Macro: 0.1675, Accuracy: 0.2292\n","Epoch 34, Train Loss: 11.4000, Val Loss: 9.3031, F1 Micro: 0.2083, F1 Macro: 0.1579, Accuracy: 0.2083\n","Epoch 35, Train Loss: 20.6849, Val Loss: 15.0837, F1 Micro: 0.2812, F1 Macro: 0.2206, Accuracy: 0.2812\n","Epoch 36, Train Loss: 15.0670, Val Loss: 29.2908, F1 Micro: 0.1667, F1 Macro: 0.0621, Accuracy: 0.1667\n","Epoch 37, Train Loss: 11.6151, Val Loss: 22.6511, F1 Micro: 0.1875, F1 Macro: 0.0929, Accuracy: 0.1875\n","Epoch 38, Train Loss: 17.8479, Val Loss: 8.4222, F1 Micro: 0.3750, F1 Macro: 0.2341, Accuracy: 0.3750\n","Epoch 39, Train Loss: 11.9703, Val Loss: 10.5336, F1 Micro: 0.2604, F1 Macro: 0.2130, Accuracy: 0.2604\n","Epoch 40, Train Loss: 8.6186, Val Loss: 9.4943, F1 Micro: 0.2500, F1 Macro: 0.2370, Accuracy: 0.2500\n","Epoch 41, Train Loss: 11.2633, Val Loss: 16.9829, F1 Micro: 0.1250, F1 Macro: 0.1062, Accuracy: 0.1250\n","Epoch 42, Train Loss: 14.2537, Val Loss: 22.0538, F1 Micro: 0.2500, F1 Macro: 0.1568, Accuracy: 0.2500\n","Epoch 43, Train Loss: 11.8437, Val Loss: 19.9715, F1 Micro: 0.2188, F1 Macro: 0.1426, Accuracy: 0.2188\n","Epoch 44, Train Loss: 10.4058, Val Loss: 10.3740, F1 Micro: 0.2917, F1 Macro: 0.1967, Accuracy: 0.2917\n","Epoch 45, Train Loss: 16.0465, Val Loss: 20.1614, F1 Micro: 0.2500, F1 Macro: 0.2007, Accuracy: 0.2500\n","Epoch 46, Train Loss: 8.5642, Val Loss: 15.8691, F1 Micro: 0.3021, F1 Macro: 0.2013, Accuracy: 0.3021\n","Epoch 47, Train Loss: 12.6300, Val Loss: 8.4772, F1 Micro: 0.2917, F1 Macro: 0.2706, Accuracy: 0.2917\n","Epoch 48, Train Loss: 10.7784, Val Loss: 8.4752, F1 Micro: 0.3854, F1 Macro: 0.2906, Accuracy: 0.3854\n","Epoch 49, Train Loss: 14.7035, Val Loss: 15.6406, F1 Micro: 0.3229, F1 Macro: 0.2308, Accuracy: 0.3229\n","Epoch 50, Train Loss: 20.1427, Val Loss: 24.9446, F1 Micro: 0.2812, F1 Macro: 0.2403, Accuracy: 0.2812\n","Epoch 51, Train Loss: 15.8269, Val Loss: 13.7978, F1 Micro: 0.3125, F1 Macro: 0.2273, Accuracy: 0.3125\n","Epoch 52, Train Loss: 12.0453, Val Loss: 19.9783, F1 Micro: 0.3125, F1 Macro: 0.2218, Accuracy: 0.3125\n","Epoch 53, Train Loss: 15.2561, Val Loss: 10.3266, F1 Micro: 0.3438, F1 Macro: 0.2396, Accuracy: 0.3438\n","Epoch 54, Train Loss: 11.0744, Val Loss: 10.5589, F1 Micro: 0.2708, F1 Macro: 0.1829, Accuracy: 0.2708\n","Epoch 55, Train Loss: 10.7993, Val Loss: 15.3336, F1 Micro: 0.1458, F1 Macro: 0.1220, Accuracy: 0.1458\n","Epoch 56, Train Loss: 12.5827, Val Loss: 6.4468, F1 Micro: 0.3854, F1 Macro: 0.2644, Accuracy: 0.3854\n","Epoch 57, Train Loss: 11.4639, Val Loss: 33.7421, F1 Micro: 0.2292, F1 Macro: 0.1469, Accuracy: 0.2292\n","Epoch 58, Train Loss: 18.2506, Val Loss: 11.3835, F1 Micro: 0.3229, F1 Macro: 0.2967, Accuracy: 0.3229\n","Epoch 59, Train Loss: 10.8658, Val Loss: 11.2928, F1 Micro: 0.2396, F1 Macro: 0.2037, Accuracy: 0.2396\n","Epoch 60, Train Loss: 12.1204, Val Loss: 15.5903, F1 Micro: 0.1458, F1 Macro: 0.0734, Accuracy: 0.1458\n","Epoch 61, Train Loss: 15.7143, Val Loss: 17.2566, F1 Micro: 0.3021, F1 Macro: 0.2697, Accuracy: 0.3021\n","Epoch 62, Train Loss: 10.1523, Val Loss: 8.3194, F1 Micro: 0.2812, F1 Macro: 0.1848, Accuracy: 0.2812\n","Epoch 63, Train Loss: 10.3384, Val Loss: 13.5135, F1 Micro: 0.1979, F1 Macro: 0.1286, Accuracy: 0.1979\n","Epoch 64, Train Loss: 9.7280, Val Loss: 12.9767, F1 Micro: 0.3229, F1 Macro: 0.2027, Accuracy: 0.3229\n","Epoch 65, Train Loss: 9.0460, Val Loss: 5.8106, F1 Micro: 0.2604, F1 Macro: 0.2319, Accuracy: 0.2604\n","Epoch 66, Train Loss: 9.0763, Val Loss: 13.8528, F1 Micro: 0.2396, F1 Macro: 0.1623, Accuracy: 0.2396\n","Epoch 67, Train Loss: 17.2304, Val Loss: 25.0184, F1 Micro: 0.1979, F1 Macro: 0.1657, Accuracy: 0.1979\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 54.1971, Val Loss: 39.6987, F1 Micro: 0.2188, F1 Macro: 0.1229, Accuracy: 0.2188\n","Epoch 2, Train Loss: 32.9748, Val Loss: 23.9218, F1 Micro: 0.2083, F1 Macro: 0.1370, Accuracy: 0.2083\n","Epoch 3, Train Loss: 30.6612, Val Loss: 23.6708, F1 Micro: 0.2292, F1 Macro: 0.1308, Accuracy: 0.2292\n","Epoch 4, Train Loss: 25.1242, Val Loss: 28.6205, F1 Micro: 0.1562, F1 Macro: 0.0770, Accuracy: 0.1562\n","Epoch 5, Train Loss: 26.4034, Val Loss: 56.9348, F1 Micro: 0.1771, F1 Macro: 0.0693, Accuracy: 0.1771\n","Epoch 6, Train Loss: 29.7270, Val Loss: 25.5059, F1 Micro: 0.1875, F1 Macro: 0.1195, Accuracy: 0.1875\n","Epoch 7, Train Loss: 19.7961, Val Loss: 10.2218, F1 Micro: 0.2292, F1 Macro: 0.1834, Accuracy: 0.2292\n","Epoch 8, Train Loss: 16.8826, Val Loss: 19.9419, F1 Micro: 0.2708, F1 Macro: 0.1551, Accuracy: 0.2708\n","Epoch 9, Train Loss: 18.2392, Val Loss: 24.1529, F1 Micro: 0.1979, F1 Macro: 0.0739, Accuracy: 0.1979\n","Epoch 10, Train Loss: 23.8032, Val Loss: 9.9123, F1 Micro: 0.2708, F1 Macro: 0.1958, Accuracy: 0.2708\n","Epoch 11, Train Loss: 22.5606, Val Loss: 26.8004, F1 Micro: 0.2083, F1 Macro: 0.1509, Accuracy: 0.2083\n","Epoch 12, Train Loss: 23.2806, Val Loss: 38.8467, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 13, Train Loss: 18.3313, Val Loss: 26.9408, F1 Micro: 0.2396, F1 Macro: 0.1477, Accuracy: 0.2396\n","Epoch 14, Train Loss: 19.8047, Val Loss: 21.1896, F1 Micro: 0.3229, F1 Macro: 0.2209, Accuracy: 0.3229\n","Epoch 15, Train Loss: 17.2056, Val Loss: 16.9998, F1 Micro: 0.1667, F1 Macro: 0.0676, Accuracy: 0.1667\n","Epoch 16, Train Loss: 16.9525, Val Loss: 24.7433, F1 Micro: 0.2604, F1 Macro: 0.1592, Accuracy: 0.2604\n","Epoch 17, Train Loss: 33.7453, Val Loss: 38.3540, F1 Micro: 0.2708, F1 Macro: 0.1507, Accuracy: 0.2708\n","Epoch 18, Train Loss: 23.4004, Val Loss: 24.8495, F1 Micro: 0.2083, F1 Macro: 0.1089, Accuracy: 0.2083\n","Epoch 19, Train Loss: 21.8462, Val Loss: 45.4368, F1 Micro: 0.1354, F1 Macro: 0.0634, Accuracy: 0.1354\n","Epoch 20, Train Loss: 21.9017, Val Loss: 17.8830, F1 Micro: 0.2708, F1 Macro: 0.1538, Accuracy: 0.2708\n","Epoch 21, Train Loss: 20.9385, Val Loss: 21.5989, F1 Micro: 0.1875, F1 Macro: 0.0545, Accuracy: 0.1875\n","Epoch 22, Train Loss: 20.3941, Val Loss: 40.2705, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 23, Train Loss: 21.7634, Val Loss: 15.9978, F1 Micro: 0.1667, F1 Macro: 0.0954, Accuracy: 0.1667\n","Epoch 24, Train Loss: 11.3993, Val Loss: 15.7739, F1 Micro: 0.2396, F1 Macro: 0.1475, Accuracy: 0.2396\n","Epoch 25, Train Loss: 16.1036, Val Loss: 21.8964, F1 Micro: 0.1562, F1 Macro: 0.0937, Accuracy: 0.1562\n","Epoch 26, Train Loss: 14.7818, Val Loss: 31.8501, F1 Micro: 0.1458, F1 Macro: 0.0424, Accuracy: 0.1458\n","Epoch 27, Train Loss: 20.2547, Val Loss: 20.6343, F1 Micro: 0.2708, F1 Macro: 0.2175, Accuracy: 0.2708\n","Epoch 28, Train Loss: 17.9788, Val Loss: 21.5033, F1 Micro: 0.2396, F1 Macro: 0.1674, Accuracy: 0.2396\n","Epoch 29, Train Loss: 12.4619, Val Loss: 6.6788, F1 Micro: 0.3125, F1 Macro: 0.2600, Accuracy: 0.3125\n","Epoch 30, Train Loss: 14.9532, Val Loss: 13.8487, F1 Micro: 0.2083, F1 Macro: 0.1512, Accuracy: 0.2083\n","Epoch 31, Train Loss: 19.4274, Val Loss: 24.0160, F1 Micro: 0.1875, F1 Macro: 0.1079, Accuracy: 0.1875\n","Epoch 32, Train Loss: 17.5156, Val Loss: 17.0715, F1 Micro: 0.2917, F1 Macro: 0.2084, Accuracy: 0.2917\n","Epoch 33, Train Loss: 11.7582, Val Loss: 13.0271, F1 Micro: 0.2708, F1 Macro: 0.1838, Accuracy: 0.2708\n","Epoch 34, Train Loss: 11.1989, Val Loss: 16.6645, F1 Micro: 0.2500, F1 Macro: 0.1859, Accuracy: 0.2500\n","Epoch 35, Train Loss: 13.7024, Val Loss: 10.5428, F1 Micro: 0.3125, F1 Macro: 0.2288, Accuracy: 0.3125\n","Epoch 36, Train Loss: 12.0694, Val Loss: 17.6691, F1 Micro: 0.2604, F1 Macro: 0.1618, Accuracy: 0.2604\n","Epoch 37, Train Loss: 18.3829, Val Loss: 45.0429, F1 Micro: 0.2500, F1 Macro: 0.1835, Accuracy: 0.2500\n","Epoch 38, Train Loss: 17.1841, Val Loss: 14.3695, F1 Micro: 0.2917, F1 Macro: 0.2040, Accuracy: 0.2917\n","Epoch 39, Train Loss: 11.1533, Val Loss: 13.0380, F1 Micro: 0.1771, F1 Macro: 0.1321, Accuracy: 0.1771\n","Epoch 40, Train Loss: 14.0394, Val Loss: 24.5547, F1 Micro: 0.2917, F1 Macro: 0.1626, Accuracy: 0.2917\n","Epoch 41, Train Loss: 17.2738, Val Loss: 18.7647, F1 Micro: 0.3542, F1 Macro: 0.2650, Accuracy: 0.3542\n","Epoch 42, Train Loss: 16.1452, Val Loss: 19.2170, F1 Micro: 0.2500, F1 Macro: 0.2005, Accuracy: 0.2500\n","Epoch 43, Train Loss: 13.1345, Val Loss: 15.8289, F1 Micro: 0.1979, F1 Macro: 0.0981, Accuracy: 0.1979\n","Epoch 44, Train Loss: 13.8502, Val Loss: 17.7164, F1 Micro: 0.2292, F1 Macro: 0.1469, Accuracy: 0.2292\n","Epoch 45, Train Loss: 10.9798, Val Loss: 12.3377, F1 Micro: 0.1771, F1 Macro: 0.1015, Accuracy: 0.1771\n","Epoch 46, Train Loss: 12.7222, Val Loss: 14.6416, F1 Micro: 0.1875, F1 Macro: 0.0984, Accuracy: 0.1875\n","Epoch 47, Train Loss: 11.5143, Val Loss: 12.9276, F1 Micro: 0.2812, F1 Macro: 0.1640, Accuracy: 0.2812\n","Epoch 48, Train Loss: 9.6845, Val Loss: 19.9582, F1 Micro: 0.2292, F1 Macro: 0.1360, Accuracy: 0.2292\n","Epoch 49, Train Loss: 12.7050, Val Loss: 10.9600, F1 Micro: 0.3646, F1 Macro: 0.2800, Accuracy: 0.3646\n","Epoch 50, Train Loss: 14.0027, Val Loss: 8.4731, F1 Micro: 0.2500, F1 Macro: 0.2241, Accuracy: 0.2500\n","Epoch 51, Train Loss: 10.6535, Val Loss: 12.7087, F1 Micro: 0.2083, F1 Macro: 0.1682, Accuracy: 0.2083\n","Epoch 52, Train Loss: 11.1174, Val Loss: 11.4378, F1 Micro: 0.2292, F1 Macro: 0.1461, Accuracy: 0.2292\n","Epoch 53, Train Loss: 19.5816, Val Loss: 22.9396, F1 Micro: 0.2083, F1 Macro: 0.1103, Accuracy: 0.2083\n","Epoch 54, Train Loss: 13.2502, Val Loss: 15.4356, F1 Micro: 0.3125, F1 Macro: 0.2566, Accuracy: 0.3125\n","Epoch 55, Train Loss: 9.2462, Val Loss: 7.9943, F1 Micro: 0.3021, F1 Macro: 0.2454, Accuracy: 0.3021\n","Epoch 56, Train Loss: 11.2140, Val Loss: 19.6454, F1 Micro: 0.2604, F1 Macro: 0.1693, Accuracy: 0.2604\n","Epoch 57, Train Loss: 11.0207, Val Loss: 18.6851, F1 Micro: 0.2917, F1 Macro: 0.2032, Accuracy: 0.2917\n","Epoch 58, Train Loss: 10.5934, Val Loss: 12.5434, F1 Micro: 0.2292, F1 Macro: 0.1570, Accuracy: 0.2292\n","Epoch 59, Train Loss: 11.3720, Val Loss: 13.1916, F1 Micro: 0.2708, F1 Macro: 0.1873, Accuracy: 0.2708\n","Epoch 60, Train Loss: 10.8674, Val Loss: 9.6095, F1 Micro: 0.1979, F1 Macro: 0.1375, Accuracy: 0.1979\n","Epoch 61, Train Loss: 9.5586, Val Loss: 16.4169, F1 Micro: 0.2188, F1 Macro: 0.1550, Accuracy: 0.2188\n","Epoch 62, Train Loss: 12.0664, Val Loss: 18.2082, F1 Micro: 0.2188, F1 Macro: 0.1442, Accuracy: 0.2188\n","Epoch 63, Train Loss: 10.1703, Val Loss: 17.0991, F1 Micro: 0.2917, F1 Macro: 0.2219, Accuracy: 0.2917\n","Epoch 64, Train Loss: 10.6946, Val Loss: 10.8172, F1 Micro: 0.3542, F1 Macro: 0.2910, Accuracy: 0.3542\n","Epoch 65, Train Loss: 15.8184, Val Loss: 13.1115, F1 Micro: 0.3229, F1 Macro: 0.2834, Accuracy: 0.3229\n","Epoch 66, Train Loss: 11.0101, Val Loss: 9.6614, F1 Micro: 0.2708, F1 Macro: 0.2519, Accuracy: 0.2708\n","Epoch 67, Train Loss: 7.4428, Val Loss: 7.6732, F1 Micro: 0.2708, F1 Macro: 0.2322, Accuracy: 0.2708\n","Epoch 68, Train Loss: 12.3113, Val Loss: 6.7017, F1 Micro: 0.2812, F1 Macro: 0.2333, Accuracy: 0.2812\n","Epoch 69, Train Loss: 12.7207, Val Loss: 16.6688, F1 Micro: 0.2604, F1 Macro: 0.1982, Accuracy: 0.2604\n","Epoch 70, Train Loss: 12.6092, Val Loss: 12.8153, F1 Micro: 0.2083, F1 Macro: 0.1397, Accuracy: 0.2083\n","Epoch 71, Train Loss: 9.1847, Val Loss: 15.0077, F1 Micro: 0.2083, F1 Macro: 0.1041, Accuracy: 0.2083\n","Epoch 72, Train Loss: 12.0422, Val Loss: 11.6787, F1 Micro: 0.2604, F1 Macro: 0.1450, Accuracy: 0.2604\n","Epoch 73, Train Loss: 8.2443, Val Loss: 15.4647, F1 Micro: 0.2500, F1 Macro: 0.1751, Accuracy: 0.2500\n","Epoch 74, Train Loss: 11.3277, Val Loss: 9.1366, F1 Micro: 0.2396, F1 Macro: 0.1862, Accuracy: 0.2396\n","Epoch 75, Train Loss: 10.0769, Val Loss: 9.9344, F1 Micro: 0.3229, F1 Macro: 0.2518, Accuracy: 0.3229\n","Epoch 76, Train Loss: 9.8688, Val Loss: 9.2106, F1 Micro: 0.3021, F1 Macro: 0.1937, Accuracy: 0.3021\n","Epoch 77, Train Loss: 7.8445, Val Loss: 7.4589, F1 Micro: 0.2292, F1 Macro: 0.2040, Accuracy: 0.2292\n","Epoch 78, Train Loss: 7.4353, Val Loss: 17.6168, F1 Micro: 0.1042, F1 Macro: 0.0458, Accuracy: 0.1042\n","Epoch 79, Train Loss: 8.5001, Val Loss: 5.7875, F1 Micro: 0.2812, F1 Macro: 0.2407, Accuracy: 0.2812\n","Epoch 80, Train Loss: 6.5933, Val Loss: 14.7348, F1 Micro: 0.2396, F1 Macro: 0.1673, Accuracy: 0.2396\n","Epoch 81, Train Loss: 10.0334, Val Loss: 14.6792, F1 Micro: 0.2083, F1 Macro: 0.1179, Accuracy: 0.2083\n","Epoch 82, Train Loss: 7.7482, Val Loss: 7.4470, F1 Micro: 0.3021, F1 Macro: 0.2464, Accuracy: 0.3021\n","Epoch 83, Train Loss: 9.6908, Val Loss: 11.2321, F1 Micro: 0.2812, F1 Macro: 0.1685, Accuracy: 0.2812\n","Epoch 84, Train Loss: 8.8130, Val Loss: 5.9599, F1 Micro: 0.3229, F1 Macro: 0.2717, Accuracy: 0.3229\n","Epoch 85, Train Loss: 5.7764, Val Loss: 12.9261, F1 Micro: 0.2500, F1 Macro: 0.1432, Accuracy: 0.2500\n","Epoch 86, Train Loss: 8.0924, Val Loss: 6.3779, F1 Micro: 0.2812, F1 Macro: 0.2388, Accuracy: 0.2812\n","Epoch 87, Train Loss: 5.8673, Val Loss: 7.6990, F1 Micro: 0.3125, F1 Macro: 0.2555, Accuracy: 0.3125\n","Epoch 88, Train Loss: 8.5795, Val Loss: 8.5402, F1 Micro: 0.2500, F1 Macro: 0.2150, Accuracy: 0.2500\n","Epoch 89, Train Loss: 8.2752, Val Loss: 5.0645, F1 Micro: 0.3438, F1 Macro: 0.2782, Accuracy: 0.3438\n","Epoch 90, Train Loss: 8.4198, Val Loss: 5.6651, F1 Micro: 0.3958, F1 Macro: 0.3471, Accuracy: 0.3958\n","Epoch 91, Train Loss: 6.2507, Val Loss: 7.5020, F1 Micro: 0.2188, F1 Macro: 0.2052, Accuracy: 0.2188\n","Epoch 92, Train Loss: 5.9486, Val Loss: 4.9515, F1 Micro: 0.3333, F1 Macro: 0.3203, Accuracy: 0.3333\n","Epoch 93, Train Loss: 6.8973, Val Loss: 12.3522, F1 Micro: 0.3125, F1 Macro: 0.2129, Accuracy: 0.3125\n","Epoch 94, Train Loss: 7.0258, Val Loss: 7.7546, F1 Micro: 0.2708, F1 Macro: 0.2382, Accuracy: 0.2708\n","Epoch 95, Train Loss: 8.1934, Val Loss: 13.1589, F1 Micro: 0.2917, F1 Macro: 0.2242, Accuracy: 0.2917\n","Epoch 96, Train Loss: 6.4328, Val Loss: 8.8268, F1 Micro: 0.1875, F1 Macro: 0.0906, Accuracy: 0.1875\n","Epoch 97, Train Loss: 7.9354, Val Loss: 7.4904, F1 Micro: 0.2917, F1 Macro: 0.2474, Accuracy: 0.2917\n","Epoch 98, Train Loss: 6.6334, Val Loss: 6.2862, F1 Micro: 0.2812, F1 Macro: 0.2355, Accuracy: 0.2812\n","Epoch 99, Train Loss: 6.9121, Val Loss: 9.1851, F1 Micro: 0.2917, F1 Macro: 0.2009, Accuracy: 0.2917\n","Epoch 100, Train Loss: 7.0847, Val Loss: 9.6490, F1 Micro: 0.3333, F1 Macro: 0.2886, Accuracy: 0.3333\n","Epoch 101, Train Loss: 7.9016, Val Loss: 14.2475, F1 Micro: 0.2917, F1 Macro: 0.1976, Accuracy: 0.2917\n","Epoch 102, Train Loss: 7.8593, Val Loss: 8.4133, F1 Micro: 0.3021, F1 Macro: 0.2111, Accuracy: 0.3021\n","Epoch 103, Train Loss: 7.0962, Val Loss: 7.8663, F1 Micro: 0.2396, F1 Macro: 0.1472, Accuracy: 0.2396\n","Epoch 104, Train Loss: 5.4746, Val Loss: 7.7765, F1 Micro: 0.2500, F1 Macro: 0.2083, Accuracy: 0.2500\n","Epoch 105, Train Loss: 7.1347, Val Loss: 10.7620, F1 Micro: 0.2292, F1 Macro: 0.1690, Accuracy: 0.2292\n","Epoch 106, Train Loss: 6.8227, Val Loss: 7.0346, F1 Micro: 0.2917, F1 Macro: 0.2740, Accuracy: 0.2917\n","Epoch 107, Train Loss: 6.7603, Val Loss: 6.2186, F1 Micro: 0.2708, F1 Macro: 0.1979, Accuracy: 0.2708\n","Epoch 108, Train Loss: 6.0226, Val Loss: 9.4294, F1 Micro: 0.2500, F1 Macro: 0.2032, Accuracy: 0.2500\n","Epoch 109, Train Loss: 6.4026, Val Loss: 7.9392, F1 Micro: 0.2812, F1 Macro: 0.1955, Accuracy: 0.2812\n","Epoch 110, Train Loss: 5.3201, Val Loss: 4.1458, F1 Micro: 0.3021, F1 Macro: 0.3086, Accuracy: 0.3021\n","Epoch 111, Train Loss: 5.8368, Val Loss: 8.2035, F1 Micro: 0.2083, F1 Macro: 0.1364, Accuracy: 0.2083\n","Epoch 112, Train Loss: 7.1525, Val Loss: 11.1882, F1 Micro: 0.2396, F1 Macro: 0.1623, Accuracy: 0.2396\n","Epoch 113, Train Loss: 6.0376, Val Loss: 8.2163, F1 Micro: 0.2292, F1 Macro: 0.1387, Accuracy: 0.2292\n","Epoch 114, Train Loss: 5.5102, Val Loss: 5.3557, F1 Micro: 0.1979, F1 Macro: 0.1124, Accuracy: 0.1979\n","Epoch 115, Train Loss: 5.4851, Val Loss: 7.0082, F1 Micro: 0.2396, F1 Macro: 0.1617, Accuracy: 0.2396\n","Epoch 116, Train Loss: 4.8997, Val Loss: 6.1698, F1 Micro: 0.3021, F1 Macro: 0.2806, Accuracy: 0.3021\n","Epoch 117, Train Loss: 4.9276, Val Loss: 8.7685, F1 Micro: 0.3125, F1 Macro: 0.2509, Accuracy: 0.3125\n","Epoch 118, Train Loss: 5.4469, Val Loss: 10.0451, F1 Micro: 0.2396, F1 Macro: 0.1499, Accuracy: 0.2396\n","Epoch 119, Train Loss: 5.7647, Val Loss: 3.8865, F1 Micro: 0.3646, F1 Macro: 0.3117, Accuracy: 0.3646\n","Epoch 120, Train Loss: 4.4792, Val Loss: 4.6507, F1 Micro: 0.2812, F1 Macro: 0.2128, Accuracy: 0.2812\n","Epoch 121, Train Loss: 6.0734, Val Loss: 4.7298, F1 Micro: 0.3542, F1 Macro: 0.2889, Accuracy: 0.3542\n","Epoch 122, Train Loss: 5.7352, Val Loss: 9.4088, F1 Micro: 0.2292, F1 Macro: 0.1682, Accuracy: 0.2292\n","Epoch 123, Train Loss: 5.6308, Val Loss: 6.3083, F1 Micro: 0.2188, F1 Macro: 0.1365, Accuracy: 0.2188\n","Epoch 124, Train Loss: 6.5617, Val Loss: 5.3310, F1 Micro: 0.2500, F1 Macro: 0.1956, Accuracy: 0.2500\n","Epoch 125, Train Loss: 4.4666, Val Loss: 6.1317, F1 Micro: 0.1875, F1 Macro: 0.1235, Accuracy: 0.1875\n","Epoch 126, Train Loss: 3.9297, Val Loss: 4.5939, F1 Micro: 0.3125, F1 Macro: 0.2672, Accuracy: 0.3125\n","Epoch 127, Train Loss: 5.1769, Val Loss: 6.0140, F1 Micro: 0.1979, F1 Macro: 0.1275, Accuracy: 0.1979\n","Epoch 128, Train Loss: 4.6573, Val Loss: 7.2556, F1 Micro: 0.3646, F1 Macro: 0.2826, Accuracy: 0.3646\n","Epoch 129, Train Loss: 4.9291, Val Loss: 5.4786, F1 Micro: 0.2500, F1 Macro: 0.1434, Accuracy: 0.2500\n","Epoch 130, Train Loss: 4.6995, Val Loss: 7.0121, F1 Micro: 0.2708, F1 Macro: 0.1906, Accuracy: 0.2708\n","Epoch 131, Train Loss: 4.6412, Val Loss: 4.6298, F1 Micro: 0.2917, F1 Macro: 0.1972, Accuracy: 0.2917\n","Epoch 132, Train Loss: 3.9323, Val Loss: 3.9801, F1 Micro: 0.3021, F1 Macro: 0.2480, Accuracy: 0.3021\n","Epoch 133, Train Loss: 3.9784, Val Loss: 5.3040, F1 Micro: 0.2917, F1 Macro: 0.2063, Accuracy: 0.2917\n","Epoch 134, Train Loss: 3.5779, Val Loss: 4.1625, F1 Micro: 0.3021, F1 Macro: 0.2499, Accuracy: 0.3021\n","Epoch 135, Train Loss: 3.1821, Val Loss: 4.4361, F1 Micro: 0.3542, F1 Macro: 0.3074, Accuracy: 0.3542\n","Epoch 136, Train Loss: 5.0549, Val Loss: 5.7381, F1 Micro: 0.2812, F1 Macro: 0.1977, Accuracy: 0.2812\n","Epoch 137, Train Loss: 5.0912, Val Loss: 7.5128, F1 Micro: 0.2604, F1 Macro: 0.1837, Accuracy: 0.2604\n","Epoch 138, Train Loss: 4.8962, Val Loss: 5.6878, F1 Micro: 0.3333, F1 Macro: 0.2604, Accuracy: 0.3333\n","Epoch 139, Train Loss: 4.5490, Val Loss: 7.9201, F1 Micro: 0.2188, F1 Macro: 0.1584, Accuracy: 0.2188\n","Epoch 140, Train Loss: 4.7042, Val Loss: 5.5118, F1 Micro: 0.2396, F1 Macro: 0.1547, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 69.1247, Val Loss: 23.0547, F1 Micro: 0.2500, F1 Macro: 0.1427, Accuracy: 0.2500\n","Epoch 2, Train Loss: 24.0834, Val Loss: 14.2351, F1 Micro: 0.2396, F1 Macro: 0.1297, Accuracy: 0.2396\n","Epoch 3, Train Loss: 21.1982, Val Loss: 33.6199, F1 Micro: 0.2396, F1 Macro: 0.1363, Accuracy: 0.2396\n","Epoch 4, Train Loss: 27.5852, Val Loss: 22.7868, F1 Micro: 0.3021, F1 Macro: 0.2021, Accuracy: 0.3021\n","Epoch 5, Train Loss: 21.7362, Val Loss: 23.9124, F1 Micro: 0.2188, F1 Macro: 0.1507, Accuracy: 0.2188\n","Epoch 6, Train Loss: 26.9665, Val Loss: 37.2450, F1 Micro: 0.1979, F1 Macro: 0.0906, Accuracy: 0.1979\n","Epoch 7, Train Loss: 23.1861, Val Loss: 28.2365, F1 Micro: 0.2188, F1 Macro: 0.1511, Accuracy: 0.2188\n","Epoch 8, Train Loss: 22.7877, Val Loss: 26.1259, F1 Micro: 0.1875, F1 Macro: 0.0835, Accuracy: 0.1875\n","Epoch 9, Train Loss: 25.0337, Val Loss: 31.6220, F1 Micro: 0.1562, F1 Macro: 0.0459, Accuracy: 0.1562\n","Epoch 10, Train Loss: 19.6144, Val Loss: 10.9637, F1 Micro: 0.2500, F1 Macro: 0.1878, Accuracy: 0.2500\n","Epoch 11, Train Loss: 29.6127, Val Loss: 24.0217, F1 Micro: 0.1771, F1 Macro: 0.1045, Accuracy: 0.1771\n","Epoch 12, Train Loss: 29.3924, Val Loss: 15.4981, F1 Micro: 0.2604, F1 Macro: 0.1504, Accuracy: 0.2604\n","Epoch 13, Train Loss: 20.9406, Val Loss: 13.9254, F1 Micro: 0.2500, F1 Macro: 0.1378, Accuracy: 0.2500\n","Epoch 14, Train Loss: 14.7462, Val Loss: 8.5526, F1 Micro: 0.3542, F1 Macro: 0.3209, Accuracy: 0.3542\n","Epoch 15, Train Loss: 15.5490, Val Loss: 8.6793, F1 Micro: 0.3229, F1 Macro: 0.2639, Accuracy: 0.3229\n","Epoch 16, Train Loss: 14.8111, Val Loss: 15.6186, F1 Micro: 0.2083, F1 Macro: 0.1443, Accuracy: 0.2083\n","Epoch 17, Train Loss: 17.8399, Val Loss: 8.9717, F1 Micro: 0.1979, F1 Macro: 0.1600, Accuracy: 0.1979\n","Epoch 18, Train Loss: 15.8342, Val Loss: 24.2808, F1 Micro: 0.2083, F1 Macro: 0.1480, Accuracy: 0.2083\n","Epoch 19, Train Loss: 24.9625, Val Loss: 21.3726, F1 Micro: 0.1667, F1 Macro: 0.0910, Accuracy: 0.1667\n","Epoch 20, Train Loss: 17.8194, Val Loss: 11.7322, F1 Micro: 0.2188, F1 Macro: 0.1553, Accuracy: 0.2188\n","Epoch 21, Train Loss: 17.8340, Val Loss: 30.1633, F1 Micro: 0.2396, F1 Macro: 0.1351, Accuracy: 0.2396\n","Epoch 22, Train Loss: 27.1459, Val Loss: 22.8996, F1 Micro: 0.1875, F1 Macro: 0.1064, Accuracy: 0.1875\n","Epoch 23, Train Loss: 16.6531, Val Loss: 18.2150, F1 Micro: 0.2188, F1 Macro: 0.1382, Accuracy: 0.2188\n","Epoch 24, Train Loss: 14.5699, Val Loss: 14.9782, F1 Micro: 0.1979, F1 Macro: 0.1325, Accuracy: 0.1979\n","Epoch 25, Train Loss: 16.0159, Val Loss: 9.8424, F1 Micro: 0.3229, F1 Macro: 0.2390, Accuracy: 0.3229\n","Epoch 26, Train Loss: 18.3411, Val Loss: 15.5999, F1 Micro: 0.2188, F1 Macro: 0.1169, Accuracy: 0.2188\n","Epoch 27, Train Loss: 19.1616, Val Loss: 16.2343, F1 Micro: 0.3125, F1 Macro: 0.2639, Accuracy: 0.3125\n","Epoch 28, Train Loss: 22.4837, Val Loss: 9.1752, F1 Micro: 0.3646, F1 Macro: 0.3075, Accuracy: 0.3646\n","Epoch 29, Train Loss: 19.6952, Val Loss: 29.7337, F1 Micro: 0.2083, F1 Macro: 0.1260, Accuracy: 0.2083\n","Epoch 30, Train Loss: 25.0169, Val Loss: 23.5323, F1 Micro: 0.2500, F1 Macro: 0.1234, Accuracy: 0.2500\n","Epoch 31, Train Loss: 19.6464, Val Loss: 12.8076, F1 Micro: 0.2188, F1 Macro: 0.1504, Accuracy: 0.2188\n","Epoch 32, Train Loss: 18.3816, Val Loss: 9.8748, F1 Micro: 0.2604, F1 Macro: 0.2223, Accuracy: 0.2604\n","Epoch 33, Train Loss: 14.6713, Val Loss: 12.1830, F1 Micro: 0.2917, F1 Macro: 0.1734, Accuracy: 0.2917\n","Epoch 34, Train Loss: 17.2178, Val Loss: 14.3930, F1 Micro: 0.2812, F1 Macro: 0.1532, Accuracy: 0.2812\n","Epoch 35, Train Loss: 18.2959, Val Loss: 20.5237, F1 Micro: 0.1667, F1 Macro: 0.0801, Accuracy: 0.1667\n","Epoch 36, Train Loss: 19.2547, Val Loss: 7.7348, F1 Micro: 0.3125, F1 Macro: 0.2628, Accuracy: 0.3125\n","Epoch 37, Train Loss: 16.8138, Val Loss: 8.2521, F1 Micro: 0.2812, F1 Macro: 0.2350, Accuracy: 0.2812\n","Epoch 38, Train Loss: 14.5405, Val Loss: 20.9982, F1 Micro: 0.2708, F1 Macro: 0.2113, Accuracy: 0.2708\n","Epoch 39, Train Loss: 19.3502, Val Loss: 20.0689, F1 Micro: 0.1667, F1 Macro: 0.0970, Accuracy: 0.1667\n","Epoch 40, Train Loss: 17.7934, Val Loss: 25.8842, F1 Micro: 0.1771, F1 Macro: 0.1062, Accuracy: 0.1771\n","Epoch 41, Train Loss: 16.4537, Val Loss: 16.8012, F1 Micro: 0.1354, F1 Macro: 0.0451, Accuracy: 0.1354\n","Epoch 42, Train Loss: 16.7318, Val Loss: 26.3782, F1 Micro: 0.1875, F1 Macro: 0.1057, Accuracy: 0.1875\n","Epoch 43, Train Loss: 14.6951, Val Loss: 6.5945, F1 Micro: 0.3125, F1 Macro: 0.2704, Accuracy: 0.3125\n","Epoch 44, Train Loss: 14.2488, Val Loss: 12.0448, F1 Micro: 0.2188, F1 Macro: 0.1505, Accuracy: 0.2188\n","Epoch 45, Train Loss: 14.9186, Val Loss: 9.8892, F1 Micro: 0.2812, F1 Macro: 0.1836, Accuracy: 0.2812\n","Epoch 46, Train Loss: 9.5613, Val Loss: 10.0347, F1 Micro: 0.2292, F1 Macro: 0.1642, Accuracy: 0.2292\n","Epoch 47, Train Loss: 8.7761, Val Loss: 12.5483, F1 Micro: 0.2083, F1 Macro: 0.1071, Accuracy: 0.2083\n","Epoch 48, Train Loss: 11.3142, Val Loss: 12.0355, F1 Micro: 0.2500, F1 Macro: 0.2083, Accuracy: 0.2500\n","Epoch 49, Train Loss: 10.3330, Val Loss: 7.7314, F1 Micro: 0.1979, F1 Macro: 0.1592, Accuracy: 0.1979\n","Epoch 50, Train Loss: 12.1983, Val Loss: 9.6980, F1 Micro: 0.2917, F1 Macro: 0.2179, Accuracy: 0.2917\n","Epoch 51, Train Loss: 14.9590, Val Loss: 9.4727, F1 Micro: 0.3333, F1 Macro: 0.2385, Accuracy: 0.3333\n","Epoch 52, Train Loss: 18.1451, Val Loss: 9.1864, F1 Micro: 0.2708, F1 Macro: 0.2266, Accuracy: 0.2708\n","Epoch 53, Train Loss: 11.3095, Val Loss: 8.4928, F1 Micro: 0.3125, F1 Macro: 0.2561, Accuracy: 0.3125\n","Epoch 54, Train Loss: 8.7052, Val Loss: 9.7644, F1 Micro: 0.2708, F1 Macro: 0.2553, Accuracy: 0.2708\n","Epoch 55, Train Loss: 14.4635, Val Loss: 18.3134, F1 Micro: 0.1667, F1 Macro: 0.0837, Accuracy: 0.1667\n","Epoch 56, Train Loss: 13.9968, Val Loss: 7.4958, F1 Micro: 0.3958, F1 Macro: 0.3561, Accuracy: 0.3958\n","Epoch 57, Train Loss: 10.9005, Val Loss: 16.5027, F1 Micro: 0.2917, F1 Macro: 0.1993, Accuracy: 0.2917\n","Epoch 58, Train Loss: 11.6492, Val Loss: 11.9974, F1 Micro: 0.1667, F1 Macro: 0.0926, Accuracy: 0.1667\n","Epoch 59, Train Loss: 11.6915, Val Loss: 8.8098, F1 Micro: 0.2188, F1 Macro: 0.1877, Accuracy: 0.2188\n","Epoch 60, Train Loss: 10.0994, Val Loss: 10.1513, F1 Micro: 0.3021, F1 Macro: 0.2211, Accuracy: 0.3021\n","Epoch 61, Train Loss: 11.4618, Val Loss: 17.5685, F1 Micro: 0.1771, F1 Macro: 0.0674, Accuracy: 0.1771\n","Epoch 62, Train Loss: 14.0695, Val Loss: 10.6484, F1 Micro: 0.2500, F1 Macro: 0.1858, Accuracy: 0.2500\n","Epoch 63, Train Loss: 10.8940, Val Loss: 11.6912, F1 Micro: 0.2188, F1 Macro: 0.1415, Accuracy: 0.2188\n","Epoch 64, Train Loss: 11.0514, Val Loss: 14.9918, F1 Micro: 0.1875, F1 Macro: 0.1145, Accuracy: 0.1875\n","Epoch 65, Train Loss: 10.0785, Val Loss: 16.0864, F1 Micro: 0.3021, F1 Macro: 0.2657, Accuracy: 0.3021\n","Epoch 66, Train Loss: 15.9843, Val Loss: 11.9286, F1 Micro: 0.3333, F1 Macro: 0.2521, Accuracy: 0.3333\n","Epoch 67, Train Loss: 13.1174, Val Loss: 9.5034, F1 Micro: 0.2500, F1 Macro: 0.2005, Accuracy: 0.2500\n","Epoch 68, Train Loss: 9.3760, Val Loss: 17.6801, F1 Micro: 0.2083, F1 Macro: 0.1456, Accuracy: 0.2083\n","Epoch 69, Train Loss: 10.6530, Val Loss: 11.2349, F1 Micro: 0.2083, F1 Macro: 0.1396, Accuracy: 0.2083\n","Epoch 70, Train Loss: 8.8849, Val Loss: 6.1682, F1 Micro: 0.3021, F1 Macro: 0.2513, Accuracy: 0.3021\n","Epoch 71, Train Loss: 9.9542, Val Loss: 11.6043, F1 Micro: 0.2188, F1 Macro: 0.1457, Accuracy: 0.2188\n","Epoch 72, Train Loss: 12.2712, Val Loss: 22.5746, F1 Micro: 0.2188, F1 Macro: 0.1461, Accuracy: 0.2188\n","Epoch 73, Train Loss: 10.7782, Val Loss: 10.0146, F1 Micro: 0.1771, F1 Macro: 0.0910, Accuracy: 0.1771\n","Epoch 74, Train Loss: 9.2565, Val Loss: 15.8200, F1 Micro: 0.2917, F1 Macro: 0.1818, Accuracy: 0.2917\n","Epoch 75, Train Loss: 10.1718, Val Loss: 7.5870, F1 Micro: 0.2500, F1 Macro: 0.2190, Accuracy: 0.2500\n","Epoch 76, Train Loss: 7.3000, Val Loss: 6.1545, F1 Micro: 0.3229, F1 Macro: 0.2614, Accuracy: 0.3229\n","Epoch 77, Train Loss: 6.6316, Val Loss: 4.7976, F1 Micro: 0.3542, F1 Macro: 0.2945, Accuracy: 0.3542\n","Epoch 78, Train Loss: 8.2206, Val Loss: 5.8982, F1 Micro: 0.2708, F1 Macro: 0.2433, Accuracy: 0.2708\n","Epoch 79, Train Loss: 7.6853, Val Loss: 12.0974, F1 Micro: 0.2604, F1 Macro: 0.1835, Accuracy: 0.2604\n","Epoch 80, Train Loss: 8.8064, Val Loss: 8.6582, F1 Micro: 0.2292, F1 Macro: 0.1951, Accuracy: 0.2292\n","Epoch 81, Train Loss: 8.9549, Val Loss: 9.1756, F1 Micro: 0.3021, F1 Macro: 0.2745, Accuracy: 0.3021\n","Epoch 82, Train Loss: 9.4510, Val Loss: 10.8537, F1 Micro: 0.3229, F1 Macro: 0.2681, Accuracy: 0.3229\n","Epoch 83, Train Loss: 14.1212, Val Loss: 13.2878, F1 Micro: 0.2812, F1 Macro: 0.2273, Accuracy: 0.2812\n","Epoch 84, Train Loss: 9.6824, Val Loss: 10.5524, F1 Micro: 0.2500, F1 Macro: 0.1917, Accuracy: 0.2500\n","Epoch 85, Train Loss: 12.6385, Val Loss: 5.7326, F1 Micro: 0.2708, F1 Macro: 0.1993, Accuracy: 0.2708\n","Epoch 86, Train Loss: 7.7787, Val Loss: 10.0395, F1 Micro: 0.2917, F1 Macro: 0.2222, Accuracy: 0.2917\n","Epoch 87, Train Loss: 8.1906, Val Loss: 11.2386, F1 Micro: 0.2500, F1 Macro: 0.1954, Accuracy: 0.2500\n","Epoch 88, Train Loss: 9.7164, Val Loss: 6.7609, F1 Micro: 0.1875, F1 Macro: 0.1320, Accuracy: 0.1875\n","Epoch 89, Train Loss: 8.1654, Val Loss: 9.7280, F1 Micro: 0.2188, F1 Macro: 0.1773, Accuracy: 0.2188\n","Epoch 90, Train Loss: 10.5012, Val Loss: 11.6798, F1 Micro: 0.2812, F1 Macro: 0.2169, Accuracy: 0.2812\n","Epoch 91, Train Loss: 8.6762, Val Loss: 5.0154, F1 Micro: 0.2604, F1 Macro: 0.2015, Accuracy: 0.2604\n","Epoch 92, Train Loss: 7.2901, Val Loss: 14.6619, F1 Micro: 0.2812, F1 Macro: 0.2005, Accuracy: 0.2812\n","Epoch 93, Train Loss: 8.5693, Val Loss: 7.0272, F1 Micro: 0.1875, F1 Macro: 0.1078, Accuracy: 0.1875\n","Epoch 94, Train Loss: 6.5074, Val Loss: 7.9854, F1 Micro: 0.3646, F1 Macro: 0.3195, Accuracy: 0.3646\n","Epoch 95, Train Loss: 7.3489, Val Loss: 11.2017, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 96, Train Loss: 8.3231, Val Loss: 9.3266, F1 Micro: 0.3438, F1 Macro: 0.2829, Accuracy: 0.3438\n","Epoch 97, Train Loss: 8.4074, Val Loss: 6.0749, F1 Micro: 0.2812, F1 Macro: 0.1843, Accuracy: 0.2812\n","Epoch 98, Train Loss: 10.1369, Val Loss: 9.6266, F1 Micro: 0.2500, F1 Macro: 0.1689, Accuracy: 0.2500\n","Epoch 99, Train Loss: 6.8026, Val Loss: 7.3083, F1 Micro: 0.2917, F1 Macro: 0.2384, Accuracy: 0.2917\n","Epoch 100, Train Loss: 5.8720, Val Loss: 4.8472, F1 Micro: 0.3021, F1 Macro: 0.2875, Accuracy: 0.3021\n","Epoch 101, Train Loss: 7.4757, Val Loss: 7.0559, F1 Micro: 0.3229, F1 Macro: 0.2394, Accuracy: 0.3229\n","Epoch 102, Train Loss: 6.6920, Val Loss: 10.1439, F1 Micro: 0.1771, F1 Macro: 0.1131, Accuracy: 0.1771\n","Epoch 103, Train Loss: 5.8252, Val Loss: 7.6913, F1 Micro: 0.2292, F1 Macro: 0.1460, Accuracy: 0.2292\n","Epoch 104, Train Loss: 4.5708, Val Loss: 4.8950, F1 Micro: 0.2188, F1 Macro: 0.1775, Accuracy: 0.2188\n","Epoch 105, Train Loss: 5.5462, Val Loss: 7.8837, F1 Micro: 0.2812, F1 Macro: 0.1842, Accuracy: 0.2812\n","Epoch 106, Train Loss: 7.6034, Val Loss: 6.5262, F1 Micro: 0.2917, F1 Macro: 0.2586, Accuracy: 0.2917\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.4020833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 91.9429, Val Loss: 51.7248, F1 Micro: 0.2396, F1 Macro: 0.1129, Accuracy: 0.2396\n","Epoch 2, Train Loss: 33.7071, Val Loss: 22.2406, F1 Micro: 0.2292, F1 Macro: 0.1143, Accuracy: 0.2292\n","Epoch 3, Train Loss: 23.4720, Val Loss: 20.4100, F1 Micro: 0.2396, F1 Macro: 0.1649, Accuracy: 0.2396\n","Epoch 4, Train Loss: 19.6299, Val Loss: 28.0740, F1 Micro: 0.1979, F1 Macro: 0.1207, Accuracy: 0.1979\n","Epoch 5, Train Loss: 14.2938, Val Loss: 11.2227, F1 Micro: 0.2812, F1 Macro: 0.1639, Accuracy: 0.2812\n","Epoch 6, Train Loss: 14.7445, Val Loss: 14.4837, F1 Micro: 0.1354, F1 Macro: 0.0589, Accuracy: 0.1354\n","Epoch 7, Train Loss: 21.7268, Val Loss: 20.3008, F1 Micro: 0.2188, F1 Macro: 0.1369, Accuracy: 0.2188\n","Epoch 8, Train Loss: 18.6841, Val Loss: 16.0506, F1 Micro: 0.2604, F1 Macro: 0.1625, Accuracy: 0.2604\n","Epoch 9, Train Loss: 16.7797, Val Loss: 13.3702, F1 Micro: 0.2500, F1 Macro: 0.2420, Accuracy: 0.2500\n","Epoch 10, Train Loss: 18.5948, Val Loss: 12.1803, F1 Micro: 0.2396, F1 Macro: 0.1275, Accuracy: 0.2396\n","Epoch 11, Train Loss: 20.6796, Val Loss: 31.4865, F1 Micro: 0.1979, F1 Macro: 0.0949, Accuracy: 0.1979\n","Epoch 12, Train Loss: 23.2960, Val Loss: 21.7657, F1 Micro: 0.1979, F1 Macro: 0.1184, Accuracy: 0.1979\n","Epoch 13, Train Loss: 23.0363, Val Loss: 19.4058, F1 Micro: 0.2917, F1 Macro: 0.2136, Accuracy: 0.2917\n","Epoch 14, Train Loss: 23.5359, Val Loss: 31.2148, F1 Micro: 0.1875, F1 Macro: 0.1599, Accuracy: 0.1875\n","Epoch 15, Train Loss: 24.0335, Val Loss: 29.1432, F1 Micro: 0.2604, F1 Macro: 0.1661, Accuracy: 0.2604\n","Epoch 16, Train Loss: 25.3016, Val Loss: 34.1123, F1 Micro: 0.2292, F1 Macro: 0.1214, Accuracy: 0.2292\n","Epoch 17, Train Loss: 18.5851, Val Loss: 22.8834, F1 Micro: 0.2083, F1 Macro: 0.1607, Accuracy: 0.2083\n","Epoch 18, Train Loss: 20.3287, Val Loss: 13.4846, F1 Micro: 0.2604, F1 Macro: 0.1699, Accuracy: 0.2604\n","Epoch 19, Train Loss: 15.8423, Val Loss: 21.5011, F1 Micro: 0.2188, F1 Macro: 0.1059, Accuracy: 0.2188\n","Epoch 20, Train Loss: 17.6749, Val Loss: 9.1570, F1 Micro: 0.2292, F1 Macro: 0.2148, Accuracy: 0.2292\n","Epoch 21, Train Loss: 14.6989, Val Loss: 24.0316, F1 Micro: 0.1667, F1 Macro: 0.0656, Accuracy: 0.1667\n","Epoch 22, Train Loss: 15.5226, Val Loss: 17.7989, F1 Micro: 0.2188, F1 Macro: 0.1459, Accuracy: 0.2188\n","Epoch 23, Train Loss: 14.9293, Val Loss: 9.7288, F1 Micro: 0.2917, F1 Macro: 0.2252, Accuracy: 0.2917\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 81.9527, Val Loss: 38.5102, F1 Micro: 0.2708, F1 Macro: 0.1666, Accuracy: 0.2708\n","Epoch 2, Train Loss: 35.4354, Val Loss: 24.5388, F1 Micro: 0.2604, F1 Macro: 0.1537, Accuracy: 0.2604\n","Epoch 3, Train Loss: 27.4066, Val Loss: 14.7314, F1 Micro: 0.1875, F1 Macro: 0.1694, Accuracy: 0.1875\n","Epoch 4, Train Loss: 19.2779, Val Loss: 17.5385, F1 Micro: 0.1875, F1 Macro: 0.1390, Accuracy: 0.1875\n","Epoch 5, Train Loss: 17.6954, Val Loss: 21.5915, F1 Micro: 0.1667, F1 Macro: 0.1107, Accuracy: 0.1667\n","Epoch 6, Train Loss: 20.6737, Val Loss: 15.5355, F1 Micro: 0.2396, F1 Macro: 0.1341, Accuracy: 0.2396\n","Epoch 7, Train Loss: 13.4637, Val Loss: 14.8531, F1 Micro: 0.2188, F1 Macro: 0.1578, Accuracy: 0.2188\n","Epoch 8, Train Loss: 17.5316, Val Loss: 33.4077, F1 Micro: 0.2396, F1 Macro: 0.1179, Accuracy: 0.2396\n","Epoch 9, Train Loss: 23.9989, Val Loss: 12.7896, F1 Micro: 0.2604, F1 Macro: 0.1731, Accuracy: 0.2604\n","Epoch 10, Train Loss: 15.0082, Val Loss: 11.8379, F1 Micro: 0.1875, F1 Macro: 0.1674, Accuracy: 0.1875\n","Epoch 11, Train Loss: 15.8708, Val Loss: 19.6300, F1 Micro: 0.2292, F1 Macro: 0.1288, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 75.2010, Val Loss: 28.9027, F1 Micro: 0.1250, F1 Macro: 0.0604, Accuracy: 0.1250\n","Epoch 2, Train Loss: 28.7547, Val Loss: 28.4454, F1 Micro: 0.1875, F1 Macro: 0.0894, Accuracy: 0.1875\n","Epoch 3, Train Loss: 22.8968, Val Loss: 13.2685, F1 Micro: 0.1979, F1 Macro: 0.1003, Accuracy: 0.1979\n","Epoch 4, Train Loss: 15.3088, Val Loss: 23.2759, F1 Micro: 0.2188, F1 Macro: 0.1333, Accuracy: 0.2188\n","Epoch 5, Train Loss: 15.1527, Val Loss: 22.8489, F1 Micro: 0.2396, F1 Macro: 0.1574, Accuracy: 0.2396\n","Epoch 6, Train Loss: 22.0925, Val Loss: 10.4103, F1 Micro: 0.1771, F1 Macro: 0.1483, Accuracy: 0.1771\n","Epoch 7, Train Loss: 20.9814, Val Loss: 23.8547, F1 Micro: 0.1979, F1 Macro: 0.1734, Accuracy: 0.1979\n","Epoch 8, Train Loss: 20.1350, Val Loss: 18.0197, F1 Micro: 0.2500, F1 Macro: 0.1662, Accuracy: 0.2500\n","Epoch 9, Train Loss: 18.2643, Val Loss: 8.9874, F1 Micro: 0.2708, F1 Macro: 0.2057, Accuracy: 0.2708\n","Epoch 10, Train Loss: 20.7845, Val Loss: 24.0606, F1 Micro: 0.1875, F1 Macro: 0.0906, Accuracy: 0.1875\n","Epoch 11, Train Loss: 18.2730, Val Loss: 26.4028, F1 Micro: 0.1875, F1 Macro: 0.0982, Accuracy: 0.1875\n","Epoch 12, Train Loss: 21.5867, Val Loss: 31.5520, F1 Micro: 0.2292, F1 Macro: 0.1738, Accuracy: 0.2292\n","Epoch 13, Train Loss: 23.8678, Val Loss: 18.4657, F1 Micro: 0.1667, F1 Macro: 0.0872, Accuracy: 0.1667\n","Epoch 14, Train Loss: 24.7710, Val Loss: 24.6728, F1 Micro: 0.2500, F1 Macro: 0.1447, Accuracy: 0.2500\n","Epoch 15, Train Loss: 21.0357, Val Loss: 17.8048, F1 Micro: 0.1979, F1 Macro: 0.1569, Accuracy: 0.1979\n","Epoch 16, Train Loss: 17.6594, Val Loss: 13.3050, F1 Micro: 0.2500, F1 Macro: 0.1132, Accuracy: 0.2500\n","Epoch 17, Train Loss: 17.4220, Val Loss: 21.2668, F1 Micro: 0.1875, F1 Macro: 0.1098, Accuracy: 0.1875\n","Epoch 18, Train Loss: 27.7373, Val Loss: 18.4015, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 19, Train Loss: 17.5352, Val Loss: 10.0958, F1 Micro: 0.2708, F1 Macro: 0.1275, Accuracy: 0.2708\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 55.4186, Val Loss: 31.0335, F1 Micro: 0.1250, F1 Macro: 0.0760, Accuracy: 0.1250\n","Epoch 2, Train Loss: 28.9019, Val Loss: 17.3614, F1 Micro: 0.2083, F1 Macro: 0.1321, Accuracy: 0.2083\n","Epoch 3, Train Loss: 17.4031, Val Loss: 28.1868, F1 Micro: 0.2188, F1 Macro: 0.1738, Accuracy: 0.2188\n","Epoch 4, Train Loss: 18.6495, Val Loss: 25.9779, F1 Micro: 0.1875, F1 Macro: 0.0906, Accuracy: 0.1875\n","Epoch 5, Train Loss: 23.0515, Val Loss: 24.0930, F1 Micro: 0.2188, F1 Macro: 0.1394, Accuracy: 0.2188\n","Epoch 6, Train Loss: 16.0335, Val Loss: 17.7664, F1 Micro: 0.1979, F1 Macro: 0.1067, Accuracy: 0.1979\n","Epoch 7, Train Loss: 16.3088, Val Loss: 20.3818, F1 Micro: 0.2188, F1 Macro: 0.1488, Accuracy: 0.2188\n","Epoch 8, Train Loss: 23.6971, Val Loss: 9.8062, F1 Micro: 0.2083, F1 Macro: 0.1332, Accuracy: 0.2083\n","Epoch 9, Train Loss: 22.3298, Val Loss: 30.0899, F1 Micro: 0.2188, F1 Macro: 0.1569, Accuracy: 0.2188\n","Epoch 10, Train Loss: 24.3279, Val Loss: 44.2958, F1 Micro: 0.1667, F1 Macro: 0.0480, Accuracy: 0.1667\n","Epoch 11, Train Loss: 29.5469, Val Loss: 23.1726, F1 Micro: 0.2292, F1 Macro: 0.1476, Accuracy: 0.2292\n","Epoch 12, Train Loss: 24.7955, Val Loss: 41.3893, F1 Micro: 0.2188, F1 Macro: 0.1145, Accuracy: 0.2188\n","Epoch 13, Train Loss: 20.1240, Val Loss: 22.3218, F1 Micro: 0.1667, F1 Macro: 0.0787, Accuracy: 0.1667\n","Epoch 14, Train Loss: 13.7408, Val Loss: 9.4534, F1 Micro: 0.2500, F1 Macro: 0.1542, Accuracy: 0.2500\n","Epoch 15, Train Loss: 15.5177, Val Loss: 22.6503, F1 Micro: 0.1458, F1 Macro: 0.0583, Accuracy: 0.1458\n","Epoch 16, Train Loss: 13.3828, Val Loss: 19.8894, F1 Micro: 0.1875, F1 Macro: 0.0904, Accuracy: 0.1875\n","Epoch 17, Train Loss: 22.3299, Val Loss: 19.3847, F1 Micro: 0.2188, F1 Macro: 0.1087, Accuracy: 0.2188\n","Epoch 18, Train Loss: 19.8320, Val Loss: 11.1692, F1 Micro: 0.2396, F1 Macro: 0.1936, Accuracy: 0.2396\n","Epoch 19, Train Loss: 16.7237, Val Loss: 23.4530, F1 Micro: 0.2292, F1 Macro: 0.1294, Accuracy: 0.2292\n","Epoch 20, Train Loss: 18.6553, Val Loss: 19.0232, F1 Micro: 0.2188, F1 Macro: 0.1089, Accuracy: 0.2188\n","Epoch 21, Train Loss: 11.3345, Val Loss: 21.4691, F1 Micro: 0.1771, F1 Macro: 0.0914, Accuracy: 0.1771\n","Epoch 22, Train Loss: 20.9157, Val Loss: 27.9646, F1 Micro: 0.2083, F1 Macro: 0.1142, Accuracy: 0.2083\n","Epoch 23, Train Loss: 22.2976, Val Loss: 23.1808, F1 Micro: 0.1979, F1 Macro: 0.1266, Accuracy: 0.1979\n","Epoch 24, Train Loss: 20.6320, Val Loss: 14.7129, F1 Micro: 0.2292, F1 Macro: 0.1482, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 68.6350, Val Loss: 20.5907, F1 Micro: 0.2083, F1 Macro: 0.1415, Accuracy: 0.2083\n","Epoch 2, Train Loss: 28.4968, Val Loss: 15.5304, F1 Micro: 0.2292, F1 Macro: 0.1806, Accuracy: 0.2292\n","Epoch 3, Train Loss: 26.5714, Val Loss: 18.7209, F1 Micro: 0.2292, F1 Macro: 0.1330, Accuracy: 0.2292\n","Epoch 4, Train Loss: 25.1203, Val Loss: 24.4836, F1 Micro: 0.2083, F1 Macro: 0.1458, Accuracy: 0.2083\n","Epoch 5, Train Loss: 23.1828, Val Loss: 24.3000, F1 Micro: 0.1458, F1 Macro: 0.0604, Accuracy: 0.1458\n","Epoch 6, Train Loss: 17.6814, Val Loss: 20.0502, F1 Micro: 0.1458, F1 Macro: 0.0674, Accuracy: 0.1458\n","Epoch 7, Train Loss: 16.7027, Val Loss: 17.1373, F1 Micro: 0.2292, F1 Macro: 0.1624, Accuracy: 0.2292\n","Epoch 8, Train Loss: 16.4963, Val Loss: 18.0259, F1 Micro: 0.2500, F1 Macro: 0.1223, Accuracy: 0.2500\n","Epoch 9, Train Loss: 20.9777, Val Loss: 11.7670, F1 Micro: 0.2708, F1 Macro: 0.1925, Accuracy: 0.2708\n","Epoch 10, Train Loss: 15.1663, Val Loss: 17.6503, F1 Micro: 0.2500, F1 Macro: 0.1223, Accuracy: 0.2500\n","Epoch 11, Train Loss: 14.9854, Val Loss: 18.9134, F1 Micro: 0.1979, F1 Macro: 0.1190, Accuracy: 0.1979\n","Epoch 12, Train Loss: 15.2439, Val Loss: 14.2265, F1 Micro: 0.2083, F1 Macro: 0.0585, Accuracy: 0.2083\n","Epoch 13, Train Loss: 9.3086, Val Loss: 19.2482, F1 Micro: 0.1875, F1 Macro: 0.0897, Accuracy: 0.1875\n","Epoch 14, Train Loss: 20.4698, Val Loss: 14.6112, F1 Micro: 0.3021, F1 Macro: 0.2520, Accuracy: 0.3021\n","Epoch 15, Train Loss: 13.6540, Val Loss: 11.0565, F1 Micro: 0.2604, F1 Macro: 0.1802, Accuracy: 0.2604\n","Epoch 16, Train Loss: 10.3336, Val Loss: 15.8805, F1 Micro: 0.2396, F1 Macro: 0.1368, Accuracy: 0.2396\n","Epoch 17, Train Loss: 12.2462, Val Loss: 17.7537, F1 Micro: 0.2500, F1 Macro: 0.1242, Accuracy: 0.2500\n","Epoch 18, Train Loss: 17.6800, Val Loss: 11.6985, F1 Micro: 0.2604, F1 Macro: 0.1970, Accuracy: 0.2604\n","Epoch 19, Train Loss: 15.9363, Val Loss: 11.7680, F1 Micro: 0.3021, F1 Macro: 0.2519, Accuracy: 0.3021\n","Epoch 20, Train Loss: 14.5517, Val Loss: 7.9437, F1 Micro: 0.2500, F1 Macro: 0.1787, Accuracy: 0.2500\n","Epoch 21, Train Loss: 9.0081, Val Loss: 9.0972, F1 Micro: 0.2292, F1 Macro: 0.1683, Accuracy: 0.2292\n","Epoch 22, Train Loss: 11.0369, Val Loss: 15.4718, F1 Micro: 0.2292, F1 Macro: 0.0907, Accuracy: 0.2292\n","Epoch 23, Train Loss: 14.3323, Val Loss: 21.1313, F1 Micro: 0.1979, F1 Macro: 0.1353, Accuracy: 0.1979\n","Epoch 24, Train Loss: 26.7144, Val Loss: 15.0271, F1 Micro: 0.2812, F1 Macro: 0.1721, Accuracy: 0.2812\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.2770833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 62.5978, Val Loss: 36.3006, F1 Micro: 0.2812, F1 Macro: 0.1893, Accuracy: 0.2812\n","Epoch 2, Train Loss: 33.4493, Val Loss: 27.9965, F1 Micro: 0.1979, F1 Macro: 0.1000, Accuracy: 0.1979\n","Epoch 3, Train Loss: 27.2919, Val Loss: 27.0598, F1 Micro: 0.2083, F1 Macro: 0.0745, Accuracy: 0.2083\n","Epoch 4, Train Loss: 20.6232, Val Loss: 17.4280, F1 Micro: 0.3021, F1 Macro: 0.1998, Accuracy: 0.3021\n","Epoch 5, Train Loss: 18.8072, Val Loss: 28.6610, F1 Micro: 0.1354, F1 Macro: 0.0421, Accuracy: 0.1354\n","Epoch 6, Train Loss: 23.5570, Val Loss: 25.5899, F1 Micro: 0.1250, F1 Macro: 0.0702, Accuracy: 0.1250\n","Epoch 7, Train Loss: 22.7494, Val Loss: 15.3487, F1 Micro: 0.2396, F1 Macro: 0.1903, Accuracy: 0.2396\n","Epoch 8, Train Loss: 21.4715, Val Loss: 25.0291, F1 Micro: 0.2396, F1 Macro: 0.1333, Accuracy: 0.2396\n","Epoch 9, Train Loss: 30.8152, Val Loss: 23.1322, F1 Micro: 0.1979, F1 Macro: 0.1242, Accuracy: 0.1979\n","Epoch 10, Train Loss: 27.6874, Val Loss: 35.7782, F1 Micro: 0.2500, F1 Macro: 0.2178, Accuracy: 0.2500\n","Epoch 11, Train Loss: 20.9088, Val Loss: 11.3614, F1 Micro: 0.2083, F1 Macro: 0.1141, Accuracy: 0.2083\n","Epoch 12, Train Loss: 17.6148, Val Loss: 23.1002, F1 Micro: 0.3021, F1 Macro: 0.2298, Accuracy: 0.3021\n","Epoch 13, Train Loss: 16.5510, Val Loss: 11.1070, F1 Micro: 0.3125, F1 Macro: 0.2551, Accuracy: 0.3125\n","Epoch 14, Train Loss: 10.9253, Val Loss: 13.3458, F1 Micro: 0.2188, F1 Macro: 0.1644, Accuracy: 0.2188\n","Epoch 15, Train Loss: 20.4382, Val Loss: 23.5791, F1 Micro: 0.2812, F1 Macro: 0.2203, Accuracy: 0.2812\n","Epoch 16, Train Loss: 21.3044, Val Loss: 18.2091, F1 Micro: 0.1875, F1 Macro: 0.1505, Accuracy: 0.1875\n","Epoch 17, Train Loss: 12.0679, Val Loss: 9.0248, F1 Micro: 0.2812, F1 Macro: 0.2171, Accuracy: 0.2812\n","Epoch 18, Train Loss: 14.4191, Val Loss: 12.2792, F1 Micro: 0.2812, F1 Macro: 0.2247, Accuracy: 0.2812\n","Epoch 19, Train Loss: 17.6350, Val Loss: 7.6484, F1 Micro: 0.2500, F1 Macro: 0.1856, Accuracy: 0.2500\n","Epoch 20, Train Loss: 14.2075, Val Loss: 17.9068, F1 Micro: 0.2708, F1 Macro: 0.1793, Accuracy: 0.2708\n","Epoch 21, Train Loss: 16.3590, Val Loss: 20.7798, F1 Micro: 0.2708, F1 Macro: 0.1642, Accuracy: 0.2708\n","Epoch 22, Train Loss: 24.4147, Val Loss: 25.6369, F1 Micro: 0.1979, F1 Macro: 0.1188, Accuracy: 0.1979\n","Epoch 23, Train Loss: 11.7468, Val Loss: 7.9360, F1 Micro: 0.3021, F1 Macro: 0.2431, Accuracy: 0.3021\n","Epoch 24, Train Loss: 13.6555, Val Loss: 15.4972, F1 Micro: 0.2188, F1 Macro: 0.1771, Accuracy: 0.2188\n","Epoch 25, Train Loss: 16.6818, Val Loss: 34.2164, F1 Micro: 0.1562, F1 Macro: 0.0450, Accuracy: 0.1562\n","Epoch 26, Train Loss: 25.5048, Val Loss: 13.5958, F1 Micro: 0.2604, F1 Macro: 0.2126, Accuracy: 0.2604\n","Epoch 27, Train Loss: 15.6506, Val Loss: 18.2356, F1 Micro: 0.2604, F1 Macro: 0.1985, Accuracy: 0.2604\n","Epoch 28, Train Loss: 14.3378, Val Loss: 19.1654, F1 Micro: 0.1458, F1 Macro: 0.0715, Accuracy: 0.1458\n","Epoch 29, Train Loss: 14.4163, Val Loss: 17.7112, F1 Micro: 0.2708, F1 Macro: 0.2396, Accuracy: 0.2708\n","Epoch 30, Train Loss: 11.4942, Val Loss: 14.5738, F1 Micro: 0.2292, F1 Macro: 0.1880, Accuracy: 0.2292\n","Epoch 31, Train Loss: 15.3851, Val Loss: 16.5627, F1 Micro: 0.2292, F1 Macro: 0.1529, Accuracy: 0.2292\n","Epoch 32, Train Loss: 12.9288, Val Loss: 17.1331, F1 Micro: 0.1667, F1 Macro: 0.0991, Accuracy: 0.1667\n","Epoch 33, Train Loss: 18.4820, Val Loss: 10.4535, F1 Micro: 0.2917, F1 Macro: 0.2481, Accuracy: 0.2917\n","Epoch 34, Train Loss: 16.3804, Val Loss: 11.1503, F1 Micro: 0.2188, F1 Macro: 0.1503, Accuracy: 0.2188\n","Epoch 35, Train Loss: 14.0766, Val Loss: 13.0840, F1 Micro: 0.3125, F1 Macro: 0.2627, Accuracy: 0.3125\n","Epoch 36, Train Loss: 18.0205, Val Loss: 31.2063, F1 Micro: 0.2083, F1 Macro: 0.1096, Accuracy: 0.2083\n","Epoch 37, Train Loss: 19.6097, Val Loss: 13.0682, F1 Micro: 0.3229, F1 Macro: 0.2920, Accuracy: 0.3229\n","Epoch 38, Train Loss: 18.7484, Val Loss: 18.8894, F1 Micro: 0.2812, F1 Macro: 0.2150, Accuracy: 0.2812\n","Epoch 39, Train Loss: 19.4303, Val Loss: 20.7993, F1 Micro: 0.2292, F1 Macro: 0.1583, Accuracy: 0.2292\n","Epoch 40, Train Loss: 18.8687, Val Loss: 18.6638, F1 Micro: 0.2083, F1 Macro: 0.1423, Accuracy: 0.2083\n","Epoch 41, Train Loss: 16.4853, Val Loss: 26.2607, F1 Micro: 0.1771, F1 Macro: 0.0930, Accuracy: 0.1771\n","Epoch 42, Train Loss: 13.8756, Val Loss: 17.1556, F1 Micro: 0.2500, F1 Macro: 0.2261, Accuracy: 0.2500\n","Epoch 43, Train Loss: 15.6885, Val Loss: 25.8892, F1 Micro: 0.2604, F1 Macro: 0.1575, Accuracy: 0.2604\n","Epoch 44, Train Loss: 21.4076, Val Loss: 13.7471, F1 Micro: 0.1979, F1 Macro: 0.1403, Accuracy: 0.1979\n","Epoch 45, Train Loss: 16.1815, Val Loss: 14.3786, F1 Micro: 0.2500, F1 Macro: 0.2066, Accuracy: 0.2500\n","Epoch 46, Train Loss: 19.7427, Val Loss: 17.3648, F1 Micro: 0.3125, F1 Macro: 0.2273, Accuracy: 0.3125\n","Epoch 47, Train Loss: 16.0322, Val Loss: 22.4769, F1 Micro: 0.2083, F1 Macro: 0.1299, Accuracy: 0.2083\n","Epoch 48, Train Loss: 13.4468, Val Loss: 19.9230, F1 Micro: 0.3021, F1 Macro: 0.2718, Accuracy: 0.3021\n","Epoch 49, Train Loss: 14.8887, Val Loss: 9.3923, F1 Micro: 0.2812, F1 Macro: 0.2109, Accuracy: 0.2812\n","Epoch 50, Train Loss: 10.4028, Val Loss: 14.6563, F1 Micro: 0.2708, F1 Macro: 0.1796, Accuracy: 0.2708\n","Epoch 51, Train Loss: 12.6774, Val Loss: 9.4838, F1 Micro: 0.2604, F1 Macro: 0.2234, Accuracy: 0.2604\n","Epoch 52, Train Loss: 11.3323, Val Loss: 20.3179, F1 Micro: 0.1667, F1 Macro: 0.0822, Accuracy: 0.1667\n","Epoch 53, Train Loss: 19.1323, Val Loss: 19.3940, F1 Micro: 0.1667, F1 Macro: 0.1367, Accuracy: 0.1667\n","Epoch 54, Train Loss: 12.9928, Val Loss: 13.5595, F1 Micro: 0.2917, F1 Macro: 0.2566, Accuracy: 0.2917\n","Epoch 55, Train Loss: 11.2206, Val Loss: 6.2733, F1 Micro: 0.2708, F1 Macro: 0.2680, Accuracy: 0.2708\n","Epoch 56, Train Loss: 11.1243, Val Loss: 15.9791, F1 Micro: 0.1875, F1 Macro: 0.1139, Accuracy: 0.1875\n","Epoch 57, Train Loss: 12.1911, Val Loss: 7.8269, F1 Micro: 0.3333, F1 Macro: 0.2973, Accuracy: 0.3333\n","Epoch 58, Train Loss: 13.4394, Val Loss: 15.6137, F1 Micro: 0.2188, F1 Macro: 0.1907, Accuracy: 0.2188\n","Epoch 59, Train Loss: 12.8083, Val Loss: 16.9581, F1 Micro: 0.2604, F1 Macro: 0.2339, Accuracy: 0.2604\n","Epoch 60, Train Loss: 9.8272, Val Loss: 8.8595, F1 Micro: 0.2812, F1 Macro: 0.2141, Accuracy: 0.2812\n","Epoch 61, Train Loss: 12.1750, Val Loss: 22.3632, F1 Micro: 0.2500, F1 Macro: 0.1267, Accuracy: 0.2500\n","Epoch 62, Train Loss: 13.7024, Val Loss: 24.7286, F1 Micro: 0.2917, F1 Macro: 0.1930, Accuracy: 0.2917\n","Epoch 63, Train Loss: 15.3616, Val Loss: 14.0332, F1 Micro: 0.1979, F1 Macro: 0.1724, Accuracy: 0.1979\n","Epoch 64, Train Loss: 16.2850, Val Loss: 12.4208, F1 Micro: 0.2604, F1 Macro: 0.2512, Accuracy: 0.2604\n","Epoch 65, Train Loss: 15.8037, Val Loss: 16.5591, F1 Micro: 0.2188, F1 Macro: 0.1632, Accuracy: 0.2188\n","Epoch 66, Train Loss: 14.1302, Val Loss: 14.6907, F1 Micro: 0.1875, F1 Macro: 0.1237, Accuracy: 0.1875\n","Epoch 67, Train Loss: 14.9535, Val Loss: 8.8513, F1 Micro: 0.2917, F1 Macro: 0.2244, Accuracy: 0.2917\n","Epoch 68, Train Loss: 11.9944, Val Loss: 16.4548, F1 Micro: 0.2500, F1 Macro: 0.1726, Accuracy: 0.2500\n","Epoch 69, Train Loss: 9.7800, Val Loss: 9.1919, F1 Micro: 0.2812, F1 Macro: 0.1958, Accuracy: 0.2812\n","Epoch 70, Train Loss: 11.2569, Val Loss: 12.2531, F1 Micro: 0.1979, F1 Macro: 0.1747, Accuracy: 0.1979\n","Epoch 71, Train Loss: 9.6350, Val Loss: 17.4738, F1 Micro: 0.2500, F1 Macro: 0.1800, Accuracy: 0.2500\n","Epoch 72, Train Loss: 13.5062, Val Loss: 8.9504, F1 Micro: 0.3125, F1 Macro: 0.2475, Accuracy: 0.3125\n","Epoch 73, Train Loss: 14.1175, Val Loss: 7.4757, F1 Micro: 0.2708, F1 Macro: 0.2613, Accuracy: 0.2708\n","Epoch 74, Train Loss: 13.8585, Val Loss: 13.5296, F1 Micro: 0.2188, F1 Macro: 0.1440, Accuracy: 0.2188\n","Epoch 75, Train Loss: 19.6495, Val Loss: 15.7846, F1 Micro: 0.2083, F1 Macro: 0.1432, Accuracy: 0.2083\n","Epoch 76, Train Loss: 11.8175, Val Loss: 10.7475, F1 Micro: 0.3021, F1 Macro: 0.2784, Accuracy: 0.3021\n","Epoch 77, Train Loss: 8.0673, Val Loss: 10.2058, F1 Micro: 0.1875, F1 Macro: 0.1323, Accuracy: 0.1875\n","Epoch 78, Train Loss: 13.8734, Val Loss: 13.1761, F1 Micro: 0.1979, F1 Macro: 0.1583, Accuracy: 0.1979\n","Epoch 79, Train Loss: 13.5593, Val Loss: 20.1204, F1 Micro: 0.2500, F1 Macro: 0.2232, Accuracy: 0.2500\n","Epoch 80, Train Loss: 17.5265, Val Loss: 19.8794, F1 Micro: 0.2292, F1 Macro: 0.1368, Accuracy: 0.2292\n","Epoch 81, Train Loss: 14.6375, Val Loss: 6.5180, F1 Micro: 0.1875, F1 Macro: 0.1436, Accuracy: 0.1875\n","Epoch 82, Train Loss: 9.6172, Val Loss: 9.4794, F1 Micro: 0.3021, F1 Macro: 0.2455, Accuracy: 0.3021\n","Epoch 83, Train Loss: 8.6318, Val Loss: 7.9987, F1 Micro: 0.2708, F1 Macro: 0.2011, Accuracy: 0.2708\n","Epoch 84, Train Loss: 8.7227, Val Loss: 5.8771, F1 Micro: 0.3229, F1 Macro: 0.2744, Accuracy: 0.3229\n","Epoch 85, Train Loss: 12.7244, Val Loss: 12.3806, F1 Micro: 0.3333, F1 Macro: 0.2730, Accuracy: 0.3333\n","Epoch 86, Train Loss: 13.1098, Val Loss: 6.5813, F1 Micro: 0.3125, F1 Macro: 0.2811, Accuracy: 0.3125\n","Epoch 87, Train Loss: 9.6551, Val Loss: 11.0544, F1 Micro: 0.3229, F1 Macro: 0.2880, Accuracy: 0.3229\n","Epoch 88, Train Loss: 7.7700, Val Loss: 5.9836, F1 Micro: 0.3021, F1 Macro: 0.2814, Accuracy: 0.3021\n","Epoch 89, Train Loss: 9.7326, Val Loss: 11.6131, F1 Micro: 0.2292, F1 Macro: 0.2139, Accuracy: 0.2292\n","Epoch 90, Train Loss: 10.1177, Val Loss: 10.5758, F1 Micro: 0.2292, F1 Macro: 0.1492, Accuracy: 0.2292\n","Epoch 91, Train Loss: 12.9594, Val Loss: 23.6294, F1 Micro: 0.2188, F1 Macro: 0.1600, Accuracy: 0.2188\n","Epoch 92, Train Loss: 13.7845, Val Loss: 7.8920, F1 Micro: 0.2188, F1 Macro: 0.1631, Accuracy: 0.2188\n","Epoch 93, Train Loss: 9.5713, Val Loss: 27.5587, F1 Micro: 0.1771, F1 Macro: 0.1281, Accuracy: 0.1771\n","Epoch 94, Train Loss: 16.1450, Val Loss: 11.1291, F1 Micro: 0.2396, F1 Macro: 0.2010, Accuracy: 0.2396\n","Epoch 95, Train Loss: 7.6801, Val Loss: 8.5060, F1 Micro: 0.2708, F1 Macro: 0.1855, Accuracy: 0.2708\n","Epoch 96, Train Loss: 10.7616, Val Loss: 17.4669, F1 Micro: 0.2083, F1 Macro: 0.1558, Accuracy: 0.2083\n","Epoch 97, Train Loss: 14.3128, Val Loss: 14.2849, F1 Micro: 0.2604, F1 Macro: 0.1919, Accuracy: 0.2604\n","Epoch 98, Train Loss: 15.4657, Val Loss: 16.4736, F1 Micro: 0.1875, F1 Macro: 0.1463, Accuracy: 0.1875\n","Epoch 99, Train Loss: 9.6631, Val Loss: 9.5261, F1 Micro: 0.2188, F1 Macro: 0.1587, Accuracy: 0.2188\n","Epoch 100, Train Loss: 12.0925, Val Loss: 15.2053, F1 Micro: 0.1771, F1 Macro: 0.1186, Accuracy: 0.1771\n","Epoch 101, Train Loss: 17.8122, Val Loss: 27.7582, F1 Micro: 0.2396, F1 Macro: 0.2249, Accuracy: 0.2396\n","Epoch 102, Train Loss: 13.3163, Val Loss: 12.0413, F1 Micro: 0.3021, F1 Macro: 0.2291, Accuracy: 0.3021\n","Epoch 103, Train Loss: 11.9895, Val Loss: 9.8828, F1 Micro: 0.3854, F1 Macro: 0.3614, Accuracy: 0.3854\n","Epoch 104, Train Loss: 10.1988, Val Loss: 7.6104, F1 Micro: 0.2188, F1 Macro: 0.1808, Accuracy: 0.2188\n","Epoch 105, Train Loss: 9.4312, Val Loss: 12.1020, F1 Micro: 0.2500, F1 Macro: 0.1332, Accuracy: 0.2500\n","Epoch 106, Train Loss: 12.0140, Val Loss: 10.0438, F1 Micro: 0.3229, F1 Macro: 0.2437, Accuracy: 0.3229\n","Epoch 107, Train Loss: 10.8498, Val Loss: 6.3742, F1 Micro: 0.2396, F1 Macro: 0.2460, Accuracy: 0.2396\n","Epoch 108, Train Loss: 6.5517, Val Loss: 9.2136, F1 Micro: 0.2500, F1 Macro: 0.1633, Accuracy: 0.2500\n","Epoch 109, Train Loss: 8.9819, Val Loss: 8.0573, F1 Micro: 0.2500, F1 Macro: 0.1330, Accuracy: 0.2500\n","Epoch 110, Train Loss: 14.5255, Val Loss: 18.6326, F1 Micro: 0.2604, F1 Macro: 0.1568, Accuracy: 0.2604\n","Epoch 111, Train Loss: 8.7924, Val Loss: 15.9823, F1 Micro: 0.2917, F1 Macro: 0.1841, Accuracy: 0.2917\n","Epoch 112, Train Loss: 8.9682, Val Loss: 19.5963, F1 Micro: 0.2396, F1 Macro: 0.1984, Accuracy: 0.2396\n","Epoch 113, Train Loss: 15.2065, Val Loss: 12.6629, F1 Micro: 0.2500, F1 Macro: 0.2113, Accuracy: 0.2500\n","Epoch 114, Train Loss: 11.8296, Val Loss: 14.3322, F1 Micro: 0.1875, F1 Macro: 0.1007, Accuracy: 0.1875\n","Epoch 115, Train Loss: 10.6543, Val Loss: 10.3560, F1 Micro: 0.1979, F1 Macro: 0.1673, Accuracy: 0.1979\n","Epoch 116, Train Loss: 7.8707, Val Loss: 17.2480, F1 Micro: 0.2708, F1 Macro: 0.2239, Accuracy: 0.2708\n","Epoch 117, Train Loss: 11.0965, Val Loss: 8.4151, F1 Micro: 0.2396, F1 Macro: 0.1622, Accuracy: 0.2396\n","Epoch 118, Train Loss: 10.8063, Val Loss: 6.7285, F1 Micro: 0.3021, F1 Macro: 0.2393, Accuracy: 0.3021\n","Epoch 119, Train Loss: 10.5395, Val Loss: 12.8375, F1 Micro: 0.3333, F1 Macro: 0.2890, Accuracy: 0.3333\n","Epoch 120, Train Loss: 19.4918, Val Loss: 18.2716, F1 Micro: 0.1771, F1 Macro: 0.1289, Accuracy: 0.1771\n","Epoch 121, Train Loss: 11.4186, Val Loss: 15.3316, F1 Micro: 0.1771, F1 Macro: 0.1186, Accuracy: 0.1771\n","Epoch 122, Train Loss: 9.9318, Val Loss: 11.9253, F1 Micro: 0.2604, F1 Macro: 0.1424, Accuracy: 0.2604\n","Epoch 123, Train Loss: 10.8534, Val Loss: 11.3192, F1 Micro: 0.3229, F1 Macro: 0.2809, Accuracy: 0.3229\n","Epoch 124, Train Loss: 11.2559, Val Loss: 12.5382, F1 Micro: 0.1979, F1 Macro: 0.1442, Accuracy: 0.1979\n","Epoch 125, Train Loss: 7.2364, Val Loss: 11.1757, F1 Micro: 0.2708, F1 Macro: 0.2420, Accuracy: 0.2708\n","Epoch 126, Train Loss: 8.6530, Val Loss: 11.2568, F1 Micro: 0.2083, F1 Macro: 0.1700, Accuracy: 0.2083\n","Epoch 127, Train Loss: 11.6844, Val Loss: 17.7542, F1 Micro: 0.2083, F1 Macro: 0.1667, Accuracy: 0.2083\n","Epoch 128, Train Loss: 10.2973, Val Loss: 9.6640, F1 Micro: 0.2292, F1 Macro: 0.1598, Accuracy: 0.2292\n","Epoch 129, Train Loss: 7.8904, Val Loss: 9.7321, F1 Micro: 0.3333, F1 Macro: 0.2504, Accuracy: 0.3333\n","Epoch 130, Train Loss: 8.5807, Val Loss: 5.4105, F1 Micro: 0.2188, F1 Macro: 0.1735, Accuracy: 0.2188\n","Epoch 131, Train Loss: 9.1815, Val Loss: 9.8886, F1 Micro: 0.2604, F1 Macro: 0.1986, Accuracy: 0.2604\n","Epoch 132, Train Loss: 10.9344, Val Loss: 11.5461, F1 Micro: 0.2396, F1 Macro: 0.2064, Accuracy: 0.2396\n","Epoch 133, Train Loss: 11.3688, Val Loss: 13.3145, F1 Micro: 0.2188, F1 Macro: 0.2032, Accuracy: 0.2188\n","Epoch 134, Train Loss: 10.8585, Val Loss: 13.8195, F1 Micro: 0.2396, F1 Macro: 0.1546, Accuracy: 0.2396\n","Epoch 135, Train Loss: 12.1682, Val Loss: 10.3959, F1 Micro: 0.2500, F1 Macro: 0.2168, Accuracy: 0.2500\n","Epoch 136, Train Loss: 9.2049, Val Loss: 8.0567, F1 Micro: 0.2917, F1 Macro: 0.2481, Accuracy: 0.2917\n","Epoch 137, Train Loss: 6.6344, Val Loss: 8.9473, F1 Micro: 0.1667, F1 Macro: 0.1435, Accuracy: 0.1667\n","Epoch 138, Train Loss: 12.1014, Val Loss: 16.9699, F1 Micro: 0.2812, F1 Macro: 0.2059, Accuracy: 0.2812\n","Epoch 139, Train Loss: 9.8995, Val Loss: 13.6622, F1 Micro: 0.2396, F1 Macro: 0.1941, Accuracy: 0.2396\n","Epoch 140, Train Loss: 8.7479, Val Loss: 4.3214, F1 Micro: 0.4271, F1 Macro: 0.3593, Accuracy: 0.4271\n","Epoch 141, Train Loss: 7.0317, Val Loss: 10.3596, F1 Micro: 0.3333, F1 Macro: 0.3090, Accuracy: 0.3333\n","Epoch 142, Train Loss: 6.1815, Val Loss: 6.4419, F1 Micro: 0.3229, F1 Macro: 0.2873, Accuracy: 0.3229\n","Epoch 143, Train Loss: 9.6113, Val Loss: 15.0398, F1 Micro: 0.2188, F1 Macro: 0.1737, Accuracy: 0.2188\n","Epoch 144, Train Loss: 9.6352, Val Loss: 7.2525, F1 Micro: 0.2396, F1 Macro: 0.1828, Accuracy: 0.2396\n","Epoch 145, Train Loss: 8.5848, Val Loss: 12.4282, F1 Micro: 0.3333, F1 Macro: 0.2787, Accuracy: 0.3333\n","Epoch 146, Train Loss: 10.9130, Val Loss: 11.3524, F1 Micro: 0.2917, F1 Macro: 0.3075, Accuracy: 0.2917\n","Epoch 147, Train Loss: 8.5894, Val Loss: 6.2295, F1 Micro: 0.3229, F1 Macro: 0.2961, Accuracy: 0.3229\n","Epoch 148, Train Loss: 9.5087, Val Loss: 14.5422, F1 Micro: 0.1875, F1 Macro: 0.0960, Accuracy: 0.1875\n","Epoch 149, Train Loss: 8.4899, Val Loss: 6.2026, F1 Micro: 0.3125, F1 Macro: 0.2623, Accuracy: 0.3125\n","Epoch 150, Train Loss: 7.8883, Val Loss: 13.3916, F1 Micro: 0.1875, F1 Macro: 0.1391, Accuracy: 0.1875\n","Epoch 151, Train Loss: 9.0020, Val Loss: 10.3035, F1 Micro: 0.2083, F1 Macro: 0.1376, Accuracy: 0.2083\n","Epoch 152, Train Loss: 10.7686, Val Loss: 11.5965, F1 Micro: 0.2292, F1 Macro: 0.1795, Accuracy: 0.2292\n","Epoch 153, Train Loss: 10.2867, Val Loss: 9.9770, F1 Micro: 0.3438, F1 Macro: 0.2717, Accuracy: 0.3438\n","Epoch 154, Train Loss: 6.6463, Val Loss: 7.3695, F1 Micro: 0.3750, F1 Macro: 0.2954, Accuracy: 0.3750\n","Epoch 155, Train Loss: 9.7239, Val Loss: 13.6165, F1 Micro: 0.2917, F1 Macro: 0.2112, Accuracy: 0.2917\n","Epoch 156, Train Loss: 11.4570, Val Loss: 8.6288, F1 Micro: 0.2500, F1 Macro: 0.1931, Accuracy: 0.2500\n","Epoch 157, Train Loss: 8.2137, Val Loss: 7.5260, F1 Micro: 0.4062, F1 Macro: 0.3394, Accuracy: 0.4062\n","Epoch 158, Train Loss: 7.7853, Val Loss: 12.0514, F1 Micro: 0.2604, F1 Macro: 0.2295, Accuracy: 0.2604\n","Epoch 159, Train Loss: 7.9982, Val Loss: 10.2807, F1 Micro: 0.3229, F1 Macro: 0.2811, Accuracy: 0.3229\n","Epoch 160, Train Loss: 10.2515, Val Loss: 12.7873, F1 Micro: 0.2188, F1 Macro: 0.1641, Accuracy: 0.2188\n","Epoch 161, Train Loss: 9.9477, Val Loss: 7.2619, F1 Micro: 0.2188, F1 Macro: 0.1873, Accuracy: 0.2188\n","Epoch 162, Train Loss: 7.6857, Val Loss: 9.8055, F1 Micro: 0.2708, F1 Macro: 0.2240, Accuracy: 0.2708\n","Epoch 163, Train Loss: 6.0266, Val Loss: 4.2526, F1 Micro: 0.3854, F1 Macro: 0.3497, Accuracy: 0.3854\n","Epoch 164, Train Loss: 5.2806, Val Loss: 5.9569, F1 Micro: 0.2917, F1 Macro: 0.2001, Accuracy: 0.2917\n","Epoch 165, Train Loss: 7.8976, Val Loss: 7.3829, F1 Micro: 0.3021, F1 Macro: 0.2296, Accuracy: 0.3021\n","Epoch 166, Train Loss: 4.7360, Val Loss: 4.9395, F1 Micro: 0.2188, F1 Macro: 0.2045, Accuracy: 0.2188\n","Epoch 167, Train Loss: 7.0668, Val Loss: 6.5463, F1 Micro: 0.1875, F1 Macro: 0.1573, Accuracy: 0.1875\n","Epoch 168, Train Loss: 7.8134, Val Loss: 5.2699, F1 Micro: 0.2812, F1 Macro: 0.2685, Accuracy: 0.2812\n","Epoch 169, Train Loss: 9.5067, Val Loss: 9.3718, F1 Micro: 0.2917, F1 Macro: 0.2409, Accuracy: 0.2917\n","Epoch 170, Train Loss: 7.6125, Val Loss: 7.6660, F1 Micro: 0.3125, F1 Macro: 0.2217, Accuracy: 0.3125\n","Epoch 171, Train Loss: 10.0632, Val Loss: 10.4259, F1 Micro: 0.3229, F1 Macro: 0.2704, Accuracy: 0.3229\n","Epoch 172, Train Loss: 8.5042, Val Loss: 16.3040, F1 Micro: 0.2292, F1 Macro: 0.1698, Accuracy: 0.2292\n","Epoch 173, Train Loss: 10.0072, Val Loss: 11.0577, F1 Micro: 0.3021, F1 Macro: 0.2361, Accuracy: 0.3021\n","Epoch 174, Train Loss: 8.7696, Val Loss: 12.9846, F1 Micro: 0.1875, F1 Macro: 0.1093, Accuracy: 0.1875\n","Epoch 175, Train Loss: 9.8182, Val Loss: 12.8916, F1 Micro: 0.2812, F1 Macro: 0.1749, Accuracy: 0.2812\n","Epoch 176, Train Loss: 9.5390, Val Loss: 8.6373, F1 Micro: 0.2083, F1 Macro: 0.1494, Accuracy: 0.2083\n","Epoch 177, Train Loss: 5.7045, Val Loss: 5.0780, F1 Micro: 0.2917, F1 Macro: 0.2394, Accuracy: 0.2917\n","Epoch 178, Train Loss: 5.2874, Val Loss: 6.5547, F1 Micro: 0.2604, F1 Macro: 0.2491, Accuracy: 0.2604\n","Epoch 179, Train Loss: 6.2261, Val Loss: 6.2545, F1 Micro: 0.3542, F1 Macro: 0.2996, Accuracy: 0.3542\n","Epoch 180, Train Loss: 7.0729, Val Loss: 9.7859, F1 Micro: 0.2292, F1 Macro: 0.2017, Accuracy: 0.2292\n","Epoch 181, Train Loss: 11.6103, Val Loss: 13.3291, F1 Micro: 0.2500, F1 Macro: 0.2117, Accuracy: 0.2500\n","Epoch 182, Train Loss: 10.3693, Val Loss: 9.3910, F1 Micro: 0.2396, F1 Macro: 0.2185, Accuracy: 0.2396\n","Epoch 183, Train Loss: 7.6224, Val Loss: 9.4664, F1 Micro: 0.2500, F1 Macro: 0.1947, Accuracy: 0.2500\n","Epoch 184, Train Loss: 6.6340, Val Loss: 6.5180, F1 Micro: 0.2708, F1 Macro: 0.2432, Accuracy: 0.2708\n","Epoch 185, Train Loss: 9.4143, Val Loss: 10.1050, F1 Micro: 0.2812, F1 Macro: 0.2293, Accuracy: 0.2812\n","Epoch 186, Train Loss: 9.6429, Val Loss: 8.6380, F1 Micro: 0.1979, F1 Macro: 0.1435, Accuracy: 0.1979\n","Epoch 187, Train Loss: 6.1264, Val Loss: 5.7708, F1 Micro: 0.2083, F1 Macro: 0.1831, Accuracy: 0.2083\n","Epoch 188, Train Loss: 6.3410, Val Loss: 14.0074, F1 Micro: 0.2812, F1 Macro: 0.2621, Accuracy: 0.2812\n","Epoch 189, Train Loss: 5.8927, Val Loss: 6.5577, F1 Micro: 0.2708, F1 Macro: 0.2531, Accuracy: 0.2708\n","Epoch 190, Train Loss: 9.7578, Val Loss: 5.2045, F1 Micro: 0.3542, F1 Macro: 0.3514, Accuracy: 0.3542\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 105.7525, Val Loss: 26.6420, F1 Micro: 0.2292, F1 Macro: 0.0983, Accuracy: 0.2292\n","Epoch 2, Train Loss: 23.2940, Val Loss: 25.5427, F1 Micro: 0.2604, F1 Macro: 0.1231, Accuracy: 0.2604\n","Epoch 3, Train Loss: 21.6376, Val Loss: 19.8859, F1 Micro: 0.1250, F1 Macro: 0.0879, Accuracy: 0.1250\n","Epoch 4, Train Loss: 34.4269, Val Loss: 33.2905, F1 Micro: 0.2500, F1 Macro: 0.1826, Accuracy: 0.2500\n","Epoch 5, Train Loss: 32.2790, Val Loss: 20.9235, F1 Micro: 0.2500, F1 Macro: 0.1759, Accuracy: 0.2500\n","Epoch 6, Train Loss: 20.7326, Val Loss: 18.6694, F1 Micro: 0.1979, F1 Macro: 0.1570, Accuracy: 0.1979\n","Epoch 7, Train Loss: 17.3559, Val Loss: 37.5071, F1 Micro: 0.1354, F1 Macro: 0.0758, Accuracy: 0.1354\n","Epoch 8, Train Loss: 25.9380, Val Loss: 15.9210, F1 Micro: 0.2812, F1 Macro: 0.1853, Accuracy: 0.2812\n","Epoch 9, Train Loss: 14.6430, Val Loss: 8.7299, F1 Micro: 0.2917, F1 Macro: 0.2209, Accuracy: 0.2917\n","Epoch 10, Train Loss: 10.6052, Val Loss: 17.4163, F1 Micro: 0.1875, F1 Macro: 0.1520, Accuracy: 0.1875\n","Epoch 11, Train Loss: 15.2265, Val Loss: 12.9903, F1 Micro: 0.2500, F1 Macro: 0.1672, Accuracy: 0.2500\n","Epoch 12, Train Loss: 22.6576, Val Loss: 17.2320, F1 Micro: 0.3125, F1 Macro: 0.2143, Accuracy: 0.3125\n","Epoch 13, Train Loss: 16.8919, Val Loss: 18.5263, F1 Micro: 0.2188, F1 Macro: 0.1795, Accuracy: 0.2188\n","Epoch 14, Train Loss: 13.5756, Val Loss: 16.8914, F1 Micro: 0.1667, F1 Macro: 0.1444, Accuracy: 0.1667\n","Epoch 15, Train Loss: 13.9075, Val Loss: 19.8888, F1 Micro: 0.1979, F1 Macro: 0.1627, Accuracy: 0.1979\n","Epoch 16, Train Loss: 22.2699, Val Loss: 20.7103, F1 Micro: 0.1354, F1 Macro: 0.0873, Accuracy: 0.1354\n","Epoch 17, Train Loss: 19.3790, Val Loss: 26.9153, F1 Micro: 0.1042, F1 Macro: 0.0317, Accuracy: 0.1042\n","Epoch 18, Train Loss: 25.3722, Val Loss: 29.5137, F1 Micro: 0.1042, F1 Macro: 0.0706, Accuracy: 0.1042\n","Epoch 19, Train Loss: 15.7905, Val Loss: 23.7480, F1 Micro: 0.1354, F1 Macro: 0.0882, Accuracy: 0.1354\n","Epoch 20, Train Loss: 15.3353, Val Loss: 13.0066, F1 Micro: 0.2188, F1 Macro: 0.1233, Accuracy: 0.2188\n","Epoch 21, Train Loss: 12.6108, Val Loss: 29.7160, F1 Micro: 0.1562, F1 Macro: 0.0889, Accuracy: 0.1562\n","Epoch 22, Train Loss: 19.7858, Val Loss: 26.3690, F1 Micro: 0.2396, F1 Macro: 0.1607, Accuracy: 0.2396\n","Epoch 23, Train Loss: 18.8760, Val Loss: 16.7827, F1 Micro: 0.2604, F1 Macro: 0.1971, Accuracy: 0.2604\n","Epoch 24, Train Loss: 14.1508, Val Loss: 20.8182, F1 Micro: 0.2292, F1 Macro: 0.1127, Accuracy: 0.2292\n","Epoch 25, Train Loss: 24.2938, Val Loss: 17.2506, F1 Micro: 0.1458, F1 Macro: 0.1011, Accuracy: 0.1458\n","Epoch 26, Train Loss: 18.5990, Val Loss: 17.8099, F1 Micro: 0.3542, F1 Macro: 0.2051, Accuracy: 0.3542\n","Epoch 27, Train Loss: 14.7315, Val Loss: 14.6441, F1 Micro: 0.2396, F1 Macro: 0.1445, Accuracy: 0.2396\n","Epoch 28, Train Loss: 14.9476, Val Loss: 16.9951, F1 Micro: 0.3229, F1 Macro: 0.2611, Accuracy: 0.3229\n","Epoch 29, Train Loss: 14.0201, Val Loss: 12.3815, F1 Micro: 0.3542, F1 Macro: 0.2265, Accuracy: 0.3542\n","Epoch 30, Train Loss: 17.7358, Val Loss: 28.4738, F1 Micro: 0.1458, F1 Macro: 0.1033, Accuracy: 0.1458\n","Epoch 31, Train Loss: 22.6801, Val Loss: 17.2040, F1 Micro: 0.2708, F1 Macro: 0.1711, Accuracy: 0.2708\n","Epoch 32, Train Loss: 15.8343, Val Loss: 12.2391, F1 Micro: 0.2917, F1 Macro: 0.2364, Accuracy: 0.2917\n","Epoch 33, Train Loss: 15.8762, Val Loss: 22.5149, F1 Micro: 0.2500, F1 Macro: 0.1892, Accuracy: 0.2500\n","Epoch 34, Train Loss: 15.6509, Val Loss: 15.6883, F1 Micro: 0.2604, F1 Macro: 0.2390, Accuracy: 0.2604\n","Epoch 35, Train Loss: 13.6559, Val Loss: 20.1707, F1 Micro: 0.2188, F1 Macro: 0.1202, Accuracy: 0.2188\n","Epoch 36, Train Loss: 15.9968, Val Loss: 9.3489, F1 Micro: 0.1875, F1 Macro: 0.1634, Accuracy: 0.1875\n","Epoch 37, Train Loss: 14.8439, Val Loss: 15.2983, F1 Micro: 0.2604, F1 Macro: 0.1523, Accuracy: 0.2604\n","Epoch 38, Train Loss: 14.9047, Val Loss: 11.5050, F1 Micro: 0.2396, F1 Macro: 0.1793, Accuracy: 0.2396\n","Epoch 39, Train Loss: 12.6605, Val Loss: 5.5144, F1 Micro: 0.3646, F1 Macro: 0.2813, Accuracy: 0.3646\n","Epoch 40, Train Loss: 15.8415, Val Loss: 5.0896, F1 Micro: 0.3229, F1 Macro: 0.3122, Accuracy: 0.3229\n","Epoch 41, Train Loss: 9.0091, Val Loss: 16.6171, F1 Micro: 0.1771, F1 Macro: 0.1251, Accuracy: 0.1771\n","Epoch 42, Train Loss: 12.2795, Val Loss: 16.8838, F1 Micro: 0.2708, F1 Macro: 0.1932, Accuracy: 0.2708\n","Epoch 43, Train Loss: 13.8272, Val Loss: 8.4782, F1 Micro: 0.1771, F1 Macro: 0.1530, Accuracy: 0.1771\n","Epoch 44, Train Loss: 8.1707, Val Loss: 10.3860, F1 Micro: 0.2500, F1 Macro: 0.1772, Accuracy: 0.2500\n","Epoch 45, Train Loss: 14.2721, Val Loss: 10.0447, F1 Micro: 0.3646, F1 Macro: 0.2907, Accuracy: 0.3646\n","Epoch 46, Train Loss: 12.1747, Val Loss: 10.1706, F1 Micro: 0.2604, F1 Macro: 0.2490, Accuracy: 0.2604\n","Epoch 47, Train Loss: 9.6629, Val Loss: 10.3312, F1 Micro: 0.2396, F1 Macro: 0.2607, Accuracy: 0.2396\n","Epoch 48, Train Loss: 20.1568, Val Loss: 17.6154, F1 Micro: 0.2604, F1 Macro: 0.1673, Accuracy: 0.2604\n","Epoch 49, Train Loss: 28.3931, Val Loss: 22.1395, F1 Micro: 0.2708, F1 Macro: 0.2311, Accuracy: 0.2708\n","Epoch 50, Train Loss: 17.0523, Val Loss: 10.2427, F1 Micro: 0.1979, F1 Macro: 0.1422, Accuracy: 0.1979\n","Epoch 51, Train Loss: 10.9369, Val Loss: 10.8951, F1 Micro: 0.3021, F1 Macro: 0.2358, Accuracy: 0.3021\n","Epoch 52, Train Loss: 12.2433, Val Loss: 8.5675, F1 Micro: 0.3438, F1 Macro: 0.2964, Accuracy: 0.3438\n","Epoch 53, Train Loss: 9.2057, Val Loss: 12.5097, F1 Micro: 0.3333, F1 Macro: 0.2414, Accuracy: 0.3333\n","Epoch 54, Train Loss: 19.3974, Val Loss: 17.1396, F1 Micro: 0.2708, F1 Macro: 0.1617, Accuracy: 0.2708\n","Epoch 55, Train Loss: 16.8955, Val Loss: 9.4420, F1 Micro: 0.3125, F1 Macro: 0.2507, Accuracy: 0.3125\n","Epoch 56, Train Loss: 8.0508, Val Loss: 10.6248, F1 Micro: 0.1562, F1 Macro: 0.1410, Accuracy: 0.1562\n","Epoch 57, Train Loss: 14.6061, Val Loss: 15.3908, F1 Micro: 0.1771, F1 Macro: 0.1365, Accuracy: 0.1771\n","Epoch 58, Train Loss: 15.9335, Val Loss: 14.8377, F1 Micro: 0.2604, F1 Macro: 0.1921, Accuracy: 0.2604\n","Epoch 59, Train Loss: 15.9305, Val Loss: 22.2908, F1 Micro: 0.3333, F1 Macro: 0.2691, Accuracy: 0.3333\n","Epoch 60, Train Loss: 14.1685, Val Loss: 16.8604, F1 Micro: 0.2708, F1 Macro: 0.1999, Accuracy: 0.2708\n","Epoch 61, Train Loss: 16.3878, Val Loss: 15.4196, F1 Micro: 0.2604, F1 Macro: 0.1644, Accuracy: 0.2604\n","Epoch 62, Train Loss: 14.4635, Val Loss: 12.5724, F1 Micro: 0.3229, F1 Macro: 0.2395, Accuracy: 0.3229\n","Epoch 63, Train Loss: 15.0730, Val Loss: 18.3848, F1 Micro: 0.2188, F1 Macro: 0.1210, Accuracy: 0.2188\n","Epoch 64, Train Loss: 11.2436, Val Loss: 11.8089, F1 Micro: 0.2812, F1 Macro: 0.1933, Accuracy: 0.2812\n","Epoch 65, Train Loss: 13.2211, Val Loss: 18.2213, F1 Micro: 0.2812, F1 Macro: 0.1629, Accuracy: 0.2812\n","Epoch 66, Train Loss: 18.7245, Val Loss: 16.8288, F1 Micro: 0.2917, F1 Macro: 0.2112, Accuracy: 0.2917\n","Epoch 67, Train Loss: 10.0803, Val Loss: 14.1457, F1 Micro: 0.3021, F1 Macro: 0.2055, Accuracy: 0.3021\n","Epoch 68, Train Loss: 12.7959, Val Loss: 12.1632, F1 Micro: 0.3333, F1 Macro: 0.2715, Accuracy: 0.3333\n","Epoch 69, Train Loss: 12.2300, Val Loss: 17.5463, F1 Micro: 0.2917, F1 Macro: 0.1962, Accuracy: 0.2917\n","Epoch 70, Train Loss: 14.5238, Val Loss: 20.9639, F1 Micro: 0.3125, F1 Macro: 0.2669, Accuracy: 0.3125\n","Epoch 71, Train Loss: 14.3290, Val Loss: 14.0731, F1 Micro: 0.2500, F1 Macro: 0.1506, Accuracy: 0.2500\n","Epoch 72, Train Loss: 15.0479, Val Loss: 15.0524, F1 Micro: 0.1979, F1 Macro: 0.1453, Accuracy: 0.1979\n","Epoch 73, Train Loss: 9.4303, Val Loss: 7.5214, F1 Micro: 0.3438, F1 Macro: 0.2598, Accuracy: 0.3438\n","Epoch 74, Train Loss: 8.9818, Val Loss: 7.1296, F1 Micro: 0.2917, F1 Macro: 0.2103, Accuracy: 0.2917\n","Epoch 75, Train Loss: 12.1311, Val Loss: 10.2495, F1 Micro: 0.3229, F1 Macro: 0.2062, Accuracy: 0.3229\n","Epoch 76, Train Loss: 12.7553, Val Loss: 8.8008, F1 Micro: 0.1771, F1 Macro: 0.1497, Accuracy: 0.1771\n","Epoch 77, Train Loss: 17.7681, Val Loss: 12.3578, F1 Micro: 0.3125, F1 Macro: 0.2631, Accuracy: 0.3125\n","Epoch 78, Train Loss: 21.4136, Val Loss: 11.9709, F1 Micro: 0.2500, F1 Macro: 0.1666, Accuracy: 0.2500\n","Epoch 79, Train Loss: 15.4696, Val Loss: 10.3360, F1 Micro: 0.3021, F1 Macro: 0.2011, Accuracy: 0.3021\n","Epoch 80, Train Loss: 14.7666, Val Loss: 16.3555, F1 Micro: 0.3125, F1 Macro: 0.2561, Accuracy: 0.3125\n","Epoch 81, Train Loss: 12.7660, Val Loss: 10.1896, F1 Micro: 0.2708, F1 Macro: 0.1759, Accuracy: 0.2708\n","Epoch 82, Train Loss: 10.8038, Val Loss: 9.1382, F1 Micro: 0.3021, F1 Macro: 0.1825, Accuracy: 0.3021\n","Epoch 83, Train Loss: 12.0758, Val Loss: 14.4174, F1 Micro: 0.1458, F1 Macro: 0.0892, Accuracy: 0.1458\n","Epoch 84, Train Loss: 12.8735, Val Loss: 15.9183, F1 Micro: 0.2604, F1 Macro: 0.1669, Accuracy: 0.2604\n","Epoch 85, Train Loss: 13.1248, Val Loss: 12.0669, F1 Micro: 0.4167, F1 Macro: 0.3610, Accuracy: 0.4167\n","Epoch 86, Train Loss: 13.5033, Val Loss: 13.1117, F1 Micro: 0.2083, F1 Macro: 0.1707, Accuracy: 0.2083\n","Epoch 87, Train Loss: 12.7466, Val Loss: 16.2318, F1 Micro: 0.3229, F1 Macro: 0.2500, Accuracy: 0.3229\n","Epoch 88, Train Loss: 13.3453, Val Loss: 13.0914, F1 Micro: 0.1458, F1 Macro: 0.0988, Accuracy: 0.1458\n","Epoch 89, Train Loss: 10.7902, Val Loss: 6.5638, F1 Micro: 0.2708, F1 Macro: 0.2322, Accuracy: 0.2708\n","Epoch 90, Train Loss: 8.9206, Val Loss: 5.5301, F1 Micro: 0.3125, F1 Macro: 0.2785, Accuracy: 0.3125\n","Epoch 91, Train Loss: 6.2217, Val Loss: 5.7759, F1 Micro: 0.2083, F1 Macro: 0.1871, Accuracy: 0.2083\n","Epoch 92, Train Loss: 9.8417, Val Loss: 12.6002, F1 Micro: 0.4062, F1 Macro: 0.3103, Accuracy: 0.4062\n","Epoch 93, Train Loss: 12.7814, Val Loss: 9.5923, F1 Micro: 0.3021, F1 Macro: 0.2369, Accuracy: 0.3021\n","Epoch 94, Train Loss: 9.2103, Val Loss: 10.1944, F1 Micro: 0.2396, F1 Macro: 0.2232, Accuracy: 0.2396\n","Epoch 95, Train Loss: 9.8599, Val Loss: 8.5821, F1 Micro: 0.3229, F1 Macro: 0.2646, Accuracy: 0.3229\n","Epoch 96, Train Loss: 9.1812, Val Loss: 8.9915, F1 Micro: 0.2604, F1 Macro: 0.2118, Accuracy: 0.2604\n","Epoch 97, Train Loss: 10.6620, Val Loss: 13.4379, F1 Micro: 0.1771, F1 Macro: 0.1299, Accuracy: 0.1771\n","Epoch 98, Train Loss: 12.5867, Val Loss: 14.0080, F1 Micro: 0.2604, F1 Macro: 0.2015, Accuracy: 0.2604\n","Epoch 99, Train Loss: 10.7172, Val Loss: 10.9467, F1 Micro: 0.2292, F1 Macro: 0.1333, Accuracy: 0.2292\n","Epoch 100, Train Loss: 9.5002, Val Loss: 7.8001, F1 Micro: 0.2083, F1 Macro: 0.1831, Accuracy: 0.2083\n","Epoch 101, Train Loss: 7.5815, Val Loss: 7.0784, F1 Micro: 0.2812, F1 Macro: 0.2243, Accuracy: 0.2812\n","Epoch 102, Train Loss: 9.5891, Val Loss: 14.8916, F1 Micro: 0.3229, F1 Macro: 0.2658, Accuracy: 0.3229\n","Epoch 103, Train Loss: 9.9975, Val Loss: 17.8983, F1 Micro: 0.1979, F1 Macro: 0.1370, Accuracy: 0.1979\n","Epoch 104, Train Loss: 10.5732, Val Loss: 5.8377, F1 Micro: 0.2812, F1 Macro: 0.2456, Accuracy: 0.2812\n","Epoch 105, Train Loss: 7.6304, Val Loss: 6.8614, F1 Micro: 0.3229, F1 Macro: 0.2953, Accuracy: 0.3229\n","Epoch 106, Train Loss: 12.5674, Val Loss: 12.2767, F1 Micro: 0.3021, F1 Macro: 0.2292, Accuracy: 0.3021\n","Epoch 107, Train Loss: 13.4007, Val Loss: 13.5523, F1 Micro: 0.3542, F1 Macro: 0.2966, Accuracy: 0.3542\n","Epoch 108, Train Loss: 9.4151, Val Loss: 17.4227, F1 Micro: 0.2500, F1 Macro: 0.1285, Accuracy: 0.2500\n","Epoch 109, Train Loss: 12.2258, Val Loss: 10.9719, F1 Micro: 0.3021, F1 Macro: 0.1988, Accuracy: 0.3021\n","Epoch 110, Train Loss: 13.8270, Val Loss: 9.5256, F1 Micro: 0.3958, F1 Macro: 0.3163, Accuracy: 0.3958\n","Epoch 111, Train Loss: 7.6813, Val Loss: 5.5156, F1 Micro: 0.3854, F1 Macro: 0.3577, Accuracy: 0.3854\n","Epoch 112, Train Loss: 6.0833, Val Loss: 9.7561, F1 Micro: 0.2500, F1 Macro: 0.2057, Accuracy: 0.2500\n","Epoch 113, Train Loss: 8.5119, Val Loss: 7.3526, F1 Micro: 0.2604, F1 Macro: 0.2787, Accuracy: 0.2604\n","Epoch 114, Train Loss: 12.4305, Val Loss: 14.7123, F1 Micro: 0.2292, F1 Macro: 0.2147, Accuracy: 0.2292\n","Epoch 115, Train Loss: 7.8189, Val Loss: 11.6675, F1 Micro: 0.1562, F1 Macro: 0.1375, Accuracy: 0.1562\n","Epoch 116, Train Loss: 12.2016, Val Loss: 23.2397, F1 Micro: 0.2083, F1 Macro: 0.1776, Accuracy: 0.2083\n","Epoch 117, Train Loss: 18.4869, Val Loss: 11.9118, F1 Micro: 0.3646, F1 Macro: 0.3119, Accuracy: 0.3646\n","Epoch 118, Train Loss: 9.5326, Val Loss: 12.9009, F1 Micro: 0.2500, F1 Macro: 0.1803, Accuracy: 0.2500\n","Epoch 119, Train Loss: 12.0274, Val Loss: 7.0967, F1 Micro: 0.2604, F1 Macro: 0.2429, Accuracy: 0.2604\n","Epoch 120, Train Loss: 9.4269, Val Loss: 11.8347, F1 Micro: 0.2396, F1 Macro: 0.1816, Accuracy: 0.2396\n","Epoch 121, Train Loss: 10.0812, Val Loss: 8.1927, F1 Micro: 0.1667, F1 Macro: 0.1040, Accuracy: 0.1667\n","Epoch 122, Train Loss: 8.1501, Val Loss: 9.0503, F1 Micro: 0.1771, F1 Macro: 0.1300, Accuracy: 0.1771\n","Epoch 123, Train Loss: 10.7300, Val Loss: 8.3246, F1 Micro: 0.2917, F1 Macro: 0.2648, Accuracy: 0.2917\n","Epoch 124, Train Loss: 6.0952, Val Loss: 12.5359, F1 Micro: 0.1354, F1 Macro: 0.0971, Accuracy: 0.1354\n","Epoch 125, Train Loss: 10.4155, Val Loss: 10.4423, F1 Micro: 0.1979, F1 Macro: 0.1010, Accuracy: 0.1979\n","Epoch 126, Train Loss: 10.0086, Val Loss: 15.7954, F1 Micro: 0.3542, F1 Macro: 0.2355, Accuracy: 0.3542\n","Epoch 127, Train Loss: 12.3598, Val Loss: 5.9042, F1 Micro: 0.3125, F1 Macro: 0.3025, Accuracy: 0.3125\n","Epoch 128, Train Loss: 10.3519, Val Loss: 14.3171, F1 Micro: 0.1042, F1 Macro: 0.0511, Accuracy: 0.1042\n","Epoch 129, Train Loss: 9.3998, Val Loss: 18.6149, F1 Micro: 0.2604, F1 Macro: 0.2447, Accuracy: 0.2604\n","Epoch 130, Train Loss: 9.2462, Val Loss: 12.0915, F1 Micro: 0.3750, F1 Macro: 0.3225, Accuracy: 0.3750\n","Epoch 131, Train Loss: 11.1321, Val Loss: 9.0212, F1 Micro: 0.3021, F1 Macro: 0.2689, Accuracy: 0.3021\n","Epoch 132, Train Loss: 5.0061, Val Loss: 6.6932, F1 Micro: 0.3229, F1 Macro: 0.3182, Accuracy: 0.3229\n","Epoch 133, Train Loss: 5.8206, Val Loss: 7.2732, F1 Micro: 0.2708, F1 Macro: 0.2353, Accuracy: 0.2708\n","Epoch 134, Train Loss: 8.2765, Val Loss: 8.0512, F1 Micro: 0.3125, F1 Macro: 0.2203, Accuracy: 0.3125\n","Epoch 135, Train Loss: 8.3364, Val Loss: 8.4567, F1 Micro: 0.3438, F1 Macro: 0.3210, Accuracy: 0.3438\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 57.8121, Val Loss: 17.6299, F1 Micro: 0.1562, F1 Macro: 0.1029, Accuracy: 0.1562\n","Epoch 2, Train Loss: 19.4785, Val Loss: 28.1579, F1 Micro: 0.2188, F1 Macro: 0.0603, Accuracy: 0.2188\n","Epoch 3, Train Loss: 28.7972, Val Loss: 14.1534, F1 Micro: 0.1875, F1 Macro: 0.1056, Accuracy: 0.1875\n","Epoch 4, Train Loss: 21.3404, Val Loss: 18.2814, F1 Micro: 0.1250, F1 Macro: 0.0955, Accuracy: 0.1250\n","Epoch 5, Train Loss: 16.7638, Val Loss: 23.2356, F1 Micro: 0.1146, F1 Macro: 0.0893, Accuracy: 0.1146\n","Epoch 6, Train Loss: 23.5629, Val Loss: 13.4242, F1 Micro: 0.2500, F1 Macro: 0.1211, Accuracy: 0.2500\n","Epoch 7, Train Loss: 18.5016, Val Loss: 17.8179, F1 Micro: 0.1667, F1 Macro: 0.1074, Accuracy: 0.1667\n","Epoch 8, Train Loss: 19.4744, Val Loss: 29.1361, F1 Micro: 0.1458, F1 Macro: 0.0912, Accuracy: 0.1458\n","Epoch 9, Train Loss: 17.0015, Val Loss: 8.1374, F1 Micro: 0.2396, F1 Macro: 0.1560, Accuracy: 0.2396\n","Epoch 10, Train Loss: 16.6694, Val Loss: 15.0405, F1 Micro: 0.1667, F1 Macro: 0.1047, Accuracy: 0.1667\n","Epoch 11, Train Loss: 19.7078, Val Loss: 22.3905, F1 Micro: 0.2812, F1 Macro: 0.1663, Accuracy: 0.2812\n","Epoch 12, Train Loss: 17.5807, Val Loss: 10.1479, F1 Micro: 0.1875, F1 Macro: 0.1614, Accuracy: 0.1875\n","Epoch 13, Train Loss: 16.4971, Val Loss: 28.2616, F1 Micro: 0.3333, F1 Macro: 0.2349, Accuracy: 0.3333\n","Epoch 14, Train Loss: 18.1182, Val Loss: 19.0902, F1 Micro: 0.2188, F1 Macro: 0.0598, Accuracy: 0.2188\n","Epoch 15, Train Loss: 18.2610, Val Loss: 6.4893, F1 Micro: 0.1979, F1 Macro: 0.1585, Accuracy: 0.1979\n","Epoch 16, Train Loss: 14.8304, Val Loss: 28.1417, F1 Micro: 0.2604, F1 Macro: 0.1827, Accuracy: 0.2604\n","Epoch 17, Train Loss: 25.1088, Val Loss: 26.0502, F1 Micro: 0.1979, F1 Macro: 0.1195, Accuracy: 0.1979\n","Epoch 18, Train Loss: 12.6443, Val Loss: 10.2133, F1 Micro: 0.1458, F1 Macro: 0.1023, Accuracy: 0.1458\n","Epoch 19, Train Loss: 15.5957, Val Loss: 15.2488, F1 Micro: 0.2500, F1 Macro: 0.1640, Accuracy: 0.2500\n","Epoch 20, Train Loss: 22.2174, Val Loss: 27.5920, F1 Micro: 0.2188, F1 Macro: 0.0609, Accuracy: 0.2188\n","Epoch 21, Train Loss: 24.9403, Val Loss: 28.9270, F1 Micro: 0.2292, F1 Macro: 0.0914, Accuracy: 0.2292\n","Epoch 22, Train Loss: 23.3287, Val Loss: 14.0855, F1 Micro: 0.2812, F1 Macro: 0.1464, Accuracy: 0.2812\n","Epoch 23, Train Loss: 13.8987, Val Loss: 29.2389, F1 Micro: 0.1875, F1 Macro: 0.1231, Accuracy: 0.1875\n","Epoch 24, Train Loss: 13.2489, Val Loss: 9.9536, F1 Micro: 0.2396, F1 Macro: 0.1774, Accuracy: 0.2396\n","Epoch 25, Train Loss: 16.8768, Val Loss: 27.9803, F1 Micro: 0.1771, F1 Macro: 0.0840, Accuracy: 0.1771\n","Epoch 26, Train Loss: 25.9746, Val Loss: 36.2203, F1 Micro: 0.1979, F1 Macro: 0.1169, Accuracy: 0.1979\n","Epoch 27, Train Loss: 15.0827, Val Loss: 14.4328, F1 Micro: 0.3333, F1 Macro: 0.2056, Accuracy: 0.3333\n","Epoch 28, Train Loss: 22.1667, Val Loss: 24.8909, F1 Micro: 0.1458, F1 Macro: 0.0801, Accuracy: 0.1458\n","Epoch 29, Train Loss: 20.5771, Val Loss: 22.0829, F1 Micro: 0.1667, F1 Macro: 0.0743, Accuracy: 0.1667\n","Epoch 30, Train Loss: 13.8007, Val Loss: 23.1918, F1 Micro: 0.3229, F1 Macro: 0.1949, Accuracy: 0.3229\n","Epoch 31, Train Loss: 18.9561, Val Loss: 23.7452, F1 Micro: 0.2292, F1 Macro: 0.1824, Accuracy: 0.2292\n","Epoch 32, Train Loss: 20.2688, Val Loss: 28.8789, F1 Micro: 0.2188, F1 Macro: 0.0827, Accuracy: 0.2188\n","Epoch 33, Train Loss: 18.9216, Val Loss: 25.8157, F1 Micro: 0.1875, F1 Macro: 0.0943, Accuracy: 0.1875\n","Epoch 34, Train Loss: 21.8676, Val Loss: 16.8439, F1 Micro: 0.3333, F1 Macro: 0.2078, Accuracy: 0.3333\n","Epoch 35, Train Loss: 11.3015, Val Loss: 10.3039, F1 Micro: 0.2396, F1 Macro: 0.1746, Accuracy: 0.2396\n","Epoch 36, Train Loss: 12.4538, Val Loss: 7.8467, F1 Micro: 0.1875, F1 Macro: 0.1587, Accuracy: 0.1875\n","Epoch 37, Train Loss: 12.7929, Val Loss: 12.3312, F1 Micro: 0.2396, F1 Macro: 0.1870, Accuracy: 0.2396\n","Epoch 38, Train Loss: 18.1313, Val Loss: 19.6312, F1 Micro: 0.1979, F1 Macro: 0.1884, Accuracy: 0.1979\n","Epoch 39, Train Loss: 16.8218, Val Loss: 9.9268, F1 Micro: 0.2917, F1 Macro: 0.1508, Accuracy: 0.2917\n","Epoch 40, Train Loss: 12.9879, Val Loss: 20.4935, F1 Micro: 0.1875, F1 Macro: 0.0943, Accuracy: 0.1875\n","Epoch 41, Train Loss: 17.7592, Val Loss: 26.2431, F1 Micro: 0.1979, F1 Macro: 0.0985, Accuracy: 0.1979\n","Epoch 42, Train Loss: 18.6382, Val Loss: 18.9986, F1 Micro: 0.1771, F1 Macro: 0.1145, Accuracy: 0.1771\n","Epoch 43, Train Loss: 16.8318, Val Loss: 19.8347, F1 Micro: 0.1771, F1 Macro: 0.0829, Accuracy: 0.1771\n","Epoch 44, Train Loss: 10.6103, Val Loss: 17.8686, F1 Micro: 0.1458, F1 Macro: 0.1354, Accuracy: 0.1458\n","Epoch 45, Train Loss: 9.8094, Val Loss: 17.8668, F1 Micro: 0.2188, F1 Macro: 0.1487, Accuracy: 0.2188\n","Epoch 46, Train Loss: 13.8909, Val Loss: 14.5965, F1 Micro: 0.2500, F1 Macro: 0.1427, Accuracy: 0.2500\n","Epoch 47, Train Loss: 15.8191, Val Loss: 12.2749, F1 Micro: 0.3125, F1 Macro: 0.2269, Accuracy: 0.3125\n","Epoch 48, Train Loss: 14.9960, Val Loss: 9.1283, F1 Micro: 0.2812, F1 Macro: 0.2395, Accuracy: 0.2812\n","Epoch 49, Train Loss: 9.4829, Val Loss: 12.1695, F1 Micro: 0.2812, F1 Macro: 0.2149, Accuracy: 0.2812\n","Epoch 50, Train Loss: 19.5095, Val Loss: 30.6422, F1 Micro: 0.3229, F1 Macro: 0.2022, Accuracy: 0.3229\n","Epoch 51, Train Loss: 21.3596, Val Loss: 10.6785, F1 Micro: 0.2500, F1 Macro: 0.2178, Accuracy: 0.2500\n","Epoch 52, Train Loss: 9.4613, Val Loss: 10.7093, F1 Micro: 0.3750, F1 Macro: 0.2160, Accuracy: 0.3750\n","Epoch 53, Train Loss: 12.7799, Val Loss: 15.3549, F1 Micro: 0.4062, F1 Macro: 0.2984, Accuracy: 0.4062\n","Epoch 54, Train Loss: 15.5545, Val Loss: 9.1186, F1 Micro: 0.3021, F1 Macro: 0.1996, Accuracy: 0.3021\n","Epoch 55, Train Loss: 14.2051, Val Loss: 6.8235, F1 Micro: 0.3229, F1 Macro: 0.2260, Accuracy: 0.3229\n","Epoch 56, Train Loss: 11.6358, Val Loss: 19.1742, F1 Micro: 0.2188, F1 Macro: 0.1630, Accuracy: 0.2188\n","Epoch 57, Train Loss: 12.1256, Val Loss: 13.9060, F1 Micro: 0.3438, F1 Macro: 0.2331, Accuracy: 0.3438\n","Epoch 58, Train Loss: 10.1864, Val Loss: 7.3463, F1 Micro: 0.3750, F1 Macro: 0.2752, Accuracy: 0.3750\n","Epoch 59, Train Loss: 7.8177, Val Loss: 9.8651, F1 Micro: 0.3021, F1 Macro: 0.1718, Accuracy: 0.3021\n","Epoch 60, Train Loss: 14.0908, Val Loss: 28.9130, F1 Micro: 0.2604, F1 Macro: 0.1869, Accuracy: 0.2604\n","Epoch 61, Train Loss: 13.8461, Val Loss: 15.8440, F1 Micro: 0.1875, F1 Macro: 0.1123, Accuracy: 0.1875\n","Epoch 62, Train Loss: 12.0297, Val Loss: 15.8422, F1 Micro: 0.4167, F1 Macro: 0.3083, Accuracy: 0.4167\n","Epoch 63, Train Loss: 9.3218, Val Loss: 8.6540, F1 Micro: 0.3542, F1 Macro: 0.2966, Accuracy: 0.3542\n","Epoch 64, Train Loss: 9.1391, Val Loss: 14.6296, F1 Micro: 0.2708, F1 Macro: 0.1931, Accuracy: 0.2708\n","Epoch 65, Train Loss: 9.5761, Val Loss: 6.7466, F1 Micro: 0.1875, F1 Macro: 0.1549, Accuracy: 0.1875\n","Epoch 66, Train Loss: 13.8062, Val Loss: 9.3207, F1 Micro: 0.2188, F1 Macro: 0.1346, Accuracy: 0.2188\n","Epoch 67, Train Loss: 13.3682, Val Loss: 20.8407, F1 Micro: 0.2500, F1 Macro: 0.2007, Accuracy: 0.2500\n","Epoch 68, Train Loss: 11.2822, Val Loss: 10.7420, F1 Micro: 0.2917, F1 Macro: 0.2390, Accuracy: 0.2917\n","Epoch 69, Train Loss: 13.2382, Val Loss: 18.1802, F1 Micro: 0.2917, F1 Macro: 0.2575, Accuracy: 0.2917\n","Epoch 70, Train Loss: 14.4706, Val Loss: 15.9804, F1 Micro: 0.1979, F1 Macro: 0.1331, Accuracy: 0.1979\n","Epoch 71, Train Loss: 12.3232, Val Loss: 8.5931, F1 Micro: 0.2604, F1 Macro: 0.2122, Accuracy: 0.2604\n","Epoch 72, Train Loss: 9.0518, Val Loss: 9.1995, F1 Micro: 0.2604, F1 Macro: 0.1791, Accuracy: 0.2604\n","Epoch 73, Train Loss: 10.6612, Val Loss: 17.7293, F1 Micro: 0.1979, F1 Macro: 0.1792, Accuracy: 0.1979\n","Epoch 74, Train Loss: 12.7419, Val Loss: 8.8842, F1 Micro: 0.1875, F1 Macro: 0.1781, Accuracy: 0.1875\n","Epoch 75, Train Loss: 7.1880, Val Loss: 10.8283, F1 Micro: 0.2812, F1 Macro: 0.1852, Accuracy: 0.2812\n","Epoch 76, Train Loss: 9.9468, Val Loss: 6.7640, F1 Micro: 0.3542, F1 Macro: 0.2683, Accuracy: 0.3542\n","Epoch 77, Train Loss: 7.4045, Val Loss: 7.4865, F1 Micro: 0.2604, F1 Macro: 0.1721, Accuracy: 0.2604\n","Epoch 78, Train Loss: 13.0587, Val Loss: 15.1140, F1 Micro: 0.3125, F1 Macro: 0.2125, Accuracy: 0.3125\n","Epoch 79, Train Loss: 13.7701, Val Loss: 13.9581, F1 Micro: 0.2917, F1 Macro: 0.2201, Accuracy: 0.2917\n","Epoch 80, Train Loss: 11.2356, Val Loss: 10.8271, F1 Micro: 0.3750, F1 Macro: 0.2615, Accuracy: 0.3750\n","Epoch 81, Train Loss: 9.8844, Val Loss: 16.4432, F1 Micro: 0.1979, F1 Macro: 0.0970, Accuracy: 0.1979\n","Epoch 82, Train Loss: 15.1162, Val Loss: 12.1454, F1 Micro: 0.2708, F1 Macro: 0.1654, Accuracy: 0.2708\n","Epoch 83, Train Loss: 10.5688, Val Loss: 18.3151, F1 Micro: 0.2083, F1 Macro: 0.1254, Accuracy: 0.2083\n","Epoch 84, Train Loss: 11.0146, Val Loss: 14.0386, F1 Micro: 0.2188, F1 Macro: 0.2198, Accuracy: 0.2188\n","Epoch 85, Train Loss: 11.0285, Val Loss: 15.9646, F1 Micro: 0.2292, F1 Macro: 0.2078, Accuracy: 0.2292\n","Epoch 86, Train Loss: 11.3443, Val Loss: 10.1802, F1 Micro: 0.4062, F1 Macro: 0.3491, Accuracy: 0.4062\n","Epoch 87, Train Loss: 10.8596, Val Loss: 14.8560, F1 Micro: 0.2396, F1 Macro: 0.2230, Accuracy: 0.2396\n","Epoch 88, Train Loss: 10.7739, Val Loss: 12.3722, F1 Micro: 0.4375, F1 Macro: 0.3481, Accuracy: 0.4375\n","Epoch 89, Train Loss: 13.9888, Val Loss: 11.3000, F1 Micro: 0.2292, F1 Macro: 0.2057, Accuracy: 0.2292\n","Epoch 90, Train Loss: 9.5577, Val Loss: 12.6135, F1 Micro: 0.2083, F1 Macro: 0.2084, Accuracy: 0.2083\n","Epoch 91, Train Loss: 7.5716, Val Loss: 10.3992, F1 Micro: 0.1875, F1 Macro: 0.1642, Accuracy: 0.1875\n","Epoch 92, Train Loss: 9.6379, Val Loss: 18.9833, F1 Micro: 0.1458, F1 Macro: 0.1120, Accuracy: 0.1458\n","Epoch 93, Train Loss: 9.4923, Val Loss: 11.6209, F1 Micro: 0.3750, F1 Macro: 0.2637, Accuracy: 0.3750\n","Epoch 94, Train Loss: 12.9174, Val Loss: 19.2379, F1 Micro: 0.2292, F1 Macro: 0.2036, Accuracy: 0.2292\n","Epoch 95, Train Loss: 14.0115, Val Loss: 23.1906, F1 Micro: 0.2396, F1 Macro: 0.1932, Accuracy: 0.2396\n","Epoch 96, Train Loss: 12.5952, Val Loss: 21.5449, F1 Micro: 0.2396, F1 Macro: 0.2102, Accuracy: 0.2396\n","Epoch 97, Train Loss: 11.6322, Val Loss: 6.5461, F1 Micro: 0.3542, F1 Macro: 0.2504, Accuracy: 0.3542\n","Epoch 98, Train Loss: 7.4547, Val Loss: 8.3128, F1 Micro: 0.2396, F1 Macro: 0.1433, Accuracy: 0.2396\n","Epoch 99, Train Loss: 10.7794, Val Loss: 5.0797, F1 Micro: 0.2812, F1 Macro: 0.2613, Accuracy: 0.2812\n","Epoch 100, Train Loss: 10.0591, Val Loss: 9.2725, F1 Micro: 0.2812, F1 Macro: 0.1892, Accuracy: 0.2812\n","Epoch 101, Train Loss: 7.9393, Val Loss: 10.7158, F1 Micro: 0.3229, F1 Macro: 0.2229, Accuracy: 0.3229\n","Epoch 102, Train Loss: 8.0967, Val Loss: 14.4696, F1 Micro: 0.3125, F1 Macro: 0.2109, Accuracy: 0.3125\n","Epoch 103, Train Loss: 12.8242, Val Loss: 17.4053, F1 Micro: 0.2917, F1 Macro: 0.1874, Accuracy: 0.2917\n","Epoch 104, Train Loss: 9.2147, Val Loss: 13.3112, F1 Micro: 0.1875, F1 Macro: 0.1542, Accuracy: 0.1875\n","Epoch 105, Train Loss: 11.3527, Val Loss: 9.8932, F1 Micro: 0.2500, F1 Macro: 0.2010, Accuracy: 0.2500\n","Epoch 106, Train Loss: 7.3257, Val Loss: 12.6540, F1 Micro: 0.3021, F1 Macro: 0.2222, Accuracy: 0.3021\n","Epoch 107, Train Loss: 6.9409, Val Loss: 10.3587, F1 Micro: 0.1771, F1 Macro: 0.1685, Accuracy: 0.1771\n","Epoch 108, Train Loss: 7.3459, Val Loss: 9.9912, F1 Micro: 0.2604, F1 Macro: 0.1629, Accuracy: 0.2604\n","Epoch 109, Train Loss: 7.9324, Val Loss: 8.0450, F1 Micro: 0.3750, F1 Macro: 0.2948, Accuracy: 0.3750\n","Epoch 110, Train Loss: 7.4728, Val Loss: 7.6014, F1 Micro: 0.2708, F1 Macro: 0.2046, Accuracy: 0.2708\n","Epoch 111, Train Loss: 7.2780, Val Loss: 6.8667, F1 Micro: 0.3750, F1 Macro: 0.2652, Accuracy: 0.3750\n","Epoch 112, Train Loss: 7.8037, Val Loss: 12.1517, F1 Micro: 0.1875, F1 Macro: 0.1637, Accuracy: 0.1875\n","Epoch 113, Train Loss: 10.4189, Val Loss: 7.7590, F1 Micro: 0.3021, F1 Macro: 0.1650, Accuracy: 0.3021\n","Epoch 114, Train Loss: 8.5085, Val Loss: 11.5078, F1 Micro: 0.2083, F1 Macro: 0.1384, Accuracy: 0.2083\n","Epoch 115, Train Loss: 13.4797, Val Loss: 13.2003, F1 Micro: 0.3125, F1 Macro: 0.2246, Accuracy: 0.3125\n","Epoch 116, Train Loss: 10.7153, Val Loss: 10.5502, F1 Micro: 0.3229, F1 Macro: 0.2287, Accuracy: 0.3229\n","Epoch 117, Train Loss: 12.9755, Val Loss: 13.3719, F1 Micro: 0.2812, F1 Macro: 0.2035, Accuracy: 0.2812\n","Epoch 118, Train Loss: 6.1639, Val Loss: 8.7226, F1 Micro: 0.3021, F1 Macro: 0.1872, Accuracy: 0.3021\n","Epoch 119, Train Loss: 9.6627, Val Loss: 10.9537, F1 Micro: 0.2083, F1 Macro: 0.1162, Accuracy: 0.2083\n","Epoch 120, Train Loss: 12.2218, Val Loss: 14.0333, F1 Micro: 0.2812, F1 Macro: 0.1857, Accuracy: 0.2812\n","Epoch 121, Train Loss: 11.4262, Val Loss: 6.8759, F1 Micro: 0.3333, F1 Macro: 0.2684, Accuracy: 0.3333\n","Epoch 122, Train Loss: 6.0767, Val Loss: 7.2617, F1 Micro: 0.3021, F1 Macro: 0.2051, Accuracy: 0.3021\n","Epoch 123, Train Loss: 7.4267, Val Loss: 8.9830, F1 Micro: 0.3229, F1 Macro: 0.2560, Accuracy: 0.3229\n","Epoch 124, Train Loss: 6.7870, Val Loss: 8.6586, F1 Micro: 0.3333, F1 Macro: 0.2280, Accuracy: 0.3333\n","Epoch 125, Train Loss: 9.1567, Val Loss: 13.0609, F1 Micro: 0.2188, F1 Macro: 0.1400, Accuracy: 0.2188\n","Epoch 126, Train Loss: 11.7214, Val Loss: 8.5987, F1 Micro: 0.2917, F1 Macro: 0.2184, Accuracy: 0.2917\n","Epoch 127, Train Loss: 9.0160, Val Loss: 12.9783, F1 Micro: 0.2188, F1 Macro: 0.1581, Accuracy: 0.2188\n","Epoch 128, Train Loss: 8.7446, Val Loss: 9.4083, F1 Micro: 0.1979, F1 Macro: 0.1210, Accuracy: 0.1979\n","Epoch 129, Train Loss: 8.0757, Val Loss: 11.8244, F1 Micro: 0.2500, F1 Macro: 0.2007, Accuracy: 0.2500\n","Epoch 130, Train Loss: 8.9652, Val Loss: 8.8353, F1 Micro: 0.3438, F1 Macro: 0.2547, Accuracy: 0.3438\n","Epoch 131, Train Loss: 9.3990, Val Loss: 22.6140, F1 Micro: 0.1875, F1 Macro: 0.1539, Accuracy: 0.1875\n","Epoch 132, Train Loss: 11.7181, Val Loss: 15.4699, F1 Micro: 0.2292, F1 Macro: 0.1102, Accuracy: 0.2292\n","Epoch 133, Train Loss: 10.3988, Val Loss: 7.9005, F1 Micro: 0.3750, F1 Macro: 0.2822, Accuracy: 0.3750\n","Epoch 134, Train Loss: 8.3516, Val Loss: 7.6483, F1 Micro: 0.3125, F1 Macro: 0.2461, Accuracy: 0.3125\n","Epoch 135, Train Loss: 6.6009, Val Loss: 11.2974, F1 Micro: 0.3021, F1 Macro: 0.1720, Accuracy: 0.3021\n","Epoch 136, Train Loss: 7.3381, Val Loss: 13.5971, F1 Micro: 0.1250, F1 Macro: 0.1047, Accuracy: 0.1250\n","Epoch 137, Train Loss: 12.1783, Val Loss: 7.7957, F1 Micro: 0.3333, F1 Macro: 0.2505, Accuracy: 0.3333\n","Epoch 138, Train Loss: 6.1617, Val Loss: 8.0015, F1 Micro: 0.2500, F1 Macro: 0.1683, Accuracy: 0.2500\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 83.1381, Val Loss: 59.5126, F1 Micro: 0.1562, F1 Macro: 0.0602, Accuracy: 0.1562\n","Epoch 2, Train Loss: 27.8032, Val Loss: 20.2324, F1 Micro: 0.1771, F1 Macro: 0.0662, Accuracy: 0.1771\n","Epoch 3, Train Loss: 22.0574, Val Loss: 41.7534, F1 Micro: 0.1562, F1 Macro: 0.0708, Accuracy: 0.1562\n","Epoch 4, Train Loss: 24.8405, Val Loss: 14.9398, F1 Micro: 0.1771, F1 Macro: 0.1119, Accuracy: 0.1771\n","Epoch 5, Train Loss: 16.9738, Val Loss: 29.4384, F1 Micro: 0.2083, F1 Macro: 0.1359, Accuracy: 0.2083\n","Epoch 6, Train Loss: 18.3296, Val Loss: 13.9028, F1 Micro: 0.1354, F1 Macro: 0.0666, Accuracy: 0.1354\n","Epoch 7, Train Loss: 21.0636, Val Loss: 38.9288, F1 Micro: 0.1875, F1 Macro: 0.0723, Accuracy: 0.1875\n","Epoch 8, Train Loss: 25.7736, Val Loss: 20.0626, F1 Micro: 0.2396, F1 Macro: 0.1723, Accuracy: 0.2396\n","Epoch 9, Train Loss: 23.8240, Val Loss: 25.6764, F1 Micro: 0.1771, F1 Macro: 0.0778, Accuracy: 0.1771\n","Epoch 10, Train Loss: 17.4403, Val Loss: 14.2350, F1 Micro: 0.1667, F1 Macro: 0.0689, Accuracy: 0.1667\n","Epoch 11, Train Loss: 13.0649, Val Loss: 13.9294, F1 Micro: 0.2396, F1 Macro: 0.1372, Accuracy: 0.2396\n","Epoch 12, Train Loss: 16.3416, Val Loss: 38.7943, F1 Micro: 0.1771, F1 Macro: 0.0689, Accuracy: 0.1771\n","Epoch 13, Train Loss: 19.0993, Val Loss: 25.1207, F1 Micro: 0.2708, F1 Macro: 0.1783, Accuracy: 0.2708\n","Epoch 14, Train Loss: 17.6252, Val Loss: 35.0777, F1 Micro: 0.1875, F1 Macro: 0.0870, Accuracy: 0.1875\n","Epoch 15, Train Loss: 20.8278, Val Loss: 30.8192, F1 Micro: 0.1979, F1 Macro: 0.0739, Accuracy: 0.1979\n","Epoch 16, Train Loss: 19.3221, Val Loss: 22.3045, F1 Micro: 0.1458, F1 Macro: 0.0583, Accuracy: 0.1458\n","Epoch 17, Train Loss: 15.2810, Val Loss: 31.2639, F1 Micro: 0.2188, F1 Macro: 0.1701, Accuracy: 0.2188\n","Epoch 18, Train Loss: 14.5946, Val Loss: 19.5619, F1 Micro: 0.1667, F1 Macro: 0.0485, Accuracy: 0.1667\n","Epoch 19, Train Loss: 16.2423, Val Loss: 16.3468, F1 Micro: 0.2083, F1 Macro: 0.1064, Accuracy: 0.2083\n","Epoch 20, Train Loss: 11.7583, Val Loss: 14.4800, F1 Micro: 0.1667, F1 Macro: 0.0703, Accuracy: 0.1667\n","Epoch 21, Train Loss: 11.0099, Val Loss: 15.1566, F1 Micro: 0.2083, F1 Macro: 0.1276, Accuracy: 0.2083\n","Epoch 22, Train Loss: 15.3813, Val Loss: 21.0398, F1 Micro: 0.2396, F1 Macro: 0.1469, Accuracy: 0.2396\n","Epoch 23, Train Loss: 20.5308, Val Loss: 25.4422, F1 Micro: 0.1771, F1 Macro: 0.0808, Accuracy: 0.1771\n","Epoch 24, Train Loss: 16.2867, Val Loss: 32.7722, F1 Micro: 0.1667, F1 Macro: 0.0494, Accuracy: 0.1667\n","Epoch 25, Train Loss: 21.2777, Val Loss: 27.8072, F1 Micro: 0.2396, F1 Macro: 0.1394, Accuracy: 0.2396\n","Epoch 26, Train Loss: 23.5160, Val Loss: 16.4776, F1 Micro: 0.2083, F1 Macro: 0.1451, Accuracy: 0.2083\n","Epoch 27, Train Loss: 17.2726, Val Loss: 26.4011, F1 Micro: 0.1979, F1 Macro: 0.0744, Accuracy: 0.1979\n","Epoch 28, Train Loss: 19.5998, Val Loss: 23.9538, F1 Micro: 0.2292, F1 Macro: 0.1156, Accuracy: 0.2292\n","Epoch 29, Train Loss: 15.7534, Val Loss: 9.3933, F1 Micro: 0.1875, F1 Macro: 0.0911, Accuracy: 0.1875\n","Epoch 30, Train Loss: 14.5497, Val Loss: 22.3799, F1 Micro: 0.1875, F1 Macro: 0.1060, Accuracy: 0.1875\n","Epoch 31, Train Loss: 12.7615, Val Loss: 13.8245, F1 Micro: 0.1979, F1 Macro: 0.1237, Accuracy: 0.1979\n","Epoch 32, Train Loss: 8.7456, Val Loss: 13.1007, F1 Micro: 0.2396, F1 Macro: 0.1405, Accuracy: 0.2396\n","Epoch 33, Train Loss: 10.7420, Val Loss: 11.1881, F1 Micro: 0.2292, F1 Macro: 0.1470, Accuracy: 0.2292\n","Epoch 34, Train Loss: 8.7452, Val Loss: 16.1753, F1 Micro: 0.2083, F1 Macro: 0.1006, Accuracy: 0.2083\n","Epoch 35, Train Loss: 12.7204, Val Loss: 16.3088, F1 Micro: 0.2396, F1 Macro: 0.1368, Accuracy: 0.2396\n","Epoch 36, Train Loss: 12.9270, Val Loss: 18.6806, F1 Micro: 0.1979, F1 Macro: 0.1007, Accuracy: 0.1979\n","Epoch 37, Train Loss: 10.3138, Val Loss: 12.4215, F1 Micro: 0.2188, F1 Macro: 0.1240, Accuracy: 0.2188\n","Epoch 38, Train Loss: 10.2200, Val Loss: 12.7215, F1 Micro: 0.2604, F1 Macro: 0.1502, Accuracy: 0.2604\n","Epoch 39, Train Loss: 15.6549, Val Loss: 37.5900, F1 Micro: 0.2292, F1 Macro: 0.1213, Accuracy: 0.2292\n","Epoch 40, Train Loss: 21.1704, Val Loss: 32.7146, F1 Micro: 0.1562, F1 Macro: 0.0628, Accuracy: 0.1562\n","Epoch 41, Train Loss: 19.1235, Val Loss: 12.2485, F1 Micro: 0.2188, F1 Macro: 0.1545, Accuracy: 0.2188\n","Epoch 42, Train Loss: 18.6988, Val Loss: 26.5829, F1 Micro: 0.1771, F1 Macro: 0.0801, Accuracy: 0.1771\n","Epoch 43, Train Loss: 13.9167, Val Loss: 15.1094, F1 Micro: 0.3229, F1 Macro: 0.2238, Accuracy: 0.3229\n","Epoch 44, Train Loss: 14.0802, Val Loss: 20.5671, F1 Micro: 0.2708, F1 Macro: 0.1540, Accuracy: 0.2708\n","Epoch 45, Train Loss: 9.0689, Val Loss: 14.6967, F1 Micro: 0.2292, F1 Macro: 0.1197, Accuracy: 0.2292\n","Epoch 46, Train Loss: 14.3095, Val Loss: 9.4969, F1 Micro: 0.2188, F1 Macro: 0.1410, Accuracy: 0.2188\n","Epoch 47, Train Loss: 13.7019, Val Loss: 17.7085, F1 Micro: 0.2708, F1 Macro: 0.1945, Accuracy: 0.2708\n","Epoch 48, Train Loss: 14.3471, Val Loss: 13.9266, F1 Micro: 0.2083, F1 Macro: 0.1230, Accuracy: 0.2083\n","Epoch 49, Train Loss: 10.4871, Val Loss: 10.6404, F1 Micro: 0.2292, F1 Macro: 0.1541, Accuracy: 0.2292\n","Epoch 50, Train Loss: 17.2724, Val Loss: 28.7591, F1 Micro: 0.2083, F1 Macro: 0.1291, Accuracy: 0.2083\n","Epoch 51, Train Loss: 20.0234, Val Loss: 15.0883, F1 Micro: 0.2396, F1 Macro: 0.1573, Accuracy: 0.2396\n","Epoch 52, Train Loss: 13.9729, Val Loss: 18.0079, F1 Micro: 0.1979, F1 Macro: 0.1280, Accuracy: 0.1979\n","Epoch 53, Train Loss: 13.6219, Val Loss: 21.3330, F1 Micro: 0.2292, F1 Macro: 0.1255, Accuracy: 0.2292\n","Epoch 54, Train Loss: 9.9863, Val Loss: 10.6850, F1 Micro: 0.2188, F1 Macro: 0.1604, Accuracy: 0.2188\n","Epoch 55, Train Loss: 13.4881, Val Loss: 15.0155, F1 Micro: 0.2188, F1 Macro: 0.1273, Accuracy: 0.2188\n","Epoch 56, Train Loss: 8.6415, Val Loss: 16.2922, F1 Micro: 0.2604, F1 Macro: 0.2062, Accuracy: 0.2604\n","Epoch 57, Train Loss: 11.2691, Val Loss: 17.9719, F1 Micro: 0.2708, F1 Macro: 0.1804, Accuracy: 0.2708\n","Epoch 58, Train Loss: 10.5293, Val Loss: 11.6580, F1 Micro: 0.1875, F1 Macro: 0.1295, Accuracy: 0.1875\n","Epoch 59, Train Loss: 11.0187, Val Loss: 13.3974, F1 Micro: 0.2708, F1 Macro: 0.1828, Accuracy: 0.2708\n","Epoch 60, Train Loss: 15.2876, Val Loss: 11.1597, F1 Micro: 0.2396, F1 Macro: 0.1710, Accuracy: 0.2396\n","Epoch 61, Train Loss: 9.7874, Val Loss: 8.2732, F1 Micro: 0.2188, F1 Macro: 0.1683, Accuracy: 0.2188\n","Epoch 62, Train Loss: 14.0019, Val Loss: 23.7692, F1 Micro: 0.1875, F1 Macro: 0.1303, Accuracy: 0.1875\n","Epoch 63, Train Loss: 18.5020, Val Loss: 24.4553, F1 Micro: 0.2917, F1 Macro: 0.2032, Accuracy: 0.2917\n","Epoch 64, Train Loss: 17.7900, Val Loss: 21.3563, F1 Micro: 0.1979, F1 Macro: 0.1017, Accuracy: 0.1979\n","Epoch 65, Train Loss: 15.2389, Val Loss: 11.5850, F1 Micro: 0.1979, F1 Macro: 0.1168, Accuracy: 0.1979\n","Epoch 66, Train Loss: 11.4980, Val Loss: 14.6289, F1 Micro: 0.1771, F1 Macro: 0.0950, Accuracy: 0.1771\n","Epoch 67, Train Loss: 12.0977, Val Loss: 17.5470, F1 Micro: 0.2396, F1 Macro: 0.1595, Accuracy: 0.2396\n","Epoch 68, Train Loss: 11.6034, Val Loss: 10.3517, F1 Micro: 0.2188, F1 Macro: 0.1463, Accuracy: 0.2188\n","Epoch 69, Train Loss: 11.4290, Val Loss: 8.5587, F1 Micro: 0.1875, F1 Macro: 0.1245, Accuracy: 0.1875\n","Epoch 70, Train Loss: 6.8759, Val Loss: 9.6841, F1 Micro: 0.2500, F1 Macro: 0.2229, Accuracy: 0.2500\n","Epoch 71, Train Loss: 7.8718, Val Loss: 13.9788, F1 Micro: 0.2083, F1 Macro: 0.1551, Accuracy: 0.2083\n","Epoch 72, Train Loss: 6.6334, Val Loss: 6.7052, F1 Micro: 0.2292, F1 Macro: 0.1621, Accuracy: 0.2292\n","Epoch 73, Train Loss: 9.7767, Val Loss: 10.6924, F1 Micro: 0.1771, F1 Macro: 0.1020, Accuracy: 0.1771\n","Epoch 74, Train Loss: 9.2634, Val Loss: 15.7400, F1 Micro: 0.3021, F1 Macro: 0.2107, Accuracy: 0.3021\n","Epoch 75, Train Loss: 10.7148, Val Loss: 25.8562, F1 Micro: 0.2292, F1 Macro: 0.1251, Accuracy: 0.2292\n","Epoch 76, Train Loss: 15.4658, Val Loss: 7.0947, F1 Micro: 0.2083, F1 Macro: 0.1678, Accuracy: 0.2083\n","Epoch 77, Train Loss: 9.0398, Val Loss: 7.2613, F1 Micro: 0.2500, F1 Macro: 0.1948, Accuracy: 0.2500\n","Epoch 78, Train Loss: 10.6940, Val Loss: 16.6065, F1 Micro: 0.1979, F1 Macro: 0.1407, Accuracy: 0.1979\n","Epoch 79, Train Loss: 12.0493, Val Loss: 9.6413, F1 Micro: 0.3854, F1 Macro: 0.3277, Accuracy: 0.3854\n","Epoch 80, Train Loss: 10.5684, Val Loss: 24.2504, F1 Micro: 0.2083, F1 Macro: 0.1524, Accuracy: 0.2083\n","Epoch 81, Train Loss: 11.1136, Val Loss: 9.9155, F1 Micro: 0.3125, F1 Macro: 0.2247, Accuracy: 0.3125\n","Epoch 82, Train Loss: 5.5524, Val Loss: 5.3878, F1 Micro: 0.3021, F1 Macro: 0.2658, Accuracy: 0.3021\n","Epoch 83, Train Loss: 5.7901, Val Loss: 10.8008, F1 Micro: 0.2396, F1 Macro: 0.1496, Accuracy: 0.2396\n","Epoch 84, Train Loss: 12.7688, Val Loss: 12.5594, F1 Micro: 0.2396, F1 Macro: 0.1865, Accuracy: 0.2396\n","Epoch 85, Train Loss: 16.0574, Val Loss: 22.1247, F1 Micro: 0.1979, F1 Macro: 0.1053, Accuracy: 0.1979\n","Epoch 86, Train Loss: 12.0033, Val Loss: 18.1760, F1 Micro: 0.2604, F1 Macro: 0.1911, Accuracy: 0.2604\n","Epoch 87, Train Loss: 9.4379, Val Loss: 12.7804, F1 Micro: 0.2604, F1 Macro: 0.1830, Accuracy: 0.2604\n","Epoch 88, Train Loss: 9.8681, Val Loss: 9.4710, F1 Micro: 0.2917, F1 Macro: 0.2217, Accuracy: 0.2917\n","Epoch 89, Train Loss: 13.1475, Val Loss: 11.5914, F1 Micro: 0.2812, F1 Macro: 0.1699, Accuracy: 0.2812\n","Epoch 90, Train Loss: 9.7566, Val Loss: 10.1132, F1 Micro: 0.1875, F1 Macro: 0.0806, Accuracy: 0.1875\n","Epoch 91, Train Loss: 6.3594, Val Loss: 5.1080, F1 Micro: 0.2812, F1 Macro: 0.2300, Accuracy: 0.2812\n","Epoch 92, Train Loss: 11.0097, Val Loss: 11.3022, F1 Micro: 0.2292, F1 Macro: 0.1577, Accuracy: 0.2292\n","Epoch 93, Train Loss: 13.2076, Val Loss: 16.0468, F1 Micro: 0.2812, F1 Macro: 0.1720, Accuracy: 0.2812\n","Epoch 94, Train Loss: 11.5846, Val Loss: 29.5473, F1 Micro: 0.2604, F1 Macro: 0.1553, Accuracy: 0.2604\n","Epoch 95, Train Loss: 13.1733, Val Loss: 19.6439, F1 Micro: 0.2083, F1 Macro: 0.1046, Accuracy: 0.2083\n","Epoch 96, Train Loss: 14.0021, Val Loss: 24.9708, F1 Micro: 0.1771, F1 Macro: 0.0891, Accuracy: 0.1771\n","Epoch 97, Train Loss: 13.7143, Val Loss: 13.5359, F1 Micro: 0.3125, F1 Macro: 0.2200, Accuracy: 0.3125\n","Epoch 98, Train Loss: 12.7448, Val Loss: 24.8901, F1 Micro: 0.2188, F1 Macro: 0.1601, Accuracy: 0.2188\n","Epoch 99, Train Loss: 10.1626, Val Loss: 7.4771, F1 Micro: 0.2604, F1 Macro: 0.1619, Accuracy: 0.2604\n","Epoch 100, Train Loss: 11.6924, Val Loss: 9.1928, F1 Micro: 0.2396, F1 Macro: 0.1532, Accuracy: 0.2396\n","Epoch 101, Train Loss: 11.5954, Val Loss: 14.6737, F1 Micro: 0.2500, F1 Macro: 0.1247, Accuracy: 0.2500\n","Epoch 102, Train Loss: 11.2256, Val Loss: 9.4249, F1 Micro: 0.2500, F1 Macro: 0.2446, Accuracy: 0.2500\n","Epoch 103, Train Loss: 10.0232, Val Loss: 15.6364, F1 Micro: 0.2604, F1 Macro: 0.1738, Accuracy: 0.2604\n","Epoch 104, Train Loss: 7.6177, Val Loss: 6.7838, F1 Micro: 0.2708, F1 Macro: 0.2108, Accuracy: 0.2708\n","Epoch 105, Train Loss: 6.7320, Val Loss: 4.8213, F1 Micro: 0.2604, F1 Macro: 0.2316, Accuracy: 0.2604\n","Epoch 106, Train Loss: 9.2419, Val Loss: 10.1161, F1 Micro: 0.2396, F1 Macro: 0.1568, Accuracy: 0.2396\n","Epoch 107, Train Loss: 8.4782, Val Loss: 9.0644, F1 Micro: 0.3021, F1 Macro: 0.2298, Accuracy: 0.3021\n","Epoch 108, Train Loss: 6.6792, Val Loss: 7.1022, F1 Micro: 0.2604, F1 Macro: 0.2273, Accuracy: 0.2604\n","Epoch 109, Train Loss: 7.6279, Val Loss: 9.9800, F1 Micro: 0.1771, F1 Macro: 0.1340, Accuracy: 0.1771\n","Epoch 110, Train Loss: 9.6562, Val Loss: 15.1486, F1 Micro: 0.2083, F1 Macro: 0.0911, Accuracy: 0.2083\n","Epoch 111, Train Loss: 12.8581, Val Loss: 13.6565, F1 Micro: 0.2812, F1 Macro: 0.1886, Accuracy: 0.2812\n","Epoch 112, Train Loss: 10.7242, Val Loss: 7.2693, F1 Micro: 0.3021, F1 Macro: 0.2227, Accuracy: 0.3021\n","Epoch 113, Train Loss: 5.5210, Val Loss: 6.4287, F1 Micro: 0.2604, F1 Macro: 0.1968, Accuracy: 0.2604\n","Epoch 114, Train Loss: 6.8083, Val Loss: 6.9067, F1 Micro: 0.3542, F1 Macro: 0.3090, Accuracy: 0.3542\n","Epoch 115, Train Loss: 7.6748, Val Loss: 13.5648, F1 Micro: 0.3021, F1 Macro: 0.1957, Accuracy: 0.3021\n","Epoch 116, Train Loss: 6.4036, Val Loss: 10.6411, F1 Micro: 0.3021, F1 Macro: 0.2447, Accuracy: 0.3021\n","Epoch 117, Train Loss: 7.9029, Val Loss: 11.0112, F1 Micro: 0.3125, F1 Macro: 0.2943, Accuracy: 0.3125\n","Epoch 118, Train Loss: 8.4867, Val Loss: 6.3782, F1 Micro: 0.2292, F1 Macro: 0.1554, Accuracy: 0.2292\n","Epoch 119, Train Loss: 9.0098, Val Loss: 12.2329, F1 Micro: 0.2500, F1 Macro: 0.1691, Accuracy: 0.2500\n","Epoch 120, Train Loss: 13.2181, Val Loss: 16.0340, F1 Micro: 0.2083, F1 Macro: 0.1384, Accuracy: 0.2083\n","Epoch 121, Train Loss: 9.4040, Val Loss: 10.1376, F1 Micro: 0.2604, F1 Macro: 0.1783, Accuracy: 0.2604\n","Epoch 122, Train Loss: 7.9908, Val Loss: 5.9067, F1 Micro: 0.2500, F1 Macro: 0.2242, Accuracy: 0.2500\n","Epoch 123, Train Loss: 5.4181, Val Loss: 6.3423, F1 Micro: 0.3125, F1 Macro: 0.2772, Accuracy: 0.3125\n","Epoch 124, Train Loss: 7.2929, Val Loss: 4.3220, F1 Micro: 0.3958, F1 Macro: 0.3538, Accuracy: 0.3958\n","Epoch 125, Train Loss: 4.7550, Val Loss: 6.4002, F1 Micro: 0.2292, F1 Macro: 0.1385, Accuracy: 0.2292\n","Epoch 126, Train Loss: 5.3290, Val Loss: 4.9945, F1 Micro: 0.2500, F1 Macro: 0.2081, Accuracy: 0.2500\n","Epoch 127, Train Loss: 7.4750, Val Loss: 14.8970, F1 Micro: 0.2188, F1 Macro: 0.1254, Accuracy: 0.2188\n","Epoch 128, Train Loss: 11.5442, Val Loss: 11.8804, F1 Micro: 0.2604, F1 Macro: 0.1816, Accuracy: 0.2604\n","Epoch 129, Train Loss: 9.9547, Val Loss: 12.7956, F1 Micro: 0.2292, F1 Macro: 0.1586, Accuracy: 0.2292\n","Epoch 130, Train Loss: 9.9827, Val Loss: 16.4722, F1 Micro: 0.2292, F1 Macro: 0.1222, Accuracy: 0.2292\n","Epoch 131, Train Loss: 9.2322, Val Loss: 10.3927, F1 Micro: 0.2188, F1 Macro: 0.1360, Accuracy: 0.2188\n","Epoch 132, Train Loss: 7.3531, Val Loss: 6.3750, F1 Micro: 0.2500, F1 Macro: 0.1958, Accuracy: 0.2500\n","Epoch 133, Train Loss: 6.3641, Val Loss: 8.1391, F1 Micro: 0.2292, F1 Macro: 0.2056, Accuracy: 0.2292\n","Epoch 134, Train Loss: 4.0562, Val Loss: 8.6757, F1 Micro: 0.1979, F1 Macro: 0.1460, Accuracy: 0.1979\n","Epoch 135, Train Loss: 10.2848, Val Loss: 6.4927, F1 Micro: 0.3021, F1 Macro: 0.2088, Accuracy: 0.3021\n","Epoch 136, Train Loss: 7.6777, Val Loss: 11.4179, F1 Micro: 0.2292, F1 Macro: 0.1835, Accuracy: 0.2292\n","Epoch 137, Train Loss: 6.9433, Val Loss: 9.1859, F1 Micro: 0.1979, F1 Macro: 0.1747, Accuracy: 0.1979\n","Epoch 138, Train Loss: 5.6504, Val Loss: 6.7783, F1 Micro: 0.2083, F1 Macro: 0.1209, Accuracy: 0.2083\n","Epoch 139, Train Loss: 9.7053, Val Loss: 10.0362, F1 Micro: 0.2812, F1 Macro: 0.1895, Accuracy: 0.2812\n","Epoch 140, Train Loss: 10.0842, Val Loss: 16.5177, F1 Micro: 0.1771, F1 Macro: 0.0693, Accuracy: 0.1771\n","Epoch 141, Train Loss: 8.9880, Val Loss: 6.4146, F1 Micro: 0.2604, F1 Macro: 0.2179, Accuracy: 0.2604\n","Epoch 142, Train Loss: 5.5763, Val Loss: 13.6543, F1 Micro: 0.3125, F1 Macro: 0.2406, Accuracy: 0.3125\n","Epoch 143, Train Loss: 6.1844, Val Loss: 10.5474, F1 Micro: 0.2708, F1 Macro: 0.1768, Accuracy: 0.2708\n","Epoch 144, Train Loss: 9.6464, Val Loss: 18.6677, F1 Micro: 0.2917, F1 Macro: 0.2305, Accuracy: 0.2917\n","Epoch 145, Train Loss: 8.8212, Val Loss: 10.8669, F1 Micro: 0.2708, F1 Macro: 0.1677, Accuracy: 0.2708\n","Epoch 146, Train Loss: 9.9589, Val Loss: 5.5139, F1 Micro: 0.3646, F1 Macro: 0.3228, Accuracy: 0.3646\n","Epoch 147, Train Loss: 5.9050, Val Loss: 10.1850, F1 Micro: 0.2500, F1 Macro: 0.2033, Accuracy: 0.2500\n","Epoch 148, Train Loss: 11.0069, Val Loss: 8.0916, F1 Micro: 0.2292, F1 Macro: 0.1550, Accuracy: 0.2292\n","Epoch 149, Train Loss: 8.9962, Val Loss: 7.6854, F1 Micro: 0.2188, F1 Macro: 0.1290, Accuracy: 0.2188\n","Epoch 150, Train Loss: 8.2772, Val Loss: 10.8860, F1 Micro: 0.2292, F1 Macro: 0.1678, Accuracy: 0.2292\n","Epoch 151, Train Loss: 7.9212, Val Loss: 7.9774, F1 Micro: 0.2604, F1 Macro: 0.2003, Accuracy: 0.2604\n","Epoch 152, Train Loss: 5.3689, Val Loss: 8.1831, F1 Micro: 0.2500, F1 Macro: 0.2119, Accuracy: 0.2500\n","Epoch 153, Train Loss: 6.5824, Val Loss: 11.5135, F1 Micro: 0.2083, F1 Macro: 0.1521, Accuracy: 0.2083\n","Epoch 154, Train Loss: 8.1754, Val Loss: 6.3438, F1 Micro: 0.3125, F1 Macro: 0.2440, Accuracy: 0.3125\n","Epoch 155, Train Loss: 8.4214, Val Loss: 12.5003, F1 Micro: 0.2708, F1 Macro: 0.1427, Accuracy: 0.2708\n","Epoch 156, Train Loss: 9.4436, Val Loss: 7.8292, F1 Micro: 0.3958, F1 Macro: 0.3174, Accuracy: 0.3958\n","Epoch 157, Train Loss: 6.6321, Val Loss: 8.0114, F1 Micro: 0.1979, F1 Macro: 0.1188, Accuracy: 0.1979\n","Epoch 158, Train Loss: 6.4884, Val Loss: 6.8964, F1 Micro: 0.2500, F1 Macro: 0.1271, Accuracy: 0.2500\n","Epoch 159, Train Loss: 10.6283, Val Loss: 16.8125, F1 Micro: 0.2604, F1 Macro: 0.2072, Accuracy: 0.2604\n","Epoch 160, Train Loss: 8.6412, Val Loss: 9.7797, F1 Micro: 0.2188, F1 Macro: 0.1665, Accuracy: 0.2188\n","Epoch 161, Train Loss: 6.4969, Val Loss: 8.2166, F1 Micro: 0.3229, F1 Macro: 0.2166, Accuracy: 0.3229\n","Epoch 162, Train Loss: 9.2965, Val Loss: 6.3492, F1 Micro: 0.3438, F1 Macro: 0.2905, Accuracy: 0.3438\n","Epoch 163, Train Loss: 6.5918, Val Loss: 9.6350, F1 Micro: 0.2188, F1 Macro: 0.1307, Accuracy: 0.2188\n","Epoch 164, Train Loss: 8.3857, Val Loss: 9.0607, F1 Micro: 0.2708, F1 Macro: 0.2137, Accuracy: 0.2708\n","Epoch 165, Train Loss: 8.9581, Val Loss: 8.6068, F1 Micro: 0.3021, F1 Macro: 0.2378, Accuracy: 0.3021\n","Epoch 166, Train Loss: 7.6140, Val Loss: 18.7424, F1 Micro: 0.3333, F1 Macro: 0.2613, Accuracy: 0.3333\n","Epoch 167, Train Loss: 8.2418, Val Loss: 10.2239, F1 Micro: 0.2188, F1 Macro: 0.1519, Accuracy: 0.2188\n","Epoch 168, Train Loss: 7.4083, Val Loss: 14.2298, F1 Micro: 0.2604, F1 Macro: 0.1979, Accuracy: 0.2604\n","Epoch 169, Train Loss: 6.5317, Val Loss: 5.4412, F1 Micro: 0.2604, F1 Macro: 0.2288, Accuracy: 0.2604\n","Epoch 170, Train Loss: 5.9802, Val Loss: 5.7977, F1 Micro: 0.2396, F1 Macro: 0.1949, Accuracy: 0.2396\n","Epoch 171, Train Loss: 6.4180, Val Loss: 3.9461, F1 Micro: 0.3854, F1 Macro: 0.3647, Accuracy: 0.3854\n","Epoch 172, Train Loss: 4.5871, Val Loss: 7.5619, F1 Micro: 0.2708, F1 Macro: 0.2245, Accuracy: 0.2708\n","Epoch 173, Train Loss: 7.0175, Val Loss: 8.6186, F1 Micro: 0.2292, F1 Macro: 0.1391, Accuracy: 0.2292\n","Epoch 174, Train Loss: 5.7173, Val Loss: 9.7413, F1 Micro: 0.2500, F1 Macro: 0.1633, Accuracy: 0.2500\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 115.6452, Val Loss: 50.3281, F1 Micro: 0.1979, F1 Macro: 0.1131, Accuracy: 0.1979\n","Epoch 2, Train Loss: 35.7664, Val Loss: 15.3265, F1 Micro: 0.2292, F1 Macro: 0.0992, Accuracy: 0.2292\n","Epoch 3, Train Loss: 17.0544, Val Loss: 12.4837, F1 Micro: 0.2083, F1 Macro: 0.1559, Accuracy: 0.2083\n","Epoch 4, Train Loss: 18.0244, Val Loss: 15.1145, F1 Micro: 0.2500, F1 Macro: 0.1326, Accuracy: 0.2500\n","Epoch 5, Train Loss: 22.1950, Val Loss: 17.5159, F1 Micro: 0.1979, F1 Macro: 0.1168, Accuracy: 0.1979\n","Epoch 6, Train Loss: 23.5579, Val Loss: 14.8315, F1 Micro: 0.1875, F1 Macro: 0.0995, Accuracy: 0.1875\n","Epoch 7, Train Loss: 15.3172, Val Loss: 22.7424, F1 Micro: 0.1458, F1 Macro: 0.0481, Accuracy: 0.1458\n","Epoch 8, Train Loss: 21.7601, Val Loss: 28.7035, F1 Micro: 0.1458, F1 Macro: 0.0557, Accuracy: 0.1458\n","Epoch 9, Train Loss: 29.0927, Val Loss: 26.0102, F1 Micro: 0.2292, F1 Macro: 0.1616, Accuracy: 0.2292\n","Epoch 10, Train Loss: 21.3287, Val Loss: 35.2406, F1 Micro: 0.2083, F1 Macro: 0.0575, Accuracy: 0.2083\n","Epoch 11, Train Loss: 20.1078, Val Loss: 13.4829, F1 Micro: 0.2292, F1 Macro: 0.1326, Accuracy: 0.2292\n","Epoch 12, Train Loss: 14.1265, Val Loss: 12.7377, F1 Micro: 0.2292, F1 Macro: 0.1860, Accuracy: 0.2292\n","Epoch 13, Train Loss: 17.6432, Val Loss: 10.2282, F1 Micro: 0.1771, F1 Macro: 0.0898, Accuracy: 0.1771\n","Epoch 14, Train Loss: 19.0731, Val Loss: 14.2818, F1 Micro: 0.2708, F1 Macro: 0.2250, Accuracy: 0.2708\n","Epoch 15, Train Loss: 11.9458, Val Loss: 9.5426, F1 Micro: 0.2812, F1 Macro: 0.1974, Accuracy: 0.2812\n","Epoch 16, Train Loss: 12.6603, Val Loss: 20.4588, F1 Micro: 0.2500, F1 Macro: 0.1769, Accuracy: 0.2500\n","Epoch 17, Train Loss: 21.3133, Val Loss: 20.3366, F1 Micro: 0.1562, F1 Macro: 0.1093, Accuracy: 0.1562\n","Epoch 18, Train Loss: 16.6199, Val Loss: 22.7109, F1 Micro: 0.2083, F1 Macro: 0.1190, Accuracy: 0.2083\n","Epoch 19, Train Loss: 15.3455, Val Loss: 14.3670, F1 Micro: 0.2083, F1 Macro: 0.1153, Accuracy: 0.2083\n","Epoch 20, Train Loss: 11.2280, Val Loss: 8.8510, F1 Micro: 0.2396, F1 Macro: 0.1945, Accuracy: 0.2396\n","Epoch 21, Train Loss: 14.4821, Val Loss: 17.6275, F1 Micro: 0.1667, F1 Macro: 0.0662, Accuracy: 0.1667\n","Epoch 22, Train Loss: 22.3993, Val Loss: 27.8511, F1 Micro: 0.1979, F1 Macro: 0.1030, Accuracy: 0.1979\n","Epoch 23, Train Loss: 22.0766, Val Loss: 20.8023, F1 Micro: 0.2083, F1 Macro: 0.1360, Accuracy: 0.2083\n","Epoch 24, Train Loss: 15.8654, Val Loss: 14.7478, F1 Micro: 0.1354, F1 Macro: 0.0524, Accuracy: 0.1354\n","Epoch 25, Train Loss: 16.5827, Val Loss: 12.2431, F1 Micro: 0.2812, F1 Macro: 0.1790, Accuracy: 0.2812\n","Epoch 26, Train Loss: 15.8791, Val Loss: 13.8454, F1 Micro: 0.3021, F1 Macro: 0.2106, Accuracy: 0.3021\n","Epoch 27, Train Loss: 12.8393, Val Loss: 15.0045, F1 Micro: 0.1458, F1 Macro: 0.0769, Accuracy: 0.1458\n","Epoch 28, Train Loss: 12.9875, Val Loss: 12.7790, F1 Micro: 0.1875, F1 Macro: 0.1153, Accuracy: 0.1875\n","Epoch 29, Train Loss: 12.2258, Val Loss: 13.1644, F1 Micro: 0.2083, F1 Macro: 0.1538, Accuracy: 0.2083\n","Epoch 30, Train Loss: 15.2777, Val Loss: 28.0380, F1 Micro: 0.1667, F1 Macro: 0.0842, Accuracy: 0.1667\n","Epoch 31, Train Loss: 21.6845, Val Loss: 16.9428, F1 Micro: 0.2188, F1 Macro: 0.1534, Accuracy: 0.2188\n","Epoch 32, Train Loss: 11.3884, Val Loss: 11.6814, F1 Micro: 0.2604, F1 Macro: 0.2107, Accuracy: 0.2604\n","Epoch 33, Train Loss: 21.9493, Val Loss: 20.7105, F1 Micro: 0.2396, F1 Macro: 0.1316, Accuracy: 0.2396\n","Epoch 34, Train Loss: 23.5118, Val Loss: 17.6970, F1 Micro: 0.3750, F1 Macro: 0.2838, Accuracy: 0.3750\n","Epoch 35, Train Loss: 19.5016, Val Loss: 17.7484, F1 Micro: 0.1771, F1 Macro: 0.0980, Accuracy: 0.1771\n","Epoch 36, Train Loss: 19.5968, Val Loss: 18.5372, F1 Micro: 0.2396, F1 Macro: 0.1598, Accuracy: 0.2396\n","Epoch 37, Train Loss: 14.7006, Val Loss: 13.0588, F1 Micro: 0.2396, F1 Macro: 0.1721, Accuracy: 0.2396\n","Epoch 38, Train Loss: 11.3090, Val Loss: 12.8030, F1 Micro: 0.2292, F1 Macro: 0.1223, Accuracy: 0.2292\n","Epoch 39, Train Loss: 19.4087, Val Loss: 14.6486, F1 Micro: 0.2917, F1 Macro: 0.1928, Accuracy: 0.2917\n","Epoch 40, Train Loss: 19.5764, Val Loss: 18.5403, F1 Micro: 0.1979, F1 Macro: 0.1019, Accuracy: 0.1979\n","Epoch 41, Train Loss: 15.7725, Val Loss: 12.2089, F1 Micro: 0.2500, F1 Macro: 0.1403, Accuracy: 0.2500\n","Epoch 42, Train Loss: 8.5663, Val Loss: 13.3905, F1 Micro: 0.1979, F1 Macro: 0.1088, Accuracy: 0.1979\n","Epoch 43, Train Loss: 10.5719, Val Loss: 22.2165, F1 Micro: 0.1354, F1 Macro: 0.0616, Accuracy: 0.1354\n","Epoch 44, Train Loss: 20.6892, Val Loss: 13.2389, F1 Micro: 0.2500, F1 Macro: 0.1604, Accuracy: 0.2500\n","Epoch 45, Train Loss: 14.1305, Val Loss: 13.7716, F1 Micro: 0.2188, F1 Macro: 0.1542, Accuracy: 0.2188\n","Epoch 46, Train Loss: 13.5534, Val Loss: 13.3614, F1 Micro: 0.2500, F1 Macro: 0.1776, Accuracy: 0.2500\n","Epoch 47, Train Loss: 9.4073, Val Loss: 8.8590, F1 Micro: 0.3646, F1 Macro: 0.3042, Accuracy: 0.3646\n","Epoch 48, Train Loss: 11.8699, Val Loss: 11.8409, F1 Micro: 0.1771, F1 Macro: 0.0918, Accuracy: 0.1771\n","Epoch 49, Train Loss: 15.7417, Val Loss: 11.2107, F1 Micro: 0.2500, F1 Macro: 0.1848, Accuracy: 0.2500\n","Epoch 50, Train Loss: 8.9235, Val Loss: 13.6840, F1 Micro: 0.2396, F1 Macro: 0.1825, Accuracy: 0.2396\n","Epoch 51, Train Loss: 13.5379, Val Loss: 13.3098, F1 Micro: 0.2292, F1 Macro: 0.1522, Accuracy: 0.2292\n","Epoch 52, Train Loss: 13.0747, Val Loss: 8.2313, F1 Micro: 0.2396, F1 Macro: 0.1454, Accuracy: 0.2396\n","Epoch 53, Train Loss: 12.5275, Val Loss: 13.0680, F1 Micro: 0.2083, F1 Macro: 0.1395, Accuracy: 0.2083\n","Epoch 54, Train Loss: 14.3957, Val Loss: 17.2205, F1 Micro: 0.1875, F1 Macro: 0.0846, Accuracy: 0.1875\n","Epoch 55, Train Loss: 20.0623, Val Loss: 8.4572, F1 Micro: 0.2708, F1 Macro: 0.2075, Accuracy: 0.2708\n","Epoch 56, Train Loss: 13.7156, Val Loss: 11.4193, F1 Micro: 0.3229, F1 Macro: 0.2207, Accuracy: 0.3229\n","Epoch 57, Train Loss: 13.7920, Val Loss: 16.7164, F1 Micro: 0.2604, F1 Macro: 0.1732, Accuracy: 0.2604\n","Epoch 58, Train Loss: 21.7433, Val Loss: 15.2013, F1 Micro: 0.1875, F1 Macro: 0.1079, Accuracy: 0.1875\n","Epoch 59, Train Loss: 14.6702, Val Loss: 13.1158, F1 Micro: 0.3125, F1 Macro: 0.2627, Accuracy: 0.3125\n","Epoch 60, Train Loss: 14.1504, Val Loss: 9.6091, F1 Micro: 0.1979, F1 Macro: 0.1016, Accuracy: 0.1979\n","Epoch 61, Train Loss: 9.1254, Val Loss: 5.7737, F1 Micro: 0.3646, F1 Macro: 0.2900, Accuracy: 0.3646\n","Epoch 62, Train Loss: 8.7664, Val Loss: 8.9046, F1 Micro: 0.2812, F1 Macro: 0.2025, Accuracy: 0.2812\n","Epoch 63, Train Loss: 9.0455, Val Loss: 18.7342, F1 Micro: 0.2708, F1 Macro: 0.1878, Accuracy: 0.2708\n","Epoch 64, Train Loss: 23.4895, Val Loss: 17.5958, F1 Micro: 0.1667, F1 Macro: 0.0813, Accuracy: 0.1667\n","Epoch 65, Train Loss: 14.4207, Val Loss: 16.2578, F1 Micro: 0.2500, F1 Macro: 0.1750, Accuracy: 0.2500\n","Epoch 66, Train Loss: 18.1492, Val Loss: 17.4634, F1 Micro: 0.1771, F1 Macro: 0.1105, Accuracy: 0.1771\n","Epoch 67, Train Loss: 15.4532, Val Loss: 18.7584, F1 Micro: 0.3229, F1 Macro: 0.2302, Accuracy: 0.3229\n","Epoch 68, Train Loss: 10.5327, Val Loss: 7.2350, F1 Micro: 0.3021, F1 Macro: 0.2479, Accuracy: 0.3021\n","Epoch 69, Train Loss: 13.4680, Val Loss: 22.1122, F1 Micro: 0.1458, F1 Macro: 0.0491, Accuracy: 0.1458\n","Epoch 70, Train Loss: 16.7506, Val Loss: 18.4263, F1 Micro: 0.2396, F1 Macro: 0.1652, Accuracy: 0.2396\n","Epoch 71, Train Loss: 16.6781, Val Loss: 19.3637, F1 Micro: 0.2500, F1 Macro: 0.1752, Accuracy: 0.2500\n","Epoch 72, Train Loss: 17.5655, Val Loss: 8.6616, F1 Micro: 0.1979, F1 Macro: 0.1218, Accuracy: 0.1979\n","Epoch 73, Train Loss: 12.4740, Val Loss: 8.0985, F1 Micro: 0.2188, F1 Macro: 0.1609, Accuracy: 0.2188\n","Epoch 74, Train Loss: 8.6859, Val Loss: 14.0759, F1 Micro: 0.2188, F1 Macro: 0.0780, Accuracy: 0.2188\n","Epoch 75, Train Loss: 13.9290, Val Loss: 10.4893, F1 Micro: 0.3646, F1 Macro: 0.3288, Accuracy: 0.3646\n","Epoch 76, Train Loss: 12.0951, Val Loss: 10.4155, F1 Micro: 0.3229, F1 Macro: 0.2462, Accuracy: 0.3229\n","Epoch 77, Train Loss: 11.5384, Val Loss: 6.0772, F1 Micro: 0.2396, F1 Macro: 0.2005, Accuracy: 0.2396\n","Epoch 78, Train Loss: 16.5429, Val Loss: 31.1989, F1 Micro: 0.2188, F1 Macro: 0.1144, Accuracy: 0.2188\n","Epoch 79, Train Loss: 16.7896, Val Loss: 18.7777, F1 Micro: 0.2708, F1 Macro: 0.2048, Accuracy: 0.2708\n","Epoch 80, Train Loss: 16.1805, Val Loss: 8.9203, F1 Micro: 0.2396, F1 Macro: 0.1548, Accuracy: 0.2396\n","Epoch 81, Train Loss: 10.9834, Val Loss: 17.1095, F1 Micro: 0.2188, F1 Macro: 0.1302, Accuracy: 0.2188\n","Epoch 82, Train Loss: 10.1862, Val Loss: 10.6746, F1 Micro: 0.2812, F1 Macro: 0.2045, Accuracy: 0.2812\n","Epoch 83, Train Loss: 12.4120, Val Loss: 14.3617, F1 Micro: 0.1979, F1 Macro: 0.1345, Accuracy: 0.1979\n","Epoch 84, Train Loss: 10.0539, Val Loss: 8.8492, F1 Micro: 0.2396, F1 Macro: 0.2464, Accuracy: 0.2396\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.4104166666666666\n","Best hyperparameters for Outer FOLD 4: (0.001, 16, 50) with score 0.4104166666666666\n","Epoch 1, Train Loss: 68.1178, Val Loss: 20.3490, F1 Micro: 0.2333, F1 Macro: 0.1132, Accuracy: 0.2333\n","Epoch 2, Train Loss: 22.5353, Val Loss: 29.1824, F1 Micro: 0.2000, F1 Macro: 0.1435, Accuracy: 0.2000\n","Epoch 3, Train Loss: 22.8542, Val Loss: 20.2641, F1 Micro: 0.2583, F1 Macro: 0.1423, Accuracy: 0.2583\n","Epoch 4, Train Loss: 18.6119, Val Loss: 31.5450, F1 Micro: 0.1917, F1 Macro: 0.1106, Accuracy: 0.1917\n","Epoch 5, Train Loss: 19.9141, Val Loss: 19.5557, F1 Micro: 0.2583, F1 Macro: 0.1886, Accuracy: 0.2583\n","Epoch 6, Train Loss: 17.8460, Val Loss: 12.8303, F1 Micro: 0.1417, F1 Macro: 0.0711, Accuracy: 0.1417\n","Epoch 7, Train Loss: 21.5635, Val Loss: 12.8539, F1 Micro: 0.2500, F1 Macro: 0.1919, Accuracy: 0.2500\n","Epoch 8, Train Loss: 26.4137, Val Loss: 29.1529, F1 Micro: 0.2083, F1 Macro: 0.1253, Accuracy: 0.2083\n","Epoch 9, Train Loss: 23.3783, Val Loss: 11.7897, F1 Micro: 0.2417, F1 Macro: 0.1547, Accuracy: 0.2417\n","Epoch 10, Train Loss: 15.1279, Val Loss: 8.1499, F1 Micro: 0.2500, F1 Macro: 0.1893, Accuracy: 0.2500\n","Epoch 11, Train Loss: 16.3272, Val Loss: 11.7038, F1 Micro: 0.2167, F1 Macro: 0.1085, Accuracy: 0.2167\n","Epoch 12, Train Loss: 15.5850, Val Loss: 10.1694, F1 Micro: 0.2500, F1 Macro: 0.2069, Accuracy: 0.2500\n","Epoch 13, Train Loss: 18.3607, Val Loss: 14.5254, F1 Micro: 0.1917, F1 Macro: 0.0950, Accuracy: 0.1917\n","Epoch 14, Train Loss: 13.1623, Val Loss: 13.7641, F1 Micro: 0.1917, F1 Macro: 0.0988, Accuracy: 0.1917\n","Epoch 15, Train Loss: 20.9963, Val Loss: 33.8351, F1 Micro: 0.1750, F1 Macro: 0.0941, Accuracy: 0.1750\n","Epoch 16, Train Loss: 22.7931, Val Loss: 15.2424, F1 Micro: 0.2667, F1 Macro: 0.1759, Accuracy: 0.2667\n","Epoch 17, Train Loss: 20.6160, Val Loss: 10.1258, F1 Micro: 0.2083, F1 Macro: 0.1358, Accuracy: 0.2083\n","Epoch 18, Train Loss: 19.8985, Val Loss: 16.7620, F1 Micro: 0.1750, F1 Macro: 0.0955, Accuracy: 0.1750\n","Epoch 19, Train Loss: 16.0895, Val Loss: 10.2205, F1 Micro: 0.2500, F1 Macro: 0.1794, Accuracy: 0.2500\n","Epoch 20, Train Loss: 17.0980, Val Loss: 16.2073, F1 Micro: 0.2417, F1 Macro: 0.1421, Accuracy: 0.2417\n","Epoch 21, Train Loss: 16.0149, Val Loss: 18.7424, F1 Micro: 0.1667, F1 Macro: 0.0826, Accuracy: 0.1667\n","Epoch 22, Train Loss: 13.5897, Val Loss: 14.3305, F1 Micro: 0.1917, F1 Macro: 0.1099, Accuracy: 0.1917\n","Epoch 23, Train Loss: 16.2106, Val Loss: 15.5080, F1 Micro: 0.2667, F1 Macro: 0.2056, Accuracy: 0.2667\n","Epoch 24, Train Loss: 17.7485, Val Loss: 13.5279, F1 Micro: 0.1750, F1 Macro: 0.0511, Accuracy: 0.1750\n","Epoch 25, Train Loss: 18.8617, Val Loss: 24.7018, F1 Micro: 0.2250, F1 Macro: 0.1629, Accuracy: 0.2250\n","Epoch 26, Train Loss: 22.8473, Val Loss: 11.9010, F1 Micro: 0.2833, F1 Macro: 0.2097, Accuracy: 0.2833\n","Epoch 27, Train Loss: 25.7515, Val Loss: 23.6084, F1 Micro: 0.2083, F1 Macro: 0.1533, Accuracy: 0.2083\n","Epoch 28, Train Loss: 18.6965, Val Loss: 13.9287, F1 Micro: 0.1833, F1 Macro: 0.1040, Accuracy: 0.1833\n","Epoch 29, Train Loss: 14.9812, Val Loss: 13.6463, F1 Micro: 0.2667, F1 Macro: 0.2221, Accuracy: 0.2667\n","Epoch 30, Train Loss: 17.2387, Val Loss: 26.2034, F1 Micro: 0.2167, F1 Macro: 0.1546, Accuracy: 0.2167\n","Epoch 31, Train Loss: 19.6841, Val Loss: 20.5316, F1 Micro: 0.2667, F1 Macro: 0.1867, Accuracy: 0.2667\n","Epoch 32, Train Loss: 16.7472, Val Loss: 25.4770, F1 Micro: 0.1833, F1 Macro: 0.1127, Accuracy: 0.1833\n","Epoch 33, Train Loss: 19.0394, Val Loss: 17.4098, F1 Micro: 0.2083, F1 Macro: 0.1004, Accuracy: 0.2083\n","Epoch 34, Train Loss: 12.7473, Val Loss: 12.5928, F1 Micro: 0.2083, F1 Macro: 0.1311, Accuracy: 0.2083\n","Epoch 35, Train Loss: 14.9968, Val Loss: 8.7970, F1 Micro: 0.2917, F1 Macro: 0.2627, Accuracy: 0.2917\n","Epoch 36, Train Loss: 10.4255, Val Loss: 4.4105, F1 Micro: 0.3250, F1 Macro: 0.3087, Accuracy: 0.3250\n","Epoch 37, Train Loss: 11.1786, Val Loss: 8.9119, F1 Micro: 0.2250, F1 Macro: 0.1317, Accuracy: 0.2250\n","Epoch 38, Train Loss: 14.6321, Val Loss: 17.9457, F1 Micro: 0.1917, F1 Macro: 0.1311, Accuracy: 0.1917\n","Epoch 39, Train Loss: 13.7269, Val Loss: 11.8745, F1 Micro: 0.2083, F1 Macro: 0.1259, Accuracy: 0.2083\n","Epoch 40, Train Loss: 8.5420, Val Loss: 14.5484, F1 Micro: 0.2500, F1 Macro: 0.1612, Accuracy: 0.2500\n","Epoch 41, Train Loss: 10.8626, Val Loss: 10.9819, F1 Micro: 0.2167, F1 Macro: 0.1334, Accuracy: 0.2167\n","Epoch 42, Train Loss: 15.2561, Val Loss: 9.2545, F1 Micro: 0.2750, F1 Macro: 0.1868, Accuracy: 0.2750\n","Epoch 43, Train Loss: 17.4320, Val Loss: 21.1420, F1 Micro: 0.2417, F1 Macro: 0.1507, Accuracy: 0.2417\n","Epoch 44, Train Loss: 16.5375, Val Loss: 15.6176, F1 Micro: 0.2667, F1 Macro: 0.2018, Accuracy: 0.2667\n","Epoch 45, Train Loss: 11.8718, Val Loss: 12.0002, F1 Micro: 0.2667, F1 Macro: 0.2175, Accuracy: 0.2667\n","Epoch 46, Train Loss: 15.3419, Val Loss: 18.4695, F1 Micro: 0.2833, F1 Macro: 0.2095, Accuracy: 0.2833\n","Epoch 47, Train Loss: 19.0579, Val Loss: 6.3379, F1 Micro: 0.3500, F1 Macro: 0.3259, Accuracy: 0.3500\n","Epoch 48, Train Loss: 11.8292, Val Loss: 6.6672, F1 Micro: 0.2500, F1 Macro: 0.2215, Accuracy: 0.2500\n","Epoch 49, Train Loss: 9.4224, Val Loss: 5.4044, F1 Micro: 0.2417, F1 Macro: 0.1888, Accuracy: 0.2417\n","Epoch 50, Train Loss: 9.6858, Val Loss: 10.6181, F1 Micro: 0.2667, F1 Macro: 0.1745, Accuracy: 0.2667\n","Epoch 51, Train Loss: 9.3284, Val Loss: 9.4210, F1 Micro: 0.2250, F1 Macro: 0.1702, Accuracy: 0.2250\n","Epoch 52, Train Loss: 8.2193, Val Loss: 15.2297, F1 Micro: 0.2500, F1 Macro: 0.1844, Accuracy: 0.2500\n","Epoch 53, Train Loss: 16.5955, Val Loss: 17.1723, F1 Micro: 0.2917, F1 Macro: 0.2007, Accuracy: 0.2917\n","Epoch 54, Train Loss: 15.9555, Val Loss: 17.6922, F1 Micro: 0.2250, F1 Macro: 0.1724, Accuracy: 0.2250\n","Epoch 55, Train Loss: 16.9111, Val Loss: 12.1519, F1 Micro: 0.1500, F1 Macro: 0.1077, Accuracy: 0.1500\n","Epoch 56, Train Loss: 9.1671, Val Loss: 7.2898, F1 Micro: 0.3167, F1 Macro: 0.2602, Accuracy: 0.3167\n","Epoch 57, Train Loss: 7.5227, Val Loss: 13.9125, F1 Micro: 0.2250, F1 Macro: 0.1624, Accuracy: 0.2250\n","Epoch 58, Train Loss: 11.2828, Val Loss: 18.3515, F1 Micro: 0.2583, F1 Macro: 0.1824, Accuracy: 0.2583\n","Epoch 59, Train Loss: 14.3672, Val Loss: 11.2195, F1 Micro: 0.3250, F1 Macro: 0.2589, Accuracy: 0.3250\n","Epoch 60, Train Loss: 12.7934, Val Loss: 9.7011, F1 Micro: 0.1833, F1 Macro: 0.1036, Accuracy: 0.1833\n","Epoch 61, Train Loss: 12.5972, Val Loss: 4.4546, F1 Micro: 0.3083, F1 Macro: 0.2946, Accuracy: 0.3083\n","Epoch 62, Train Loss: 8.7856, Val Loss: 6.8914, F1 Micro: 0.2583, F1 Macro: 0.2123, Accuracy: 0.2583\n","Epoch 63, Train Loss: 9.8457, Val Loss: 6.1249, F1 Micro: 0.2250, F1 Macro: 0.1882, Accuracy: 0.2250\n","Epoch 64, Train Loss: 8.9869, Val Loss: 6.5718, F1 Micro: 0.2167, F1 Macro: 0.1884, Accuracy: 0.2167\n","Epoch 65, Train Loss: 9.2006, Val Loss: 10.0782, F1 Micro: 0.2083, F1 Macro: 0.1497, Accuracy: 0.2083\n","Epoch 66, Train Loss: 12.1352, Val Loss: 8.2544, F1 Micro: 0.2667, F1 Macro: 0.2121, Accuracy: 0.2667\n","Epoch 67, Train Loss: 10.3838, Val Loss: 13.0938, F1 Micro: 0.2750, F1 Macro: 0.2368, Accuracy: 0.2750\n","Epoch 68, Train Loss: 13.2955, Val Loss: 19.6774, F1 Micro: 0.3000, F1 Macro: 0.2546, Accuracy: 0.3000\n","Epoch 69, Train Loss: 13.6070, Val Loss: 10.8682, F1 Micro: 0.2083, F1 Macro: 0.1170, Accuracy: 0.2083\n","Epoch 70, Train Loss: 12.7687, Val Loss: 16.9366, F1 Micro: 0.2333, F1 Macro: 0.1644, Accuracy: 0.2333\n","Epoch 71, Train Loss: 9.9399, Val Loss: 10.5826, F1 Micro: 0.2500, F1 Macro: 0.1594, Accuracy: 0.2500\n","Epoch 72, Train Loss: 9.1917, Val Loss: 6.6853, F1 Micro: 0.2750, F1 Macro: 0.2183, Accuracy: 0.2750\n","Epoch 73, Train Loss: 11.4600, Val Loss: 11.8661, F1 Micro: 0.2333, F1 Macro: 0.1889, Accuracy: 0.2333\n","Epoch 74, Train Loss: 11.2420, Val Loss: 8.6664, F1 Micro: 0.2750, F1 Macro: 0.1969, Accuracy: 0.2750\n","Epoch 75, Train Loss: 11.4440, Val Loss: 13.4259, F1 Micro: 0.2167, F1 Macro: 0.1632, Accuracy: 0.2167\n","Epoch 76, Train Loss: 12.5612, Val Loss: 6.2108, F1 Micro: 0.3167, F1 Macro: 0.3007, Accuracy: 0.3167\n","Epoch 77, Train Loss: 9.6231, Val Loss: 6.1778, F1 Micro: 0.2250, F1 Macro: 0.1665, Accuracy: 0.2250\n","Epoch 78, Train Loss: 6.8490, Val Loss: 5.9757, F1 Micro: 0.3667, F1 Macro: 0.3099, Accuracy: 0.3667\n","Epoch 79, Train Loss: 10.6918, Val Loss: 12.7110, F1 Micro: 0.1750, F1 Macro: 0.0762, Accuracy: 0.1750\n","Epoch 80, Train Loss: 11.2608, Val Loss: 9.8261, F1 Micro: 0.4000, F1 Macro: 0.3592, Accuracy: 0.4000\n","Epoch 81, Train Loss: 8.8879, Val Loss: 3.7280, F1 Micro: 0.3500, F1 Macro: 0.2969, Accuracy: 0.3500\n","Epoch 82, Train Loss: 5.7892, Val Loss: 7.3900, F1 Micro: 0.2917, F1 Macro: 0.2566, Accuracy: 0.2917\n","Epoch 83, Train Loss: 9.1006, Val Loss: 6.3815, F1 Micro: 0.2667, F1 Macro: 0.2045, Accuracy: 0.2667\n","Epoch 84, Train Loss: 7.6978, Val Loss: 5.5551, F1 Micro: 0.3417, F1 Macro: 0.2995, Accuracy: 0.3417\n","Epoch 85, Train Loss: 11.6937, Val Loss: 9.5506, F1 Micro: 0.2333, F1 Macro: 0.1448, Accuracy: 0.2333\n","Epoch 86, Train Loss: 11.0654, Val Loss: 7.0390, F1 Micro: 0.2250, F1 Macro: 0.1584, Accuracy: 0.2250\n","Epoch 87, Train Loss: 9.6414, Val Loss: 10.4673, F1 Micro: 0.2250, F1 Macro: 0.1550, Accuracy: 0.2250\n","Epoch 88, Train Loss: 14.2526, Val Loss: 10.4378, F1 Micro: 0.2583, F1 Macro: 0.2083, Accuracy: 0.2583\n","Epoch 89, Train Loss: 7.5312, Val Loss: 7.1737, F1 Micro: 0.3333, F1 Macro: 0.2744, Accuracy: 0.3333\n","Epoch 90, Train Loss: 4.8889, Val Loss: 6.0642, F1 Micro: 0.2917, F1 Macro: 0.2352, Accuracy: 0.2917\n","Epoch 91, Train Loss: 12.5011, Val Loss: 15.8654, F1 Micro: 0.2083, F1 Macro: 0.1421, Accuracy: 0.2083\n","Epoch 92, Train Loss: 15.7286, Val Loss: 13.7874, F1 Micro: 0.2417, F1 Macro: 0.1408, Accuracy: 0.2417\n","Epoch 93, Train Loss: 13.3318, Val Loss: 12.6774, F1 Micro: 0.2917, F1 Macro: 0.2341, Accuracy: 0.2917\n","Epoch 94, Train Loss: 12.7935, Val Loss: 8.2024, F1 Micro: 0.3583, F1 Macro: 0.3425, Accuracy: 0.3583\n","Epoch 95, Train Loss: 8.1635, Val Loss: 6.2990, F1 Micro: 0.3250, F1 Macro: 0.3006, Accuracy: 0.3250\n","Epoch 96, Train Loss: 9.1969, Val Loss: 11.3928, F1 Micro: 0.2000, F1 Macro: 0.1094, Accuracy: 0.2000\n","Epoch 97, Train Loss: 12.9581, Val Loss: 18.9942, F1 Micro: 0.2167, F1 Macro: 0.1660, Accuracy: 0.2167\n","Epoch 98, Train Loss: 14.3841, Val Loss: 11.4944, F1 Micro: 0.2750, F1 Macro: 0.2287, Accuracy: 0.2750\n","Epoch 99, Train Loss: 13.9165, Val Loss: 20.3830, F1 Micro: 0.2917, F1 Macro: 0.2011, Accuracy: 0.2917\n","Epoch 100, Train Loss: 9.8962, Val Loss: 8.1455, F1 Micro: 0.3333, F1 Macro: 0.2661, Accuracy: 0.3333\n","Epoch 101, Train Loss: 7.5326, Val Loss: 8.8551, F1 Micro: 0.2500, F1 Macro: 0.2153, Accuracy: 0.2500\n","Epoch 102, Train Loss: 10.5693, Val Loss: 9.6657, F1 Micro: 0.2667, F1 Macro: 0.1976, Accuracy: 0.2667\n","Epoch 103, Train Loss: 7.3977, Val Loss: 5.0701, F1 Micro: 0.2750, F1 Macro: 0.1940, Accuracy: 0.2750\n","Epoch 104, Train Loss: 5.4977, Val Loss: 5.4346, F1 Micro: 0.2750, F1 Macro: 0.2114, Accuracy: 0.2750\n","Epoch 105, Train Loss: 9.1468, Val Loss: 11.9426, F1 Micro: 0.2500, F1 Macro: 0.2010, Accuracy: 0.2500\n","Epoch 106, Train Loss: 7.9542, Val Loss: 8.0694, F1 Micro: 0.3333, F1 Macro: 0.2802, Accuracy: 0.3333\n","Epoch 107, Train Loss: 5.8704, Val Loss: 7.2018, F1 Micro: 0.2583, F1 Macro: 0.1916, Accuracy: 0.2583\n","Epoch 108, Train Loss: 7.3333, Val Loss: 7.4555, F1 Micro: 0.2417, F1 Macro: 0.1775, Accuracy: 0.2417\n","Epoch 109, Train Loss: 10.1532, Val Loss: 6.9679, F1 Micro: 0.2333, F1 Macro: 0.1790, Accuracy: 0.2333\n","Epoch 110, Train Loss: 7.1720, Val Loss: 11.9674, F1 Micro: 0.3000, F1 Macro: 0.2054, Accuracy: 0.3000\n","Epoch 111, Train Loss: 14.4797, Val Loss: 14.8567, F1 Micro: 0.2167, F1 Macro: 0.1018, Accuracy: 0.2167\n","Epoch 112, Train Loss: 11.3306, Val Loss: 7.0562, F1 Micro: 0.2917, F1 Macro: 0.2335, Accuracy: 0.2917\n","Epoch 113, Train Loss: 8.0726, Val Loss: 10.1103, F1 Micro: 0.2583, F1 Macro: 0.1857, Accuracy: 0.2583\n","Epoch 114, Train Loss: 11.0086, Val Loss: 15.1865, F1 Micro: 0.2000, F1 Macro: 0.1513, Accuracy: 0.2000\n","Epoch 115, Train Loss: 9.7073, Val Loss: 10.7121, F1 Micro: 0.2500, F1 Macro: 0.1686, Accuracy: 0.2500\n","Epoch 116, Train Loss: 11.5421, Val Loss: 5.7655, F1 Micro: 0.3083, F1 Macro: 0.2557, Accuracy: 0.3083\n","Epoch 117, Train Loss: 9.9710, Val Loss: 9.5065, F1 Micro: 0.2167, F1 Macro: 0.1201, Accuracy: 0.2167\n","Epoch 118, Train Loss: 8.7977, Val Loss: 4.1197, F1 Micro: 0.3000, F1 Macro: 0.2666, Accuracy: 0.3000\n","Epoch 119, Train Loss: 5.4557, Val Loss: 4.9825, F1 Micro: 0.3083, F1 Macro: 0.2820, Accuracy: 0.3083\n","Epoch 120, Train Loss: 6.5366, Val Loss: 5.9736, F1 Micro: 0.2500, F1 Macro: 0.2132, Accuracy: 0.2500\n","Epoch 121, Train Loss: 10.7909, Val Loss: 11.6118, F1 Micro: 0.2500, F1 Macro: 0.1342, Accuracy: 0.2500\n","Epoch 122, Train Loss: 9.1326, Val Loss: 7.7131, F1 Micro: 0.2833, F1 Macro: 0.2441, Accuracy: 0.2833\n","Epoch 123, Train Loss: 9.5884, Val Loss: 6.9222, F1 Micro: 0.3167, F1 Macro: 0.2395, Accuracy: 0.3167\n","Epoch 124, Train Loss: 9.8208, Val Loss: 5.0310, F1 Micro: 0.2000, F1 Macro: 0.1452, Accuracy: 0.2000\n","Epoch 125, Train Loss: 5.6501, Val Loss: 7.3280, F1 Micro: 0.2833, F1 Macro: 0.2179, Accuracy: 0.2833\n","Epoch 126, Train Loss: 10.6242, Val Loss: 4.3044, F1 Micro: 0.3250, F1 Macro: 0.2836, Accuracy: 0.3250\n","Epoch 127, Train Loss: 6.4798, Val Loss: 4.1204, F1 Micro: 0.3250, F1 Macro: 0.2850, Accuracy: 0.3250\n","Epoch 128, Train Loss: 6.6505, Val Loss: 3.6154, F1 Micro: 0.2917, F1 Macro: 0.2567, Accuracy: 0.2917\n","Epoch 129, Train Loss: 9.6112, Val Loss: 8.4759, F1 Micro: 0.3083, F1 Macro: 0.2955, Accuracy: 0.3083\n","Epoch 130, Train Loss: 5.5716, Val Loss: 4.9110, F1 Micro: 0.2583, F1 Macro: 0.2155, Accuracy: 0.2583\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.2583, F1 Macro: 0.2155, Accuracy: 0.2583\n"]}]},{"cell_type":"code","source":["print(np.mean(f1_micro_test_list))\n","print(np.mean(f1_macro_test_list))\n","print(np.mean(accuracy_test_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTfar4tfjaQQ","executionInfo":{"status":"ok","timestamp":1711490780706,"user_tz":-60,"elapsed":260,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"34621d60-e7ea-48ba-b18b-cc66c00c795c"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["0.25166666666666665\n","0.18534248801769299\n","0.25166666666666665\n"]}]},{"cell_type":"code","source":["# Initialize a dictionary to store metrics for different models\n","models_evaluation_metrics = {}\n","\n","# Example model identifiers\n","model_names = ['BasicGraphModel', 'GraphSAGEModel', 'GINModel']\n","\n","# Initialize metric dictionaries for each model\n","for model_name in model_names:\n","    models_evaluation_metrics[model_name] = {'f1_micro': [], 'f1_macro': [], 'accuracy': []}\n","\n","def update_model_metrics(model_name, f1_micro, f1_macro, accuracy):\n","    models_evaluation_metrics[model_name]['f1_micro'].append(f1_micro)\n","    models_evaluation_metrics[model_name]['f1_macro'].append(f1_macro)\n","    models_evaluation_metrics[model_name]['accuracy'].append(accuracy)\n","\n","update_model_metrics('BasicGraphModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2noBYul_jext","executionInfo":{"status":"ok","timestamp":1711490784343,"user_tz":-60,"elapsed":246,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"20a6e175-bba7-4544-e2bf-573da9cd8d68"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.3, 0.24166666666666667, 0.18333333333333332, 0.275, 0.25833333333333336]], 'f1_macro': [[0.24020232640922298, 0.12173005938051677, 0.1502883461554861, 0.19894665720752677, 0.2155450509357123]], 'accuracy': [[0.3, 0.24166666666666667, 0.18333333333333332, 0.275, 0.25833333333333336]]}, 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"markdown","source":["# Do the same thing to the dataset REDDIT-BINARY"],"metadata":{"id":"zOcHO28oklD_"}},{"cell_type":"code","source":["# The dataset Reddit-Binary has no node_features, so we use node_degree as its feature\n","import torch\n","from torch_geometric.datasets import TUDataset\n","from torch_geometric.transforms import BaseTransform\n","from torch_geometric.utils import degree\n","\n","class AddDegreeFeature(BaseTransform):\n","    def __call__(self, data):\n","        deg = degree(data.edge_index[0], dtype=torch.float)\n","        data.x = deg.unsqueeze(-1)  # Make it a 2D tensor [num_nodes, 1]\n","        return data\n","\n","# Load your dataset and apply the transformation\n","dataset_rd = TUDataset(root='/tmp/REDDIT-BINARY', name='REDDIT-BINARY', transform=AddDegreeFeature())\n","\n","# Now verify by printing the features of the first few graphs\n","for i, data in enumerate(dataset_rd):\n","    if i >= 5:  # Check the first 5 graphs\n","        break\n","    print(data.x)"],"metadata":{"id":"CDmrbk2qkid0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Subset\n","\n","# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_rd)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_subset = Subset(dataset_rd, train_val_idx)\n","    test_subset = Subset(dataset_rd, test_idx)\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_subset = Subset(train_val_subset, inner_train_idx)\n","            inner_val_subset = Subset(train_val_subset, inner_val_idx)\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_subset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_subset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = MLP1(\n","                input_size=1,\n","                hidden_size=256,\n","                output_size=dataset_rd.num_classes\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_subset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_subset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = MLP1(\n","        input_size=1,\n","        hidden_size=256,\n","        output_size=dataset_rd.num_classes\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'rd_Basic_model_fold_{fold}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSYeWCBpk3pJ","executionInfo":{"status":"ok","timestamp":1711496314607,"user_tz":-60,"elapsed":2853126,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"06ef4454-2d95-4065-c855-655b6c449cc9"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 28, Train Loss: 38.3186, Val Loss: 48.7488, F1 Micro: 0.2083, F1 Macro: 0.1724, Accuracy: 0.2083\n","Epoch 29, Train Loss: 17.0715, Val Loss: 10.5695, F1 Micro: 0.3125, F1 Macro: 0.3050, Accuracy: 0.3125\n","Epoch 30, Train Loss: 26.4205, Val Loss: 8.3602, F1 Micro: 0.7708, F1 Macro: 0.5107, Accuracy: 0.7708\n","Epoch 31, Train Loss: 40.2417, Val Loss: 8.9798, F1 Micro: 0.4167, F1 Macro: 0.4167, Accuracy: 0.4167\n","Epoch 32, Train Loss: 31.3814, Val Loss: 5.7499, F1 Micro: 0.6146, F1 Macro: 0.5697, Accuracy: 0.6146\n","Epoch 33, Train Loss: 21.5324, Val Loss: 8.5518, F1 Micro: 0.4792, F1 Macro: 0.4771, Accuracy: 0.4792\n","Epoch 34, Train Loss: 19.7031, Val Loss: 38.1296, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 35, Train Loss: 14.9647, Val Loss: 12.2819, F1 Micro: 0.7812, F1 Macro: 0.5171, Accuracy: 0.7812\n","Epoch 36, Train Loss: 21.8412, Val Loss: 26.8941, F1 Micro: 0.2188, F1 Macro: 0.1869, Accuracy: 0.2188\n","Epoch 37, Train Loss: 14.7944, Val Loss: 12.9780, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 38, Train Loss: 12.3475, Val Loss: 21.5861, F1 Micro: 0.2083, F1 Macro: 0.1724, Accuracy: 0.2083\n","Epoch 39, Train Loss: 21.6729, Val Loss: 60.5954, F1 Micro: 0.2083, F1 Macro: 0.1724, Accuracy: 0.2083\n","Epoch 40, Train Loss: 30.8331, Val Loss: 11.2487, F1 Micro: 0.7396, F1 Macro: 0.4923, Accuracy: 0.7396\n","Epoch 41, Train Loss: 12.1667, Val Loss: 26.2695, F1 Micro: 0.2083, F1 Macro: 0.1724, Accuracy: 0.2083\n","Epoch 42, Train Loss: 32.1404, Val Loss: 5.4020, F1 Micro: 0.5521, F1 Macro: 0.5248, Accuracy: 0.5521\n","Epoch 43, Train Loss: 13.4964, Val Loss: 7.4010, F1 Micro: 0.4792, F1 Macro: 0.4735, Accuracy: 0.4792\n","Epoch 44, Train Loss: 19.4653, Val Loss: 15.4674, F1 Micro: 0.2917, F1 Macro: 0.2804, Accuracy: 0.2917\n","Epoch 45, Train Loss: 22.7174, Val Loss: 48.2221, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 46, Train Loss: 27.6757, Val Loss: 5.2967, F1 Micro: 0.6667, F1 Macro: 0.6047, Accuracy: 0.6667\n","Epoch 47, Train Loss: 13.4299, Val Loss: 9.5158, F1 Micro: 0.4167, F1 Macro: 0.4167, Accuracy: 0.4167\n","Epoch 48, Train Loss: 17.0779, Val Loss: 12.9839, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 49, Train Loss: 14.6670, Val Loss: 8.2891, F1 Micro: 0.4062, F1 Macro: 0.4062, Accuracy: 0.4062\n","Epoch 50, Train Loss: 13.7619, Val Loss: 18.1585, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 51, Train Loss: 28.4699, Val Loss: 16.6680, F1 Micro: 0.2604, F1 Macro: 0.2419, Accuracy: 0.2604\n","Epoch 52, Train Loss: 26.4072, Val Loss: 4.7982, F1 Micro: 0.6042, F1 Macro: 0.5674, Accuracy: 0.6042\n","Epoch 53, Train Loss: 46.7865, Val Loss: 107.4690, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 41.7413, Val Loss: 18.0520, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 16.5111, Val Loss: 36.6268, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 16.6184, Val Loss: 7.9357, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 4, Train Loss: 13.7418, Val Loss: 15.8609, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 35.5921, Val Loss: 15.0322, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 29.3849, Val Loss: 71.8014, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 7, Train Loss: 37.8481, Val Loss: 17.0679, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 8, Train Loss: 11.0547, Val Loss: 19.2745, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 9, Train Loss: 11.0028, Val Loss: 8.7460, F1 Micro: 0.2604, F1 Macro: 0.2603, Accuracy: 0.2604\n","Epoch 10, Train Loss: 13.4547, Val Loss: 5.1505, F1 Micro: 0.3542, F1 Macro: 0.3471, Accuracy: 0.3542\n","Epoch 11, Train Loss: 16.3456, Val Loss: 3.1182, F1 Micro: 0.7083, F1 Macro: 0.5214, Accuracy: 0.7083\n","Epoch 12, Train Loss: 19.0204, Val Loss: 4.8772, F1 Micro: 0.4167, F1 Macro: 0.4000, Accuracy: 0.4167\n","Epoch 13, Train Loss: 26.3207, Val Loss: 14.5904, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 14, Train Loss: 28.7693, Val Loss: 28.9963, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 15, Train Loss: 23.1321, Val Loss: 12.1852, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 16, Train Loss: 30.0933, Val Loss: 43.8614, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 17, Train Loss: 64.6289, Val Loss: 41.2130, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 18, Train Loss: 40.1774, Val Loss: 22.4791, F1 Micro: 0.1979, F1 Macro: 0.1908, Accuracy: 0.1979\n","Epoch 19, Train Loss: 19.0578, Val Loss: 17.2457, F1 Micro: 0.2500, F1 Macro: 0.2497, Accuracy: 0.2500\n","Epoch 20, Train Loss: 11.9176, Val Loss: 4.2928, F1 Micro: 0.6458, F1 Macro: 0.4988, Accuracy: 0.6458\n","Epoch 21, Train Loss: 25.8272, Val Loss: 79.6978, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 22, Train Loss: 33.1113, Val Loss: 7.1673, F1 Micro: 0.3750, F1 Macro: 0.3651, Accuracy: 0.3750\n","Epoch 23, Train Loss: 9.9181, Val Loss: 12.6925, F1 Micro: 0.2604, F1 Macro: 0.2603, Accuracy: 0.2604\n","Epoch 24, Train Loss: 12.3890, Val Loss: 10.0586, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 25, Train Loss: 30.2936, Val Loss: 35.0048, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 26, Train Loss: 19.2624, Val Loss: 9.6715, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 27, Train Loss: 10.8555, Val Loss: 18.5607, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 28, Train Loss: 21.7029, Val Loss: 11.6200, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 29, Train Loss: 16.7093, Val Loss: 5.1146, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 30, Train Loss: 11.1262, Val Loss: 3.9227, F1 Micro: 0.8229, F1 Macro: 0.6091, Accuracy: 0.8229\n","Epoch 31, Train Loss: 30.5034, Val Loss: 39.8129, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 32, Train Loss: 31.1173, Val Loss: 54.7681, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 33, Train Loss: 54.6878, Val Loss: 6.9227, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 34, Train Loss: 48.4921, Val Loss: 5.0288, F1 Micro: 0.8021, F1 Macro: 0.5906, Accuracy: 0.8021\n","Epoch 35, Train Loss: 55.2070, Val Loss: 58.8469, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 36, Train Loss: 41.5294, Val Loss: 4.5728, F1 Micro: 0.5833, F1 Macro: 0.4847, Accuracy: 0.5833\n","Epoch 37, Train Loss: 11.1843, Val Loss: 35.9431, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 38, Train Loss: 37.3635, Val Loss: 12.2721, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 39, Train Loss: 15.7447, Val Loss: 10.0163, F1 Micro: 0.3125, F1 Macro: 0.3098, Accuracy: 0.3125\n","Epoch 40, Train Loss: 15.7891, Val Loss: 14.6231, F1 Micro: 0.2604, F1 Macro: 0.2603, Accuracy: 0.2604\n","Epoch 41, Train Loss: 15.4207, Val Loss: 12.6349, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 42, Train Loss: 17.7605, Val Loss: 37.0130, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 43, Train Loss: 33.1089, Val Loss: 4.6141, F1 Micro: 0.4688, F1 Macro: 0.4364, Accuracy: 0.4688\n","Epoch 44, Train Loss: 10.1468, Val Loss: 11.9570, F1 Micro: 0.2500, F1 Macro: 0.2487, Accuracy: 0.2500\n","Epoch 45, Train Loss: 8.7082, Val Loss: 14.9782, F1 Micro: 0.1979, F1 Macro: 0.1908, Accuracy: 0.1979\n","Epoch 46, Train Loss: 13.9071, Val Loss: 23.5360, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 47, Train Loss: 34.7230, Val Loss: 23.8811, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 48, Train Loss: 18.5577, Val Loss: 68.1462, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 49, Train Loss: 29.4204, Val Loss: 4.8528, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 50, Train Loss: 22.0132, Val Loss: 79.5887, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 51, Train Loss: 58.9038, Val Loss: 3.5573, F1 Micro: 0.5938, F1 Macro: 0.5031, Accuracy: 0.5938\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 83.5779, Val Loss: 45.5241, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 23.8046, Val Loss: 16.6260, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 33.6349, Val Loss: 45.1914, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 4, Train Loss: 37.1966, Val Loss: 24.4033, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 5, Train Loss: 21.3079, Val Loss: 20.0287, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 6, Train Loss: 16.5854, Val Loss: 7.5084, F1 Micro: 0.2604, F1 Macro: 0.2506, Accuracy: 0.2604\n","Epoch 7, Train Loss: 19.8029, Val Loss: 26.3594, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 36.7385, Val Loss: 44.5860, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 9, Train Loss: 28.5839, Val Loss: 22.5866, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 30.8216, Val Loss: 24.0166, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 12.1943, Val Loss: 3.8847, F1 Micro: 0.5208, F1 Macro: 0.4690, Accuracy: 0.5208\n","Epoch 12, Train Loss: 9.4068, Val Loss: 28.1950, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 28.8628, Val Loss: 36.2564, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 14, Train Loss: 31.6196, Val Loss: 29.1001, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 15, Train Loss: 17.8804, Val Loss: 31.5459, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 16, Train Loss: 20.9202, Val Loss: 23.9170, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 17, Train Loss: 20.2324, Val Loss: 27.0596, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 18, Train Loss: 53.0668, Val Loss: 19.0164, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 19, Train Loss: 27.8727, Val Loss: 14.7970, F1 Micro: 0.2708, F1 Macro: 0.2628, Accuracy: 0.2708\n","Epoch 20, Train Loss: 18.1087, Val Loss: 46.6154, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 21, Train Loss: 26.4887, Val Loss: 5.1078, F1 Micro: 0.5729, F1 Macro: 0.4984, Accuracy: 0.5729\n","Epoch 22, Train Loss: 21.9618, Val Loss: 4.6791, F1 Micro: 0.6042, F1 Macro: 0.5210, Accuracy: 0.6042\n","Epoch 23, Train Loss: 7.3282, Val Loss: 3.6492, F1 Micro: 0.6562, F1 Macro: 0.5479, Accuracy: 0.6562\n","Epoch 24, Train Loss: 18.5925, Val Loss: 37.0329, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 25, Train Loss: 50.8926, Val Loss: 34.8587, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 26, Train Loss: 55.1097, Val Loss: 9.4038, F1 Micro: 0.6979, F1 Macro: 0.4422, Accuracy: 0.6979\n","Epoch 27, Train Loss: 19.9999, Val Loss: 12.4234, F1 Micro: 0.7500, F1 Macro: 0.4286, Accuracy: 0.7500\n","Epoch 28, Train Loss: 12.4206, Val Loss: 4.6038, F1 Micro: 0.6562, F1 Macro: 0.5479, Accuracy: 0.6562\n","Epoch 29, Train Loss: 10.6760, Val Loss: 3.5544, F1 Micro: 0.6667, F1 Macro: 0.5673, Accuracy: 0.6667\n","Epoch 30, Train Loss: 21.1849, Val Loss: 40.7119, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 31, Train Loss: 37.9797, Val Loss: 23.3208, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 32, Train Loss: 31.3553, Val Loss: 18.0076, F1 Micro: 0.2188, F1 Macro: 0.1992, Accuracy: 0.2188\n","Epoch 33, Train Loss: 24.3258, Val Loss: 47.6244, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 34, Train Loss: 32.1016, Val Loss: 45.4542, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 35, Train Loss: 20.6583, Val Loss: 5.2891, F1 Micro: 0.6458, F1 Macro: 0.5516, Accuracy: 0.6458\n","Epoch 36, Train Loss: 19.6303, Val Loss: 13.5514, F1 Micro: 0.7604, F1 Macro: 0.4320, Accuracy: 0.7604\n","Epoch 37, Train Loss: 10.6899, Val Loss: 4.0067, F1 Micro: 0.5000, F1 Macro: 0.4604, Accuracy: 0.5000\n","Epoch 38, Train Loss: 7.4396, Val Loss: 2.7606, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Epoch 39, Train Loss: 9.8350, Val Loss: 12.4937, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 40, Train Loss: 9.6668, Val Loss: 2.1633, F1 Micro: 0.7083, F1 Macro: 0.5579, Accuracy: 0.7083\n","Epoch 41, Train Loss: 19.7961, Val Loss: 10.0068, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 42, Train Loss: 20.1138, Val Loss: 3.5676, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 43, Train Loss: 15.4670, Val Loss: 5.8523, F1 Micro: 0.3542, F1 Macro: 0.3542, Accuracy: 0.3542\n","Epoch 44, Train Loss: 34.6376, Val Loss: 75.3394, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 45, Train Loss: 57.3544, Val Loss: 69.5412, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 46, Train Loss: 20.8929, Val Loss: 5.0640, F1 Micro: 0.7083, F1 Macro: 0.5733, Accuracy: 0.7083\n","Epoch 47, Train Loss: 27.6579, Val Loss: 78.0057, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 48, Train Loss: 49.9119, Val Loss: 53.7219, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 49, Train Loss: 23.1502, Val Loss: 10.6114, F1 Micro: 0.3333, F1 Macro: 0.3330, Accuracy: 0.3333\n","Epoch 50, Train Loss: 11.8312, Val Loss: 9.2728, F1 Micro: 0.3333, F1 Macro: 0.3330, Accuracy: 0.3333\n","Epoch 51, Train Loss: 26.9886, Val Loss: 11.8153, F1 Micro: 0.2604, F1 Macro: 0.2506, Accuracy: 0.2604\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 82.1775, Val Loss: 14.0296, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 2, Train Loss: 34.9821, Val Loss: 79.2806, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 3, Train Loss: 28.4121, Val Loss: 7.6752, F1 Micro: 0.3229, F1 Macro: 0.3228, Accuracy: 0.3229\n","Epoch 4, Train Loss: 22.1326, Val Loss: 25.9574, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 5, Train Loss: 15.0537, Val Loss: 9.0541, F1 Micro: 0.7708, F1 Macro: 0.5875, Accuracy: 0.7708\n","Epoch 6, Train Loss: 10.4997, Val Loss: 22.2294, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 7, Train Loss: 23.6253, Val Loss: 43.9522, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 8, Train Loss: 10.9324, Val Loss: 5.6817, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 9, Train Loss: 9.5631, Val Loss: 11.7247, F1 Micro: 0.2188, F1 Macro: 0.2084, Accuracy: 0.2188\n","Epoch 10, Train Loss: 12.8001, Val Loss: 8.0232, F1 Micro: 0.3125, F1 Macro: 0.3122, Accuracy: 0.3125\n","Epoch 11, Train Loss: 23.3352, Val Loss: 16.4216, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 40.5858, Val Loss: 45.7596, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 13, Train Loss: 45.3825, Val Loss: 9.0073, F1 Micro: 0.6458, F1 Macro: 0.5278, Accuracy: 0.6458\n","Epoch 14, Train Loss: 26.5649, Val Loss: 18.2352, F1 Micro: 0.2812, F1 Macro: 0.2793, Accuracy: 0.2812\n","Epoch 15, Train Loss: 14.6641, Val Loss: 21.9836, F1 Micro: 0.7604, F1 Macro: 0.4711, Accuracy: 0.7604\n","Epoch 16, Train Loss: 35.4491, Val Loss: 9.5415, F1 Micro: 0.5938, F1 Macro: 0.4918, Accuracy: 0.5938\n","Epoch 17, Train Loss: 12.0450, Val Loss: 9.0292, F1 Micro: 0.4375, F1 Macro: 0.4170, Accuracy: 0.4375\n","Epoch 18, Train Loss: 12.7765, Val Loss: 11.7342, F1 Micro: 0.7812, F1 Macro: 0.5961, Accuracy: 0.7812\n","Epoch 19, Train Loss: 14.1754, Val Loss: 27.9784, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 20, Train Loss: 17.0689, Val Loss: 13.7124, F1 Micro: 0.7604, F1 Macro: 0.4711, Accuracy: 0.7604\n","Epoch 21, Train Loss: 10.6782, Val Loss: 38.0856, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 22, Train Loss: 17.1333, Val Loss: 38.5848, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 23, Train Loss: 81.0269, Val Loss: 131.8123, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 24, Train Loss: 45.4810, Val Loss: 17.5869, F1 Micro: 0.3021, F1 Macro: 0.3014, Accuracy: 0.3021\n","Epoch 25, Train Loss: 26.6077, Val Loss: 57.4837, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 26, Train Loss: 25.3039, Val Loss: 34.7431, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 27, Train Loss: 17.2644, Val Loss: 23.7197, F1 Micro: 0.7604, F1 Macro: 0.4711, Accuracy: 0.7604\n","Epoch 28, Train Loss: 21.9747, Val Loss: 48.6966, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 29, Train Loss: 31.5297, Val Loss: 42.2856, F1 Micro: 0.1667, F1 Macro: 0.1429, Accuracy: 0.1667\n","Epoch 30, Train Loss: 18.1530, Val Loss: 21.7267, F1 Micro: 0.7604, F1 Macro: 0.4711, Accuracy: 0.7604\n","Epoch 31, Train Loss: 15.2818, Val Loss: 21.4351, F1 Micro: 0.2604, F1 Macro: 0.2565, Accuracy: 0.2604\n","Epoch 32, Train Loss: 11.6470, Val Loss: 13.7198, F1 Micro: 0.7812, F1 Macro: 0.5961, Accuracy: 0.7812\n","Epoch 33, Train Loss: 9.4911, Val Loss: 7.1005, F1 Micro: 0.4479, F1 Macro: 0.4254, Accuracy: 0.4479\n","Epoch 34, Train Loss: 9.4448, Val Loss: 5.7640, F1 Micro: 0.4479, F1 Macro: 0.4376, Accuracy: 0.4479\n","Epoch 35, Train Loss: 10.4046, Val Loss: 17.9813, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 36, Train Loss: 16.9873, Val Loss: 47.7436, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 37, Train Loss: 14.5723, Val Loss: 22.2350, F1 Micro: 0.1667, F1 Macro: 0.1429, Accuracy: 0.1667\n","Epoch 38, Train Loss: 28.4070, Val Loss: 18.8053, F1 Micro: 0.2083, F1 Macro: 0.1958, Accuracy: 0.2083\n","Epoch 39, Train Loss: 15.7853, Val Loss: 10.3573, F1 Micro: 0.7188, F1 Macro: 0.5480, Accuracy: 0.7188\n","Epoch 40, Train Loss: 9.5529, Val Loss: 7.1200, F1 Micro: 0.6250, F1 Macro: 0.5132, Accuracy: 0.6250\n","Epoch 41, Train Loss: 10.5411, Val Loss: 20.2057, F1 Micro: 0.1667, F1 Macro: 0.1429, Accuracy: 0.1667\n","Epoch 42, Train Loss: 18.9565, Val Loss: 19.0024, F1 Micro: 0.1979, F1 Macro: 0.1829, Accuracy: 0.1979\n","Epoch 43, Train Loss: 30.1315, Val Loss: 29.7263, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 44, Train Loss: 18.5058, Val Loss: 7.3958, F1 Micro: 0.5312, F1 Macro: 0.4684, Accuracy: 0.5312\n","Epoch 45, Train Loss: 18.3241, Val Loss: 15.0205, F1 Micro: 0.7604, F1 Macro: 0.5044, Accuracy: 0.7604\n","Epoch 46, Train Loss: 13.3933, Val Loss: 20.5783, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 47, Train Loss: 26.9890, Val Loss: 30.1197, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 48, Train Loss: 38.9001, Val Loss: 61.8031, F1 Micro: 0.1771, F1 Macro: 0.1504, Accuracy: 0.1771\n","Epoch 49, Train Loss: 43.7359, Val Loss: 107.9137, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 50, Train Loss: 44.2485, Val Loss: 12.9844, F1 Micro: 0.4375, F1 Macro: 0.4214, Accuracy: 0.4375\n","Epoch 51, Train Loss: 13.4883, Val Loss: 13.7694, F1 Micro: 0.7500, F1 Macro: 0.5711, Accuracy: 0.7500\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.8083333333333333\n","Best hyperparameters for Outer FOLD 2: (0.01, 16, 50) with score 0.9395833333333332\n","Epoch 1, Train Loss: 258.5561, Val Loss: 78.7231, F1 Micro: 0.4800, F1 Macro: 0.3243, Accuracy: 0.4800\n","Epoch 2, Train Loss: 61.7077, Val Loss: 41.0775, F1 Micro: 0.4775, F1 Macro: 0.3640, Accuracy: 0.4775\n","Epoch 3, Train Loss: 29.7675, Val Loss: 227.7280, F1 Micro: 0.4800, F1 Macro: 0.3243, Accuracy: 0.4800\n","Epoch 4, Train Loss: 45.2321, Val Loss: 138.9530, F1 Micro: 0.4800, F1 Macro: 0.3243, Accuracy: 0.4800\n","Epoch 5, Train Loss: 40.9198, Val Loss: 25.0367, F1 Micro: 0.5200, F1 Macro: 0.3421, Accuracy: 0.5200\n","Epoch 6, Train Loss: 20.2704, Val Loss: 48.8074, F1 Micro: 0.4900, F1 Macro: 0.3454, Accuracy: 0.4900\n","Epoch 7, Train Loss: 22.5679, Val Loss: 15.5985, F1 Micro: 0.6525, F1 Macro: 0.6188, Accuracy: 0.6525\n","Epoch 8, Train Loss: 20.5743, Val Loss: 9.9031, F1 Micro: 0.6525, F1 Macro: 0.6268, Accuracy: 0.6525\n","Epoch 9, Train Loss: 12.5278, Val Loss: 7.1479, F1 Micro: 0.5275, F1 Macro: 0.3592, Accuracy: 0.5275\n","Epoch 10, Train Loss: 12.0693, Val Loss: 44.1388, F1 Micro: 0.5650, F1 Macro: 0.4846, Accuracy: 0.5650\n","Epoch 11, Train Loss: 10.7983, Val Loss: 38.3148, F1 Micro: 0.5100, F1 Macro: 0.3988, Accuracy: 0.5100\n","Epoch 12, Train Loss: 20.5191, Val Loss: 3.9269, F1 Micro: 0.7100, F1 Macro: 0.7050, Accuracy: 0.7100\n","Epoch 13, Train Loss: 6.4578, Val Loss: 9.4811, F1 Micro: 0.6050, F1 Macro: 0.5918, Accuracy: 0.6050\n","Epoch 14, Train Loss: 3.5532, Val Loss: 8.6097, F1 Micro: 0.6725, F1 Macro: 0.6562, Accuracy: 0.6725\n","Epoch 15, Train Loss: 4.3068, Val Loss: 2.5029, F1 Micro: 0.7350, F1 Macro: 0.7335, Accuracy: 0.7350\n","Epoch 16, Train Loss: 2.6421, Val Loss: 5.3436, F1 Micro: 0.7150, F1 Macro: 0.7108, Accuracy: 0.7150\n","Epoch 17, Train Loss: 2.4786, Val Loss: 4.8572, F1 Micro: 0.6925, F1 Macro: 0.6836, Accuracy: 0.6925\n","Epoch 18, Train Loss: 3.9103, Val Loss: 6.9802, F1 Micro: 0.6700, F1 Macro: 0.6540, Accuracy: 0.6700\n","Epoch 19, Train Loss: 6.4596, Val Loss: 4.2802, F1 Micro: 0.5200, F1 Macro: 0.3421, Accuracy: 0.5200\n","Epoch 20, Train Loss: 4.8066, Val Loss: 12.0731, F1 Micro: 0.5800, F1 Macro: 0.5470, Accuracy: 0.5800\n","Epoch 21, Train Loss: 5.0581, Val Loss: 3.4268, F1 Micro: 0.7050, F1 Macro: 0.7041, Accuracy: 0.7050\n","Epoch 22, Train Loss: 2.7969, Val Loss: 3.8515, F1 Micro: 0.5600, F1 Macro: 0.5461, Accuracy: 0.5600\n","Epoch 23, Train Loss: 1.9317, Val Loss: 4.6519, F1 Micro: 0.6875, F1 Macro: 0.6779, Accuracy: 0.6875\n","Epoch 24, Train Loss: 2.0630, Val Loss: 1.7315, F1 Micro: 0.7425, F1 Macro: 0.7413, Accuracy: 0.7425\n","Epoch 25, Train Loss: 1.9862, Val Loss: 1.4225, F1 Micro: 0.7250, F1 Macro: 0.7250, Accuracy: 0.7250\n","Epoch 26, Train Loss: 2.0594, Val Loss: 2.1073, F1 Micro: 0.5925, F1 Macro: 0.5828, Accuracy: 0.5925\n","Epoch 27, Train Loss: 1.5651, Val Loss: 1.9283, F1 Micro: 0.6950, F1 Macro: 0.6947, Accuracy: 0.6950\n","Epoch 28, Train Loss: 2.0428, Val Loss: 1.5274, F1 Micro: 0.7200, F1 Macro: 0.7162, Accuracy: 0.7200\n","Epoch 29, Train Loss: 1.2516, Val Loss: 1.3043, F1 Micro: 0.5975, F1 Macro: 0.5859, Accuracy: 0.5975\n","Epoch 30, Train Loss: 1.1980, Val Loss: 1.3113, F1 Micro: 0.7050, F1 Macro: 0.7033, Accuracy: 0.7050\n","Epoch 31, Train Loss: 1.1748, Val Loss: 1.1172, F1 Micro: 0.7150, F1 Macro: 0.7097, Accuracy: 0.7150\n","Epoch 32, Train Loss: 1.9812, Val Loss: 8.2515, F1 Micro: 0.6375, F1 Macro: 0.5844, Accuracy: 0.6375\n","Epoch 33, Train Loss: 11.5859, Val Loss: 7.7809, F1 Micro: 0.5275, F1 Macro: 0.4980, Accuracy: 0.5275\n","Epoch 34, Train Loss: 2.4746, Val Loss: 1.9920, F1 Micro: 0.7050, F1 Macro: 0.6987, Accuracy: 0.7050\n","Epoch 35, Train Loss: 2.7331, Val Loss: 3.1358, F1 Micro: 0.7125, F1 Macro: 0.7097, Accuracy: 0.7125\n","Epoch 36, Train Loss: 2.1330, Val Loss: 3.5247, F1 Micro: 0.6775, F1 Macro: 0.6769, Accuracy: 0.6775\n","Epoch 37, Train Loss: 1.2995, Val Loss: 0.9071, F1 Micro: 0.5650, F1 Macro: 0.5384, Accuracy: 0.5650\n","Epoch 38, Train Loss: 1.6754, Val Loss: 3.4665, F1 Micro: 0.6925, F1 Macro: 0.6892, Accuracy: 0.6925\n","Epoch 39, Train Loss: 1.2057, Val Loss: 0.9120, F1 Micro: 0.6475, F1 Macro: 0.6459, Accuracy: 0.6475\n","Epoch 40, Train Loss: 1.2921, Val Loss: 4.6717, F1 Micro: 0.6850, F1 Macro: 0.6762, Accuracy: 0.6850\n","Epoch 41, Train Loss: 4.7471, Val Loss: 1.5140, F1 Micro: 0.7300, F1 Macro: 0.7135, Accuracy: 0.7300\n","Epoch 42, Train Loss: 1.5656, Val Loss: 1.2348, F1 Micro: 0.6075, F1 Macro: 0.6054, Accuracy: 0.6075\n","Epoch 43, Train Loss: 0.9825, Val Loss: 7.0991, F1 Micro: 0.6075, F1 Macro: 0.6051, Accuracy: 0.6075\n","Epoch 44, Train Loss: 7.5358, Val Loss: 2.5460, F1 Micro: 0.5200, F1 Macro: 0.3421, Accuracy: 0.5200\n","Epoch 45, Train Loss: 1.6879, Val Loss: 1.0288, F1 Micro: 0.7025, F1 Macro: 0.7021, Accuracy: 0.7025\n","Epoch 46, Train Loss: 0.9131, Val Loss: 1.9192, F1 Micro: 0.6725, F1 Macro: 0.6723, Accuracy: 0.6725\n","Epoch 47, Train Loss: 1.2886, Val Loss: 0.9574, F1 Micro: 0.7075, F1 Macro: 0.7057, Accuracy: 0.7075\n","Epoch 48, Train Loss: 3.0167, Val Loss: 2.9628, F1 Micro: 0.6750, F1 Macro: 0.6592, Accuracy: 0.6750\n","Epoch 49, Train Loss: 2.0993, Val Loss: 1.8851, F1 Micro: 0.7175, F1 Macro: 0.6991, Accuracy: 0.7175\n","Epoch 50, Train Loss: 2.3301, Val Loss: 1.0990, F1 Micro: 0.7050, F1 Macro: 0.7045, Accuracy: 0.7050\n","Epoch 51, Train Loss: 1.5499, Val Loss: 0.9558, F1 Micro: 0.7100, F1 Macro: 0.7099, Accuracy: 0.7100\n","Epoch 52, Train Loss: 0.9999, Val Loss: 0.8451, F1 Micro: 0.7150, F1 Macro: 0.7101, Accuracy: 0.7150\n","Epoch 53, Train Loss: 1.0107, Val Loss: 0.8039, F1 Micro: 0.6600, F1 Macro: 0.6225, Accuracy: 0.6600\n","Epoch 54, Train Loss: 3.3760, Val Loss: 6.2147, F1 Micro: 0.5075, F1 Macro: 0.4561, Accuracy: 0.5075\n","Epoch 55, Train Loss: 2.3329, Val Loss: 1.0556, F1 Micro: 0.7275, F1 Macro: 0.7264, Accuracy: 0.7275\n","Epoch 56, Train Loss: 0.7839, Val Loss: 0.8986, F1 Micro: 0.7400, F1 Macro: 0.7391, Accuracy: 0.7400\n","Epoch 57, Train Loss: 1.4362, Val Loss: 1.3822, F1 Micro: 0.7050, F1 Macro: 0.7003, Accuracy: 0.7050\n","Epoch 58, Train Loss: 2.2757, Val Loss: 8.1245, F1 Micro: 0.4650, F1 Macro: 0.3801, Accuracy: 0.4650\n","Epoch 59, Train Loss: 5.0805, Val Loss: 5.8428, F1 Micro: 0.6225, F1 Macro: 0.5872, Accuracy: 0.6225\n","Epoch 60, Train Loss: 4.3236, Val Loss: 0.9868, F1 Micro: 0.6050, F1 Macro: 0.5462, Accuracy: 0.6050\n","Epoch 61, Train Loss: 0.9056, Val Loss: 1.0219, F1 Micro: 0.7150, F1 Macro: 0.7118, Accuracy: 0.7150\n","Epoch 62, Train Loss: 2.1809, Val Loss: 0.9249, F1 Micro: 0.7000, F1 Macro: 0.6995, Accuracy: 0.7000\n","Epoch 63, Train Loss: 1.4459, Val Loss: 1.8447, F1 Micro: 0.5900, F1 Macro: 0.5895, Accuracy: 0.5900\n","Epoch 64, Train Loss: 0.9700, Val Loss: 1.8479, F1 Micro: 0.6800, F1 Macro: 0.6800, Accuracy: 0.6800\n","Epoch 65, Train Loss: 0.8746, Val Loss: 0.9825, F1 Micro: 0.5575, F1 Macro: 0.5261, Accuracy: 0.5575\n","Epoch 66, Train Loss: 2.9135, Val Loss: 2.9690, F1 Micro: 0.6375, F1 Macro: 0.6212, Accuracy: 0.6375\n","Epoch 67, Train Loss: 4.7471, Val Loss: 7.2202, F1 Micro: 0.6325, F1 Macro: 0.5955, Accuracy: 0.6325\n","Epoch 68, Train Loss: 8.9936, Val Loss: 10.2558, F1 Micro: 0.5200, F1 Macro: 0.3421, Accuracy: 0.5200\n","Epoch 69, Train Loss: 3.5932, Val Loss: 2.8372, F1 Micro: 0.6925, F1 Macro: 0.6836, Accuracy: 0.6925\n","Epoch 70, Train Loss: 1.4934, Val Loss: 1.1551, F1 Micro: 0.7450, F1 Macro: 0.7444, Accuracy: 0.7450\n","Epoch 71, Train Loss: 0.9904, Val Loss: 1.0662, F1 Micro: 0.7175, F1 Macro: 0.7116, Accuracy: 0.7175\n","Epoch 72, Train Loss: 1.0434, Val Loss: 1.2010, F1 Micro: 0.7075, F1 Macro: 0.7065, Accuracy: 0.7075\n","Epoch 73, Train Loss: 0.7885, Val Loss: 1.2136, F1 Micro: 0.6700, F1 Macro: 0.6673, Accuracy: 0.6700\n","Epoch 74, Train Loss: 0.8027, Val Loss: 0.9683, F1 Micro: 0.7200, F1 Macro: 0.6989, Accuracy: 0.7200\n","Epoch 75, Train Loss: 0.6851, Val Loss: 0.7614, F1 Micro: 0.7400, F1 Macro: 0.7391, Accuracy: 0.7400\n","Epoch 76, Train Loss: 0.8197, Val Loss: 1.0572, F1 Micro: 0.6900, F1 Macro: 0.6546, Accuracy: 0.6900\n","Epoch 77, Train Loss: 0.7674, Val Loss: 0.7182, F1 Micro: 0.7075, F1 Macro: 0.7057, Accuracy: 0.7075\n","Epoch 78, Train Loss: 0.7802, Val Loss: 0.7338, F1 Micro: 0.7000, F1 Macro: 0.6999, Accuracy: 0.7000\n","Epoch 79, Train Loss: 1.0432, Val Loss: 1.2383, F1 Micro: 0.6725, F1 Macro: 0.6652, Accuracy: 0.6725\n","Epoch 80, Train Loss: 2.5962, Val Loss: 1.0693, F1 Micro: 0.5525, F1 Macro: 0.5245, Accuracy: 0.5525\n","Epoch 81, Train Loss: 13.9548, Val Loss: 5.5008, F1 Micro: 0.5675, F1 Macro: 0.5393, Accuracy: 0.5675\n","Epoch 82, Train Loss: 2.1757, Val Loss: 1.1347, F1 Micro: 0.7025, F1 Macro: 0.7021, Accuracy: 0.7025\n","Epoch 83, Train Loss: 0.7862, Val Loss: 0.8449, F1 Micro: 0.5925, F1 Macro: 0.5742, Accuracy: 0.5925\n","Epoch 84, Train Loss: 0.7725, Val Loss: 0.9483, F1 Micro: 0.6975, F1 Macro: 0.6975, Accuracy: 0.6975\n","Epoch 85, Train Loss: 0.7403, Val Loss: 1.4672, F1 Micro: 0.7100, F1 Macro: 0.6834, Accuracy: 0.7100\n","Epoch 86, Train Loss: 1.1469, Val Loss: 2.3628, F1 Micro: 0.6425, F1 Macro: 0.6264, Accuracy: 0.6425\n","Epoch 87, Train Loss: 0.7275, Val Loss: 0.7165, F1 Micro: 0.6675, F1 Macro: 0.6664, Accuracy: 0.6675\n","Epoch 88, Train Loss: 0.6961, Val Loss: 1.1604, F1 Micro: 0.7175, F1 Macro: 0.7116, Accuracy: 0.7175\n","Epoch 89, Train Loss: 1.7485, Val Loss: 1.6071, F1 Micro: 0.6625, F1 Macro: 0.6509, Accuracy: 0.6625\n","Epoch 90, Train Loss: 45.8536, Val Loss: 27.1075, F1 Micro: 0.4575, F1 Macro: 0.3217, Accuracy: 0.4575\n","Epoch 91, Train Loss: 8.1601, Val Loss: 4.7289, F1 Micro: 0.6225, F1 Macro: 0.6055, Accuracy: 0.6225\n","Epoch 92, Train Loss: 1.4242, Val Loss: 1.1660, F1 Micro: 0.7425, F1 Macro: 0.7418, Accuracy: 0.7425\n","Epoch 93, Train Loss: 0.8387, Val Loss: 1.0200, F1 Micro: 0.6975, F1 Macro: 0.6975, Accuracy: 0.6975\n","Epoch 94, Train Loss: 0.7354, Val Loss: 0.8961, F1 Micro: 0.7350, F1 Macro: 0.7345, Accuracy: 0.7350\n","Epoch 95, Train Loss: 0.7306, Val Loss: 0.7914, F1 Micro: 0.7425, F1 Macro: 0.7422, Accuracy: 0.7425\n","Epoch 96, Train Loss: 0.7112, Val Loss: 0.7372, F1 Micro: 0.7375, F1 Macro: 0.7373, Accuracy: 0.7375\n","Epoch 97, Train Loss: 0.6255, Val Loss: 0.6720, F1 Micro: 0.7075, F1 Macro: 0.7065, Accuracy: 0.7075\n","Epoch 98, Train Loss: 0.6240, Val Loss: 0.8286, F1 Micro: 0.7050, F1 Macro: 0.7039, Accuracy: 0.7050\n","Epoch 99, Train Loss: 0.6383, Val Loss: 0.9424, F1 Micro: 0.6650, F1 Macro: 0.6623, Accuracy: 0.6650\n","Epoch 100, Train Loss: 0.6861, Val Loss: 0.7595, F1 Micro: 0.7025, F1 Macro: 0.7021, Accuracy: 0.7025\n","Epoch 101, Train Loss: 0.6477, Val Loss: 0.6390, F1 Micro: 0.7050, F1 Macro: 0.7020, Accuracy: 0.7050\n","Epoch 102, Train Loss: 0.6186, Val Loss: 0.7762, F1 Micro: 0.6900, F1 Macro: 0.6900, Accuracy: 0.6900\n","Epoch 103, Train Loss: 0.6637, Val Loss: 1.7046, F1 Micro: 0.6675, F1 Macro: 0.6485, Accuracy: 0.6675\n","Epoch 104, Train Loss: 0.7970, Val Loss: 1.4301, F1 Micro: 0.5550, F1 Macro: 0.5525, Accuracy: 0.5550\n","Epoch 105, Train Loss: 4.3022, Val Loss: 8.2380, F1 Micro: 0.5200, F1 Macro: 0.3421, Accuracy: 0.5200\n","Epoch 106, Train Loss: 5.7360, Val Loss: 2.9795, F1 Micro: 0.5500, F1 Macro: 0.4591, Accuracy: 0.5500\n","Epoch 107, Train Loss: 1.0734, Val Loss: 1.3566, F1 Micro: 0.6750, F1 Macro: 0.6743, Accuracy: 0.6750\n","Epoch 108, Train Loss: 0.7993, Val Loss: 0.7700, F1 Micro: 0.5550, F1 Macro: 0.5171, Accuracy: 0.5550\n","Epoch 109, Train Loss: 0.7185, Val Loss: 0.7020, F1 Micro: 0.6950, F1 Macro: 0.6909, Accuracy: 0.6950\n","Epoch 110, Train Loss: 0.7185, Val Loss: 1.6811, F1 Micro: 0.6975, F1 Macro: 0.6681, Accuracy: 0.6975\n","Epoch 111, Train Loss: 0.9388, Val Loss: 0.7944, F1 Micro: 0.7250, F1 Macro: 0.7234, Accuracy: 0.7250\n","Epoch 112, Train Loss: 0.7414, Val Loss: 0.9659, F1 Micro: 0.7075, F1 Macro: 0.7023, Accuracy: 0.7075\n","Epoch 113, Train Loss: 0.6734, Val Loss: 0.8954, F1 Micro: 0.6725, F1 Macro: 0.6705, Accuracy: 0.6725\n","Epoch 114, Train Loss: 0.8212, Val Loss: 2.2596, F1 Micro: 0.6225, F1 Macro: 0.5968, Accuracy: 0.6225\n","Epoch 115, Train Loss: 0.8058, Val Loss: 0.8385, F1 Micro: 0.7275, F1 Macro: 0.7249, Accuracy: 0.7275\n","Epoch 116, Train Loss: 1.0798, Val Loss: 1.9569, F1 Micro: 0.6100, F1 Macro: 0.5954, Accuracy: 0.6100\n","Epoch 117, Train Loss: 4.2586, Val Loss: 0.9633, F1 Micro: 0.7075, F1 Macro: 0.7065, Accuracy: 0.7075\n","Epoch 118, Train Loss: 4.7101, Val Loss: 1.1574, F1 Micro: 0.5775, F1 Macro: 0.4717, Accuracy: 0.5775\n","Epoch 119, Train Loss: 0.8047, Val Loss: 0.7389, F1 Micro: 0.5375, F1 Macro: 0.4974, Accuracy: 0.5375\n","Epoch 120, Train Loss: 1.2426, Val Loss: 1.3180, F1 Micro: 0.7075, F1 Macro: 0.7019, Accuracy: 0.7075\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.7075, F1 Macro: 0.7019, Accuracy: 0.7075\n","Outer FOLD 3\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 881.8348, Val Loss: 625.9515, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 2, Train Loss: 328.0063, Val Loss: 410.8202, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 88.8962, Val Loss: 8.9581, F1 Micro: 0.7708, F1 Macro: 0.6648, Accuracy: 0.7708\n","Epoch 4, Train Loss: 45.8784, Val Loss: 54.2548, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 5, Train Loss: 50.8257, Val Loss: 7.9289, F1 Micro: 0.7812, F1 Macro: 0.6744, Accuracy: 0.7812\n","Epoch 6, Train Loss: 52.3854, Val Loss: 19.6357, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 7, Train Loss: 79.9077, Val Loss: 206.1526, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 121.3433, Val Loss: 49.3207, F1 Micro: 0.4167, F1 Macro: 0.4157, Accuracy: 0.4167\n","Epoch 9, Train Loss: 45.8271, Val Loss: 53.8497, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 28.2706, Val Loss: 26.2598, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 26.3484, Val Loss: 119.7122, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 12, Train Loss: 29.9423, Val Loss: 4.6992, F1 Micro: 0.7604, F1 Macro: 0.6849, Accuracy: 0.7604\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 516.1927, Val Loss: 175.7057, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 2, Train Loss: 169.0958, Val Loss: 105.5767, F1 Micro: 0.1667, F1 Macro: 0.1534, Accuracy: 0.1667\n","Epoch 3, Train Loss: 158.6502, Val Loss: 237.8996, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 112.8088, Val Loss: 57.9687, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 110.9221, Val Loss: 77.0464, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 6, Train Loss: 126.0879, Val Loss: 94.9190, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 7, Train Loss: 63.2064, Val Loss: 93.5385, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 8, Train Loss: 76.1032, Val Loss: 4.5039, F1 Micro: 0.6458, F1 Macro: 0.5278, Accuracy: 0.6458\n","Epoch 9, Train Loss: 34.9552, Val Loss: 3.4500, F1 Micro: 0.7083, F1 Macro: 0.5733, Accuracy: 0.7083\n","Epoch 10, Train Loss: 52.2257, Val Loss: 113.7000, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 11, Train Loss: 63.7697, Val Loss: 21.7694, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 12, Train Loss: 24.8803, Val Loss: 49.4417, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 62.1313, Val Loss: 18.1041, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 481.7436, Val Loss: 16.3712, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 2, Train Loss: 258.8264, Val Loss: 362.6946, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 154.4306, Val Loss: 61.3134, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 252.8900, Val Loss: 43.7018, F1 Micro: 0.2708, F1 Macro: 0.2696, Accuracy: 0.2708\n","Epoch 5, Train Loss: 103.8180, Val Loss: 80.9971, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 93.4044, Val Loss: 68.8416, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 7, Train Loss: 32.8484, Val Loss: 98.4325, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 8, Train Loss: 72.2337, Val Loss: 75.4345, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 54.0221, Val Loss: 10.5577, F1 Micro: 0.7708, F1 Macro: 0.5401, Accuracy: 0.7708\n","Epoch 10, Train Loss: 49.8774, Val Loss: 18.8470, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 11, Train Loss: 49.0775, Val Loss: 15.9217, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 12, Train Loss: 13.3686, Val Loss: 8.0559, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 533.8717, Val Loss: 200.7101, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 2, Train Loss: 200.9931, Val Loss: 200.1069, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 3, Train Loss: 105.8332, Val Loss: 183.8975, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 4, Train Loss: 139.8373, Val Loss: 115.4743, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 5, Train Loss: 40.5805, Val Loss: 104.7712, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 6, Train Loss: 139.4339, Val Loss: 58.2336, F1 Micro: 0.3750, F1 Macro: 0.3466, Accuracy: 0.3750\n","Epoch 7, Train Loss: 201.3969, Val Loss: 33.0320, F1 Micro: 0.5625, F1 Macro: 0.4589, Accuracy: 0.5625\n","Epoch 8, Train Loss: 47.8626, Val Loss: 97.0766, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 9, Train Loss: 50.2207, Val Loss: 31.6155, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 10, Train Loss: 85.9654, Val Loss: 127.3365, F1 Micro: 0.1146, F1 Macro: 0.1067, Accuracy: 0.1146\n","Epoch 11, Train Loss: 38.0025, Val Loss: 17.6532, F1 Micro: 0.5208, F1 Macro: 0.4424, Accuracy: 0.5208\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 665.2328, Val Loss: 80.5670, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 2, Train Loss: 362.9260, Val Loss: 160.8019, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 92.1758, Val Loss: 96.3788, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 4, Train Loss: 112.3459, Val Loss: 113.9585, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 5, Train Loss: 61.0400, Val Loss: 67.5102, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 48.2868, Val Loss: 61.1188, F1 Micro: 0.2083, F1 Macro: 0.2028, Accuracy: 0.2083\n","Epoch 7, Train Loss: 43.1291, Val Loss: 8.1517, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 8, Train Loss: 12.2973, Val Loss: 9.0568, F1 Micro: 0.3125, F1 Macro: 0.3113, Accuracy: 0.3125\n","Epoch 9, Train Loss: 31.4326, Val Loss: 42.5737, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 10, Train Loss: 17.0795, Val Loss: 20.3416, F1 Micro: 0.4688, F1 Macro: 0.4231, Accuracy: 0.4688\n","Epoch 11, Train Loss: 36.4197, Val Loss: 22.6612, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 12, Train Loss: 26.7677, Val Loss: 57.5458, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.8583333333333332\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 406.2291, Val Loss: 129.6684, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 2, Train Loss: 328.2030, Val Loss: 271.4399, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 105.7670, Val Loss: 74.3825, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 4, Train Loss: 234.9000, Val Loss: 216.7229, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 5, Train Loss: 157.9556, Val Loss: 14.2342, F1 Micro: 0.8125, F1 Macro: 0.6783, Accuracy: 0.8125\n","Epoch 6, Train Loss: 42.6259, Val Loss: 64.5367, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 7, Train Loss: 46.7431, Val Loss: 211.7069, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 51.6314, Val Loss: 106.3968, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 9, Train Loss: 36.0576, Val Loss: 17.0012, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 80.4516, Val Loss: 21.0449, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 11, Train Loss: 34.1388, Val Loss: 5.8786, F1 Micro: 0.6562, F1 Macro: 0.6102, Accuracy: 0.6562\n","Epoch 12, Train Loss: 23.8238, Val Loss: 47.2896, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 46.9932, Val Loss: 47.1893, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 14, Train Loss: 19.0572, Val Loss: 26.2071, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 15, Train Loss: 14.8190, Val Loss: 14.2120, F1 Micro: 0.8229, F1 Macro: 0.6730, Accuracy: 0.8229\n","Epoch 16, Train Loss: 13.1779, Val Loss: 6.2307, F1 Micro: 0.8125, F1 Macro: 0.7158, Accuracy: 0.8125\n","Epoch 17, Train Loss: 13.6775, Val Loss: 26.0630, F1 Micro: 0.2500, F1 Macro: 0.2381, Accuracy: 0.2500\n","Epoch 18, Train Loss: 17.1458, Val Loss: 39.5149, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 19, Train Loss: 13.6217, Val Loss: 7.5979, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 20, Train Loss: 14.3123, Val Loss: 3.0367, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 21, Train Loss: 14.6053, Val Loss: 3.3338, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 22, Train Loss: 14.3059, Val Loss: 3.0100, F1 Micro: 0.6562, F1 Macro: 0.6036, Accuracy: 0.6562\n","Epoch 23, Train Loss: 10.8305, Val Loss: 43.1174, F1 Micro: 0.4375, F1 Macro: 0.4353, Accuracy: 0.4375\n","Epoch 24, Train Loss: 11.0058, Val Loss: 9.7761, F1 Micro: 0.5625, F1 Macro: 0.4589, Accuracy: 0.5625\n","Epoch 25, Train Loss: 14.8455, Val Loss: 7.4147, F1 Micro: 0.6250, F1 Macro: 0.5844, Accuracy: 0.6250\n","Epoch 26, Train Loss: 6.6136, Val Loss: 12.6746, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 27, Train Loss: 5.5261, Val Loss: 19.1018, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 28, Train Loss: 16.2292, Val Loss: 13.0950, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 29, Train Loss: 6.8116, Val Loss: 6.6456, F1 Micro: 0.7500, F1 Macro: 0.4983, Accuracy: 0.7500\n","Epoch 30, Train Loss: 7.0336, Val Loss: 4.8237, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 31, Train Loss: 2.4022, Val Loss: 3.8684, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 32, Train Loss: 2.9473, Val Loss: 4.2447, F1 Micro: 0.7396, F1 Macro: 0.6997, Accuracy: 0.7396\n","Epoch 33, Train Loss: 2.8911, Val Loss: 4.1263, F1 Micro: 0.7188, F1 Macro: 0.6811, Accuracy: 0.7188\n","Epoch 34, Train Loss: 1.9470, Val Loss: 1.8359, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 35, Train Loss: 2.1061, Val Loss: 3.1077, F1 Micro: 0.7500, F1 Macro: 0.5897, Accuracy: 0.7500\n","Epoch 36, Train Loss: 5.0006, Val Loss: 39.7677, F1 Micro: 0.3125, F1 Macro: 0.3050, Accuracy: 0.3125\n","Epoch 37, Train Loss: 6.5667, Val Loss: 5.6244, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 38, Train Loss: 7.4139, Val Loss: 1.9477, F1 Micro: 0.8021, F1 Macro: 0.7463, Accuracy: 0.8021\n","Epoch 39, Train Loss: 3.4203, Val Loss: 1.5248, F1 Micro: 0.8229, F1 Macro: 0.7730, Accuracy: 0.8229\n","Epoch 40, Train Loss: 2.1927, Val Loss: 0.6950, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 41, Train Loss: 2.7599, Val Loss: 3.0809, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 42, Train Loss: 2.7763, Val Loss: 6.5980, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 43, Train Loss: 1.1898, Val Loss: 1.2390, F1 Micro: 0.8333, F1 Macro: 0.7641, Accuracy: 0.8333\n","Epoch 44, Train Loss: 0.9412, Val Loss: 2.6679, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 45, Train Loss: 3.1917, Val Loss: 5.6318, F1 Micro: 0.6042, F1 Macro: 0.5822, Accuracy: 0.6042\n","Epoch 46, Train Loss: 2.9827, Val Loss: 3.2156, F1 Micro: 0.7500, F1 Macro: 0.7091, Accuracy: 0.7500\n","Epoch 47, Train Loss: 2.0206, Val Loss: 3.0881, F1 Micro: 0.7500, F1 Macro: 0.7091, Accuracy: 0.7500\n","Epoch 48, Train Loss: 7.9556, Val Loss: 24.8116, F1 Micro: 0.2917, F1 Macro: 0.2867, Accuracy: 0.2917\n","Epoch 49, Train Loss: 21.4211, Val Loss: 3.2700, F1 Micro: 0.8021, F1 Macro: 0.7397, Accuracy: 0.8021\n","Epoch 50, Train Loss: 1.9429, Val Loss: 5.6523, F1 Micro: 0.7396, F1 Macro: 0.5815, Accuracy: 0.7396\n","Epoch 51, Train Loss: 2.5015, Val Loss: 2.2744, F1 Micro: 0.8125, F1 Macro: 0.7681, Accuracy: 0.8125\n","Epoch 52, Train Loss: 3.5556, Val Loss: 4.3334, F1 Micro: 0.8021, F1 Macro: 0.7397, Accuracy: 0.8021\n","Epoch 53, Train Loss: 1.4302, Val Loss: 1.4619, F1 Micro: 0.8542, F1 Macro: 0.6886, Accuracy: 0.8542\n","Epoch 54, Train Loss: 2.6796, Val Loss: 4.7486, F1 Micro: 0.7188, F1 Macro: 0.6082, Accuracy: 0.7188\n","Epoch 55, Train Loss: 4.2543, Val Loss: 2.4226, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 56, Train Loss: 5.9163, Val Loss: 2.7668, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 57, Train Loss: 1.6440, Val Loss: 0.6851, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 58, Train Loss: 2.1975, Val Loss: 2.9848, F1 Micro: 0.8646, F1 Macro: 0.7984, Accuracy: 0.8646\n","Epoch 59, Train Loss: 1.7843, Val Loss: 1.0881, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 60, Train Loss: 0.4970, Val Loss: 0.9301, F1 Micro: 0.8750, F1 Macro: 0.8105, Accuracy: 0.8750\n","Epoch 61, Train Loss: 1.3332, Val Loss: 1.5007, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 62, Train Loss: 1.0416, Val Loss: 0.8085, F1 Micro: 0.8750, F1 Macro: 0.7491, Accuracy: 0.8750\n","Epoch 63, Train Loss: 3.2120, Val Loss: 2.4167, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 64, Train Loss: 11.1191, Val Loss: 13.8334, F1 Micro: 0.6042, F1 Macro: 0.5822, Accuracy: 0.6042\n","Epoch 65, Train Loss: 7.1142, Val Loss: 6.0763, F1 Micro: 0.7083, F1 Macro: 0.6719, Accuracy: 0.7083\n","Epoch 66, Train Loss: 1.6490, Val Loss: 1.1345, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 67, Train Loss: 1.7018, Val Loss: 2.2338, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 68, Train Loss: 1.6212, Val Loss: 3.6083, F1 Micro: 0.8021, F1 Macro: 0.7397, Accuracy: 0.8021\n","Epoch 69, Train Loss: 4.1029, Val Loss: 1.3856, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 70, Train Loss: 2.6171, Val Loss: 1.0424, F1 Micro: 0.8750, F1 Macro: 0.8171, Accuracy: 0.8750\n","Epoch 71, Train Loss: 1.4825, Val Loss: 2.2120, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 72, Train Loss: 6.3913, Val Loss: 3.5978, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 73, Train Loss: 4.9775, Val Loss: 8.3967, F1 Micro: 0.6250, F1 Macro: 0.6000, Accuracy: 0.6250\n","Epoch 74, Train Loss: 1.1823, Val Loss: 7.9627, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 75, Train Loss: 2.4818, Val Loss: 5.8629, F1 Micro: 0.6979, F1 Macro: 0.6627, Accuracy: 0.6979\n","Epoch 76, Train Loss: 2.9397, Val Loss: 1.1202, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 77, Train Loss: 1.8282, Val Loss: 7.2635, F1 Micro: 0.6667, F1 Macro: 0.6357, Accuracy: 0.6667\n","Epoch 78, Train Loss: 4.1786, Val Loss: 3.2100, F1 Micro: 0.8021, F1 Macro: 0.7324, Accuracy: 0.8021\n","Epoch 79, Train Loss: 5.2281, Val Loss: 7.9265, F1 Micro: 0.6979, F1 Macro: 0.5503, Accuracy: 0.6979\n","Epoch 80, Train Loss: 4.3745, Val Loss: 3.2830, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 81, Train Loss: 3.2119, Val Loss: 3.6931, F1 Micro: 0.7708, F1 Macro: 0.7025, Accuracy: 0.7708\n","Epoch 82, Train Loss: 10.4784, Val Loss: 4.1449, F1 Micro: 0.8854, F1 Macro: 0.8159, Accuracy: 0.8854\n","Epoch 83, Train Loss: 6.4238, Val Loss: 4.8179, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 84, Train Loss: 3.2224, Val Loss: 1.7872, F1 Micro: 0.8229, F1 Macro: 0.6091, Accuracy: 0.8229\n","Epoch 85, Train Loss: 6.9010, Val Loss: 1.9616, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 86, Train Loss: 3.1583, Val Loss: 29.8557, F1 Micro: 0.3229, F1 Macro: 0.3211, Accuracy: 0.3229\n","Epoch 87, Train Loss: 33.6248, Val Loss: 7.0466, F1 Micro: 0.7292, F1 Macro: 0.6903, Accuracy: 0.7292\n","Epoch 88, Train Loss: 3.8146, Val Loss: 5.7765, F1 Micro: 0.7917, F1 Macro: 0.7363, Accuracy: 0.7917\n","Epoch 89, Train Loss: 9.3125, Val Loss: 5.2762, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 90, Train Loss: 21.3527, Val Loss: 18.4965, F1 Micro: 0.6667, F1 Macro: 0.5124, Accuracy: 0.6667\n","Epoch 91, Train Loss: 9.9879, Val Loss: 4.1771, F1 Micro: 0.7812, F1 Macro: 0.7196, Accuracy: 0.7812\n","Epoch 92, Train Loss: 1.7923, Val Loss: 3.2463, F1 Micro: 0.8125, F1 Macro: 0.6783, Accuracy: 0.8125\n","Epoch 93, Train Loss: 0.8893, Val Loss: 1.1522, F1 Micro: 0.9167, F1 Macro: 0.8688, Accuracy: 0.9167\n","Epoch 94, Train Loss: 1.4864, Val Loss: 1.7604, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 95, Train Loss: 2.4166, Val Loss: 1.7650, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 96, Train Loss: 1.5953, Val Loss: 1.0530, F1 Micro: 0.9375, F1 Macro: 0.8928, Accuracy: 0.9375\n","Epoch 97, Train Loss: 1.4907, Val Loss: 7.2808, F1 Micro: 0.7708, F1 Macro: 0.7099, Accuracy: 0.7708\n","Epoch 98, Train Loss: 7.2384, Val Loss: 16.7922, F1 Micro: 0.5312, F1 Macro: 0.5195, Accuracy: 0.5312\n","Epoch 99, Train Loss: 4.5699, Val Loss: 21.2581, F1 Micro: 0.5000, F1 Macro: 0.4723, Accuracy: 0.5000\n","Epoch 100, Train Loss: 9.4697, Val Loss: 11.0119, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 101, Train Loss: 20.9945, Val Loss: 8.1432, F1 Micro: 0.6771, F1 Macro: 0.6447, Accuracy: 0.6771\n","Epoch 102, Train Loss: 2.0260, Val Loss: 10.3907, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 103, Train Loss: 4.6429, Val Loss: 1.6308, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 104, Train Loss: 0.9338, Val Loss: 1.9970, F1 Micro: 0.8438, F1 Macro: 0.7587, Accuracy: 0.8438\n","Epoch 105, Train Loss: 1.6430, Val Loss: 20.3184, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 106, Train Loss: 2.8726, Val Loss: 1.8243, F1 Micro: 0.8854, F1 Macro: 0.8352, Accuracy: 0.8854\n","Epoch 107, Train Loss: 2.8182, Val Loss: 1.2742, F1 Micro: 0.8646, F1 Macro: 0.7908, Accuracy: 0.8646\n","Epoch 108, Train Loss: 1.4901, Val Loss: 1.9386, F1 Micro: 0.8229, F1 Macro: 0.6730, Accuracy: 0.8229\n","Epoch 109, Train Loss: 1.3537, Val Loss: 3.4074, F1 Micro: 0.8021, F1 Macro: 0.5906, Accuracy: 0.8021\n","Epoch 110, Train Loss: 0.6572, Val Loss: 1.6786, F1 Micro: 0.8750, F1 Macro: 0.8171, Accuracy: 0.8750\n","Epoch 111, Train Loss: 1.7006, Val Loss: 1.8015, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 112, Train Loss: 4.1080, Val Loss: 17.3861, F1 Micro: 0.5208, F1 Macro: 0.5104, Accuracy: 0.5208\n","Epoch 113, Train Loss: 7.1049, Val Loss: 5.5535, F1 Micro: 0.7708, F1 Macro: 0.6526, Accuracy: 0.7708\n","Epoch 114, Train Loss: 1.9900, Val Loss: 3.6959, F1 Micro: 0.8333, F1 Macro: 0.7837, Accuracy: 0.8333\n","Epoch 115, Train Loss: 1.1314, Val Loss: 2.2986, F1 Micro: 0.8333, F1 Macro: 0.7641, Accuracy: 0.8333\n","Epoch 116, Train Loss: 5.0154, Val Loss: 5.2039, F1 Micro: 0.7604, F1 Macro: 0.7186, Accuracy: 0.7604\n","Epoch 117, Train Loss: 2.6541, Val Loss: 2.1391, F1 Micro: 0.8333, F1 Macro: 0.5893, Accuracy: 0.8333\n","Epoch 118, Train Loss: 2.3364, Val Loss: 5.2064, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 119, Train Loss: 15.4850, Val Loss: 35.9549, F1 Micro: 0.5000, F1 Macro: 0.4921, Accuracy: 0.5000\n","Epoch 120, Train Loss: 26.9717, Val Loss: 73.2365, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 121, Train Loss: 17.2290, Val Loss: 30.7922, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 122, Train Loss: 3.8809, Val Loss: 1.9893, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 123, Train Loss: 2.4343, Val Loss: 1.1604, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 124, Train Loss: 1.1044, Val Loss: 1.3330, F1 Micro: 0.9375, F1 Macro: 0.8974, Accuracy: 0.9375\n","Epoch 125, Train Loss: 3.0248, Val Loss: 1.4975, F1 Micro: 0.9375, F1 Macro: 0.8974, Accuracy: 0.9375\n","Epoch 126, Train Loss: 1.7703, Val Loss: 1.3436, F1 Micro: 0.8750, F1 Macro: 0.8105, Accuracy: 0.8750\n","Epoch 127, Train Loss: 1.1323, Val Loss: 1.7085, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 128, Train Loss: 0.7192, Val Loss: 1.1973, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 129, Train Loss: 0.7427, Val Loss: 1.2435, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 130, Train Loss: 1.5682, Val Loss: 3.4606, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 131, Train Loss: 1.8644, Val Loss: 3.0203, F1 Micro: 0.8333, F1 Macro: 0.7778, Accuracy: 0.8333\n","Epoch 132, Train Loss: 9.8034, Val Loss: 6.0051, F1 Micro: 0.7604, F1 Macro: 0.7131, Accuracy: 0.7604\n","Epoch 133, Train Loss: 2.1183, Val Loss: 2.3202, F1 Micro: 0.9062, F1 Macro: 0.8552, Accuracy: 0.9062\n","Epoch 134, Train Loss: 1.0222, Val Loss: 5.0266, F1 Micro: 0.7812, F1 Macro: 0.7123, Accuracy: 0.7812\n","Epoch 135, Train Loss: 7.8327, Val Loss: 65.5008, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 136, Train Loss: 9.3718, Val Loss: 1.7250, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 137, Train Loss: 1.3567, Val Loss: 3.9945, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 138, Train Loss: 6.1798, Val Loss: 15.0209, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 139, Train Loss: 9.4019, Val Loss: 7.5419, F1 Micro: 0.7917, F1 Macro: 0.7296, Accuracy: 0.7917\n","Epoch 140, Train Loss: 6.7997, Val Loss: 17.9860, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 141, Train Loss: 7.5747, Val Loss: 12.9881, F1 Micro: 0.6562, F1 Macro: 0.6267, Accuracy: 0.6562\n","Epoch 142, Train Loss: 2.7277, Val Loss: 14.9978, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 143, Train Loss: 3.7415, Val Loss: 4.0337, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 144, Train Loss: 2.0089, Val Loss: 1.4943, F1 Micro: 0.8750, F1 Macro: 0.8105, Accuracy: 0.8750\n","Epoch 145, Train Loss: 0.9775, Val Loss: 2.0765, F1 Micro: 0.9167, F1 Macro: 0.8688, Accuracy: 0.9167\n","Epoch 146, Train Loss: 1.4910, Val Loss: 2.4373, F1 Micro: 0.8958, F1 Macro: 0.8526, Accuracy: 0.8958\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 389.7429, Val Loss: 37.4104, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 255.4003, Val Loss: 46.9353, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 3, Train Loss: 284.6774, Val Loss: 381.0382, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 4, Train Loss: 148.4484, Val Loss: 50.0340, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 103.8193, Val Loss: 178.6058, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 74.9112, Val Loss: 15.6129, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 7, Train Loss: 58.0196, Val Loss: 54.6078, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 8, Train Loss: 64.6419, Val Loss: 10.4101, F1 Micro: 0.7812, F1 Macro: 0.4813, Accuracy: 0.7812\n","Epoch 9, Train Loss: 131.3541, Val Loss: 26.0158, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 10, Train Loss: 42.1730, Val Loss: 18.6479, F1 Micro: 0.5208, F1 Macro: 0.4829, Accuracy: 0.5208\n","Epoch 11, Train Loss: 50.1694, Val Loss: 67.7783, F1 Micro: 0.2083, F1 Macro: 0.2052, Accuracy: 0.2083\n","Epoch 12, Train Loss: 90.7142, Val Loss: 78.0413, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 50.1877, Val Loss: 206.8548, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 14, Train Loss: 49.0972, Val Loss: 21.2031, F1 Micro: 0.2604, F1 Macro: 0.2603, Accuracy: 0.2604\n","Epoch 15, Train Loss: 23.7611, Val Loss: 3.7499, F1 Micro: 0.5625, F1 Macro: 0.5218, Accuracy: 0.5625\n","Epoch 16, Train Loss: 8.9254, Val Loss: 5.9315, F1 Micro: 0.8750, F1 Macro: 0.5909, Accuracy: 0.8750\n","Epoch 17, Train Loss: 34.5848, Val Loss: 33.1046, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 18, Train Loss: 19.5794, Val Loss: 3.3537, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 19, Train Loss: 29.6221, Val Loss: 19.1762, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 20, Train Loss: 33.4841, Val Loss: 28.6350, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 21, Train Loss: 21.7337, Val Loss: 18.2110, F1 Micro: 0.1875, F1 Macro: 0.1786, Accuracy: 0.1875\n","Epoch 22, Train Loss: 14.2161, Val Loss: 1.5739, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 23, Train Loss: 9.4256, Val Loss: 9.1763, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 24, Train Loss: 12.1929, Val Loss: 14.0598, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 25, Train Loss: 9.0753, Val Loss: 7.8213, F1 Micro: 0.4896, F1 Macro: 0.4639, Accuracy: 0.4896\n","Epoch 26, Train Loss: 5.8656, Val Loss: 5.3351, F1 Micro: 0.5104, F1 Macro: 0.4806, Accuracy: 0.5104\n","Epoch 27, Train Loss: 3.5845, Val Loss: 0.7873, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 28, Train Loss: 2.2634, Val Loss: 1.2018, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 29, Train Loss: 3.1233, Val Loss: 0.7369, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 30, Train Loss: 8.1753, Val Loss: 15.7722, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 31, Train Loss: 6.4798, Val Loss: 2.5877, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 32, Train Loss: 2.7303, Val Loss: 4.2369, F1 Micro: 0.5833, F1 Macro: 0.5312, Accuracy: 0.5833\n","Epoch 33, Train Loss: 4.1431, Val Loss: 6.2362, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 34, Train Loss: 11.2963, Val Loss: 34.1193, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 35, Train Loss: 15.8496, Val Loss: 5.0441, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 36, Train Loss: 9.0918, Val Loss: 2.8586, F1 Micro: 0.6562, F1 Macro: 0.5963, Accuracy: 0.6562\n","Epoch 37, Train Loss: 7.9868, Val Loss: 1.1858, F1 Micro: 0.8750, F1 Macro: 0.5909, Accuracy: 0.8750\n","Epoch 38, Train Loss: 2.0027, Val Loss: 1.8160, F1 Micro: 0.8646, F1 Macro: 0.7621, Accuracy: 0.8646\n","Epoch 39, Train Loss: 1.4623, Val Loss: 5.9594, F1 Micro: 0.6667, F1 Macro: 0.4751, Accuracy: 0.6667\n","Epoch 40, Train Loss: 1.4417, Val Loss: 1.4155, F1 Micro: 0.7604, F1 Macro: 0.5576, Accuracy: 0.7604\n","Epoch 41, Train Loss: 2.2638, Val Loss: 8.2909, F1 Micro: 0.6458, F1 Macro: 0.5714, Accuracy: 0.6458\n","Epoch 42, Train Loss: 7.0052, Val Loss: 1.5160, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 43, Train Loss: 1.9899, Val Loss: 1.1189, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 44, Train Loss: 3.0347, Val Loss: 26.2694, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 45, Train Loss: 8.3235, Val Loss: 0.5771, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 46, Train Loss: 2.1876, Val Loss: 2.2161, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 47, Train Loss: 3.7940, Val Loss: 1.3513, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 48, Train Loss: 2.4910, Val Loss: 0.8149, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 49, Train Loss: 4.4117, Val Loss: 2.3583, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 50, Train Loss: 2.8288, Val Loss: 0.8763, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 51, Train Loss: 2.2508, Val Loss: 1.7898, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 52, Train Loss: 1.1764, Val Loss: 0.7234, F1 Micro: 0.9167, F1 Macro: 0.7767, Accuracy: 0.9167\n","Epoch 53, Train Loss: 8.8335, Val Loss: 0.7870, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 54, Train Loss: 7.9286, Val Loss: 6.5191, F1 Micro: 0.5833, F1 Macro: 0.5059, Accuracy: 0.5833\n","Epoch 55, Train Loss: 10.4941, Val Loss: 2.8539, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 56, Train Loss: 9.4144, Val Loss: 21.2133, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 57, Train Loss: 5.3534, Val Loss: 2.3752, F1 Micro: 0.7396, F1 Macro: 0.6372, Accuracy: 0.7396\n","Epoch 58, Train Loss: 1.9894, Val Loss: 0.4063, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 59, Train Loss: 1.3023, Val Loss: 0.3218, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 60, Train Loss: 1.5904, Val Loss: 0.7154, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 61, Train Loss: 1.5441, Val Loss: 2.5307, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 62, Train Loss: 0.7177, Val Loss: 1.2903, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 63, Train Loss: 1.8711, Val Loss: 1.9871, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 64, Train Loss: 1.2962, Val Loss: 7.4254, F1 Micro: 0.6458, F1 Macro: 0.4632, Accuracy: 0.6458\n","Epoch 65, Train Loss: 11.0819, Val Loss: 9.4803, F1 Micro: 0.6146, F1 Macro: 0.5629, Accuracy: 0.6146\n","Epoch 66, Train Loss: 5.7272, Val Loss: 10.3703, F1 Micro: 0.6771, F1 Macro: 0.4328, Accuracy: 0.6771\n","Epoch 67, Train Loss: 7.9271, Val Loss: 1.3161, F1 Micro: 0.8646, F1 Macro: 0.7908, Accuracy: 0.8646\n","Epoch 68, Train Loss: 14.0847, Val Loss: 2.0335, F1 Micro: 0.8125, F1 Macro: 0.7346, Accuracy: 0.8125\n","Epoch 69, Train Loss: 15.7767, Val Loss: 4.8127, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 70, Train Loss: 7.9340, Val Loss: 4.2820, F1 Micro: 0.6979, F1 Macro: 0.6305, Accuracy: 0.6979\n","Epoch 71, Train Loss: 9.5135, Val Loss: 1.7839, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 72, Train Loss: 8.1046, Val Loss: 1.4559, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 73, Train Loss: 2.1738, Val Loss: 1.5167, F1 Micro: 0.8229, F1 Macro: 0.7453, Accuracy: 0.8229\n","Epoch 74, Train Loss: 1.5673, Val Loss: 0.7720, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 75, Train Loss: 1.4894, Val Loss: 0.3186, F1 Micro: 0.9375, F1 Macro: 0.8665, Accuracy: 0.9375\n","Epoch 76, Train Loss: 0.9151, Val Loss: 3.7919, F1 Micro: 0.7083, F1 Macro: 0.5998, Accuracy: 0.7083\n","Epoch 77, Train Loss: 5.0542, Val Loss: 1.1788, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 78, Train Loss: 4.6926, Val Loss: 0.4061, F1 Micro: 0.9375, F1 Macro: 0.8665, Accuracy: 0.9375\n","Epoch 79, Train Loss: 2.2051, Val Loss: 2.6241, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 80, Train Loss: 2.6578, Val Loss: 1.2690, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 81, Train Loss: 1.2342, Val Loss: 0.2924, F1 Micro: 0.9583, F1 Macro: 0.9048, Accuracy: 0.9583\n","Epoch 82, Train Loss: 5.6730, Val Loss: 1.1850, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 83, Train Loss: 3.0515, Val Loss: 1.0325, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 84, Train Loss: 4.2902, Val Loss: 2.8812, F1 Micro: 0.7396, F1 Macro: 0.6254, Accuracy: 0.7396\n","Epoch 85, Train Loss: 3.3176, Val Loss: 0.5047, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 86, Train Loss: 1.8947, Val Loss: 3.7365, F1 Micro: 0.6771, F1 Macro: 0.6133, Accuracy: 0.6771\n","Epoch 87, Train Loss: 1.4593, Val Loss: 1.0361, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 88, Train Loss: 1.5411, Val Loss: 2.5982, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 89, Train Loss: 3.7485, Val Loss: 1.4691, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 90, Train Loss: 1.5464, Val Loss: 0.6863, F1 Micro: 0.8854, F1 Macro: 0.7630, Accuracy: 0.8854\n","Epoch 91, Train Loss: 2.1031, Val Loss: 1.1983, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 92, Train Loss: 4.5946, Val Loss: 1.4467, F1 Micro: 0.8021, F1 Macro: 0.7153, Accuracy: 0.8021\n","Epoch 93, Train Loss: 15.9612, Val Loss: 58.4123, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 94, Train Loss: 30.8929, Val Loss: 5.0764, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 95, Train Loss: 10.8387, Val Loss: 3.7216, F1 Micro: 0.7396, F1 Macro: 0.6662, Accuracy: 0.7396\n","Epoch 96, Train Loss: 4.0362, Val Loss: 2.7427, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 97, Train Loss: 2.4496, Val Loss: 0.4267, F1 Micro: 0.9375, F1 Macro: 0.8460, Accuracy: 0.9375\n","Epoch 98, Train Loss: 1.7497, Val Loss: 1.3124, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 99, Train Loss: 5.1434, Val Loss: 1.2817, F1 Micro: 0.8125, F1 Macro: 0.7257, Accuracy: 0.8125\n","Epoch 100, Train Loss: 4.9723, Val Loss: 0.9869, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 101, Train Loss: 2.9910, Val Loss: 2.7581, F1 Micro: 0.7604, F1 Macro: 0.6849, Accuracy: 0.7604\n","Epoch 102, Train Loss: 12.7372, Val Loss: 15.3774, F1 Micro: 0.5104, F1 Macro: 0.4858, Accuracy: 0.5104\n","Epoch 103, Train Loss: 12.1543, Val Loss: 0.7746, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 104, Train Loss: 2.5527, Val Loss: 4.4032, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 105, Train Loss: 3.1041, Val Loss: 0.8705, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 106, Train Loss: 27.4036, Val Loss: 47.9113, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 107, Train Loss: 29.6599, Val Loss: 14.4123, F1 Micro: 0.4792, F1 Macro: 0.4555, Accuracy: 0.4792\n","Epoch 108, Train Loss: 3.9912, Val Loss: 0.4860, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 109, Train Loss: 1.6124, Val Loss: 1.6575, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 110, Train Loss: 4.3222, Val Loss: 0.7827, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 111, Train Loss: 1.4865, Val Loss: 0.4742, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 112, Train Loss: 1.8131, Val Loss: 1.6590, F1 Micro: 0.7917, F1 Macro: 0.7052, Accuracy: 0.7917\n","Epoch 113, Train Loss: 1.3079, Val Loss: 1.8912, F1 Micro: 0.8021, F1 Macro: 0.7153, Accuracy: 0.8021\n","Epoch 114, Train Loss: 2.5499, Val Loss: 1.9082, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 115, Train Loss: 4.2773, Val Loss: 9.3363, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 116, Train Loss: 6.0313, Val Loss: 4.8222, F1 Micro: 0.7083, F1 Macro: 0.5872, Accuracy: 0.7083\n","Epoch 117, Train Loss: 52.9586, Val Loss: 10.3408, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 118, Train Loss: 5.6846, Val Loss: 1.5372, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 119, Train Loss: 3.8590, Val Loss: 2.9336, F1 Micro: 0.7292, F1 Macro: 0.6571, Accuracy: 0.7292\n","Epoch 120, Train Loss: 3.3639, Val Loss: 4.4578, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 121, Train Loss: 6.2059, Val Loss: 0.7833, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 122, Train Loss: 2.2387, Val Loss: 0.5896, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 123, Train Loss: 5.2830, Val Loss: 1.3284, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 124, Train Loss: 1.7211, Val Loss: 0.9072, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 125, Train Loss: 3.0257, Val Loss: 5.6891, F1 Micro: 0.8438, F1 Macro: 0.6954, Accuracy: 0.8438\n","Epoch 126, Train Loss: 10.5098, Val Loss: 10.6030, F1 Micro: 0.6042, F1 Macro: 0.5547, Accuracy: 0.6042\n","Epoch 127, Train Loss: 5.6487, Val Loss: 0.5201, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 128, Train Loss: 2.0554, Val Loss: 1.8411, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 129, Train Loss: 4.9189, Val Loss: 5.3550, F1 Micro: 0.6562, F1 Macro: 0.6036, Accuracy: 0.6562\n","Epoch 130, Train Loss: 4.2051, Val Loss: 1.6017, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 131, Train Loss: 2.9584, Val Loss: 3.7317, F1 Micro: 0.7812, F1 Macro: 0.4813, Accuracy: 0.7812\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 395.1662, Val Loss: 484.9717, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 2, Train Loss: 242.6466, Val Loss: 21.6958, F1 Micro: 0.5312, F1 Macro: 0.4684, Accuracy: 0.5312\n","Epoch 3, Train Loss: 184.6653, Val Loss: 304.7144, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 80.6540, Val Loss: 19.2303, F1 Micro: 0.2188, F1 Macro: 0.2187, Accuracy: 0.2188\n","Epoch 5, Train Loss: 61.7945, Val Loss: 38.9197, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 108.7560, Val Loss: 14.9492, F1 Micro: 0.6458, F1 Macro: 0.5140, Accuracy: 0.6458\n","Epoch 7, Train Loss: 52.1932, Val Loss: 25.9896, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 51.1141, Val Loss: 50.8052, F1 Micro: 0.1979, F1 Macro: 0.1971, Accuracy: 0.1979\n","Epoch 9, Train Loss: 15.6086, Val Loss: 49.3194, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 10, Train Loss: 36.1011, Val Loss: 9.4065, F1 Micro: 0.5417, F1 Macro: 0.4844, Accuracy: 0.5417\n","Epoch 11, Train Loss: 47.1655, Val Loss: 18.8585, F1 Micro: 0.6354, F1 Macro: 0.5205, Accuracy: 0.6354\n","Epoch 12, Train Loss: 50.3380, Val Loss: 33.7984, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 13, Train Loss: 34.1902, Val Loss: 14.5294, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 14, Train Loss: 22.4403, Val Loss: 14.4344, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 15, Train Loss: 13.5896, Val Loss: 6.1191, F1 Micro: 0.8542, F1 Macro: 0.6093, Accuracy: 0.8542\n","Epoch 16, Train Loss: 12.3512, Val Loss: 1.6449, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 17, Train Loss: 9.5441, Val Loss: 3.3230, F1 Micro: 0.8229, F1 Macro: 0.6337, Accuracy: 0.8229\n","Epoch 18, Train Loss: 14.4463, Val Loss: 11.3811, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 19, Train Loss: 16.5906, Val Loss: 4.3539, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 20, Train Loss: 15.2559, Val Loss: 12.3193, F1 Micro: 0.5521, F1 Macro: 0.4109, Accuracy: 0.5521\n","Epoch 21, Train Loss: 11.1165, Val Loss: 6.4786, F1 Micro: 0.7917, F1 Macro: 0.5551, Accuracy: 0.7917\n","Epoch 22, Train Loss: 12.4001, Val Loss: 10.4047, F1 Micro: 0.3021, F1 Macro: 0.2959, Accuracy: 0.3021\n","Epoch 23, Train Loss: 8.7074, Val Loss: 1.0906, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 24, Train Loss: 3.8472, Val Loss: 1.6480, F1 Micro: 0.8646, F1 Macro: 0.7011, Accuracy: 0.8646\n","Epoch 25, Train Loss: 8.1531, Val Loss: 1.9430, F1 Micro: 0.6667, F1 Macro: 0.5878, Accuracy: 0.6667\n","Epoch 26, Train Loss: 6.3816, Val Loss: 4.9154, F1 Micro: 0.6458, F1 Macro: 0.5714, Accuracy: 0.6458\n","Epoch 27, Train Loss: 5.1504, Val Loss: 0.9773, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 28, Train Loss: 3.9653, Val Loss: 3.1092, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 29, Train Loss: 5.5006, Val Loss: 2.8985, F1 Micro: 0.6875, F1 Macro: 0.5944, Accuracy: 0.6875\n","Epoch 30, Train Loss: 4.8076, Val Loss: 0.3181, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 31, Train Loss: 1.3493, Val Loss: 2.4223, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 32, Train Loss: 1.9649, Val Loss: 0.7086, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 33, Train Loss: 3.4806, Val Loss: 1.2641, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 34, Train Loss: 4.2692, Val Loss: 10.9127, F1 Micro: 0.2292, F1 Macro: 0.2292, Accuracy: 0.2292\n","Epoch 35, Train Loss: 5.8645, Val Loss: 1.6550, F1 Micro: 0.8438, F1 Macro: 0.7115, Accuracy: 0.8438\n","Epoch 36, Train Loss: 6.2146, Val Loss: 9.3310, F1 Micro: 0.7083, F1 Macro: 0.5872, Accuracy: 0.7083\n","Epoch 37, Train Loss: 7.4417, Val Loss: 7.7455, F1 Micro: 0.6458, F1 Macro: 0.5620, Accuracy: 0.6458\n","Epoch 38, Train Loss: 3.3084, Val Loss: 2.4614, F1 Micro: 0.7917, F1 Macro: 0.5551, Accuracy: 0.7917\n","Epoch 39, Train Loss: 2.2037, Val Loss: 0.3164, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 40, Train Loss: 8.0272, Val Loss: 1.8659, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 41, Train Loss: 5.6617, Val Loss: 0.3103, F1 Micro: 0.9479, F1 Macro: 0.8540, Accuracy: 0.9479\n","Epoch 42, Train Loss: 1.4986, Val Loss: 0.9813, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 43, Train Loss: 2.3012, Val Loss: 3.3166, F1 Micro: 0.7812, F1 Macro: 0.6621, Accuracy: 0.7812\n","Epoch 44, Train Loss: 4.6310, Val Loss: 0.7084, F1 Micro: 0.9167, F1 Macro: 0.7273, Accuracy: 0.9167\n","Epoch 45, Train Loss: 1.8344, Val Loss: 0.5022, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 46, Train Loss: 1.6084, Val Loss: 0.4030, F1 Micro: 0.9167, F1 Macro: 0.7947, Accuracy: 0.9167\n","Epoch 47, Train Loss: 2.4395, Val Loss: 3.6504, F1 Micro: 0.7396, F1 Macro: 0.6123, Accuracy: 0.7396\n","Epoch 48, Train Loss: 1.8451, Val Loss: 0.1384, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 49, Train Loss: 5.0640, Val Loss: 3.4321, F1 Micro: 0.7604, F1 Macro: 0.6554, Accuracy: 0.7604\n","Epoch 50, Train Loss: 6.5882, Val Loss: 9.9534, F1 Micro: 0.6354, F1 Macro: 0.5541, Accuracy: 0.6354\n","Epoch 51, Train Loss: 8.3553, Val Loss: 1.4783, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 52, Train Loss: 1.5753, Val Loss: 0.1724, F1 Micro: 0.9479, F1 Macro: 0.8540, Accuracy: 0.9479\n","Epoch 53, Train Loss: 3.2632, Val Loss: 0.2626, F1 Micro: 0.9479, F1 Macro: 0.8540, Accuracy: 0.9479\n","Epoch 54, Train Loss: 3.2478, Val Loss: 8.0370, F1 Micro: 0.5521, F1 Macro: 0.4834, Accuracy: 0.5521\n","Epoch 55, Train Loss: 5.4486, Val Loss: 1.0880, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 56, Train Loss: 1.5628, Val Loss: 3.8911, F1 Micro: 0.7604, F1 Macro: 0.5982, Accuracy: 0.7604\n","Epoch 57, Train Loss: 0.8175, Val Loss: 0.3516, F1 Micro: 0.9375, F1 Macro: 0.7955, Accuracy: 0.9375\n","Epoch 58, Train Loss: 2.9738, Val Loss: 0.3457, F1 Micro: 0.9375, F1 Macro: 0.8665, Accuracy: 0.9375\n","Epoch 59, Train Loss: 3.5486, Val Loss: 4.2864, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 60, Train Loss: 2.6171, Val Loss: 0.4078, F1 Micro: 0.9375, F1 Macro: 0.8326, Accuracy: 0.9375\n","Epoch 61, Train Loss: 3.8047, Val Loss: 12.0085, F1 Micro: 0.7188, F1 Macro: 0.5813, Accuracy: 0.7188\n","Epoch 62, Train Loss: 11.0258, Val Loss: 13.3552, F1 Micro: 0.8646, F1 Macro: 0.5805, Accuracy: 0.8646\n","Epoch 63, Train Loss: 5.9571, Val Loss: 2.2681, F1 Micro: 0.8229, F1 Macro: 0.7265, Accuracy: 0.8229\n","Epoch 64, Train Loss: 2.9476, Val Loss: 1.2349, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 65, Train Loss: 2.6050, Val Loss: 1.6032, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 66, Train Loss: 9.7355, Val Loss: 8.7178, F1 Micro: 0.6875, F1 Macro: 0.5833, Accuracy: 0.6875\n","Epoch 67, Train Loss: 8.7340, Val Loss: 2.5872, F1 Micro: 0.8125, F1 Macro: 0.5380, Accuracy: 0.8125\n","Epoch 68, Train Loss: 2.4393, Val Loss: 0.4428, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 69, Train Loss: 2.5058, Val Loss: 1.0590, F1 Micro: 0.8646, F1 Macro: 0.7729, Accuracy: 0.8646\n","Epoch 70, Train Loss: 2.2742, Val Loss: 0.2256, F1 Micro: 0.9375, F1 Macro: 0.8571, Accuracy: 0.9375\n","Epoch 71, Train Loss: 4.5421, Val Loss: 11.1904, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 72, Train Loss: 24.3603, Val Loss: 5.6817, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 73, Train Loss: 2.8948, Val Loss: 2.3326, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 74, Train Loss: 5.6734, Val Loss: 3.1549, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 75, Train Loss: 2.4009, Val Loss: 1.0730, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 76, Train Loss: 3.1935, Val Loss: 0.5033, F1 Micro: 0.9271, F1 Macro: 0.7741, Accuracy: 0.9271\n","Epoch 77, Train Loss: 7.2990, Val Loss: 2.8672, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 78, Train Loss: 11.4183, Val Loss: 1.7754, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 79, Train Loss: 2.1275, Val Loss: 1.0717, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 80, Train Loss: 1.3211, Val Loss: 2.2713, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 81, Train Loss: 2.0913, Val Loss: 1.3623, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 82, Train Loss: 3.9880, Val Loss: 4.6459, F1 Micro: 0.8021, F1 Macro: 0.6681, Accuracy: 0.8021\n","Epoch 83, Train Loss: 3.4709, Val Loss: 2.7110, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 84, Train Loss: 10.2979, Val Loss: 5.3917, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 85, Train Loss: 14.9791, Val Loss: 3.2681, F1 Micro: 0.8333, F1 Macro: 0.7141, Accuracy: 0.8333\n","Epoch 86, Train Loss: 11.2684, Val Loss: 4.9411, F1 Micro: 0.8646, F1 Macro: 0.6789, Accuracy: 0.8646\n","Epoch 87, Train Loss: 3.9897, Val Loss: 0.2447, F1 Micro: 0.9688, F1 Macro: 0.9259, Accuracy: 0.9688\n","Epoch 88, Train Loss: 2.5177, Val Loss: 3.4670, F1 Micro: 0.8229, F1 Macro: 0.7030, Accuracy: 0.8229\n","Epoch 89, Train Loss: 7.0936, Val Loss: 0.6539, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 90, Train Loss: 5.8261, Val Loss: 0.2523, F1 Micro: 0.9688, F1 Macro: 0.9198, Accuracy: 0.9688\n","Epoch 91, Train Loss: 2.1230, Val Loss: 1.6864, F1 Micro: 0.8854, F1 Macro: 0.7630, Accuracy: 0.8854\n","Epoch 92, Train Loss: 3.9625, Val Loss: 25.0351, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 93, Train Loss: 7.1813, Val Loss: 0.9191, F1 Micro: 0.9062, F1 Macro: 0.7096, Accuracy: 0.9062\n","Epoch 94, Train Loss: 3.8403, Val Loss: 4.2002, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 95, Train Loss: 7.0980, Val Loss: 2.2517, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 96, Train Loss: 5.6800, Val Loss: 4.3018, F1 Micro: 0.8021, F1 Macro: 0.6820, Accuracy: 0.8021\n","Epoch 97, Train Loss: 2.9582, Val Loss: 0.4669, F1 Micro: 0.9375, F1 Macro: 0.8460, Accuracy: 0.9375\n","Epoch 98, Train Loss: 2.1809, Val Loss: 2.8030, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 99, Train Loss: 8.1318, Val Loss: 5.4758, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 100, Train Loss: 14.6952, Val Loss: 5.4032, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 101, Train Loss: 4.0460, Val Loss: 1.3850, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 102, Train Loss: 1.3687, Val Loss: 1.6170, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 103, Train Loss: 1.4893, Val Loss: 0.7377, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 104, Train Loss: 12.1325, Val Loss: 8.7345, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 105, Train Loss: 13.9600, Val Loss: 0.6705, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 106, Train Loss: 1.6693, Val Loss: 0.4811, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 107, Train Loss: 2.0524, Val Loss: 1.7754, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 108, Train Loss: 1.4314, Val Loss: 2.4885, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 109, Train Loss: 4.3797, Val Loss: 1.4445, F1 Micro: 0.9062, F1 Macro: 0.6287, Accuracy: 0.9062\n","Epoch 110, Train Loss: 11.0400, Val Loss: 3.0349, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 111, Train Loss: 7.9391, Val Loss: 5.4366, F1 Micro: 0.7188, F1 Macro: 0.6301, Accuracy: 0.7188\n","Epoch 112, Train Loss: 3.4600, Val Loss: 2.0967, F1 Micro: 0.8542, F1 Macro: 0.7607, Accuracy: 0.8542\n","Epoch 113, Train Loss: 5.0256, Val Loss: 7.0997, F1 Micro: 0.6250, F1 Macro: 0.5553, Accuracy: 0.6250\n","Epoch 114, Train Loss: 1.5223, Val Loss: 0.7311, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 115, Train Loss: 0.9037, Val Loss: 0.8812, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 116, Train Loss: 4.8243, Val Loss: 0.2556, F1 Micro: 0.9583, F1 Macro: 0.8774, Accuracy: 0.9583\n","Epoch 117, Train Loss: 3.4863, Val Loss: 10.3583, F1 Micro: 0.5521, F1 Macro: 0.4999, Accuracy: 0.5521\n","Epoch 118, Train Loss: 2.2251, Val Loss: 0.7473, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 119, Train Loss: 5.7499, Val Loss: 5.4894, F1 Micro: 0.7708, F1 Macro: 0.6648, Accuracy: 0.7708\n","Epoch 120, Train Loss: 2.4396, Val Loss: 0.5912, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 121, Train Loss: 3.7932, Val Loss: 1.0964, F1 Micro: 0.9271, F1 Macro: 0.7741, Accuracy: 0.9271\n","Epoch 122, Train Loss: 2.0840, Val Loss: 0.6936, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 123, Train Loss: 4.3173, Val Loss: 0.5405, F1 Micro: 0.9375, F1 Macro: 0.7955, Accuracy: 0.9375\n","Epoch 124, Train Loss: 1.9723, Val Loss: 0.2822, F1 Micro: 0.9688, F1 Macro: 0.9198, Accuracy: 0.9688\n","Epoch 125, Train Loss: 1.5226, Val Loss: 0.9559, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 126, Train Loss: 1.3074, Val Loss: 0.8782, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 127, Train Loss: 3.0301, Val Loss: 2.6902, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 128, Train Loss: 4.4600, Val Loss: 0.3855, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 129, Train Loss: 1.5810, Val Loss: 2.7412, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 130, Train Loss: 1.4485, Val Loss: 0.5196, F1 Micro: 0.9271, F1 Macro: 0.8271, Accuracy: 0.9271\n","Epoch 131, Train Loss: 1.1534, Val Loss: 0.5963, F1 Micro: 0.9479, F1 Macro: 0.8540, Accuracy: 0.9479\n","Epoch 132, Train Loss: 2.3059, Val Loss: 1.3516, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 133, Train Loss: 2.5572, Val Loss: 1.2446, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 134, Train Loss: 4.8214, Val Loss: 3.0450, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 135, Train Loss: 6.9814, Val Loss: 0.7490, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 136, Train Loss: 7.1494, Val Loss: 3.3509, F1 Micro: 0.8438, F1 Macro: 0.7256, Accuracy: 0.8438\n","Epoch 137, Train Loss: 6.9463, Val Loss: 7.8692, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 391.7073, Val Loss: 43.2476, F1 Micro: 0.2292, F1 Macro: 0.2261, Accuracy: 0.2292\n","Epoch 2, Train Loss: 166.8164, Val Loss: 450.2640, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 3, Train Loss: 187.2055, Val Loss: 92.5285, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 185.4902, Val Loss: 213.5051, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 5, Train Loss: 232.6752, Val Loss: 202.8685, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 6, Train Loss: 128.1044, Val Loss: 68.9281, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 7, Train Loss: 53.6900, Val Loss: 51.7827, F1 Micro: 0.2917, F1 Macro: 0.2804, Accuracy: 0.2917\n","Epoch 8, Train Loss: 117.2116, Val Loss: 129.4793, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 9, Train Loss: 119.3676, Val Loss: 36.4526, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 10, Train Loss: 55.5676, Val Loss: 3.0643, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 11, Train Loss: 29.9307, Val Loss: 19.5637, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 12, Train Loss: 44.9184, Val Loss: 8.1118, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 13, Train Loss: 52.2273, Val Loss: 143.9868, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 14, Train Loss: 80.2117, Val Loss: 17.9187, F1 Micro: 0.7188, F1 Macro: 0.5283, Accuracy: 0.7188\n","Epoch 15, Train Loss: 57.4864, Val Loss: 55.3478, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 16, Train Loss: 23.5751, Val Loss: 41.2995, F1 Micro: 0.1771, F1 Macro: 0.1763, Accuracy: 0.1771\n","Epoch 17, Train Loss: 23.7436, Val Loss: 26.4223, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 18, Train Loss: 15.2848, Val Loss: 10.0578, F1 Micro: 0.4792, F1 Macro: 0.4228, Accuracy: 0.4792\n","Epoch 19, Train Loss: 12.4296, Val Loss: 24.2235, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 20, Train Loss: 27.9560, Val Loss: 25.4891, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 21, Train Loss: 43.7957, Val Loss: 43.7344, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 22, Train Loss: 36.7171, Val Loss: 3.9674, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 23, Train Loss: 12.0438, Val Loss: 5.8244, F1 Micro: 0.4271, F1 Macro: 0.3983, Accuracy: 0.4271\n","Epoch 24, Train Loss: 14.0942, Val Loss: 13.9396, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 25, Train Loss: 22.7988, Val Loss: 7.4383, F1 Micro: 0.7500, F1 Macro: 0.5500, Accuracy: 0.7500\n","Epoch 26, Train Loss: 16.1806, Val Loss: 17.1731, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 27, Train Loss: 8.5635, Val Loss: 8.9981, F1 Micro: 0.3333, F1 Macro: 0.3228, Accuracy: 0.3333\n","Epoch 28, Train Loss: 13.4106, Val Loss: 14.9977, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 29, Train Loss: 17.4651, Val Loss: 16.1361, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 30, Train Loss: 12.1660, Val Loss: 3.9977, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 31, Train Loss: 5.8465, Val Loss: 2.9862, F1 Micro: 0.7812, F1 Macro: 0.6485, Accuracy: 0.7812\n","Epoch 32, Train Loss: 5.7047, Val Loss: 2.3968, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 33, Train Loss: 10.8901, Val Loss: 2.0422, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 34, Train Loss: 2.9883, Val Loss: 14.5519, F1 Micro: 0.7500, F1 Macro: 0.5259, Accuracy: 0.7500\n","Epoch 35, Train Loss: 15.2513, Val Loss: 6.1855, F1 Micro: 0.4896, F1 Macro: 0.4457, Accuracy: 0.4896\n","Epoch 36, Train Loss: 3.4471, Val Loss: 1.3819, F1 Micro: 0.8646, F1 Macro: 0.7499, Accuracy: 0.8646\n","Epoch 37, Train Loss: 1.5614, Val Loss: 0.3476, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 38, Train Loss: 2.3708, Val Loss: 0.3490, F1 Micro: 0.9375, F1 Macro: 0.7689, Accuracy: 0.9375\n","Epoch 39, Train Loss: 3.6677, Val Loss: 5.0353, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 40, Train Loss: 4.7172, Val Loss: 1.1450, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 41, Train Loss: 4.1449, Val Loss: 2.7965, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 42, Train Loss: 3.9698, Val Loss: 3.6519, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 43, Train Loss: 2.0491, Val Loss: 2.4374, F1 Micro: 0.7292, F1 Macro: 0.6167, Accuracy: 0.7292\n","Epoch 44, Train Loss: 6.6122, Val Loss: 5.5835, F1 Micro: 0.6042, F1 Macro: 0.5210, Accuracy: 0.6042\n","Epoch 45, Train Loss: 3.8226, Val Loss: 3.5112, F1 Micro: 0.7708, F1 Macro: 0.6391, Accuracy: 0.7708\n","Epoch 46, Train Loss: 4.0135, Val Loss: 6.2010, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 47, Train Loss: 5.9521, Val Loss: 3.4737, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 48, Train Loss: 5.9947, Val Loss: 7.5350, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 49, Train Loss: 3.2458, Val Loss: 0.6411, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 50, Train Loss: 1.3833, Val Loss: 0.9124, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 51, Train Loss: 2.0781, Val Loss: 5.6370, F1 Micro: 0.7292, F1 Macro: 0.5895, Accuracy: 0.7292\n","Epoch 52, Train Loss: 6.1895, Val Loss: 9.3125, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 53, Train Loss: 3.7672, Val Loss: 0.5377, F1 Micro: 0.9062, F1 Macro: 0.5660, Accuracy: 0.9062\n","Epoch 54, Train Loss: 5.6688, Val Loss: 9.7089, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 55, Train Loss: 8.8573, Val Loss: 15.3806, F1 Micro: 0.7500, F1 Macro: 0.5500, Accuracy: 0.7500\n","Epoch 56, Train Loss: 10.1023, Val Loss: 1.5561, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 57, Train Loss: 7.0076, Val Loss: 11.6799, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 58, Train Loss: 4.8951, Val Loss: 22.2945, F1 Micro: 0.6771, F1 Macro: 0.5355, Accuracy: 0.6771\n","Epoch 59, Train Loss: 4.7123, Val Loss: 2.4499, F1 Micro: 0.8125, F1 Macro: 0.6625, Accuracy: 0.8125\n","Epoch 60, Train Loss: 3.0911, Val Loss: 14.8256, F1 Micro: 0.6146, F1 Macro: 0.5060, Accuracy: 0.6146\n","Epoch 61, Train Loss: 4.5103, Val Loss: 4.3131, F1 Micro: 0.6146, F1 Macro: 0.5384, Accuracy: 0.6146\n","Epoch 62, Train Loss: 2.5257, Val Loss: 13.2455, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 63, Train Loss: 9.1070, Val Loss: 9.3641, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 64, Train Loss: 7.3199, Val Loss: 1.4080, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 65, Train Loss: 1.7223, Val Loss: 1.2445, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 66, Train Loss: 3.5584, Val Loss: 1.1051, F1 Micro: 0.9062, F1 Macro: 0.5660, Accuracy: 0.9062\n","Epoch 67, Train Loss: 3.3177, Val Loss: 1.0120, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 68, Train Loss: 1.4527, Val Loss: 1.2719, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 69, Train Loss: 2.9137, Val Loss: 2.5997, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 70, Train Loss: 1.1634, Val Loss: 0.4355, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 71, Train Loss: 1.8927, Val Loss: 0.7264, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 72, Train Loss: 2.9416, Val Loss: 4.6181, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 73, Train Loss: 10.1135, Val Loss: 2.8970, F1 Micro: 0.7188, F1 Macro: 0.6197, Accuracy: 0.7188\n","Epoch 74, Train Loss: 7.8309, Val Loss: 0.8356, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 75, Train Loss: 2.0374, Val Loss: 1.6780, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 76, Train Loss: 2.1909, Val Loss: 3.2104, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 77, Train Loss: 4.3487, Val Loss: 5.4268, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 78, Train Loss: 7.4628, Val Loss: 13.1763, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 79, Train Loss: 9.1707, Val Loss: 7.9776, F1 Micro: 0.7396, F1 Macro: 0.5978, Accuracy: 0.7396\n","Epoch 80, Train Loss: 5.3460, Val Loss: 3.2504, F1 Micro: 0.7188, F1 Macro: 0.6197, Accuracy: 0.7188\n","Epoch 81, Train Loss: 1.8468, Val Loss: 6.1598, F1 Micro: 0.7812, F1 Macro: 0.6331, Accuracy: 0.7812\n","Epoch 82, Train Loss: 8.0538, Val Loss: 7.3149, F1 Micro: 0.8750, F1 Macro: 0.5377, Accuracy: 0.8750\n","Epoch 83, Train Loss: 4.9138, Val Loss: 1.7954, F1 Micro: 0.8125, F1 Macro: 0.7047, Accuracy: 0.8125\n","Epoch 84, Train Loss: 6.4452, Val Loss: 3.3321, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 85, Train Loss: 2.7250, Val Loss: 2.6606, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 86, Train Loss: 1.5248, Val Loss: 12.3201, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 87, Train Loss: 13.5221, Val Loss: 17.3342, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 88, Train Loss: 5.0509, Val Loss: 2.7074, F1 Micro: 0.8958, F1 Macro: 0.5556, Accuracy: 0.8958\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 674.1968, Val Loss: 773.7778, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 158.4544, Val Loss: 64.7467, F1 Micro: 0.7500, F1 Macro: 0.4983, Accuracy: 0.7500\n","Epoch 3, Train Loss: 128.2894, Val Loss: 213.7650, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 117.3507, Val Loss: 22.7029, F1 Micro: 0.4583, F1 Macro: 0.4155, Accuracy: 0.4583\n","Epoch 5, Train Loss: 93.5328, Val Loss: 99.1699, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 6, Train Loss: 91.4289, Val Loss: 99.8929, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 7, Train Loss: 60.5077, Val Loss: 27.4387, F1 Micro: 0.7083, F1 Macro: 0.5579, Accuracy: 0.7083\n","Epoch 8, Train Loss: 118.0494, Val Loss: 58.6559, F1 Micro: 0.7188, F1 Macro: 0.5060, Accuracy: 0.7188\n","Epoch 9, Train Loss: 48.3109, Val Loss: 41.8735, F1 Micro: 0.7396, F1 Macro: 0.4923, Accuracy: 0.7396\n","Epoch 10, Train Loss: 28.2140, Val Loss: 23.1676, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 11, Train Loss: 28.0522, Val Loss: 58.8451, F1 Micro: 0.2500, F1 Macro: 0.2487, Accuracy: 0.2500\n","Epoch 12, Train Loss: 25.9485, Val Loss: 15.8801, F1 Micro: 0.7083, F1 Macro: 0.5579, Accuracy: 0.7083\n","Epoch 13, Train Loss: 30.6822, Val Loss: 53.2210, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 14, Train Loss: 30.6214, Val Loss: 23.9880, F1 Micro: 0.6771, F1 Macro: 0.5355, Accuracy: 0.6771\n","Epoch 15, Train Loss: 14.9785, Val Loss: 27.3133, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 16, Train Loss: 13.1188, Val Loss: 0.6222, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 17, Train Loss: 9.9183, Val Loss: 11.4448, F1 Micro: 0.6458, F1 Macro: 0.5403, Accuracy: 0.6458\n","Epoch 18, Train Loss: 18.9569, Val Loss: 45.5702, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 19, Train Loss: 33.9375, Val Loss: 2.9929, F1 Micro: 0.7396, F1 Macro: 0.6372, Accuracy: 0.7396\n","Epoch 20, Train Loss: 8.5864, Val Loss: 7.8075, F1 Micro: 0.7396, F1 Macro: 0.5815, Accuracy: 0.7396\n","Epoch 21, Train Loss: 6.4440, Val Loss: 7.3191, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 22, Train Loss: 13.5494, Val Loss: 20.8886, F1 Micro: 0.3229, F1 Macro: 0.3211, Accuracy: 0.3229\n","Epoch 23, Train Loss: 16.6449, Val Loss: 13.6995, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 24, Train Loss: 9.3438, Val Loss: 8.6904, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 25, Train Loss: 8.9331, Val Loss: 3.9248, F1 Micro: 0.7708, F1 Macro: 0.6391, Accuracy: 0.7708\n","Epoch 26, Train Loss: 10.0589, Val Loss: 13.9850, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 27, Train Loss: 7.8118, Val Loss: 20.0867, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 28, Train Loss: 10.7148, Val Loss: 1.4054, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 29, Train Loss: 1.9020, Val Loss: 5.0338, F1 Micro: 0.5729, F1 Macro: 0.5418, Accuracy: 0.5729\n","Epoch 30, Train Loss: 10.6938, Val Loss: 4.1428, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 31, Train Loss: 9.8474, Val Loss: 14.4972, F1 Micro: 0.6771, F1 Macro: 0.5501, Accuracy: 0.6771\n","Epoch 32, Train Loss: 7.3366, Val Loss: 1.4268, F1 Micro: 0.7708, F1 Macro: 0.7099, Accuracy: 0.7708\n","Epoch 33, Train Loss: 11.1012, Val Loss: 11.9508, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Epoch 34, Train Loss: 9.5152, Val Loss: 46.6611, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 35, Train Loss: 20.8640, Val Loss: 22.8105, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 36, Train Loss: 4.0670, Val Loss: 2.3271, F1 Micro: 0.8229, F1 Macro: 0.7453, Accuracy: 0.8229\n","Epoch 37, Train Loss: 4.2585, Val Loss: 1.5193, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 38, Train Loss: 5.7209, Val Loss: 1.8936, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 39, Train Loss: 1.2994, Val Loss: 5.6233, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 40, Train Loss: 3.4707, Val Loss: 24.5758, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 41, Train Loss: 11.1083, Val Loss: 6.4560, F1 Micro: 0.8646, F1 Macro: 0.7011, Accuracy: 0.8646\n","Epoch 42, Train Loss: 4.5543, Val Loss: 2.9791, F1 Micro: 0.7292, F1 Macro: 0.6723, Accuracy: 0.7292\n","Epoch 43, Train Loss: 3.0838, Val Loss: 1.5681, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 44, Train Loss: 2.8113, Val Loss: 8.9205, F1 Micro: 0.7396, F1 Macro: 0.6254, Accuracy: 0.7396\n","Epoch 45, Train Loss: 7.3047, Val Loss: 14.1179, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 46, Train Loss: 3.0144, Val Loss: 3.2438, F1 Micro: 0.8854, F1 Macro: 0.7630, Accuracy: 0.8854\n","Epoch 47, Train Loss: 1.2429, Val Loss: 0.4400, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 48, Train Loss: 1.3918, Val Loss: 3.5216, F1 Micro: 0.8438, F1 Macro: 0.7256, Accuracy: 0.8438\n","Epoch 49, Train Loss: 1.9226, Val Loss: 1.3095, F1 Micro: 0.8333, F1 Macro: 0.7641, Accuracy: 0.8333\n","Epoch 50, Train Loss: 6.7245, Val Loss: 0.8323, F1 Micro: 0.9062, F1 Macro: 0.7931, Accuracy: 0.9062\n","Epoch 51, Train Loss: 8.8738, Val Loss: 5.5580, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 52, Train Loss: 3.4090, Val Loss: 0.7713, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 53, Train Loss: 1.7547, Val Loss: 4.3562, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 54, Train Loss: 1.7972, Val Loss: 1.2301, F1 Micro: 0.9062, F1 Macro: 0.7931, Accuracy: 0.9062\n","Epoch 55, Train Loss: 8.3014, Val Loss: 0.7823, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 56, Train Loss: 2.4615, Val Loss: 4.7894, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 57, Train Loss: 3.9229, Val Loss: 0.2770, F1 Micro: 0.9375, F1 Macro: 0.8815, Accuracy: 0.9375\n","Epoch 58, Train Loss: 1.3611, Val Loss: 1.1240, F1 Micro: 0.8854, F1 Macro: 0.8230, Accuracy: 0.8854\n","Epoch 59, Train Loss: 6.9822, Val Loss: 7.2416, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 60, Train Loss: 11.8204, Val Loss: 0.4289, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 61, Train Loss: 7.0640, Val Loss: 4.2430, F1 Micro: 0.7292, F1 Macro: 0.6723, Accuracy: 0.7292\n","Epoch 62, Train Loss: 4.0299, Val Loss: 0.9594, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 63, Train Loss: 9.3813, Val Loss: 6.1585, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 64, Train Loss: 5.0949, Val Loss: 6.8504, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 65, Train Loss: 1.7009, Val Loss: 3.3217, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 66, Train Loss: 0.8082, Val Loss: 0.3780, F1 Micro: 0.9375, F1 Macro: 0.8815, Accuracy: 0.9375\n","Epoch 67, Train Loss: 1.6523, Val Loss: 3.5421, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 68, Train Loss: 4.9619, Val Loss: 2.8468, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 69, Train Loss: 5.9771, Val Loss: 20.6248, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 70, Train Loss: 14.9628, Val Loss: 16.1214, F1 Micro: 0.5208, F1 Macro: 0.4763, Accuracy: 0.5208\n","Epoch 71, Train Loss: 11.5040, Val Loss: 1.4249, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 72, Train Loss: 1.7601, Val Loss: 1.0843, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 73, Train Loss: 1.2263, Val Loss: 4.6350, F1 Micro: 0.8125, F1 Macro: 0.7047, Accuracy: 0.8125\n","Epoch 74, Train Loss: 2.0665, Val Loss: 0.8104, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 75, Train Loss: 1.0889, Val Loss: 0.6095, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 76, Train Loss: 7.9261, Val Loss: 0.9107, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 77, Train Loss: 2.7315, Val Loss: 10.9854, F1 Micro: 0.7708, F1 Macro: 0.6069, Accuracy: 0.7708\n","Epoch 78, Train Loss: 6.5063, Val Loss: 5.4084, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 79, Train Loss: 2.2096, Val Loss: 1.5079, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 80, Train Loss: 5.7164, Val Loss: 4.8779, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 81, Train Loss: 1.6967, Val Loss: 3.6602, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 82, Train Loss: 2.9684, Val Loss: 1.7889, F1 Micro: 0.8750, F1 Macro: 0.8105, Accuracy: 0.8750\n","Epoch 83, Train Loss: 2.0698, Val Loss: 1.7463, F1 Micro: 0.9167, F1 Macro: 0.8570, Accuracy: 0.9167\n","Epoch 84, Train Loss: 9.0654, Val Loss: 34.9688, F1 Micro: 0.4583, F1 Macro: 0.4386, Accuracy: 0.4583\n","Epoch 85, Train Loss: 32.9520, Val Loss: 150.3448, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 86, Train Loss: 18.3890, Val Loss: 7.8010, F1 Micro: 0.5833, F1 Macro: 0.5504, Accuracy: 0.5833\n","Epoch 87, Train Loss: 6.0300, Val Loss: 8.8540, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 88, Train Loss: 3.5112, Val Loss: 2.1205, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 89, Train Loss: 2.2314, Val Loss: 3.6103, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 90, Train Loss: 2.6070, Val Loss: 2.5957, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 91, Train Loss: 5.3757, Val Loss: 0.9847, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 92, Train Loss: 4.0964, Val Loss: 1.0912, F1 Micro: 0.9062, F1 Macro: 0.8493, Accuracy: 0.9062\n","Epoch 93, Train Loss: 1.2093, Val Loss: 0.5915, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 94, Train Loss: 6.1661, Val Loss: 12.1186, F1 Micro: 0.6875, F1 Macro: 0.6044, Accuracy: 0.6875\n","Epoch 95, Train Loss: 3.2605, Val Loss: 0.9852, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 96, Train Loss: 3.8842, Val Loss: 2.0207, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 97, Train Loss: 5.8246, Val Loss: 68.1906, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 98, Train Loss: 5.5894, Val Loss: 2.4609, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 99, Train Loss: 1.9745, Val Loss: 4.5889, F1 Micro: 0.8542, F1 Macro: 0.7498, Accuracy: 0.8542\n","Epoch 100, Train Loss: 8.8344, Val Loss: 0.9256, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 101, Train Loss: 1.8460, Val Loss: 3.9004, F1 Micro: 0.8125, F1 Macro: 0.7427, Accuracy: 0.8125\n","Epoch 102, Train Loss: 4.5378, Val Loss: 1.0408, F1 Micro: 0.9062, F1 Macro: 0.7931, Accuracy: 0.9062\n","Epoch 103, Train Loss: 4.6183, Val Loss: 2.5497, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 104, Train Loss: 11.6539, Val Loss: 7.3237, F1 Micro: 0.6562, F1 Macro: 0.6036, Accuracy: 0.6562\n","Epoch 105, Train Loss: 13.2534, Val Loss: 1.0200, F1 Micro: 0.9062, F1 Macro: 0.8493, Accuracy: 0.9062\n","Epoch 106, Train Loss: 2.8369, Val Loss: 1.7304, F1 Micro: 0.9271, F1 Macro: 0.8777, Accuracy: 0.9271\n","Epoch 107, Train Loss: 1.3946, Val Loss: 1.2286, F1 Micro: 0.9375, F1 Macro: 0.8875, Accuracy: 0.9375\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.9479166666666667\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 461.6864, Val Loss: 389.7750, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 319.1411, Val Loss: 170.6796, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 3, Train Loss: 188.7707, Val Loss: 564.0086, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 281.3170, Val Loss: 208.4304, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 5, Train Loss: 100.5975, Val Loss: 47.1174, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 6, Train Loss: 103.6129, Val Loss: 39.6357, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 7, Train Loss: 43.5345, Val Loss: 20.7113, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 8, Train Loss: 146.4718, Val Loss: 192.0727, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 9, Train Loss: 160.2756, Val Loss: 53.9270, F1 Micro: 0.3542, F1 Macro: 0.3539, Accuracy: 0.3542\n","Epoch 10, Train Loss: 42.2819, Val Loss: 90.7970, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 72.9803, Val Loss: 72.0742, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 550.5690, Val Loss: 310.8934, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 183.7740, Val Loss: 117.1100, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 102.0039, Val Loss: 87.7551, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 4, Train Loss: 183.1514, Val Loss: 81.0768, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 5, Train Loss: 158.7546, Val Loss: 499.8839, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 205.3271, Val Loss: 23.0516, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 7, Train Loss: 36.2680, Val Loss: 63.0735, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 8, Train Loss: 50.4025, Val Loss: 30.7304, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 9, Train Loss: 61.0147, Val Loss: 33.6995, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 10, Train Loss: 48.6765, Val Loss: 37.0208, F1 Micro: 0.3333, F1 Macro: 0.3307, Accuracy: 0.3333\n","Epoch 11, Train Loss: 56.6830, Val Loss: 114.2175, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 465.0448, Val Loss: 19.8045, F1 Micro: 0.5104, F1 Macro: 0.4534, Accuracy: 0.5104\n","Epoch 2, Train Loss: 37.3998, Val Loss: 106.5929, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 152.6980, Val Loss: 215.4195, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 4, Train Loss: 211.6133, Val Loss: 110.2024, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 80.8647, Val Loss: 73.2173, F1 Micro: 0.2292, F1 Macro: 0.2292, Accuracy: 0.2292\n","Epoch 6, Train Loss: 78.3559, Val Loss: 29.0629, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 7, Train Loss: 70.8206, Val Loss: 8.3511, F1 Micro: 0.7292, F1 Macro: 0.5125, Accuracy: 0.7292\n","Epoch 8, Train Loss: 83.3394, Val Loss: 141.9666, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 70.3336, Val Loss: 98.5847, F1 Micro: 0.1250, F1 Macro: 0.1154, Accuracy: 0.1250\n","Epoch 10, Train Loss: 74.5750, Val Loss: 149.2919, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 11, Train Loss: 76.2452, Val Loss: 95.0238, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 12, Train Loss: 52.4081, Val Loss: 9.0866, F1 Micro: 0.5938, F1 Macro: 0.5135, Accuracy: 0.5938\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 786.6748, Val Loss: 27.6002, F1 Micro: 0.2812, F1 Macro: 0.2717, Accuracy: 0.2812\n","Epoch 2, Train Loss: 289.9266, Val Loss: 237.3443, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 3, Train Loss: 104.0646, Val Loss: 44.6863, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 4, Train Loss: 52.2158, Val Loss: 157.3833, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 5, Train Loss: 109.6976, Val Loss: 82.5840, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 6, Train Loss: 84.9942, Val Loss: 97.1021, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 7, Train Loss: 130.3920, Val Loss: 46.3500, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 8, Train Loss: 106.3864, Val Loss: 145.9067, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 9, Train Loss: 99.1693, Val Loss: 59.9770, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 10, Train Loss: 36.3412, Val Loss: 37.2462, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 11, Train Loss: 26.2482, Val Loss: 112.8261, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 12, Train Loss: 118.7517, Val Loss: 40.9867, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 627.4892, Val Loss: 30.5525, F1 Micro: 0.7083, F1 Macro: 0.4996, Accuracy: 0.7083\n","Epoch 2, Train Loss: 278.9612, Val Loss: 677.4774, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 281.2414, Val Loss: 232.0345, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 228.8058, Val Loss: 229.2827, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 42.9924, Val Loss: 27.8091, F1 Micro: 0.5938, F1 Macro: 0.4793, Accuracy: 0.5938\n","Epoch 6, Train Loss: 70.8447, Val Loss: 73.9421, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 7, Train Loss: 39.3714, Val Loss: 24.2961, F1 Micro: 0.3750, F1 Macro: 0.3614, Accuracy: 0.3750\n","Epoch 8, Train Loss: 50.2501, Val Loss: 53.0107, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 9, Train Loss: 44.9568, Val Loss: 43.7649, F1 Micro: 0.2188, F1 Macro: 0.2118, Accuracy: 0.2188\n","Epoch 10, Train Loss: 42.3750, Val Loss: 28.5928, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 11, Train Loss: 36.7781, Val Loss: 69.7043, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 12, Train Loss: 38.7329, Val Loss: 159.3846, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.8583333333333332\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 673.2822, Val Loss: 338.0746, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 519.3754, Val Loss: 466.3523, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 180.4817, Val Loss: 245.7664, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 4, Train Loss: 127.5389, Val Loss: 15.5451, F1 Micro: 0.5521, F1 Macro: 0.5248, Accuracy: 0.5521\n","Epoch 5, Train Loss: 27.0530, Val Loss: 185.1449, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 208.9928, Val Loss: 303.2676, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 140.4606, Val Loss: 166.0868, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 8, Train Loss: 107.9304, Val Loss: 164.0390, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 9, Train Loss: 116.1800, Val Loss: 131.2701, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 130.1571, Val Loss: 114.6679, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 11, Train Loss: 33.6462, Val Loss: 112.3313, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 60.3831, Val Loss: 102.2210, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 53.5430, Val Loss: 107.1325, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 14, Train Loss: 59.9372, Val Loss: 304.9720, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 15, Train Loss: 85.3375, Val Loss: 31.2190, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 16, Train Loss: 23.6378, Val Loss: 17.7592, F1 Micro: 0.5417, F1 Macro: 0.5163, Accuracy: 0.5417\n","Epoch 17, Train Loss: 26.5658, Val Loss: 43.3855, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 18, Train Loss: 38.2450, Val Loss: 86.6575, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 19, Train Loss: 48.5002, Val Loss: 110.5834, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 20, Train Loss: 36.5246, Val Loss: 19.2503, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 21, Train Loss: 32.4223, Val Loss: 43.9567, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 22, Train Loss: 68.6761, Val Loss: 9.9458, F1 Micro: 0.7396, F1 Macro: 0.6575, Accuracy: 0.7396\n","Epoch 23, Train Loss: 58.5473, Val Loss: 45.2876, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 24, Train Loss: 53.4502, Val Loss: 95.4736, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 25, Train Loss: 28.9994, Val Loss: 19.8610, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 26, Train Loss: 14.8367, Val Loss: 23.1127, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 27, Train Loss: 16.7684, Val Loss: 37.6138, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 28, Train Loss: 18.4888, Val Loss: 24.7848, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 29, Train Loss: 10.6464, Val Loss: 11.1904, F1 Micro: 0.4062, F1 Macro: 0.4057, Accuracy: 0.4062\n","Epoch 30, Train Loss: 7.2499, Val Loss: 9.3113, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 31, Train Loss: 14.4236, Val Loss: 25.7210, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 32, Train Loss: 15.3870, Val Loss: 5.1488, F1 Micro: 0.6354, F1 Macro: 0.5988, Accuracy: 0.6354\n","Epoch 33, Train Loss: 4.9429, Val Loss: 10.8275, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 34, Train Loss: 4.5174, Val Loss: 7.8968, F1 Micro: 0.8438, F1 Macro: 0.6954, Accuracy: 0.8438\n","Epoch 35, Train Loss: 14.2341, Val Loss: 12.9437, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 36, Train Loss: 16.7021, Val Loss: 25.2109, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 37, Train Loss: 5.7506, Val Loss: 2.0799, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 38, Train Loss: 7.1285, Val Loss: 8.1064, F1 Micro: 0.7396, F1 Macro: 0.4251, Accuracy: 0.7396\n","Epoch 39, Train Loss: 6.1411, Val Loss: 11.6592, F1 Micro: 0.3646, F1 Macro: 0.3645, Accuracy: 0.3646\n","Epoch 40, Train Loss: 9.5197, Val Loss: 23.3384, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 41, Train Loss: 7.2257, Val Loss: 1.4416, F1 Micro: 0.8854, F1 Macro: 0.8159, Accuracy: 0.8854\n","Epoch 42, Train Loss: 1.9052, Val Loss: 3.5857, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 43, Train Loss: 5.4532, Val Loss: 1.5937, F1 Micro: 0.8542, F1 Macro: 0.7867, Accuracy: 0.8542\n","Epoch 44, Train Loss: 4.6495, Val Loss: 6.8827, F1 Micro: 0.5312, F1 Macro: 0.5195, Accuracy: 0.5312\n","Epoch 45, Train Loss: 9.5858, Val Loss: 6.7099, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 46, Train Loss: 2.3552, Val Loss: 1.0352, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 47, Train Loss: 1.4876, Val Loss: 1.7311, F1 Micro: 0.7708, F1 Macro: 0.7283, Accuracy: 0.7708\n","Epoch 48, Train Loss: 2.0169, Val Loss: 3.4645, F1 Micro: 0.6458, F1 Macro: 0.5800, Accuracy: 0.6458\n","Epoch 49, Train Loss: 2.2735, Val Loss: 0.4120, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 50, Train Loss: 2.7876, Val Loss: 2.3044, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 51, Train Loss: 3.8827, Val Loss: 4.9751, F1 Micro: 0.5938, F1 Macro: 0.5530, Accuracy: 0.5938\n","Epoch 52, Train Loss: 3.2120, Val Loss: 3.0022, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 53, Train Loss: 3.3891, Val Loss: 1.9390, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 54, Train Loss: 5.3419, Val Loss: 3.7846, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 55, Train Loss: 6.7066, Val Loss: 6.1561, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 56, Train Loss: 6.7433, Val Loss: 6.8100, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 57, Train Loss: 3.7059, Val Loss: 10.8634, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 58, Train Loss: 2.9348, Val Loss: 1.1292, F1 Micro: 0.8229, F1 Macro: 0.7671, Accuracy: 0.8229\n","Epoch 59, Train Loss: 1.4104, Val Loss: 2.5016, F1 Micro: 0.7500, F1 Macro: 0.7091, Accuracy: 0.7500\n","Epoch 60, Train Loss: 2.1696, Val Loss: 2.6574, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 61, Train Loss: 2.6040, Val Loss: 7.6523, F1 Micro: 0.6771, F1 Macro: 0.5013, Accuracy: 0.6771\n","Epoch 62, Train Loss: 3.7674, Val Loss: 4.9156, F1 Micro: 0.8646, F1 Macro: 0.7499, Accuracy: 0.8646\n","Epoch 63, Train Loss: 2.1769, Val Loss: 3.2123, F1 Micro: 0.6875, F1 Macro: 0.6537, Accuracy: 0.6875\n","Epoch 64, Train Loss: 1.7273, Val Loss: 3.4650, F1 Micro: 0.7500, F1 Macro: 0.5897, Accuracy: 0.7500\n","Epoch 65, Train Loss: 1.6623, Val Loss: 0.9095, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 66, Train Loss: 1.6781, Val Loss: 1.4029, F1 Micro: 0.8750, F1 Macro: 0.8285, Accuracy: 0.8750\n","Epoch 67, Train Loss: 1.8241, Val Loss: 5.2874, F1 Micro: 0.7708, F1 Macro: 0.4353, Accuracy: 0.7708\n","Epoch 68, Train Loss: 1.3605, Val Loss: 1.4176, F1 Micro: 0.8854, F1 Macro: 0.8294, Accuracy: 0.8854\n","Epoch 69, Train Loss: 0.7299, Val Loss: 3.3963, F1 Micro: 0.7188, F1 Macro: 0.6082, Accuracy: 0.7188\n","Epoch 70, Train Loss: 0.8814, Val Loss: 3.5058, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 71, Train Loss: 0.8883, Val Loss: 1.7867, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 72, Train Loss: 1.8677, Val Loss: 3.3396, F1 Micro: 0.7604, F1 Macro: 0.5576, Accuracy: 0.7604\n","Epoch 73, Train Loss: 0.7877, Val Loss: 0.9984, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 74, Train Loss: 1.0887, Val Loss: 1.0661, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 75, Train Loss: 1.1256, Val Loss: 0.9361, F1 Micro: 0.8229, F1 Macro: 0.6091, Accuracy: 0.8229\n","Epoch 76, Train Loss: 1.3099, Val Loss: 3.2706, F1 Micro: 0.8229, F1 Macro: 0.7453, Accuracy: 0.8229\n","Epoch 77, Train Loss: 3.5206, Val Loss: 3.9189, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 78, Train Loss: 1.8064, Val Loss: 3.4322, F1 Micro: 0.6979, F1 Macro: 0.6516, Accuracy: 0.6979\n","Epoch 79, Train Loss: 2.9697, Val Loss: 2.5652, F1 Micro: 0.7708, F1 Macro: 0.7227, Accuracy: 0.7708\n","Epoch 80, Train Loss: 1.7308, Val Loss: 9.7686, F1 Micro: 0.7188, F1 Macro: 0.4807, Accuracy: 0.7188\n","Epoch 81, Train Loss: 6.5988, Val Loss: 4.1179, F1 Micro: 0.8021, F1 Macro: 0.7243, Accuracy: 0.8021\n","Epoch 82, Train Loss: 4.6157, Val Loss: 5.6420, F1 Micro: 0.7292, F1 Macro: 0.6723, Accuracy: 0.7292\n","Epoch 83, Train Loss: 2.9643, Val Loss: 2.5475, F1 Micro: 0.7708, F1 Macro: 0.7166, Accuracy: 0.7708\n","Epoch 84, Train Loss: 1.1372, Val Loss: 1.0190, F1 Micro: 0.8958, F1 Macro: 0.8526, Accuracy: 0.8958\n","Epoch 85, Train Loss: 1.8943, Val Loss: 1.7969, F1 Micro: 0.8021, F1 Macro: 0.7397, Accuracy: 0.8021\n","Epoch 86, Train Loss: 0.9643, Val Loss: 1.4368, F1 Micro: 0.8854, F1 Macro: 0.8230, Accuracy: 0.8854\n","Epoch 87, Train Loss: 1.0049, Val Loss: 0.8604, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 88, Train Loss: 0.4943, Val Loss: 0.5571, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 89, Train Loss: 1.3876, Val Loss: 1.7991, F1 Micro: 0.8646, F1 Macro: 0.8169, Accuracy: 0.8646\n","Epoch 90, Train Loss: 0.6977, Val Loss: 0.9154, F1 Micro: 0.8958, F1 Macro: 0.8476, Accuracy: 0.8958\n","Epoch 91, Train Loss: 0.8393, Val Loss: 1.4170, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 92, Train Loss: 0.7062, Val Loss: 1.1057, F1 Micro: 0.8958, F1 Macro: 0.8476, Accuracy: 0.8958\n","Epoch 93, Train Loss: 0.9010, Val Loss: 1.6635, F1 Micro: 0.8646, F1 Macro: 0.8113, Accuracy: 0.8646\n","Epoch 94, Train Loss: 1.5562, Val Loss: 1.1348, F1 Micro: 0.8646, F1 Macro: 0.8113, Accuracy: 0.8646\n","Epoch 95, Train Loss: 2.0318, Val Loss: 2.5090, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 96, Train Loss: 2.8643, Val Loss: 2.9017, F1 Micro: 0.7708, F1 Macro: 0.7227, Accuracy: 0.7708\n","Epoch 97, Train Loss: 1.7525, Val Loss: 1.5294, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 98, Train Loss: 2.5861, Val Loss: 4.9436, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 99, Train Loss: 3.4920, Val Loss: 2.4200, F1 Micro: 0.7812, F1 Macro: 0.7380, Accuracy: 0.7812\n","Epoch 100, Train Loss: 2.7576, Val Loss: 4.3142, F1 Micro: 0.6875, F1 Macro: 0.6537, Accuracy: 0.6875\n","Epoch 101, Train Loss: 2.7061, Val Loss: 3.2250, F1 Micro: 0.7083, F1 Macro: 0.6471, Accuracy: 0.7083\n","Epoch 102, Train Loss: 1.3840, Val Loss: 2.0371, F1 Micro: 0.8125, F1 Macro: 0.7681, Accuracy: 0.8125\n","Epoch 103, Train Loss: 2.1132, Val Loss: 2.7431, F1 Micro: 0.8854, F1 Macro: 0.8159, Accuracy: 0.8854\n","Epoch 104, Train Loss: 1.9174, Val Loss: 1.4715, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 105, Train Loss: 0.5617, Val Loss: 2.1285, F1 Micro: 0.8125, F1 Macro: 0.7626, Accuracy: 0.8125\n","Epoch 106, Train Loss: 0.7242, Val Loss: 4.5518, F1 Micro: 0.7604, F1 Macro: 0.5329, Accuracy: 0.7604\n","Epoch 107, Train Loss: 3.3251, Val Loss: 1.4711, F1 Micro: 0.8854, F1 Macro: 0.8294, Accuracy: 0.8854\n","Epoch 108, Train Loss: 2.9130, Val Loss: 10.5266, F1 Micro: 0.7188, F1 Macro: 0.4807, Accuracy: 0.7188\n","Epoch 109, Train Loss: 3.8896, Val Loss: 2.0647, F1 Micro: 0.8021, F1 Macro: 0.7579, Accuracy: 0.8021\n","Epoch 110, Train Loss: 1.0714, Val Loss: 0.6803, F1 Micro: 0.9167, F1 Macro: 0.8632, Accuracy: 0.9167\n","Epoch 111, Train Loss: 1.0661, Val Loss: 1.3465, F1 Micro: 0.8958, F1 Macro: 0.8360, Accuracy: 0.8958\n","Epoch 112, Train Loss: 0.9259, Val Loss: 2.0815, F1 Micro: 0.8229, F1 Macro: 0.7785, Accuracy: 0.8229\n","Epoch 113, Train Loss: 2.3819, Val Loss: 1.6373, F1 Micro: 0.8333, F1 Macro: 0.7778, Accuracy: 0.8333\n","Epoch 114, Train Loss: 2.6289, Val Loss: 3.8460, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 115, Train Loss: 2.6054, Val Loss: 2.7362, F1 Micro: 0.8333, F1 Macro: 0.7713, Accuracy: 0.8333\n","Epoch 116, Train Loss: 1.9582, Val Loss: 1.5973, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 117, Train Loss: 0.9524, Val Loss: 1.4025, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 118, Train Loss: 1.4333, Val Loss: 0.9318, F1 Micro: 0.8750, F1 Macro: 0.7491, Accuracy: 0.8750\n","Epoch 119, Train Loss: 1.0323, Val Loss: 0.8483, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 120, Train Loss: 0.4170, Val Loss: 1.1495, F1 Micro: 0.8542, F1 Macro: 0.7936, Accuracy: 0.8542\n","Epoch 121, Train Loss: 0.6518, Val Loss: 0.9520, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 122, Train Loss: 0.7786, Val Loss: 0.8706, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 123, Train Loss: 1.4868, Val Loss: 2.1126, F1 Micro: 0.8021, F1 Macro: 0.6820, Accuracy: 0.8021\n","Epoch 124, Train Loss: 2.1469, Val Loss: 1.1921, F1 Micro: 0.8542, F1 Macro: 0.7999, Accuracy: 0.8542\n","Epoch 125, Train Loss: 0.6218, Val Loss: 2.2390, F1 Micro: 0.8646, F1 Macro: 0.8169, Accuracy: 0.8646\n","Epoch 126, Train Loss: 1.5849, Val Loss: 2.9739, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 127, Train Loss: 1.3206, Val Loss: 1.0267, F1 Micro: 0.8958, F1 Macro: 0.8421, Accuracy: 0.8958\n","Epoch 128, Train Loss: 1.9123, Val Loss: 2.2449, F1 Micro: 0.8646, F1 Macro: 0.8052, Accuracy: 0.8646\n","Epoch 129, Train Loss: 2.6482, Val Loss: 1.4093, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 130, Train Loss: 0.8366, Val Loss: 4.8633, F1 Micro: 0.7500, F1 Macro: 0.5897, Accuracy: 0.7500\n","Epoch 131, Train Loss: 1.3606, Val Loss: 1.7083, F1 Micro: 0.8854, F1 Macro: 0.8294, Accuracy: 0.8854\n","Epoch 132, Train Loss: 2.1345, Val Loss: 6.9240, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 133, Train Loss: 1.5311, Val Loss: 1.4556, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 134, Train Loss: 0.6700, Val Loss: 0.7388, F1 Micro: 0.8646, F1 Macro: 0.7621, Accuracy: 0.8646\n","Epoch 135, Train Loss: 2.1127, Val Loss: 7.9222, F1 Micro: 0.6875, F1 Macro: 0.6537, Accuracy: 0.6875\n","Epoch 136, Train Loss: 2.6680, Val Loss: 2.1397, F1 Micro: 0.8021, F1 Macro: 0.5906, Accuracy: 0.8021\n","Epoch 137, Train Loss: 0.7535, Val Loss: 1.3515, F1 Micro: 0.8438, F1 Macro: 0.7587, Accuracy: 0.8438\n","Epoch 138, Train Loss: 0.6065, Val Loss: 1.3756, F1 Micro: 0.8229, F1 Macro: 0.6091, Accuracy: 0.8229\n","Epoch 139, Train Loss: 1.1727, Val Loss: 3.0888, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 140, Train Loss: 3.0950, Val Loss: 1.5438, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 141, Train Loss: 2.3361, Val Loss: 5.1994, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 142, Train Loss: 5.3568, Val Loss: 2.7498, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 143, Train Loss: 5.3670, Val Loss: 3.0556, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 144, Train Loss: 2.3190, Val Loss: 11.1222, F1 Micro: 0.5625, F1 Macro: 0.4909, Accuracy: 0.5625\n","Epoch 145, Train Loss: 2.5139, Val Loss: 2.9317, F1 Micro: 0.8021, F1 Macro: 0.6820, Accuracy: 0.8021\n","Epoch 146, Train Loss: 4.1200, Val Loss: 1.7711, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 147, Train Loss: 2.0196, Val Loss: 5.7649, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 148, Train Loss: 2.2391, Val Loss: 1.2763, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 149, Train Loss: 0.7795, Val Loss: 1.6240, F1 Micro: 0.8438, F1 Macro: 0.7887, Accuracy: 0.8438\n","Epoch 150, Train Loss: 1.2934, Val Loss: 9.7179, F1 Micro: 0.6667, F1 Macro: 0.5426, Accuracy: 0.6667\n","Epoch 151, Train Loss: 2.7800, Val Loss: 3.8611, F1 Micro: 0.7708, F1 Macro: 0.7283, Accuracy: 0.7708\n","Epoch 152, Train Loss: 1.0715, Val Loss: 1.9829, F1 Micro: 0.8125, F1 Macro: 0.7566, Accuracy: 0.8125\n","Epoch 153, Train Loss: 0.8111, Val Loss: 0.7945, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 154, Train Loss: 1.2224, Val Loss: 0.9319, F1 Micro: 0.9375, F1 Macro: 0.8974, Accuracy: 0.9375\n","Epoch 155, Train Loss: 0.6866, Val Loss: 1.5893, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 156, Train Loss: 2.8735, Val Loss: 5.7901, F1 Micro: 0.6771, F1 Macro: 0.6207, Accuracy: 0.6771\n","Epoch 157, Train Loss: 2.5703, Val Loss: 1.4836, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 158, Train Loss: 1.3500, Val Loss: 1.3669, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 159, Train Loss: 0.8834, Val Loss: 1.3607, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 160, Train Loss: 0.6955, Val Loss: 0.7268, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 161, Train Loss: 0.6697, Val Loss: 0.9016, F1 Micro: 0.9167, F1 Macro: 0.8688, Accuracy: 0.9167\n","Epoch 162, Train Loss: 0.5359, Val Loss: 1.2664, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 163, Train Loss: 0.5681, Val Loss: 1.9304, F1 Micro: 0.8229, F1 Macro: 0.7605, Accuracy: 0.8229\n","Epoch 164, Train Loss: 0.9631, Val Loss: 0.7536, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 165, Train Loss: 0.6414, Val Loss: 4.2036, F1 Micro: 0.7917, F1 Macro: 0.5819, Accuracy: 0.7917\n","Epoch 166, Train Loss: 1.3339, Val Loss: 0.9218, F1 Micro: 0.8750, F1 Macro: 0.8105, Accuracy: 0.8750\n","Epoch 167, Train Loss: 1.1827, Val Loss: 1.9595, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 168, Train Loss: 1.2144, Val Loss: 1.5637, F1 Micro: 0.8958, F1 Macro: 0.8526, Accuracy: 0.8958\n","Epoch 169, Train Loss: 1.2007, Val Loss: 2.8205, F1 Micro: 0.8542, F1 Macro: 0.7073, Accuracy: 0.8542\n","Epoch 170, Train Loss: 3.2640, Val Loss: 2.9502, F1 Micro: 0.7917, F1 Macro: 0.7479, Accuracy: 0.7917\n","Epoch 171, Train Loss: 3.2797, Val Loss: 4.4080, F1 Micro: 0.8542, F1 Macro: 0.6667, Accuracy: 0.8542\n","Epoch 172, Train Loss: 5.5564, Val Loss: 10.0279, F1 Micro: 0.7083, F1 Macro: 0.6541, Accuracy: 0.7083\n","Epoch 173, Train Loss: 4.9910, Val Loss: 8.6525, F1 Micro: 0.6354, F1 Macro: 0.5988, Accuracy: 0.6354\n","Epoch 174, Train Loss: 2.2854, Val Loss: 1.6275, F1 Micro: 0.8958, F1 Macro: 0.8526, Accuracy: 0.8958\n","Epoch 175, Train Loss: 1.9096, Val Loss: 3.2461, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 176, Train Loss: 2.1353, Val Loss: 3.0000, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 177, Train Loss: 2.2020, Val Loss: 2.0049, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 178, Train Loss: 1.0747, Val Loss: 1.3478, F1 Micro: 0.8958, F1 Macro: 0.8476, Accuracy: 0.8958\n","Epoch 179, Train Loss: 1.0087, Val Loss: 1.0689, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 180, Train Loss: 0.6582, Val Loss: 1.7033, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 181, Train Loss: 1.5154, Val Loss: 2.2706, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 182, Train Loss: 0.6360, Val Loss: 1.7776, F1 Micro: 0.8438, F1 Macro: 0.7379, Accuracy: 0.8438\n","Epoch 183, Train Loss: 0.5396, Val Loss: 2.7931, F1 Micro: 0.8333, F1 Macro: 0.7641, Accuracy: 0.8333\n","Epoch 184, Train Loss: 2.3317, Val Loss: 3.8100, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 185, Train Loss: 1.9343, Val Loss: 3.1240, F1 Micro: 0.8646, F1 Macro: 0.7984, Accuracy: 0.8646\n","Epoch 186, Train Loss: 4.7481, Val Loss: 2.3870, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 187, Train Loss: 2.1568, Val Loss: 2.2697, F1 Micro: 0.8229, F1 Macro: 0.7785, Accuracy: 0.8229\n","Epoch 188, Train Loss: 1.8205, Val Loss: 0.8785, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 189, Train Loss: 5.3914, Val Loss: 7.7234, F1 Micro: 0.6875, F1 Macro: 0.5833, Accuracy: 0.6875\n","Epoch 190, Train Loss: 1.6303, Val Loss: 9.6603, F1 Micro: 0.5833, F1 Macro: 0.5644, Accuracy: 0.5833\n","Epoch 191, Train Loss: 2.3961, Val Loss: 1.5982, F1 Micro: 0.8958, F1 Macro: 0.8526, Accuracy: 0.8958\n","Epoch 192, Train Loss: 4.7226, Val Loss: 1.0481, F1 Micro: 0.9375, F1 Macro: 0.8974, Accuracy: 0.9375\n","Epoch 193, Train Loss: 11.9859, Val Loss: 3.4019, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 194, Train Loss: 3.4522, Val Loss: 3.8962, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 195, Train Loss: 3.9346, Val Loss: 3.0176, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 196, Train Loss: 3.2011, Val Loss: 2.2526, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 197, Train Loss: 1.2852, Val Loss: 6.4577, F1 Micro: 0.6875, F1 Macro: 0.6427, Accuracy: 0.6875\n","Epoch 198, Train Loss: 1.3317, Val Loss: 1.1404, F1 Micro: 0.8958, F1 Macro: 0.8421, Accuracy: 0.8958\n","Epoch 199, Train Loss: 1.1397, Val Loss: 1.7905, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 200, Train Loss: 0.4084, Val Loss: 0.9342, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 453.7701, Val Loss: 60.6915, F1 Micro: 0.1667, F1 Macro: 0.1534, Accuracy: 0.1667\n","Epoch 2, Train Loss: 121.7664, Val Loss: 43.8740, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 142.2776, Val Loss: 29.2516, F1 Micro: 0.4375, F1 Macro: 0.4214, Accuracy: 0.4375\n","Epoch 4, Train Loss: 191.8753, Val Loss: 301.0842, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 5, Train Loss: 68.3186, Val Loss: 76.4978, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 69.7209, Val Loss: 127.4402, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 7, Train Loss: 395.4521, Val Loss: 385.0785, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 8, Train Loss: 117.1798, Val Loss: 87.9262, F1 Micro: 0.1667, F1 Macro: 0.1575, Accuracy: 0.1667\n","Epoch 9, Train Loss: 127.6208, Val Loss: 84.5760, F1 Micro: 0.2188, F1 Macro: 0.2166, Accuracy: 0.2188\n","Epoch 10, Train Loss: 146.7859, Val Loss: 468.3683, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 11, Train Loss: 261.4504, Val Loss: 31.6877, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 59.1434, Val Loss: 77.8387, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 59.5830, Val Loss: 27.3857, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 14, Train Loss: 34.1560, Val Loss: 27.3497, F1 Micro: 0.1771, F1 Macro: 0.1698, Accuracy: 0.1771\n","Epoch 15, Train Loss: 28.9814, Val Loss: 54.3882, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 16, Train Loss: 33.3314, Val Loss: 91.5390, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 17, Train Loss: 56.1917, Val Loss: 17.0631, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 18, Train Loss: 32.0018, Val Loss: 4.9245, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 19, Train Loss: 21.3348, Val Loss: 51.1182, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 20, Train Loss: 118.9255, Val Loss: 11.3364, F1 Micro: 0.6146, F1 Macro: 0.5060, Accuracy: 0.6146\n","Epoch 21, Train Loss: 103.5739, Val Loss: 22.8271, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 22, Train Loss: 20.3847, Val Loss: 27.4613, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 23, Train Loss: 26.3621, Val Loss: 35.3677, F1 Micro: 0.3125, F1 Macro: 0.3113, Accuracy: 0.3125\n","Epoch 24, Train Loss: 22.2817, Val Loss: 27.4855, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 25, Train Loss: 20.3216, Val Loss: 1.5808, F1 Micro: 0.7083, F1 Macro: 0.6393, Accuracy: 0.7083\n","Epoch 26, Train Loss: 26.7716, Val Loss: 68.4944, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 27, Train Loss: 36.8743, Val Loss: 11.3100, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 28, Train Loss: 34.6656, Val Loss: 38.1225, F1 Micro: 0.1667, F1 Macro: 0.1534, Accuracy: 0.1667\n","Epoch 29, Train Loss: 17.4437, Val Loss: 2.8777, F1 Micro: 0.6354, F1 Macro: 0.5718, Accuracy: 0.6354\n","Epoch 30, Train Loss: 17.1279, Val Loss: 2.5050, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 31, Train Loss: 56.1079, Val Loss: 39.8127, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 32, Train Loss: 28.6124, Val Loss: 18.0336, F1 Micro: 0.4375, F1 Macro: 0.4214, Accuracy: 0.4375\n","Epoch 33, Train Loss: 42.8965, Val Loss: 56.3703, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 34, Train Loss: 39.2717, Val Loss: 9.7660, F1 Micro: 0.2500, F1 Macro: 0.2487, Accuracy: 0.2500\n","Epoch 35, Train Loss: 25.5877, Val Loss: 17.1548, F1 Micro: 0.3646, F1 Macro: 0.3589, Accuracy: 0.3646\n","Epoch 36, Train Loss: 20.2463, Val Loss: 4.9318, F1 Micro: 0.5104, F1 Macro: 0.4806, Accuracy: 0.5104\n","Epoch 37, Train Loss: 6.5777, Val Loss: 19.9797, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 38, Train Loss: 22.2780, Val Loss: 9.8502, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 39, Train Loss: 12.8957, Val Loss: 6.0895, F1 Micro: 0.8021, F1 Macro: 0.5906, Accuracy: 0.8021\n","Epoch 40, Train Loss: 17.1540, Val Loss: 9.1360, F1 Micro: 0.5104, F1 Macro: 0.4806, Accuracy: 0.5104\n","Epoch 41, Train Loss: 8.9015, Val Loss: 9.1877, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 42, Train Loss: 7.8524, Val Loss: 27.0019, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 43, Train Loss: 14.9824, Val Loss: 11.5120, F1 Micro: 0.3438, F1 Macro: 0.3402, Accuracy: 0.3438\n","Epoch 44, Train Loss: 4.0459, Val Loss: 8.0005, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 45, Train Loss: 4.2294, Val Loss: 2.5144, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 46, Train Loss: 7.5810, Val Loss: 4.9683, F1 Micro: 0.5521, F1 Macro: 0.5136, Accuracy: 0.5521\n","Epoch 47, Train Loss: 5.9130, Val Loss: 3.7465, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 48, Train Loss: 4.7357, Val Loss: 1.2582, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 49, Train Loss: 4.3044, Val Loss: 3.5386, F1 Micro: 0.7083, F1 Macro: 0.6214, Accuracy: 0.7083\n","Epoch 50, Train Loss: 4.4968, Val Loss: 0.8960, F1 Micro: 0.8750, F1 Macro: 0.7949, Accuracy: 0.8750\n","Epoch 51, Train Loss: 11.0757, Val Loss: 8.2803, F1 Micro: 0.5625, F1 Macro: 0.5152, Accuracy: 0.5625\n","Epoch 52, Train Loss: 9.0341, Val Loss: 7.7300, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 53, Train Loss: 8.0284, Val Loss: 2.1122, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 54, Train Loss: 4.4238, Val Loss: 7.6238, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 55, Train Loss: 3.8907, Val Loss: 0.6346, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 56, Train Loss: 4.7396, Val Loss: 4.7430, F1 Micro: 0.5104, F1 Macro: 0.4806, Accuracy: 0.5104\n","Epoch 57, Train Loss: 11.3430, Val Loss: 18.2716, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 58, Train Loss: 10.3073, Val Loss: 4.1132, F1 Micro: 0.6042, F1 Macro: 0.5547, Accuracy: 0.6042\n","Epoch 59, Train Loss: 5.5995, Val Loss: 9.0115, F1 Micro: 0.5208, F1 Macro: 0.4889, Accuracy: 0.5208\n","Epoch 60, Train Loss: 6.0963, Val Loss: 2.3822, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 61, Train Loss: 7.3061, Val Loss: 12.8428, F1 Micro: 0.4062, F1 Macro: 0.3952, Accuracy: 0.4062\n","Epoch 62, Train Loss: 7.6451, Val Loss: 3.0703, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 63, Train Loss: 6.1571, Val Loss: 5.2836, F1 Micro: 0.5312, F1 Macro: 0.4971, Accuracy: 0.5312\n","Epoch 64, Train Loss: 3.7859, Val Loss: 0.9907, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 65, Train Loss: 2.7571, Val Loss: 5.9438, F1 Micro: 0.6458, F1 Macro: 0.5714, Accuracy: 0.6458\n","Epoch 66, Train Loss: 6.4595, Val Loss: 6.6581, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 67, Train Loss: 4.8124, Val Loss: 2.1167, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 68, Train Loss: 5.7048, Val Loss: 4.7331, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 69, Train Loss: 3.2915, Val Loss: 1.1982, F1 Micro: 0.8750, F1 Macro: 0.5909, Accuracy: 0.8750\n","Epoch 70, Train Loss: 2.4928, Val Loss: 0.5083, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 71, Train Loss: 2.5337, Val Loss: 0.3443, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 72, Train Loss: 0.5040, Val Loss: 0.4503, F1 Micro: 0.9271, F1 Macro: 0.8129, Accuracy: 0.9271\n","Epoch 73, Train Loss: 1.0414, Val Loss: 1.2418, F1 Micro: 0.7917, F1 Macro: 0.7141, Accuracy: 0.7917\n","Epoch 74, Train Loss: 2.1622, Val Loss: 0.3899, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 75, Train Loss: 1.0489, Val Loss: 0.2499, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 76, Train Loss: 1.8500, Val Loss: 1.7437, F1 Micro: 0.8750, F1 Macro: 0.5909, Accuracy: 0.8750\n","Epoch 77, Train Loss: 2.2849, Val Loss: 1.6830, F1 Micro: 0.8333, F1 Macro: 0.7474, Accuracy: 0.8333\n","Epoch 78, Train Loss: 3.3420, Val Loss: 0.5420, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 79, Train Loss: 2.4210, Val Loss: 6.0067, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 80, Train Loss: 9.4646, Val Loss: 0.7331, F1 Micro: 0.8229, F1 Macro: 0.7265, Accuracy: 0.8229\n","Epoch 81, Train Loss: 4.2789, Val Loss: 4.9970, F1 Micro: 0.7396, F1 Macro: 0.6478, Accuracy: 0.7396\n","Epoch 82, Train Loss: 9.1232, Val Loss: 5.1771, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 83, Train Loss: 8.3789, Val Loss: 3.4195, F1 Micro: 0.8333, F1 Macro: 0.6840, Accuracy: 0.8333\n","Epoch 84, Train Loss: 5.3356, Val Loss: 2.7912, F1 Micro: 0.7292, F1 Macro: 0.6571, Accuracy: 0.7292\n","Epoch 85, Train Loss: 2.4893, Val Loss: 0.8943, F1 Micro: 0.8125, F1 Macro: 0.7346, Accuracy: 0.8125\n","Epoch 86, Train Loss: 1.8184, Val Loss: 1.3819, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 87, Train Loss: 1.1387, Val Loss: 1.4496, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 88, Train Loss: 1.2027, Val Loss: 0.6859, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 89, Train Loss: 2.0053, Val Loss: 2.7591, F1 Micro: 0.7500, F1 Macro: 0.6755, Accuracy: 0.7500\n","Epoch 90, Train Loss: 4.3446, Val Loss: 0.9661, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 91, Train Loss: 0.9908, Val Loss: 0.4384, F1 Micro: 0.9271, F1 Macro: 0.8129, Accuracy: 0.9271\n","Epoch 92, Train Loss: 0.4624, Val Loss: 0.8104, F1 Micro: 0.8021, F1 Macro: 0.7153, Accuracy: 0.8021\n","Epoch 93, Train Loss: 1.0057, Val Loss: 0.5205, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 94, Train Loss: 0.7607, Val Loss: 1.4149, F1 Micro: 0.7500, F1 Macro: 0.6755, Accuracy: 0.7500\n","Epoch 95, Train Loss: 1.1313, Val Loss: 0.3413, F1 Micro: 0.9271, F1 Macro: 0.8129, Accuracy: 0.9271\n","Epoch 96, Train Loss: 0.5260, Val Loss: 0.4606, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 97, Train Loss: 2.9192, Val Loss: 2.4828, F1 Micro: 0.7812, F1 Macro: 0.7042, Accuracy: 0.7812\n","Epoch 98, Train Loss: 3.0621, Val Loss: 2.0164, F1 Micro: 0.8438, F1 Macro: 0.7379, Accuracy: 0.8438\n","Epoch 99, Train Loss: 4.0934, Val Loss: 1.1595, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 100, Train Loss: 1.4656, Val Loss: 0.6606, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 101, Train Loss: 2.4828, Val Loss: 1.9101, F1 Micro: 0.8542, F1 Macro: 0.7073, Accuracy: 0.8542\n","Epoch 102, Train Loss: 1.8279, Val Loss: 0.6227, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 103, Train Loss: 2.2428, Val Loss: 2.5181, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 104, Train Loss: 3.2725, Val Loss: 0.7389, F1 Micro: 0.8125, F1 Macro: 0.7257, Accuracy: 0.8125\n","Epoch 105, Train Loss: 3.3551, Val Loss: 4.1238, F1 Micro: 0.7917, F1 Macro: 0.6842, Accuracy: 0.7917\n","Epoch 106, Train Loss: 4.1783, Val Loss: 1.3330, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 107, Train Loss: 1.1320, Val Loss: 0.8197, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 108, Train Loss: 1.0543, Val Loss: 2.8605, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 109, Train Loss: 1.5555, Val Loss: 0.3132, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 110, Train Loss: 0.7347, Val Loss: 1.6958, F1 Micro: 0.7604, F1 Macro: 0.6150, Accuracy: 0.7604\n","Epoch 111, Train Loss: 1.6369, Val Loss: 0.2921, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 112, Train Loss: 3.0938, Val Loss: 2.4125, F1 Micro: 0.8542, F1 Macro: 0.7073, Accuracy: 0.8542\n","Epoch 113, Train Loss: 2.0941, Val Loss: 2.0220, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 114, Train Loss: 1.0582, Val Loss: 0.3285, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 115, Train Loss: 1.6078, Val Loss: 5.5622, F1 Micro: 0.5938, F1 Macro: 0.5135, Accuracy: 0.5938\n","Epoch 116, Train Loss: 2.3373, Val Loss: 0.2903, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 117, Train Loss: 5.0150, Val Loss: 8.9543, F1 Micro: 0.7083, F1 Macro: 0.4469, Accuracy: 0.7083\n","Epoch 118, Train Loss: 3.5148, Val Loss: 0.3895, F1 Micro: 0.9375, F1 Macro: 0.8571, Accuracy: 0.9375\n","Epoch 119, Train Loss: 1.6114, Val Loss: 0.3353, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 120, Train Loss: 0.8183, Val Loss: 1.7624, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 121, Train Loss: 0.8976, Val Loss: 0.9304, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 122, Train Loss: 1.7366, Val Loss: 0.8335, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 123, Train Loss: 0.8117, Val Loss: 1.0182, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 124, Train Loss: 0.8243, Val Loss: 1.1261, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 125, Train Loss: 1.0149, Val Loss: 0.8450, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 126, Train Loss: 0.8440, Val Loss: 0.3883, F1 Micro: 0.9375, F1 Macro: 0.8460, Accuracy: 0.9375\n","Epoch 127, Train Loss: 1.1905, Val Loss: 0.9126, F1 Micro: 0.8021, F1 Macro: 0.6820, Accuracy: 0.8021\n","Epoch 128, Train Loss: 2.2809, Val Loss: 0.6158, F1 Micro: 0.9167, F1 Macro: 0.7947, Accuracy: 0.9167\n","Epoch 129, Train Loss: 0.8929, Val Loss: 0.6211, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 130, Train Loss: 1.1381, Val Loss: 0.7049, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 131, Train Loss: 0.9514, Val Loss: 0.2889, F1 Micro: 0.9375, F1 Macro: 0.8665, Accuracy: 0.9375\n","Epoch 132, Train Loss: 1.2145, Val Loss: 0.5962, F1 Micro: 0.9167, F1 Macro: 0.7947, Accuracy: 0.9167\n","Epoch 133, Train Loss: 0.9479, Val Loss: 0.4205, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 134, Train Loss: 0.6612, Val Loss: 0.3590, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 135, Train Loss: 0.7777, Val Loss: 0.8752, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 136, Train Loss: 1.1089, Val Loss: 1.1117, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 137, Train Loss: 2.8797, Val Loss: 1.0747, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 138, Train Loss: 1.7842, Val Loss: 0.3048, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 139, Train Loss: 3.8825, Val Loss: 4.2183, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 140, Train Loss: 4.5751, Val Loss: 16.1874, F1 Micro: 0.7500, F1 Macro: 0.4662, Accuracy: 0.7500\n","Epoch 141, Train Loss: 6.7775, Val Loss: 18.0402, F1 Micro: 0.4688, F1 Macro: 0.4516, Accuracy: 0.4688\n","Epoch 142, Train Loss: 4.1369, Val Loss: 0.3765, F1 Micro: 0.9375, F1 Macro: 0.8460, Accuracy: 0.9375\n","Epoch 143, Train Loss: 2.6992, Val Loss: 0.7288, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 144, Train Loss: 1.6604, Val Loss: 0.7921, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 145, Train Loss: 2.7315, Val Loss: 0.8075, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 146, Train Loss: 2.8435, Val Loss: 0.5635, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 147, Train Loss: 5.3869, Val Loss: 6.0847, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 148, Train Loss: 4.4248, Val Loss: 2.4141, F1 Micro: 0.7083, F1 Macro: 0.6393, Accuracy: 0.7083\n","Epoch 149, Train Loss: 5.3147, Val Loss: 1.8414, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 150, Train Loss: 0.7305, Val Loss: 0.3363, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 151, Train Loss: 1.0094, Val Loss: 0.3400, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 152, Train Loss: 1.1313, Val Loss: 2.5060, F1 Micro: 0.7396, F1 Macro: 0.6254, Accuracy: 0.7396\n","Epoch 153, Train Loss: 1.8049, Val Loss: 0.9121, F1 Micro: 0.8646, F1 Macro: 0.7908, Accuracy: 0.8646\n","Epoch 154, Train Loss: 3.9357, Val Loss: 11.9601, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 155, Train Loss: 6.4069, Val Loss: 10.9399, F1 Micro: 0.4688, F1 Macro: 0.4516, Accuracy: 0.4688\n","Epoch 156, Train Loss: 7.1001, Val Loss: 2.1559, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 157, Train Loss: 4.9260, Val Loss: 5.7907, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 158, Train Loss: 11.0725, Val Loss: 13.0789, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 159, Train Loss: 2.8777, Val Loss: 4.3484, F1 Micro: 0.6250, F1 Macro: 0.5712, Accuracy: 0.6250\n","Epoch 160, Train Loss: 3.3811, Val Loss: 4.6611, F1 Micro: 0.7292, F1 Macro: 0.6571, Accuracy: 0.7292\n","Epoch 161, Train Loss: 3.7574, Val Loss: 9.7206, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 162, Train Loss: 6.9692, Val Loss: 1.1052, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 163, Train Loss: 2.8380, Val Loss: 0.5407, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 164, Train Loss: 0.7195, Val Loss: 0.2790, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 428.1361, Val Loss: 439.3477, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 2, Train Loss: 237.8130, Val Loss: 202.6116, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 128.1430, Val Loss: 109.1388, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Epoch 4, Train Loss: 124.2732, Val Loss: 15.5064, F1 Micro: 0.7083, F1 Macro: 0.4996, Accuracy: 0.7083\n","Epoch 5, Train Loss: 134.4908, Val Loss: 244.4825, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 236.8332, Val Loss: 189.7875, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 7, Train Loss: 139.6721, Val Loss: 53.7582, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 8, Train Loss: 41.0763, Val Loss: 11.6217, F1 Micro: 0.6354, F1 Macro: 0.5327, Accuracy: 0.6354\n","Epoch 9, Train Loss: 80.4097, Val Loss: 20.9184, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 10, Train Loss: 122.7697, Val Loss: 146.9692, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 11, Train Loss: 280.0522, Val Loss: 157.6865, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 12, Train Loss: 184.8083, Val Loss: 139.6971, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 13, Train Loss: 55.1463, Val Loss: 9.6096, F1 Micro: 0.6875, F1 Macro: 0.5263, Accuracy: 0.6875\n","Epoch 14, Train Loss: 35.5856, Val Loss: 2.1379, F1 Micro: 0.7292, F1 Macro: 0.5895, Accuracy: 0.7292\n","Epoch 15, Train Loss: 54.8730, Val Loss: 48.0472, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 16, Train Loss: 39.9686, Val Loss: 29.1402, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 17, Train Loss: 20.8491, Val Loss: 4.4776, F1 Micro: 0.6250, F1 Macro: 0.5362, Accuracy: 0.6250\n","Epoch 18, Train Loss: 8.9034, Val Loss: 5.4511, F1 Micro: 0.1979, F1 Macro: 0.1971, Accuracy: 0.1979\n","Epoch 19, Train Loss: 15.6221, Val Loss: 3.6799, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 20, Train Loss: 20.8045, Val Loss: 50.3514, F1 Micro: 0.1562, F1 Macro: 0.1517, Accuracy: 0.1562\n","Epoch 21, Train Loss: 65.1604, Val Loss: 8.4224, F1 Micro: 0.6771, F1 Macro: 0.5355, Accuracy: 0.6771\n","Epoch 22, Train Loss: 32.0485, Val Loss: 54.6248, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 23, Train Loss: 59.6611, Val Loss: 14.7239, F1 Micro: 0.6146, F1 Macro: 0.5178, Accuracy: 0.6146\n","Epoch 24, Train Loss: 17.0411, Val Loss: 2.3061, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 25, Train Loss: 18.5779, Val Loss: 27.3529, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 26, Train Loss: 25.7087, Val Loss: 16.3825, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 27, Train Loss: 26.5513, Val Loss: 4.0668, F1 Micro: 0.7812, F1 Macro: 0.5961, Accuracy: 0.7812\n","Epoch 28, Train Loss: 18.5383, Val Loss: 19.4377, F1 Micro: 0.1979, F1 Macro: 0.1971, Accuracy: 0.1979\n","Epoch 29, Train Loss: 9.8257, Val Loss: 1.3517, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 30, Train Loss: 18.5501, Val Loss: 20.3291, F1 Micro: 0.1771, F1 Macro: 0.1748, Accuracy: 0.1771\n","Epoch 31, Train Loss: 20.3851, Val Loss: 17.5348, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 32, Train Loss: 26.5398, Val Loss: 17.2632, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 33, Train Loss: 12.3520, Val Loss: 25.1175, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 34, Train Loss: 31.9909, Val Loss: 18.0707, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 35, Train Loss: 18.8390, Val Loss: 2.6381, F1 Micro: 0.6771, F1 Macro: 0.5861, Accuracy: 0.6771\n","Epoch 36, Train Loss: 8.1283, Val Loss: 0.0974, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 37, Train Loss: 4.3363, Val Loss: 7.6182, F1 Micro: 0.2083, F1 Macro: 0.2080, Accuracy: 0.2083\n","Epoch 38, Train Loss: 14.2996, Val Loss: 23.4369, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 39, Train Loss: 13.6288, Val Loss: 0.6255, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 40, Train Loss: 4.1524, Val Loss: 5.5432, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 41, Train Loss: 4.4854, Val Loss: 5.1958, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 42, Train Loss: 6.8018, Val Loss: 8.4057, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Epoch 43, Train Loss: 9.5244, Val Loss: 4.7499, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 44, Train Loss: 4.6897, Val Loss: 7.2244, F1 Micro: 0.6354, F1 Macro: 0.5439, Accuracy: 0.6354\n","Epoch 45, Train Loss: 11.3293, Val Loss: 2.5755, F1 Micro: 0.8542, F1 Macro: 0.6886, Accuracy: 0.8542\n","Epoch 46, Train Loss: 3.2263, Val Loss: 2.1313, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 47, Train Loss: 7.9211, Val Loss: 0.2729, F1 Micro: 0.9375, F1 Macro: 0.7955, Accuracy: 0.9375\n","Epoch 48, Train Loss: 5.8421, Val Loss: 2.7194, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 49, Train Loss: 7.3413, Val Loss: 4.2439, F1 Micro: 0.7917, F1 Macro: 0.6250, Accuracy: 0.7917\n","Epoch 50, Train Loss: 8.6176, Val Loss: 3.1040, F1 Micro: 0.7812, F1 Macro: 0.6485, Accuracy: 0.7812\n","Epoch 51, Train Loss: 4.1444, Val Loss: 0.5223, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 52, Train Loss: 4.9876, Val Loss: 3.5087, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 53, Train Loss: 5.9701, Val Loss: 0.6804, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 54, Train Loss: 5.8330, Val Loss: 2.5021, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 55, Train Loss: 7.6904, Val Loss: 4.6110, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 56, Train Loss: 3.2941, Val Loss: 3.3249, F1 Micro: 0.5312, F1 Macro: 0.4842, Accuracy: 0.5312\n","Epoch 57, Train Loss: 3.0670, Val Loss: 2.0610, F1 Micro: 0.8542, F1 Macro: 0.7073, Accuracy: 0.8542\n","Epoch 58, Train Loss: 3.8303, Val Loss: 1.3960, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 59, Train Loss: 2.5219, Val Loss: 0.1460, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 60, Train Loss: 1.4861, Val Loss: 3.6786, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 61, Train Loss: 3.0692, Val Loss: 2.3486, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 62, Train Loss: 3.5263, Val Loss: 1.8378, F1 Micro: 0.8229, F1 Macro: 0.6890, Accuracy: 0.8229\n","Epoch 63, Train Loss: 1.8092, Val Loss: 0.2184, F1 Micro: 0.9479, F1 Macro: 0.8850, Accuracy: 0.9479\n","Epoch 64, Train Loss: 1.4272, Val Loss: 0.9942, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 65, Train Loss: 2.6043, Val Loss: 0.3803, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 66, Train Loss: 4.6391, Val Loss: 1.0971, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 67, Train Loss: 3.5297, Val Loss: 2.6646, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 68, Train Loss: 1.5014, Val Loss: 0.3078, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 69, Train Loss: 1.7419, Val Loss: 0.4450, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 70, Train Loss: 1.5186, Val Loss: 0.4123, F1 Micro: 0.8958, F1 Macro: 0.6148, Accuracy: 0.8958\n","Epoch 71, Train Loss: 6.9782, Val Loss: 4.0896, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 72, Train Loss: 5.4215, Val Loss: 3.9514, F1 Micro: 0.8542, F1 Macro: 0.6093, Accuracy: 0.8542\n","Epoch 73, Train Loss: 9.1221, Val Loss: 1.1911, F1 Micro: 0.8750, F1 Macro: 0.7491, Accuracy: 0.8750\n","Epoch 74, Train Loss: 6.3712, Val Loss: 4.0829, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 75, Train Loss: 2.0328, Val Loss: 1.8289, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 76, Train Loss: 2.9597, Val Loss: 0.1146, F1 Micro: 0.9688, F1 Macro: 0.9310, Accuracy: 0.9688\n","Epoch 77, Train Loss: 1.9794, Val Loss: 1.9706, F1 Micro: 0.8646, F1 Macro: 0.6789, Accuracy: 0.8646\n","Epoch 78, Train Loss: 3.2217, Val Loss: 2.9833, F1 Micro: 0.8854, F1 Macro: 0.6023, Accuracy: 0.8854\n","Epoch 79, Train Loss: 1.9927, Val Loss: 0.8061, F1 Micro: 0.8646, F1 Macro: 0.7729, Accuracy: 0.8646\n","Epoch 80, Train Loss: 0.8409, Val Loss: 0.5063, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 81, Train Loss: 2.5331, Val Loss: 2.8995, F1 Micro: 0.7396, F1 Macro: 0.6372, Accuracy: 0.7396\n","Epoch 82, Train Loss: 5.3972, Val Loss: 2.7205, F1 Micro: 0.8021, F1 Macro: 0.6681, Accuracy: 0.8021\n","Epoch 83, Train Loss: 9.0687, Val Loss: 4.9394, F1 Micro: 0.8542, F1 Macro: 0.6093, Accuracy: 0.8542\n","Epoch 84, Train Loss: 8.9038, Val Loss: 4.2539, F1 Micro: 0.8333, F1 Macro: 0.6655, Accuracy: 0.8333\n","Epoch 85, Train Loss: 3.9347, Val Loss: 4.2320, F1 Micro: 0.5312, F1 Macro: 0.4842, Accuracy: 0.5312\n","Epoch 86, Train Loss: 7.0566, Val Loss: 2.2152, F1 Micro: 0.7396, F1 Macro: 0.6372, Accuracy: 0.7396\n","Epoch 87, Train Loss: 4.0255, Val Loss: 1.1791, F1 Micro: 0.7917, F1 Macro: 0.6842, Accuracy: 0.7917\n","Epoch 88, Train Loss: 1.1084, Val Loss: 0.2305, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 89, Train Loss: 4.0100, Val Loss: 0.5327, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 90, Train Loss: 2.5158, Val Loss: 1.4205, F1 Micro: 0.9062, F1 Macro: 0.7096, Accuracy: 0.9062\n","Epoch 91, Train Loss: 3.4386, Val Loss: 1.4478, F1 Micro: 0.8646, F1 Macro: 0.7621, Accuracy: 0.8646\n","Epoch 92, Train Loss: 3.9291, Val Loss: 5.5368, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 93, Train Loss: 8.5582, Val Loss: 0.8989, F1 Micro: 0.8646, F1 Macro: 0.7729, Accuracy: 0.8646\n","Epoch 94, Train Loss: 1.5858, Val Loss: 0.1720, F1 Micro: 0.9479, F1 Macro: 0.8387, Accuracy: 0.9479\n","Epoch 95, Train Loss: 1.5961, Val Loss: 1.7453, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 96, Train Loss: 1.1244, Val Loss: 0.6598, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 97, Train Loss: 3.9484, Val Loss: 0.1732, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 98, Train Loss: 2.1795, Val Loss: 2.3050, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 99, Train Loss: 2.3812, Val Loss: 0.5662, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 100, Train Loss: 1.7122, Val Loss: 0.1277, F1 Micro: 0.9688, F1 Macro: 0.9259, Accuracy: 0.9688\n","Epoch 101, Train Loss: 2.9475, Val Loss: 1.0359, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 102, Train Loss: 2.2023, Val Loss: 0.8505, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 103, Train Loss: 4.4852, Val Loss: 1.1134, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 104, Train Loss: 1.6266, Val Loss: 0.7387, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 105, Train Loss: 2.1331, Val Loss: 2.3146, F1 Micro: 0.8229, F1 Macro: 0.7030, Accuracy: 0.8229\n","Epoch 106, Train Loss: 3.1842, Val Loss: 0.7302, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 107, Train Loss: 0.7592, Val Loss: 0.3283, F1 Micro: 0.9375, F1 Macro: 0.8326, Accuracy: 0.9375\n","Epoch 108, Train Loss: 0.9990, Val Loss: 0.1615, F1 Micro: 0.9375, F1 Macro: 0.8571, Accuracy: 0.9375\n","Epoch 109, Train Loss: 0.5809, Val Loss: 0.2352, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 110, Train Loss: 1.0425, Val Loss: 2.9595, F1 Micro: 0.7812, F1 Macro: 0.5171, Accuracy: 0.7812\n","Epoch 111, Train Loss: 0.8184, Val Loss: 0.2442, F1 Micro: 0.9479, F1 Macro: 0.8540, Accuracy: 0.9479\n","Epoch 112, Train Loss: 0.4523, Val Loss: 0.1317, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 113, Train Loss: 2.3896, Val Loss: 0.6476, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 114, Train Loss: 0.9654, Val Loss: 0.6166, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 115, Train Loss: 0.5515, Val Loss: 0.2220, F1 Micro: 0.9375, F1 Macro: 0.8161, Accuracy: 0.9375\n","Epoch 116, Train Loss: 1.0369, Val Loss: 0.1191, F1 Micro: 0.9583, F1 Macro: 0.8884, Accuracy: 0.9583\n","Epoch 117, Train Loss: 1.3151, Val Loss: 4.5406, F1 Micro: 0.7708, F1 Macro: 0.6526, Accuracy: 0.7708\n","Epoch 118, Train Loss: 10.6012, Val Loss: 11.5387, F1 Micro: 0.6354, F1 Macro: 0.5439, Accuracy: 0.6354\n","Epoch 119, Train Loss: 9.7568, Val Loss: 5.4291, F1 Micro: 0.7812, F1 Macro: 0.6485, Accuracy: 0.7812\n","Epoch 120, Train Loss: 7.8890, Val Loss: 6.0510, F1 Micro: 0.7083, F1 Macro: 0.5998, Accuracy: 0.7083\n","Epoch 121, Train Loss: 8.7908, Val Loss: 4.0898, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 122, Train Loss: 6.8891, Val Loss: 0.7157, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 123, Train Loss: 1.1572, Val Loss: 0.2390, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 124, Train Loss: 2.4787, Val Loss: 1.9566, F1 Micro: 0.8333, F1 Macro: 0.7265, Accuracy: 0.8333\n","Epoch 125, Train Loss: 3.1333, Val Loss: 0.5744, F1 Micro: 0.9062, F1 Macro: 0.6287, Accuracy: 0.9062\n","Epoch 126, Train Loss: 1.5486, Val Loss: 0.6198, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 546.4817, Val Loss: 9.1988, F1 Micro: 0.6771, F1 Macro: 0.5013, Accuracy: 0.6771\n","Epoch 2, Train Loss: 59.7413, Val Loss: 46.6718, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 3, Train Loss: 90.8446, Val Loss: 116.6508, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 4, Train Loss: 132.8482, Val Loss: 25.8537, F1 Micro: 0.7083, F1 Macro: 0.4469, Accuracy: 0.7083\n","Epoch 5, Train Loss: 37.9618, Val Loss: 22.1678, F1 Micro: 0.3854, F1 Macro: 0.3480, Accuracy: 0.3854\n","Epoch 6, Train Loss: 68.4106, Val Loss: 77.3004, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 7, Train Loss: 147.2641, Val Loss: 121.7058, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 8, Train Loss: 318.4491, Val Loss: 17.2300, F1 Micro: 0.5729, F1 Macro: 0.4657, Accuracy: 0.5729\n","Epoch 9, Train Loss: 59.9952, Val Loss: 20.8896, F1 Micro: 0.4375, F1 Macro: 0.3852, Accuracy: 0.4375\n","Epoch 10, Train Loss: 50.3400, Val Loss: 130.4691, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 11, Train Loss: 65.7972, Val Loss: 12.4243, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 12, Train Loss: 21.7514, Val Loss: 13.5971, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 13, Train Loss: 116.8539, Val Loss: 84.5561, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 14, Train Loss: 101.8003, Val Loss: 41.4407, F1 Micro: 0.2500, F1 Macro: 0.2448, Accuracy: 0.2500\n","Epoch 15, Train Loss: 54.9519, Val Loss: 30.6907, F1 Micro: 0.3854, F1 Macro: 0.3480, Accuracy: 0.3854\n","Epoch 16, Train Loss: 35.1749, Val Loss: 115.5025, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 17, Train Loss: 64.3788, Val Loss: 18.4614, F1 Micro: 0.5729, F1 Macro: 0.4657, Accuracy: 0.5729\n","Epoch 18, Train Loss: 51.7644, Val Loss: 62.8366, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 19, Train Loss: 36.9948, Val Loss: 23.5891, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 20, Train Loss: 34.1781, Val Loss: 16.6544, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 21, Train Loss: 22.7164, Val Loss: 33.3919, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 22, Train Loss: 37.9935, Val Loss: 13.5049, F1 Micro: 0.6562, F1 Macro: 0.5211, Accuracy: 0.6562\n","Epoch 23, Train Loss: 11.6389, Val Loss: 14.8053, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 24, Train Loss: 31.3027, Val Loss: 53.5259, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 25, Train Loss: 33.7625, Val Loss: 32.3340, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 26, Train Loss: 39.2636, Val Loss: 20.8222, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 27, Train Loss: 54.4208, Val Loss: 78.1089, F1 Micro: 0.1562, F1 Macro: 0.1540, Accuracy: 0.1562\n","Epoch 28, Train Loss: 26.9024, Val Loss: 7.6912, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 29, Train Loss: 6.9872, Val Loss: 2.9605, F1 Micro: 0.7292, F1 Macro: 0.5735, Accuracy: 0.7292\n","Epoch 30, Train Loss: 12.5410, Val Loss: 22.2999, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 31, Train Loss: 50.2376, Val Loss: 20.5701, F1 Micro: 0.7188, F1 Macro: 0.5060, Accuracy: 0.7188\n","Epoch 32, Train Loss: 15.8283, Val Loss: 17.5132, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 33, Train Loss: 14.0180, Val Loss: 29.8473, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 34, Train Loss: 22.9696, Val Loss: 8.8777, F1 Micro: 0.4792, F1 Macro: 0.4228, Accuracy: 0.4792\n","Epoch 35, Train Loss: 14.4861, Val Loss: 12.0685, F1 Micro: 0.3438, F1 Macro: 0.3315, Accuracy: 0.3438\n","Epoch 36, Train Loss: 12.1786, Val Loss: 6.2936, F1 Micro: 0.6146, F1 Macro: 0.5060, Accuracy: 0.6146\n","Epoch 37, Train Loss: 5.4676, Val Loss: 2.9606, F1 Micro: 0.9062, F1 Macro: 0.5660, Accuracy: 0.9062\n","Epoch 38, Train Loss: 9.7158, Val Loss: 6.3289, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 39, Train Loss: 13.7874, Val Loss: 38.4548, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 40, Train Loss: 25.8097, Val Loss: 12.2274, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 41, Train Loss: 21.2159, Val Loss: 16.5122, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 42, Train Loss: 15.3929, Val Loss: 2.9331, F1 Micro: 0.7917, F1 Macro: 0.5551, Accuracy: 0.7917\n","Epoch 43, Train Loss: 9.5968, Val Loss: 9.9829, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 44, Train Loss: 8.0668, Val Loss: 1.8397, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 45, Train Loss: 8.1225, Val Loss: 15.0909, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 46, Train Loss: 13.5364, Val Loss: 11.1808, F1 Micro: 0.6667, F1 Macro: 0.5283, Accuracy: 0.6667\n","Epoch 47, Train Loss: 8.1438, Val Loss: 12.1185, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 48, Train Loss: 8.1788, Val Loss: 10.3611, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 49, Train Loss: 4.8634, Val Loss: 2.9979, F1 Micro: 0.8958, F1 Macro: 0.5556, Accuracy: 0.8958\n","Epoch 50, Train Loss: 6.4650, Val Loss: 11.2738, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 51, Train Loss: 10.1404, Val Loss: 5.8407, F1 Micro: 0.5521, F1 Macro: 0.4921, Accuracy: 0.5521\n","Epoch 52, Train Loss: 5.2670, Val Loss: 4.2409, F1 Micro: 0.5312, F1 Macro: 0.4767, Accuracy: 0.5312\n","Epoch 53, Train Loss: 4.6396, Val Loss: 4.7928, F1 Micro: 0.7708, F1 Macro: 0.5654, Accuracy: 0.7708\n","Epoch 54, Train Loss: 16.6280, Val Loss: 15.3492, F1 Micro: 0.3438, F1 Macro: 0.3315, Accuracy: 0.3438\n","Epoch 55, Train Loss: 7.5717, Val Loss: 8.0415, F1 Micro: 0.7500, F1 Macro: 0.5500, Accuracy: 0.7500\n","Epoch 56, Train Loss: 6.4256, Val Loss: 12.2541, F1 Micro: 0.7500, F1 Macro: 0.5500, Accuracy: 0.7500\n","Epoch 57, Train Loss: 14.9814, Val Loss: 26.4910, F1 Micro: 0.7396, F1 Macro: 0.4613, Accuracy: 0.7396\n","Epoch 58, Train Loss: 16.2288, Val Loss: 22.1809, F1 Micro: 0.2188, F1 Macro: 0.2187, Accuracy: 0.2188\n","Epoch 59, Train Loss: 6.3590, Val Loss: 6.8654, F1 Micro: 0.4375, F1 Macro: 0.4063, Accuracy: 0.4375\n","Epoch 60, Train Loss: 7.0094, Val Loss: 4.6251, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Epoch 61, Train Loss: 8.1244, Val Loss: 1.4501, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 62, Train Loss: 8.4386, Val Loss: 23.9179, F1 Micro: 0.2604, F1 Macro: 0.2584, Accuracy: 0.2604\n","Epoch 63, Train Loss: 5.8707, Val Loss: 2.9935, F1 Micro: 0.6146, F1 Macro: 0.5384, Accuracy: 0.6146\n","Epoch 64, Train Loss: 7.2509, Val Loss: 6.2903, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 65, Train Loss: 4.3758, Val Loss: 0.3591, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 66, Train Loss: 1.8251, Val Loss: 1.3265, F1 Micro: 0.8958, F1 Macro: 0.6591, Accuracy: 0.8958\n","Epoch 67, Train Loss: 2.4097, Val Loss: 7.0455, F1 Micro: 0.5417, F1 Macro: 0.4844, Accuracy: 0.5417\n","Epoch 68, Train Loss: 3.0098, Val Loss: 3.4208, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 69, Train Loss: 3.7001, Val Loss: 0.5691, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 70, Train Loss: 5.0890, Val Loss: 1.7021, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 71, Train Loss: 2.4067, Val Loss: 1.8837, F1 Micro: 0.8125, F1 Macro: 0.6783, Accuracy: 0.8125\n","Epoch 72, Train Loss: 2.5574, Val Loss: 4.8351, F1 Micro: 0.5312, F1 Macro: 0.4767, Accuracy: 0.5312\n","Epoch 73, Train Loss: 5.7303, Val Loss: 17.5667, F1 Micro: 0.7500, F1 Macro: 0.4662, Accuracy: 0.7500\n","Epoch 74, Train Loss: 8.7384, Val Loss: 2.8720, F1 Micro: 0.7396, F1 Macro: 0.6123, Accuracy: 0.7396\n","Epoch 75, Train Loss: 2.6499, Val Loss: 9.9410, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 76, Train Loss: 4.6310, Val Loss: 6.0344, F1 Micro: 0.6667, F1 Macro: 0.5426, Accuracy: 0.6667\n","Epoch 77, Train Loss: 5.4963, Val Loss: 4.8230, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 78, Train Loss: 4.0391, Val Loss: 3.4296, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 79, Train Loss: 11.8677, Val Loss: 9.0887, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 80, Train Loss: 3.0797, Val Loss: 2.1320, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 81, Train Loss: 4.3905, Val Loss: 1.7755, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 82, Train Loss: 3.5488, Val Loss: 7.0236, F1 Micro: 0.7188, F1 Macro: 0.5813, Accuracy: 0.7188\n","Epoch 83, Train Loss: 2.6718, Val Loss: 0.2210, F1 Micro: 0.9375, F1 Macro: 0.8326, Accuracy: 0.9375\n","Epoch 84, Train Loss: 2.8106, Val Loss: 1.2484, F1 Micro: 0.8542, F1 Macro: 0.7375, Accuracy: 0.8542\n","Epoch 85, Train Loss: 2.8211, Val Loss: 0.8103, F1 Micro: 0.8854, F1 Macro: 0.6023, Accuracy: 0.8854\n","Epoch 86, Train Loss: 3.4627, Val Loss: 10.7587, F1 Micro: 0.6979, F1 Macro: 0.5146, Accuracy: 0.6979\n","Epoch 87, Train Loss: 10.4243, Val Loss: 19.0074, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 88, Train Loss: 27.0341, Val Loss: 28.3725, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 89, Train Loss: 38.5939, Val Loss: 64.9909, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 90, Train Loss: 37.8040, Val Loss: 57.4207, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 91, Train Loss: 22.2723, Val Loss: 6.5244, F1 Micro: 0.5208, F1 Macro: 0.4690, Accuracy: 0.5208\n","Epoch 92, Train Loss: 4.1972, Val Loss: 2.9338, F1 Micro: 0.6875, F1 Macro: 0.5944, Accuracy: 0.6875\n","Epoch 93, Train Loss: 4.1418, Val Loss: 5.6830, F1 Micro: 0.7500, F1 Macro: 0.5897, Accuracy: 0.7500\n","Epoch 94, Train Loss: 2.8750, Val Loss: 3.5270, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 95, Train Loss: 2.3322, Val Loss: 2.8270, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 96, Train Loss: 4.1500, Val Loss: 5.3250, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 97, Train Loss: 3.4412, Val Loss: 1.6820, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 98, Train Loss: 4.6154, Val Loss: 3.2288, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 99, Train Loss: 1.3758, Val Loss: 2.1667, F1 Micro: 0.7604, F1 Macro: 0.6554, Accuracy: 0.7604\n","Epoch 100, Train Loss: 1.6802, Val Loss: 3.7822, F1 Micro: 0.7917, F1 Macro: 0.6426, Accuracy: 0.7917\n","Epoch 101, Train Loss: 1.4395, Val Loss: 0.4770, F1 Micro: 0.9271, F1 Macro: 0.8271, Accuracy: 0.9271\n","Epoch 102, Train Loss: 1.6668, Val Loss: 1.7477, F1 Micro: 0.8021, F1 Macro: 0.6820, Accuracy: 0.8021\n","Epoch 103, Train Loss: 0.9924, Val Loss: 1.4725, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 104, Train Loss: 1.9551, Val Loss: 2.5830, F1 Micro: 0.7917, F1 Macro: 0.6426, Accuracy: 0.7917\n","Epoch 105, Train Loss: 1.9292, Val Loss: 0.6828, F1 Micro: 0.8750, F1 Macro: 0.7491, Accuracy: 0.8750\n","Epoch 106, Train Loss: 2.7151, Val Loss: 4.5830, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 107, Train Loss: 5.3925, Val Loss: 2.1472, F1 Micro: 0.8333, F1 Macro: 0.7000, Accuracy: 0.8333\n","Epoch 108, Train Loss: 2.2053, Val Loss: 1.5360, F1 Micro: 0.8542, F1 Macro: 0.7375, Accuracy: 0.8542\n","Epoch 109, Train Loss: 1.7588, Val Loss: 0.3157, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 110, Train Loss: 2.2317, Val Loss: 0.6379, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 111, Train Loss: 2.4466, Val Loss: 2.3136, F1 Micro: 0.8333, F1 Macro: 0.6840, Accuracy: 0.8333\n","Epoch 112, Train Loss: 1.5635, Val Loss: 0.8459, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 113, Train Loss: 1.1447, Val Loss: 0.5768, F1 Micro: 0.9167, F1 Macro: 0.7767, Accuracy: 0.9167\n","Epoch 114, Train Loss: 0.9098, Val Loss: 0.7663, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 115, Train Loss: 0.7420, Val Loss: 0.8657, F1 Micro: 0.9375, F1 Macro: 0.8460, Accuracy: 0.9375\n","Epoch 116, Train Loss: 1.7967, Val Loss: 3.5548, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 117, Train Loss: 1.3779, Val Loss: 0.2667, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 118, Train Loss: 0.4894, Val Loss: 0.3076, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 119, Train Loss: 0.6629, Val Loss: 0.8312, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 120, Train Loss: 0.7571, Val Loss: 5.6869, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 121, Train Loss: 6.1367, Val Loss: 11.8731, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 122, Train Loss: 4.0640, Val Loss: 2.1095, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 123, Train Loss: 0.7482, Val Loss: 0.9397, F1 Micro: 0.8646, F1 Macro: 0.7621, Accuracy: 0.8646\n","Epoch 124, Train Loss: 0.7365, Val Loss: 0.7730, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 125, Train Loss: 1.4234, Val Loss: 4.1369, F1 Micro: 0.7188, F1 Macro: 0.5813, Accuracy: 0.7188\n","Epoch 126, Train Loss: 7.1516, Val Loss: 3.3418, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 127, Train Loss: 1.9888, Val Loss: 2.1613, F1 Micro: 0.8854, F1 Macro: 0.6023, Accuracy: 0.8854\n","Epoch 128, Train Loss: 1.3408, Val Loss: 1.4147, F1 Micro: 0.7917, F1 Macro: 0.6842, Accuracy: 0.7917\n","Epoch 129, Train Loss: 1.4818, Val Loss: 3.8976, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 130, Train Loss: 3.7933, Val Loss: 0.2873, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 131, Train Loss: 1.0370, Val Loss: 0.2638, F1 Micro: 0.9375, F1 Macro: 0.8326, Accuracy: 0.9375\n","Epoch 132, Train Loss: 0.5703, Val Loss: 0.2115, F1 Micro: 0.9375, F1 Macro: 0.7955, Accuracy: 0.9375\n","Epoch 133, Train Loss: 1.0118, Val Loss: 1.3430, F1 Micro: 0.8333, F1 Macro: 0.7141, Accuracy: 0.8333\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1085.4010, Val Loss: 221.6726, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 159.6500, Val Loss: 176.2525, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 99.3104, Val Loss: 31.7432, F1 Micro: 0.7083, F1 Macro: 0.4996, Accuracy: 0.7083\n","Epoch 4, Train Loss: 95.1280, Val Loss: 234.4631, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 55.2740, Val Loss: 89.8186, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 6, Train Loss: 107.5911, Val Loss: 276.2127, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 7, Train Loss: 128.2057, Val Loss: 45.5019, F1 Micro: 0.6042, F1 Macro: 0.4862, Accuracy: 0.6042\n","Epoch 8, Train Loss: 117.0229, Val Loss: 59.5953, F1 Micro: 0.4062, F1 Macro: 0.3820, Accuracy: 0.4062\n","Epoch 9, Train Loss: 73.6688, Val Loss: 233.4249, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 10, Train Loss: 156.3380, Val Loss: 250.9219, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 11, Train Loss: 158.1858, Val Loss: 234.9000, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 12, Train Loss: 92.3187, Val Loss: 127.5473, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 13, Train Loss: 43.1352, Val Loss: 114.5318, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 14, Train Loss: 51.1889, Val Loss: 94.3257, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 15, Train Loss: 45.6849, Val Loss: 118.9154, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 16, Train Loss: 37.0125, Val Loss: 16.6310, F1 Micro: 0.5104, F1 Macro: 0.4534, Accuracy: 0.5104\n","Epoch 17, Train Loss: 35.6421, Val Loss: 28.2858, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 18, Train Loss: 31.2447, Val Loss: 86.9048, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 19, Train Loss: 63.9588, Val Loss: 196.7837, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 118.3123, Val Loss: 105.2259, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 21, Train Loss: 38.4197, Val Loss: 48.6707, F1 Micro: 0.2188, F1 Macro: 0.2118, Accuracy: 0.2188\n","Epoch 22, Train Loss: 23.8460, Val Loss: 29.0328, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 23, Train Loss: 21.4961, Val Loss: 11.1223, F1 Micro: 0.6042, F1 Macro: 0.5105, Accuracy: 0.6042\n","Epoch 24, Train Loss: 16.9890, Val Loss: 17.3027, F1 Micro: 0.7708, F1 Macro: 0.5401, Accuracy: 0.7708\n","Epoch 25, Train Loss: 22.1006, Val Loss: 36.1810, F1 Micro: 0.2396, F1 Macro: 0.2355, Accuracy: 0.2396\n","Epoch 26, Train Loss: 36.6864, Val Loss: 43.2248, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 27, Train Loss: 26.9668, Val Loss: 23.0064, F1 Micro: 0.3958, F1 Macro: 0.3786, Accuracy: 0.3958\n","Epoch 28, Train Loss: 32.0737, Val Loss: 69.2751, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 29, Train Loss: 40.7306, Val Loss: 18.4539, F1 Micro: 0.6250, F1 Macro: 0.5253, Accuracy: 0.6250\n","Epoch 30, Train Loss: 10.2680, Val Loss: 11.2125, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 31, Train Loss: 19.5582, Val Loss: 13.7883, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 32, Train Loss: 32.3654, Val Loss: 27.5934, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 33, Train Loss: 7.2328, Val Loss: 18.3074, F1 Micro: 0.7812, F1 Macro: 0.5475, Accuracy: 0.7812\n","Epoch 34, Train Loss: 16.0900, Val Loss: 26.9029, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 35, Train Loss: 11.6160, Val Loss: 38.8730, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 36, Train Loss: 20.0871, Val Loss: 17.9045, F1 Micro: 0.3229, F1 Macro: 0.3211, Accuracy: 0.3229\n","Epoch 37, Train Loss: 16.3415, Val Loss: 4.9691, F1 Micro: 0.5833, F1 Macro: 0.5382, Accuracy: 0.5833\n","Epoch 38, Train Loss: 7.4426, Val Loss: 5.8278, F1 Micro: 0.3750, F1 Macro: 0.3725, Accuracy: 0.3750\n","Epoch 39, Train Loss: 7.4659, Val Loss: 22.8922, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 40, Train Loss: 15.0411, Val Loss: 42.5462, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 41, Train Loss: 17.1265, Val Loss: 11.4669, F1 Micro: 0.4688, F1 Macro: 0.4471, Accuracy: 0.4688\n","Epoch 42, Train Loss: 17.1730, Val Loss: 17.2006, F1 Micro: 0.4792, F1 Macro: 0.4444, Accuracy: 0.4792\n","Epoch 43, Train Loss: 15.0486, Val Loss: 3.1719, F1 Micro: 0.7083, F1 Macro: 0.6393, Accuracy: 0.7083\n","Epoch 44, Train Loss: 11.3110, Val Loss: 15.0028, F1 Micro: 0.8125, F1 Macro: 0.5380, Accuracy: 0.8125\n","Epoch 45, Train Loss: 8.1666, Val Loss: 4.1674, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 46, Train Loss: 8.2853, Val Loss: 1.9103, F1 Micro: 0.7292, F1 Macro: 0.6284, Accuracy: 0.7292\n","Epoch 47, Train Loss: 12.9592, Val Loss: 9.5729, F1 Micro: 0.7604, F1 Macro: 0.5982, Accuracy: 0.7604\n","Epoch 48, Train Loss: 11.4991, Val Loss: 6.2994, F1 Micro: 0.4688, F1 Macro: 0.4471, Accuracy: 0.4688\n","Epoch 49, Train Loss: 17.8985, Val Loss: 17.2951, F1 Micro: 0.4167, F1 Macro: 0.4040, Accuracy: 0.4167\n","Epoch 50, Train Loss: 7.6332, Val Loss: 4.4371, F1 Micro: 0.5833, F1 Macro: 0.5504, Accuracy: 0.5833\n","Epoch 51, Train Loss: 4.8610, Val Loss: 11.7538, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 52, Train Loss: 7.5218, Val Loss: 3.0112, F1 Micro: 0.8646, F1 Macro: 0.7360, Accuracy: 0.8646\n","Epoch 53, Train Loss: 7.0585, Val Loss: 13.3966, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 54, Train Loss: 4.6372, Val Loss: 6.3472, F1 Micro: 0.5833, F1 Macro: 0.5236, Accuracy: 0.5833\n","Epoch 55, Train Loss: 13.3359, Val Loss: 9.9939, F1 Micro: 0.4271, F1 Macro: 0.4164, Accuracy: 0.4271\n","Epoch 56, Train Loss: 18.2872, Val Loss: 12.3440, F1 Micro: 0.6562, F1 Macro: 0.5594, Accuracy: 0.6562\n","Epoch 57, Train Loss: 16.1160, Val Loss: 13.3707, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 58, Train Loss: 2.3471, Val Loss: 0.6857, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 59, Train Loss: 4.3978, Val Loss: 1.9244, F1 Micro: 0.8646, F1 Macro: 0.6789, Accuracy: 0.8646\n","Epoch 60, Train Loss: 11.5867, Val Loss: 1.2458, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 61, Train Loss: 7.1495, Val Loss: 2.7466, F1 Micro: 0.7812, F1 Macro: 0.7042, Accuracy: 0.7812\n","Epoch 62, Train Loss: 2.5183, Val Loss: 3.0582, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 63, Train Loss: 1.5802, Val Loss: 2.5937, F1 Micro: 0.7292, F1 Macro: 0.6723, Accuracy: 0.7292\n","Epoch 64, Train Loss: 1.9138, Val Loss: 2.7285, F1 Micro: 0.7188, F1 Macro: 0.6632, Accuracy: 0.7188\n","Epoch 65, Train Loss: 2.4493, Val Loss: 4.2129, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 66, Train Loss: 4.0241, Val Loss: 1.0005, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 67, Train Loss: 4.7680, Val Loss: 5.6441, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 68, Train Loss: 7.8402, Val Loss: 17.3204, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 69, Train Loss: 6.1492, Val Loss: 11.5723, F1 Micro: 0.7604, F1 Macro: 0.5982, Accuracy: 0.7604\n","Epoch 70, Train Loss: 4.8574, Val Loss: 2.4903, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 71, Train Loss: 4.2601, Val Loss: 1.3466, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 72, Train Loss: 3.7369, Val Loss: 3.1563, F1 Micro: 0.8438, F1 Macro: 0.5990, Accuracy: 0.8438\n","Epoch 73, Train Loss: 2.7802, Val Loss: 1.3911, F1 Micro: 0.8229, F1 Macro: 0.7533, Accuracy: 0.8229\n","Epoch 74, Train Loss: 2.6497, Val Loss: 5.3945, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 75, Train Loss: 2.2956, Val Loss: 0.9217, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 76, Train Loss: 1.2887, Val Loss: 1.9696, F1 Micro: 0.8333, F1 Macro: 0.7641, Accuracy: 0.8333\n","Epoch 77, Train Loss: 1.2466, Val Loss: 1.5054, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 78, Train Loss: 3.8101, Val Loss: 1.0192, F1 Micro: 0.9167, F1 Macro: 0.8632, Accuracy: 0.9167\n","Epoch 79, Train Loss: 1.5797, Val Loss: 5.3820, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 80, Train Loss: 3.1815, Val Loss: 3.2729, F1 Micro: 0.6667, F1 Macro: 0.6047, Accuracy: 0.6667\n","Epoch 81, Train Loss: 4.6550, Val Loss: 0.9479, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 82, Train Loss: 1.6615, Val Loss: 0.3725, F1 Micro: 0.9375, F1 Macro: 0.8875, Accuracy: 0.9375\n","Epoch 83, Train Loss: 0.6992, Val Loss: 0.6381, F1 Micro: 0.9167, F1 Macro: 0.8632, Accuracy: 0.9167\n","Epoch 84, Train Loss: 1.1948, Val Loss: 1.6611, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 85, Train Loss: 1.8285, Val Loss: 6.8774, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 86, Train Loss: 4.7113, Val Loss: 4.8708, F1 Micro: 0.7812, F1 Macro: 0.6621, Accuracy: 0.7812\n","Epoch 87, Train Loss: 5.6104, Val Loss: 0.8648, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 88, Train Loss: 0.9333, Val Loss: 1.0053, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 89, Train Loss: 1.6010, Val Loss: 0.7717, F1 Micro: 0.8750, F1 Macro: 0.7949, Accuracy: 0.8750\n","Epoch 90, Train Loss: 6.3038, Val Loss: 8.2503, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 91, Train Loss: 4.5152, Val Loss: 4.7266, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 92, Train Loss: 3.9908, Val Loss: 3.0342, F1 Micro: 0.7396, F1 Macro: 0.6662, Accuracy: 0.7396\n","Epoch 93, Train Loss: 4.6579, Val Loss: 14.0328, F1 Micro: 0.8229, F1 Macro: 0.6337, Accuracy: 0.8229\n","Epoch 94, Train Loss: 11.2342, Val Loss: 15.3490, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 95, Train Loss: 4.6624, Val Loss: 2.2554, F1 Micro: 0.8542, F1 Macro: 0.7073, Accuracy: 0.8542\n","Epoch 96, Train Loss: 1.6708, Val Loss: 0.4687, F1 Micro: 0.9167, F1 Macro: 0.8570, Accuracy: 0.9167\n","Epoch 97, Train Loss: 3.7488, Val Loss: 2.6668, F1 Micro: 0.7917, F1 Macro: 0.6842, Accuracy: 0.7917\n","Epoch 98, Train Loss: 2.0811, Val Loss: 0.9427, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 99, Train Loss: 0.7701, Val Loss: 1.5348, F1 Micro: 0.7500, F1 Macro: 0.6667, Accuracy: 0.7500\n","Epoch 100, Train Loss: 1.3690, Val Loss: 1.8605, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 101, Train Loss: 0.9721, Val Loss: 1.3501, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 102, Train Loss: 0.8438, Val Loss: 0.3978, F1 Micro: 0.9375, F1 Macro: 0.8875, Accuracy: 0.9375\n","Epoch 103, Train Loss: 0.6356, Val Loss: 1.5752, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 104, Train Loss: 0.8512, Val Loss: 1.1411, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 105, Train Loss: 4.3215, Val Loss: 1.5830, F1 Micro: 0.8542, F1 Macro: 0.7498, Accuracy: 0.8542\n","Epoch 106, Train Loss: 1.6301, Val Loss: 3.0253, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 107, Train Loss: 1.9153, Val Loss: 17.5939, F1 Micro: 0.7708, F1 Macro: 0.6069, Accuracy: 0.7708\n","Epoch 108, Train Loss: 4.9338, Val Loss: 1.1795, F1 Micro: 0.8854, F1 Macro: 0.8230, Accuracy: 0.8854\n","Epoch 109, Train Loss: 3.2155, Val Loss: 1.6320, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 110, Train Loss: 1.0675, Val Loss: 1.0158, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 111, Train Loss: 1.0187, Val Loss: 0.5793, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 112, Train Loss: 1.5642, Val Loss: 1.4294, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 113, Train Loss: 1.8790, Val Loss: 3.3546, F1 Micro: 0.8438, F1 Macro: 0.7256, Accuracy: 0.8438\n","Epoch 114, Train Loss: 6.3102, Val Loss: 11.1320, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 115, Train Loss: 9.5693, Val Loss: 32.1917, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 116, Train Loss: 8.3764, Val Loss: 0.4289, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 117, Train Loss: 4.4677, Val Loss: 15.5037, F1 Micro: 0.6250, F1 Macro: 0.5462, Accuracy: 0.6250\n","Epoch 118, Train Loss: 5.9276, Val Loss: 3.3331, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 119, Train Loss: 2.2764, Val Loss: 0.6166, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 120, Train Loss: 2.3915, Val Loss: 5.6890, F1 Micro: 0.7812, F1 Macro: 0.6621, Accuracy: 0.7812\n","Epoch 121, Train Loss: 2.8665, Val Loss: 5.3544, F1 Micro: 0.8333, F1 Macro: 0.7000, Accuracy: 0.8333\n","Epoch 122, Train Loss: 2.4779, Val Loss: 0.9046, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 123, Train Loss: 1.2733, Val Loss: 0.9533, F1 Micro: 0.9167, F1 Macro: 0.8570, Accuracy: 0.9167\n","Epoch 124, Train Loss: 1.7442, Val Loss: 1.2999, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 125, Train Loss: 1.2313, Val Loss: 0.8620, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 126, Train Loss: 0.6780, Val Loss: 0.2929, F1 Micro: 0.9479, F1 Macro: 0.8985, Accuracy: 0.9479\n","Epoch 127, Train Loss: 1.7158, Val Loss: 3.0964, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 128, Train Loss: 3.0754, Val Loss: 24.0199, F1 Micro: 0.7917, F1 Macro: 0.6049, Accuracy: 0.7917\n","Epoch 129, Train Loss: 5.8940, Val Loss: 10.1695, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 130, Train Loss: 11.2771, Val Loss: 1.6674, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 131, Train Loss: 2.5761, Val Loss: 3.7334, F1 Micro: 0.7083, F1 Macro: 0.6541, Accuracy: 0.7083\n","Epoch 132, Train Loss: 1.4094, Val Loss: 1.7129, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 133, Train Loss: 1.1927, Val Loss: 3.3449, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 134, Train Loss: 5.2689, Val Loss: 15.9139, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 135, Train Loss: 2.7149, Val Loss: 1.1472, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 136, Train Loss: 1.0231, Val Loss: 1.4765, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 137, Train Loss: 0.6715, Val Loss: 1.5043, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 138, Train Loss: 4.6058, Val Loss: 3.8107, F1 Micro: 0.8438, F1 Macro: 0.7256, Accuracy: 0.8438\n","Epoch 139, Train Loss: 3.0616, Val Loss: 2.3719, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 140, Train Loss: 0.9682, Val Loss: 0.9445, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 141, Train Loss: 2.2354, Val Loss: 3.2323, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 142, Train Loss: 1.9063, Val Loss: 0.4189, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 143, Train Loss: 0.4567, Val Loss: 0.3783, F1 Micro: 0.9375, F1 Macro: 0.8815, Accuracy: 0.9375\n","Epoch 144, Train Loss: 0.5197, Val Loss: 0.4414, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 145, Train Loss: 1.2688, Val Loss: 2.7324, F1 Micro: 0.8646, F1 Macro: 0.7729, Accuracy: 0.8646\n","Epoch 146, Train Loss: 9.7322, Val Loss: 1.2436, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 147, Train Loss: 7.3093, Val Loss: 2.8153, F1 Micro: 0.8438, F1 Macro: 0.7674, Accuracy: 0.8438\n","Epoch 148, Train Loss: 2.3133, Val Loss: 0.9126, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 149, Train Loss: 2.4634, Val Loss: 1.3869, F1 Micro: 0.8750, F1 Macro: 0.7491, Accuracy: 0.8750\n","Epoch 150, Train Loss: 1.3551, Val Loss: 0.7593, F1 Micro: 0.9271, F1 Macro: 0.8777, Accuracy: 0.9271\n","Epoch 151, Train Loss: 0.9125, Val Loss: 1.3771, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 152, Train Loss: 2.7008, Val Loss: 0.8744, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 153, Train Loss: 0.6944, Val Loss: 0.8822, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 154, Train Loss: 0.6616, Val Loss: 0.5442, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 155, Train Loss: 0.5578, Val Loss: 0.6618, F1 Micro: 0.9375, F1 Macro: 0.8746, Accuracy: 0.9375\n","Epoch 156, Train Loss: 4.8613, Val Loss: 0.8167, F1 Micro: 0.9375, F1 Macro: 0.8875, Accuracy: 0.9375\n","Epoch 157, Train Loss: 2.7026, Val Loss: 5.6438, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 158, Train Loss: 2.4228, Val Loss: 3.0926, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 159, Train Loss: 4.3868, Val Loss: 23.4061, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 160, Train Loss: 4.5783, Val Loss: 2.4680, F1 Micro: 0.8333, F1 Macro: 0.7641, Accuracy: 0.8333\n","Epoch 161, Train Loss: 1.1022, Val Loss: 0.3458, F1 Micro: 0.9375, F1 Macro: 0.8665, Accuracy: 0.9375\n","Epoch 162, Train Loss: 0.8352, Val Loss: 0.4306, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 163, Train Loss: 1.0238, Val Loss: 1.3661, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 164, Train Loss: 0.8887, Val Loss: 0.6553, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 165, Train Loss: 0.5882, Val Loss: 0.3464, F1 Micro: 0.9479, F1 Macro: 0.8985, Accuracy: 0.9479\n","Epoch 166, Train Loss: 0.8273, Val Loss: 10.0006, F1 Micro: 0.8646, F1 Macro: 0.7011, Accuracy: 0.8646\n","Epoch 167, Train Loss: 2.3941, Val Loss: 0.4016, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 168, Train Loss: 1.3486, Val Loss: 0.5522, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 169, Train Loss: 0.4720, Val Loss: 0.5949, F1 Micro: 0.9375, F1 Macro: 0.8875, Accuracy: 0.9375\n","Epoch 170, Train Loss: 0.4963, Val Loss: 1.5257, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 171, Train Loss: 2.2414, Val Loss: 2.0445, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 172, Train Loss: 9.7976, Val Loss: 38.4633, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 173, Train Loss: 12.0916, Val Loss: 17.5790, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 174, Train Loss: 3.9941, Val Loss: 7.3271, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 175, Train Loss: 3.1994, Val Loss: 10.2667, F1 Micro: 0.6875, F1 Macro: 0.5944, Accuracy: 0.6875\n","Epoch 176, Train Loss: 3.1132, Val Loss: 0.4415, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.9479166666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 58.6802, Val Loss: 5.0610, F1 Micro: 0.7396, F1 Macro: 0.6575, Accuracy: 0.7396\n","Epoch 2, Train Loss: 11.9236, Val Loss: 7.4557, F1 Micro: 0.7917, F1 Macro: 0.5819, Accuracy: 0.7917\n","Epoch 3, Train Loss: 21.3356, Val Loss: 7.9769, F1 Micro: 0.7917, F1 Macro: 0.5551, Accuracy: 0.7917\n","Epoch 4, Train Loss: 14.9367, Val Loss: 5.2786, F1 Micro: 0.6146, F1 Macro: 0.5629, Accuracy: 0.6146\n","Epoch 5, Train Loss: 14.4552, Val Loss: 20.5766, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 25.9336, Val Loss: 50.5567, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 15.6136, Val Loss: 3.6139, F1 Micro: 0.7500, F1 Macro: 0.6667, Accuracy: 0.7500\n","Epoch 8, Train Loss: 19.6917, Val Loss: 38.8885, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 9, Train Loss: 21.5882, Val Loss: 11.5595, F1 Micro: 0.3021, F1 Macro: 0.2984, Accuracy: 0.3021\n","Epoch 10, Train Loss: 29.1793, Val Loss: 11.2383, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 11, Train Loss: 25.2322, Val Loss: 9.4589, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 12, Train Loss: 16.8321, Val Loss: 35.7672, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 47.1772, Val Loss: 6.2659, F1 Micro: 0.5729, F1 Macro: 0.5362, Accuracy: 0.5729\n","Epoch 14, Train Loss: 61.2785, Val Loss: 6.2440, F1 Micro: 0.6250, F1 Macro: 0.5712, Accuracy: 0.6250\n","Epoch 15, Train Loss: 24.2170, Val Loss: 23.5231, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 111.1929, Val Loss: 32.0964, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 29.8238, Val Loss: 8.3953, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 3, Train Loss: 29.9411, Val Loss: 80.0691, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 4, Train Loss: 40.8715, Val Loss: 32.1678, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 32.5035, Val Loss: 164.2639, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 35.9340, Val Loss: 11.7475, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 7, Train Loss: 57.2155, Val Loss: 18.2700, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 8, Train Loss: 15.9438, Val Loss: 17.4161, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 9, Train Loss: 36.6599, Val Loss: 11.0441, F1 Micro: 0.3333, F1 Macro: 0.3307, Accuracy: 0.3333\n","Epoch 10, Train Loss: 40.1809, Val Loss: 3.2862, F1 Micro: 0.7083, F1 Macro: 0.5214, Accuracy: 0.7083\n","Epoch 11, Train Loss: 18.3916, Val Loss: 10.0296, F1 Micro: 0.3542, F1 Macro: 0.3497, Accuracy: 0.3542\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 99.8705, Val Loss: 74.9539, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 2, Train Loss: 26.0915, Val Loss: 12.6369, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 17.6116, Val Loss: 15.8709, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 4, Train Loss: 36.3017, Val Loss: 52.0882, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 54.6290, Val Loss: 79.0332, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 44.2140, Val Loss: 3.3863, F1 Micro: 0.6667, F1 Macro: 0.5283, Accuracy: 0.6667\n","Epoch 7, Train Loss: 17.2198, Val Loss: 4.1282, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 8, Train Loss: 16.8136, Val Loss: 7.4396, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 9, Train Loss: 60.3987, Val Loss: 9.5500, F1 Micro: 0.4375, F1 Macro: 0.4120, Accuracy: 0.4375\n","Epoch 10, Train Loss: 28.2512, Val Loss: 11.2858, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 11, Train Loss: 17.0883, Val Loss: 15.5304, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 12, Train Loss: 24.4778, Val Loss: 5.9858, F1 Micro: 0.4583, F1 Macro: 0.4222, Accuracy: 0.4583\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 36.0128, Val Loss: 18.4721, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 2, Train Loss: 53.6267, Val Loss: 51.5239, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 3, Train Loss: 56.1533, Val Loss: 99.9094, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 4, Train Loss: 48.3735, Val Loss: 16.0560, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 19.5288, Val Loss: 16.5895, F1 Micro: 0.2708, F1 Macro: 0.2628, Accuracy: 0.2708\n","Epoch 6, Train Loss: 15.6405, Val Loss: 9.7436, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 7, Train Loss: 43.2873, Val Loss: 10.3265, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 8, Train Loss: 30.0459, Val Loss: 36.8239, F1 Micro: 0.1562, F1 Macro: 0.1540, Accuracy: 0.1562\n","Epoch 9, Train Loss: 32.9125, Val Loss: 25.9369, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 10, Train Loss: 28.2363, Val Loss: 83.1466, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 11, Train Loss: 48.2239, Val Loss: 9.9419, F1 Micro: 0.4792, F1 Macro: 0.4045, Accuracy: 0.4792\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 122.0245, Val Loss: 212.8261, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 27.4023, Val Loss: 50.6553, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 23.5885, Val Loss: 6.5582, F1 Micro: 0.5729, F1 Macro: 0.4776, Accuracy: 0.5729\n","Epoch 4, Train Loss: 9.0953, Val Loss: 6.1132, F1 Micro: 0.4583, F1 Macro: 0.4155, Accuracy: 0.4583\n","Epoch 5, Train Loss: 18.4978, Val Loss: 31.7367, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 27.6942, Val Loss: 13.8937, F1 Micro: 0.7500, F1 Macro: 0.4983, Accuracy: 0.7500\n","Epoch 7, Train Loss: 45.1850, Val Loss: 33.6754, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 8, Train Loss: 29.4394, Val Loss: 63.2497, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 9, Train Loss: 26.1478, Val Loss: 26.4787, F1 Micro: 0.2188, F1 Macro: 0.2118, Accuracy: 0.2188\n","Epoch 10, Train Loss: 58.4119, Val Loss: 64.1818, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 11, Train Loss: 24.8614, Val Loss: 22.1075, F1 Micro: 0.7396, F1 Macro: 0.4923, Accuracy: 0.7396\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.8583333333333332\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 27.4737, Val Loss: 8.0594, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 36.9687, Val Loss: 60.1860, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 3, Train Loss: 38.4520, Val Loss: 45.2421, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 31.0738, Val Loss: 5.6329, F1 Micro: 0.8229, F1 Macro: 0.7030, Accuracy: 0.8229\n","Epoch 5, Train Loss: 34.0561, Val Loss: 38.4969, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 6, Train Loss: 25.1595, Val Loss: 23.0651, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 40.4329, Val Loss: 24.0765, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 36.6828, Val Loss: 23.5638, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 9, Train Loss: 27.5666, Val Loss: 56.8085, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 31.7154, Val Loss: 15.6934, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 11, Train Loss: 33.7821, Val Loss: 46.1224, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 26.2028, Val Loss: 10.1659, F1 Micro: 0.7917, F1 Macro: 0.5238, Accuracy: 0.7917\n","Epoch 13, Train Loss: 32.2081, Val Loss: 77.6125, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 14, Train Loss: 39.9632, Val Loss: 19.4217, F1 Micro: 0.3229, F1 Macro: 0.3211, Accuracy: 0.3229\n","Epoch 15, Train Loss: 45.5749, Val Loss: 51.3368, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 16, Train Loss: 19.0554, Val Loss: 47.1156, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 17, Train Loss: 23.6756, Val Loss: 5.9548, F1 Micro: 0.7188, F1 Macro: 0.6395, Accuracy: 0.7188\n","Epoch 18, Train Loss: 29.2537, Val Loss: 12.6531, F1 Micro: 0.4375, F1 Macro: 0.4353, Accuracy: 0.4375\n","Epoch 19, Train Loss: 23.9924, Val Loss: 61.7833, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 20, Train Loss: 24.7975, Val Loss: 10.1884, F1 Micro: 0.5000, F1 Macro: 0.4857, Accuracy: 0.5000\n","Epoch 21, Train Loss: 23.5675, Val Loss: 32.6027, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 22, Train Loss: 18.9868, Val Loss: 66.4251, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 23, Train Loss: 35.4382, Val Loss: 55.1818, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 24, Train Loss: 38.8000, Val Loss: 39.3484, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 25, Train Loss: 52.8126, Val Loss: 7.8139, F1 Micro: 0.7292, F1 Macro: 0.6485, Accuracy: 0.7292\n","Epoch 26, Train Loss: 24.0710, Val Loss: 12.1658, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 27, Train Loss: 29.3639, Val Loss: 6.8325, F1 Micro: 0.6979, F1 Macro: 0.6305, Accuracy: 0.6979\n","Epoch 28, Train Loss: 21.4980, Val Loss: 83.2417, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 29, Train Loss: 53.4418, Val Loss: 70.7329, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 30, Train Loss: 25.4639, Val Loss: 55.5838, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 31, Train Loss: 24.9784, Val Loss: 33.1667, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 32, Train Loss: 47.0389, Val Loss: 126.1795, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 33, Train Loss: 30.5433, Val Loss: 44.8870, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 34, Train Loss: 53.5384, Val Loss: 7.7260, F1 Micro: 0.5833, F1 Macro: 0.5382, Accuracy: 0.5833\n","Epoch 35, Train Loss: 17.2290, Val Loss: 20.5095, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 36, Train Loss: 13.6661, Val Loss: 19.3294, F1 Micro: 0.2812, F1 Macro: 0.2749, Accuracy: 0.2812\n","Epoch 37, Train Loss: 27.5241, Val Loss: 31.9210, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 38, Train Loss: 22.6713, Val Loss: 9.9243, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 39, Train Loss: 32.5580, Val Loss: 68.8892, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 40, Train Loss: 26.7543, Val Loss: 11.3073, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 41, Train Loss: 24.7151, Val Loss: 6.0796, F1 Micro: 0.7708, F1 Macro: 0.6757, Accuracy: 0.7708\n","Epoch 42, Train Loss: 20.0882, Val Loss: 108.3669, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 43, Train Loss: 36.0612, Val Loss: 9.7717, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 44, Train Loss: 31.2863, Val Loss: 12.1919, F1 Micro: 0.5104, F1 Macro: 0.5013, Accuracy: 0.5104\n","Epoch 45, Train Loss: 31.1652, Val Loss: 15.9828, F1 Micro: 0.4167, F1 Macro: 0.4157, Accuracy: 0.4167\n","Epoch 46, Train Loss: 34.4021, Val Loss: 38.6799, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 47, Train Loss: 30.2454, Val Loss: 15.3434, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 48, Train Loss: 44.1056, Val Loss: 40.7396, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 49, Train Loss: 38.2043, Val Loss: 71.7033, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 50, Train Loss: 41.5633, Val Loss: 23.5940, F1 Micro: 0.4167, F1 Macro: 0.4157, Accuracy: 0.4167\n","Epoch 51, Train Loss: 14.9965, Val Loss: 7.7189, F1 Micro: 0.6250, F1 Macro: 0.5712, Accuracy: 0.6250\n","Epoch 52, Train Loss: 12.2531, Val Loss: 121.8948, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 53, Train Loss: 30.5463, Val Loss: 15.2765, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 54, Train Loss: 45.1703, Val Loss: 15.9223, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 102.8973, Val Loss: 2.1064, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 2, Train Loss: 15.8838, Val Loss: 36.6900, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 3, Train Loss: 59.6862, Val Loss: 17.5026, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 22.8601, Val Loss: 38.6431, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 19.5028, Val Loss: 34.4435, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 6, Train Loss: 35.2313, Val Loss: 131.5421, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 7, Train Loss: 70.8892, Val Loss: 40.2493, F1 Micro: 0.1667, F1 Macro: 0.1534, Accuracy: 0.1667\n","Epoch 8, Train Loss: 37.9124, Val Loss: 5.4352, F1 Micro: 0.5833, F1 Macro: 0.5236, Accuracy: 0.5833\n","Epoch 9, Train Loss: 55.9088, Val Loss: 39.3370, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 10, Train Loss: 67.3898, Val Loss: 129.2527, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 11, Train Loss: 38.5309, Val Loss: 5.3834, F1 Micro: 0.7292, F1 Macro: 0.5354, Accuracy: 0.7292\n","Epoch 12, Train Loss: 34.3768, Val Loss: 6.2765, F1 Micro: 0.5208, F1 Macro: 0.4763, Accuracy: 0.5208\n","Epoch 13, Train Loss: 33.0071, Val Loss: 10.4401, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 14, Train Loss: 19.1298, Val Loss: 17.6412, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 15, Train Loss: 27.9069, Val Loss: 25.3429, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 16, Train Loss: 27.8308, Val Loss: 33.9606, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 17, Train Loss: 29.1893, Val Loss: 3.5706, F1 Micro: 0.6771, F1 Macro: 0.5193, Accuracy: 0.6771\n","Epoch 18, Train Loss: 29.6328, Val Loss: 23.1121, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 19, Train Loss: 20.6840, Val Loss: 36.9349, F1 Micro: 0.1667, F1 Macro: 0.1534, Accuracy: 0.1667\n","Epoch 20, Train Loss: 49.8110, Val Loss: 33.0679, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 21, Train Loss: 53.6161, Val Loss: 26.6036, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 22, Train Loss: 65.2237, Val Loss: 85.4868, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 23, Train Loss: 45.1288, Val Loss: 22.0843, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 24, Train Loss: 31.6595, Val Loss: 35.9830, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 25, Train Loss: 46.3041, Val Loss: 22.8304, F1 Micro: 0.3438, F1 Macro: 0.3402, Accuracy: 0.3438\n","Epoch 26, Train Loss: 37.1723, Val Loss: 43.8244, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 27, Train Loss: 33.9600, Val Loss: 32.3217, F1 Micro: 0.2083, F1 Macro: 0.2052, Accuracy: 0.2083\n","Epoch 28, Train Loss: 18.8765, Val Loss: 8.1469, F1 Micro: 0.5104, F1 Macro: 0.4748, Accuracy: 0.5104\n","Epoch 29, Train Loss: 16.4777, Val Loss: 3.9749, F1 Micro: 0.6146, F1 Macro: 0.5178, Accuracy: 0.6146\n","Epoch 30, Train Loss: 31.1326, Val Loss: 27.4411, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 31, Train Loss: 36.1549, Val Loss: 5.3214, F1 Micro: 0.5312, F1 Macro: 0.4842, Accuracy: 0.5312\n","Epoch 32, Train Loss: 15.0053, Val Loss: 20.2489, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 33, Train Loss: 16.3595, Val Loss: 14.6933, F1 Micro: 0.2500, F1 Macro: 0.2497, Accuracy: 0.2500\n","Epoch 34, Train Loss: 19.0937, Val Loss: 12.5922, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 35, Train Loss: 24.1616, Val Loss: 17.8617, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 36, Train Loss: 36.5332, Val Loss: 5.0369, F1 Micro: 0.5312, F1 Macro: 0.4842, Accuracy: 0.5312\n","Epoch 37, Train Loss: 27.5758, Val Loss: 21.4144, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 38, Train Loss: 13.4871, Val Loss: 3.9973, F1 Micro: 0.7188, F1 Macro: 0.5283, Accuracy: 0.7188\n","Epoch 39, Train Loss: 11.0412, Val Loss: 3.4196, F1 Micro: 0.8125, F1 Macro: 0.5380, Accuracy: 0.8125\n","Epoch 40, Train Loss: 29.9239, Val Loss: 24.3852, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 41, Train Loss: 17.0579, Val Loss: 40.7881, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 42, Train Loss: 38.6745, Val Loss: 20.0648, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 43, Train Loss: 27.7729, Val Loss: 4.2375, F1 Micro: 0.8125, F1 Macro: 0.5380, Accuracy: 0.8125\n","Epoch 44, Train Loss: 13.9990, Val Loss: 9.1212, F1 Micro: 0.3750, F1 Macro: 0.3681, Accuracy: 0.3750\n","Epoch 45, Train Loss: 14.9336, Val Loss: 68.3326, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 46, Train Loss: 60.9379, Val Loss: 15.6593, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 47, Train Loss: 44.4852, Val Loss: 41.0573, F1 Micro: 0.1667, F1 Macro: 0.1575, Accuracy: 0.1667\n","Epoch 48, Train Loss: 40.7739, Val Loss: 39.8720, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 49, Train Loss: 35.6166, Val Loss: 11.9832, F1 Micro: 0.4479, F1 Macro: 0.4300, Accuracy: 0.4479\n","Epoch 50, Train Loss: 23.2804, Val Loss: 4.6205, F1 Micro: 0.7292, F1 Macro: 0.5354, Accuracy: 0.7292\n","Epoch 51, Train Loss: 49.5286, Val Loss: 62.0725, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 52, Train Loss: 21.7812, Val Loss: 11.4484, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 53, Train Loss: 10.3665, Val Loss: 11.9600, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 34.8985, Val Loss: 17.6982, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 2, Train Loss: 27.1163, Val Loss: 7.5549, F1 Micro: 0.4375, F1 Macro: 0.4063, Accuracy: 0.4375\n","Epoch 3, Train Loss: 21.9814, Val Loss: 6.0220, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 4, Train Loss: 16.0993, Val Loss: 12.0539, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 20.8020, Val Loss: 4.8827, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 6, Train Loss: 19.6275, Val Loss: 17.4558, F1 Micro: 0.2083, F1 Macro: 0.2080, Accuracy: 0.2083\n","Epoch 7, Train Loss: 88.1425, Val Loss: 52.5728, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 32.3766, Val Loss: 9.8620, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 9, Train Loss: 20.7133, Val Loss: 16.1996, F1 Micro: 0.3021, F1 Macro: 0.2984, Accuracy: 0.3021\n","Epoch 10, Train Loss: 15.2736, Val Loss: 4.8062, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 11, Train Loss: 26.7705, Val Loss: 4.5423, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 12, Train Loss: 17.7605, Val Loss: 31.3147, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 13, Train Loss: 34.6977, Val Loss: 3.9770, F1 Micro: 0.6562, F1 Macro: 0.5211, Accuracy: 0.6562\n","Epoch 14, Train Loss: 13.7356, Val Loss: 11.6041, F1 Micro: 0.2604, F1 Macro: 0.2597, Accuracy: 0.2604\n","Epoch 15, Train Loss: 28.8200, Val Loss: 76.2061, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 16, Train Loss: 54.4395, Val Loss: 56.2997, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 17, Train Loss: 18.7956, Val Loss: 22.2829, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 18, Train Loss: 13.0547, Val Loss: 19.0874, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 19, Train Loss: 32.7635, Val Loss: 7.8616, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 20, Train Loss: 19.6719, Val Loss: 8.6920, F1 Micro: 0.3958, F1 Macro: 0.3786, Accuracy: 0.3958\n","Epoch 21, Train Loss: 35.6303, Val Loss: 8.4993, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 22, Train Loss: 20.7402, Val Loss: 38.1987, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 23, Train Loss: 35.6111, Val Loss: 4.5506, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 24, Train Loss: 32.7595, Val Loss: 5.1892, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 25, Train Loss: 15.0371, Val Loss: 22.1415, F1 Micro: 0.1562, F1 Macro: 0.1517, Accuracy: 0.1562\n","Epoch 26, Train Loss: 27.0845, Val Loss: 3.7188, F1 Micro: 0.6771, F1 Macro: 0.5193, Accuracy: 0.6771\n","Epoch 27, Train Loss: 46.3004, Val Loss: 86.4557, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 28, Train Loss: 55.1273, Val Loss: 21.5683, F1 Micro: 0.2708, F1 Macro: 0.2696, Accuracy: 0.2708\n","Epoch 29, Train Loss: 18.8282, Val Loss: 7.9309, F1 Micro: 0.5417, F1 Macro: 0.4759, Accuracy: 0.5417\n","Epoch 30, Train Loss: 12.3338, Val Loss: 31.8894, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 31, Train Loss: 32.0108, Val Loss: 4.0347, F1 Micro: 0.6354, F1 Macro: 0.5327, Accuracy: 0.6354\n","Epoch 32, Train Loss: 20.9348, Val Loss: 7.0005, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 33, Train Loss: 20.0532, Val Loss: 11.6205, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 34, Train Loss: 26.2197, Val Loss: 71.7938, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 35, Train Loss: 56.2387, Val Loss: 17.1697, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 36, Train Loss: 20.1320, Val Loss: 41.6710, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 37, Train Loss: 31.5193, Val Loss: 5.9642, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 38, Train Loss: 19.9553, Val Loss: 15.5117, F1 Micro: 0.2188, F1 Macro: 0.2187, Accuracy: 0.2188\n","Epoch 39, Train Loss: 45.9434, Val Loss: 12.5848, F1 Micro: 0.3646, F1 Macro: 0.3527, Accuracy: 0.3646\n","Epoch 40, Train Loss: 53.3751, Val Loss: 21.2246, F1 Micro: 0.2604, F1 Macro: 0.2597, Accuracy: 0.2604\n","Epoch 41, Train Loss: 26.2535, Val Loss: 9.2381, F1 Micro: 0.4688, F1 Macro: 0.4301, Accuracy: 0.4688\n","Epoch 42, Train Loss: 16.7217, Val Loss: 7.8634, F1 Micro: 0.4583, F1 Macro: 0.4222, Accuracy: 0.4583\n","Epoch 43, Train Loss: 21.8785, Val Loss: 8.3369, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 44, Train Loss: 27.0971, Val Loss: 57.7224, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 45, Train Loss: 24.4835, Val Loss: 23.5756, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Epoch 46, Train Loss: 21.4669, Val Loss: 26.5380, F1 Micro: 0.1250, F1 Macro: 0.1154, Accuracy: 0.1250\n","Epoch 47, Train Loss: 34.8723, Val Loss: 45.3884, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 48, Train Loss: 38.4388, Val Loss: 8.1821, F1 Micro: 0.5104, F1 Macro: 0.4613, Accuracy: 0.5104\n","Epoch 49, Train Loss: 25.5885, Val Loss: 10.2471, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 50, Train Loss: 25.7231, Val Loss: 33.5337, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 51, Train Loss: 44.3714, Val Loss: 4.6042, F1 Micro: 0.6562, F1 Macro: 0.5351, Accuracy: 0.6562\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 24.9118, Val Loss: 15.5878, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 2, Train Loss: 31.9501, Val Loss: 20.5553, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 3, Train Loss: 34.8335, Val Loss: 14.7053, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 24.0161, Val Loss: 66.2002, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 5, Train Loss: 23.6594, Val Loss: 12.0938, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 6, Train Loss: 24.2912, Val Loss: 11.8321, F1 Micro: 0.3958, F1 Macro: 0.3623, Accuracy: 0.3958\n","Epoch 7, Train Loss: 16.2372, Val Loss: 13.0181, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 34.1612, Val Loss: 21.4622, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 9, Train Loss: 37.4597, Val Loss: 27.4754, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 10, Train Loss: 26.9674, Val Loss: 11.0690, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 65.2316, Val Loss: 56.1573, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 12, Train Loss: 48.0485, Val Loss: 103.6580, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 13, Train Loss: 32.5059, Val Loss: 9.7362, F1 Micro: 0.6771, F1 Macro: 0.5013, Accuracy: 0.6771\n","Epoch 14, Train Loss: 18.4887, Val Loss: 11.4735, F1 Micro: 0.7812, F1 Macro: 0.4813, Accuracy: 0.7812\n","Epoch 15, Train Loss: 25.5300, Val Loss: 70.3503, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 16, Train Loss: 31.2526, Val Loss: 51.9923, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 17, Train Loss: 38.0377, Val Loss: 10.7944, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 18, Train Loss: 31.2994, Val Loss: 8.0257, F1 Micro: 0.6771, F1 Macro: 0.5013, Accuracy: 0.6771\n","Epoch 19, Train Loss: 18.8828, Val Loss: 49.6226, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 20, Train Loss: 30.6035, Val Loss: 12.1771, F1 Micro: 0.3958, F1 Macro: 0.3623, Accuracy: 0.3958\n","Epoch 21, Train Loss: 27.4245, Val Loss: 9.3116, F1 Micro: 0.4688, F1 Macro: 0.4069, Accuracy: 0.4688\n","Epoch 22, Train Loss: 25.7851, Val Loss: 11.0530, F1 Micro: 0.4375, F1 Macro: 0.3852, Accuracy: 0.4375\n","Epoch 23, Train Loss: 15.2835, Val Loss: 9.5668, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 24, Train Loss: 18.6494, Val Loss: 16.3314, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 25, Train Loss: 11.8897, Val Loss: 9.1800, F1 Micro: 0.3854, F1 Macro: 0.3545, Accuracy: 0.3854\n","Epoch 26, Train Loss: 42.9190, Val Loss: 77.9736, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 27, Train Loss: 42.7391, Val Loss: 8.5146, F1 Micro: 0.5833, F1 Macro: 0.4725, Accuracy: 0.5833\n","Epoch 28, Train Loss: 38.3078, Val Loss: 7.8450, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 29, Train Loss: 32.2968, Val Loss: 114.0547, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 30, Train Loss: 45.7751, Val Loss: 11.1764, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 31, Train Loss: 17.4440, Val Loss: 22.6308, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 32, Train Loss: 25.9101, Val Loss: 59.2265, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 33, Train Loss: 33.1516, Val Loss: 32.2459, F1 Micro: 0.2292, F1 Macro: 0.2288, Accuracy: 0.2292\n","Epoch 34, Train Loss: 21.1913, Val Loss: 23.3614, F1 Micro: 0.2500, F1 Macro: 0.2448, Accuracy: 0.2500\n","Epoch 35, Train Loss: 27.0003, Val Loss: 39.2099, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 36, Train Loss: 37.6910, Val Loss: 56.4541, F1 Micro: 0.1146, F1 Macro: 0.1067, Accuracy: 0.1146\n","Epoch 37, Train Loss: 21.2901, Val Loss: 57.7696, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 38, Train Loss: 26.1564, Val Loss: 90.0895, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 39, Train Loss: 55.1975, Val Loss: 34.2842, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 40, Train Loss: 44.3118, Val Loss: 27.9255, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 41, Train Loss: 18.6570, Val Loss: 13.3839, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 42, Train Loss: 13.0882, Val Loss: 24.9217, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 43, Train Loss: 30.3895, Val Loss: 64.5748, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 44, Train Loss: 21.1080, Val Loss: 6.8328, F1 Micro: 0.7188, F1 Macro: 0.5060, Accuracy: 0.7188\n","Epoch 45, Train Loss: 9.3549, Val Loss: 4.7427, F1 Micro: 0.6562, F1 Macro: 0.5211, Accuracy: 0.6562\n","Epoch 46, Train Loss: 24.2220, Val Loss: 8.5823, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 47, Train Loss: 24.9200, Val Loss: 7.2499, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 48, Train Loss: 25.0779, Val Loss: 11.2720, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 49, Train Loss: 39.9525, Val Loss: 58.8693, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 50, Train Loss: 30.2772, Val Loss: 83.3373, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 51, Train Loss: 21.4663, Val Loss: 11.6702, F1 Micro: 0.4479, F1 Macro: 0.3925, Accuracy: 0.4479\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 89.5907, Val Loss: 116.3177, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 83.4039, Val Loss: 75.5505, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 47.9740, Val Loss: 56.7156, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 21.3716, Val Loss: 27.4973, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 5, Train Loss: 27.1332, Val Loss: 14.3115, F1 Micro: 0.3854, F1 Macro: 0.3655, Accuracy: 0.3854\n","Epoch 6, Train Loss: 28.4076, Val Loss: 41.1281, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 7, Train Loss: 24.5787, Val Loss: 30.8737, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 8, Train Loss: 20.2713, Val Loss: 21.8532, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 9, Train Loss: 36.0349, Val Loss: 14.2651, F1 Micro: 0.7396, F1 Macro: 0.5815, Accuracy: 0.7396\n","Epoch 10, Train Loss: 28.6054, Val Loss: 11.4635, F1 Micro: 0.6042, F1 Macro: 0.4862, Accuracy: 0.6042\n","Epoch 11, Train Loss: 12.0100, Val Loss: 34.8693, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 12, Train Loss: 26.1246, Val Loss: 10.7467, F1 Micro: 0.3958, F1 Macro: 0.3786, Accuracy: 0.3958\n","Epoch 13, Train Loss: 12.8846, Val Loss: 17.3733, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 14, Train Loss: 15.6789, Val Loss: 18.4425, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 15, Train Loss: 41.6052, Val Loss: 25.7395, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 16, Train Loss: 20.6513, Val Loss: 9.3408, F1 Micro: 0.4792, F1 Macro: 0.4307, Accuracy: 0.4792\n","Epoch 17, Train Loss: 16.9731, Val Loss: 66.0988, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 18, Train Loss: 20.7207, Val Loss: 10.6083, F1 Micro: 0.7083, F1 Macro: 0.5579, Accuracy: 0.7083\n","Epoch 19, Train Loss: 12.3293, Val Loss: 51.0865, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 24.1460, Val Loss: 27.6963, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 21, Train Loss: 21.2723, Val Loss: 57.5378, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 22, Train Loss: 16.3418, Val Loss: 20.8580, F1 Micro: 0.2188, F1 Macro: 0.2146, Accuracy: 0.2188\n","Epoch 23, Train Loss: 20.1048, Val Loss: 16.1584, F1 Micro: 0.7604, F1 Macro: 0.5044, Accuracy: 0.7604\n","Epoch 24, Train Loss: 10.7140, Val Loss: 21.6057, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 25, Train Loss: 42.6348, Val Loss: 33.9913, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 26, Train Loss: 35.4243, Val Loss: 23.4005, F1 Micro: 0.7812, F1 Macro: 0.4813, Accuracy: 0.7812\n","Epoch 27, Train Loss: 36.3628, Val Loss: 15.1782, F1 Micro: 0.3542, F1 Macro: 0.3471, Accuracy: 0.3542\n","Epoch 28, Train Loss: 14.8834, Val Loss: 12.3666, F1 Micro: 0.7396, F1 Macro: 0.5815, Accuracy: 0.7396\n","Epoch 29, Train Loss: 47.9863, Val Loss: 140.8001, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 30, Train Loss: 75.2070, Val Loss: 21.3106, F1 Micro: 0.7292, F1 Macro: 0.5125, Accuracy: 0.7292\n","Epoch 31, Train Loss: 37.2447, Val Loss: 138.3650, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 32, Train Loss: 31.4563, Val Loss: 19.7621, F1 Micro: 0.7396, F1 Macro: 0.5815, Accuracy: 0.7396\n","Epoch 33, Train Loss: 39.1372, Val Loss: 27.0632, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 34, Train Loss: 12.9563, Val Loss: 13.1030, F1 Micro: 0.5104, F1 Macro: 0.4448, Accuracy: 0.5104\n","Epoch 35, Train Loss: 47.2249, Val Loss: 48.6450, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 36, Train Loss: 28.0837, Val Loss: 32.7337, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 37, Train Loss: 16.3557, Val Loss: 12.7051, F1 Micro: 0.5312, F1 Macro: 0.4594, Accuracy: 0.5312\n","Epoch 38, Train Loss: 20.5269, Val Loss: 13.5110, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 39, Train Loss: 19.7203, Val Loss: 21.0869, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 40, Train Loss: 26.3563, Val Loss: 24.6199, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 41, Train Loss: 20.3337, Val Loss: 12.4198, F1 Micro: 0.3958, F1 Macro: 0.3786, Accuracy: 0.3958\n","Epoch 42, Train Loss: 21.2258, Val Loss: 46.1532, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 43, Train Loss: 29.1653, Val Loss: 13.9049, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 44, Train Loss: 17.1327, Val Loss: 25.9178, F1 Micro: 0.2396, F1 Macro: 0.2375, Accuracy: 0.2396\n","Epoch 45, Train Loss: 17.3680, Val Loss: 37.3740, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 46, Train Loss: 16.6677, Val Loss: 25.3358, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 47, Train Loss: 29.4967, Val Loss: 13.2149, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 48, Train Loss: 14.0100, Val Loss: 18.6579, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 49, Train Loss: 31.7034, Val Loss: 117.8537, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 50, Train Loss: 24.8974, Val Loss: 20.4478, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 51, Train Loss: 34.6700, Val Loss: 25.7365, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.8604166666666668\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 45.9073, Val Loss: 66.8175, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 43.0441, Val Loss: 34.1244, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 32.3497, Val Loss: 48.5907, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 20.3165, Val Loss: 42.1693, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 40.6983, Val Loss: 77.7813, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 30.1988, Val Loss: 1.9207, F1 Micro: 0.6042, F1 Macro: 0.5547, Accuracy: 0.6042\n","Epoch 7, Train Loss: 17.3435, Val Loss: 20.8756, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 11.7966, Val Loss: 2.5164, F1 Micro: 0.6875, F1 Macro: 0.6135, Accuracy: 0.6875\n","Epoch 9, Train Loss: 13.9397, Val Loss: 35.2729, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 43.4925, Val Loss: 64.9516, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 34.4228, Val Loss: 44.5608, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 118.5899, Val Loss: 16.3871, F1 Micro: 0.6458, F1 Macro: 0.4188, Accuracy: 0.6458\n","Epoch 2, Train Loss: 44.5600, Val Loss: 32.7968, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 3, Train Loss: 21.9394, Val Loss: 21.6397, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 39.0861, Val Loss: 15.3017, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 5, Train Loss: 31.8252, Val Loss: 10.9341, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 16.4623, Val Loss: 10.8744, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 7, Train Loss: 8.5930, Val Loss: 10.9658, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 8, Train Loss: 9.9525, Val Loss: 33.3574, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 9, Train Loss: 13.9679, Val Loss: 15.9319, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 10, Train Loss: 8.6951, Val Loss: 7.6588, F1 Micro: 0.2500, F1 Macro: 0.2497, Accuracy: 0.2500\n","Epoch 11, Train Loss: 12.5175, Val Loss: 5.2885, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 12, Train Loss: 10.3319, Val Loss: 38.2817, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 34.1561, Val Loss: 44.7976, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 132.6608, Val Loss: 6.9867, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 26.6306, Val Loss: 13.1322, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 3, Train Loss: 7.8390, Val Loss: 0.9371, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 4, Train Loss: 15.4959, Val Loss: 3.4361, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 13.4953, Val Loss: 1.6163, F1 Micro: 0.6562, F1 Macro: 0.5211, Accuracy: 0.6562\n","Epoch 6, Train Loss: 8.8180, Val Loss: 6.4512, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 7, Train Loss: 18.2679, Val Loss: 15.0261, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 14.2186, Val Loss: 2.1730, F1 Micro: 0.6667, F1 Macro: 0.5124, Accuracy: 0.6667\n","Epoch 9, Train Loss: 14.8413, Val Loss: 4.0461, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 10, Train Loss: 13.5506, Val Loss: 3.7323, F1 Micro: 0.8333, F1 Macro: 0.5096, Accuracy: 0.8333\n","Epoch 11, Train Loss: 13.0366, Val Loss: 41.1218, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 12, Train Loss: 36.3540, Val Loss: 13.8841, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 13, Train Loss: 29.7062, Val Loss: 7.5899, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 14, Train Loss: 16.4360, Val Loss: 27.6893, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 39.0883, Val Loss: 61.0260, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 2, Train Loss: 29.5388, Val Loss: 39.9317, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 3, Train Loss: 33.8278, Val Loss: 39.1370, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 4, Train Loss: 25.4520, Val Loss: 24.0046, F1 Micro: 0.1562, F1 Macro: 0.1540, Accuracy: 0.1562\n","Epoch 5, Train Loss: 14.5570, Val Loss: 14.4194, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 21.3276, Val Loss: 34.1881, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 7, Train Loss: 18.0294, Val Loss: 22.6602, F1 Micro: 0.1875, F1 Macro: 0.1871, Accuracy: 0.1875\n","Epoch 8, Train Loss: 56.8331, Val Loss: 80.3206, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 9, Train Loss: 27.1816, Val Loss: 23.4542, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 10, Train Loss: 18.2988, Val Loss: 12.9245, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 11, Train Loss: 11.4839, Val Loss: 6.2046, F1 Micro: 0.6979, F1 Macro: 0.5146, Accuracy: 0.6979\n","Epoch 12, Train Loss: 19.0553, Val Loss: 9.0891, F1 Micro: 0.4062, F1 Macro: 0.3631, Accuracy: 0.4062\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 29.3646, Val Loss: 8.5877, F1 Micro: 0.7396, F1 Macro: 0.5815, Accuracy: 0.7396\n","Epoch 2, Train Loss: 17.9410, Val Loss: 8.4252, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 3, Train Loss: 35.3273, Val Loss: 49.4285, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 24.2382, Val Loss: 45.5388, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 20.4822, Val Loss: 20.3179, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 6, Train Loss: 28.5521, Val Loss: 24.0752, F1 Micro: 0.2292, F1 Macro: 0.2261, Accuracy: 0.2292\n","Epoch 7, Train Loss: 25.7455, Val Loss: 19.2227, F1 Micro: 0.7396, F1 Macro: 0.4923, Accuracy: 0.7396\n","Epoch 8, Train Loss: 16.7684, Val Loss: 21.9420, F1 Micro: 0.2500, F1 Macro: 0.2497, Accuracy: 0.2500\n","Epoch 9, Train Loss: 20.3901, Val Loss: 12.9733, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 10, Train Loss: 19.2560, Val Loss: 73.4888, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 11, Train Loss: 58.7101, Val Loss: 39.8477, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 12, Train Loss: 16.3097, Val Loss: 15.1901, F1 Micro: 0.7292, F1 Macro: 0.5556, Accuracy: 0.7292\n","Epoch 13, Train Loss: 16.7378, Val Loss: 11.5918, F1 Micro: 0.5104, F1 Macro: 0.4448, Accuracy: 0.5104\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.8583333333333332\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 102.2454, Val Loss: 34.8690, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 17.8904, Val Loss: 5.1449, F1 Micro: 0.3438, F1 Macro: 0.3431, Accuracy: 0.3438\n","Epoch 3, Train Loss: 6.8441, Val Loss: 38.8876, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 14.5077, Val Loss: 22.3989, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 7.1124, Val Loss: 1.9935, F1 Micro: 0.7604, F1 Macro: 0.6760, Accuracy: 0.7604\n","Epoch 6, Train Loss: 19.4692, Val Loss: 45.3389, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 10.1363, Val Loss: 19.5729, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 4.8960, Val Loss: 4.5462, F1 Micro: 0.4062, F1 Macro: 0.4057, Accuracy: 0.4062\n","Epoch 9, Train Loss: 12.5701, Val Loss: 17.4951, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 10, Train Loss: 10.0745, Val Loss: 13.9598, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 11, Train Loss: 24.0952, Val Loss: 32.2261, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 15.7939, Val Loss: 49.2676, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 34.6317, Val Loss: 116.4694, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 14, Train Loss: 55.4642, Val Loss: 24.0640, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 15, Train Loss: 18.9017, Val Loss: 12.9269, F1 Micro: 0.7917, F1 Macro: 0.4419, Accuracy: 0.7917\n","Epoch 16, Train Loss: 10.0508, Val Loss: 4.0976, F1 Micro: 0.6979, F1 Macro: 0.6221, Accuracy: 0.6979\n","Epoch 17, Train Loss: 21.3045, Val Loss: 5.0633, F1 Micro: 0.5729, F1 Macro: 0.5300, Accuracy: 0.5729\n","Epoch 18, Train Loss: 6.8997, Val Loss: 22.8726, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 19, Train Loss: 26.7608, Val Loss: 98.5527, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 20, Train Loss: 62.1333, Val Loss: 25.5241, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 21, Train Loss: 33.6479, Val Loss: 6.6450, F1 Micro: 0.5521, F1 Macro: 0.5248, Accuracy: 0.5521\n","Epoch 22, Train Loss: 7.9230, Val Loss: 22.7446, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 23, Train Loss: 24.2965, Val Loss: 12.2773, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 24, Train Loss: 12.7054, Val Loss: 5.4475, F1 Micro: 0.5417, F1 Macro: 0.5163, Accuracy: 0.5417\n","Epoch 25, Train Loss: 24.3342, Val Loss: 40.4363, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 26, Train Loss: 23.7079, Val Loss: 23.0018, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 27, Train Loss: 26.4384, Val Loss: 53.9177, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 28, Train Loss: 42.6109, Val Loss: 45.3105, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 29, Train Loss: 17.9116, Val Loss: 5.9319, F1 Micro: 0.5833, F1 Macro: 0.5446, Accuracy: 0.5833\n","Epoch 30, Train Loss: 13.6409, Val Loss: 16.1123, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 31, Train Loss: 11.4239, Val Loss: 16.8849, F1 Micro: 0.2604, F1 Macro: 0.2506, Accuracy: 0.2604\n","Epoch 32, Train Loss: 11.4349, Val Loss: 24.2044, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 33, Train Loss: 15.8332, Val Loss: 28.2038, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 34, Train Loss: 19.0548, Val Loss: 6.4967, F1 Micro: 0.5417, F1 Macro: 0.5163, Accuracy: 0.5417\n","Epoch 35, Train Loss: 11.2733, Val Loss: 7.9059, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 36, Train Loss: 11.0230, Val Loss: 13.0786, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 37, Train Loss: 21.3382, Val Loss: 28.6866, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 38, Train Loss: 24.5266, Val Loss: 45.3189, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 39, Train Loss: 41.2181, Val Loss: 4.5088, F1 Micro: 0.6667, F1 Macro: 0.6047, Accuracy: 0.6667\n","Epoch 40, Train Loss: 7.5724, Val Loss: 5.4167, F1 Micro: 0.5521, F1 Macro: 0.5248, Accuracy: 0.5521\n","Epoch 41, Train Loss: 19.7999, Val Loss: 15.7797, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 42, Train Loss: 12.5744, Val Loss: 7.0164, F1 Micro: 0.5417, F1 Macro: 0.5163, Accuracy: 0.5417\n","Epoch 43, Train Loss: 9.2952, Val Loss: 27.7124, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 44, Train Loss: 32.4877, Val Loss: 125.1161, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 45, Train Loss: 51.7250, Val Loss: 8.0617, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 46, Train Loss: 10.2591, Val Loss: 30.0104, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 47, Train Loss: 14.2724, Val Loss: 5.2176, F1 Micro: 0.5521, F1 Macro: 0.5248, Accuracy: 0.5521\n","Epoch 48, Train Loss: 6.7762, Val Loss: 6.4616, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 49, Train Loss: 21.2381, Val Loss: 25.6706, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 50, Train Loss: 26.4100, Val Loss: 25.8396, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 51, Train Loss: 13.7644, Val Loss: 21.6127, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 144.7288, Val Loss: 51.7902, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 24.1351, Val Loss: 3.5798, F1 Micro: 0.6354, F1 Macro: 0.5541, Accuracy: 0.6354\n","Epoch 3, Train Loss: 21.2655, Val Loss: 22.8347, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 4, Train Loss: 34.4747, Val Loss: 14.4455, F1 Micro: 0.3542, F1 Macro: 0.3497, Accuracy: 0.3542\n","Epoch 5, Train Loss: 13.3182, Val Loss: 4.2635, F1 Micro: 0.6146, F1 Macro: 0.5473, Accuracy: 0.6146\n","Epoch 6, Train Loss: 11.9153, Val Loss: 12.5053, F1 Micro: 0.3438, F1 Macro: 0.3402, Accuracy: 0.3438\n","Epoch 7, Train Loss: 10.1567, Val Loss: 22.5713, F1 Micro: 0.1667, F1 Macro: 0.1534, Accuracy: 0.1667\n","Epoch 8, Train Loss: 16.1486, Val Loss: 6.0940, F1 Micro: 0.4167, F1 Macro: 0.4040, Accuracy: 0.4167\n","Epoch 9, Train Loss: 11.8816, Val Loss: 15.6278, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 10, Train Loss: 19.4223, Val Loss: 10.4467, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 11, Train Loss: 16.7391, Val Loss: 4.5657, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Epoch 12, Train Loss: 19.3323, Val Loss: 20.4858, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 13, Train Loss: 16.9828, Val Loss: 5.6199, F1 Micro: 0.4792, F1 Macro: 0.4555, Accuracy: 0.4792\n","Epoch 14, Train Loss: 8.0054, Val Loss: 3.1084, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 15, Train Loss: 7.2849, Val Loss: 6.8103, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 16, Train Loss: 12.4496, Val Loss: 10.9913, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 17, Train Loss: 36.1756, Val Loss: 37.1052, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 18, Train Loss: 14.4434, Val Loss: 23.8034, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 19, Train Loss: 17.1271, Val Loss: 3.5863, F1 Micro: 0.7292, F1 Macro: 0.5354, Accuracy: 0.7292\n","Epoch 20, Train Loss: 7.8867, Val Loss: 5.4037, F1 Micro: 0.4271, F1 Macro: 0.4127, Accuracy: 0.4271\n","Epoch 21, Train Loss: 19.9227, Val Loss: 58.5125, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 22, Train Loss: 49.3089, Val Loss: 32.5376, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 23, Train Loss: 19.5136, Val Loss: 32.2853, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 24, Train Loss: 45.4069, Val Loss: 72.2032, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 25, Train Loss: 47.9360, Val Loss: 53.0571, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 26, Train Loss: 66.0732, Val Loss: 40.3485, F1 Micro: 0.1667, F1 Macro: 0.1575, Accuracy: 0.1667\n","Epoch 27, Train Loss: 37.7759, Val Loss: 72.2545, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 28, Train Loss: 41.0294, Val Loss: 8.8685, F1 Micro: 0.5208, F1 Macro: 0.4763, Accuracy: 0.5208\n","Epoch 29, Train Loss: 22.4887, Val Loss: 20.1849, F1 Micro: 0.3542, F1 Macro: 0.3497, Accuracy: 0.3542\n","Epoch 30, Train Loss: 25.0115, Val Loss: 30.2659, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 31, Train Loss: 23.8086, Val Loss: 6.6862, F1 Micro: 0.5521, F1 Macro: 0.4999, Accuracy: 0.5521\n","Epoch 32, Train Loss: 23.3180, Val Loss: 8.0366, F1 Micro: 0.5208, F1 Macro: 0.4763, Accuracy: 0.5208\n","Epoch 33, Train Loss: 17.1925, Val Loss: 10.7108, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 34, Train Loss: 15.5719, Val Loss: 4.2585, F1 Micro: 0.6146, F1 Macro: 0.5178, Accuracy: 0.6146\n","Epoch 35, Train Loss: 16.4648, Val Loss: 9.5952, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 36, Train Loss: 12.5808, Val Loss: 16.8841, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 37, Train Loss: 18.4225, Val Loss: 4.0870, F1 Micro: 0.7292, F1 Macro: 0.5125, Accuracy: 0.7292\n","Epoch 38, Train Loss: 29.9547, Val Loss: 99.6445, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 39, Train Loss: 78.9732, Val Loss: 65.1698, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 40, Train Loss: 42.3434, Val Loss: 12.4154, F1 Micro: 0.4167, F1 Macro: 0.4040, Accuracy: 0.4167\n","Epoch 41, Train Loss: 23.2360, Val Loss: 25.6609, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 42, Train Loss: 9.2878, Val Loss: 4.5600, F1 Micro: 0.7188, F1 Macro: 0.5283, Accuracy: 0.7188\n","Epoch 43, Train Loss: 9.0352, Val Loss: 8.2505, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 44, Train Loss: 30.0403, Val Loss: 3.5841, F1 Micro: 0.7083, F1 Macro: 0.5214, Accuracy: 0.7083\n","Epoch 45, Train Loss: 49.6324, Val Loss: 17.7984, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 46, Train Loss: 18.4371, Val Loss: 13.5704, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 47, Train Loss: 14.1569, Val Loss: 21.1682, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 48, Train Loss: 8.2289, Val Loss: 7.2497, F1 Micro: 0.4271, F1 Macro: 0.4127, Accuracy: 0.4271\n","Epoch 49, Train Loss: 9.2388, Val Loss: 16.5270, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 50, Train Loss: 48.2773, Val Loss: 11.7625, F1 Micro: 0.3021, F1 Macro: 0.3014, Accuracy: 0.3021\n","Epoch 51, Train Loss: 18.0539, Val Loss: 3.0895, F1 Micro: 0.7188, F1 Macro: 0.5283, Accuracy: 0.7188\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 47.2137, Val Loss: 5.6151, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 2, Train Loss: 48.0322, Val Loss: 58.0145, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 3, Train Loss: 23.3530, Val Loss: 16.6345, F1 Micro: 0.2500, F1 Macro: 0.2497, Accuracy: 0.2500\n","Epoch 4, Train Loss: 30.9817, Val Loss: 26.3539, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 21.9490, Val Loss: 8.7255, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 6, Train Loss: 17.5664, Val Loss: 5.3085, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 7, Train Loss: 10.8095, Val Loss: 12.3326, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 8, Train Loss: 6.6558, Val Loss: 5.3065, F1 Micro: 0.4479, F1 Macro: 0.4143, Accuracy: 0.4479\n","Epoch 9, Train Loss: 6.6930, Val Loss: 1.8281, F1 Micro: 0.6562, F1 Macro: 0.5211, Accuracy: 0.6562\n","Epoch 10, Train Loss: 45.0813, Val Loss: 4.9170, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 11, Train Loss: 18.6470, Val Loss: 6.8347, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 12, Train Loss: 21.5714, Val Loss: 2.9650, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 13, Train Loss: 7.0956, Val Loss: 6.3314, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 14, Train Loss: 35.0350, Val Loss: 58.8603, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 15, Train Loss: 20.0395, Val Loss: 3.2111, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 16, Train Loss: 9.2149, Val Loss: 2.4816, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 17, Train Loss: 11.4802, Val Loss: 14.6771, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Epoch 18, Train Loss: 8.5043, Val Loss: 6.8790, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 19, Train Loss: 5.4538, Val Loss: 6.9388, F1 Micro: 0.2292, F1 Macro: 0.2292, Accuracy: 0.2292\n","Epoch 20, Train Loss: 16.2296, Val Loss: 2.4531, F1 Micro: 0.8438, F1 Macro: 0.5619, Accuracy: 0.8438\n","Epoch 21, Train Loss: 17.3284, Val Loss: 8.4480, F1 Micro: 0.2604, F1 Macro: 0.2597, Accuracy: 0.2604\n","Epoch 22, Train Loss: 27.0940, Val Loss: 11.6769, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 23, Train Loss: 9.3753, Val Loss: 14.8651, F1 Micro: 0.1562, F1 Macro: 0.1517, Accuracy: 0.1562\n","Epoch 24, Train Loss: 9.2111, Val Loss: 1.9129, F1 Micro: 0.7083, F1 Macro: 0.5407, Accuracy: 0.7083\n","Epoch 25, Train Loss: 24.3666, Val Loss: 2.4669, F1 Micro: 0.6458, F1 Macro: 0.5278, Accuracy: 0.6458\n","Epoch 26, Train Loss: 25.4317, Val Loss: 4.4910, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 27, Train Loss: 20.2368, Val Loss: 11.3486, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 28, Train Loss: 21.8360, Val Loss: 4.2067, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 29, Train Loss: 8.7722, Val Loss: 12.4765, F1 Micro: 0.2188, F1 Macro: 0.2187, Accuracy: 0.2188\n","Epoch 30, Train Loss: 10.6578, Val Loss: 8.6571, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 31, Train Loss: 28.1148, Val Loss: 26.6348, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 32, Train Loss: 28.6479, Val Loss: 19.4281, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 33, Train Loss: 32.7682, Val Loss: 16.3367, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 34, Train Loss: 46.2885, Val Loss: 41.6075, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 35, Train Loss: 37.2363, Val Loss: 14.8682, F1 Micro: 0.3229, F1 Macro: 0.3169, Accuracy: 0.3229\n","Epoch 36, Train Loss: 21.7540, Val Loss: 5.7764, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 37, Train Loss: 12.5988, Val Loss: 17.8541, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 38, Train Loss: 15.3301, Val Loss: 11.5266, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 39, Train Loss: 21.5018, Val Loss: 41.2298, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 40, Train Loss: 34.1133, Val Loss: 8.4032, F1 Micro: 0.4583, F1 Macro: 0.4283, Accuracy: 0.4583\n","Epoch 41, Train Loss: 19.8875, Val Loss: 12.6874, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 42, Train Loss: 19.8287, Val Loss: 26.5847, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 43, Train Loss: 28.6063, Val Loss: 32.8632, F1 Micro: 0.1250, F1 Macro: 0.1154, Accuracy: 0.1250\n","Epoch 44, Train Loss: 22.7980, Val Loss: 4.1470, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 45, Train Loss: 23.6509, Val Loss: 13.4953, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 46, Train Loss: 14.5382, Val Loss: 4.7063, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 47, Train Loss: 8.6503, Val Loss: 3.3999, F1 Micro: 0.6458, F1 Macro: 0.5403, Accuracy: 0.6458\n","Epoch 48, Train Loss: 15.6251, Val Loss: 9.9296, F1 Micro: 0.2812, F1 Macro: 0.2793, Accuracy: 0.2812\n","Epoch 49, Train Loss: 16.1674, Val Loss: 28.3120, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 50, Train Loss: 20.2917, Val Loss: 12.3757, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 51, Train Loss: 22.3860, Val Loss: 3.5671, F1 Micro: 0.6458, F1 Macro: 0.5140, Accuracy: 0.6458\n","Epoch 52, Train Loss: 13.5741, Val Loss: 14.8782, F1 Micro: 0.2292, F1 Macro: 0.2292, Accuracy: 0.2292\n","Epoch 53, Train Loss: 31.0307, Val Loss: 14.3067, F1 Micro: 0.2604, F1 Macro: 0.2597, Accuracy: 0.2604\n","Epoch 54, Train Loss: 21.2771, Val Loss: 16.4828, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 88.0442, Val Loss: 44.1823, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 2, Train Loss: 38.5368, Val Loss: 29.8888, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 3, Train Loss: 22.4647, Val Loss: 43.2374, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 4, Train Loss: 28.0330, Val Loss: 18.6435, F1 Micro: 0.2083, F1 Macro: 0.2083, Accuracy: 0.2083\n","Epoch 5, Train Loss: 43.4071, Val Loss: 70.5682, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 6, Train Loss: 22.3950, Val Loss: 17.6137, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 7, Train Loss: 29.2195, Val Loss: 8.7447, F1 Micro: 0.5208, F1 Macro: 0.4318, Accuracy: 0.5208\n","Epoch 8, Train Loss: 28.6817, Val Loss: 28.6227, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 9, Train Loss: 22.5948, Val Loss: 17.8335, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 10, Train Loss: 22.3518, Val Loss: 71.3959, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 11, Train Loss: 36.6297, Val Loss: 8.2060, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 12, Train Loss: 18.0331, Val Loss: 12.8506, F1 Micro: 0.3854, F1 Macro: 0.3480, Accuracy: 0.3854\n","Epoch 13, Train Loss: 21.7974, Val Loss: 7.8347, F1 Micro: 0.6667, F1 Macro: 0.4947, Accuracy: 0.6667\n","Epoch 14, Train Loss: 13.4795, Val Loss: 21.1754, F1 Micro: 0.2500, F1 Macro: 0.2487, Accuracy: 0.2500\n","Epoch 15, Train Loss: 21.5576, Val Loss: 11.9132, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 16, Train Loss: 13.5599, Val Loss: 20.2947, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 17, Train Loss: 15.2748, Val Loss: 15.3235, F1 Micro: 0.2500, F1 Macro: 0.2448, Accuracy: 0.2500\n","Epoch 18, Train Loss: 9.0984, Val Loss: 6.7383, F1 Micro: 0.7500, F1 Macro: 0.4662, Accuracy: 0.7500\n","Epoch 19, Train Loss: 11.0676, Val Loss: 10.5214, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 20, Train Loss: 15.5892, Val Loss: 23.2774, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 21, Train Loss: 34.3713, Val Loss: 14.2772, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 22, Train Loss: 32.0015, Val Loss: 7.1546, F1 Micro: 0.7083, F1 Macro: 0.4469, Accuracy: 0.7083\n","Epoch 23, Train Loss: 40.1306, Val Loss: 29.0224, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 24, Train Loss: 11.8544, Val Loss: 7.0370, F1 Micro: 0.6354, F1 Macro: 0.4756, Accuracy: 0.6354\n","Epoch 25, Train Loss: 19.0905, Val Loss: 46.2326, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 26, Train Loss: 44.7108, Val Loss: 34.6087, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 27, Train Loss: 27.7963, Val Loss: 55.6667, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 28, Train Loss: 47.3279, Val Loss: 74.1126, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 29, Train Loss: 21.4126, Val Loss: 8.4894, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 30, Train Loss: 25.5659, Val Loss: 18.7809, F1 Micro: 0.2708, F1 Macro: 0.2628, Accuracy: 0.2708\n","Epoch 31, Train Loss: 16.3917, Val Loss: 8.8024, F1 Micro: 0.6354, F1 Macro: 0.5070, Accuracy: 0.6354\n","Epoch 32, Train Loss: 14.9625, Val Loss: 30.5205, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 33, Train Loss: 13.6704, Val Loss: 17.9371, F1 Micro: 0.2500, F1 Macro: 0.2448, Accuracy: 0.2500\n","Epoch 34, Train Loss: 14.0792, Val Loss: 13.4406, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 35, Train Loss: 10.8606, Val Loss: 6.8132, F1 Micro: 0.5625, F1 Macro: 0.4589, Accuracy: 0.5625\n","Epoch 36, Train Loss: 7.7888, Val Loss: 10.5196, F1 Micro: 0.2708, F1 Macro: 0.2628, Accuracy: 0.2708\n","Epoch 37, Train Loss: 13.7036, Val Loss: 27.1868, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 38, Train Loss: 12.5186, Val Loss: 11.1803, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 39, Train Loss: 8.7733, Val Loss: 3.9179, F1 Micro: 0.7083, F1 Macro: 0.5214, Accuracy: 0.7083\n","Epoch 40, Train Loss: 9.4312, Val Loss: 4.2705, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 41, Train Loss: 17.0102, Val Loss: 28.1259, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 42, Train Loss: 31.3608, Val Loss: 7.8797, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 43, Train Loss: 15.2614, Val Loss: 13.5535, F1 Micro: 0.8958, F1 Macro: 0.4725, Accuracy: 0.8958\n","Epoch 44, Train Loss: 10.3782, Val Loss: 4.6711, F1 Micro: 0.7083, F1 Macro: 0.4750, Accuracy: 0.7083\n","Epoch 45, Train Loss: 11.6411, Val Loss: 4.0816, F1 Micro: 0.6458, F1 Macro: 0.4819, Accuracy: 0.6458\n","Epoch 46, Train Loss: 14.4205, Val Loss: 4.2914, F1 Micro: 0.7396, F1 Macro: 0.4613, Accuracy: 0.7396\n","Epoch 47, Train Loss: 17.3631, Val Loss: 48.2859, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 48, Train Loss: 23.9190, Val Loss: 8.6096, F1 Micro: 0.3854, F1 Macro: 0.3480, Accuracy: 0.3854\n","Epoch 49, Train Loss: 15.7364, Val Loss: 81.1984, F1 Micro: 0.1042, F1 Macro: 0.0943, Accuracy: 0.1042\n","Epoch 50, Train Loss: 40.7794, Val Loss: 6.5516, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 51, Train Loss: 14.1484, Val Loss: 12.6999, F1 Micro: 0.3958, F1 Macro: 0.3623, Accuracy: 0.3958\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 26.4338, Val Loss: 10.1559, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 15.0562, Val Loss: 3.1666, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 3, Train Loss: 6.8930, Val Loss: 14.6170, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 17.6483, Val Loss: 72.5562, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 5, Train Loss: 50.4097, Val Loss: 55.6971, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 6, Train Loss: 49.2854, Val Loss: 20.9380, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 7, Train Loss: 19.4005, Val Loss: 36.2837, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 8, Train Loss: 9.9439, Val Loss: 11.4611, F1 Micro: 0.7708, F1 Macro: 0.5107, Accuracy: 0.7708\n","Epoch 9, Train Loss: 10.4969, Val Loss: 7.4927, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 10, Train Loss: 10.6547, Val Loss: 20.3644, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 11, Train Loss: 6.1125, Val Loss: 7.9194, F1 Micro: 0.7083, F1 Macro: 0.4996, Accuracy: 0.7083\n","Epoch 12, Train Loss: 12.5018, Val Loss: 12.3201, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 13, Train Loss: 16.4722, Val Loss: 16.5674, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 14, Train Loss: 7.6677, Val Loss: 12.6111, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 15, Train Loss: 17.1822, Val Loss: 22.5441, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 16, Train Loss: 20.4973, Val Loss: 34.6472, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 17, Train Loss: 22.8858, Val Loss: 7.9865, F1 Micro: 0.4583, F1 Macro: 0.4155, Accuracy: 0.4583\n","Epoch 18, Train Loss: 12.1645, Val Loss: 22.8200, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 19, Train Loss: 19.0671, Val Loss: 47.4797, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 11.1299, Val Loss: 7.2551, F1 Micro: 0.5000, F1 Macro: 0.4375, Accuracy: 0.5000\n","Epoch 21, Train Loss: 6.3549, Val Loss: 9.5732, F1 Micro: 0.7396, F1 Macro: 0.4923, Accuracy: 0.7396\n","Epoch 22, Train Loss: 6.5752, Val Loss: 25.2094, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 23, Train Loss: 12.1219, Val Loss: 9.0277, F1 Micro: 0.7396, F1 Macro: 0.4923, Accuracy: 0.7396\n","Epoch 24, Train Loss: 6.2322, Val Loss: 20.4714, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 25, Train Loss: 22.1291, Val Loss: 46.5117, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 26, Train Loss: 23.1652, Val Loss: 16.6447, F1 Micro: 0.2188, F1 Macro: 0.2118, Accuracy: 0.2188\n","Epoch 27, Train Loss: 19.0205, Val Loss: 9.3947, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 28, Train Loss: 14.9972, Val Loss: 46.7906, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 29, Train Loss: 18.2073, Val Loss: 62.5760, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 30, Train Loss: 23.0195, Val Loss: 19.8594, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 31, Train Loss: 15.2094, Val Loss: 66.6358, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 32, Train Loss: 23.7002, Val Loss: 9.1279, F1 Micro: 0.3854, F1 Macro: 0.3655, Accuracy: 0.3854\n","Epoch 33, Train Loss: 12.0374, Val Loss: 7.9673, F1 Micro: 0.4479, F1 Macro: 0.4078, Accuracy: 0.4479\n","Epoch 34, Train Loss: 9.0061, Val Loss: 7.6311, F1 Micro: 0.3958, F1 Macro: 0.3738, Accuracy: 0.3958\n","Epoch 35, Train Loss: 12.0348, Val Loss: 14.9546, F1 Micro: 0.2188, F1 Macro: 0.2118, Accuracy: 0.2188\n","Epoch 36, Train Loss: 14.4349, Val Loss: 28.3816, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 37, Train Loss: 24.8831, Val Loss: 7.1126, F1 Micro: 0.6250, F1 Macro: 0.5000, Accuracy: 0.6250\n","Epoch 38, Train Loss: 26.7832, Val Loss: 9.7727, F1 Micro: 0.7083, F1 Macro: 0.4996, Accuracy: 0.7083\n","Epoch 39, Train Loss: 18.5936, Val Loss: 9.0098, F1 Micro: 0.6771, F1 Macro: 0.5355, Accuracy: 0.6771\n","Epoch 40, Train Loss: 12.0740, Val Loss: 8.2066, F1 Micro: 0.6667, F1 Macro: 0.5283, Accuracy: 0.6667\n","Epoch 41, Train Loss: 7.0066, Val Loss: 9.6523, F1 Micro: 0.7396, F1 Macro: 0.5191, Accuracy: 0.7396\n","Epoch 42, Train Loss: 11.7664, Val Loss: 14.2284, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 43, Train Loss: 7.0630, Val Loss: 13.1429, F1 Micro: 0.2292, F1 Macro: 0.2238, Accuracy: 0.2292\n","Epoch 44, Train Loss: 10.9842, Val Loss: 8.6161, F1 Micro: 0.7604, F1 Macro: 0.5044, Accuracy: 0.7604\n","Epoch 45, Train Loss: 10.2240, Val Loss: 6.0448, F1 Micro: 0.7188, F1 Macro: 0.5656, Accuracy: 0.7188\n","Epoch 46, Train Loss: 12.6771, Val Loss: 84.0491, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 47, Train Loss: 40.2251, Val Loss: 6.9759, F1 Micro: 0.6771, F1 Macro: 0.5355, Accuracy: 0.6771\n","Epoch 48, Train Loss: 7.4181, Val Loss: 15.3258, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 49, Train Loss: 15.6162, Val Loss: 16.2645, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 50, Train Loss: 17.3510, Val Loss: 25.7971, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 51, Train Loss: 11.7348, Val Loss: 47.1991, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.8583333333333332\n","Best hyperparameters for Outer FOLD 3: (0.01, 8, 50) with score 0.9479166666666667\n","Epoch 1, Train Loss: 174.7662, Val Loss: 52.3070, F1 Micro: 0.4100, F1 Macro: 0.3690, Accuracy: 0.4100\n","Epoch 2, Train Loss: 108.7161, Val Loss: 18.5608, F1 Micro: 0.5400, F1 Macro: 0.5188, Accuracy: 0.5400\n","Epoch 3, Train Loss: 31.7545, Val Loss: 66.1918, F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Epoch 4, Train Loss: 12.8492, Val Loss: 8.0940, F1 Micro: 0.5725, F1 Macro: 0.5099, Accuracy: 0.5725\n","Epoch 5, Train Loss: 8.9670, Val Loss: 9.4545, F1 Micro: 0.5675, F1 Macro: 0.5119, Accuracy: 0.5675\n","Epoch 6, Train Loss: 7.8497, Val Loss: 3.2426, F1 Micro: 0.7100, F1 Macro: 0.6915, Accuracy: 0.7100\n","Epoch 7, Train Loss: 4.2720, Val Loss: 5.1587, F1 Micro: 0.6050, F1 Macro: 0.5997, Accuracy: 0.6050\n","Epoch 8, Train Loss: 8.6935, Val Loss: 2.4714, F1 Micro: 0.7525, F1 Macro: 0.7396, Accuracy: 0.7525\n","Epoch 9, Train Loss: 4.5673, Val Loss: 2.3276, F1 Micro: 0.6250, F1 Macro: 0.6250, Accuracy: 0.6250\n","Epoch 10, Train Loss: 4.8152, Val Loss: 2.1353, F1 Micro: 0.6775, F1 Macro: 0.6770, Accuracy: 0.6775\n","Epoch 11, Train Loss: 3.3272, Val Loss: 1.2714, F1 Micro: 0.7225, F1 Macro: 0.7186, Accuracy: 0.7225\n","Epoch 12, Train Loss: 2.6300, Val Loss: 4.6416, F1 Micro: 0.6100, F1 Macro: 0.6072, Accuracy: 0.6100\n","Epoch 13, Train Loss: 3.0297, Val Loss: 3.6783, F1 Micro: 0.6300, F1 Macro: 0.6292, Accuracy: 0.6300\n","Epoch 14, Train Loss: 3.5416, Val Loss: 3.3418, F1 Micro: 0.6550, F1 Macro: 0.6447, Accuracy: 0.6550\n","Epoch 15, Train Loss: 3.4353, Val Loss: 1.2227, F1 Micro: 0.6375, F1 Macro: 0.6250, Accuracy: 0.6375\n","Epoch 16, Train Loss: 7.2153, Val Loss: 1.4079, F1 Micro: 0.7425, F1 Macro: 0.7336, Accuracy: 0.7425\n","Epoch 17, Train Loss: 3.7524, Val Loss: 1.4076, F1 Micro: 0.6275, F1 Macro: 0.6275, Accuracy: 0.6275\n","Epoch 18, Train Loss: 2.1844, Val Loss: 17.7547, F1 Micro: 0.5600, F1 Macro: 0.5294, Accuracy: 0.5600\n","Epoch 19, Train Loss: 3.5408, Val Loss: 2.8907, F1 Micro: 0.6275, F1 Macro: 0.6268, Accuracy: 0.6275\n","Epoch 20, Train Loss: 14.9377, Val Loss: 1.8042, F1 Micro: 0.6700, F1 Macro: 0.6673, Accuracy: 0.6700\n","Epoch 21, Train Loss: 4.9491, Val Loss: 1.1216, F1 Micro: 0.7575, F1 Macro: 0.7525, Accuracy: 0.7575\n","Epoch 22, Train Loss: 1.8975, Val Loss: 3.2337, F1 Micro: 0.6400, F1 Macro: 0.6265, Accuracy: 0.6400\n","Epoch 23, Train Loss: 2.7367, Val Loss: 1.3202, F1 Micro: 0.6850, F1 Macro: 0.6842, Accuracy: 0.6850\n","Epoch 24, Train Loss: 1.7800, Val Loss: 1.7558, F1 Micro: 0.5525, F1 Macro: 0.5303, Accuracy: 0.5525\n","Epoch 25, Train Loss: 2.7546, Val Loss: 5.7445, F1 Micro: 0.5175, F1 Macro: 0.4740, Accuracy: 0.5175\n","Epoch 26, Train Loss: 12.7970, Val Loss: 10.8682, F1 Micro: 0.6375, F1 Macro: 0.5442, Accuracy: 0.6375\n","Epoch 27, Train Loss: 3.3604, Val Loss: 1.9660, F1 Micro: 0.6925, F1 Macro: 0.6866, Accuracy: 0.6925\n","Epoch 28, Train Loss: 1.2308, Val Loss: 5.4537, F1 Micro: 0.6225, F1 Macro: 0.6212, Accuracy: 0.6225\n","Epoch 29, Train Loss: 3.4268, Val Loss: 4.3886, F1 Micro: 0.7000, F1 Macro: 0.6735, Accuracy: 0.7000\n","Epoch 30, Train Loss: 9.9336, Val Loss: 1.1313, F1 Micro: 0.7125, F1 Macro: 0.7065, Accuracy: 0.7125\n","Epoch 31, Train Loss: 1.3155, Val Loss: 0.7932, F1 Micro: 0.7150, F1 Macro: 0.7134, Accuracy: 0.7150\n","Epoch 32, Train Loss: 1.7557, Val Loss: 3.6012, F1 Micro: 0.6825, F1 Macro: 0.6360, Accuracy: 0.6825\n","Epoch 33, Train Loss: 12.8829, Val Loss: 9.6978, F1 Micro: 0.5650, F1 Macro: 0.4161, Accuracy: 0.5650\n","Epoch 34, Train Loss: 6.1874, Val Loss: 2.9536, F1 Micro: 0.6975, F1 Macro: 0.6702, Accuracy: 0.6975\n","Epoch 35, Train Loss: 1.2370, Val Loss: 0.9963, F1 Micro: 0.6900, F1 Macro: 0.6885, Accuracy: 0.6900\n","Epoch 36, Train Loss: 1.8200, Val Loss: 2.8094, F1 Micro: 0.6725, F1 Macro: 0.6345, Accuracy: 0.6725\n","Epoch 37, Train Loss: 16.5684, Val Loss: 6.8673, F1 Micro: 0.6100, F1 Macro: 0.5805, Accuracy: 0.6100\n","Epoch 38, Train Loss: 17.6499, Val Loss: 4.1991, F1 Micro: 0.6700, F1 Macro: 0.6397, Accuracy: 0.6700\n","Epoch 39, Train Loss: 1.9389, Val Loss: 1.3026, F1 Micro: 0.6950, F1 Macro: 0.6925, Accuracy: 0.6950\n","Epoch 40, Train Loss: 1.1379, Val Loss: 0.9548, F1 Micro: 0.6275, F1 Macro: 0.6154, Accuracy: 0.6275\n","Epoch 41, Train Loss: 1.3177, Val Loss: 0.9381, F1 Micro: 0.7250, F1 Macro: 0.7206, Accuracy: 0.7250\n","Epoch 42, Train Loss: 1.9484, Val Loss: 3.2696, F1 Micro: 0.6750, F1 Macro: 0.6311, Accuracy: 0.6750\n","Epoch 43, Train Loss: 2.3004, Val Loss: 0.9463, F1 Micro: 0.5650, F1 Macro: 0.5487, Accuracy: 0.5650\n","Epoch 44, Train Loss: 2.1393, Val Loss: 0.8150, F1 Micro: 0.7225, F1 Macro: 0.7163, Accuracy: 0.7225\n","Epoch 45, Train Loss: 3.4268, Val Loss: 0.7360, F1 Micro: 0.7050, F1 Macro: 0.7029, Accuracy: 0.7050\n","Epoch 46, Train Loss: 2.0549, Val Loss: 0.7824, F1 Micro: 0.6275, F1 Macro: 0.6147, Accuracy: 0.6275\n","Epoch 47, Train Loss: 0.9603, Val Loss: 0.8791, F1 Micro: 0.5925, F1 Macro: 0.5894, Accuracy: 0.5925\n","Epoch 48, Train Loss: 2.2391, Val Loss: 0.7854, F1 Micro: 0.6950, F1 Macro: 0.6922, Accuracy: 0.6950\n","Epoch 49, Train Loss: 2.5172, Val Loss: 1.2508, F1 Micro: 0.7300, F1 Macro: 0.7112, Accuracy: 0.7300\n","Epoch 50, Train Loss: 6.4507, Val Loss: 76.2374, F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Epoch 51, Train Loss: 47.8644, Val Loss: 58.2651, F1 Micro: 0.5525, F1 Macro: 0.3559, Accuracy: 0.5525\n","Epoch 52, Train Loss: 8.0485, Val Loss: 1.0506, F1 Micro: 0.6775, F1 Macro: 0.6750, Accuracy: 0.6775\n","Epoch 53, Train Loss: 1.2187, Val Loss: 0.8708, F1 Micro: 0.6675, F1 Macro: 0.6675, Accuracy: 0.6675\n","Epoch 54, Train Loss: 0.9340, Val Loss: 0.7173, F1 Micro: 0.6925, F1 Macro: 0.6917, Accuracy: 0.6925\n","Epoch 55, Train Loss: 0.9860, Val Loss: 0.7041, F1 Micro: 0.6950, F1 Macro: 0.6928, Accuracy: 0.6950\n","Epoch 56, Train Loss: 0.7441, Val Loss: 1.0012, F1 Micro: 0.6450, F1 Macro: 0.6449, Accuracy: 0.6450\n","Epoch 57, Train Loss: 0.8182, Val Loss: 0.6520, F1 Micro: 0.7025, F1 Macro: 0.6990, Accuracy: 0.7025\n","Epoch 58, Train Loss: 0.8969, Val Loss: 0.6866, F1 Micro: 0.7550, F1 Macro: 0.7477, Accuracy: 0.7550\n","Epoch 59, Train Loss: 0.8380, Val Loss: 3.9388, F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Epoch 60, Train Loss: 2.0580, Val Loss: 0.8550, F1 Micro: 0.5250, F1 Macro: 0.4587, Accuracy: 0.5250\n","Epoch 61, Train Loss: 0.6611, Val Loss: 0.6077, F1 Micro: 0.7050, F1 Macro: 0.7037, Accuracy: 0.7050\n","Epoch 62, Train Loss: 32.6635, Val Loss: 5.2708, F1 Micro: 0.5575, F1 Macro: 0.5025, Accuracy: 0.5575\n","Epoch 63, Train Loss: 7.1306, Val Loss: 0.9823, F1 Micro: 0.5300, F1 Macro: 0.4987, Accuracy: 0.5300\n","Epoch 64, Train Loss: 0.9595, Val Loss: 0.9783, F1 Micro: 0.5550, F1 Macro: 0.5266, Accuracy: 0.5550\n","Epoch 65, Train Loss: 0.9004, Val Loss: 1.1755, F1 Micro: 0.6800, F1 Macro: 0.6786, Accuracy: 0.6800\n","Epoch 66, Train Loss: 0.8392, Val Loss: 0.6409, F1 Micro: 0.7025, F1 Macro: 0.7007, Accuracy: 0.7025\n","Epoch 67, Train Loss: 0.7020, Val Loss: 0.7380, F1 Micro: 0.7500, F1 Macro: 0.7379, Accuracy: 0.7500\n","Epoch 68, Train Loss: 1.2986, Val Loss: 12.2719, F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Epoch 69, Train Loss: 6.1646, Val Loss: 1.0339, F1 Micro: 0.7550, F1 Macro: 0.7431, Accuracy: 0.7550\n","Epoch 70, Train Loss: 0.9467, Val Loss: 0.6888, F1 Micro: 0.6675, F1 Macro: 0.6646, Accuracy: 0.6675\n","Epoch 71, Train Loss: 5.5406, Val Loss: 19.5109, F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.4475, F1 Macro: 0.3092, Accuracy: 0.4475\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 682.2772, Val Loss: 321.8635, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 200.3496, Val Loss: 272.9308, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 318.1926, Val Loss: 212.0998, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 88.4223, Val Loss: 149.6828, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 5, Train Loss: 130.2900, Val Loss: 257.2215, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 6, Train Loss: 129.9897, Val Loss: 322.0847, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 80.4267, Val Loss: 33.8332, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 22.0279, Val Loss: 19.4433, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 9, Train Loss: 39.5092, Val Loss: 85.6322, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 42.6452, Val Loss: 22.8652, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 11, Train Loss: 18.2907, Val Loss: 107.6901, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 422.4419, Val Loss: 42.1206, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 2, Train Loss: 106.5316, Val Loss: 66.8770, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 112.6041, Val Loss: 257.5522, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 337.4799, Val Loss: 61.2081, F1 Micro: 0.2500, F1 Macro: 0.2497, Accuracy: 0.2500\n","Epoch 5, Train Loss: 72.3127, Val Loss: 178.6460, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 6, Train Loss: 38.2707, Val Loss: 51.5453, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 7, Train Loss: 17.0799, Val Loss: 8.9494, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 8, Train Loss: 55.9139, Val Loss: 109.1153, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 9, Train Loss: 50.2608, Val Loss: 18.9126, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 10, Train Loss: 20.8131, Val Loss: 45.8848, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 11, Train Loss: 34.2177, Val Loss: 17.6865, F1 Micro: 0.4375, F1 Macro: 0.4214, Accuracy: 0.4375\n","Epoch 12, Train Loss: 21.0551, Val Loss: 38.3724, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 565.7004, Val Loss: 48.3300, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 207.7219, Val Loss: 154.3473, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 3, Train Loss: 183.6401, Val Loss: 112.9621, F1 Micro: 0.1771, F1 Macro: 0.1727, Accuracy: 0.1771\n","Epoch 4, Train Loss: 139.8401, Val Loss: 181.2056, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 5, Train Loss: 138.3190, Val Loss: 11.5654, F1 Micro: 0.7292, F1 Macro: 0.6038, Accuracy: 0.7292\n","Epoch 6, Train Loss: 62.5057, Val Loss: 108.4256, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 7, Train Loss: 47.3098, Val Loss: 37.4866, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 8, Train Loss: 57.0513, Val Loss: 31.6561, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 9, Train Loss: 71.1848, Val Loss: 6.8800, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 10, Train Loss: 103.5374, Val Loss: 101.7495, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 11, Train Loss: 51.1556, Val Loss: 112.4626, F1 Micro: 0.1875, F1 Macro: 0.1843, Accuracy: 0.1875\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 459.4033, Val Loss: 78.7002, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 2, Train Loss: 193.2291, Val Loss: 384.6813, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 156.9681, Val Loss: 28.8292, F1 Micro: 0.6979, F1 Macro: 0.4934, Accuracy: 0.6979\n","Epoch 4, Train Loss: 121.7938, Val Loss: 21.9628, F1 Micro: 0.5208, F1 Macro: 0.4424, Accuracy: 0.5208\n","Epoch 5, Train Loss: 180.8012, Val Loss: 63.9204, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 104.4952, Val Loss: 48.5667, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 7, Train Loss: 77.8677, Val Loss: 54.2979, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 60.1059, Val Loss: 120.0089, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 58.8447, Val Loss: 31.9348, F1 Micro: 0.3438, F1 Macro: 0.3170, Accuracy: 0.3438\n","Epoch 10, Train Loss: 95.9181, Val Loss: 93.0056, F1 Micro: 0.1562, F1 Macro: 0.1517, Accuracy: 0.1562\n","Epoch 11, Train Loss: 53.4148, Val Loss: 270.9210, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 345.5954, Val Loss: 496.2296, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 273.9951, Val Loss: 79.5475, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 171.3492, Val Loss: 339.6787, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 178.5356, Val Loss: 18.4941, F1 Micro: 0.7292, F1 Macro: 0.5556, Accuracy: 0.7292\n","Epoch 5, Train Loss: 78.5581, Val Loss: 64.8884, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 91.0181, Val Loss: 15.1509, F1 Micro: 0.5625, F1 Macro: 0.4812, Accuracy: 0.5625\n","Epoch 7, Train Loss: 56.1513, Val Loss: 164.7335, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 8, Train Loss: 72.4107, Val Loss: 20.8953, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 9, Train Loss: 43.6941, Val Loss: 54.8257, F1 Micro: 0.1875, F1 Macro: 0.1746, Accuracy: 0.1875\n","Epoch 10, Train Loss: 43.3009, Val Loss: 24.2389, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 11, Train Loss: 48.1006, Val Loss: 21.4385, F1 Micro: 0.4062, F1 Macro: 0.3914, Accuracy: 0.4062\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.8541666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 545.5065, Val Loss: 122.4312, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 192.0482, Val Loss: 89.6840, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 128.7465, Val Loss: 18.8818, F1 Micro: 0.6458, F1 Macro: 0.5714, Accuracy: 0.6458\n","Epoch 4, Train Loss: 58.7542, Val Loss: 83.1068, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 5, Train Loss: 72.7917, Val Loss: 120.0961, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 108.6359, Val Loss: 83.0267, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 7, Train Loss: 90.0915, Val Loss: 86.5197, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 8, Train Loss: 48.0687, Val Loss: 142.9417, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 9, Train Loss: 49.4411, Val Loss: 12.3838, F1 Micro: 0.7812, F1 Macro: 0.6331, Accuracy: 0.7812\n","Epoch 10, Train Loss: 28.8897, Val Loss: 24.4489, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 43.3719, Val Loss: 73.6781, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 56.1483, Val Loss: 145.9758, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 13, Train Loss: 42.8137, Val Loss: 13.3441, F1 Micro: 0.7292, F1 Macro: 0.6284, Accuracy: 0.7292\n","Epoch 14, Train Loss: 21.4442, Val Loss: 14.2522, F1 Micro: 0.3542, F1 Macro: 0.3542, Accuracy: 0.3542\n","Epoch 15, Train Loss: 15.5059, Val Loss: 19.2870, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 16, Train Loss: 22.7751, Val Loss: 44.3637, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 17, Train Loss: 21.3279, Val Loss: 24.3370, F1 Micro: 0.3229, F1 Macro: 0.3223, Accuracy: 0.3229\n","Epoch 18, Train Loss: 20.1757, Val Loss: 9.7096, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 19, Train Loss: 5.6339, Val Loss: 15.5902, F1 Micro: 0.2812, F1 Macro: 0.2774, Accuracy: 0.2812\n","Epoch 20, Train Loss: 11.1628, Val Loss: 5.2339, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 21, Train Loss: 18.3220, Val Loss: 10.8227, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 22, Train Loss: 9.9181, Val Loss: 4.2083, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 23, Train Loss: 5.7140, Val Loss: 2.0432, F1 Micro: 0.7708, F1 Macro: 0.7099, Accuracy: 0.7708\n","Epoch 24, Train Loss: 7.6214, Val Loss: 6.7471, F1 Micro: 0.8438, F1 Macro: 0.7115, Accuracy: 0.8438\n","Epoch 25, Train Loss: 6.5034, Val Loss: 8.2996, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 26, Train Loss: 5.2746, Val Loss: 0.4131, F1 Micro: 0.8438, F1 Macro: 0.7115, Accuracy: 0.8438\n","Epoch 27, Train Loss: 3.3521, Val Loss: 15.2417, F1 Micro: 0.3125, F1 Macro: 0.3113, Accuracy: 0.3125\n","Epoch 28, Train Loss: 10.1461, Val Loss: 8.0666, F1 Micro: 0.4271, F1 Macro: 0.4255, Accuracy: 0.4271\n","Epoch 29, Train Loss: 4.4022, Val Loss: 3.6080, F1 Micro: 0.5833, F1 Macro: 0.5602, Accuracy: 0.5833\n","Epoch 30, Train Loss: 7.2224, Val Loss: 1.6553, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 31, Train Loss: 8.2435, Val Loss: 2.1666, F1 Micro: 0.8229, F1 Macro: 0.7265, Accuracy: 0.8229\n","Epoch 32, Train Loss: 3.3352, Val Loss: 14.8157, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 33, Train Loss: 4.1971, Val Loss: 3.8657, F1 Micro: 0.8646, F1 Macro: 0.7621, Accuracy: 0.8646\n","Epoch 34, Train Loss: 3.4930, Val Loss: 3.5090, F1 Micro: 0.8542, F1 Macro: 0.7498, Accuracy: 0.8542\n","Epoch 35, Train Loss: 3.3172, Val Loss: 0.3915, F1 Micro: 0.8854, F1 Macro: 0.8294, Accuracy: 0.8854\n","Epoch 36, Train Loss: 6.2519, Val Loss: 7.9573, F1 Micro: 0.4271, F1 Macro: 0.4240, Accuracy: 0.4271\n","Epoch 37, Train Loss: 4.8584, Val Loss: 1.7845, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 38, Train Loss: 3.3456, Val Loss: 6.8451, F1 Micro: 0.8646, F1 Macro: 0.7011, Accuracy: 0.8646\n","Epoch 39, Train Loss: 3.4939, Val Loss: 3.5715, F1 Micro: 0.6875, F1 Macro: 0.6484, Accuracy: 0.6875\n","Epoch 40, Train Loss: 5.1516, Val Loss: 5.0547, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 41, Train Loss: 4.0936, Val Loss: 0.9664, F1 Micro: 0.8333, F1 Macro: 0.7141, Accuracy: 0.8333\n","Epoch 42, Train Loss: 1.4381, Val Loss: 5.5530, F1 Micro: 0.8542, F1 Macro: 0.7498, Accuracy: 0.8542\n","Epoch 43, Train Loss: 4.5089, Val Loss: 5.5486, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 44, Train Loss: 2.4694, Val Loss: 2.1432, F1 Micro: 0.8125, F1 Macro: 0.7427, Accuracy: 0.8125\n","Epoch 45, Train Loss: 2.4030, Val Loss: 0.3512, F1 Micro: 0.9062, F1 Macro: 0.8493, Accuracy: 0.9062\n","Epoch 46, Train Loss: 1.5252, Val Loss: 2.9780, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 47, Train Loss: 6.1873, Val Loss: 9.8177, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 48, Train Loss: 2.7901, Val Loss: 3.1167, F1 Micro: 0.8229, F1 Macro: 0.7265, Accuracy: 0.8229\n","Epoch 49, Train Loss: 5.7409, Val Loss: 1.4483, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 50, Train Loss: 7.0298, Val Loss: 4.4650, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 51, Train Loss: 4.3495, Val Loss: 0.6199, F1 Micro: 0.9062, F1 Macro: 0.8493, Accuracy: 0.9062\n","Epoch 52, Train Loss: 2.1110, Val Loss: 6.3497, F1 Micro: 0.5104, F1 Macro: 0.5013, Accuracy: 0.5104\n","Epoch 53, Train Loss: 5.5854, Val Loss: 1.2337, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 54, Train Loss: 2.3652, Val Loss: 8.0272, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 55, Train Loss: 2.7033, Val Loss: 2.6971, F1 Micro: 0.8021, F1 Macro: 0.7324, Accuracy: 0.8021\n","Epoch 56, Train Loss: 10.3916, Val Loss: 34.3595, F1 Micro: 0.2500, F1 Macro: 0.2381, Accuracy: 0.2500\n","Epoch 57, Train Loss: 23.2934, Val Loss: 3.8373, F1 Micro: 0.6562, F1 Macro: 0.6267, Accuracy: 0.6562\n","Epoch 58, Train Loss: 6.3610, Val Loss: 11.2326, F1 Micro: 0.4479, F1 Macro: 0.4450, Accuracy: 0.4479\n","Epoch 59, Train Loss: 5.0480, Val Loss: 5.1374, F1 Micro: 0.6458, F1 Macro: 0.5620, Accuracy: 0.6458\n","Epoch 60, Train Loss: 2.9389, Val Loss: 1.5826, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 61, Train Loss: 1.8049, Val Loss: 3.5021, F1 Micro: 0.7604, F1 Macro: 0.6300, Accuracy: 0.7604\n","Epoch 62, Train Loss: 1.1556, Val Loss: 0.3734, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 63, Train Loss: 0.6146, Val Loss: 1.1120, F1 Micro: 0.8854, F1 Macro: 0.8294, Accuracy: 0.8854\n","Epoch 64, Train Loss: 1.7761, Val Loss: 5.1584, F1 Micro: 0.8021, F1 Macro: 0.7054, Accuracy: 0.8021\n","Epoch 65, Train Loss: 3.5036, Val Loss: 1.5807, F1 Micro: 0.8542, F1 Macro: 0.7999, Accuracy: 0.8542\n","Epoch 66, Train Loss: 1.1822, Val Loss: 0.7488, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 67, Train Loss: 0.8688, Val Loss: 1.0596, F1 Micro: 0.8438, F1 Macro: 0.7887, Accuracy: 0.8438\n","Epoch 68, Train Loss: 1.0998, Val Loss: 2.0445, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 69, Train Loss: 1.5636, Val Loss: 0.5963, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 70, Train Loss: 5.3947, Val Loss: 4.1245, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 71, Train Loss: 3.0420, Val Loss: 2.0338, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 72, Train Loss: 5.2217, Val Loss: 7.7749, F1 Micro: 0.7292, F1 Macro: 0.6389, Accuracy: 0.7292\n","Epoch 73, Train Loss: 2.7460, Val Loss: 0.8507, F1 Micro: 0.9062, F1 Macro: 0.8552, Accuracy: 0.9062\n","Epoch 74, Train Loss: 4.7171, Val Loss: 2.1947, F1 Micro: 0.7500, F1 Macro: 0.7036, Accuracy: 0.7500\n","Epoch 75, Train Loss: 2.1307, Val Loss: 0.9518, F1 Micro: 0.8854, F1 Macro: 0.8404, Accuracy: 0.8854\n","Epoch 76, Train Loss: 2.2434, Val Loss: 3.0261, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 77, Train Loss: 2.6863, Val Loss: 3.8157, F1 Micro: 0.7604, F1 Macro: 0.7131, Accuracy: 0.7604\n","Epoch 78, Train Loss: 2.6085, Val Loss: 3.0396, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 79, Train Loss: 1.8674, Val Loss: 0.4990, F1 Micro: 0.9167, F1 Macro: 0.8781, Accuracy: 0.9167\n","Epoch 80, Train Loss: 1.8535, Val Loss: 0.9615, F1 Micro: 0.8542, F1 Macro: 0.7936, Accuracy: 0.8542\n","Epoch 81, Train Loss: 2.8536, Val Loss: 0.7075, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 82, Train Loss: 3.0622, Val Loss: 2.9713, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 83, Train Loss: 8.4540, Val Loss: 0.8396, F1 Micro: 0.8958, F1 Macro: 0.8526, Accuracy: 0.8958\n","Epoch 84, Train Loss: 1.6674, Val Loss: 3.7125, F1 Micro: 0.7292, F1 Macro: 0.6848, Accuracy: 0.7292\n","Epoch 85, Train Loss: 4.1631, Val Loss: 79.2669, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 86, Train Loss: 33.5409, Val Loss: 209.7229, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 87, Train Loss: 33.2907, Val Loss: 12.7531, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 88, Train Loss: 4.6400, Val Loss: 0.7470, F1 Micro: 0.9062, F1 Macro: 0.8493, Accuracy: 0.9062\n","Epoch 89, Train Loss: 2.6098, Val Loss: 4.0722, F1 Micro: 0.7708, F1 Macro: 0.7166, Accuracy: 0.7708\n","Epoch 90, Train Loss: 4.1382, Val Loss: 3.7744, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 91, Train Loss: 2.0012, Val Loss: 5.8686, F1 Micro: 0.7812, F1 Macro: 0.4813, Accuracy: 0.7812\n","Epoch 92, Train Loss: 5.9932, Val Loss: 1.2316, F1 Micro: 0.8646, F1 Macro: 0.8169, Accuracy: 0.8646\n","Epoch 93, Train Loss: 8.9240, Val Loss: 3.3687, F1 Micro: 0.7917, F1 Macro: 0.7424, Accuracy: 0.7917\n","Epoch 94, Train Loss: 5.6772, Val Loss: 7.7267, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 95, Train Loss: 3.5296, Val Loss: 2.3708, F1 Micro: 0.8438, F1 Macro: 0.5990, Accuracy: 0.8438\n","Epoch 96, Train Loss: 7.2233, Val Loss: 3.5845, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 97, Train Loss: 2.2319, Val Loss: 0.8509, F1 Micro: 0.8854, F1 Macro: 0.8404, Accuracy: 0.8854\n","Epoch 98, Train Loss: 3.5477, Val Loss: 4.6583, F1 Micro: 0.7292, F1 Macro: 0.6848, Accuracy: 0.7292\n","Epoch 99, Train Loss: 2.5068, Val Loss: 1.2306, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 100, Train Loss: 5.7105, Val Loss: 0.5124, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 101, Train Loss: 1.6790, Val Loss: 2.0533, F1 Micro: 0.8229, F1 Macro: 0.7730, Accuracy: 0.8229\n","Epoch 102, Train Loss: 1.0147, Val Loss: 1.4999, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 103, Train Loss: 1.3679, Val Loss: 1.0388, F1 Micro: 0.8438, F1 Macro: 0.7887, Accuracy: 0.8438\n","Epoch 104, Train Loss: 4.0999, Val Loss: 4.0242, F1 Micro: 0.7188, F1 Macro: 0.6811, Accuracy: 0.7188\n","Epoch 105, Train Loss: 3.8764, Val Loss: 1.0838, F1 Micro: 0.8854, F1 Macro: 0.8404, Accuracy: 0.8854\n","Epoch 106, Train Loss: 1.7390, Val Loss: 0.7762, F1 Micro: 0.9062, F1 Macro: 0.8493, Accuracy: 0.9062\n","Epoch 107, Train Loss: 3.1696, Val Loss: 4.4922, F1 Micro: 0.7604, F1 Macro: 0.7131, Accuracy: 0.7604\n","Epoch 108, Train Loss: 2.6004, Val Loss: 3.8986, F1 Micro: 0.7917, F1 Macro: 0.6426, Accuracy: 0.7917\n","Epoch 109, Train Loss: 4.6494, Val Loss: 0.8636, F1 Micro: 0.9062, F1 Macro: 0.8651, Accuracy: 0.9062\n","Epoch 110, Train Loss: 4.4088, Val Loss: 12.1587, F1 Micro: 0.5417, F1 Macro: 0.5054, Accuracy: 0.5417\n","Epoch 111, Train Loss: 4.0511, Val Loss: 5.6025, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 112, Train Loss: 5.9143, Val Loss: 4.2377, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 504.7845, Val Loss: 113.1127, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 244.2454, Val Loss: 63.3981, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 70.2522, Val Loss: 405.2194, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 107.6781, Val Loss: 79.7951, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 80.5723, Val Loss: 190.2501, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 6, Train Loss: 54.1643, Val Loss: 165.7666, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 7, Train Loss: 75.5986, Val Loss: 126.8153, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 8, Train Loss: 75.6730, Val Loss: 21.7613, F1 Micro: 0.5521, F1 Macro: 0.4921, Accuracy: 0.5521\n","Epoch 9, Train Loss: 60.3135, Val Loss: 191.4819, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 10, Train Loss: 48.9481, Val Loss: 78.0647, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 11, Train Loss: 20.4502, Val Loss: 6.8559, F1 Micro: 0.6354, F1 Macro: 0.5327, Accuracy: 0.6354\n","Epoch 12, Train Loss: 17.8910, Val Loss: 38.7450, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 45.4402, Val Loss: 42.1814, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 14, Train Loss: 35.4190, Val Loss: 23.5272, F1 Micro: 0.3438, F1 Macro: 0.3402, Accuracy: 0.3438\n","Epoch 15, Train Loss: 20.4909, Val Loss: 72.4783, F1 Micro: 0.2604, F1 Macro: 0.2603, Accuracy: 0.2604\n","Epoch 16, Train Loss: 19.4660, Val Loss: 26.2079, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 17, Train Loss: 19.8514, Val Loss: 25.9503, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 18, Train Loss: 16.2983, Val Loss: 4.4003, F1 Micro: 0.7083, F1 Macro: 0.5579, Accuracy: 0.7083\n","Epoch 19, Train Loss: 7.5434, Val Loss: 3.3292, F1 Micro: 0.5104, F1 Macro: 0.4858, Accuracy: 0.5104\n","Epoch 20, Train Loss: 13.3584, Val Loss: 5.4011, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 21, Train Loss: 10.7114, Val Loss: 12.0127, F1 Micro: 0.7500, F1 Macro: 0.4662, Accuracy: 0.7500\n","Epoch 22, Train Loss: 15.5920, Val Loss: 5.2567, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 23, Train Loss: 2.9405, Val Loss: 2.5840, F1 Micro: 0.8125, F1 Macro: 0.6625, Accuracy: 0.8125\n","Epoch 24, Train Loss: 6.7688, Val Loss: 2.2765, F1 Micro: 0.8333, F1 Macro: 0.5535, Accuracy: 0.8333\n","Epoch 25, Train Loss: 12.4398, Val Loss: 15.5540, F1 Micro: 0.2708, F1 Macro: 0.2708, Accuracy: 0.2708\n","Epoch 26, Train Loss: 8.0139, Val Loss: 2.5221, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 27, Train Loss: 2.3979, Val Loss: 7.1409, F1 Micro: 0.4583, F1 Macro: 0.4429, Accuracy: 0.4583\n","Epoch 28, Train Loss: 5.9119, Val Loss: 4.9222, F1 Micro: 0.6250, F1 Macro: 0.5712, Accuracy: 0.6250\n","Epoch 29, Train Loss: 8.5781, Val Loss: 6.8426, F1 Micro: 0.6875, F1 Macro: 0.5833, Accuracy: 0.6875\n","Epoch 30, Train Loss: 6.6213, Val Loss: 1.3802, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 31, Train Loss: 3.4636, Val Loss: 0.6742, F1 Micro: 0.8750, F1 Macro: 0.7949, Accuracy: 0.8750\n","Epoch 32, Train Loss: 1.9053, Val Loss: 3.9369, F1 Micro: 0.5729, F1 Macro: 0.5300, Accuracy: 0.5729\n","Epoch 33, Train Loss: 4.0270, Val Loss: 5.5448, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 34, Train Loss: 3.4845, Val Loss: 4.1615, F1 Micro: 0.6250, F1 Macro: 0.5712, Accuracy: 0.6250\n","Epoch 35, Train Loss: 3.8669, Val Loss: 5.7866, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 36, Train Loss: 3.1291, Val Loss: 1.5221, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 37, Train Loss: 3.6006, Val Loss: 8.1951, F1 Micro: 0.5833, F1 Macro: 0.5382, Accuracy: 0.5833\n","Epoch 38, Train Loss: 2.2747, Val Loss: 2.6666, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 39, Train Loss: 1.0822, Val Loss: 1.1959, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 40, Train Loss: 2.3349, Val Loss: 25.2644, F1 Micro: 0.7812, F1 Macro: 0.4386, Accuracy: 0.7812\n","Epoch 41, Train Loss: 21.1569, Val Loss: 11.5938, F1 Micro: 0.6042, F1 Macro: 0.5306, Accuracy: 0.6042\n","Epoch 42, Train Loss: 4.2809, Val Loss: 3.7676, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 43, Train Loss: 13.5514, Val Loss: 4.4876, F1 Micro: 0.7708, F1 Macro: 0.6239, Accuracy: 0.7708\n","Epoch 44, Train Loss: 4.7692, Val Loss: 4.0102, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 45, Train Loss: 1.8990, Val Loss: 2.4686, F1 Micro: 0.8229, F1 Macro: 0.7030, Accuracy: 0.8229\n","Epoch 46, Train Loss: 3.5773, Val Loss: 2.6510, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 47, Train Loss: 0.9817, Val Loss: 0.7215, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 48, Train Loss: 0.8698, Val Loss: 1.2698, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 49, Train Loss: 1.6683, Val Loss: 1.4848, F1 Micro: 0.8333, F1 Macro: 0.7474, Accuracy: 0.8333\n","Epoch 50, Train Loss: 0.9691, Val Loss: 1.4916, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 51, Train Loss: 1.6150, Val Loss: 2.5390, F1 Micro: 0.8542, F1 Macro: 0.6886, Accuracy: 0.8542\n","Epoch 52, Train Loss: 2.3099, Val Loss: 0.6617, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 53, Train Loss: 0.9689, Val Loss: 0.8850, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 54, Train Loss: 1.7719, Val Loss: 3.2618, F1 Micro: 0.8333, F1 Macro: 0.6840, Accuracy: 0.8333\n","Epoch 55, Train Loss: 6.0568, Val Loss: 1.6646, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 56, Train Loss: 1.5454, Val Loss: 1.0923, F1 Micro: 0.8438, F1 Macro: 0.7115, Accuracy: 0.8438\n","Epoch 57, Train Loss: 1.0778, Val Loss: 1.3897, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 58, Train Loss: 2.4531, Val Loss: 1.7421, F1 Micro: 0.8021, F1 Macro: 0.6943, Accuracy: 0.8021\n","Epoch 59, Train Loss: 1.6820, Val Loss: 1.1587, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 60, Train Loss: 0.6335, Val Loss: 1.1631, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 61, Train Loss: 1.2234, Val Loss: 0.5809, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 62, Train Loss: 1.5598, Val Loss: 1.3908, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 63, Train Loss: 3.8709, Val Loss: 5.2887, F1 Micro: 0.5625, F1 Macro: 0.5218, Accuracy: 0.5625\n","Epoch 64, Train Loss: 6.0717, Val Loss: 13.6051, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 65, Train Loss: 19.8963, Val Loss: 11.0943, F1 Micro: 0.5104, F1 Macro: 0.4806, Accuracy: 0.5104\n","Epoch 66, Train Loss: 3.8430, Val Loss: 2.9495, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 67, Train Loss: 0.8430, Val Loss: 1.3119, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 68, Train Loss: 2.3129, Val Loss: 12.9584, F1 Micro: 0.6771, F1 Macro: 0.5633, Accuracy: 0.6771\n","Epoch 69, Train Loss: 13.3935, Val Loss: 23.7555, F1 Micro: 0.7500, F1 Macro: 0.4662, Accuracy: 0.7500\n","Epoch 70, Train Loss: 13.1388, Val Loss: 1.1245, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 71, Train Loss: 2.2170, Val Loss: 3.0094, F1 Micro: 0.7604, F1 Macro: 0.6849, Accuracy: 0.7604\n","Epoch 72, Train Loss: 2.1703, Val Loss: 1.5441, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 73, Train Loss: 1.1289, Val Loss: 0.9165, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 74, Train Loss: 1.4103, Val Loss: 1.3124, F1 Micro: 0.8542, F1 Macro: 0.6667, Accuracy: 0.8542\n","Epoch 75, Train Loss: 3.0134, Val Loss: 1.2570, F1 Micro: 0.8646, F1 Macro: 0.5805, Accuracy: 0.8646\n","Epoch 76, Train Loss: 2.4150, Val Loss: 6.7573, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 77, Train Loss: 5.3010, Val Loss: 3.0744, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 78, Train Loss: 5.8513, Val Loss: 3.2487, F1 Micro: 0.8542, F1 Macro: 0.7375, Accuracy: 0.8542\n","Epoch 79, Train Loss: 1.8975, Val Loss: 1.0519, F1 Micro: 0.8542, F1 Macro: 0.6093, Accuracy: 0.8542\n","Epoch 80, Train Loss: 4.2230, Val Loss: 1.4836, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 81, Train Loss: 2.8211, Val Loss: 4.8753, F1 Micro: 0.7708, F1 Macro: 0.6526, Accuracy: 0.7708\n","Epoch 82, Train Loss: 2.4207, Val Loss: 5.5543, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 83, Train Loss: 2.2807, Val Loss: 0.7391, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 84, Train Loss: 1.7536, Val Loss: 1.2657, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 85, Train Loss: 6.2197, Val Loss: 1.9534, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 86, Train Loss: 10.3405, Val Loss: 11.8074, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 87, Train Loss: 8.9428, Val Loss: 8.8133, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 88, Train Loss: 7.7930, Val Loss: 1.2899, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 89, Train Loss: 1.0784, Val Loss: 1.2950, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 90, Train Loss: 1.4263, Val Loss: 2.9301, F1 Micro: 0.8750, F1 Macro: 0.7143, Accuracy: 0.8750\n","Epoch 91, Train Loss: 3.6822, Val Loss: 4.7254, F1 Micro: 0.7708, F1 Macro: 0.6648, Accuracy: 0.7708\n","Epoch 92, Train Loss: 7.8283, Val Loss: 7.7551, F1 Micro: 0.6875, F1 Macro: 0.6218, Accuracy: 0.6875\n","Epoch 93, Train Loss: 9.2275, Val Loss: 4.5341, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 94, Train Loss: 2.3167, Val Loss: 1.9461, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 95, Train Loss: 1.7895, Val Loss: 0.9144, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 96, Train Loss: 3.5999, Val Loss: 4.5141, F1 Micro: 0.7917, F1 Macro: 0.7141, Accuracy: 0.7917\n","Epoch 97, Train Loss: 2.7647, Val Loss: 2.7724, F1 Micro: 0.8646, F1 Macro: 0.7908, Accuracy: 0.8646\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 913.7162, Val Loss: 121.3391, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 142.9946, Val Loss: 24.9526, F1 Micro: 0.4375, F1 Macro: 0.4120, Accuracy: 0.4375\n","Epoch 3, Train Loss: 83.5942, Val Loss: 108.9781, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 4, Train Loss: 140.6793, Val Loss: 26.7433, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 5, Train Loss: 123.6023, Val Loss: 73.7410, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 6, Train Loss: 80.6445, Val Loss: 72.2798, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 7, Train Loss: 97.3141, Val Loss: 116.2799, F1 Micro: 0.1771, F1 Macro: 0.1727, Accuracy: 0.1771\n","Epoch 8, Train Loss: 49.4939, Val Loss: 18.5971, F1 Micro: 0.3438, F1 Macro: 0.3379, Accuracy: 0.3438\n","Epoch 9, Train Loss: 78.3496, Val Loss: 64.1424, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 10, Train Loss: 39.9580, Val Loss: 167.9698, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 11, Train Loss: 72.7764, Val Loss: 37.4407, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 12, Train Loss: 32.9251, Val Loss: 13.4459, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 13, Train Loss: 19.4489, Val Loss: 2.1694, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 14, Train Loss: 9.9350, Val Loss: 2.9323, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 15, Train Loss: 26.4580, Val Loss: 22.8219, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 16, Train Loss: 26.7223, Val Loss: 8.9863, F1 Micro: 0.7188, F1 Macro: 0.6082, Accuracy: 0.7188\n","Epoch 17, Train Loss: 14.8964, Val Loss: 18.3328, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 18, Train Loss: 23.3998, Val Loss: 16.1321, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 19, Train Loss: 24.6989, Val Loss: 4.4253, F1 Micro: 0.8438, F1 Macro: 0.6768, Accuracy: 0.8438\n","Epoch 20, Train Loss: 27.6860, Val Loss: 7.5192, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 21, Train Loss: 23.0135, Val Loss: 13.4207, F1 Micro: 0.3021, F1 Macro: 0.2984, Accuracy: 0.3021\n","Epoch 22, Train Loss: 16.7393, Val Loss: 22.3037, F1 Micro: 0.6146, F1 Macro: 0.5473, Accuracy: 0.6146\n","Epoch 23, Train Loss: 14.1393, Val Loss: 8.4919, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 24, Train Loss: 7.3903, Val Loss: 24.7085, F1 Micro: 0.1667, F1 Macro: 0.1608, Accuracy: 0.1667\n","Epoch 25, Train Loss: 7.3917, Val Loss: 5.1405, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 26, Train Loss: 3.3815, Val Loss: 6.9187, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 27, Train Loss: 7.0836, Val Loss: 2.7279, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 28, Train Loss: 4.8812, Val Loss: 1.7944, F1 Micro: 0.8438, F1 Macro: 0.7256, Accuracy: 0.8438\n","Epoch 29, Train Loss: 4.9482, Val Loss: 6.1046, F1 Micro: 0.3958, F1 Macro: 0.3827, Accuracy: 0.3958\n","Epoch 30, Train Loss: 5.1636, Val Loss: 8.7122, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 31, Train Loss: 6.7936, Val Loss: 1.8295, F1 Micro: 0.9062, F1 Macro: 0.7096, Accuracy: 0.9062\n","Epoch 32, Train Loss: 3.8804, Val Loss: 0.9374, F1 Micro: 0.8958, F1 Macro: 0.6591, Accuracy: 0.8958\n","Epoch 33, Train Loss: 2.6519, Val Loss: 4.5065, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 34, Train Loss: 4.1530, Val Loss: 5.7528, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 35, Train Loss: 6.7833, Val Loss: 1.0062, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 36, Train Loss: 3.4123, Val Loss: 1.7468, F1 Micro: 0.7083, F1 Macro: 0.6214, Accuracy: 0.7083\n","Epoch 37, Train Loss: 6.9597, Val Loss: 7.2704, F1 Micro: 0.5208, F1 Macro: 0.4424, Accuracy: 0.5208\n","Epoch 38, Train Loss: 2.0469, Val Loss: 2.4301, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 39, Train Loss: 3.5426, Val Loss: 4.7085, F1 Micro: 0.6146, F1 Macro: 0.5555, Accuracy: 0.6146\n","Epoch 40, Train Loss: 8.6287, Val Loss: 8.5415, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 41, Train Loss: 4.3180, Val Loss: 0.8726, F1 Micro: 0.8333, F1 Macro: 0.6655, Accuracy: 0.8333\n","Epoch 42, Train Loss: 1.6449, Val Loss: 0.7331, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 43, Train Loss: 1.7238, Val Loss: 0.3742, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 44, Train Loss: 2.2561, Val Loss: 0.4022, F1 Micro: 0.9375, F1 Macro: 0.8326, Accuracy: 0.9375\n","Epoch 45, Train Loss: 2.8249, Val Loss: 4.3131, F1 Micro: 0.5625, F1 Macro: 0.5152, Accuracy: 0.5625\n","Epoch 46, Train Loss: 2.6238, Val Loss: 0.4451, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 47, Train Loss: 6.3391, Val Loss: 6.8005, F1 Micro: 0.5729, F1 Macro: 0.4526, Accuracy: 0.5729\n","Epoch 48, Train Loss: 7.4663, Val Loss: 7.2437, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 49, Train Loss: 4.6140, Val Loss: 0.8576, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 50, Train Loss: 2.0537, Val Loss: 0.4191, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 51, Train Loss: 2.5024, Val Loss: 8.4609, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 52, Train Loss: 2.9671, Val Loss: 0.5656, F1 Micro: 0.9583, F1 Macro: 0.9110, Accuracy: 0.9583\n","Epoch 53, Train Loss: 6.1077, Val Loss: 9.8825, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 54, Train Loss: 5.8322, Val Loss: 1.2797, F1 Micro: 0.8229, F1 Macro: 0.7154, Accuracy: 0.8229\n","Epoch 55, Train Loss: 3.6079, Val Loss: 4.5121, F1 Micro: 0.8229, F1 Macro: 0.7030, Accuracy: 0.8229\n","Epoch 56, Train Loss: 1.3739, Val Loss: 0.5356, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 57, Train Loss: 7.5986, Val Loss: 4.9327, F1 Micro: 0.5521, F1 Macro: 0.5071, Accuracy: 0.5521\n","Epoch 58, Train Loss: 4.1296, Val Loss: 2.4849, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 59, Train Loss: 5.1649, Val Loss: 1.4025, F1 Micro: 0.8333, F1 Macro: 0.7474, Accuracy: 0.8333\n","Epoch 60, Train Loss: 1.5048, Val Loss: 1.3777, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 61, Train Loss: 1.8982, Val Loss: 0.5089, F1 Micro: 0.9271, F1 Macro: 0.8271, Accuracy: 0.9271\n","Epoch 62, Train Loss: 2.6175, Val Loss: 2.6236, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 63, Train Loss: 2.7185, Val Loss: 0.6490, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 64, Train Loss: 0.9429, Val Loss: 0.7573, F1 Micro: 0.8854, F1 Macro: 0.6450, Accuracy: 0.8854\n","Epoch 65, Train Loss: 3.1125, Val Loss: 4.1622, F1 Micro: 0.7708, F1 Macro: 0.6855, Accuracy: 0.7708\n","Epoch 66, Train Loss: 4.7777, Val Loss: 7.3342, F1 Micro: 0.5521, F1 Macro: 0.4522, Accuracy: 0.5521\n","Epoch 67, Train Loss: 3.6906, Val Loss: 3.9182, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 68, Train Loss: 4.2225, Val Loss: 5.0007, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 69, Train Loss: 10.8707, Val Loss: 4.0864, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 70, Train Loss: 6.0895, Val Loss: 7.8643, F1 Micro: 0.6354, F1 Macro: 0.5718, Accuracy: 0.6354\n","Epoch 71, Train Loss: 4.6284, Val Loss: 4.5526, F1 Micro: 0.7083, F1 Macro: 0.4750, Accuracy: 0.7083\n","Epoch 72, Train Loss: 4.7658, Val Loss: 1.7770, F1 Micro: 0.7812, F1 Macro: 0.6853, Accuracy: 0.7812\n","Epoch 73, Train Loss: 1.6595, Val Loss: 0.5972, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 74, Train Loss: 2.9925, Val Loss: 1.0665, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 75, Train Loss: 1.6683, Val Loss: 2.0342, F1 Micro: 0.8438, F1 Macro: 0.7587, Accuracy: 0.8438\n","Epoch 76, Train Loss: 1.9658, Val Loss: 0.5567, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 77, Train Loss: 3.6906, Val Loss: 1.0490, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 78, Train Loss: 1.4313, Val Loss: 0.8430, F1 Micro: 0.9271, F1 Macro: 0.8129, Accuracy: 0.9271\n","Epoch 79, Train Loss: 1.8729, Val Loss: 4.5850, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 80, Train Loss: 3.2590, Val Loss: 0.7828, F1 Micro: 0.9375, F1 Macro: 0.8815, Accuracy: 0.9375\n","Epoch 81, Train Loss: 1.4285, Val Loss: 0.5613, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 82, Train Loss: 4.5376, Val Loss: 7.4941, F1 Micro: 0.6146, F1 Macro: 0.5555, Accuracy: 0.6146\n","Epoch 83, Train Loss: 8.9254, Val Loss: 1.0111, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 84, Train Loss: 13.4962, Val Loss: 2.7021, F1 Micro: 0.7396, F1 Macro: 0.6372, Accuracy: 0.7396\n","Epoch 85, Train Loss: 13.1945, Val Loss: 8.1016, F1 Micro: 0.8125, F1 Macro: 0.6923, Accuracy: 0.8125\n","Epoch 86, Train Loss: 39.9179, Val Loss: 7.9986, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 87, Train Loss: 7.9845, Val Loss: 2.2478, F1 Micro: 0.7708, F1 Macro: 0.6855, Accuracy: 0.7708\n","Epoch 88, Train Loss: 5.3195, Val Loss: 11.9180, F1 Micro: 0.5104, F1 Macro: 0.4748, Accuracy: 0.5104\n","Epoch 89, Train Loss: 3.1011, Val Loss: 1.0874, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 90, Train Loss: 3.4272, Val Loss: 2.1449, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 91, Train Loss: 1.7931, Val Loss: 0.6553, F1 Micro: 0.9688, F1 Macro: 0.9310, Accuracy: 0.9688\n","Epoch 92, Train Loss: 5.1028, Val Loss: 9.8001, F1 Micro: 0.5104, F1 Macro: 0.4613, Accuracy: 0.5104\n","Epoch 93, Train Loss: 2.4091, Val Loss: 0.6292, F1 Micro: 0.9375, F1 Macro: 0.8460, Accuracy: 0.9375\n","Epoch 94, Train Loss: 2.7510, Val Loss: 0.9586, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 95, Train Loss: 2.6642, Val Loss: 1.3335, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 96, Train Loss: 3.6097, Val Loss: 3.2264, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 97, Train Loss: 1.2965, Val Loss: 0.8565, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 98, Train Loss: 2.8216, Val Loss: 0.8192, F1 Micro: 0.9583, F1 Macro: 0.9110, Accuracy: 0.9583\n","Epoch 99, Train Loss: 3.1657, Val Loss: 7.8162, F1 Micro: 0.5729, F1 Macro: 0.5232, Accuracy: 0.5729\n","Epoch 100, Train Loss: 3.1607, Val Loss: 1.5880, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 101, Train Loss: 5.1750, Val Loss: 1.5373, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 102, Train Loss: 5.3494, Val Loss: 2.2086, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 103, Train Loss: 2.1490, Val Loss: 1.1172, F1 Micro: 0.8750, F1 Macro: 0.5909, Accuracy: 0.8750\n","Epoch 104, Train Loss: 1.0356, Val Loss: 2.3319, F1 Micro: 0.8021, F1 Macro: 0.6943, Accuracy: 0.8021\n","Epoch 105, Train Loss: 1.5229, Val Loss: 1.0939, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 106, Train Loss: 0.8241, Val Loss: 0.7383, F1 Micro: 0.9375, F1 Macro: 0.8665, Accuracy: 0.9375\n","Epoch 107, Train Loss: 1.2047, Val Loss: 4.4856, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 108, Train Loss: 6.3229, Val Loss: 7.2152, F1 Micro: 0.5833, F1 Macro: 0.5312, Accuracy: 0.5833\n","Epoch 109, Train Loss: 2.7001, Val Loss: 0.9945, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 110, Train Loss: 3.8855, Val Loss: 1.7830, F1 Micro: 0.8125, F1 Macro: 0.6923, Accuracy: 0.8125\n","Epoch 111, Train Loss: 1.5439, Val Loss: 1.4538, F1 Micro: 0.9167, F1 Macro: 0.7767, Accuracy: 0.9167\n","Epoch 112, Train Loss: 2.7846, Val Loss: 8.4406, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 113, Train Loss: 3.4748, Val Loss: 5.2488, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 114, Train Loss: 8.4356, Val Loss: 1.8482, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 115, Train Loss: 12.0068, Val Loss: 1.5754, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 116, Train Loss: 11.0268, Val Loss: 21.2199, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 117, Train Loss: 5.6637, Val Loss: 6.1513, F1 Micro: 0.7708, F1 Macro: 0.6757, Accuracy: 0.7708\n","Epoch 118, Train Loss: 5.6723, Val Loss: 0.7547, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 119, Train Loss: 4.5049, Val Loss: 2.9114, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 120, Train Loss: 1.7647, Val Loss: 1.5171, F1 Micro: 0.8958, F1 Macro: 0.6591, Accuracy: 0.8958\n","Epoch 121, Train Loss: 2.6065, Val Loss: 1.6965, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 122, Train Loss: 4.5432, Val Loss: 1.7107, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 123, Train Loss: 3.7797, Val Loss: 0.7959, F1 Micro: 0.9688, F1 Macro: 0.9310, Accuracy: 0.9688\n","Epoch 124, Train Loss: 4.5033, Val Loss: 1.3677, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 125, Train Loss: 8.6881, Val Loss: 0.9095, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 126, Train Loss: 8.6041, Val Loss: 1.1778, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 127, Train Loss: 2.4795, Val Loss: 1.3455, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 128, Train Loss: 5.3671, Val Loss: 30.7934, F1 Micro: 0.2917, F1 Macro: 0.2904, Accuracy: 0.2917\n","Epoch 129, Train Loss: 9.6941, Val Loss: 9.0314, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 130, Train Loss: 5.0285, Val Loss: 2.3101, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 131, Train Loss: 4.8923, Val Loss: 0.9401, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 132, Train Loss: 4.9617, Val Loss: 3.8371, F1 Micro: 0.9062, F1 Macro: 0.7096, Accuracy: 0.9062\n","Epoch 133, Train Loss: 15.6672, Val Loss: 31.0176, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 134, Train Loss: 28.7729, Val Loss: 118.8012, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 135, Train Loss: 50.3481, Val Loss: 8.5397, F1 Micro: 0.6875, F1 Macro: 0.6135, Accuracy: 0.6875\n","Epoch 136, Train Loss: 6.0152, Val Loss: 2.7166, F1 Micro: 0.8021, F1 Macro: 0.6943, Accuracy: 0.8021\n","Epoch 137, Train Loss: 2.6167, Val Loss: 1.2529, F1 Micro: 0.9167, F1 Macro: 0.8500, Accuracy: 0.9167\n","Epoch 138, Train Loss: 3.1147, Val Loss: 3.7793, F1 Micro: 0.8333, F1 Macro: 0.7474, Accuracy: 0.8333\n","Epoch 139, Train Loss: 2.4223, Val Loss: 1.0345, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 140, Train Loss: 1.5024, Val Loss: 0.8302, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 141, Train Loss: 0.8053, Val Loss: 1.7498, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 361.7530, Val Loss: 510.7659, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 2, Train Loss: 299.0606, Val Loss: 32.9515, F1 Micro: 0.5729, F1 Macro: 0.4526, Accuracy: 0.5729\n","Epoch 3, Train Loss: 252.8327, Val Loss: 246.5080, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 136.9856, Val Loss: 124.2921, F1 Micro: 0.1771, F1 Macro: 0.1748, Accuracy: 0.1771\n","Epoch 5, Train Loss: 235.9816, Val Loss: 127.3206, F1 Micro: 0.1562, F1 Macro: 0.1517, Accuracy: 0.1562\n","Epoch 6, Train Loss: 65.5571, Val Loss: 12.1395, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 7, Train Loss: 62.1683, Val Loss: 59.2426, F1 Micro: 0.2188, F1 Macro: 0.2187, Accuracy: 0.2188\n","Epoch 8, Train Loss: 43.5804, Val Loss: 147.7224, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 103.2097, Val Loss: 36.2400, F1 Micro: 0.1667, F1 Macro: 0.1634, Accuracy: 0.1667\n","Epoch 10, Train Loss: 47.7495, Val Loss: 124.2237, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 11, Train Loss: 55.9255, Val Loss: 20.7452, F1 Micro: 0.3854, F1 Macro: 0.3480, Accuracy: 0.3854\n","Epoch 12, Train Loss: 33.3031, Val Loss: 26.5931, F1 Micro: 0.6667, F1 Macro: 0.4947, Accuracy: 0.6667\n","Epoch 13, Train Loss: 20.2071, Val Loss: 4.4916, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 14, Train Loss: 27.2616, Val Loss: 68.7765, F1 Micro: 0.3125, F1 Macro: 0.2976, Accuracy: 0.3125\n","Epoch 15, Train Loss: 72.9319, Val Loss: 75.5169, F1 Micro: 0.1562, F1 Macro: 0.1517, Accuracy: 0.1562\n","Epoch 16, Train Loss: 24.1203, Val Loss: 35.0759, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 17, Train Loss: 19.7818, Val Loss: 30.3320, F1 Micro: 0.2396, F1 Macro: 0.2395, Accuracy: 0.2396\n","Epoch 18, Train Loss: 29.9211, Val Loss: 38.6001, F1 Micro: 0.1771, F1 Macro: 0.1748, Accuracy: 0.1771\n","Epoch 19, Train Loss: 46.3258, Val Loss: 67.1946, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 20, Train Loss: 27.3286, Val Loss: 16.9422, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 21, Train Loss: 21.1583, Val Loss: 5.6671, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 22, Train Loss: 6.5703, Val Loss: 7.2698, F1 Micro: 0.6667, F1 Macro: 0.5124, Accuracy: 0.6667\n","Epoch 23, Train Loss: 6.5786, Val Loss: 8.6399, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 24, Train Loss: 11.9070, Val Loss: 2.2106, F1 Micro: 0.6146, F1 Macro: 0.5473, Accuracy: 0.6146\n","Epoch 25, Train Loss: 8.4283, Val Loss: 14.7229, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 26, Train Loss: 17.3062, Val Loss: 9.6222, F1 Micro: 0.4583, F1 Macro: 0.3997, Accuracy: 0.4583\n","Epoch 27, Train Loss: 14.7491, Val Loss: 8.8572, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 28, Train Loss: 12.0892, Val Loss: 13.1056, F1 Micro: 0.6667, F1 Macro: 0.5124, Accuracy: 0.6667\n","Epoch 29, Train Loss: 14.0703, Val Loss: 26.2081, F1 Micro: 0.1875, F1 Macro: 0.1861, Accuracy: 0.1875\n","Epoch 30, Train Loss: 10.3741, Val Loss: 4.7655, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 31, Train Loss: 4.7185, Val Loss: 4.3155, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 32, Train Loss: 5.4043, Val Loss: 0.7966, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 33, Train Loss: 4.6171, Val Loss: 3.4661, F1 Micro: 0.8958, F1 Macro: 0.6148, Accuracy: 0.8958\n","Epoch 34, Train Loss: 5.5398, Val Loss: 10.5876, F1 Micro: 0.3854, F1 Macro: 0.3700, Accuracy: 0.3854\n","Epoch 35, Train Loss: 7.1164, Val Loss: 3.6004, F1 Micro: 0.7604, F1 Macro: 0.6150, Accuracy: 0.7604\n","Epoch 36, Train Loss: 4.2605, Val Loss: 7.2635, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 37, Train Loss: 8.7404, Val Loss: 1.3941, F1 Micro: 0.7604, F1 Macro: 0.6434, Accuracy: 0.7604\n","Epoch 38, Train Loss: 1.6379, Val Loss: 1.4727, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 39, Train Loss: 1.9914, Val Loss: 4.0532, F1 Micro: 0.8854, F1 Macro: 0.6023, Accuracy: 0.8854\n","Epoch 40, Train Loss: 5.1731, Val Loss: 6.6988, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 41, Train Loss: 1.9123, Val Loss: 1.5003, F1 Micro: 0.9062, F1 Macro: 0.6287, Accuracy: 0.9062\n","Epoch 42, Train Loss: 2.1881, Val Loss: 1.1537, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 43, Train Loss: 0.9527, Val Loss: 0.2106, F1 Micro: 0.9375, F1 Macro: 0.8161, Accuracy: 0.9375\n","Epoch 44, Train Loss: 1.1407, Val Loss: 0.5728, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 45, Train Loss: 2.6315, Val Loss: 5.2918, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 46, Train Loss: 2.8534, Val Loss: 0.7323, F1 Micro: 0.9271, F1 Macro: 0.7469, Accuracy: 0.9271\n","Epoch 47, Train Loss: 3.2218, Val Loss: 1.5000, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 48, Train Loss: 3.9304, Val Loss: 6.0905, F1 Micro: 0.7812, F1 Macro: 0.6158, Accuracy: 0.7812\n","Epoch 49, Train Loss: 5.1809, Val Loss: 2.3689, F1 Micro: 0.8125, F1 Macro: 0.6625, Accuracy: 0.8125\n","Epoch 50, Train Loss: 2.3542, Val Loss: 1.2271, F1 Micro: 0.8646, F1 Macro: 0.6525, Accuracy: 0.8646\n","Epoch 51, Train Loss: 8.7700, Val Loss: 5.7847, F1 Micro: 0.7500, F1 Macro: 0.6063, Accuracy: 0.7500\n","Epoch 52, Train Loss: 5.2360, Val Loss: 6.6794, F1 Micro: 0.5000, F1 Macro: 0.4375, Accuracy: 0.5000\n","Epoch 53, Train Loss: 2.2984, Val Loss: 5.4561, F1 Micro: 0.7604, F1 Macro: 0.6150, Accuracy: 0.7604\n","Epoch 54, Train Loss: 1.9288, Val Loss: 1.4995, F1 Micro: 0.8438, F1 Macro: 0.6551, Accuracy: 0.8438\n","Epoch 55, Train Loss: 1.7121, Val Loss: 1.1531, F1 Micro: 0.8646, F1 Macro: 0.7499, Accuracy: 0.8646\n","Epoch 56, Train Loss: 1.9882, Val Loss: 2.4326, F1 Micro: 0.7812, F1 Macro: 0.6331, Accuracy: 0.7812\n","Epoch 57, Train Loss: 1.4533, Val Loss: 2.8430, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 58, Train Loss: 1.3544, Val Loss: 1.3212, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 59, Train Loss: 1.4886, Val Loss: 0.7538, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 60, Train Loss: 1.7098, Val Loss: 11.2803, F1 Micro: 0.6354, F1 Macro: 0.5205, Accuracy: 0.6354\n","Epoch 61, Train Loss: 9.0393, Val Loss: 5.2778, F1 Micro: 0.8750, F1 Macro: 0.5377, Accuracy: 0.8750\n","Epoch 62, Train Loss: 2.7013, Val Loss: 1.0836, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 63, Train Loss: 0.9264, Val Loss: 1.0486, F1 Micro: 0.8333, F1 Macro: 0.7375, Accuracy: 0.8333\n","Epoch 64, Train Loss: 2.5679, Val Loss: 5.3633, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 65, Train Loss: 4.7803, Val Loss: 6.2023, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 66, Train Loss: 4.4071, Val Loss: 6.7705, F1 Micro: 0.5417, F1 Macro: 0.4921, Accuracy: 0.5417\n","Epoch 67, Train Loss: 4.3944, Val Loss: 6.1713, F1 Micro: 0.7083, F1 Macro: 0.5733, Accuracy: 0.7083\n","Epoch 68, Train Loss: 4.8222, Val Loss: 2.1926, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 69, Train Loss: 2.7814, Val Loss: 0.3761, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 70, Train Loss: 0.9781, Val Loss: 0.9489, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 71, Train Loss: 0.8486, Val Loss: 0.4427, F1 Micro: 0.9271, F1 Macro: 0.7469, Accuracy: 0.9271\n","Epoch 72, Train Loss: 1.1361, Val Loss: 1.8882, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 73, Train Loss: 2.9261, Val Loss: 2.6568, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 74, Train Loss: 4.0524, Val Loss: 0.5178, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 75, Train Loss: 1.9641, Val Loss: 4.7137, F1 Micro: 0.6250, F1 Macro: 0.5362, Accuracy: 0.6250\n","Epoch 76, Train Loss: 1.9952, Val Loss: 2.5046, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 77, Train Loss: 2.3850, Val Loss: 2.0139, F1 Micro: 0.9062, F1 Macro: 0.6287, Accuracy: 0.9062\n","Epoch 78, Train Loss: 1.4510, Val Loss: 2.0382, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 79, Train Loss: 2.2425, Val Loss: 3.4322, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 80, Train Loss: 4.9979, Val Loss: 12.6071, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 81, Train Loss: 2.8654, Val Loss: 4.0151, F1 Micro: 0.7083, F1 Macro: 0.5872, Accuracy: 0.7083\n","Epoch 82, Train Loss: 5.5591, Val Loss: 2.4899, F1 Micro: 0.8438, F1 Macro: 0.6954, Accuracy: 0.8438\n","Epoch 83, Train Loss: 2.3463, Val Loss: 0.2347, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 84, Train Loss: 2.7256, Val Loss: 0.3526, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 85, Train Loss: 2.8226, Val Loss: 1.8762, F1 Micro: 0.7500, F1 Macro: 0.6569, Accuracy: 0.7500\n","Epoch 86, Train Loss: 9.1798, Val Loss: 0.2177, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 87, Train Loss: 2.0213, Val Loss: 6.8469, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 88, Train Loss: 2.3363, Val Loss: 0.9383, F1 Micro: 0.8646, F1 Macro: 0.7729, Accuracy: 0.8646\n","Epoch 89, Train Loss: 1.1812, Val Loss: 4.0046, F1 Micro: 0.6771, F1 Macro: 0.5753, Accuracy: 0.6771\n","Epoch 90, Train Loss: 2.2975, Val Loss: 0.6774, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 91, Train Loss: 7.8319, Val Loss: 8.7269, F1 Micro: 0.5000, F1 Macro: 0.4604, Accuracy: 0.5000\n","Epoch 92, Train Loss: 6.0713, Val Loss: 8.9202, F1 Micro: 0.7292, F1 Macro: 0.5735, Accuracy: 0.7292\n","Epoch 93, Train Loss: 7.2495, Val Loss: 0.5777, F1 Micro: 0.9271, F1 Macro: 0.7469, Accuracy: 0.9271\n","Epoch 94, Train Loss: 2.6514, Val Loss: 4.5513, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 95, Train Loss: 2.2146, Val Loss: 0.5576, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 96, Train Loss: 5.9627, Val Loss: 6.2044, F1 Micro: 0.6042, F1 Macro: 0.5394, Accuracy: 0.6042\n","Epoch 97, Train Loss: 3.2949, Val Loss: 2.7592, F1 Micro: 0.8229, F1 Macro: 0.6730, Accuracy: 0.8229\n","Epoch 98, Train Loss: 2.2019, Val Loss: 2.1527, F1 Micro: 0.9167, F1 Macro: 0.6918, Accuracy: 0.9167\n","Epoch 99, Train Loss: 10.6542, Val Loss: 18.0913, F1 Micro: 0.8229, F1 Macro: 0.5801, Accuracy: 0.8229\n","Epoch 100, Train Loss: 26.2037, Val Loss: 8.0410, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 101, Train Loss: 5.4450, Val Loss: 0.9195, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 102, Train Loss: 1.7623, Val Loss: 8.2428, F1 Micro: 0.5521, F1 Macro: 0.4739, Accuracy: 0.5521\n","Epoch 103, Train Loss: 2.3449, Val Loss: 0.8985, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 104, Train Loss: 4.5964, Val Loss: 3.6083, F1 Micro: 0.8125, F1 Macro: 0.6625, Accuracy: 0.8125\n","Epoch 105, Train Loss: 3.0861, Val Loss: 2.4657, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 106, Train Loss: 3.8876, Val Loss: 1.5791, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 107, Train Loss: 2.9775, Val Loss: 4.7639, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 108, Train Loss: 3.4792, Val Loss: 4.1569, F1 Micro: 0.7604, F1 Macro: 0.6434, Accuracy: 0.7604\n","Epoch 109, Train Loss: 3.5674, Val Loss: 1.8813, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 110, Train Loss: 4.9984, Val Loss: 0.7736, F1 Micro: 0.9271, F1 Macro: 0.7469, Accuracy: 0.9271\n","Epoch 111, Train Loss: 2.4498, Val Loss: 4.5467, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 112, Train Loss: 3.1077, Val Loss: 2.6272, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 113, Train Loss: 2.4136, Val Loss: 0.3790, F1 Micro: 0.9271, F1 Macro: 0.8271, Accuracy: 0.9271\n","Epoch 114, Train Loss: 3.5240, Val Loss: 3.8420, F1 Micro: 0.9062, F1 Macro: 0.6746, Accuracy: 0.9062\n","Epoch 115, Train Loss: 4.9113, Val Loss: 3.4309, F1 Micro: 0.7500, F1 Macro: 0.6569, Accuracy: 0.7500\n","Epoch 116, Train Loss: 1.7326, Val Loss: 1.6390, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 117, Train Loss: 1.1251, Val Loss: 0.4804, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 118, Train Loss: 1.8138, Val Loss: 0.4703, F1 Micro: 0.9479, F1 Macro: 0.8387, Accuracy: 0.9479\n","Epoch 119, Train Loss: 33.4631, Val Loss: 50.4433, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 120, Train Loss: 20.6819, Val Loss: 4.4919, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 121, Train Loss: 6.2086, Val Loss: 1.0726, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 122, Train Loss: 1.4981, Val Loss: 0.3037, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 123, Train Loss: 1.3749, Val Loss: 1.9582, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 124, Train Loss: 1.2972, Val Loss: 0.3446, F1 Micro: 0.9375, F1 Macro: 0.8571, Accuracy: 0.9375\n","Epoch 125, Train Loss: 1.6665, Val Loss: 2.0726, F1 Micro: 0.8125, F1 Macro: 0.6923, Accuracy: 0.8125\n","Epoch 126, Train Loss: 5.7030, Val Loss: 1.9505, F1 Micro: 0.8854, F1 Macro: 0.6023, Accuracy: 0.8854\n","Epoch 127, Train Loss: 7.6698, Val Loss: 13.0912, F1 Micro: 0.4583, F1 Macro: 0.4283, Accuracy: 0.4583\n","Epoch 128, Train Loss: 10.9506, Val Loss: 1.7417, F1 Micro: 0.8854, F1 Macro: 0.7471, Accuracy: 0.8854\n","Epoch 129, Train Loss: 3.0080, Val Loss: 0.7234, F1 Micro: 0.9167, F1 Macro: 0.8328, Accuracy: 0.9167\n","Epoch 130, Train Loss: 2.9170, Val Loss: 0.3491, F1 Micro: 0.9583, F1 Macro: 0.8884, Accuracy: 0.9583\n","Epoch 131, Train Loss: 2.6340, Val Loss: 1.4418, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 132, Train Loss: 1.9314, Val Loss: 5.4717, F1 Micro: 0.8438, F1 Macro: 0.6954, Accuracy: 0.8438\n","Epoch 133, Train Loss: 3.4256, Val Loss: 2.3026, F1 Micro: 0.8646, F1 Macro: 0.6789, Accuracy: 0.8646\n","Epoch 134, Train Loss: 5.7167, Val Loss: 5.2020, F1 Micro: 0.8958, F1 Macro: 0.5556, Accuracy: 0.8958\n","Epoch 135, Train Loss: 5.6158, Val Loss: 3.3317, F1 Micro: 0.8125, F1 Macro: 0.6625, Accuracy: 0.8125\n","Epoch 136, Train Loss: 5.3883, Val Loss: 11.3092, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1018.1075, Val Loss: 273.1865, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 2, Train Loss: 158.6492, Val Loss: 131.6438, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 56.0702, Val Loss: 129.4904, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 89.4127, Val Loss: 20.9621, F1 Micro: 0.7604, F1 Macro: 0.5792, Accuracy: 0.7604\n","Epoch 5, Train Loss: 54.1554, Val Loss: 15.2596, F1 Micro: 0.6771, F1 Macro: 0.5355, Accuracy: 0.6771\n","Epoch 6, Train Loss: 174.7583, Val Loss: 39.8104, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 7, Train Loss: 51.1975, Val Loss: 16.1592, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 8, Train Loss: 28.4385, Val Loss: 32.7986, F1 Micro: 0.1979, F1 Macro: 0.1872, Accuracy: 0.1979\n","Epoch 9, Train Loss: 30.6285, Val Loss: 24.1765, F1 Micro: 0.3333, F1 Macro: 0.3322, Accuracy: 0.3333\n","Epoch 10, Train Loss: 20.0758, Val Loss: 16.1812, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 11, Train Loss: 36.6020, Val Loss: 19.4131, F1 Micro: 0.5208, F1 Macro: 0.4521, Accuracy: 0.5208\n","Epoch 12, Train Loss: 25.2687, Val Loss: 21.4117, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 13, Train Loss: 30.8304, Val Loss: 7.2856, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Epoch 14, Train Loss: 21.6997, Val Loss: 24.7964, F1 Micro: 0.4479, F1 Macro: 0.4254, Accuracy: 0.4479\n","Epoch 15, Train Loss: 16.6731, Val Loss: 8.6586, F1 Micro: 0.5833, F1 Macro: 0.4958, Accuracy: 0.5833\n","Epoch 16, Train Loss: 11.8580, Val Loss: 5.9759, F1 Micro: 0.7292, F1 Macro: 0.5125, Accuracy: 0.7292\n","Epoch 17, Train Loss: 11.4870, Val Loss: 18.6367, F1 Micro: 0.8542, F1 Macro: 0.6667, Accuracy: 0.8542\n","Epoch 18, Train Loss: 27.6954, Val Loss: 20.0139, F1 Micro: 0.7812, F1 Macro: 0.5961, Accuracy: 0.7812\n","Epoch 19, Train Loss: 28.9266, Val Loss: 7.5084, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 9.0597, Val Loss: 1.6988, F1 Micro: 0.7917, F1 Macro: 0.6581, Accuracy: 0.7917\n","Epoch 21, Train Loss: 5.6170, Val Loss: 0.5455, F1 Micro: 0.8646, F1 Macro: 0.5805, Accuracy: 0.8646\n","Epoch 22, Train Loss: 6.7144, Val Loss: 7.2718, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 23, Train Loss: 5.7830, Val Loss: 6.3691, F1 Micro: 0.4583, F1 Macro: 0.4466, Accuracy: 0.4583\n","Epoch 24, Train Loss: 3.5135, Val Loss: 1.7011, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 25, Train Loss: 8.6747, Val Loss: 8.6270, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 26, Train Loss: 10.0085, Val Loss: 8.5235, F1 Micro: 0.6250, F1 Macro: 0.5462, Accuracy: 0.6250\n","Epoch 27, Train Loss: 6.8509, Val Loss: 2.0074, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 28, Train Loss: 3.2685, Val Loss: 1.6377, F1 Micro: 0.8854, F1 Macro: 0.7630, Accuracy: 0.8854\n","Epoch 29, Train Loss: 2.1744, Val Loss: 0.7651, F1 Micro: 0.8542, F1 Macro: 0.7607, Accuracy: 0.8542\n","Epoch 30, Train Loss: 1.9103, Val Loss: 0.5359, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 31, Train Loss: 1.8914, Val Loss: 0.6278, F1 Micro: 0.8750, F1 Macro: 0.7750, Accuracy: 0.8750\n","Epoch 32, Train Loss: 2.7002, Val Loss: 5.4036, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 33, Train Loss: 4.3421, Val Loss: 2.9099, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 34, Train Loss: 2.1529, Val Loss: 0.4432, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 35, Train Loss: 2.5131, Val Loss: 0.6577, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 36, Train Loss: 2.6426, Val Loss: 2.3941, F1 Micro: 0.7083, F1 Macro: 0.5733, Accuracy: 0.7083\n","Epoch 37, Train Loss: 1.6244, Val Loss: 1.4245, F1 Micro: 0.8125, F1 Macro: 0.7346, Accuracy: 0.8125\n","Epoch 38, Train Loss: 2.4808, Val Loss: 4.6592, F1 Micro: 0.8542, F1 Macro: 0.6667, Accuracy: 0.8542\n","Epoch 39, Train Loss: 2.4911, Val Loss: 3.6159, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 40, Train Loss: 2.7882, Val Loss: 5.3082, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 41, Train Loss: 4.4286, Val Loss: 19.6565, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 42, Train Loss: 6.9560, Val Loss: 1.2772, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 43, Train Loss: 5.7942, Val Loss: 11.6461, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 44, Train Loss: 3.3308, Val Loss: 4.3362, F1 Micro: 0.7708, F1 Macro: 0.6391, Accuracy: 0.7708\n","Epoch 45, Train Loss: 6.6831, Val Loss: 4.5926, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 46, Train Loss: 4.1557, Val Loss: 2.5162, F1 Micro: 0.8229, F1 Macro: 0.6890, Accuracy: 0.8229\n","Epoch 47, Train Loss: 1.4964, Val Loss: 0.6043, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 48, Train Loss: 1.3868, Val Loss: 0.4750, F1 Micro: 0.8750, F1 Macro: 0.7630, Accuracy: 0.8750\n","Epoch 49, Train Loss: 1.2629, Val Loss: 1.8771, F1 Micro: 0.8021, F1 Macro: 0.7243, Accuracy: 0.8021\n","Epoch 50, Train Loss: 1.3368, Val Loss: 0.6793, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 51, Train Loss: 1.6757, Val Loss: 2.3678, F1 Micro: 0.8229, F1 Macro: 0.6890, Accuracy: 0.8229\n","Epoch 52, Train Loss: 1.5049, Val Loss: 2.7376, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 53, Train Loss: 5.4098, Val Loss: 0.3729, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 54, Train Loss: 4.2092, Val Loss: 0.5447, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 55, Train Loss: 3.3698, Val Loss: 6.1699, F1 Micro: 0.6875, F1 Macro: 0.6044, Accuracy: 0.6875\n","Epoch 56, Train Loss: 3.8105, Val Loss: 0.4756, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 57, Train Loss: 3.9004, Val Loss: 6.1135, F1 Micro: 0.5833, F1 Macro: 0.5504, Accuracy: 0.5833\n","Epoch 58, Train Loss: 5.9281, Val Loss: 1.4356, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 59, Train Loss: 1.2048, Val Loss: 1.4431, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 60, Train Loss: 1.4217, Val Loss: 0.6611, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 61, Train Loss: 2.3537, Val Loss: 3.6405, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 62, Train Loss: 2.0786, Val Loss: 1.3885, F1 Micro: 0.8021, F1 Macro: 0.7153, Accuracy: 0.8021\n","Epoch 63, Train Loss: 1.6781, Val Loss: 0.8420, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 64, Train Loss: 0.8052, Val Loss: 0.7622, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 65, Train Loss: 2.3255, Val Loss: 1.1242, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 66, Train Loss: 2.5784, Val Loss: 1.8699, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 67, Train Loss: 3.4546, Val Loss: 5.8119, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 68, Train Loss: 6.6175, Val Loss: 7.1179, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 69, Train Loss: 7.8998, Val Loss: 1.9595, F1 Micro: 0.7917, F1 Macro: 0.6719, Accuracy: 0.7917\n","Epoch 70, Train Loss: 5.5540, Val Loss: 0.8155, F1 Micro: 0.8542, F1 Macro: 0.7703, Accuracy: 0.8542\n","Epoch 71, Train Loss: 1.7172, Val Loss: 5.8731, F1 Micro: 0.7812, F1 Macro: 0.5735, Accuracy: 0.7812\n","Epoch 72, Train Loss: 3.2505, Val Loss: 4.4730, F1 Micro: 0.7188, F1 Macro: 0.6482, Accuracy: 0.7188\n","Epoch 73, Train Loss: 5.5452, Val Loss: 4.3214, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 74, Train Loss: 7.3420, Val Loss: 15.4623, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 75, Train Loss: 5.6615, Val Loss: 5.1704, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 76, Train Loss: 6.1795, Val Loss: 4.6930, F1 Micro: 0.7917, F1 Macro: 0.5819, Accuracy: 0.7917\n","Epoch 77, Train Loss: 5.6601, Val Loss: 2.8954, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 78, Train Loss: 2.9024, Val Loss: 0.6968, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 79, Train Loss: 2.6247, Val Loss: 4.5285, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 80, Train Loss: 5.0069, Val Loss: 1.7315, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 81, Train Loss: 2.7890, Val Loss: 2.3245, F1 Micro: 0.8021, F1 Macro: 0.7243, Accuracy: 0.8021\n","Epoch 82, Train Loss: 2.0646, Val Loss: 0.7410, F1 Micro: 0.9167, F1 Macro: 0.8570, Accuracy: 0.9167\n","Epoch 83, Train Loss: 2.2455, Val Loss: 8.3256, F1 Micro: 0.5938, F1 Macro: 0.5315, Accuracy: 0.5938\n","Epoch 84, Train Loss: 2.8357, Val Loss: 0.6154, F1 Micro: 0.9062, F1 Macro: 0.7931, Accuracy: 0.9062\n","Epoch 85, Train Loss: 4.1447, Val Loss: 3.1807, F1 Micro: 0.8125, F1 Macro: 0.7158, Accuracy: 0.8125\n","Epoch 86, Train Loss: 3.4803, Val Loss: 0.9232, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 87, Train Loss: 3.3391, Val Loss: 4.0672, F1 Micro: 0.8021, F1 Macro: 0.6681, Accuracy: 0.8021\n","Epoch 88, Train Loss: 9.0099, Val Loss: 16.5009, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 89, Train Loss: 20.1623, Val Loss: 5.2075, F1 Micro: 0.8646, F1 Macro: 0.7360, Accuracy: 0.8646\n","Epoch 90, Train Loss: 4.5465, Val Loss: 1.6647, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 91, Train Loss: 3.6512, Val Loss: 2.5584, F1 Micro: 0.8021, F1 Macro: 0.5631, Accuracy: 0.8021\n","Epoch 92, Train Loss: 5.7972, Val Loss: 17.3415, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 93, Train Loss: 5.1721, Val Loss: 1.2290, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 94, Train Loss: 3.6491, Val Loss: 4.7913, F1 Micro: 0.6875, F1 Macro: 0.6294, Accuracy: 0.6875\n","Epoch 95, Train Loss: 27.5920, Val Loss: 9.7017, F1 Micro: 0.8125, F1 Macro: 0.6783, Accuracy: 0.8125\n","Epoch 96, Train Loss: 8.3548, Val Loss: 1.6774, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 97, Train Loss: 3.4284, Val Loss: 1.9754, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 98, Train Loss: 1.5011, Val Loss: 4.0533, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 99, Train Loss: 2.8895, Val Loss: 0.5846, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 100, Train Loss: 1.5227, Val Loss: 0.6868, F1 Micro: 0.9583, F1 Macro: 0.9210, Accuracy: 0.9583\n","Epoch 101, Train Loss: 4.2565, Val Loss: 1.9613, F1 Micro: 0.8646, F1 Macro: 0.7360, Accuracy: 0.8646\n","Epoch 102, Train Loss: 3.2055, Val Loss: 1.3288, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 103, Train Loss: 1.5322, Val Loss: 3.2462, F1 Micro: 0.7917, F1 Macro: 0.7141, Accuracy: 0.7917\n","Epoch 104, Train Loss: 5.9797, Val Loss: 17.1903, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 105, Train Loss: 6.9145, Val Loss: 2.0164, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 106, Train Loss: 1.6773, Val Loss: 2.5858, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 107, Train Loss: 1.8446, Val Loss: 0.7150, F1 Micro: 0.9167, F1 Macro: 0.8095, Accuracy: 0.9167\n","Epoch 108, Train Loss: 4.9162, Val Loss: 7.1615, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 109, Train Loss: 3.7983, Val Loss: 0.6209, F1 Micro: 0.9271, F1 Macro: 0.8390, Accuracy: 0.9271\n","Epoch 110, Train Loss: 1.6154, Val Loss: 3.4068, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 111, Train Loss: 2.3970, Val Loss: 7.1385, F1 Micro: 0.7917, F1 Macro: 0.5819, Accuracy: 0.7917\n","Epoch 112, Train Loss: 5.1995, Val Loss: 1.3044, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 113, Train Loss: 6.3280, Val Loss: 4.6765, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 114, Train Loss: 5.2684, Val Loss: 7.9260, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 115, Train Loss: 7.8472, Val Loss: 5.1769, F1 Micro: 0.7396, F1 Macro: 0.6478, Accuracy: 0.7396\n","Epoch 116, Train Loss: 9.6802, Val Loss: 6.6212, F1 Micro: 0.7188, F1 Macro: 0.6301, Accuracy: 0.7188\n","Epoch 117, Train Loss: 5.9725, Val Loss: 17.1947, F1 Micro: 0.5625, F1 Macro: 0.5279, Accuracy: 0.5625\n","Epoch 118, Train Loss: 13.7920, Val Loss: 1.5560, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 119, Train Loss: 2.0410, Val Loss: 1.7674, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 120, Train Loss: 3.0332, Val Loss: 10.3242, F1 Micro: 0.6250, F1 Macro: 0.5844, Accuracy: 0.6250\n","Epoch 121, Train Loss: 5.0799, Val Loss: 3.9653, F1 Micro: 0.7396, F1 Macro: 0.6123, Accuracy: 0.7396\n","Epoch 122, Train Loss: 3.1575, Val Loss: 1.4404, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 123, Train Loss: 2.6346, Val Loss: 1.5561, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 124, Train Loss: 2.3319, Val Loss: 0.6384, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 125, Train Loss: 2.0785, Val Loss: 0.7202, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 126, Train Loss: 1.8667, Val Loss: 1.3355, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 127, Train Loss: 2.5006, Val Loss: 1.7494, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 128, Train Loss: 2.2991, Val Loss: 2.6831, F1 Micro: 0.7708, F1 Macro: 0.6944, Accuracy: 0.7708\n","Epoch 129, Train Loss: 4.8978, Val Loss: 1.3805, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 130, Train Loss: 2.0068, Val Loss: 1.0001, F1 Micro: 0.8750, F1 Macro: 0.7949, Accuracy: 0.8750\n","Epoch 131, Train Loss: 1.8638, Val Loss: 7.6581, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 132, Train Loss: 3.2216, Val Loss: 10.9133, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 133, Train Loss: 4.0843, Val Loss: 1.6091, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 134, Train Loss: 0.9880, Val Loss: 0.9367, F1 Micro: 0.9167, F1 Macro: 0.8570, Accuracy: 0.9167\n","Epoch 135, Train Loss: 1.6525, Val Loss: 1.0552, F1 Micro: 0.8958, F1 Macro: 0.8125, Accuracy: 0.8958\n","Epoch 136, Train Loss: 2.2390, Val Loss: 2.1924, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 137, Train Loss: 1.0032, Val Loss: 6.1872, F1 Micro: 0.7708, F1 Macro: 0.6069, Accuracy: 0.7708\n","Epoch 138, Train Loss: 4.7216, Val Loss: 0.8300, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 139, Train Loss: 4.5679, Val Loss: 3.4743, F1 Micro: 0.8333, F1 Macro: 0.7000, Accuracy: 0.8333\n","Epoch 140, Train Loss: 6.2996, Val Loss: 5.7310, F1 Micro: 0.7500, F1 Macro: 0.6755, Accuracy: 0.7500\n","Epoch 141, Train Loss: 4.7256, Val Loss: 0.6855, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 142, Train Loss: 1.7156, Val Loss: 1.6190, F1 Micro: 0.8750, F1 Macro: 0.8031, Accuracy: 0.8750\n","Epoch 143, Train Loss: 8.6082, Val Loss: 5.6355, F1 Micro: 0.7812, F1 Macro: 0.6744, Accuracy: 0.7812\n","Epoch 144, Train Loss: 11.5879, Val Loss: 6.2997, F1 Micro: 0.8229, F1 Macro: 0.6890, Accuracy: 0.8229\n","Epoch 145, Train Loss: 4.6966, Val Loss: 0.6774, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 146, Train Loss: 1.9226, Val Loss: 0.8955, F1 Micro: 0.9375, F1 Macro: 0.8875, Accuracy: 0.9375\n","Epoch 147, Train Loss: 1.9075, Val Loss: 1.1350, F1 Micro: 0.8542, F1 Macro: 0.7703, Accuracy: 0.8542\n","Epoch 148, Train Loss: 1.6310, Val Loss: 0.9903, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 149, Train Loss: 10.8405, Val Loss: 201.5799, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 150, Train Loss: 44.7538, Val Loss: 119.5717, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.9479166666666667\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 962.8398, Val Loss: 374.8302, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 409.6646, Val Loss: 111.8452, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 3, Train Loss: 126.8744, Val Loss: 264.1992, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 135.6016, Val Loss: 90.9063, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 55.4865, Val Loss: 55.9663, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 6, Train Loss: 65.6456, Val Loss: 80.1068, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 7, Train Loss: 52.3405, Val Loss: 15.8045, F1 Micro: 0.5938, F1 Macro: 0.5315, Accuracy: 0.5938\n","Epoch 8, Train Loss: 55.4549, Val Loss: 189.7508, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 9, Train Loss: 81.6179, Val Loss: 222.6710, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 103.2369, Val Loss: 33.7859, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 11, Train Loss: 37.9760, Val Loss: 48.4762, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 548.7238, Val Loss: 625.6367, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 2, Train Loss: 327.7981, Val Loss: 136.3991, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 106.3841, Val Loss: 77.7608, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 4, Train Loss: 65.2081, Val Loss: 18.8543, F1 Micro: 0.6250, F1 Macro: 0.4514, Accuracy: 0.6250\n","Epoch 5, Train Loss: 107.4378, Val Loss: 156.7882, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 6, Train Loss: 45.9292, Val Loss: 59.1267, F1 Micro: 0.2917, F1 Macro: 0.2914, Accuracy: 0.2917\n","Epoch 7, Train Loss: 63.6249, Val Loss: 63.4949, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 8, Train Loss: 50.3964, Val Loss: 57.4786, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 9, Train Loss: 104.0667, Val Loss: 162.1839, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 10, Train Loss: 117.5951, Val Loss: 220.6952, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 11, Train Loss: 61.7468, Val Loss: 34.6926, F1 Micro: 0.6979, F1 Macro: 0.4110, Accuracy: 0.6979\n","Epoch 12, Train Loss: 76.3526, Val Loss: 25.9186, F1 Micro: 0.6667, F1 Macro: 0.4281, Accuracy: 0.6667\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 299.3899, Val Loss: 54.7848, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 125.9322, Val Loss: 17.7160, F1 Micro: 0.6562, F1 Macro: 0.5700, Accuracy: 0.6562\n","Epoch 3, Train Loss: 51.0741, Val Loss: 20.4109, F1 Micro: 0.4896, F1 Macro: 0.4525, Accuracy: 0.4896\n","Epoch 4, Train Loss: 244.1416, Val Loss: 452.1505, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 5, Train Loss: 314.8415, Val Loss: 60.5092, F1 Micro: 0.3333, F1 Macro: 0.3287, Accuracy: 0.3333\n","Epoch 6, Train Loss: 128.4248, Val Loss: 197.3292, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 7, Train Loss: 162.6108, Val Loss: 45.3678, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 8, Train Loss: 118.4237, Val Loss: 145.7047, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 9, Train Loss: 73.3112, Val Loss: 86.4319, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 10, Train Loss: 75.6803, Val Loss: 39.0332, F1 Micro: 0.3958, F1 Macro: 0.3827, Accuracy: 0.3958\n","Epoch 11, Train Loss: 51.2993, Val Loss: 34.3936, F1 Micro: 0.3333, F1 Macro: 0.3287, Accuracy: 0.3333\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 528.8159, Val Loss: 196.2181, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 2, Train Loss: 205.1597, Val Loss: 170.5208, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 98.4745, Val Loss: 50.8725, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 4, Train Loss: 111.8801, Val Loss: 36.7064, F1 Micro: 0.4062, F1 Macro: 0.3631, Accuracy: 0.4062\n","Epoch 5, Train Loss: 161.6057, Val Loss: 221.5474, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 78.7324, Val Loss: 89.2811, F1 Micro: 0.1875, F1 Macro: 0.1861, Accuracy: 0.1875\n","Epoch 7, Train Loss: 94.2898, Val Loss: 207.5146, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 8, Train Loss: 105.3485, Val Loss: 37.6477, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 9, Train Loss: 62.1596, Val Loss: 59.5525, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 10, Train Loss: 90.8876, Val Loss: 55.7029, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 11, Train Loss: 58.0406, Val Loss: 114.5831, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1151.2309, Val Loss: 1072.9443, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 310.4003, Val Loss: 167.9093, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 3, Train Loss: 125.9277, Val Loss: 148.4588, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 119.6189, Val Loss: 340.1773, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 77.6580, Val Loss: 50.1404, F1 Micro: 0.2812, F1 Macro: 0.2805, Accuracy: 0.2812\n","Epoch 6, Train Loss: 119.9149, Val Loss: 57.4126, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 7, Train Loss: 85.8546, Val Loss: 77.3491, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 8, Train Loss: 44.6157, Val Loss: 116.2878, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 9, Train Loss: 54.5151, Val Loss: 23.9224, F1 Micro: 0.3958, F1 Macro: 0.3827, Accuracy: 0.3958\n","Epoch 10, Train Loss: 78.3620, Val Loss: 270.5495, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 11, Train Loss: 217.1357, Val Loss: 251.5174, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.8541666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 838.2790, Val Loss: 1383.3492, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 507.0626, Val Loss: 225.6165, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 234.6661, Val Loss: 49.7287, F1 Micro: 0.2396, F1 Macro: 0.2254, Accuracy: 0.2396\n","Epoch 4, Train Loss: 46.2343, Val Loss: 14.1768, F1 Micro: 0.7500, F1 Macro: 0.6063, Accuracy: 0.7500\n","Epoch 5, Train Loss: 60.9840, Val Loss: 150.0048, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 189.3399, Val Loss: 154.3016, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 38.8661, Val Loss: 148.6856, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 30.6920, Val Loss: 11.1934, F1 Micro: 0.4792, F1 Macro: 0.4643, Accuracy: 0.4792\n","Epoch 9, Train Loss: 37.3863, Val Loss: 92.7620, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 109.9213, Val Loss: 265.9454, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 11, Train Loss: 112.3733, Val Loss: 43.5043, F1 Micro: 0.2917, F1 Macro: 0.2889, Accuracy: 0.2917\n","Epoch 12, Train Loss: 49.8538, Val Loss: 97.0722, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 63.5424, Val Loss: 14.0685, F1 Micro: 0.6667, F1 Macro: 0.5878, Accuracy: 0.6667\n","Epoch 14, Train Loss: 49.7844, Val Loss: 45.5486, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 15, Train Loss: 29.9417, Val Loss: 135.2978, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 16, Train Loss: 36.5389, Val Loss: 102.6768, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 17, Train Loss: 45.1685, Val Loss: 11.2491, F1 Micro: 0.5729, F1 Macro: 0.5157, Accuracy: 0.5729\n","Epoch 18, Train Loss: 21.1264, Val Loss: 83.1525, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 19, Train Loss: 19.4605, Val Loss: 51.3404, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 20, Train Loss: 43.6176, Val Loss: 19.4836, F1 Micro: 0.7500, F1 Macro: 0.6063, Accuracy: 0.7500\n","Epoch 21, Train Loss: 14.4280, Val Loss: 48.5602, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 22, Train Loss: 22.4839, Val Loss: 42.4530, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 23, Train Loss: 34.3679, Val Loss: 9.8960, F1 Micro: 0.6667, F1 Macro: 0.5878, Accuracy: 0.6667\n","Epoch 24, Train Loss: 28.1445, Val Loss: 105.1457, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 25, Train Loss: 40.1057, Val Loss: 23.6334, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 26, Train Loss: 47.3562, Val Loss: 31.1565, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 27, Train Loss: 35.8976, Val Loss: 27.4999, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 28, Train Loss: 46.9659, Val Loss: 23.6586, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 29, Train Loss: 12.2972, Val Loss: 24.7869, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 30, Train Loss: 19.2074, Val Loss: 12.3309, F1 Micro: 0.8333, F1 Macro: 0.5893, Accuracy: 0.8333\n","Epoch 31, Train Loss: 20.4223, Val Loss: 9.3834, F1 Micro: 0.5938, F1 Macro: 0.5315, Accuracy: 0.5938\n","Epoch 32, Train Loss: 15.4534, Val Loss: 40.7662, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 33, Train Loss: 16.1449, Val Loss: 25.1602, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 34, Train Loss: 8.2967, Val Loss: 7.2930, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 35, Train Loss: 11.2639, Val Loss: 15.1809, F1 Micro: 0.2396, F1 Macro: 0.2254, Accuracy: 0.2396\n","Epoch 36, Train Loss: 18.4814, Val Loss: 17.9620, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 37, Train Loss: 13.9398, Val Loss: 21.3354, F1 Micro: 0.8229, F1 Macro: 0.6091, Accuracy: 0.8229\n","Epoch 38, Train Loss: 12.3610, Val Loss: 21.7594, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 39, Train Loss: 10.9665, Val Loss: 32.6615, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 40, Train Loss: 34.0858, Val Loss: 10.0870, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 41, Train Loss: 22.4824, Val Loss: 29.2513, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 42, Train Loss: 15.6226, Val Loss: 7.7908, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 43, Train Loss: 9.8845, Val Loss: 8.9097, F1 Micro: 0.4583, F1 Macro: 0.4524, Accuracy: 0.4583\n","Epoch 44, Train Loss: 11.5743, Val Loss: 3.5044, F1 Micro: 0.6875, F1 Macro: 0.6294, Accuracy: 0.6875\n","Epoch 45, Train Loss: 12.1765, Val Loss: 2.3994, F1 Micro: 0.8750, F1 Macro: 0.7491, Accuracy: 0.8750\n","Epoch 46, Train Loss: 10.7331, Val Loss: 1.3657, F1 Micro: 0.7396, F1 Macro: 0.6942, Accuracy: 0.7396\n","Epoch 47, Train Loss: 4.2793, Val Loss: 8.3845, F1 Micro: 0.6667, F1 Macro: 0.5283, Accuracy: 0.6667\n","Epoch 48, Train Loss: 11.8471, Val Loss: 11.6230, F1 Micro: 0.3646, F1 Macro: 0.3645, Accuracy: 0.3646\n","Epoch 49, Train Loss: 10.1320, Val Loss: 14.5280, F1 Micro: 0.5208, F1 Macro: 0.5071, Accuracy: 0.5208\n","Epoch 50, Train Loss: 12.4920, Val Loss: 0.3048, F1 Micro: 0.9167, F1 Macro: 0.8688, Accuracy: 0.9167\n","Epoch 51, Train Loss: 4.4280, Val Loss: 2.2130, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 52, Train Loss: 4.5464, Val Loss: 4.2767, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 53, Train Loss: 5.9054, Val Loss: 3.4869, F1 Micro: 0.5729, F1 Macro: 0.5515, Accuracy: 0.5729\n","Epoch 54, Train Loss: 6.9303, Val Loss: 33.7708, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 55, Train Loss: 16.2565, Val Loss: 7.8474, F1 Micro: 0.5417, F1 Macro: 0.5250, Accuracy: 0.5417\n","Epoch 56, Train Loss: 3.7045, Val Loss: 6.7096, F1 Micro: 0.5833, F1 Macro: 0.4847, Accuracy: 0.5833\n","Epoch 57, Train Loss: 5.7069, Val Loss: 8.2664, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 58, Train Loss: 3.7569, Val Loss: 1.5920, F1 Micro: 0.8125, F1 Macro: 0.7626, Accuracy: 0.8125\n","Epoch 59, Train Loss: 2.3647, Val Loss: 3.5935, F1 Micro: 0.6667, F1 Macro: 0.6306, Accuracy: 0.6667\n","Epoch 60, Train Loss: 3.1564, Val Loss: 0.6090, F1 Micro: 0.8854, F1 Macro: 0.7630, Accuracy: 0.8854\n","Epoch 61, Train Loss: 1.8795, Val Loss: 0.6555, F1 Micro: 0.8438, F1 Macro: 0.5990, Accuracy: 0.8438\n","Epoch 62, Train Loss: 2.8151, Val Loss: 3.2520, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 63, Train Loss: 1.9017, Val Loss: 2.5830, F1 Micro: 0.6562, F1 Macro: 0.6217, Accuracy: 0.6562\n","Epoch 64, Train Loss: 4.3350, Val Loss: 11.1311, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 65, Train Loss: 8.0008, Val Loss: 1.3642, F1 Micro: 0.8438, F1 Macro: 0.7674, Accuracy: 0.8438\n","Epoch 66, Train Loss: 4.1974, Val Loss: 6.6556, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 67, Train Loss: 4.1712, Val Loss: 4.3504, F1 Micro: 0.8021, F1 Macro: 0.7054, Accuracy: 0.8021\n","Epoch 68, Train Loss: 5.2349, Val Loss: 7.1043, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 69, Train Loss: 3.1245, Val Loss: 2.8593, F1 Micro: 0.8646, F1 Macro: 0.7011, Accuracy: 0.8646\n","Epoch 70, Train Loss: 2.1292, Val Loss: 2.2537, F1 Micro: 0.6875, F1 Macro: 0.6427, Accuracy: 0.6875\n","Epoch 71, Train Loss: 2.5202, Val Loss: 11.1456, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 72, Train Loss: 6.3674, Val Loss: 0.7849, F1 Micro: 0.8646, F1 Macro: 0.6789, Accuracy: 0.8646\n","Epoch 73, Train Loss: 2.4250, Val Loss: 1.6448, F1 Micro: 0.7812, F1 Macro: 0.7324, Accuracy: 0.7812\n","Epoch 74, Train Loss: 1.4169, Val Loss: 0.4248, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 75, Train Loss: 2.2920, Val Loss: 1.4139, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 76, Train Loss: 1.8345, Val Loss: 19.0069, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 77, Train Loss: 6.3393, Val Loss: 1.7148, F1 Micro: 0.8542, F1 Macro: 0.7607, Accuracy: 0.8542\n","Epoch 78, Train Loss: 1.8294, Val Loss: 1.3777, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 79, Train Loss: 1.1304, Val Loss: 0.6221, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 80, Train Loss: 1.2523, Val Loss: 1.1510, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 81, Train Loss: 2.0196, Val Loss: 2.7070, F1 Micro: 0.7604, F1 Macro: 0.7131, Accuracy: 0.7604\n","Epoch 82, Train Loss: 3.4995, Val Loss: 11.6140, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 83, Train Loss: 4.2492, Val Loss: 6.1087, F1 Micro: 0.8229, F1 Macro: 0.7154, Accuracy: 0.8229\n","Epoch 84, Train Loss: 2.3734, Val Loss: 1.1769, F1 Micro: 0.8542, F1 Macro: 0.7867, Accuracy: 0.8542\n","Epoch 85, Train Loss: 1.5145, Val Loss: 1.4299, F1 Micro: 0.8125, F1 Macro: 0.7626, Accuracy: 0.8125\n","Epoch 86, Train Loss: 1.8123, Val Loss: 3.6413, F1 Micro: 0.8438, F1 Macro: 0.5990, Accuracy: 0.8438\n","Epoch 87, Train Loss: 3.3896, Val Loss: 2.2015, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 88, Train Loss: 4.0264, Val Loss: 34.8034, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 89, Train Loss: 14.7147, Val Loss: 9.8581, F1 Micro: 0.6042, F1 Macro: 0.5613, Accuracy: 0.6042\n","Epoch 90, Train Loss: 4.3494, Val Loss: 2.3640, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 91, Train Loss: 2.0307, Val Loss: 1.6972, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 92, Train Loss: 4.2974, Val Loss: 0.8696, F1 Micro: 0.8750, F1 Macro: 0.8285, Accuracy: 0.8750\n","Epoch 93, Train Loss: 2.5845, Val Loss: 1.1788, F1 Micro: 0.8542, F1 Macro: 0.7999, Accuracy: 0.8542\n","Epoch 94, Train Loss: 1.3292, Val Loss: 3.2473, F1 Micro: 0.7500, F1 Macro: 0.6063, Accuracy: 0.7500\n","Epoch 95, Train Loss: 1.4067, Val Loss: 1.4958, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 96, Train Loss: 1.6022, Val Loss: 0.7765, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 97, Train Loss: 0.8600, Val Loss: 0.6180, F1 Micro: 0.8646, F1 Macro: 0.8113, Accuracy: 0.8646\n","Epoch 98, Train Loss: 0.9907, Val Loss: 0.5407, F1 Micro: 0.9062, F1 Macro: 0.8552, Accuracy: 0.9062\n","Epoch 99, Train Loss: 1.2229, Val Loss: 2.1836, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 100, Train Loss: 2.4884, Val Loss: 2.3552, F1 Micro: 0.7292, F1 Macro: 0.6903, Accuracy: 0.7292\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 580.7740, Val Loss: 122.8391, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 122.7474, Val Loss: 88.5221, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 180.3456, Val Loss: 442.5065, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 4, Train Loss: 175.2609, Val Loss: 204.2272, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 81.4310, Val Loss: 33.7257, F1 Micro: 0.7292, F1 Macro: 0.4217, Accuracy: 0.7292\n","Epoch 6, Train Loss: 68.9113, Val Loss: 132.8297, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 7, Train Loss: 96.6662, Val Loss: 122.3144, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 8, Train Loss: 100.1488, Val Loss: 55.1144, F1 Micro: 0.7500, F1 Macro: 0.4286, Accuracy: 0.7500\n","Epoch 9, Train Loss: 95.8726, Val Loss: 131.1098, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 10, Train Loss: 65.1600, Val Loss: 136.6800, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 11, Train Loss: 55.6269, Val Loss: 76.4180, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 12, Train Loss: 81.6515, Val Loss: 30.7481, F1 Micro: 0.7292, F1 Macro: 0.4217, Accuracy: 0.7292\n","Epoch 13, Train Loss: 39.4197, Val Loss: 45.4189, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 14, Train Loss: 115.9935, Val Loss: 22.3263, F1 Micro: 0.6042, F1 Macro: 0.4722, Accuracy: 0.6042\n","Epoch 15, Train Loss: 102.0418, Val Loss: 26.9787, F1 Micro: 0.5833, F1 Macro: 0.5152, Accuracy: 0.5833\n","Epoch 16, Train Loss: 55.6862, Val Loss: 39.9060, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 17, Train Loss: 23.4397, Val Loss: 17.5671, F1 Micro: 0.4688, F1 Macro: 0.4421, Accuracy: 0.4688\n","Epoch 18, Train Loss: 80.7955, Val Loss: 136.5067, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 19, Train Loss: 85.2518, Val Loss: 34.9322, F1 Micro: 0.7188, F1 Macro: 0.4182, Accuracy: 0.7188\n","Epoch 20, Train Loss: 51.1744, Val Loss: 132.4338, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 21, Train Loss: 55.0137, Val Loss: 55.1429, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 22, Train Loss: 33.6032, Val Loss: 17.6157, F1 Micro: 0.7708, F1 Macro: 0.4353, Accuracy: 0.7708\n","Epoch 23, Train Loss: 17.4674, Val Loss: 15.2394, F1 Micro: 0.5000, F1 Macro: 0.4667, Accuracy: 0.5000\n","Epoch 24, Train Loss: 57.9879, Val Loss: 54.7212, F1 Micro: 0.3333, F1 Macro: 0.3307, Accuracy: 0.3333\n","Epoch 25, Train Loss: 35.0566, Val Loss: 43.7384, F1 Micro: 0.1979, F1 Macro: 0.1936, Accuracy: 0.1979\n","Epoch 26, Train Loss: 23.4767, Val Loss: 24.6898, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 27, Train Loss: 52.7060, Val Loss: 17.3168, F1 Micro: 0.6146, F1 Macro: 0.4931, Accuracy: 0.6146\n","Epoch 28, Train Loss: 56.0020, Val Loss: 59.1587, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 29, Train Loss: 71.9696, Val Loss: 48.3812, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 30, Train Loss: 41.0387, Val Loss: 25.1092, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 31, Train Loss: 20.0143, Val Loss: 18.3059, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 32, Train Loss: 40.5396, Val Loss: 12.7104, F1 Micro: 0.7292, F1 Macro: 0.4564, Accuracy: 0.7292\n","Epoch 33, Train Loss: 25.1494, Val Loss: 23.5624, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 34, Train Loss: 13.6238, Val Loss: 16.7432, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 35, Train Loss: 25.2213, Val Loss: 64.3058, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 36, Train Loss: 31.0396, Val Loss: 18.6836, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 37, Train Loss: 11.7291, Val Loss: 18.3184, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 38, Train Loss: 10.1084, Val Loss: 2.5031, F1 Micro: 0.7292, F1 Macro: 0.6485, Accuracy: 0.7292\n","Epoch 39, Train Loss: 22.5172, Val Loss: 51.0271, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 40, Train Loss: 20.1550, Val Loss: 7.8451, F1 Micro: 0.7292, F1 Macro: 0.4864, Accuracy: 0.7292\n","Epoch 41, Train Loss: 6.1051, Val Loss: 16.5804, F1 Micro: 0.3646, F1 Macro: 0.3589, Accuracy: 0.3646\n","Epoch 42, Train Loss: 11.8051, Val Loss: 6.3396, F1 Micro: 0.6458, F1 Macro: 0.5800, Accuracy: 0.6458\n","Epoch 43, Train Loss: 9.4490, Val Loss: 33.2818, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 44, Train Loss: 23.3396, Val Loss: 10.2095, F1 Micro: 0.5104, F1 Macro: 0.4806, Accuracy: 0.5104\n","Epoch 45, Train Loss: 7.4178, Val Loss: 12.2802, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 46, Train Loss: 3.3148, Val Loss: 1.0731, F1 Micro: 0.8854, F1 Macro: 0.7283, Accuracy: 0.8854\n","Epoch 47, Train Loss: 1.4701, Val Loss: 5.4524, F1 Micro: 0.4167, F1 Macro: 0.4040, Accuracy: 0.4167\n","Epoch 48, Train Loss: 5.5031, Val Loss: 6.4292, F1 Micro: 0.6354, F1 Macro: 0.5541, Accuracy: 0.6354\n","Epoch 49, Train Loss: 4.4955, Val Loss: 10.2282, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 50, Train Loss: 3.6864, Val Loss: 1.5205, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 51, Train Loss: 5.5112, Val Loss: 13.8157, F1 Micro: 0.3229, F1 Macro: 0.3211, Accuracy: 0.3229\n","Epoch 52, Train Loss: 10.9457, Val Loss: 3.1305, F1 Micro: 0.7604, F1 Macro: 0.6554, Accuracy: 0.7604\n","Epoch 53, Train Loss: 4.0376, Val Loss: 1.7043, F1 Micro: 0.8021, F1 Macro: 0.7243, Accuracy: 0.8021\n","Epoch 54, Train Loss: 4.5429, Val Loss: 4.1958, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 55, Train Loss: 2.5305, Val Loss: 2.5952, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 56, Train Loss: 4.4408, Val Loss: 9.0005, F1 Micro: 0.5312, F1 Macro: 0.4971, Accuracy: 0.5312\n","Epoch 57, Train Loss: 11.2204, Val Loss: 16.1534, F1 Micro: 0.7292, F1 Macro: 0.4564, Accuracy: 0.7292\n","Epoch 58, Train Loss: 10.0579, Val Loss: 11.3898, F1 Micro: 0.3333, F1 Macro: 0.3307, Accuracy: 0.3333\n","Epoch 59, Train Loss: 6.8696, Val Loss: 3.9117, F1 Micro: 0.5729, F1 Macro: 0.5300, Accuracy: 0.5729\n","Epoch 60, Train Loss: 2.0942, Val Loss: 2.7084, F1 Micro: 0.6979, F1 Macro: 0.6305, Accuracy: 0.6979\n","Epoch 61, Train Loss: 2.0443, Val Loss: 6.7058, F1 Micro: 0.4271, F1 Macro: 0.4127, Accuracy: 0.4271\n","Epoch 62, Train Loss: 4.2565, Val Loss: 7.1678, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 63, Train Loss: 8.9491, Val Loss: 6.3759, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 64, Train Loss: 5.4731, Val Loss: 2.5225, F1 Micro: 0.7917, F1 Macro: 0.7052, Accuracy: 0.7917\n","Epoch 65, Train Loss: 9.7038, Val Loss: 3.1503, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 66, Train Loss: 1.4168, Val Loss: 1.3017, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 67, Train Loss: 6.9545, Val Loss: 7.5678, F1 Micro: 0.7708, F1 Macro: 0.5875, Accuracy: 0.7708\n","Epoch 68, Train Loss: 10.6872, Val Loss: 9.3476, F1 Micro: 0.5625, F1 Macro: 0.5218, Accuracy: 0.5625\n","Epoch 69, Train Loss: 5.6633, Val Loss: 9.4893, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 70, Train Loss: 1.1522, Val Loss: 2.2273, F1 Micro: 0.7812, F1 Macro: 0.7042, Accuracy: 0.7812\n","Epoch 71, Train Loss: 2.4149, Val Loss: 2.5819, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 72, Train Loss: 5.2420, Val Loss: 6.7368, F1 Micro: 0.6562, F1 Macro: 0.5883, Accuracy: 0.6562\n","Epoch 73, Train Loss: 3.9373, Val Loss: 1.2670, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 74, Train Loss: 2.5303, Val Loss: 3.4063, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 75, Train Loss: 1.9262, Val Loss: 1.5481, F1 Micro: 0.8750, F1 Macro: 0.7143, Accuracy: 0.8750\n","Epoch 76, Train Loss: 2.4555, Val Loss: 1.4165, F1 Micro: 0.9167, F1 Macro: 0.8570, Accuracy: 0.9167\n","Epoch 77, Train Loss: 1.3325, Val Loss: 2.0121, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 78, Train Loss: 2.2556, Val Loss: 0.5035, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 79, Train Loss: 2.0475, Val Loss: 1.8787, F1 Micro: 0.8021, F1 Macro: 0.7153, Accuracy: 0.8021\n","Epoch 80, Train Loss: 1.8453, Val Loss: 0.6318, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 81, Train Loss: 0.6159, Val Loss: 0.6713, F1 Micro: 0.8854, F1 Macro: 0.7471, Accuracy: 0.8854\n","Epoch 82, Train Loss: 0.7111, Val Loss: 1.7683, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 83, Train Loss: 1.4897, Val Loss: 2.1353, F1 Micro: 0.8333, F1 Macro: 0.7141, Accuracy: 0.8333\n","Epoch 84, Train Loss: 3.5602, Val Loss: 0.9798, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 85, Train Loss: 3.2621, Val Loss: 5.0089, F1 Micro: 0.5729, F1 Macro: 0.5300, Accuracy: 0.5729\n","Epoch 86, Train Loss: 2.4249, Val Loss: 1.7295, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 87, Train Loss: 1.2751, Val Loss: 0.7410, F1 Micro: 0.8854, F1 Macro: 0.7884, Accuracy: 0.8854\n","Epoch 88, Train Loss: 1.0663, Val Loss: 0.6287, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 89, Train Loss: 1.0997, Val Loss: 0.5321, F1 Micro: 0.8646, F1 Macro: 0.6789, Accuracy: 0.8646\n","Epoch 90, Train Loss: 1.9810, Val Loss: 1.6389, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 91, Train Loss: 1.6758, Val Loss: 4.7698, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 92, Train Loss: 1.3600, Val Loss: 1.4785, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 93, Train Loss: 0.5019, Val Loss: 0.5559, F1 Micro: 0.8750, F1 Macro: 0.7143, Accuracy: 0.8750\n","Epoch 94, Train Loss: 0.7811, Val Loss: 2.5924, F1 Micro: 0.7604, F1 Macro: 0.6849, Accuracy: 0.7604\n","Epoch 95, Train Loss: 0.6088, Val Loss: 1.1106, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 96, Train Loss: 1.4474, Val Loss: 2.0984, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 97, Train Loss: 2.2535, Val Loss: 1.1312, F1 Micro: 0.8646, F1 Macro: 0.5805, Accuracy: 0.8646\n","Epoch 98, Train Loss: 2.0935, Val Loss: 5.6462, F1 Micro: 0.7917, F1 Macro: 0.6049, Accuracy: 0.7917\n","Epoch 99, Train Loss: 2.7074, Val Loss: 2.8205, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 100, Train Loss: 1.3457, Val Loss: 1.3145, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 101, Train Loss: 2.0634, Val Loss: 2.4108, F1 Micro: 0.7917, F1 Macro: 0.7141, Accuracy: 0.7917\n","Epoch 102, Train Loss: 1.4013, Val Loss: 1.7283, F1 Micro: 0.8021, F1 Macro: 0.5307, Accuracy: 0.8021\n","Epoch 103, Train Loss: 1.3909, Val Loss: 2.0768, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 104, Train Loss: 0.9702, Val Loss: 1.3087, F1 Micro: 0.8958, F1 Macro: 0.7909, Accuracy: 0.8958\n","Epoch 105, Train Loss: 0.9243, Val Loss: 0.5086, F1 Micro: 0.9062, F1 Macro: 0.7931, Accuracy: 0.9062\n","Epoch 106, Train Loss: 0.8831, Val Loss: 1.8423, F1 Micro: 0.8438, F1 Macro: 0.7674, Accuracy: 0.8438\n","Epoch 107, Train Loss: 1.3459, Val Loss: 0.5490, F1 Micro: 0.9062, F1 Macro: 0.8061, Accuracy: 0.9062\n","Epoch 108, Train Loss: 0.7662, Val Loss: 1.4171, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 109, Train Loss: 0.8309, Val Loss: 1.0906, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 110, Train Loss: 0.8042, Val Loss: 0.9184, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 111, Train Loss: 0.9271, Val Loss: 1.1651, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 112, Train Loss: 1.7324, Val Loss: 3.9822, F1 Micro: 0.7812, F1 Macro: 0.6744, Accuracy: 0.7812\n","Epoch 113, Train Loss: 2.3941, Val Loss: 2.0371, F1 Micro: 0.8229, F1 Macro: 0.7453, Accuracy: 0.8229\n","Epoch 114, Train Loss: 1.2112, Val Loss: 4.2694, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 115, Train Loss: 2.0765, Val Loss: 2.6038, F1 Micro: 0.8021, F1 Macro: 0.7243, Accuracy: 0.8021\n","Epoch 116, Train Loss: 3.2412, Val Loss: 7.2813, F1 Micro: 0.5938, F1 Macro: 0.5465, Accuracy: 0.5938\n","Epoch 117, Train Loss: 2.9371, Val Loss: 0.5626, F1 Micro: 0.9167, F1 Macro: 0.8221, Accuracy: 0.9167\n","Epoch 118, Train Loss: 0.9553, Val Loss: 0.6989, F1 Micro: 0.8958, F1 Macro: 0.7619, Accuracy: 0.8958\n","Epoch 119, Train Loss: 0.6334, Val Loss: 1.2833, F1 Micro: 0.8542, F1 Macro: 0.7703, Accuracy: 0.8542\n","Epoch 120, Train Loss: 1.4209, Val Loss: 0.6532, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 121, Train Loss: 0.8179, Val Loss: 1.1203, F1 Micro: 0.9271, F1 Macro: 0.8654, Accuracy: 0.9271\n","Epoch 122, Train Loss: 2.5319, Val Loss: 0.6578, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 123, Train Loss: 0.9378, Val Loss: 2.2198, F1 Micro: 0.7604, F1 Macro: 0.5982, Accuracy: 0.7604\n","Epoch 124, Train Loss: 0.8307, Val Loss: 0.9008, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 125, Train Loss: 0.6922, Val Loss: 0.9114, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 126, Train Loss: 1.0349, Val Loss: 0.7158, F1 Micro: 0.8854, F1 Macro: 0.7630, Accuracy: 0.8854\n","Epoch 127, Train Loss: 0.4595, Val Loss: 1.6362, F1 Micro: 0.8125, F1 Macro: 0.5380, Accuracy: 0.8125\n","Epoch 128, Train Loss: 0.6941, Val Loss: 0.9410, F1 Micro: 0.8646, F1 Macro: 0.7499, Accuracy: 0.8646\n","Epoch 129, Train Loss: 1.1782, Val Loss: 1.7676, F1 Micro: 0.8229, F1 Macro: 0.7265, Accuracy: 0.8229\n","Epoch 130, Train Loss: 2.6430, Val Loss: 0.6673, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 131, Train Loss: 2.7315, Val Loss: 9.2359, F1 Micro: 0.7708, F1 Macro: 0.5875, Accuracy: 0.7708\n","Epoch 132, Train Loss: 3.5404, Val Loss: 0.7860, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 133, Train Loss: 2.3251, Val Loss: 4.7004, F1 Micro: 0.8229, F1 Macro: 0.6337, Accuracy: 0.8229\n","Epoch 134, Train Loss: 1.5248, Val Loss: 0.6558, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 135, Train Loss: 0.9037, Val Loss: 1.0909, F1 Micro: 0.8646, F1 Macro: 0.7621, Accuracy: 0.8646\n","Epoch 136, Train Loss: 1.3789, Val Loss: 0.9553, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 137, Train Loss: 0.7996, Val Loss: 0.6209, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 138, Train Loss: 1.1526, Val Loss: 1.1357, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 139, Train Loss: 0.5581, Val Loss: 0.7074, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 140, Train Loss: 2.1591, Val Loss: 2.2623, F1 Micro: 0.8229, F1 Macro: 0.7453, Accuracy: 0.8229\n","Epoch 141, Train Loss: 10.6533, Val Loss: 15.2767, F1 Micro: 0.6146, F1 Macro: 0.5555, Accuracy: 0.6146\n","Epoch 142, Train Loss: 4.7727, Val Loss: 4.4649, F1 Micro: 0.7708, F1 Macro: 0.6648, Accuracy: 0.7708\n","Epoch 143, Train Loss: 2.5557, Val Loss: 1.5819, F1 Micro: 0.8646, F1 Macro: 0.5805, Accuracy: 0.8646\n","Epoch 144, Train Loss: 1.2163, Val Loss: 1.4408, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 145, Train Loss: 1.2436, Val Loss: 4.5730, F1 Micro: 0.6354, F1 Macro: 0.5795, Accuracy: 0.6354\n","Epoch 146, Train Loss: 1.6586, Val Loss: 2.2135, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 147, Train Loss: 3.2840, Val Loss: 1.4222, F1 Micro: 0.8646, F1 Macro: 0.6203, Accuracy: 0.8646\n","Epoch 148, Train Loss: 2.1745, Val Loss: 1.8349, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 149, Train Loss: 1.1209, Val Loss: 2.3948, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 150, Train Loss: 1.6905, Val Loss: 1.0318, F1 Micro: 0.8854, F1 Macro: 0.7987, Accuracy: 0.8854\n","Epoch 151, Train Loss: 1.1194, Val Loss: 2.6367, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 152, Train Loss: 1.0597, Val Loss: 2.4075, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 153, Train Loss: 2.2554, Val Loss: 2.7854, F1 Micro: 0.8542, F1 Macro: 0.7235, Accuracy: 0.8542\n","Epoch 154, Train Loss: 2.0191, Val Loss: 0.9535, F1 Micro: 0.9062, F1 Macro: 0.8353, Accuracy: 0.9062\n","Epoch 155, Train Loss: 1.2986, Val Loss: 1.0304, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 156, Train Loss: 6.5590, Val Loss: 4.5757, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 157, Train Loss: 3.5327, Val Loss: 0.9066, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 158, Train Loss: 1.7340, Val Loss: 0.9483, F1 Micro: 0.8958, F1 Macro: 0.8213, Accuracy: 0.8958\n","Epoch 159, Train Loss: 3.3176, Val Loss: 3.9726, F1 Micro: 0.7604, F1 Macro: 0.6434, Accuracy: 0.7604\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 299.7377, Val Loss: 237.3375, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 261.2347, Val Loss: 55.5619, F1 Micro: 0.3021, F1 Macro: 0.3002, Accuracy: 0.3021\n","Epoch 3, Train Loss: 215.3689, Val Loss: 44.7463, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 4, Train Loss: 97.9814, Val Loss: 22.9504, F1 Micro: 0.5625, F1 Macro: 0.5078, Accuracy: 0.5625\n","Epoch 5, Train Loss: 73.6110, Val Loss: 46.9338, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 6, Train Loss: 46.9022, Val Loss: 70.0255, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 7, Train Loss: 43.9350, Val Loss: 142.3436, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 8, Train Loss: 261.5520, Val Loss: 51.7897, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 9, Train Loss: 81.4682, Val Loss: 64.0024, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 10, Train Loss: 50.9414, Val Loss: 15.2573, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 11, Train Loss: 216.7261, Val Loss: 63.6439, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 12, Train Loss: 110.2650, Val Loss: 72.6165, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 13, Train Loss: 127.3015, Val Loss: 23.6808, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 14, Train Loss: 40.9112, Val Loss: 8.1259, F1 Micro: 0.7396, F1 Macro: 0.6123, Accuracy: 0.7396\n","Epoch 15, Train Loss: 49.5392, Val Loss: 58.4052, F1 Micro: 0.1354, F1 Macro: 0.1239, Accuracy: 0.1354\n","Epoch 16, Train Loss: 80.4108, Val Loss: 36.0680, F1 Micro: 0.3542, F1 Macro: 0.3471, Accuracy: 0.3542\n","Epoch 17, Train Loss: 39.0768, Val Loss: 12.4186, F1 Micro: 0.6354, F1 Macro: 0.5634, Accuracy: 0.6354\n","Epoch 18, Train Loss: 76.9509, Val Loss: 67.0063, F1 Micro: 0.2604, F1 Macro: 0.2603, Accuracy: 0.2604\n","Epoch 19, Train Loss: 79.2957, Val Loss: 108.8845, F1 Micro: 0.1562, F1 Macro: 0.1488, Accuracy: 0.1562\n","Epoch 20, Train Loss: 30.7787, Val Loss: 13.6337, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 21, Train Loss: 74.1199, Val Loss: 52.0428, F1 Micro: 0.2708, F1 Macro: 0.2705, Accuracy: 0.2708\n","Epoch 22, Train Loss: 26.9769, Val Loss: 16.0105, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 23, Train Loss: 56.7452, Val Loss: 44.2677, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 24, Train Loss: 95.8279, Val Loss: 21.7765, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 25, Train Loss: 22.0447, Val Loss: 28.6842, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 26, Train Loss: 30.1594, Val Loss: 25.3858, F1 Micro: 0.3438, F1 Macro: 0.3379, Accuracy: 0.3438\n","Epoch 27, Train Loss: 15.4543, Val Loss: 57.7126, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 28, Train Loss: 34.6583, Val Loss: 20.9930, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 29, Train Loss: 27.4847, Val Loss: 11.5517, F1 Micro: 0.4062, F1 Macro: 0.3914, Accuracy: 0.4062\n","Epoch 30, Train Loss: 31.0937, Val Loss: 88.2653, F1 Micro: 0.1354, F1 Macro: 0.1239, Accuracy: 0.1354\n","Epoch 31, Train Loss: 25.7556, Val Loss: 3.0765, F1 Micro: 0.7188, F1 Macro: 0.6301, Accuracy: 0.7188\n","Epoch 32, Train Loss: 28.4152, Val Loss: 10.0277, F1 Micro: 0.5729, F1 Macro: 0.5157, Accuracy: 0.5729\n","Epoch 33, Train Loss: 30.9938, Val Loss: 15.8200, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 34, Train Loss: 36.7653, Val Loss: 8.8812, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 35, Train Loss: 19.9002, Val Loss: 26.1938, F1 Micro: 0.1562, F1 Macro: 0.1488, Accuracy: 0.1562\n","Epoch 36, Train Loss: 23.1048, Val Loss: 62.1256, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 37, Train Loss: 25.5785, Val Loss: 7.1462, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 38, Train Loss: 8.7553, Val Loss: 14.9396, F1 Micro: 0.8750, F1 Macro: 0.5377, Accuracy: 0.8750\n","Epoch 39, Train Loss: 14.6263, Val Loss: 15.3842, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 40, Train Loss: 41.9083, Val Loss: 41.7391, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 41, Train Loss: 23.6600, Val Loss: 23.8576, F1 Micro: 0.3854, F1 Macro: 0.3739, Accuracy: 0.3854\n","Epoch 42, Train Loss: 15.0800, Val Loss: 2.4984, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 43, Train Loss: 10.7406, Val Loss: 12.4772, F1 Micro: 0.4167, F1 Macro: 0.4000, Accuracy: 0.4167\n","Epoch 44, Train Loss: 10.0546, Val Loss: 9.6637, F1 Micro: 0.4062, F1 Macro: 0.3914, Accuracy: 0.4062\n","Epoch 45, Train Loss: 6.3589, Val Loss: 18.8944, F1 Micro: 0.2396, F1 Macro: 0.2395, Accuracy: 0.2396\n","Epoch 46, Train Loss: 8.5576, Val Loss: 17.8365, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 47, Train Loss: 20.4352, Val Loss: 33.5650, F1 Micro: 0.2396, F1 Macro: 0.2395, Accuracy: 0.2396\n","Epoch 48, Train Loss: 34.9807, Val Loss: 25.5412, F1 Micro: 0.2708, F1 Macro: 0.2705, Accuracy: 0.2708\n","Epoch 49, Train Loss: 43.9769, Val Loss: 9.1824, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 50, Train Loss: 19.7284, Val Loss: 19.5522, F1 Micro: 0.1771, F1 Macro: 0.1727, Accuracy: 0.1771\n","Epoch 51, Train Loss: 12.0993, Val Loss: 1.9887, F1 Micro: 0.8646, F1 Macro: 0.7360, Accuracy: 0.8646\n","Epoch 52, Train Loss: 2.6423, Val Loss: 2.2662, F1 Micro: 0.7083, F1 Macro: 0.4750, Accuracy: 0.7083\n","Epoch 53, Train Loss: 3.4553, Val Loss: 1.7556, F1 Micro: 0.8750, F1 Macro: 0.7331, Accuracy: 0.8750\n","Epoch 54, Train Loss: 3.7800, Val Loss: 4.4674, F1 Micro: 0.5000, F1 Macro: 0.4604, Accuracy: 0.5000\n","Epoch 55, Train Loss: 6.8595, Val Loss: 6.3846, F1 Micro: 0.4688, F1 Macro: 0.4421, Accuracy: 0.4688\n","Epoch 56, Train Loss: 2.7724, Val Loss: 16.2057, F1 Micro: 0.1979, F1 Macro: 0.1957, Accuracy: 0.1979\n","Epoch 57, Train Loss: 3.0587, Val Loss: 1.6035, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 58, Train Loss: 11.6807, Val Loss: 13.1154, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 59, Train Loss: 8.2797, Val Loss: 8.6027, F1 Micro: 0.5729, F1 Macro: 0.5232, Accuracy: 0.5729\n","Epoch 60, Train Loss: 5.6777, Val Loss: 9.4892, F1 Micro: 0.8646, F1 Macro: 0.5299, Accuracy: 0.8646\n","Epoch 61, Train Loss: 6.3162, Val Loss: 2.3736, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 62, Train Loss: 4.9340, Val Loss: 10.5645, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 63, Train Loss: 5.9084, Val Loss: 3.2670, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 64, Train Loss: 5.0433, Val Loss: 0.9471, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 65, Train Loss: 4.7784, Val Loss: 2.2443, F1 Micro: 0.6667, F1 Macro: 0.5966, Accuracy: 0.6667\n","Epoch 66, Train Loss: 1.5931, Val Loss: 1.1252, F1 Micro: 0.7917, F1 Macro: 0.6719, Accuracy: 0.7917\n","Epoch 67, Train Loss: 2.6049, Val Loss: 5.9603, F1 Micro: 0.4896, F1 Macro: 0.4585, Accuracy: 0.4896\n","Epoch 68, Train Loss: 3.1982, Val Loss: 5.9120, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 69, Train Loss: 2.9806, Val Loss: 11.3609, F1 Micro: 0.3229, F1 Macro: 0.3193, Accuracy: 0.3229\n","Epoch 70, Train Loss: 5.1506, Val Loss: 11.2458, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 71, Train Loss: 6.6606, Val Loss: 1.6836, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 72, Train Loss: 5.4424, Val Loss: 4.7354, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 73, Train Loss: 4.0501, Val Loss: 3.4702, F1 Micro: 0.8958, F1 Macro: 0.6935, Accuracy: 0.8958\n","Epoch 74, Train Loss: 3.0382, Val Loss: 4.0087, F1 Micro: 0.7604, F1 Macro: 0.6662, Accuracy: 0.7604\n","Epoch 75, Train Loss: 3.2218, Val Loss: 0.3705, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 76, Train Loss: 1.8714, Val Loss: 2.1328, F1 Micro: 0.6979, F1 Macro: 0.6221, Accuracy: 0.6979\n","Epoch 77, Train Loss: 2.9500, Val Loss: 2.7856, F1 Micro: 0.7396, F1 Macro: 0.6575, Accuracy: 0.7396\n","Epoch 78, Train Loss: 5.8529, Val Loss: 4.3607, F1 Micro: 0.7292, F1 Macro: 0.6389, Accuracy: 0.7292\n","Epoch 79, Train Loss: 5.2922, Val Loss: 1.0040, F1 Micro: 0.8750, F1 Macro: 0.5377, Accuracy: 0.8750\n","Epoch 80, Train Loss: 4.0656, Val Loss: 3.4774, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 81, Train Loss: 1.9535, Val Loss: 0.4333, F1 Micro: 0.9271, F1 Macro: 0.8129, Accuracy: 0.9271\n","Epoch 82, Train Loss: 1.0376, Val Loss: 0.6143, F1 Micro: 0.8750, F1 Macro: 0.5909, Accuracy: 0.8750\n","Epoch 83, Train Loss: 2.5567, Val Loss: 5.4766, F1 Micro: 0.7188, F1 Macro: 0.6301, Accuracy: 0.7188\n","Epoch 84, Train Loss: 5.4529, Val Loss: 0.9405, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 85, Train Loss: 2.6177, Val Loss: 2.7938, F1 Micro: 0.8854, F1 Macro: 0.6787, Accuracy: 0.8854\n","Epoch 86, Train Loss: 2.8122, Val Loss: 0.6761, F1 Micro: 0.8958, F1 Macro: 0.8025, Accuracy: 0.8958\n","Epoch 87, Train Loss: 0.9691, Val Loss: 1.2757, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 88, Train Loss: 2.6897, Val Loss: 0.4756, F1 Micro: 0.9688, F1 Macro: 0.9310, Accuracy: 0.9688\n","Epoch 89, Train Loss: 0.9300, Val Loss: 0.8756, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 90, Train Loss: 1.0673, Val Loss: 3.1458, F1 Micro: 0.6875, F1 Macro: 0.6135, Accuracy: 0.6875\n","Epoch 91, Train Loss: 4.6434, Val Loss: 0.6008, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 92, Train Loss: 3.4747, Val Loss: 2.2148, F1 Micro: 0.6875, F1 Macro: 0.5944, Accuracy: 0.6875\n","Epoch 93, Train Loss: 5.6784, Val Loss: 0.5308, F1 Micro: 0.9479, F1 Macro: 0.8765, Accuracy: 0.9479\n","Epoch 94, Train Loss: 2.7832, Val Loss: 2.5653, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 95, Train Loss: 0.8429, Val Loss: 0.5603, F1 Micro: 0.9062, F1 Macro: 0.7096, Accuracy: 0.9062\n","Epoch 96, Train Loss: 1.8327, Val Loss: 3.2421, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 97, Train Loss: 4.1606, Val Loss: 3.3581, F1 Micro: 0.8021, F1 Macro: 0.7054, Accuracy: 0.8021\n","Epoch 98, Train Loss: 3.0763, Val Loss: 1.1091, F1 Micro: 0.9062, F1 Macro: 0.8172, Accuracy: 0.9062\n","Epoch 99, Train Loss: 3.9964, Val Loss: 1.0736, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 100, Train Loss: 0.9782, Val Loss: 0.5650, F1 Micro: 0.9375, F1 Macro: 0.8571, Accuracy: 0.9375\n","Epoch 101, Train Loss: 1.3584, Val Loss: 0.6961, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 102, Train Loss: 1.5192, Val Loss: 3.4443, F1 Micro: 0.8750, F1 Macro: 0.5377, Accuracy: 0.8750\n","Epoch 103, Train Loss: 1.6376, Val Loss: 0.5769, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 104, Train Loss: 1.8311, Val Loss: 2.1951, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 105, Train Loss: 3.3130, Val Loss: 4.7036, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 106, Train Loss: 4.9737, Val Loss: 3.3011, F1 Micro: 0.6354, F1 Macro: 0.5718, Accuracy: 0.6354\n","Epoch 107, Train Loss: 1.7811, Val Loss: 1.0540, F1 Micro: 0.8438, F1 Macro: 0.7379, Accuracy: 0.8438\n","Epoch 108, Train Loss: 1.0999, Val Loss: 0.7742, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 109, Train Loss: 1.5568, Val Loss: 1.0654, F1 Micro: 0.8750, F1 Macro: 0.5377, Accuracy: 0.8750\n","Epoch 110, Train Loss: 1.2362, Val Loss: 1.3616, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 111, Train Loss: 2.1037, Val Loss: 0.5629, F1 Micro: 0.9479, F1 Macro: 0.8923, Accuracy: 0.9479\n","Epoch 112, Train Loss: 1.0894, Val Loss: 0.4288, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 113, Train Loss: 1.4573, Val Loss: 0.8585, F1 Micro: 0.8854, F1 Macro: 0.7766, Accuracy: 0.8854\n","Epoch 114, Train Loss: 2.7325, Val Loss: 5.8353, F1 Micro: 0.6458, F1 Macro: 0.5800, Accuracy: 0.6458\n","Epoch 115, Train Loss: 2.2001, Val Loss: 1.9408, F1 Micro: 0.7604, F1 Macro: 0.6554, Accuracy: 0.7604\n","Epoch 116, Train Loss: 1.6081, Val Loss: 3.1399, F1 Micro: 0.6562, F1 Macro: 0.5883, Accuracy: 0.6562\n","Epoch 117, Train Loss: 2.3302, Val Loss: 1.0812, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 118, Train Loss: 0.7929, Val Loss: 0.4383, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 119, Train Loss: 0.9899, Val Loss: 0.9254, F1 Micro: 0.8854, F1 Macro: 0.8078, Accuracy: 0.8854\n","Epoch 120, Train Loss: 1.2321, Val Loss: 0.4882, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 121, Train Loss: 0.5655, Val Loss: 0.6391, F1 Micro: 0.9167, F1 Macro: 0.8420, Accuracy: 0.9167\n","Epoch 122, Train Loss: 0.6845, Val Loss: 0.6440, F1 Micro: 0.9479, F1 Macro: 0.8985, Accuracy: 0.9479\n","Epoch 123, Train Loss: 1.2930, Val Loss: 0.5307, F1 Micro: 0.9583, F1 Macro: 0.9110, Accuracy: 0.9583\n","Epoch 124, Train Loss: 1.1816, Val Loss: 3.3547, F1 Micro: 0.7292, F1 Macro: 0.6485, Accuracy: 0.7292\n","Epoch 125, Train Loss: 0.7126, Val Loss: 0.5431, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 126, Train Loss: 0.7279, Val Loss: 0.4815, F1 Micro: 0.9688, F1 Macro: 0.9259, Accuracy: 0.9688\n","Epoch 127, Train Loss: 0.6995, Val Loss: 0.4428, F1 Micro: 0.9583, F1 Macro: 0.8973, Accuracy: 0.9583\n","Epoch 128, Train Loss: 2.8862, Val Loss: 1.5810, F1 Micro: 0.9167, F1 Macro: 0.7548, Accuracy: 0.9167\n","Epoch 129, Train Loss: 1.9100, Val Loss: 0.8780, F1 Micro: 0.8750, F1 Macro: 0.6651, Accuracy: 0.8750\n","Epoch 130, Train Loss: 0.8897, Val Loss: 0.5206, F1 Micro: 0.9271, F1 Macro: 0.8129, Accuracy: 0.9271\n","Epoch 131, Train Loss: 0.7821, Val Loss: 0.6596, F1 Micro: 0.9271, F1 Macro: 0.7956, Accuracy: 0.9271\n","Epoch 132, Train Loss: 0.6338, Val Loss: 0.5853, F1 Micro: 0.9062, F1 Macro: 0.7371, Accuracy: 0.9062\n","Epoch 133, Train Loss: 0.5885, Val Loss: 0.4486, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 134, Train Loss: 1.2478, Val Loss: 0.4619, F1 Micro: 0.9479, F1 Macro: 0.8663, Accuracy: 0.9479\n","Epoch 135, Train Loss: 1.2501, Val Loss: 1.2640, F1 Micro: 0.8646, F1 Macro: 0.7824, Accuracy: 0.8646\n","Epoch 136, Train Loss: 1.4513, Val Loss: 1.1567, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 137, Train Loss: 1.2675, Val Loss: 1.6229, F1 Micro: 0.8750, F1 Macro: 0.7856, Accuracy: 0.8750\n","Epoch 138, Train Loss: 3.1575, Val Loss: 5.1001, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 487.1853, Val Loss: 52.5733, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 2, Train Loss: 454.3280, Val Loss: 251.4259, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 3, Train Loss: 106.0689, Val Loss: 431.2507, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 4, Train Loss: 165.6832, Val Loss: 33.3895, F1 Micro: 0.5000, F1 Macro: 0.4283, Accuracy: 0.5000\n","Epoch 5, Train Loss: 87.4862, Val Loss: 48.6489, F1 Micro: 0.3646, F1 Macro: 0.3326, Accuracy: 0.3646\n","Epoch 6, Train Loss: 129.6902, Val Loss: 68.5579, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 7, Train Loss: 67.2331, Val Loss: 215.9755, F1 Micro: 0.1250, F1 Macro: 0.1154, Accuracy: 0.1250\n","Epoch 8, Train Loss: 100.7470, Val Loss: 159.0433, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 9, Train Loss: 79.0685, Val Loss: 147.0791, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 10, Train Loss: 116.3871, Val Loss: 87.2523, F1 Micro: 0.2188, F1 Macro: 0.2166, Accuracy: 0.2188\n","Epoch 11, Train Loss: 116.9839, Val Loss: 107.0828, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 12, Train Loss: 139.2300, Val Loss: 48.2285, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 13, Train Loss: 35.6964, Val Loss: 17.7892, F1 Micro: 0.7396, F1 Macro: 0.5191, Accuracy: 0.7396\n","Epoch 14, Train Loss: 144.2909, Val Loss: 284.2260, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 15, Train Loss: 69.3102, Val Loss: 38.2377, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 16, Train Loss: 27.6466, Val Loss: 19.7853, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 17, Train Loss: 19.1808, Val Loss: 103.1427, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 18, Train Loss: 44.0295, Val Loss: 14.2716, F1 Micro: 0.5104, F1 Macro: 0.4354, Accuracy: 0.5104\n","Epoch 19, Train Loss: 46.7872, Val Loss: 23.6409, F1 Micro: 0.5833, F1 Macro: 0.4592, Accuracy: 0.5833\n","Epoch 20, Train Loss: 29.4806, Val Loss: 74.4533, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 21, Train Loss: 49.6193, Val Loss: 81.9893, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Epoch 22, Train Loss: 34.5720, Val Loss: 24.6933, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Epoch 23, Train Loss: 11.6247, Val Loss: 18.8052, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 24, Train Loss: 28.9149, Val Loss: 19.9644, F1 Micro: 0.5521, F1 Macro: 0.4635, Accuracy: 0.5521\n","Epoch 25, Train Loss: 28.1171, Val Loss: 30.2568, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 26, Train Loss: 10.0414, Val Loss: 4.9146, F1 Micro: 0.6667, F1 Macro: 0.5283, Accuracy: 0.6667\n","Epoch 27, Train Loss: 14.5726, Val Loss: 15.9731, F1 Micro: 0.7708, F1 Macro: 0.5401, Accuracy: 0.7708\n","Epoch 28, Train Loss: 8.5107, Val Loss: 41.1814, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 29, Train Loss: 38.8519, Val Loss: 49.7765, F1 Micro: 0.1875, F1 Macro: 0.1861, Accuracy: 0.1875\n","Epoch 30, Train Loss: 21.3116, Val Loss: 10.0576, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 31, Train Loss: 33.4006, Val Loss: 23.9198, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 32, Train Loss: 40.0389, Val Loss: 15.5976, F1 Micro: 0.3750, F1 Macro: 0.3404, Accuracy: 0.3750\n","Epoch 33, Train Loss: 14.3097, Val Loss: 18.7959, F1 Micro: 0.2812, F1 Macro: 0.2793, Accuracy: 0.2812\n","Epoch 34, Train Loss: 13.9369, Val Loss: 60.1466, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 35, Train Loss: 26.1152, Val Loss: 11.2756, F1 Micro: 0.7917, F1 Macro: 0.5551, Accuracy: 0.7917\n","Epoch 36, Train Loss: 9.9606, Val Loss: 26.3891, F1 Micro: 0.1771, F1 Macro: 0.1748, Accuracy: 0.1771\n","Epoch 37, Train Loss: 7.9886, Val Loss: 8.1690, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 38, Train Loss: 34.2130, Val Loss: 19.5455, F1 Micro: 0.5833, F1 Macro: 0.4725, Accuracy: 0.5833\n","Epoch 39, Train Loss: 47.2829, Val Loss: 13.6098, F1 Micro: 0.6771, F1 Macro: 0.5193, Accuracy: 0.6771\n","Epoch 40, Train Loss: 24.2941, Val Loss: 55.0260, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 41, Train Loss: 37.7530, Val Loss: 28.8632, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 42, Train Loss: 19.4715, Val Loss: 8.7401, F1 Micro: 0.8542, F1 Macro: 0.5709, Accuracy: 0.8542\n","Epoch 43, Train Loss: 12.8610, Val Loss: 4.1552, F1 Micro: 0.6250, F1 Macro: 0.5132, Accuracy: 0.6250\n","Epoch 44, Train Loss: 11.7243, Val Loss: 11.7908, F1 Micro: 0.7292, F1 Macro: 0.5556, Accuracy: 0.7292\n","Epoch 45, Train Loss: 7.4182, Val Loss: 17.5661, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 46, Train Loss: 11.6184, Val Loss: 17.1629, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 47, Train Loss: 14.1988, Val Loss: 16.7738, F1 Micro: 0.3646, F1 Macro: 0.3387, Accuracy: 0.3646\n","Epoch 48, Train Loss: 16.3598, Val Loss: 9.0559, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 49, Train Loss: 8.8122, Val Loss: 16.6191, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 50, Train Loss: 7.2163, Val Loss: 8.8618, F1 Micro: 0.7917, F1 Macro: 0.5819, Accuracy: 0.7917\n","Epoch 51, Train Loss: 5.5035, Val Loss: 11.3900, F1 Micro: 0.3958, F1 Macro: 0.3623, Accuracy: 0.3958\n","Epoch 52, Train Loss: 17.9063, Val Loss: 10.2016, F1 Micro: 0.5938, F1 Macro: 0.4918, Accuracy: 0.5938\n","Epoch 53, Train Loss: 5.2266, Val Loss: 7.5627, F1 Micro: 0.4688, F1 Macro: 0.4364, Accuracy: 0.4688\n","Epoch 54, Train Loss: 3.4804, Val Loss: 7.9798, F1 Micro: 0.8854, F1 Macro: 0.5462, Accuracy: 0.8854\n","Epoch 55, Train Loss: 4.0874, Val Loss: 11.4973, F1 Micro: 0.2604, F1 Macro: 0.2597, Accuracy: 0.2604\n","Epoch 56, Train Loss: 7.0454, Val Loss: 5.8558, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 699.7865, Val Loss: 1224.7314, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 334.1211, Val Loss: 105.8495, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 84.1839, Val Loss: 12.8115, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 4, Train Loss: 197.7974, Val Loss: 51.0607, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 209.0752, Val Loss: 296.5375, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 186.7282, Val Loss: 31.0949, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 7, Train Loss: 37.8686, Val Loss: 76.0931, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 8, Train Loss: 80.5453, Val Loss: 71.3336, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 9, Train Loss: 122.9664, Val Loss: 25.4047, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 10, Train Loss: 195.0167, Val Loss: 414.1936, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 11, Train Loss: 219.4947, Val Loss: 188.5831, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 12, Train Loss: 67.0339, Val Loss: 50.7830, F1 Micro: 0.2708, F1 Macro: 0.2696, Accuracy: 0.2708\n","Epoch 13, Train Loss: 55.3038, Val Loss: 18.5116, F1 Micro: 0.7292, F1 Macro: 0.5556, Accuracy: 0.7292\n","Epoch 14, Train Loss: 55.7172, Val Loss: 179.5641, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 15, Train Loss: 98.2326, Val Loss: 85.5993, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 16, Train Loss: 35.8854, Val Loss: 11.4854, F1 Micro: 0.5625, F1 Macro: 0.4812, Accuracy: 0.5625\n","Epoch 17, Train Loss: 80.8499, Val Loss: 99.0814, F1 Micro: 0.2083, F1 Macro: 0.1996, Accuracy: 0.2083\n","Epoch 18, Train Loss: 58.4070, Val Loss: 19.5317, F1 Micro: 0.8021, F1 Macro: 0.6141, Accuracy: 0.8021\n","Epoch 19, Train Loss: 59.7532, Val Loss: 71.7400, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 65.5870, Val Loss: 17.6343, F1 Micro: 0.6875, F1 Macro: 0.5263, Accuracy: 0.6875\n","Epoch 21, Train Loss: 27.8022, Val Loss: 21.4514, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 22, Train Loss: 32.9333, Val Loss: 16.5159, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 23, Train Loss: 21.2249, Val Loss: 21.9983, F1 Micro: 0.2500, F1 Macro: 0.2471, Accuracy: 0.2500\n","Epoch 24, Train Loss: 27.4402, Val Loss: 34.1768, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 25, Train Loss: 51.6004, Val Loss: 17.7026, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 26, Train Loss: 26.3846, Val Loss: 5.8134, F1 Micro: 0.6146, F1 Macro: 0.5178, Accuracy: 0.6146\n","Epoch 27, Train Loss: 64.5346, Val Loss: 73.7626, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 28, Train Loss: 74.8335, Val Loss: 122.2056, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 29, Train Loss: 78.8526, Val Loss: 11.9084, F1 Micro: 0.7083, F1 Macro: 0.5872, Accuracy: 0.7083\n","Epoch 30, Train Loss: 60.4523, Val Loss: 32.7752, F1 Micro: 0.1979, F1 Macro: 0.1872, Accuracy: 0.1979\n","Epoch 31, Train Loss: 15.3281, Val Loss: 5.9393, F1 Micro: 0.3958, F1 Macro: 0.3916, Accuracy: 0.3958\n","Epoch 32, Train Loss: 10.6962, Val Loss: 6.0274, F1 Micro: 0.8646, F1 Macro: 0.5805, Accuracy: 0.8646\n","Epoch 33, Train Loss: 7.3537, Val Loss: 6.0617, F1 Micro: 0.3646, F1 Macro: 0.3629, Accuracy: 0.3646\n","Epoch 34, Train Loss: 18.2274, Val Loss: 36.1033, F1 Micro: 0.2292, F1 Macro: 0.2238, Accuracy: 0.2292\n","Epoch 35, Train Loss: 48.1066, Val Loss: 50.7552, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 36, Train Loss: 23.7507, Val Loss: 3.4445, F1 Micro: 0.8125, F1 Macro: 0.6783, Accuracy: 0.8125\n","Epoch 37, Train Loss: 7.1310, Val Loss: 3.8705, F1 Micro: 0.6979, F1 Macro: 0.6128, Accuracy: 0.6979\n","Epoch 38, Train Loss: 8.7466, Val Loss: 5.7221, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 39, Train Loss: 8.5702, Val Loss: 12.6288, F1 Micro: 0.5312, F1 Macro: 0.4767, Accuracy: 0.5312\n","Epoch 40, Train Loss: 10.7234, Val Loss: 26.6734, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 41, Train Loss: 16.3989, Val Loss: 11.7728, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 42, Train Loss: 11.8913, Val Loss: 4.1437, F1 Micro: 0.6458, F1 Macro: 0.5950, Accuracy: 0.6458\n","Epoch 43, Train Loss: 10.3977, Val Loss: 3.9393, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 44, Train Loss: 4.9048, Val Loss: 9.2812, F1 Micro: 0.3021, F1 Macro: 0.3020, Accuracy: 0.3021\n","Epoch 45, Train Loss: 7.9293, Val Loss: 22.1278, F1 Micro: 0.1979, F1 Macro: 0.1872, Accuracy: 0.1979\n","Epoch 46, Train Loss: 12.1546, Val Loss: 1.0920, F1 Micro: 0.8125, F1 Macro: 0.7346, Accuracy: 0.8125\n","Epoch 47, Train Loss: 4.8775, Val Loss: 5.3725, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 48, Train Loss: 16.9515, Val Loss: 4.3851, F1 Micro: 0.7083, F1 Macro: 0.6111, Accuracy: 0.7083\n","Epoch 49, Train Loss: 11.5798, Val Loss: 48.2575, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 50, Train Loss: 14.8621, Val Loss: 1.4166, F1 Micro: 0.7604, F1 Macro: 0.6849, Accuracy: 0.7604\n","Epoch 51, Train Loss: 10.4523, Val Loss: 8.3857, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 52, Train Loss: 9.7538, Val Loss: 21.7382, F1 Micro: 0.2604, F1 Macro: 0.2584, Accuracy: 0.2604\n","Epoch 53, Train Loss: 14.6757, Val Loss: 5.0426, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 54, Train Loss: 9.9206, Val Loss: 5.0261, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 55, Train Loss: 15.4313, Val Loss: 8.9710, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 56, Train Loss: 24.9491, Val Loss: 3.4221, F1 Micro: 0.7812, F1 Macro: 0.6485, Accuracy: 0.7812\n","Epoch 57, Train Loss: 10.2662, Val Loss: 5.3043, F1 Micro: 0.6667, F1 Macro: 0.6047, Accuracy: 0.6667\n","Epoch 58, Train Loss: 4.3406, Val Loss: 0.6301, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 59, Train Loss: 1.7196, Val Loss: 1.3981, F1 Micro: 0.7917, F1 Macro: 0.7222, Accuracy: 0.7917\n","Epoch 60, Train Loss: 5.4181, Val Loss: 11.2974, F1 Micro: 0.4271, F1 Macro: 0.4164, Accuracy: 0.4271\n","Epoch 61, Train Loss: 13.5900, Val Loss: 7.1100, F1 Micro: 0.5729, F1 Macro: 0.5232, Accuracy: 0.5729\n","Epoch 62, Train Loss: 2.5835, Val Loss: 2.0487, F1 Micro: 0.8438, F1 Macro: 0.7115, Accuracy: 0.8438\n","Epoch 63, Train Loss: 1.9734, Val Loss: 2.0183, F1 Micro: 0.7917, F1 Macro: 0.6952, Accuracy: 0.7917\n","Epoch 64, Train Loss: 2.0804, Val Loss: 0.8919, F1 Micro: 0.8333, F1 Macro: 0.7000, Accuracy: 0.8333\n","Epoch 65, Train Loss: 2.5754, Val Loss: 1.0775, F1 Micro: 0.8542, F1 Macro: 0.7607, Accuracy: 0.8542\n","Epoch 66, Train Loss: 2.2091, Val Loss: 3.4570, F1 Micro: 0.7292, F1 Macro: 0.6389, Accuracy: 0.7292\n","Epoch 67, Train Loss: 3.5683, Val Loss: 10.3523, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 68, Train Loss: 3.5366, Val Loss: 4.2960, F1 Micro: 0.7812, F1 Macro: 0.5735, Accuracy: 0.7812\n","Epoch 69, Train Loss: 3.4610, Val Loss: 1.8776, F1 Micro: 0.7396, F1 Macro: 0.6662, Accuracy: 0.7396\n","Epoch 70, Train Loss: 3.0271, Val Loss: 2.1922, F1 Micro: 0.7812, F1 Macro: 0.7042, Accuracy: 0.7812\n","Epoch 71, Train Loss: 3.1785, Val Loss: 4.2013, F1 Micro: 0.7083, F1 Macro: 0.6393, Accuracy: 0.7083\n","Epoch 72, Train Loss: 2.4618, Val Loss: 1.5747, F1 Micro: 0.8125, F1 Macro: 0.6923, Accuracy: 0.8125\n","Epoch 73, Train Loss: 1.4396, Val Loss: 0.3670, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 74, Train Loss: 0.7994, Val Loss: 1.2522, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 75, Train Loss: 3.0056, Val Loss: 0.5846, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 76, Train Loss: 2.1051, Val Loss: 3.8649, F1 Micro: 0.8750, F1 Macro: 0.6920, Accuracy: 0.8750\n","Epoch 77, Train Loss: 2.3878, Val Loss: 0.5639, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 78, Train Loss: 0.9463, Val Loss: 2.3331, F1 Micro: 0.8438, F1 Macro: 0.5990, Accuracy: 0.8438\n","Epoch 79, Train Loss: 1.6541, Val Loss: 0.3603, F1 Micro: 0.9375, F1 Macro: 0.8815, Accuracy: 0.9375\n","Epoch 80, Train Loss: 1.3475, Val Loss: 0.4356, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 81, Train Loss: 2.4760, Val Loss: 1.2156, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 82, Train Loss: 0.6750, Val Loss: 1.4053, F1 Micro: 0.8021, F1 Macro: 0.7243, Accuracy: 0.8021\n","Epoch 83, Train Loss: 1.8674, Val Loss: 2.4279, F1 Micro: 0.8750, F1 Macro: 0.7143, Accuracy: 0.8750\n","Epoch 84, Train Loss: 1.3904, Val Loss: 0.9521, F1 Micro: 0.8958, F1 Macro: 0.7433, Accuracy: 0.8958\n","Epoch 85, Train Loss: 3.2078, Val Loss: 1.2329, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 86, Train Loss: 1.4085, Val Loss: 2.4891, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 87, Train Loss: 2.6665, Val Loss: 4.2235, F1 Micro: 0.6250, F1 Macro: 0.5781, Accuracy: 0.6250\n","Epoch 88, Train Loss: 2.1995, Val Loss: 0.5898, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 89, Train Loss: 4.2658, Val Loss: 0.9968, F1 Micro: 0.8333, F1 Macro: 0.7562, Accuracy: 0.8333\n","Epoch 90, Train Loss: 9.2660, Val Loss: 3.2068, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 91, Train Loss: 7.1840, Val Loss: 9.8028, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 92, Train Loss: 5.2690, Val Loss: 3.0482, F1 Micro: 0.7812, F1 Macro: 0.6158, Accuracy: 0.7812\n","Epoch 93, Train Loss: 2.5554, Val Loss: 3.8001, F1 Micro: 0.8125, F1 Macro: 0.6783, Accuracy: 0.8125\n","Epoch 94, Train Loss: 2.3951, Val Loss: 2.9023, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 95, Train Loss: 1.2857, Val Loss: 0.5431, F1 Micro: 0.8542, F1 Macro: 0.7607, Accuracy: 0.8542\n","Epoch 96, Train Loss: 0.7528, Val Loss: 1.4767, F1 Micro: 0.8646, F1 Macro: 0.7360, Accuracy: 0.8646\n","Epoch 97, Train Loss: 0.8719, Val Loss: 0.3697, F1 Micro: 0.9271, F1 Macro: 0.8578, Accuracy: 0.9271\n","Epoch 98, Train Loss: 1.4169, Val Loss: 1.7056, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 99, Train Loss: 1.7162, Val Loss: 1.5431, F1 Micro: 0.8229, F1 Macro: 0.7453, Accuracy: 0.8229\n","Epoch 100, Train Loss: 2.1037, Val Loss: 5.9343, F1 Micro: 0.8854, F1 Macro: 0.7059, Accuracy: 0.8854\n","Epoch 101, Train Loss: 4.0635, Val Loss: 2.5757, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 102, Train Loss: 1.1069, Val Loss: 0.4035, F1 Micro: 0.9062, F1 Macro: 0.8269, Accuracy: 0.9062\n","Epoch 103, Train Loss: 0.9195, Val Loss: 1.3708, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 104, Train Loss: 2.2094, Val Loss: 0.5589, F1 Micro: 0.9062, F1 Macro: 0.8428, Accuracy: 0.9062\n","Epoch 105, Train Loss: 1.1535, Val Loss: 0.7952, F1 Micro: 0.8958, F1 Macro: 0.8291, Accuracy: 0.8958\n","Epoch 106, Train Loss: 1.5280, Val Loss: 1.1554, F1 Micro: 0.8229, F1 Macro: 0.7364, Accuracy: 0.8229\n","Epoch 107, Train Loss: 2.1820, Val Loss: 1.2320, F1 Micro: 0.8438, F1 Macro: 0.7489, Accuracy: 0.8438\n","Epoch 108, Train Loss: 1.4360, Val Loss: 0.7126, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 109, Train Loss: 0.5645, Val Loss: 0.6935, F1 Micro: 0.9271, F1 Macro: 0.8492, Accuracy: 0.9271\n","Epoch 110, Train Loss: 0.7187, Val Loss: 0.9004, F1 Micro: 0.8750, F1 Macro: 0.7949, Accuracy: 0.8750\n","Epoch 111, Train Loss: 0.6873, Val Loss: 0.5082, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 112, Train Loss: 0.7415, Val Loss: 0.7775, F1 Micro: 0.8958, F1 Macro: 0.7209, Accuracy: 0.8958\n","Epoch 113, Train Loss: 0.6555, Val Loss: 0.5880, F1 Micro: 0.8854, F1 Macro: 0.7471, Accuracy: 0.8854\n","Epoch 114, Train Loss: 0.8941, Val Loss: 1.7115, F1 Micro: 0.8229, F1 Macro: 0.7030, Accuracy: 0.8229\n","Epoch 115, Train Loss: 2.1609, Val Loss: 1.5817, F1 Micro: 0.7708, F1 Macro: 0.6648, Accuracy: 0.7708\n","Epoch 116, Train Loss: 1.7081, Val Loss: 0.9410, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 117, Train Loss: 2.2262, Val Loss: 0.9475, F1 Micro: 0.8542, F1 Macro: 0.7789, Accuracy: 0.8542\n","Epoch 118, Train Loss: 1.9555, Val Loss: 4.3065, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 119, Train Loss: 3.8309, Val Loss: 1.1197, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 120, Train Loss: 1.4075, Val Loss: 3.3742, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 121, Train Loss: 0.8493, Val Loss: 0.5380, F1 Micro: 0.9062, F1 Macro: 0.7777, Accuracy: 0.9062\n","Epoch 122, Train Loss: 0.9442, Val Loss: 1.0063, F1 Micro: 0.8438, F1 Macro: 0.6954, Accuracy: 0.8438\n","Epoch 123, Train Loss: 1.4923, Val Loss: 2.7419, F1 Micro: 0.8333, F1 Macro: 0.7000, Accuracy: 0.8333\n","Epoch 124, Train Loss: 1.3042, Val Loss: 0.6629, F1 Micro: 0.8542, F1 Macro: 0.7375, Accuracy: 0.8542\n","Epoch 125, Train Loss: 0.7741, Val Loss: 0.7250, F1 Micro: 0.8750, F1 Macro: 0.6322, Accuracy: 0.8750\n","Epoch 126, Train Loss: 0.9542, Val Loss: 1.8234, F1 Micro: 0.8958, F1 Macro: 0.7776, Accuracy: 0.8958\n","Epoch 127, Train Loss: 1.8467, Val Loss: 0.5501, F1 Micro: 0.9271, F1 Macro: 0.8719, Accuracy: 0.9271\n","Epoch 128, Train Loss: 2.2331, Val Loss: 0.5849, F1 Micro: 0.9062, F1 Macro: 0.7594, Accuracy: 0.9062\n","Epoch 129, Train Loss: 1.2379, Val Loss: 0.4204, F1 Micro: 0.9375, F1 Macro: 0.8815, Accuracy: 0.9375\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.9270833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 40.0306, Val Loss: 27.3601, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 19.3047, Val Loss: 25.5991, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 3, Train Loss: 18.8243, Val Loss: 10.2252, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 4, Train Loss: 22.9783, Val Loss: 30.7144, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 25.5035, Val Loss: 44.6918, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 24.1673, Val Loss: 51.1110, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 29.3902, Val Loss: 108.8201, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 46.0894, Val Loss: 13.7228, F1 Micro: 0.4479, F1 Macro: 0.4406, Accuracy: 0.4479\n","Epoch 9, Train Loss: 15.7698, Val Loss: 30.6474, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 10, Train Loss: 15.3980, Val Loss: 7.5751, F1 Micro: 0.7917, F1 Macro: 0.6250, Accuracy: 0.7917\n","Epoch 11, Train Loss: 38.2679, Val Loss: 46.6996, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 119.0617, Val Loss: 103.3540, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 35.8557, Val Loss: 16.3709, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 3, Train Loss: 35.9584, Val Loss: 25.5408, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 42.9689, Val Loss: 198.6312, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 55.7372, Val Loss: 4.8670, F1 Micro: 0.5938, F1 Macro: 0.4918, Accuracy: 0.5938\n","Epoch 6, Train Loss: 18.9333, Val Loss: 11.2909, F1 Micro: 0.3333, F1 Macro: 0.3307, Accuracy: 0.3333\n","Epoch 7, Train Loss: 18.1093, Val Loss: 38.1137, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 8, Train Loss: 32.5158, Val Loss: 6.6208, F1 Micro: 0.6146, F1 Macro: 0.5060, Accuracy: 0.6146\n","Epoch 9, Train Loss: 31.2714, Val Loss: 47.6998, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 10, Train Loss: 28.7137, Val Loss: 23.5210, F1 Micro: 0.2396, F1 Macro: 0.2388, Accuracy: 0.2396\n","Epoch 11, Train Loss: 32.6311, Val Loss: 53.4138, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 33.2962, Val Loss: 29.0248, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 31.3203, Val Loss: 8.3005, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 3, Train Loss: 13.0479, Val Loss: 36.4556, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 4, Train Loss: 38.5945, Val Loss: 35.9616, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 5, Train Loss: 37.5517, Val Loss: 26.9606, F1 Micro: 0.1562, F1 Macro: 0.1488, Accuracy: 0.1562\n","Epoch 6, Train Loss: 19.3539, Val Loss: 93.0249, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 7, Train Loss: 56.5696, Val Loss: 10.6044, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 8, Train Loss: 32.6642, Val Loss: 57.5540, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 9, Train Loss: 89.3745, Val Loss: 48.2269, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 10, Train Loss: 19.9547, Val Loss: 7.0184, F1 Micro: 0.6042, F1 Macro: 0.5394, Accuracy: 0.6042\n","Epoch 11, Train Loss: 21.9244, Val Loss: 5.7627, F1 Micro: 0.6771, F1 Macro: 0.5861, Accuracy: 0.6771\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 58.1744, Val Loss: 13.7423, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 2, Train Loss: 29.4586, Val Loss: 30.6747, F1 Micro: 0.1250, F1 Macro: 0.1154, Accuracy: 0.1250\n","Epoch 3, Train Loss: 34.4978, Val Loss: 10.5659, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 13.1611, Val Loss: 40.9247, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 5, Train Loss: 40.7019, Val Loss: 9.0068, F1 Micro: 0.7708, F1 Macro: 0.4762, Accuracy: 0.7708\n","Epoch 6, Train Loss: 17.9655, Val Loss: 39.0664, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 7, Train Loss: 38.3466, Val Loss: 8.5661, F1 Micro: 0.7188, F1 Macro: 0.5060, Accuracy: 0.7188\n","Epoch 8, Train Loss: 29.1836, Val Loss: 62.1575, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 9, Train Loss: 38.2955, Val Loss: 12.5287, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 10, Train Loss: 21.9754, Val Loss: 10.2770, F1 Micro: 0.5104, F1 Macro: 0.4354, Accuracy: 0.5104\n","Epoch 11, Train Loss: 23.9667, Val Loss: 15.6898, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 48.4377, Val Loss: 158.3252, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 41.2279, Val Loss: 24.7233, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 22.2515, Val Loss: 16.9875, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 16.6036, Val Loss: 10.5491, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 15.6830, Val Loss: 37.1768, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 11.1624, Val Loss: 5.1607, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 7, Train Loss: 28.2144, Val Loss: 28.5192, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 8, Train Loss: 29.5172, Val Loss: 7.8183, F1 Micro: 0.3333, F1 Macro: 0.3322, Accuracy: 0.3333\n","Epoch 9, Train Loss: 26.7190, Val Loss: 62.0755, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 10, Train Loss: 19.0933, Val Loss: 8.3019, F1 Micro: 0.3750, F1 Macro: 0.3681, Accuracy: 0.3750\n","Epoch 11, Train Loss: 25.4276, Val Loss: 6.7500, F1 Micro: 0.8229, F1 Macro: 0.6337, Accuracy: 0.8229\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.8541666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 61.1321, Val Loss: 5.5758, F1 Micro: 0.5833, F1 Macro: 0.5236, Accuracy: 0.5833\n","Epoch 2, Train Loss: 28.0133, Val Loss: 6.1258, F1 Micro: 0.6250, F1 Macro: 0.5553, Accuracy: 0.6250\n","Epoch 3, Train Loss: 20.7591, Val Loss: 5.8967, F1 Micro: 0.6458, F1 Macro: 0.5714, Accuracy: 0.6458\n","Epoch 4, Train Loss: 21.9036, Val Loss: 39.4501, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 31.8434, Val Loss: 66.7931, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 20.3268, Val Loss: 56.0593, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 7, Train Loss: 46.9601, Val Loss: 38.6018, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 8, Train Loss: 83.2934, Val Loss: 9.4802, F1 Micro: 0.4896, F1 Macro: 0.4688, Accuracy: 0.4896\n","Epoch 9, Train Loss: 36.8296, Val Loss: 13.3382, F1 Micro: 0.4271, F1 Macro: 0.4240, Accuracy: 0.4271\n","Epoch 10, Train Loss: 30.0692, Val Loss: 21.2915, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 11, Train Loss: 16.6606, Val Loss: 47.6373, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 12, Train Loss: 31.2979, Val Loss: 6.9643, F1 Micro: 0.6250, F1 Macro: 0.5553, Accuracy: 0.6250\n","Epoch 13, Train Loss: 22.5591, Val Loss: 11.0035, F1 Micro: 0.4479, F1 Macro: 0.4406, Accuracy: 0.4479\n","Epoch 14, Train Loss: 16.6695, Val Loss: 37.5853, F1 Micro: 0.2188, F1 Macro: 0.1992, Accuracy: 0.2188\n","Epoch 15, Train Loss: 54.3456, Val Loss: 7.8623, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Epoch 16, Train Loss: 58.7706, Val Loss: 100.7657, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 17, Train Loss: 17.4107, Val Loss: 13.2875, F1 Micro: 0.8125, F1 Macro: 0.6237, Accuracy: 0.8125\n","Epoch 18, Train Loss: 24.1136, Val Loss: 10.0446, F1 Micro: 0.4792, F1 Macro: 0.4643, Accuracy: 0.4792\n","Epoch 19, Train Loss: 64.6264, Val Loss: 79.5885, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 20, Train Loss: 43.8569, Val Loss: 42.5215, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 21, Train Loss: 45.3599, Val Loss: 50.8881, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 22, Train Loss: 17.6014, Val Loss: 6.6567, F1 Micro: 0.7188, F1 Macro: 0.6197, Accuracy: 0.7188\n","Epoch 23, Train Loss: 25.0536, Val Loss: 48.4563, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 24, Train Loss: 34.8039, Val Loss: 13.6805, F1 Micro: 0.3854, F1 Macro: 0.3848, Accuracy: 0.3854\n","Epoch 25, Train Loss: 19.1384, Val Loss: 29.5274, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 26, Train Loss: 32.0683, Val Loss: 6.5841, F1 Micro: 0.7188, F1 Macro: 0.6197, Accuracy: 0.7188\n","Epoch 27, Train Loss: 26.3972, Val Loss: 5.6591, F1 Micro: 0.6250, F1 Macro: 0.5553, Accuracy: 0.6250\n","Epoch 28, Train Loss: 18.9497, Val Loss: 55.7875, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 29, Train Loss: 26.6694, Val Loss: 49.5646, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 30, Train Loss: 52.5350, Val Loss: 37.4801, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 31, Train Loss: 32.8614, Val Loss: 47.3547, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 32, Train Loss: 23.7040, Val Loss: 40.4029, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 33, Train Loss: 35.6280, Val Loss: 67.7255, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 34, Train Loss: 28.5613, Val Loss: 47.7497, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 35, Train Loss: 21.1318, Val Loss: 6.8623, F1 Micro: 0.7292, F1 Macro: 0.6167, Accuracy: 0.7292\n","Epoch 36, Train Loss: 24.5704, Val Loss: 37.3572, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 37, Train Loss: 23.4455, Val Loss: 7.7816, F1 Micro: 0.5104, F1 Macro: 0.4905, Accuracy: 0.5104\n","Epoch 38, Train Loss: 20.1578, Val Loss: 6.4288, F1 Micro: 0.8021, F1 Macro: 0.6524, Accuracy: 0.8021\n","Epoch 39, Train Loss: 18.6724, Val Loss: 21.7246, F1 Micro: 0.2396, F1 Macro: 0.2254, Accuracy: 0.2396\n","Epoch 40, Train Loss: 18.2730, Val Loss: 4.6948, F1 Micro: 0.5625, F1 Macro: 0.5218, Accuracy: 0.5625\n","Epoch 41, Train Loss: 31.5630, Val Loss: 52.5730, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 42, Train Loss: 22.6308, Val Loss: 66.9148, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 43, Train Loss: 23.4844, Val Loss: 20.7305, F1 Micro: 0.2604, F1 Macro: 0.2539, Accuracy: 0.2604\n","Epoch 44, Train Loss: 14.1115, Val Loss: 29.3359, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 45, Train Loss: 23.7313, Val Loss: 8.5348, F1 Micro: 0.5104, F1 Macro: 0.4905, Accuracy: 0.5104\n","Epoch 46, Train Loss: 27.3976, Val Loss: 85.6076, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 47, Train Loss: 45.8332, Val Loss: 13.4239, F1 Micro: 0.8021, F1 Macro: 0.6141, Accuracy: 0.8021\n","Epoch 48, Train Loss: 28.4312, Val Loss: 21.7912, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 49, Train Loss: 14.7738, Val Loss: 10.4333, F1 Micro: 0.4375, F1 Macro: 0.4336, Accuracy: 0.4375\n","Epoch 50, Train Loss: 60.4423, Val Loss: 56.8566, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 51, Train Loss: 21.2241, Val Loss: 10.2679, F1 Micro: 0.5104, F1 Macro: 0.4946, Accuracy: 0.5104\n","Epoch 52, Train Loss: 12.0192, Val Loss: 8.7112, F1 Micro: 0.4167, F1 Macro: 0.4144, Accuracy: 0.4167\n","Epoch 53, Train Loss: 13.2854, Val Loss: 6.6315, F1 Micro: 0.8229, F1 Macro: 0.6547, Accuracy: 0.8229\n","Epoch 54, Train Loss: 36.8439, Val Loss: 14.6634, F1 Micro: 0.3229, F1 Macro: 0.3223, Accuracy: 0.3229\n","Epoch 55, Train Loss: 13.5938, Val Loss: 32.4356, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 56, Train Loss: 42.0148, Val Loss: 4.8750, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 57, Train Loss: 29.6357, Val Loss: 84.3496, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 58, Train Loss: 75.0280, Val Loss: 8.0812, F1 Micro: 0.6667, F1 Macro: 0.5878, Accuracy: 0.6667\n","Epoch 59, Train Loss: 20.3198, Val Loss: 20.7687, F1 Micro: 0.3229, F1 Macro: 0.3223, Accuracy: 0.3229\n","Epoch 60, Train Loss: 42.9218, Val Loss: 15.8566, F1 Micro: 0.4271, F1 Macro: 0.4240, Accuracy: 0.4271\n","Epoch 61, Train Loss: 33.7063, Val Loss: 9.0758, F1 Micro: 0.5833, F1 Macro: 0.5236, Accuracy: 0.5833\n","Epoch 62, Train Loss: 26.3147, Val Loss: 7.5685, F1 Micro: 0.6875, F1 Macro: 0.6044, Accuracy: 0.6875\n","Epoch 63, Train Loss: 25.5157, Val Loss: 72.7941, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 64, Train Loss: 22.9918, Val Loss: 25.8540, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 65, Train Loss: 31.0252, Val Loss: 116.0800, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 66, Train Loss: 22.9963, Val Loss: 6.4380, F1 Micro: 0.7396, F1 Macro: 0.6372, Accuracy: 0.7396\n","Epoch 67, Train Loss: 14.7282, Val Loss: 45.1821, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 68, Train Loss: 52.3863, Val Loss: 6.5735, F1 Micro: 0.6042, F1 Macro: 0.5394, Accuracy: 0.6042\n","Epoch 69, Train Loss: 13.1016, Val Loss: 11.6438, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 70, Train Loss: 42.1075, Val Loss: 64.6197, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 71, Train Loss: 24.2441, Val Loss: 23.9288, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 72, Train Loss: 29.2544, Val Loss: 6.1394, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 73, Train Loss: 11.4592, Val Loss: 15.3949, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 74, Train Loss: 27.2636, Val Loss: 179.4253, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 75, Train Loss: 42.8495, Val Loss: 8.3447, F1 Micro: 0.4896, F1 Macro: 0.4800, Accuracy: 0.4896\n","Epoch 76, Train Loss: 13.1597, Val Loss: 34.2821, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 77, Train Loss: 35.6222, Val Loss: 4.2334, F1 Micro: 0.7812, F1 Macro: 0.6621, Accuracy: 0.7812\n","Epoch 78, Train Loss: 36.8661, Val Loss: 19.4748, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 79, Train Loss: 21.0449, Val Loss: 4.5117, F1 Micro: 0.6146, F1 Macro: 0.5629, Accuracy: 0.6146\n","Epoch 80, Train Loss: 12.2428, Val Loss: 2.6090, F1 Micro: 0.8542, F1 Macro: 0.7375, Accuracy: 0.8542\n","Epoch 81, Train Loss: 12.5323, Val Loss: 6.9281, F1 Micro: 0.4167, F1 Macro: 0.4144, Accuracy: 0.4167\n","Epoch 82, Train Loss: 8.7024, Val Loss: 9.9136, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 83, Train Loss: 16.2000, Val Loss: 89.6542, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 84, Train Loss: 33.4354, Val Loss: 47.0453, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 85, Train Loss: 24.1569, Val Loss: 10.1533, F1 Micro: 0.5000, F1 Macro: 0.4891, Accuracy: 0.5000\n","Epoch 86, Train Loss: 22.5239, Val Loss: 7.5809, F1 Micro: 0.5104, F1 Macro: 0.4905, Accuracy: 0.5104\n","Epoch 87, Train Loss: 20.8561, Val Loss: 66.8972, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 88, Train Loss: 32.3099, Val Loss: 17.0873, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 89, Train Loss: 32.7048, Val Loss: 7.9481, F1 Micro: 0.7917, F1 Macro: 0.6719, Accuracy: 0.7917\n","Epoch 90, Train Loss: 13.2768, Val Loss: 5.0017, F1 Micro: 0.6458, F1 Macro: 0.5714, Accuracy: 0.6458\n","Epoch 91, Train Loss: 26.4388, Val Loss: 28.1142, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 92, Train Loss: 22.8435, Val Loss: 4.7054, F1 Micro: 0.7708, F1 Macro: 0.6648, Accuracy: 0.7708\n","Epoch 93, Train Loss: 10.0434, Val Loss: 3.8784, F1 Micro: 0.6354, F1 Macro: 0.5866, Accuracy: 0.6354\n","Epoch 94, Train Loss: 13.6969, Val Loss: 46.5247, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 95, Train Loss: 55.6848, Val Loss: 16.6978, F1 Micro: 0.3438, F1 Macro: 0.3437, Accuracy: 0.3438\n","Epoch 96, Train Loss: 12.9766, Val Loss: 24.5417, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 97, Train Loss: 29.9600, Val Loss: 6.8270, F1 Micro: 0.5417, F1 Macro: 0.5111, Accuracy: 0.5417\n","Epoch 98, Train Loss: 11.2131, Val Loss: 18.7827, F1 Micro: 0.2500, F1 Macro: 0.2381, Accuracy: 0.2500\n","Epoch 99, Train Loss: 9.7170, Val Loss: 15.9227, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 100, Train Loss: 19.3659, Val Loss: 4.5521, F1 Micro: 0.5521, F1 Macro: 0.5296, Accuracy: 0.5521\n","Epoch 101, Train Loss: 14.7554, Val Loss: 25.9453, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 102, Train Loss: 29.2326, Val Loss: 8.0019, F1 Micro: 0.8125, F1 Macro: 0.6444, Accuracy: 0.8125\n","Epoch 103, Train Loss: 9.3070, Val Loss: 2.7240, F1 Micro: 0.7812, F1 Macro: 0.6853, Accuracy: 0.7812\n","Epoch 104, Train Loss: 14.8700, Val Loss: 24.9292, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 105, Train Loss: 16.2106, Val Loss: 5.6758, F1 Micro: 0.4896, F1 Macro: 0.4800, Accuracy: 0.4896\n","Epoch 106, Train Loss: 24.4037, Val Loss: 20.5765, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 107, Train Loss: 9.5094, Val Loss: 13.4340, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 108, Train Loss: 20.1599, Val Loss: 45.8509, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 109, Train Loss: 62.7346, Val Loss: 38.1849, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 110, Train Loss: 25.1502, Val Loss: 6.9969, F1 Micro: 0.5938, F1 Macro: 0.5315, Accuracy: 0.5938\n","Epoch 111, Train Loss: 8.2361, Val Loss: 2.3327, F1 Micro: 0.7188, F1 Macro: 0.6301, Accuracy: 0.7188\n","Epoch 112, Train Loss: 11.7546, Val Loss: 7.4484, F1 Micro: 0.4167, F1 Macro: 0.4144, Accuracy: 0.4167\n","Epoch 113, Train Loss: 16.4608, Val Loss: 14.7692, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 114, Train Loss: 6.4586, Val Loss: 8.4033, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 115, Train Loss: 16.6991, Val Loss: 21.0903, F1 Micro: 0.2396, F1 Macro: 0.2254, Accuracy: 0.2396\n","Epoch 116, Train Loss: 22.3826, Val Loss: 5.4821, F1 Micro: 0.7500, F1 Macro: 0.6569, Accuracy: 0.7500\n","Epoch 117, Train Loss: 23.5508, Val Loss: 8.6201, F1 Micro: 0.7812, F1 Macro: 0.6621, Accuracy: 0.7812\n","Epoch 118, Train Loss: 14.9180, Val Loss: 25.5640, F1 Micro: 0.2500, F1 Macro: 0.2381, Accuracy: 0.2500\n","Epoch 119, Train Loss: 63.1536, Val Loss: 9.7401, F1 Micro: 0.5208, F1 Macro: 0.4943, Accuracy: 0.5208\n","Epoch 120, Train Loss: 13.4487, Val Loss: 6.0156, F1 Micro: 0.5521, F1 Macro: 0.5296, Accuracy: 0.5521\n","Epoch 121, Train Loss: 16.5657, Val Loss: 22.5844, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 122, Train Loss: 14.4912, Val Loss: 73.6010, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 123, Train Loss: 16.0358, Val Loss: 20.6271, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 124, Train Loss: 28.6876, Val Loss: 20.4474, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 125, Train Loss: 58.5850, Val Loss: 11.6790, F1 Micro: 0.4375, F1 Macro: 0.4336, Accuracy: 0.4375\n","Epoch 126, Train Loss: 12.8896, Val Loss: 10.3178, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 127, Train Loss: 7.1038, Val Loss: 11.8298, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 128, Train Loss: 14.5161, Val Loss: 4.5614, F1 Micro: 0.8646, F1 Macro: 0.7199, Accuracy: 0.8646\n","Epoch 129, Train Loss: 15.9320, Val Loss: 98.8190, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 130, Train Loss: 30.9261, Val Loss: 4.0903, F1 Micro: 0.8229, F1 Macro: 0.7154, Accuracy: 0.8229\n","Epoch 131, Train Loss: 24.3679, Val Loss: 5.1460, F1 Micro: 0.6250, F1 Macro: 0.5712, Accuracy: 0.6250\n","Epoch 132, Train Loss: 13.9005, Val Loss: 4.3749, F1 Micro: 0.6250, F1 Macro: 0.5553, Accuracy: 0.6250\n","Epoch 133, Train Loss: 43.3883, Val Loss: 5.8588, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 134, Train Loss: 14.3860, Val Loss: 18.1689, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 135, Train Loss: 18.5712, Val Loss: 33.6522, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 136, Train Loss: 20.4985, Val Loss: 17.9682, F1 Micro: 0.2604, F1 Macro: 0.2506, Accuracy: 0.2604\n","Epoch 137, Train Loss: 20.0468, Val Loss: 29.4693, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 138, Train Loss: 20.7026, Val Loss: 10.2000, F1 Micro: 0.8229, F1 Macro: 0.5455, Accuracy: 0.8229\n","Epoch 139, Train Loss: 15.4030, Val Loss: 21.4044, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 140, Train Loss: 23.4114, Val Loss: 48.4423, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 141, Train Loss: 31.6040, Val Loss: 28.5181, F1 Micro: 0.2396, F1 Macro: 0.2254, Accuracy: 0.2396\n","Epoch 142, Train Loss: 14.2115, Val Loss: 9.1793, F1 Micro: 0.3125, F1 Macro: 0.3113, Accuracy: 0.3125\n","Epoch 143, Train Loss: 22.6491, Val Loss: 108.5215, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 144, Train Loss: 23.4838, Val Loss: 4.5336, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 145, Train Loss: 7.8070, Val Loss: 2.6441, F1 Micro: 0.6458, F1 Macro: 0.6129, Accuracy: 0.6458\n","Epoch 146, Train Loss: 9.9867, Val Loss: 5.6820, F1 Micro: 0.8646, F1 Macro: 0.7011, Accuracy: 0.8646\n","Epoch 147, Train Loss: 13.2180, Val Loss: 4.7953, F1 Micro: 0.5938, F1 Macro: 0.5642, Accuracy: 0.5938\n","Epoch 148, Train Loss: 23.4941, Val Loss: 38.1506, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 149, Train Loss: 27.4102, Val Loss: 20.9834, F1 Micro: 0.2604, F1 Macro: 0.2539, Accuracy: 0.2604\n","Epoch 150, Train Loss: 14.4148, Val Loss: 12.0901, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 151, Train Loss: 35.9670, Val Loss: 76.0297, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 152, Train Loss: 23.4016, Val Loss: 25.1268, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 153, Train Loss: 32.9884, Val Loss: 6.3152, F1 Micro: 0.7708, F1 Macro: 0.6757, Accuracy: 0.7708\n","Epoch 154, Train Loss: 11.4695, Val Loss: 3.9079, F1 Micro: 0.8229, F1 Macro: 0.7265, Accuracy: 0.8229\n","Epoch 155, Train Loss: 7.3344, Val Loss: 4.0458, F1 Micro: 0.4583, F1 Macro: 0.4545, Accuracy: 0.4583\n","Epoch 156, Train Loss: 11.2378, Val Loss: 3.5633, F1 Micro: 0.6354, F1 Macro: 0.5988, Accuracy: 0.6354\n","Epoch 157, Train Loss: 42.4483, Val Loss: 11.2718, F1 Micro: 0.4688, F1 Macro: 0.4617, Accuracy: 0.4688\n","Epoch 158, Train Loss: 15.9200, Val Loss: 5.7577, F1 Micro: 0.8542, F1 Macro: 0.7375, Accuracy: 0.8542\n","Epoch 159, Train Loss: 17.3239, Val Loss: 28.3508, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 160, Train Loss: 12.2612, Val Loss: 7.2177, F1 Micro: 0.4688, F1 Macro: 0.4617, Accuracy: 0.4688\n","Epoch 161, Train Loss: 18.4922, Val Loss: 46.2649, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 162, Train Loss: 24.0737, Val Loss: 117.8007, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 163, Train Loss: 47.0703, Val Loss: 100.7097, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 164, Train Loss: 17.1099, Val Loss: 26.2804, F1 Micro: 0.2604, F1 Macro: 0.2539, Accuracy: 0.2604\n","Epoch 165, Train Loss: 27.7128, Val Loss: 14.0812, F1 Micro: 0.8333, F1 Macro: 0.6190, Accuracy: 0.8333\n","Epoch 166, Train Loss: 9.6207, Val Loss: 10.2640, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 167, Train Loss: 10.0109, Val Loss: 23.4630, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 168, Train Loss: 17.3693, Val Loss: 28.4221, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 169, Train Loss: 25.1635, Val Loss: 96.2710, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 170, Train Loss: 69.6428, Val Loss: 133.9506, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 171, Train Loss: 54.6816, Val Loss: 10.4958, F1 Micro: 0.5938, F1 Macro: 0.5530, Accuracy: 0.5938\n","Epoch 172, Train Loss: 32.5146, Val Loss: 7.4493, F1 Micro: 0.6042, F1 Macro: 0.5394, Accuracy: 0.6042\n","Epoch 173, Train Loss: 68.0083, Val Loss: 45.8923, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 174, Train Loss: 41.5484, Val Loss: 97.9759, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 175, Train Loss: 22.5971, Val Loss: 6.8260, F1 Micro: 0.5625, F1 Macro: 0.5383, Accuracy: 0.5625\n","Epoch 176, Train Loss: 8.9532, Val Loss: 24.4813, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 177, Train Loss: 30.3168, Val Loss: 133.4836, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 178, Train Loss: 33.4863, Val Loss: 22.2746, F1 Micro: 0.3542, F1 Macro: 0.3542, Accuracy: 0.3542\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 131.8264, Val Loss: 119.3312, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 2, Train Loss: 40.6753, Val Loss: 12.1084, F1 Micro: 0.1771, F1 Macro: 0.1661, Accuracy: 0.1771\n","Epoch 3, Train Loss: 25.4322, Val Loss: 53.4439, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 42.6887, Val Loss: 123.8810, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 5, Train Loss: 58.0607, Val Loss: 82.2327, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 22.9984, Val Loss: 31.3170, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 7, Train Loss: 15.4339, Val Loss: 36.1444, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 8, Train Loss: 10.6817, Val Loss: 16.9067, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 9, Train Loss: 25.5273, Val Loss: 38.0033, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 10, Train Loss: 17.5465, Val Loss: 54.9869, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 11, Train Loss: 58.0177, Val Loss: 8.7029, F1 Micro: 0.5521, F1 Macro: 0.4921, Accuracy: 0.5521\n","Epoch 12, Train Loss: 23.3329, Val Loss: 67.7232, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 20.9188, Val Loss: 12.8024, F1 Micro: 0.7708, F1 Macro: 0.4353, Accuracy: 0.7708\n","Epoch 14, Train Loss: 16.7018, Val Loss: 9.9398, F1 Micro: 0.7292, F1 Macro: 0.4217, Accuracy: 0.7292\n","Epoch 15, Train Loss: 19.3049, Val Loss: 22.9799, F1 Micro: 0.2083, F1 Macro: 0.2052, Accuracy: 0.2083\n","Epoch 16, Train Loss: 26.2557, Val Loss: 33.9285, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 17, Train Loss: 43.1423, Val Loss: 30.0883, F1 Micro: 0.1979, F1 Macro: 0.1936, Accuracy: 0.1979\n","Epoch 18, Train Loss: 23.0680, Val Loss: 12.4759, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 19, Train Loss: 45.9934, Val Loss: 116.4805, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 20, Train Loss: 33.3246, Val Loss: 11.8238, F1 Micro: 0.7083, F1 Macro: 0.4146, Accuracy: 0.7083\n","Epoch 21, Train Loss: 20.1497, Val Loss: 15.5943, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 22, Train Loss: 26.4587, Val Loss: 9.1195, F1 Micro: 0.6042, F1 Macro: 0.5105, Accuracy: 0.6042\n","Epoch 23, Train Loss: 13.3220, Val Loss: 18.1264, F1 Micro: 0.3333, F1 Macro: 0.3307, Accuracy: 0.3333\n","Epoch 24, Train Loss: 15.1184, Val Loss: 14.0159, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 25, Train Loss: 28.1797, Val Loss: 15.7913, F1 Micro: 0.2917, F1 Macro: 0.2914, Accuracy: 0.2917\n","Epoch 26, Train Loss: 41.7201, Val Loss: 10.5951, F1 Micro: 0.7188, F1 Macro: 0.4182, Accuracy: 0.7188\n","Epoch 27, Train Loss: 25.9154, Val Loss: 13.5487, F1 Micro: 0.4062, F1 Macro: 0.3952, Accuracy: 0.4062\n","Epoch 28, Train Loss: 45.7432, Val Loss: 86.0723, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 29, Train Loss: 22.0483, Val Loss: 10.2147, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Epoch 30, Train Loss: 18.5240, Val Loss: 15.2363, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 31, Train Loss: 30.3795, Val Loss: 53.3271, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 32, Train Loss: 17.2983, Val Loss: 8.3055, F1 Micro: 0.5104, F1 Macro: 0.4684, Accuracy: 0.5104\n","Epoch 33, Train Loss: 11.3714, Val Loss: 10.6880, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 34, Train Loss: 13.5483, Val Loss: 12.2169, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 35, Train Loss: 39.9051, Val Loss: 13.2138, F1 Micro: 0.3646, F1 Macro: 0.3589, Accuracy: 0.3646\n","Epoch 36, Train Loss: 22.5327, Val Loss: 31.3207, F1 Micro: 0.1875, F1 Macro: 0.1818, Accuracy: 0.1875\n","Epoch 37, Train Loss: 24.7843, Val Loss: 30.4797, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 38, Train Loss: 16.3902, Val Loss: 16.5779, F1 Micro: 0.2917, F1 Macro: 0.2914, Accuracy: 0.2917\n","Epoch 39, Train Loss: 55.2330, Val Loss: 177.5348, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 40, Train Loss: 61.1815, Val Loss: 10.5132, F1 Micro: 0.6771, F1 Macro: 0.4328, Accuracy: 0.6771\n","Epoch 41, Train Loss: 29.7193, Val Loss: 58.8054, F1 Micro: 0.1458, F1 Macro: 0.1323, Accuracy: 0.1458\n","Epoch 42, Train Loss: 37.2861, Val Loss: 14.2975, F1 Micro: 0.7292, F1 Macro: 0.4217, Accuracy: 0.7292\n","Epoch 43, Train Loss: 21.9146, Val Loss: 13.2348, F1 Micro: 0.4896, F1 Macro: 0.4585, Accuracy: 0.4896\n","Epoch 44, Train Loss: 56.4796, Val Loss: 44.2348, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 45, Train Loss: 27.3799, Val Loss: 30.2610, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 46, Train Loss: 19.8492, Val Loss: 11.8004, F1 Micro: 0.7188, F1 Macro: 0.4517, Accuracy: 0.7188\n","Epoch 47, Train Loss: 19.6647, Val Loss: 8.4323, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 48, Train Loss: 33.9750, Val Loss: 24.4875, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 49, Train Loss: 18.4125, Val Loss: 8.8486, F1 Micro: 0.6562, F1 Macro: 0.4476, Accuracy: 0.6562\n","Epoch 50, Train Loss: 13.2899, Val Loss: 55.8298, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 51, Train Loss: 52.0670, Val Loss: 15.9712, F1 Micro: 0.3958, F1 Macro: 0.3862, Accuracy: 0.3958\n","Epoch 52, Train Loss: 48.2619, Val Loss: 18.9703, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 53, Train Loss: 25.1575, Val Loss: 96.2458, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 56.1877, Val Loss: 25.2923, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 2, Train Loss: 36.1366, Val Loss: 5.3110, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 3, Train Loss: 44.1527, Val Loss: 20.3942, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 4, Train Loss: 29.3578, Val Loss: 11.1327, F1 Micro: 0.4271, F1 Macro: 0.4037, Accuracy: 0.4271\n","Epoch 5, Train Loss: 14.8850, Val Loss: 15.6297, F1 Micro: 0.2812, F1 Macro: 0.2805, Accuracy: 0.2812\n","Epoch 6, Train Loss: 35.7522, Val Loss: 19.3304, F1 Micro: 0.2708, F1 Macro: 0.2705, Accuracy: 0.2708\n","Epoch 7, Train Loss: 26.4573, Val Loss: 39.1269, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 8, Train Loss: 53.0456, Val Loss: 13.6001, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 9, Train Loss: 36.1329, Val Loss: 71.5489, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 10, Train Loss: 51.0217, Val Loss: 29.6312, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 11, Train Loss: 43.5249, Val Loss: 10.0688, F1 Micro: 0.5833, F1 Macro: 0.5236, Accuracy: 0.5833\n","Epoch 12, Train Loss: 26.2638, Val Loss: 53.2824, F1 Micro: 0.1354, F1 Macro: 0.1239, Accuracy: 0.1354\n","Epoch 13, Train Loss: 60.0050, Val Loss: 11.7032, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 14, Train Loss: 27.4066, Val Loss: 19.0285, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 15, Train Loss: 26.3573, Val Loss: 38.3844, F1 Micro: 0.1875, F1 Macro: 0.1843, Accuracy: 0.1875\n","Epoch 16, Train Loss: 41.2958, Val Loss: 32.9778, F1 Micro: 0.2396, F1 Macro: 0.2395, Accuracy: 0.2396\n","Epoch 17, Train Loss: 18.9270, Val Loss: 18.8359, F1 Micro: 0.3542, F1 Macro: 0.3471, Accuracy: 0.3542\n","Epoch 18, Train Loss: 24.8647, Val Loss: 5.5186, F1 Micro: 0.7917, F1 Macro: 0.6250, Accuracy: 0.7917\n","Epoch 19, Train Loss: 22.3389, Val Loss: 5.4107, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 20, Train Loss: 26.0317, Val Loss: 13.1806, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 21, Train Loss: 53.6678, Val Loss: 80.2811, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 22, Train Loss: 44.6819, Val Loss: 8.9581, F1 Micro: 0.5938, F1 Macro: 0.5315, Accuracy: 0.5938\n","Epoch 23, Train Loss: 31.2225, Val Loss: 20.2625, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 24, Train Loss: 31.1062, Val Loss: 24.1753, F1 Micro: 0.2812, F1 Macro: 0.2805, Accuracy: 0.2812\n","Epoch 25, Train Loss: 16.7980, Val Loss: 39.7610, F1 Micro: 0.1458, F1 Macro: 0.1365, Accuracy: 0.1458\n","Epoch 26, Train Loss: 27.6664, Val Loss: 17.6214, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 27, Train Loss: 19.8649, Val Loss: 5.3146, F1 Micro: 0.8542, F1 Macro: 0.6667, Accuracy: 0.8542\n","Epoch 28, Train Loss: 19.9629, Val Loss: 25.5212, F1 Micro: 0.1875, F1 Macro: 0.1843, Accuracy: 0.1875\n","Epoch 29, Train Loss: 36.0442, Val Loss: 4.3971, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 30, Train Loss: 23.1508, Val Loss: 53.1734, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 31, Train Loss: 36.4383, Val Loss: 13.9971, F1 Micro: 0.3958, F1 Macro: 0.3827, Accuracy: 0.3958\n","Epoch 32, Train Loss: 24.6979, Val Loss: 18.0353, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 33, Train Loss: 18.6298, Val Loss: 5.3129, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 34, Train Loss: 13.9557, Val Loss: 5.2728, F1 Micro: 0.5729, F1 Macro: 0.5157, Accuracy: 0.5729\n","Epoch 35, Train Loss: 19.1780, Val Loss: 26.6060, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 36, Train Loss: 40.7290, Val Loss: 3.3349, F1 Micro: 0.7917, F1 Macro: 0.6426, Accuracy: 0.7917\n","Epoch 37, Train Loss: 40.5140, Val Loss: 42.9979, F1 Micro: 0.1354, F1 Macro: 0.1239, Accuracy: 0.1354\n","Epoch 38, Train Loss: 21.2421, Val Loss: 10.9949, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 39, Train Loss: 40.3925, Val Loss: 101.5701, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 40, Train Loss: 40.6844, Val Loss: 54.4820, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 41, Train Loss: 20.8518, Val Loss: 37.9082, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 42, Train Loss: 15.8455, Val Loss: 33.3975, F1 Micro: 0.1562, F1 Macro: 0.1488, Accuracy: 0.1562\n","Epoch 43, Train Loss: 25.1144, Val Loss: 54.0322, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 44, Train Loss: 42.4540, Val Loss: 47.8217, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 45, Train Loss: 23.9257, Val Loss: 63.7454, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 46, Train Loss: 27.4166, Val Loss: 4.4306, F1 Micro: 0.7188, F1 Macro: 0.6082, Accuracy: 0.7188\n","Epoch 47, Train Loss: 17.1003, Val Loss: 9.7042, F1 Micro: 0.4479, F1 Macro: 0.4202, Accuracy: 0.4479\n","Epoch 48, Train Loss: 29.3942, Val Loss: 31.3408, F1 Micro: 0.1562, F1 Macro: 0.1488, Accuracy: 0.1562\n","Epoch 49, Train Loss: 36.1461, Val Loss: 25.7931, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 50, Train Loss: 17.6545, Val Loss: 21.5603, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 51, Train Loss: 25.7619, Val Loss: 10.2867, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 67.4358, Val Loss: 50.2988, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 2, Train Loss: 30.6226, Val Loss: 37.4370, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 3, Train Loss: 26.2602, Val Loss: 9.1962, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 41.8025, Val Loss: 17.1164, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 20.7541, Val Loss: 24.8990, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 6, Train Loss: 34.9820, Val Loss: 9.0427, F1 Micro: 0.4271, F1 Macro: 0.3779, Accuracy: 0.4271\n","Epoch 7, Train Loss: 24.5633, Val Loss: 29.7445, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 16.3266, Val Loss: 17.4989, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 12.4399, Val Loss: 14.9886, F1 Micro: 0.3021, F1 Macro: 0.2890, Accuracy: 0.3021\n","Epoch 10, Train Loss: 33.3584, Val Loss: 88.2952, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 11, Train Loss: 54.9891, Val Loss: 19.6716, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 12, Train Loss: 32.5047, Val Loss: 8.7109, F1 Micro: 0.5312, F1 Macro: 0.4386, Accuracy: 0.5312\n","Epoch 13, Train Loss: 28.3162, Val Loss: 34.9746, F1 Micro: 0.1771, F1 Macro: 0.1748, Accuracy: 0.1771\n","Epoch 14, Train Loss: 31.2438, Val Loss: 12.5206, F1 Micro: 0.4167, F1 Macro: 0.3705, Accuracy: 0.4167\n","Epoch 15, Train Loss: 20.4190, Val Loss: 15.6535, F1 Micro: 0.3333, F1 Macro: 0.3090, Accuracy: 0.3333\n","Epoch 16, Train Loss: 26.0275, Val Loss: 13.0519, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 17, Train Loss: 24.2864, Val Loss: 9.8354, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 18, Train Loss: 11.6266, Val Loss: 12.2506, F1 Micro: 0.3438, F1 Macro: 0.3170, Accuracy: 0.3438\n","Epoch 19, Train Loss: 20.0514, Val Loss: 40.5484, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 20, Train Loss: 19.6207, Val Loss: 10.4052, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 21, Train Loss: 24.6966, Val Loss: 12.2898, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 22, Train Loss: 35.8403, Val Loss: 48.3993, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 23, Train Loss: 28.6153, Val Loss: 26.3237, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 24, Train Loss: 16.8968, Val Loss: 11.0346, F1 Micro: 0.4167, F1 Macro: 0.3705, Accuracy: 0.4167\n","Epoch 25, Train Loss: 12.5815, Val Loss: 18.0640, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 26, Train Loss: 14.9641, Val Loss: 6.3326, F1 Micro: 0.5521, F1 Macro: 0.4635, Accuracy: 0.5521\n","Epoch 27, Train Loss: 21.7835, Val Loss: 29.7702, F1 Micro: 0.1458, F1 Macro: 0.1399, Accuracy: 0.1458\n","Epoch 28, Train Loss: 22.7780, Val Loss: 23.9910, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 29, Train Loss: 27.3380, Val Loss: 8.3504, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 30, Train Loss: 27.1008, Val Loss: 14.3427, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 31, Train Loss: 17.7852, Val Loss: 13.3763, F1 Micro: 0.3750, F1 Macro: 0.3404, Accuracy: 0.3750\n","Epoch 32, Train Loss: 44.2516, Val Loss: 17.9029, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 33, Train Loss: 20.0554, Val Loss: 29.0990, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 34, Train Loss: 21.6510, Val Loss: 18.6994, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 35, Train Loss: 25.8558, Val Loss: 108.4923, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 36, Train Loss: 54.2799, Val Loss: 17.4426, F1 Micro: 0.3229, F1 Macro: 0.3060, Accuracy: 0.3229\n","Epoch 37, Train Loss: 52.6745, Val Loss: 10.9509, F1 Micro: 0.5938, F1 Macro: 0.4657, Accuracy: 0.5938\n","Epoch 38, Train Loss: 16.6495, Val Loss: 34.2072, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 39, Train Loss: 34.8592, Val Loss: 10.0119, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 40, Train Loss: 31.9889, Val Loss: 15.8455, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 41, Train Loss: 35.8221, Val Loss: 24.1011, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 42, Train Loss: 60.7346, Val Loss: 54.1800, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 43, Train Loss: 73.8134, Val Loss: 19.3054, F1 Micro: 0.3750, F1 Macro: 0.3404, Accuracy: 0.3750\n","Epoch 44, Train Loss: 34.5033, Val Loss: 29.9366, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 45, Train Loss: 56.7935, Val Loss: 15.9738, F1 Micro: 0.5208, F1 Macro: 0.4424, Accuracy: 0.5208\n","Epoch 46, Train Loss: 28.6340, Val Loss: 40.6187, F1 Micro: 0.2083, F1 Macro: 0.2080, Accuracy: 0.2083\n","Epoch 47, Train Loss: 36.6127, Val Loss: 26.2776, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 48, Train Loss: 22.0866, Val Loss: 63.5057, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 49, Train Loss: 39.6885, Val Loss: 24.8502, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 50, Train Loss: 22.4230, Val Loss: 22.4959, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 51, Train Loss: 68.5295, Val Loss: 13.2946, F1 Micro: 0.5417, F1 Macro: 0.4454, Accuracy: 0.5417\n","Epoch 52, Train Loss: 18.2281, Val Loss: 11.2858, F1 Micro: 0.6458, F1 Macro: 0.4819, Accuracy: 0.6458\n","Epoch 53, Train Loss: 17.0477, Val Loss: 9.3027, F1 Micro: 0.6458, F1 Macro: 0.4819, Accuracy: 0.6458\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 149.9339, Val Loss: 65.2282, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 2, Train Loss: 63.3262, Val Loss: 123.7597, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 28.2823, Val Loss: 20.1192, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 15.3705, Val Loss: 30.0112, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 5, Train Loss: 38.0268, Val Loss: 54.8671, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 6, Train Loss: 29.8237, Val Loss: 5.3588, F1 Micro: 0.6562, F1 Macro: 0.5479, Accuracy: 0.6562\n","Epoch 7, Train Loss: 13.5802, Val Loss: 4.7063, F1 Micro: 0.5417, F1 Macro: 0.4667, Accuracy: 0.5417\n","Epoch 8, Train Loss: 29.3066, Val Loss: 5.9921, F1 Micro: 0.7188, F1 Macro: 0.5480, Accuracy: 0.7188\n","Epoch 9, Train Loss: 35.8734, Val Loss: 6.9233, F1 Micro: 0.5312, F1 Macro: 0.4594, Accuracy: 0.5312\n","Epoch 10, Train Loss: 34.5395, Val Loss: 67.3889, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 11, Train Loss: 25.0615, Val Loss: 7.9373, F1 Micro: 0.5417, F1 Macro: 0.4667, Accuracy: 0.5417\n","Epoch 12, Train Loss: 29.2439, Val Loss: 11.1064, F1 Micro: 0.7812, F1 Macro: 0.5961, Accuracy: 0.7812\n","Epoch 13, Train Loss: 29.0146, Val Loss: 64.5200, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 14, Train Loss: 29.1329, Val Loss: 8.8580, F1 Micro: 0.4688, F1 Macro: 0.4154, Accuracy: 0.4688\n","Epoch 15, Train Loss: 20.1263, Val Loss: 8.4001, F1 Micro: 0.4688, F1 Macro: 0.4301, Accuracy: 0.4688\n","Epoch 16, Train Loss: 23.9124, Val Loss: 6.2515, F1 Micro: 0.6771, F1 Macro: 0.5501, Accuracy: 0.6771\n","Epoch 17, Train Loss: 24.6710, Val Loss: 51.7864, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 18, Train Loss: 33.1995, Val Loss: 11.9822, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 19, Train Loss: 24.0965, Val Loss: 19.9695, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 25.1096, Val Loss: 7.7607, F1 Micro: 0.7292, F1 Macro: 0.5556, Accuracy: 0.7292\n","Epoch 21, Train Loss: 34.1300, Val Loss: 7.8909, F1 Micro: 0.5833, F1 Macro: 0.4958, Accuracy: 0.5833\n","Epoch 22, Train Loss: 32.8436, Val Loss: 9.0462, F1 Micro: 0.4896, F1 Macro: 0.4457, Accuracy: 0.4896\n","Epoch 23, Train Loss: 40.8273, Val Loss: 30.7172, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 24, Train Loss: 18.1580, Val Loss: 20.0003, F1 Micro: 0.3438, F1 Macro: 0.3420, Accuracy: 0.3438\n","Epoch 25, Train Loss: 20.3272, Val Loss: 8.5474, F1 Micro: 0.5625, F1 Macro: 0.4812, Accuracy: 0.5625\n","Epoch 26, Train Loss: 23.1734, Val Loss: 96.9777, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 27, Train Loss: 37.5326, Val Loss: 43.1716, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 28, Train Loss: 13.1208, Val Loss: 20.7648, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 29, Train Loss: 9.2553, Val Loss: 7.3706, F1 Micro: 0.8125, F1 Macro: 0.5714, Accuracy: 0.8125\n","Epoch 30, Train Loss: 16.4409, Val Loss: 7.9665, F1 Micro: 0.3854, F1 Macro: 0.3800, Accuracy: 0.3854\n","Epoch 31, Train Loss: 27.1905, Val Loss: 71.4548, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 32, Train Loss: 22.5231, Val Loss: 5.9404, F1 Micro: 0.7292, F1 Macro: 0.5556, Accuracy: 0.7292\n","Epoch 33, Train Loss: 21.5683, Val Loss: 32.7633, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 34, Train Loss: 29.9505, Val Loss: 6.1759, F1 Micro: 0.5938, F1 Macro: 0.5031, Accuracy: 0.5938\n","Epoch 35, Train Loss: 19.4744, Val Loss: 34.5013, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 36, Train Loss: 42.8849, Val Loss: 26.3087, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 37, Train Loss: 19.0624, Val Loss: 12.7569, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 38, Train Loss: 28.3580, Val Loss: 21.6492, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 39, Train Loss: 38.9972, Val Loss: 17.4312, F1 Micro: 0.3646, F1 Macro: 0.3612, Accuracy: 0.3646\n","Epoch 40, Train Loss: 17.4937, Val Loss: 59.9248, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 41, Train Loss: 28.9242, Val Loss: 51.1036, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 42, Train Loss: 35.0935, Val Loss: 49.2619, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 43, Train Loss: 61.0230, Val Loss: 28.5694, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 44, Train Loss: 21.5314, Val Loss: 35.8949, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 45, Train Loss: 27.6228, Val Loss: 75.2019, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 46, Train Loss: 29.6405, Val Loss: 13.4483, F1 Micro: 0.3854, F1 Macro: 0.3800, Accuracy: 0.3854\n","Epoch 47, Train Loss: 35.8355, Val Loss: 16.3558, F1 Micro: 0.3021, F1 Macro: 0.3020, Accuracy: 0.3021\n","Epoch 48, Train Loss: 18.0025, Val Loss: 9.5898, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 49, Train Loss: 38.1743, Val Loss: 21.2720, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 50, Train Loss: 18.7177, Val Loss: 86.1358, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 51, Train Loss: 46.1154, Val Loss: 6.6990, F1 Micro: 0.6354, F1 Macro: 0.5327, Accuracy: 0.6354\n","Epoch 52, Train Loss: 30.4138, Val Loss: 16.3293, F1 Micro: 0.3333, F1 Macro: 0.3322, Accuracy: 0.3333\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.8645833333333333\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 65.4931, Val Loss: 94.6414, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 2, Train Loss: 72.5002, Val Loss: 142.0971, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 3, Train Loss: 44.9317, Val Loss: 18.2632, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 11.0014, Val Loss: 17.5064, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 19.6315, Val Loss: 18.8828, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 6, Train Loss: 11.8839, Val Loss: 3.2239, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 7, Train Loss: 8.3513, Val Loss: 4.6683, F1 Micro: 0.4583, F1 Macro: 0.4497, Accuracy: 0.4583\n","Epoch 8, Train Loss: 15.7014, Val Loss: 11.3113, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 9, Train Loss: 35.6206, Val Loss: 28.0984, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 10, Train Loss: 11.3618, Val Loss: 10.3739, F1 Micro: 0.2917, F1 Macro: 0.2889, Accuracy: 0.2917\n","Epoch 11, Train Loss: 11.4260, Val Loss: 8.0629, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 28.7529, Val Loss: 16.5710, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 2, Train Loss: 28.3301, Val Loss: 100.4547, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 33.0647, Val Loss: 13.0941, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 4, Train Loss: 22.0712, Val Loss: 41.3350, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 5, Train Loss: 23.9035, Val Loss: 83.9299, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 6, Train Loss: 57.7975, Val Loss: 49.1928, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 7, Train Loss: 30.3083, Val Loss: 12.7034, F1 Micro: 0.4271, F1 Macro: 0.4127, Accuracy: 0.4271\n","Epoch 8, Train Loss: 19.9780, Val Loss: 11.2232, F1 Micro: 0.7188, F1 Macro: 0.4182, Accuracy: 0.7188\n","Epoch 9, Train Loss: 9.8109, Val Loss: 9.7118, F1 Micro: 0.7083, F1 Macro: 0.4146, Accuracy: 0.7083\n","Epoch 10, Train Loss: 9.9321, Val Loss: 21.4629, F1 Micro: 0.2188, F1 Macro: 0.2166, Accuracy: 0.2188\n","Epoch 11, Train Loss: 14.7074, Val Loss: 22.3689, F1 Micro: 0.1979, F1 Macro: 0.1936, Accuracy: 0.1979\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 22.7146, Val Loss: 4.3358, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 2, Train Loss: 11.7617, Val Loss: 8.3469, F1 Micro: 0.2292, F1 Macro: 0.2288, Accuracy: 0.2292\n","Epoch 3, Train Loss: 16.1510, Val Loss: 2.6421, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 4, Train Loss: 15.3891, Val Loss: 41.7061, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 5, Train Loss: 54.4650, Val Loss: 14.2153, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 6, Train Loss: 12.1920, Val Loss: 3.1427, F1 Micro: 0.7396, F1 Macro: 0.6123, Accuracy: 0.7396\n","Epoch 7, Train Loss: 29.2945, Val Loss: 16.8613, F1 Micro: 0.2292, F1 Macro: 0.2288, Accuracy: 0.2292\n","Epoch 8, Train Loss: 26.5736, Val Loss: 12.2788, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 9, Train Loss: 17.7225, Val Loss: 6.6624, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 10, Train Loss: 10.5246, Val Loss: 3.3704, F1 Micro: 0.7292, F1 Macro: 0.5895, Accuracy: 0.7292\n","Epoch 11, Train Loss: 8.4704, Val Loss: 10.9321, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 12, Train Loss: 10.1686, Val Loss: 4.2329, F1 Micro: 0.6354, F1 Macro: 0.5634, Accuracy: 0.6354\n","Epoch 13, Train Loss: 24.6116, Val Loss: 22.7224, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 14, Train Loss: 29.4946, Val Loss: 5.8040, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 52.9762, Val Loss: 16.3019, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 2, Train Loss: 9.8753, Val Loss: 3.4486, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 3, Train Loss: 18.0727, Val Loss: 31.8518, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 4, Train Loss: 19.8928, Val Loss: 4.9643, F1 Micro: 0.6562, F1 Macro: 0.4883, Accuracy: 0.6562\n","Epoch 5, Train Loss: 6.2061, Val Loss: 7.1287, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 6, Train Loss: 12.7143, Val Loss: 25.3539, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 7, Train Loss: 27.6172, Val Loss: 32.6022, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 8, Train Loss: 22.8520, Val Loss: 19.2361, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 43.9925, Val Loss: 54.4623, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 10, Train Loss: 30.9253, Val Loss: 18.5090, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 11, Train Loss: 15.1657, Val Loss: 11.6322, F1 Micro: 0.4062, F1 Macro: 0.3631, Accuracy: 0.4062\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 236.6703, Val Loss: 71.1846, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 50.4672, Val Loss: 52.5364, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 21.8192, Val Loss: 107.3459, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 4, Train Loss: 23.6185, Val Loss: 14.7634, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 5, Train Loss: 6.5936, Val Loss: 8.4903, F1 Micro: 0.2292, F1 Macro: 0.2238, Accuracy: 0.2292\n","Epoch 6, Train Loss: 15.0249, Val Loss: 4.5390, F1 Micro: 0.3646, F1 Macro: 0.3589, Accuracy: 0.3646\n","Epoch 7, Train Loss: 7.3105, Val Loss: 3.3225, F1 Micro: 0.4688, F1 Macro: 0.4301, Accuracy: 0.4688\n","Epoch 8, Train Loss: 7.9717, Val Loss: 3.4095, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 9, Train Loss: 13.9467, Val Loss: 11.4993, F1 Micro: 0.1979, F1 Macro: 0.1872, Accuracy: 0.1979\n","Epoch 10, Train Loss: 28.0791, Val Loss: 3.5680, F1 Micro: 0.5000, F1 Macro: 0.4375, Accuracy: 0.5000\n","Epoch 11, Train Loss: 27.9986, Val Loss: 7.8804, F1 Micro: 0.3542, F1 Macro: 0.3516, Accuracy: 0.3542\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.8541666666666666\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 70.8695, Val Loss: 8.3488, F1 Micro: 0.7917, F1 Macro: 0.6426, Accuracy: 0.7917\n","Epoch 2, Train Loss: 17.5817, Val Loss: 7.3521, F1 Micro: 0.7500, F1 Macro: 0.6063, Accuracy: 0.7500\n","Epoch 3, Train Loss: 11.1254, Val Loss: 26.3062, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 4, Train Loss: 24.4003, Val Loss: 27.5597, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 5, Train Loss: 22.3713, Val Loss: 62.7493, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 6, Train Loss: 13.5203, Val Loss: 20.1626, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 7, Train Loss: 14.2902, Val Loss: 28.4350, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 8, Train Loss: 14.5434, Val Loss: 5.1634, F1 Micro: 0.5104, F1 Macro: 0.4858, Accuracy: 0.5104\n","Epoch 9, Train Loss: 11.3718, Val Loss: 30.8923, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 10, Train Loss: 15.6214, Val Loss: 25.2224, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 11, Train Loss: 15.6085, Val Loss: 7.0027, F1 Micro: 0.3750, F1 Macro: 0.3747, Accuracy: 0.3750\n","Epoch 12, Train Loss: 14.6327, Val Loss: 32.4019, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 13, Train Loss: 11.5168, Val Loss: 23.2480, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 14, Train Loss: 15.2079, Val Loss: 56.9623, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 15, Train Loss: 25.7952, Val Loss: 4.7415, F1 Micro: 0.5104, F1 Macro: 0.4858, Accuracy: 0.5104\n","Epoch 16, Train Loss: 20.0435, Val Loss: 108.3557, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 17, Train Loss: 48.3740, Val Loss: 14.0250, F1 Micro: 0.2917, F1 Macro: 0.2889, Accuracy: 0.2917\n","Epoch 18, Train Loss: 14.1746, Val Loss: 25.6299, F1 Micro: 0.2188, F1 Macro: 0.1992, Accuracy: 0.2188\n","Epoch 19, Train Loss: 16.3676, Val Loss: 19.6556, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 20, Train Loss: 15.5702, Val Loss: 10.2833, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 21, Train Loss: 8.4479, Val Loss: 4.6020, F1 Micro: 0.7500, F1 Macro: 0.6343, Accuracy: 0.7500\n","Epoch 22, Train Loss: 10.9288, Val Loss: 7.1228, F1 Micro: 0.3646, F1 Macro: 0.3645, Accuracy: 0.3646\n","Epoch 23, Train Loss: 17.7318, Val Loss: 21.1569, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 24, Train Loss: 33.8409, Val Loss: 10.6437, F1 Micro: 0.7917, F1 Macro: 0.4866, Accuracy: 0.7917\n","Epoch 25, Train Loss: 7.9411, Val Loss: 7.8555, F1 Micro: 0.8125, F1 Macro: 0.5996, Accuracy: 0.8125\n","Epoch 26, Train Loss: 16.2598, Val Loss: 70.6194, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 27, Train Loss: 50.2217, Val Loss: 69.3959, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 28, Train Loss: 34.0418, Val Loss: 46.1313, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 29, Train Loss: 32.3517, Val Loss: 18.1557, F1 Micro: 0.2917, F1 Macro: 0.2889, Accuracy: 0.2917\n","Epoch 30, Train Loss: 14.6246, Val Loss: 6.0376, F1 Micro: 0.6562, F1 Macro: 0.5796, Accuracy: 0.6562\n","Epoch 31, Train Loss: 18.4868, Val Loss: 33.2077, F1 Micro: 0.1979, F1 Macro: 0.1720, Accuracy: 0.1979\n","Epoch 32, Train Loss: 17.1406, Val Loss: 34.5879, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 33, Train Loss: 24.8987, Val Loss: 18.5787, F1 Micro: 0.2604, F1 Macro: 0.2539, Accuracy: 0.2604\n","Epoch 34, Train Loss: 27.1244, Val Loss: 27.3907, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 35, Train Loss: 11.5046, Val Loss: 10.0470, F1 Micro: 0.4479, F1 Macro: 0.4430, Accuracy: 0.4479\n","Epoch 36, Train Loss: 10.0385, Val Loss: 18.5208, F1 Micro: 0.8125, F1 Macro: 0.4977, Accuracy: 0.8125\n","Epoch 37, Train Loss: 13.8403, Val Loss: 12.1093, F1 Micro: 0.2917, F1 Macro: 0.2889, Accuracy: 0.2917\n","Epoch 38, Train Loss: 23.5676, Val Loss: 15.1821, F1 Micro: 0.8021, F1 Macro: 0.4921, Accuracy: 0.8021\n","Epoch 39, Train Loss: 7.9468, Val Loss: 4.0545, F1 Micro: 0.7188, F1 Macro: 0.6197, Accuracy: 0.7188\n","Epoch 40, Train Loss: 24.6042, Val Loss: 16.5648, F1 Micro: 0.2500, F1 Macro: 0.2418, Accuracy: 0.2500\n","Epoch 41, Train Loss: 33.9748, Val Loss: 56.0840, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 42, Train Loss: 30.3298, Val Loss: 23.1440, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 43, Train Loss: 21.0462, Val Loss: 7.0264, F1 Micro: 0.7604, F1 Macro: 0.6150, Accuracy: 0.7604\n","Epoch 44, Train Loss: 16.5403, Val Loss: 33.2329, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 45, Train Loss: 15.2184, Val Loss: 76.7200, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 46, Train Loss: 34.4883, Val Loss: 26.8264, F1 Micro: 0.2292, F1 Macro: 0.2124, Accuracy: 0.2292\n","Epoch 47, Train Loss: 30.3809, Val Loss: 6.7046, F1 Micro: 0.7604, F1 Macro: 0.6150, Accuracy: 0.7604\n","Epoch 48, Train Loss: 22.8958, Val Loss: 10.1967, F1 Micro: 0.8125, F1 Macro: 0.6237, Accuracy: 0.8125\n","Epoch 49, Train Loss: 11.2263, Val Loss: 5.1831, F1 Micro: 0.5833, F1 Macro: 0.5236, Accuracy: 0.5833\n","Epoch 50, Train Loss: 41.1837, Val Loss: 87.1466, F1 Micro: 0.1875, F1 Macro: 0.1579, Accuracy: 0.1875\n","Epoch 51, Train Loss: 38.8825, Val Loss: 34.8468, F1 Micro: 0.2083, F1 Macro: 0.1857, Accuracy: 0.2083\n","Epoch 52, Train Loss: 32.4686, Val Loss: 30.6784, F1 Micro: 0.8125, F1 Macro: 0.4483, Accuracy: 0.8125\n","Epoch 53, Train Loss: 31.2237, Val Loss: 35.1097, F1 Micro: 0.2188, F1 Macro: 0.1992, Accuracy: 0.2188\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 149.3995, Val Loss: 10.1323, F1 Micro: 0.2812, F1 Macro: 0.2812, Accuracy: 0.2812\n","Epoch 2, Train Loss: 9.6098, Val Loss: 18.0866, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 3, Train Loss: 14.8617, Val Loss: 4.4908, F1 Micro: 0.6354, F1 Macro: 0.4141, Accuracy: 0.6354\n","Epoch 4, Train Loss: 10.5614, Val Loss: 60.6230, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 5, Train Loss: 54.6204, Val Loss: 31.6082, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 6, Train Loss: 13.2932, Val Loss: 6.9679, F1 Micro: 0.6875, F1 Macro: 0.4074, Accuracy: 0.6875\n","Epoch 7, Train Loss: 6.8167, Val Loss: 8.7591, F1 Micro: 0.7812, F1 Macro: 0.4386, Accuracy: 0.7812\n","Epoch 8, Train Loss: 18.8592, Val Loss: 46.5457, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 9, Train Loss: 10.6954, Val Loss: 18.7696, F1 Micro: 0.1979, F1 Macro: 0.1936, Accuracy: 0.1979\n","Epoch 10, Train Loss: 8.7921, Val Loss: 20.4264, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 11, Train Loss: 17.1309, Val Loss: 66.3125, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 12, Train Loss: 53.2497, Val Loss: 33.7359, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 13, Train Loss: 26.1611, Val Loss: 6.9740, F1 Micro: 0.6354, F1 Macro: 0.4369, Accuracy: 0.6354\n","Epoch 14, Train Loss: 12.4629, Val Loss: 17.2800, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 15, Train Loss: 10.6453, Val Loss: 24.9502, F1 Micro: 0.1979, F1 Macro: 0.1936, Accuracy: 0.1979\n","Epoch 16, Train Loss: 8.5739, Val Loss: 8.5047, F1 Micro: 0.4375, F1 Macro: 0.4214, Accuracy: 0.4375\n","Epoch 17, Train Loss: 12.1651, Val Loss: 20.4217, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 18, Train Loss: 11.1791, Val Loss: 19.6683, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 19, Train Loss: 19.5422, Val Loss: 7.2217, F1 Micro: 0.7083, F1 Macro: 0.4146, Accuracy: 0.7083\n","Epoch 20, Train Loss: 10.2869, Val Loss: 29.4123, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 21, Train Loss: 22.3173, Val Loss: 70.8194, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 22, Train Loss: 42.4518, Val Loss: 11.4726, F1 Micro: 0.3542, F1 Macro: 0.3497, Accuracy: 0.3542\n","Epoch 23, Train Loss: 42.2842, Val Loss: 34.0343, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 24, Train Loss: 42.2475, Val Loss: 7.8499, F1 Micro: 0.5729, F1 Macro: 0.5074, Accuracy: 0.5729\n","Epoch 25, Train Loss: 17.9998, Val Loss: 6.6949, F1 Micro: 0.6354, F1 Macro: 0.4921, Accuracy: 0.6354\n","Epoch 26, Train Loss: 12.7646, Val Loss: 22.5474, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 27, Train Loss: 11.2200, Val Loss: 6.2687, F1 Micro: 0.6146, F1 Macro: 0.5178, Accuracy: 0.6146\n","Epoch 28, Train Loss: 9.7473, Val Loss: 27.2648, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 29, Train Loss: 11.2362, Val Loss: 33.7800, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 30, Train Loss: 18.9322, Val Loss: 6.3839, F1 Micro: 0.5521, F1 Macro: 0.4921, Accuracy: 0.5521\n","Epoch 31, Train Loss: 10.3801, Val Loss: 6.1119, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Epoch 32, Train Loss: 8.6050, Val Loss: 32.0602, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 33, Train Loss: 57.9564, Val Loss: 104.2929, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 34, Train Loss: 32.4189, Val Loss: 13.3714, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 35, Train Loss: 8.8919, Val Loss: 51.2474, F1 Micro: 0.1458, F1 Macro: 0.1273, Accuracy: 0.1458\n","Epoch 36, Train Loss: 14.1505, Val Loss: 11.3088, F1 Micro: 0.3854, F1 Macro: 0.3772, Accuracy: 0.3854\n","Epoch 37, Train Loss: 18.0603, Val Loss: 11.7572, F1 Micro: 0.3646, F1 Macro: 0.3589, Accuracy: 0.3646\n","Epoch 38, Train Loss: 20.5949, Val Loss: 27.4126, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 39, Train Loss: 12.7419, Val Loss: 23.0147, F1 Micro: 0.2188, F1 Macro: 0.2166, Accuracy: 0.2188\n","Epoch 40, Train Loss: 16.1996, Val Loss: 33.8324, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 41, Train Loss: 21.1431, Val Loss: 38.5980, F1 Micro: 0.1562, F1 Macro: 0.1405, Accuracy: 0.1562\n","Epoch 42, Train Loss: 16.5717, Val Loss: 35.2201, F1 Micro: 0.1562, F1 Macro: 0.1450, Accuracy: 0.1562\n","Epoch 43, Train Loss: 13.5186, Val Loss: 15.1609, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 44, Train Loss: 17.6518, Val Loss: 20.2101, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 45, Train Loss: 23.3269, Val Loss: 22.8049, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 46, Train Loss: 21.6468, Val Loss: 23.3442, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 47, Train Loss: 13.4992, Val Loss: 6.5372, F1 Micro: 0.6562, F1 Macro: 0.4476, Accuracy: 0.6562\n","Epoch 48, Train Loss: 6.3543, Val Loss: 4.9999, F1 Micro: 0.6667, F1 Macro: 0.4530, Accuracy: 0.6667\n","Epoch 49, Train Loss: 18.0980, Val Loss: 4.8343, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Epoch 50, Train Loss: 11.5534, Val Loss: 5.4019, F1 Micro: 0.5417, F1 Macro: 0.4844, Accuracy: 0.5417\n","Epoch 51, Train Loss: 30.5013, Val Loss: 10.8391, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 52, Train Loss: 18.9235, Val Loss: 6.6450, F1 Micro: 0.5625, F1 Macro: 0.4998, Accuracy: 0.5625\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 274.6403, Val Loss: 131.6760, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 2, Train Loss: 91.1996, Val Loss: 28.8142, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 3, Train Loss: 34.2648, Val Loss: 29.9230, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 4, Train Loss: 20.1073, Val Loss: 12.5793, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 5, Train Loss: 12.7156, Val Loss: 15.5328, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 6, Train Loss: 45.7891, Val Loss: 42.5646, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 7, Train Loss: 27.0884, Val Loss: 35.1374, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 8, Train Loss: 9.4306, Val Loss: 2.4282, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 9, Train Loss: 10.6621, Val Loss: 45.4988, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 10, Train Loss: 37.4487, Val Loss: 3.4507, F1 Micro: 0.8542, F1 Macro: 0.6093, Accuracy: 0.8542\n","Epoch 11, Train Loss: 12.4035, Val Loss: 56.1211, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 12, Train Loss: 71.0885, Val Loss: 44.4075, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 13, Train Loss: 45.0822, Val Loss: 3.4422, F1 Micro: 0.7708, F1 Macro: 0.6069, Accuracy: 0.7708\n","Epoch 14, Train Loss: 8.6115, Val Loss: 5.5097, F1 Micro: 0.5729, F1 Macro: 0.5157, Accuracy: 0.5729\n","Epoch 15, Train Loss: 8.5443, Val Loss: 2.6574, F1 Micro: 0.7188, F1 Macro: 0.6082, Accuracy: 0.7188\n","Epoch 16, Train Loss: 13.3109, Val Loss: 2.9777, F1 Micro: 0.6771, F1 Macro: 0.5960, Accuracy: 0.6771\n","Epoch 17, Train Loss: 22.8552, Val Loss: 10.1942, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 18, Train Loss: 13.6651, Val Loss: 25.7333, F1 Micro: 0.1354, F1 Macro: 0.1239, Accuracy: 0.1354\n","Epoch 19, Train Loss: 7.8350, Val Loss: 12.3740, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 20, Train Loss: 25.4412, Val Loss: 15.5965, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 21, Train Loss: 35.9565, Val Loss: 8.2824, F1 Micro: 0.4167, F1 Macro: 0.4000, Accuracy: 0.4167\n","Epoch 22, Train Loss: 20.7404, Val Loss: 3.6522, F1 Micro: 0.8333, F1 Macro: 0.6441, Accuracy: 0.8333\n","Epoch 23, Train Loss: 12.8755, Val Loss: 14.1679, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 24, Train Loss: 40.0082, Val Loss: 10.2222, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 25, Train Loss: 28.9635, Val Loss: 15.2582, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 26, Train Loss: 9.3691, Val Loss: 3.3455, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 27, Train Loss: 18.4606, Val Loss: 13.9962, F1 Micro: 0.2292, F1 Macro: 0.2288, Accuracy: 0.2292\n","Epoch 28, Train Loss: 28.2569, Val Loss: 4.4345, F1 Micro: 0.6146, F1 Macro: 0.5473, Accuracy: 0.6146\n","Epoch 29, Train Loss: 24.1851, Val Loss: 9.6324, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 30, Train Loss: 14.2760, Val Loss: 2.9776, F1 Micro: 0.7917, F1 Macro: 0.6250, Accuracy: 0.7917\n","Epoch 31, Train Loss: 30.5549, Val Loss: 14.5399, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 32, Train Loss: 26.9428, Val Loss: 10.2213, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 33, Train Loss: 15.1059, Val Loss: 7.7956, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 34, Train Loss: 13.5665, Val Loss: 3.9424, F1 Micro: 0.8438, F1 Macro: 0.6295, Accuracy: 0.8438\n","Epoch 35, Train Loss: 17.7336, Val Loss: 24.1032, F1 Micro: 0.1667, F1 Macro: 0.1608, Accuracy: 0.1667\n","Epoch 36, Train Loss: 21.5110, Val Loss: 5.5600, F1 Micro: 0.5938, F1 Macro: 0.5315, Accuracy: 0.5938\n","Epoch 37, Train Loss: 14.9741, Val Loss: 23.0943, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 38, Train Loss: 27.0185, Val Loss: 6.2110, F1 Micro: 0.8438, F1 Macro: 0.5160, Accuracy: 0.8438\n","Epoch 39, Train Loss: 22.5356, Val Loss: 32.5961, F1 Micro: 0.1562, F1 Macro: 0.1488, Accuracy: 0.1562\n","Epoch 40, Train Loss: 14.9690, Val Loss: 13.8231, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 41, Train Loss: 14.1062, Val Loss: 4.0537, F1 Micro: 0.7917, F1 Macro: 0.6250, Accuracy: 0.7917\n","Epoch 42, Train Loss: 10.7192, Val Loss: 14.6517, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 43, Train Loss: 10.3674, Val Loss: 7.3864, F1 Micro: 0.8542, F1 Macro: 0.5227, Accuracy: 0.8542\n","Epoch 44, Train Loss: 10.3071, Val Loss: 67.3001, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 45, Train Loss: 44.8999, Val Loss: 72.8194, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 46, Train Loss: 14.3324, Val Loss: 3.6343, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 47, Train Loss: 5.5056, Val Loss: 2.2549, F1 Micro: 0.8021, F1 Macro: 0.6345, Accuracy: 0.8021\n","Epoch 48, Train Loss: 14.6275, Val Loss: 36.9962, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 49, Train Loss: 56.7593, Val Loss: 81.5305, F1 Micro: 0.1250, F1 Macro: 0.1111, Accuracy: 0.1250\n","Epoch 50, Train Loss: 55.8087, Val Loss: 16.8837, F1 Micro: 0.2188, F1 Macro: 0.2180, Accuracy: 0.2188\n","Epoch 51, Train Loss: 26.1361, Val Loss: 19.6772, F1 Micro: 0.2188, F1 Macro: 0.2180, Accuracy: 0.2188\n","Epoch 52, Train Loss: 13.9957, Val Loss: 15.8469, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 53, Train Loss: 18.3453, Val Loss: 4.0566, F1 Micro: 0.8542, F1 Macro: 0.6406, Accuracy: 0.8542\n","Epoch 54, Train Loss: 41.1100, Val Loss: 4.2526, F1 Micro: 0.6875, F1 Macro: 0.5944, Accuracy: 0.6875\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 135.1079, Val Loss: 40.6110, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 2, Train Loss: 36.1987, Val Loss: 11.3083, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 3, Train Loss: 10.5424, Val Loss: 2.4194, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 4, Train Loss: 28.0961, Val Loss: 29.9900, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 5, Train Loss: 16.1867, Val Loss: 29.0381, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 6, Train Loss: 19.5373, Val Loss: 58.5393, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 7, Train Loss: 47.3603, Val Loss: 32.5455, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 8, Train Loss: 33.4445, Val Loss: 26.8272, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 9, Train Loss: 34.6399, Val Loss: 47.0205, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 10, Train Loss: 56.7819, Val Loss: 87.5192, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 11, Train Loss: 58.0802, Val Loss: 32.5066, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 12, Train Loss: 15.2843, Val Loss: 18.7625, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 13, Train Loss: 15.1170, Val Loss: 14.4088, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 14, Train Loss: 14.8220, Val Loss: 28.9475, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 15, Train Loss: 20.3398, Val Loss: 13.4413, F1 Micro: 0.3438, F1 Macro: 0.3170, Accuracy: 0.3438\n","Epoch 16, Train Loss: 19.8374, Val Loss: 24.0710, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 17, Train Loss: 25.5729, Val Loss: 8.5595, F1 Micro: 0.6146, F1 Macro: 0.4788, Accuracy: 0.6146\n","Epoch 18, Train Loss: 15.7807, Val Loss: 8.1029, F1 Micro: 0.6771, F1 Macro: 0.5013, Accuracy: 0.6771\n","Epoch 19, Train Loss: 39.0697, Val Loss: 15.8891, F1 Micro: 0.3333, F1 Macro: 0.3143, Accuracy: 0.3333\n","Epoch 20, Train Loss: 36.3810, Val Loss: 26.6143, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 21, Train Loss: 28.7713, Val Loss: 81.6002, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Epoch 22, Train Loss: 42.8775, Val Loss: 30.5532, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 23, Train Loss: 18.0406, Val Loss: 17.4583, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 24, Train Loss: 20.4091, Val Loss: 9.8770, F1 Micro: 0.5521, F1 Macro: 0.4522, Accuracy: 0.5521\n","Epoch 25, Train Loss: 38.5331, Val Loss: 56.5966, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 26, Train Loss: 34.4717, Val Loss: 10.5461, F1 Micro: 0.7083, F1 Macro: 0.5214, Accuracy: 0.7083\n","Epoch 27, Train Loss: 15.1635, Val Loss: 12.2380, F1 Micro: 0.7812, F1 Macro: 0.4813, Accuracy: 0.7812\n","Epoch 28, Train Loss: 15.4479, Val Loss: 20.4000, F1 Micro: 0.3021, F1 Macro: 0.2890, Accuracy: 0.3021\n","Epoch 29, Train Loss: 17.8649, Val Loss: 9.0638, F1 Micro: 0.6875, F1 Macro: 0.5079, Accuracy: 0.6875\n","Epoch 30, Train Loss: 11.1130, Val Loss: 8.7045, F1 Micro: 0.5729, F1 Macro: 0.4657, Accuracy: 0.5729\n","Epoch 31, Train Loss: 19.5375, Val Loss: 7.5923, F1 Micro: 0.7083, F1 Macro: 0.5214, Accuracy: 0.7083\n","Epoch 32, Train Loss: 25.3765, Val Loss: 18.7024, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 33, Train Loss: 17.1358, Val Loss: 9.3800, F1 Micro: 0.5104, F1 Macro: 0.4354, Accuracy: 0.5104\n","Epoch 34, Train Loss: 9.9554, Val Loss: 7.6726, F1 Micro: 0.5104, F1 Macro: 0.4354, Accuracy: 0.5104\n","Epoch 35, Train Loss: 24.3451, Val Loss: 11.9030, F1 Micro: 0.8646, F1 Macro: 0.4637, Accuracy: 0.8646\n","Epoch 36, Train Loss: 35.8790, Val Loss: 36.1615, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 37, Train Loss: 10.6416, Val Loss: 6.7587, F1 Micro: 0.6250, F1 Macro: 0.4693, Accuracy: 0.6250\n","Epoch 38, Train Loss: 9.7061, Val Loss: 8.2464, F1 Micro: 0.8229, F1 Macro: 0.5035, Accuracy: 0.8229\n","Epoch 39, Train Loss: 9.9540, Val Loss: 10.9136, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 40, Train Loss: 15.9557, Val Loss: 9.2318, F1 Micro: 0.8542, F1 Macro: 0.4607, Accuracy: 0.8542\n","Epoch 41, Train Loss: 16.7053, Val Loss: 37.3744, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 42, Train Loss: 14.0554, Val Loss: 25.0194, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 43, Train Loss: 8.7361, Val Loss: 4.5471, F1 Micro: 0.6146, F1 Macro: 0.4788, Accuracy: 0.6146\n","Epoch 44, Train Loss: 11.3227, Val Loss: 17.6310, F1 Micro: 0.1354, F1 Macro: 0.1278, Accuracy: 0.1354\n","Epoch 45, Train Loss: 21.3161, Val Loss: 5.5595, F1 Micro: 0.7812, F1 Macro: 0.5171, Accuracy: 0.7812\n","Epoch 46, Train Loss: 10.6746, Val Loss: 12.0407, F1 Micro: 0.2083, F1 Macro: 0.2080, Accuracy: 0.2083\n","Epoch 47, Train Loss: 28.2169, Val Loss: 13.0730, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 48, Train Loss: 15.0640, Val Loss: 21.7054, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 49, Train Loss: 17.8078, Val Loss: 17.7118, F1 Micro: 0.1979, F1 Macro: 0.1971, Accuracy: 0.1979\n","Epoch 50, Train Loss: 21.9153, Val Loss: 10.9265, F1 Micro: 0.8750, F1 Macro: 0.4667, Accuracy: 0.8750\n","Epoch 51, Train Loss: 14.2653, Val Loss: 17.5148, F1 Micro: 0.8854, F1 Macro: 0.4696, Accuracy: 0.8854\n","Epoch 52, Train Loss: 45.3669, Val Loss: 100.6910, F1 Micro: 0.1146, F1 Macro: 0.1028, Accuracy: 0.1146\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 65.3849, Val Loss: 40.7363, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 2, Train Loss: 22.5449, Val Loss: 22.2213, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 3, Train Loss: 44.7635, Val Loss: 7.6325, F1 Micro: 0.6562, F1 Macro: 0.5055, Accuracy: 0.6562\n","Epoch 4, Train Loss: 24.8664, Val Loss: 15.3728, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 5, Train Loss: 11.1095, Val Loss: 11.5945, F1 Micro: 0.3542, F1 Macro: 0.3516, Accuracy: 0.3542\n","Epoch 6, Train Loss: 19.4485, Val Loss: 6.3063, F1 Micro: 0.4688, F1 Macro: 0.4154, Accuracy: 0.4688\n","Epoch 7, Train Loss: 14.2354, Val Loss: 9.8173, F1 Micro: 0.3646, F1 Macro: 0.3561, Accuracy: 0.3646\n","Epoch 8, Train Loss: 14.0676, Val Loss: 15.7297, F1 Micro: 0.2708, F1 Macro: 0.2696, Accuracy: 0.2708\n","Epoch 9, Train Loss: 28.7209, Val Loss: 13.2230, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 10, Train Loss: 30.0356, Val Loss: 62.9362, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 11, Train Loss: 18.0487, Val Loss: 11.6064, F1 Micro: 0.3333, F1 Macro: 0.3322, Accuracy: 0.3333\n","Epoch 12, Train Loss: 23.6946, Val Loss: 5.8552, F1 Micro: 0.6562, F1 Macro: 0.5351, Accuracy: 0.6562\n","Epoch 13, Train Loss: 18.5383, Val Loss: 25.5515, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 14, Train Loss: 27.7027, Val Loss: 18.7794, F1 Micro: 0.2708, F1 Macro: 0.2696, Accuracy: 0.2708\n","Epoch 15, Train Loss: 14.7675, Val Loss: 7.6001, F1 Micro: 0.4583, F1 Macro: 0.4283, Accuracy: 0.4583\n","Epoch 16, Train Loss: 26.4719, Val Loss: 16.1365, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 17, Train Loss: 34.5406, Val Loss: 112.1236, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 18, Train Loss: 27.7178, Val Loss: 8.0915, F1 Micro: 0.4688, F1 Macro: 0.4154, Accuracy: 0.4688\n","Epoch 19, Train Loss: 13.0889, Val Loss: 29.6374, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 20, Train Loss: 29.2345, Val Loss: 50.0594, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 21, Train Loss: 20.1188, Val Loss: 9.4763, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 22, Train Loss: 9.9602, Val Loss: 22.0159, F1 Micro: 0.2083, F1 Macro: 0.1996, Accuracy: 0.2083\n","Epoch 23, Train Loss: 9.9671, Val Loss: 6.4846, F1 Micro: 0.4271, F1 Macro: 0.4085, Accuracy: 0.4271\n","Epoch 24, Train Loss: 16.0695, Val Loss: 6.1727, F1 Micro: 0.4062, F1 Macro: 0.3914, Accuracy: 0.4062\n","Epoch 25, Train Loss: 36.4564, Val Loss: 4.5703, F1 Micro: 0.6771, F1 Macro: 0.5501, Accuracy: 0.6771\n","Epoch 26, Train Loss: 22.9647, Val Loss: 5.2472, F1 Micro: 0.6562, F1 Macro: 0.5351, Accuracy: 0.6562\n","Epoch 27, Train Loss: 11.9999, Val Loss: 9.9747, F1 Micro: 0.8021, F1 Macro: 0.4451, Accuracy: 0.8021\n","Epoch 28, Train Loss: 19.6772, Val Loss: 19.2462, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 29, Train Loss: 26.3875, Val Loss: 26.4923, F1 Micro: 0.1979, F1 Macro: 0.1872, Accuracy: 0.1979\n","Epoch 30, Train Loss: 31.5830, Val Loss: 6.8001, F1 Micro: 0.6562, F1 Macro: 0.5351, Accuracy: 0.6562\n","Epoch 31, Train Loss: 10.8706, Val Loss: 17.8778, F1 Micro: 0.2708, F1 Macro: 0.2705, Accuracy: 0.2708\n","Epoch 32, Train Loss: 25.5553, Val Loss: 31.8306, F1 Micro: 0.1667, F1 Macro: 0.1486, Accuracy: 0.1667\n","Epoch 33, Train Loss: 18.9201, Val Loss: 33.3682, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 34, Train Loss: 27.2433, Val Loss: 20.5342, F1 Micro: 0.2812, F1 Macro: 0.2805, Accuracy: 0.2812\n","Epoch 35, Train Loss: 21.6791, Val Loss: 6.8923, F1 Micro: 0.6667, F1 Macro: 0.5124, Accuracy: 0.6667\n","Epoch 36, Train Loss: 11.7785, Val Loss: 29.7953, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 37, Train Loss: 29.7135, Val Loss: 52.0247, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 38, Train Loss: 44.3649, Val Loss: 91.8109, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 39, Train Loss: 23.0474, Val Loss: 9.9706, F1 Micro: 0.8229, F1 Macro: 0.6091, Accuracy: 0.8229\n","Epoch 40, Train Loss: 8.5406, Val Loss: 5.0728, F1 Micro: 0.6146, F1 Macro: 0.5178, Accuracy: 0.6146\n","Epoch 41, Train Loss: 17.4941, Val Loss: 40.9389, F1 Micro: 0.1562, F1 Macro: 0.1351, Accuracy: 0.1562\n","Epoch 42, Train Loss: 32.7523, Val Loss: 14.6241, F1 Micro: 0.8333, F1 Macro: 0.4545, Accuracy: 0.8333\n","Epoch 43, Train Loss: 22.7332, Val Loss: 14.1713, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 44, Train Loss: 11.2571, Val Loss: 10.5323, F1 Micro: 0.3750, F1 Macro: 0.3706, Accuracy: 0.3750\n","Epoch 45, Train Loss: 22.1560, Val Loss: 5.8006, F1 Micro: 0.5521, F1 Macro: 0.4739, Accuracy: 0.5521\n","Epoch 46, Train Loss: 8.4737, Val Loss: 9.8774, F1 Micro: 0.8229, F1 Macro: 0.4514, Accuracy: 0.8229\n","Epoch 47, Train Loss: 8.8081, Val Loss: 3.5054, F1 Micro: 0.7917, F1 Macro: 0.6049, Accuracy: 0.7917\n","Epoch 48, Train Loss: 6.2915, Val Loss: 3.3640, F1 Micro: 0.4583, F1 Macro: 0.4338, Accuracy: 0.4583\n","Epoch 49, Train Loss: 18.1487, Val Loss: 9.9317, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Epoch 50, Train Loss: 11.2901, Val Loss: 17.8910, F1 Micro: 0.1979, F1 Macro: 0.1872, Accuracy: 0.1979\n","Epoch 51, Train Loss: 12.6609, Val Loss: 11.8176, F1 Micro: 0.8438, F1 Macro: 0.4576, Accuracy: 0.8438\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.8541666666666666\n","Best hyperparameters for Outer FOLD 4: (0.01, 8, 50) with score 0.9479166666666667\n","Epoch 1, Train Loss: 178.5853, Val Loss: 28.8894, F1 Micro: 0.4475, F1 Macro: 0.3856, Accuracy: 0.4475\n","Epoch 2, Train Loss: 48.8198, Val Loss: 22.0151, F1 Micro: 0.4400, F1 Macro: 0.3166, Accuracy: 0.4400\n","Epoch 3, Train Loss: 23.6406, Val Loss: 9.8904, F1 Micro: 0.6150, F1 Macro: 0.5595, Accuracy: 0.6150\n","Epoch 4, Train Loss: 19.3145, Val Loss: 41.0239, F1 Micro: 0.4750, F1 Macro: 0.3302, Accuracy: 0.4750\n","Epoch 5, Train Loss: 48.4085, Val Loss: 8.8766, F1 Micro: 0.5800, F1 Macro: 0.5495, Accuracy: 0.5800\n","Epoch 6, Train Loss: 4.4686, Val Loss: 6.4325, F1 Micro: 0.6775, F1 Macro: 0.6607, Accuracy: 0.6775\n","Epoch 7, Train Loss: 4.0464, Val Loss: 3.4095, F1 Micro: 0.5325, F1 Macro: 0.4338, Accuracy: 0.5325\n","Epoch 8, Train Loss: 4.7333, Val Loss: 14.4663, F1 Micro: 0.6225, F1 Macro: 0.6215, Accuracy: 0.6225\n","Epoch 9, Train Loss: 3.8290, Val Loss: 2.7000, F1 Micro: 0.6975, F1 Macro: 0.6952, Accuracy: 0.6975\n","Epoch 10, Train Loss: 2.8382, Val Loss: 11.9474, F1 Micro: 0.5975, F1 Macro: 0.5940, Accuracy: 0.5975\n","Epoch 11, Train Loss: 7.2180, Val Loss: 2.9826, F1 Micro: 0.7225, F1 Macro: 0.7167, Accuracy: 0.7225\n","Epoch 12, Train Loss: 2.7758, Val Loss: 5.5628, F1 Micro: 0.6550, F1 Macro: 0.6533, Accuracy: 0.6550\n","Epoch 13, Train Loss: 4.5567, Val Loss: 3.6690, F1 Micro: 0.5825, F1 Macro: 0.4944, Accuracy: 0.5825\n","Epoch 14, Train Loss: 5.1662, Val Loss: 3.6319, F1 Micro: 0.6600, F1 Macro: 0.6566, Accuracy: 0.6600\n","Epoch 15, Train Loss: 7.4638, Val Loss: 3.7974, F1 Micro: 0.5475, F1 Macro: 0.4790, Accuracy: 0.5475\n","Epoch 16, Train Loss: 3.8099, Val Loss: 47.2701, F1 Micro: 0.5150, F1 Macro: 0.4705, Accuracy: 0.5150\n","Epoch 17, Train Loss: 10.3657, Val Loss: 3.9370, F1 Micro: 0.6225, F1 Macro: 0.6172, Accuracy: 0.6225\n","Epoch 18, Train Loss: 3.1480, Val Loss: 5.1393, F1 Micro: 0.5325, F1 Macro: 0.4017, Accuracy: 0.5325\n","Epoch 19, Train Loss: 4.2697, Val Loss: 3.3447, F1 Micro: 0.6775, F1 Macro: 0.6717, Accuracy: 0.6775\n","Epoch 20, Train Loss: 2.5180, Val Loss: 2.7838, F1 Micro: 0.6025, F1 Macro: 0.5279, Accuracy: 0.6025\n","Epoch 21, Train Loss: 4.0715, Val Loss: 6.0282, F1 Micro: 0.6550, F1 Macro: 0.6330, Accuracy: 0.6550\n","Epoch 22, Train Loss: 4.1241, Val Loss: 15.0237, F1 Micro: 0.5600, F1 Macro: 0.5506, Accuracy: 0.5600\n","Epoch 23, Train Loss: 20.1823, Val Loss: 2.9716, F1 Micro: 0.7475, F1 Macro: 0.7426, Accuracy: 0.7475\n","Epoch 24, Train Loss: 2.4769, Val Loss: 1.5831, F1 Micro: 0.7150, F1 Macro: 0.7148, Accuracy: 0.7150\n","Epoch 25, Train Loss: 3.2319, Val Loss: 2.2038, F1 Micro: 0.6875, F1 Macro: 0.6875, Accuracy: 0.6875\n","Epoch 26, Train Loss: 4.0436, Val Loss: 1.1792, F1 Micro: 0.5850, F1 Macro: 0.5573, Accuracy: 0.5850\n","Epoch 27, Train Loss: 1.7602, Val Loss: 3.9452, F1 Micro: 0.6725, F1 Macro: 0.6441, Accuracy: 0.6725\n","Epoch 28, Train Loss: 1.9618, Val Loss: 1.0091, F1 Micro: 0.5800, F1 Macro: 0.5233, Accuracy: 0.5800\n","Epoch 29, Train Loss: 1.2097, Val Loss: 0.7839, F1 Micro: 0.7675, F1 Macro: 0.7673, Accuracy: 0.7675\n","Epoch 30, Train Loss: 1.9388, Val Loss: 3.4423, F1 Micro: 0.6050, F1 Macro: 0.6045, Accuracy: 0.6050\n","Epoch 31, Train Loss: 21.0767, Val Loss: 75.8026, F1 Micro: 0.4950, F1 Macro: 0.3311, Accuracy: 0.4950\n","Epoch 32, Train Loss: 28.2197, Val Loss: 2.7391, F1 Micro: 0.6950, F1 Macro: 0.6950, Accuracy: 0.6950\n","Epoch 33, Train Loss: 1.5888, Val Loss: 2.7805, F1 Micro: 0.7500, F1 Macro: 0.7446, Accuracy: 0.7500\n","Epoch 34, Train Loss: 2.0095, Val Loss: 1.7785, F1 Micro: 0.6975, F1 Macro: 0.6940, Accuracy: 0.6975\n","Epoch 35, Train Loss: 1.4404, Val Loss: 1.3495, F1 Micro: 0.7125, F1 Macro: 0.7052, Accuracy: 0.7125\n","Epoch 36, Train Loss: 3.0466, Val Loss: 2.2699, F1 Micro: 0.6875, F1 Macro: 0.6680, Accuracy: 0.6875\n","Epoch 37, Train Loss: 1.7365, Val Loss: 1.0954, F1 Micro: 0.7475, F1 Macro: 0.7460, Accuracy: 0.7475\n","Epoch 38, Train Loss: 2.9464, Val Loss: 31.8339, F1 Micro: 0.5025, F1 Macro: 0.3344, Accuracy: 0.5025\n","Epoch 39, Train Loss: 72.4446, Val Loss: 6.8747, F1 Micro: 0.5475, F1 Macro: 0.5205, Accuracy: 0.5475\n","Epoch 40, Train Loss: 22.4908, Val Loss: 13.9644, F1 Micro: 0.6125, F1 Macro: 0.5557, Accuracy: 0.6125\n","Epoch 41, Train Loss: 10.0492, Val Loss: 4.5694, F1 Micro: 0.6675, F1 Macro: 0.6657, Accuracy: 0.6675\n","Epoch 42, Train Loss: 1.8673, Val Loss: 1.4787, F1 Micro: 0.7725, F1 Macro: 0.7725, Accuracy: 0.7725\n","Epoch 43, Train Loss: 1.5984, Val Loss: 1.2207, F1 Micro: 0.7450, F1 Macro: 0.7448, Accuracy: 0.7450\n","Epoch 44, Train Loss: 1.3412, Val Loss: 1.0674, F1 Micro: 0.6275, F1 Macro: 0.6139, Accuracy: 0.6275\n","Epoch 45, Train Loss: 1.1790, Val Loss: 0.8386, F1 Micro: 0.7375, F1 Macro: 0.7369, Accuracy: 0.7375\n","Epoch 46, Train Loss: 0.9163, Val Loss: 0.7432, F1 Micro: 0.6100, F1 Macro: 0.5892, Accuracy: 0.6100\n","Epoch 47, Train Loss: 2.4684, Val Loss: 3.6134, F1 Micro: 0.5050, F1 Macro: 0.3486, Accuracy: 0.5050\n","Epoch 48, Train Loss: 3.7362, Val Loss: 1.3740, F1 Micro: 0.6575, F1 Macro: 0.6191, Accuracy: 0.6575\n","Epoch 49, Train Loss: 0.9753, Val Loss: 0.6698, F1 Micro: 0.6975, F1 Macro: 0.6925, Accuracy: 0.6975\n","Epoch 50, Train Loss: 1.2921, Val Loss: 0.8313, F1 Micro: 0.6800, F1 Macro: 0.6782, Accuracy: 0.6800\n","Epoch 51, Train Loss: 39.7875, Val Loss: 136.8517, F1 Micro: 0.5025, F1 Macro: 0.3344, Accuracy: 0.5025\n","Epoch 52, Train Loss: 19.7453, Val Loss: 11.2196, F1 Micro: 0.5975, F1 Macro: 0.5306, Accuracy: 0.5975\n","Epoch 53, Train Loss: 2.4574, Val Loss: 1.2320, F1 Micro: 0.5575, F1 Macro: 0.4927, Accuracy: 0.5575\n","Epoch 54, Train Loss: 1.1867, Val Loss: 3.1607, F1 Micro: 0.5150, F1 Macro: 0.3812, Accuracy: 0.5150\n","Epoch 55, Train Loss: 1.3421, Val Loss: 5.0347, F1 Micro: 0.6625, F1 Macro: 0.6332, Accuracy: 0.6625\n","Epoch 56, Train Loss: 1.9270, Val Loss: 1.0205, F1 Micro: 0.7125, F1 Macro: 0.7117, Accuracy: 0.7125\n","Epoch 57, Train Loss: 0.9021, Val Loss: 0.7497, F1 Micro: 0.7325, F1 Macro: 0.7321, Accuracy: 0.7325\n","Epoch 58, Train Loss: 0.7871, Val Loss: 0.6278, F1 Micro: 0.6350, F1 Macro: 0.6146, Accuracy: 0.6350\n","Epoch 59, Train Loss: 0.6765, Val Loss: 0.8871, F1 Micro: 0.7050, F1 Macro: 0.6967, Accuracy: 0.7050\n","Epoch 60, Train Loss: 1.1569, Val Loss: 1.1455, F1 Micro: 0.6775, F1 Macro: 0.6495, Accuracy: 0.6775\n","Epoch 61, Train Loss: 3.8511, Val Loss: 7.9868, F1 Micro: 0.4725, F1 Macro: 0.3441, Accuracy: 0.4725\n","Epoch 62, Train Loss: 3.2282, Val Loss: 3.2734, F1 Micro: 0.7000, F1 Macro: 0.6808, Accuracy: 0.7000\n","Epoch 63, Train Loss: 1.6456, Val Loss: 1.6871, F1 Micro: 0.6725, F1 Macro: 0.6687, Accuracy: 0.6725\n","Epoch 64, Train Loss: 2.4965, Val Loss: 1.4632, F1 Micro: 0.7000, F1 Macro: 0.6956, Accuracy: 0.7000\n","Epoch 65, Train Loss: 6.4948, Val Loss: 38.1124, F1 Micro: 0.4950, F1 Macro: 0.3311, Accuracy: 0.4950\n","Epoch 66, Train Loss: 25.1855, Val Loss: 4.2969, F1 Micro: 0.7025, F1 Macro: 0.6891, Accuracy: 0.7025\n","Epoch 67, Train Loss: 1.6458, Val Loss: 1.0572, F1 Micro: 0.7700, F1 Macro: 0.7700, Accuracy: 0.7700\n","Epoch 68, Train Loss: 0.9772, Val Loss: 0.9147, F1 Micro: 0.7100, F1 Macro: 0.7024, Accuracy: 0.7100\n","Epoch 69, Train Loss: 0.8437, Val Loss: 0.7772, F1 Micro: 0.7725, F1 Macro: 0.7724, Accuracy: 0.7725\n","Epoch 70, Train Loss: 3.4245, Val Loss: 0.9626, F1 Micro: 0.7200, F1 Macro: 0.7169, Accuracy: 0.7200\n","Epoch 71, Train Loss: 1.6604, Val Loss: 0.8337, F1 Micro: 0.7225, F1 Macro: 0.7214, Accuracy: 0.7225\n","Epoch 72, Train Loss: 0.7631, Val Loss: 0.7476, F1 Micro: 0.7275, F1 Macro: 0.7272, Accuracy: 0.7275\n","Epoch 73, Train Loss: 0.8345, Val Loss: 1.4650, F1 Micro: 0.7125, F1 Macro: 0.7002, Accuracy: 0.7125\n","Epoch 74, Train Loss: 6.4986, Val Loss: 1.7251, F1 Micro: 0.6750, F1 Macro: 0.6484, Accuracy: 0.6750\n","Epoch 75, Train Loss: 45.0223, Val Loss: 2.4995, F1 Micro: 0.6825, F1 Macro: 0.6814, Accuracy: 0.6825\n","Epoch 76, Train Loss: 2.5546, Val Loss: 0.9696, F1 Micro: 0.6975, F1 Macro: 0.6933, Accuracy: 0.6975\n","Epoch 77, Train Loss: 0.9587, Val Loss: 0.9369, F1 Micro: 0.5825, F1 Macro: 0.5529, Accuracy: 0.5825\n","Epoch 78, Train Loss: 0.7648, Val Loss: 0.7236, F1 Micro: 0.5500, F1 Macro: 0.5038, Accuracy: 0.5500\n","Epoch 79, Train Loss: 0.8045, Val Loss: 0.6688, F1 Micro: 0.7725, F1 Macro: 0.7725, Accuracy: 0.7725\n","Epoch 80, Train Loss: 1.3307, Val Loss: 4.7529, F1 Micro: 0.5550, F1 Macro: 0.4752, Accuracy: 0.5550\n","Epoch 81, Train Loss: 32.9876, Val Loss: 1.0587, F1 Micro: 0.6425, F1 Macro: 0.6052, Accuracy: 0.6425\n","Epoch 82, Train Loss: 1.1147, Val Loss: 0.7853, F1 Micro: 0.6650, F1 Macro: 0.6538, Accuracy: 0.6650\n","Epoch 83, Train Loss: 0.7546, Val Loss: 0.9567, F1 Micro: 0.6700, F1 Macro: 0.6385, Accuracy: 0.6700\n","Epoch 84, Train Loss: 0.7704, Val Loss: 0.8230, F1 Micro: 0.7125, F1 Macro: 0.7070, Accuracy: 0.7125\n","Epoch 85, Train Loss: 0.8181, Val Loss: 0.8898, F1 Micro: 0.7400, F1 Macro: 0.7365, Accuracy: 0.7400\n","Epoch 86, Train Loss: 0.6836, Val Loss: 0.9644, F1 Micro: 0.6950, F1 Macro: 0.6755, Accuracy: 0.6950\n","Epoch 87, Train Loss: 1.7025, Val Loss: 3.1586, F1 Micro: 0.6025, F1 Macro: 0.5497, Accuracy: 0.6025\n","Epoch 88, Train Loss: 1.3263, Val Loss: 0.6313, F1 Micro: 0.6825, F1 Macro: 0.6744, Accuracy: 0.6825\n","Epoch 89, Train Loss: 0.8734, Val Loss: 1.5563, F1 Micro: 0.5700, F1 Macro: 0.4725, Accuracy: 0.5700\n","Epoch 90, Train Loss: 0.8391, Val Loss: 0.6453, F1 Micro: 0.7125, F1 Macro: 0.7061, Accuracy: 0.7125\n","Epoch 91, Train Loss: 4.2471, Val Loss: 6.6254, F1 Micro: 0.5125, F1 Macro: 0.4003, Accuracy: 0.5125\n","Epoch 92, Train Loss: 12.6301, Val Loss: 10.6828, F1 Micro: 0.5425, F1 Macro: 0.4459, Accuracy: 0.5425\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.5425, F1 Macro: 0.4459, Accuracy: 0.5425\n"]}]},{"cell_type":"code","source":["print(np.mean(f1_micro_test_list))\n","print(np.mean(f1_macro_test_list))\n","print(np.mean(accuracy_test_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6oZWgdBRIV3b","executionInfo":{"status":"ok","timestamp":1711496342489,"user_tz":-60,"elapsed":247,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"79367006-7508-4f15-b7b8-9113dbfda9e2"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["0.603\n","0.5491640114702554\n","0.603\n"]}]},{"cell_type":"code","source":["# Initialize a dictionary to store metrics for different models\n","models_evaluation_metrics = {}\n","\n","# Example model identifiers\n","model_names = ['BasicGraphModel', 'GraphSAGEModel', 'GINModel']\n","\n","# Initialize metric dictionaries for each model\n","for model_name in model_names:\n","    models_evaluation_metrics[model_name] = {'f1_micro': [], 'f1_macro': [], 'accuracy': []}\n","\n","def update_model_metrics(model_name, f1_micro, f1_macro, accuracy):\n","    models_evaluation_metrics[model_name]['f1_micro'].append(f1_micro)\n","    models_evaluation_metrics[model_name]['f1_macro'].append(f1_macro)\n","    models_evaluation_metrics[model_name]['accuracy'].append(accuracy)\n","\n","update_model_metrics('BasicGraphModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4H5ILBUIe0n","executionInfo":{"status":"ok","timestamp":1711496372239,"user_tz":-60,"elapsed":254,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"1f916943-0891-425e-e93a-ca0d5d57f7cb"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.735, 0.5825, 0.7075, 0.4475, 0.5425]], 'f1_macro': [[0.7271135825352693, 0.561768931516555, 0.7018633540372672, 0.30915371329879104, 0.44592047596339446]], 'accuracy': [[0.735, 0.5825, 0.7075, 0.4475, 0.5425]]}, 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]},{"cell_type":"markdown","source":["# Do the same thing with Protein Dataset"],"metadata":{"id":"6wIs9ll-nELk"}},{"cell_type":"code","source":["class MLP2(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(MLP2, self).__init__()\n","\n","        self.fc = nn.Linear(input_size, output_size)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, data):\n","        x = graphnn.global_add_pool(data.x, data.batch)\n","        x = self.fc(x)\n","        x = self.relu(x)\n","\n","        return x"],"metadata":{"id":"uEJ6feLInRrW","executionInfo":{"status":"ok","timestamp":1711496730190,"user_tz":-60,"elapsed":263,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Outer k-fold cross-validation setup\n","outer_k_folds = 5\n","inner_k_folds = 5\n","num_epochs = 200\n","\n","# Possible hyperparameters to tune\n","learning_rates = [0.01, 0.001]\n","batch_sizes = [8, 16]\n","patiences = [10, 50]\n","\n","# Set list to store the evaluation metrics\n","f1_micro_test_list = []\n","f1_macro_test_list = []\n","accuracy_test_list = []\n","\n","# Prepare the outer k-fold cross-validation\n","outer_kf = KFold(n_splits=outer_k_folds, shuffle=True, random_state=42)\n","\n","# Loop over each fold for the outer k-fold\n","for fold, (train_val_idx, test_idx) in enumerate(outer_kf.split(dataset_pr)):\n","    print(f\"Outer FOLD {fold}\")\n","    print(\"--------------------------------\")\n","\n","    # Split dataset into train_val and test for the current outer fold\n","    train_val_dataset = dataset_pr[train_val_idx]\n","    test_dataset = dataset_pr[test_idx]\n","\n","    # Initialize the best hyperparameter set and its performance score\n","    best_hyperparams = None\n","    best_score = 0\n","\n","    # Inner k-fold cross-validation for hyperparameter tuning\n","    inner_kf = KFold(n_splits=inner_k_folds, shuffle=True, random_state=42)\n","\n","    # Create all combinations of hyperparameters\n","    all_params = list(product(learning_rates, batch_sizes, patiences))\n","\n","    # Loop over all combinations of hyperparameters\n","    for params in all_params:\n","        lr, batch_size, patience = params\n","        inner_scores = []\n","\n","        # Perform inner k-fold cross-validation\n","        for inner_fold, (inner_train_idx, inner_val_idx) in enumerate(inner_kf.split(train_val_dataset)):\n","            print(f\"Inner FOLD {inner_fold}\")\n","            print(f\"Hyperparameters: LR={lr}, Batch Size={batch_size}, Patience={patience}\")\n","\n","            # Split dataset into inner train and validation sets\n","            inner_train_dataset = train_val_dataset[inner_train_idx]\n","            inner_val_dataset = train_val_dataset[inner_val_idx]\n","\n","            # Define train and validation dataloaders for the current inner fold\n","            inner_train_loader = DataLoader(inner_train_dataset, batch_size=batch_size, shuffle=True)\n","            inner_val_loader = DataLoader(inner_val_dataset, batch_size=batch_size, shuffle=False)\n","\n","            # Initialize model and optimizer for the current inner fold\n","            model = MLP2(\n","                input_size=dataset_pr.num_node_features,\n","                output_size=dataset_pr.num_classes\n","            ).to(device)\n","\n","            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","            loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","            # Train the model for the current inner fold\n","            inner_metrics = train(model, loss_fcn, device, optimizer, num_epochs, inner_train_loader, inner_val_loader, patience)\n","\n","            # Evaluate model performance, e.g., using validation F1 score\n","            # Save the model performance score for the current hyperparameter combination\n","            inner_scores.append(inner_metrics['best_score'])\n","\n","        # Calculate the average performance over all inner folds for the current hyperparameter set\n","        average_score = np.mean(inner_scores)\n","        print(f\"Average Score for hyperparameters {params}: {average_score}\")\n","\n","        # If the current hyperparameters outperform the previous ones, update the best_hyperparams\n","        if average_score > best_score:\n","            best_hyperparams = params\n","            best_score = average_score\n","\n","    print(f\"Best hyperparameters for Outer FOLD {fold}: {best_hyperparams} with score {best_score}\")\n","\n","    # Now retrain the model on the full train_val_dataset with the best_hyperparams\n","\n","    # Extract best hyperparameters\n","    best_lr, best_batch_size, best_patience = best_hyperparams\n","\n","    # DataLoader for the combined training and validation set\n","    train_val_loader = DataLoader(train_val_dataset, batch_size=best_batch_size, shuffle=True)\n","\n","    # DataLoader for the test set\n","    test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False)\n","\n","    # Initialize the model with the best hyperparameters\n","    model = MLP2(\n","        input_size=dataset_pr.num_node_features,\n","        output_size=dataset_pr.num_classes\n","    ).to(device)\n","\n","    # Initialize the optimizer with the best learning rate\n","    optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n","\n","    # Loss function\n","    loss_fcn = torch.nn.CrossEntropyLoss()\n","\n","    # Retrain the model on the full train_val_dataset\n","    retrained_metrics = train(\n","        model,\n","        loss_fcn,\n","        device,\n","        optimizer,\n","        num_epochs,\n","        train_val_loader,\n","        test_loader,  # We're using the test_loader here to monitor the performance, but we do not use this for making decisions\n","        best_patience\n","    )\n","\n","    # After retraining, evaluate on the test set\n","    f1_micro_test, f1_macro_test, accuracy_test = evaluate_metrics(model, device, test_loader)\n","    print(f\"Test set evaluation - F1 Micro: {f1_micro_test:.4f}, F1 Macro: {f1_macro_test:.4f}, Accuracy: {accuracy_test:.4f}\")\n","    f1_micro_test_list.append(f1_micro_test)\n","    f1_macro_test_list.append(f1_macro_test)\n","    accuracy_test_list.append(accuracy_test)\n","    # Optionally, save your retrained model\n","    torch.save(model.state_dict(), f'Basic_model_fold_{fold}.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KMJalaRjJrau","executionInfo":{"status":"ok","timestamp":1711499345029,"user_tz":-60,"elapsed":2587183,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"7a1511d2-1845-4ef9-f0f7-3fe47848d843"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 7, Train Loss: 0.7261, Val Loss: 0.7657, F1 Micro: 0.6910, F1 Macro: 0.5056, Accuracy: 0.6910\n","Epoch 8, Train Loss: 0.7215, Val Loss: 0.7590, F1 Micro: 0.6910, F1 Macro: 0.5056, Accuracy: 0.6910\n","Epoch 9, Train Loss: 0.7181, Val Loss: 0.7488, F1 Micro: 0.6910, F1 Macro: 0.5056, Accuracy: 0.6910\n","Epoch 10, Train Loss: 0.7125, Val Loss: 0.7429, F1 Micro: 0.6854, F1 Macro: 0.5021, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.7081, Val Loss: 0.7365, F1 Micro: 0.6854, F1 Macro: 0.5021, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.7042, Val Loss: 0.7297, F1 Micro: 0.6854, F1 Macro: 0.5021, Accuracy: 0.6854\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 4.3945, Val Loss: 3.7242, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 2, Train Loss: 3.8500, Val Loss: 3.1755, F1 Micro: 0.5899, F1 Macro: 0.3710, Accuracy: 0.5899\n","Epoch 3, Train Loss: 3.2504, Val Loss: 2.6069, F1 Micro: 0.5899, F1 Macro: 0.3834, Accuracy: 0.5899\n","Epoch 4, Train Loss: 2.6008, Val Loss: 1.9881, F1 Micro: 0.5787, F1 Macro: 0.3899, Accuracy: 0.5787\n","Epoch 5, Train Loss: 1.9366, Val Loss: 1.4410, F1 Micro: 0.5787, F1 Macro: 0.4007, Accuracy: 0.5787\n","Epoch 6, Train Loss: 1.3908, Val Loss: 1.0341, F1 Micro: 0.6236, F1 Macro: 0.5253, Accuracy: 0.6236\n","Epoch 7, Train Loss: 1.0435, Val Loss: 0.8081, F1 Micro: 0.6629, F1 Macro: 0.6129, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.8563, Val Loss: 0.7074, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 9, Train Loss: 0.7526, Val Loss: 0.6414, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6800, Val Loss: 0.5955, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.6314, Val Loss: 0.5648, F1 Micro: 0.7191, F1 Macro: 0.7025, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.6006, Val Loss: 0.5495, F1 Micro: 0.7247, F1 Macro: 0.7108, Accuracy: 0.7247\n","Epoch 13, Train Loss: 0.5848, Val Loss: 0.5433, F1 Micro: 0.7416, F1 Macro: 0.7263, Accuracy: 0.7416\n","Epoch 14, Train Loss: 0.5793, Val Loss: 0.5408, F1 Micro: 0.7360, F1 Macro: 0.7212, Accuracy: 0.7360\n","Epoch 15, Train Loss: 0.5828, Val Loss: 0.5414, F1 Micro: 0.7303, F1 Macro: 0.7213, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.5754, Val Loss: 0.5396, F1 Micro: 0.7472, F1 Macro: 0.7370, Accuracy: 0.7472\n","Epoch 17, Train Loss: 0.5727, Val Loss: 0.5403, F1 Micro: 0.7303, F1 Macro: 0.7213, Accuracy: 0.7303\n","Epoch 18, Train Loss: 0.5706, Val Loss: 0.5393, F1 Micro: 0.7472, F1 Macro: 0.7370, Accuracy: 0.7472\n","Epoch 19, Train Loss: 0.5741, Val Loss: 0.5399, F1 Micro: 0.7360, F1 Macro: 0.7266, Accuracy: 0.7360\n","Epoch 20, Train Loss: 0.5699, Val Loss: 0.5392, F1 Micro: 0.7416, F1 Macro: 0.7318, Accuracy: 0.7416\n","Epoch 21, Train Loss: 0.5710, Val Loss: 0.5388, F1 Micro: 0.7303, F1 Macro: 0.7213, Accuracy: 0.7303\n","Epoch 22, Train Loss: 0.5726, Val Loss: 0.5389, F1 Micro: 0.7303, F1 Macro: 0.7213, Accuracy: 0.7303\n","Epoch 23, Train Loss: 0.5731, Val Loss: 0.5383, F1 Micro: 0.7303, F1 Macro: 0.7213, Accuracy: 0.7303\n","Epoch 24, Train Loss: 0.5729, Val Loss: 0.5380, F1 Micro: 0.7360, F1 Macro: 0.7266, Accuracy: 0.7360\n","Epoch 25, Train Loss: 0.5720, Val Loss: 0.5388, F1 Micro: 0.7247, F1 Macro: 0.7161, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.5714, Val Loss: 0.5380, F1 Micro: 0.7303, F1 Macro: 0.7213, Accuracy: 0.7303\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 6.1439, Val Loss: 4.6031, F1 Micro: 0.3820, F1 Macro: 0.2764, Accuracy: 0.3820\n","Epoch 2, Train Loss: 4.4587, Val Loss: 3.4059, F1 Micro: 0.3820, F1 Macro: 0.3086, Accuracy: 0.3820\n","Epoch 3, Train Loss: 2.8711, Val Loss: 2.3056, F1 Micro: 0.4663, F1 Macro: 0.4422, Accuracy: 0.4663\n","Epoch 4, Train Loss: 1.8466, Val Loss: 1.6272, F1 Micro: 0.5225, F1 Macro: 0.5223, Accuracy: 0.5225\n","Epoch 5, Train Loss: 1.3944, Val Loss: 1.3587, F1 Micro: 0.5787, F1 Macro: 0.5727, Accuracy: 0.5787\n","Epoch 6, Train Loss: 1.2233, Val Loss: 1.2702, F1 Micro: 0.5899, F1 Macro: 0.5802, Accuracy: 0.5899\n","Epoch 7, Train Loss: 1.1477, Val Loss: 1.2090, F1 Micro: 0.5730, F1 Macro: 0.5569, Accuracy: 0.5730\n","Epoch 8, Train Loss: 1.0933, Val Loss: 1.1615, F1 Micro: 0.5787, F1 Macro: 0.5617, Accuracy: 0.5787\n","Epoch 9, Train Loss: 1.0520, Val Loss: 1.1133, F1 Micro: 0.5843, F1 Macro: 0.5644, Accuracy: 0.5843\n","Epoch 10, Train Loss: 1.0042, Val Loss: 1.0706, F1 Micro: 0.5787, F1 Macro: 0.5574, Accuracy: 0.5787\n","Epoch 11, Train Loss: 0.9684, Val Loss: 1.0297, F1 Micro: 0.5843, F1 Macro: 0.5598, Accuracy: 0.5843\n","Epoch 12, Train Loss: 0.9207, Val Loss: 0.9909, F1 Micro: 0.5843, F1 Macro: 0.5622, Accuracy: 0.5843\n","Epoch 13, Train Loss: 0.8844, Val Loss: 0.9531, F1 Micro: 0.5730, F1 Macro: 0.5479, Accuracy: 0.5730\n","Epoch 14, Train Loss: 0.8417, Val Loss: 0.9223, F1 Micro: 0.5674, F1 Macro: 0.5379, Accuracy: 0.5674\n","Epoch 15, Train Loss: 0.8155, Val Loss: 0.8930, F1 Micro: 0.5730, F1 Macro: 0.5365, Accuracy: 0.5730\n","Epoch 16, Train Loss: 0.7835, Val Loss: 0.8624, F1 Micro: 0.5337, F1 Macro: 0.4762, Accuracy: 0.5337\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.6697, Val Loss: 1.4617, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 1.2092, Val Loss: 1.0715, F1 Micro: 0.5955, F1 Macro: 0.4090, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.8570, Val Loss: 0.8158, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.6831, Val Loss: 0.7392, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6364, Val Loss: 0.7130, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 6, Train Loss: 0.6195, Val Loss: 0.6982, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.6049, Val Loss: 0.6824, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6022, Val Loss: 0.6713, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.5974, Val Loss: 0.6624, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.5915, Val Loss: 0.6522, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 11, Train Loss: 0.5885, Val Loss: 0.6483, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.5859, Val Loss: 0.6392, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.5783, Val Loss: 0.6338, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.5722, Val Loss: 0.6294, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 15, Train Loss: 0.5708, Val Loss: 0.6229, F1 Micro: 0.6742, F1 Macro: 0.5967, Accuracy: 0.6742\n","Epoch 16, Train Loss: 0.5705, Val Loss: 0.6188, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 17, Train Loss: 0.5693, Val Loss: 0.6106, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 18, Train Loss: 0.5615, Val Loss: 0.6050, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 19, Train Loss: 0.5590, Val Loss: 0.5983, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 20, Train Loss: 0.5545, Val Loss: 0.5950, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 21, Train Loss: 0.5548, Val Loss: 0.5890, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.5566, Val Loss: 0.5838, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 23, Train Loss: 0.5502, Val Loss: 0.5776, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 24, Train Loss: 0.5489, Val Loss: 0.5729, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 25, Train Loss: 0.5392, Val Loss: 0.5717, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 26, Train Loss: 0.5408, Val Loss: 0.5696, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 27, Train Loss: 0.5349, Val Loss: 0.5628, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.5342, Val Loss: 0.5586, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.5305, Val Loss: 0.5565, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 30, Train Loss: 0.5309, Val Loss: 0.5524, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 31, Train Loss: 0.5298, Val Loss: 0.5495, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 32, Train Loss: 0.5275, Val Loss: 0.5485, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.6865168539325844\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7036, Val Loss: 0.6897, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 2, Train Loss: 0.6967, Val Loss: 0.6900, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 3, Train Loss: 0.6952, Val Loss: 0.6905, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 4, Train Loss: 0.6951, Val Loss: 0.6906, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.6949, Val Loss: 0.6908, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6948, Val Loss: 0.6910, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 7, Train Loss: 0.6946, Val Loss: 0.6912, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 8, Train Loss: 0.6950, Val Loss: 0.6913, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6942, Val Loss: 0.6916, F1 Micro: 0.6067, F1 Macro: 0.4029, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6941, Val Loss: 0.6916, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6940, Val Loss: 0.6917, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6939, Val Loss: 0.6917, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6938, Val Loss: 0.6917, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6936, Val Loss: 0.6917, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6935, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6934, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6930, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6932, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6933, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6930, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 21, Train Loss: 0.6929, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6929, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6929, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 24, Train Loss: 0.6929, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6929, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 40, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.6928, Val Loss: 0.6919, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Epoch 51, Train Loss: 0.6928, Val Loss: 0.6918, F1 Micro: 0.6011, F1 Macro: 0.3883, Accuracy: 0.6011\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8617, Val Loss: 1.0127, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 2, Train Loss: 0.8192, Val Loss: 0.9655, F1 Micro: 0.6910, F1 Macro: 0.5817, Accuracy: 0.6910\n","Epoch 3, Train Loss: 0.7953, Val Loss: 0.9162, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 4, Train Loss: 0.7706, Val Loss: 0.8766, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 5, Train Loss: 0.7569, Val Loss: 0.8399, F1 Micro: 0.6854, F1 Macro: 0.5563, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.7373, Val Loss: 0.8018, F1 Micro: 0.6798, F1 Macro: 0.5364, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.7181, Val Loss: 0.7738, F1 Micro: 0.6798, F1 Macro: 0.5277, Accuracy: 0.6798\n","Epoch 8, Train Loss: 0.7104, Val Loss: 0.7571, F1 Micro: 0.6854, F1 Macro: 0.5223, Accuracy: 0.6854\n","Epoch 9, Train Loss: 0.7054, Val Loss: 0.7395, F1 Micro: 0.6742, F1 Macro: 0.4951, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.7017, Val Loss: 0.7285, F1 Micro: 0.6742, F1 Macro: 0.4951, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.7005, Val Loss: 0.7208, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6999, Val Loss: 0.7181, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6996, Val Loss: 0.7156, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 14, Train Loss: 0.6994, Val Loss: 0.7129, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 15, Train Loss: 0.6992, Val Loss: 0.7093, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.6991, Val Loss: 0.7066, F1 Micro: 0.6685, F1 Macro: 0.4810, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6988, Val Loss: 0.7057, F1 Micro: 0.6742, F1 Macro: 0.4843, Accuracy: 0.6742\n","Epoch 18, Train Loss: 0.6986, Val Loss: 0.7048, F1 Micro: 0.6742, F1 Macro: 0.4843, Accuracy: 0.6742\n","Epoch 19, Train Loss: 0.6986, Val Loss: 0.7038, F1 Micro: 0.6742, F1 Macro: 0.4843, Accuracy: 0.6742\n","Epoch 20, Train Loss: 0.6982, Val Loss: 0.7032, F1 Micro: 0.6742, F1 Macro: 0.4843, Accuracy: 0.6742\n","Epoch 21, Train Loss: 0.6979, Val Loss: 0.7024, F1 Micro: 0.6798, F1 Macro: 0.4877, Accuracy: 0.6798\n","Epoch 22, Train Loss: 0.7006, Val Loss: 0.7022, F1 Micro: 0.6798, F1 Macro: 0.4877, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.6974, Val Loss: 0.7012, F1 Micro: 0.6798, F1 Macro: 0.4760, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6972, Val Loss: 0.7007, F1 Micro: 0.6742, F1 Macro: 0.4606, Accuracy: 0.6742\n","Epoch 25, Train Loss: 0.6970, Val Loss: 0.7004, F1 Micro: 0.6742, F1 Macro: 0.4606, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.6968, Val Loss: 0.6999, F1 Micro: 0.6742, F1 Macro: 0.4606, Accuracy: 0.6742\n","Epoch 27, Train Loss: 0.6966, Val Loss: 0.6996, F1 Micro: 0.6742, F1 Macro: 0.4476, Accuracy: 0.6742\n","Epoch 28, Train Loss: 0.6965, Val Loss: 0.6995, F1 Micro: 0.6742, F1 Macro: 0.4476, Accuracy: 0.6742\n","Epoch 29, Train Loss: 0.6963, Val Loss: 0.6994, F1 Micro: 0.6742, F1 Macro: 0.4476, Accuracy: 0.6742\n","Epoch 30, Train Loss: 0.6962, Val Loss: 0.6992, F1 Micro: 0.6742, F1 Macro: 0.4476, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.6957, Val Loss: 0.6990, F1 Micro: 0.6685, F1 Macro: 0.4311, Accuracy: 0.6685\n","Epoch 32, Train Loss: 0.6959, Val Loss: 0.6989, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 33, Train Loss: 0.6952, Val Loss: 0.6987, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.6957, Val Loss: 0.6986, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.6957, Val Loss: 0.6985, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 36, Train Loss: 0.6955, Val Loss: 0.6984, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.6954, Val Loss: 0.6983, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.6953, Val Loss: 0.6982, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 39, Train Loss: 0.6955, Val Loss: 0.6981, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 40, Train Loss: 0.6952, Val Loss: 0.6979, F1 Micro: 0.6854, F1 Macro: 0.4792, Accuracy: 0.6854\n","Epoch 41, Train Loss: 0.6950, Val Loss: 0.6978, F1 Micro: 0.6798, F1 Macro: 0.4636, Accuracy: 0.6798\n","Epoch 42, Train Loss: 0.6952, Val Loss: 0.6976, F1 Micro: 0.6910, F1 Macro: 0.4944, Accuracy: 0.6910\n","Epoch 43, Train Loss: 0.6951, Val Loss: 0.6976, F1 Micro: 0.6854, F1 Macro: 0.4792, Accuracy: 0.6854\n","Epoch 44, Train Loss: 0.6948, Val Loss: 0.6973, F1 Micro: 0.6910, F1 Macro: 0.4944, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.6940, Val Loss: 0.6970, F1 Micro: 0.6910, F1 Macro: 0.4944, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.6946, Val Loss: 0.6967, F1 Micro: 0.6910, F1 Macro: 0.4944, Accuracy: 0.6910\n","Epoch 47, Train Loss: 0.6945, Val Loss: 0.6965, F1 Micro: 0.6910, F1 Macro: 0.4944, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.6944, Val Loss: 0.6962, F1 Micro: 0.6910, F1 Macro: 0.4944, Accuracy: 0.6910\n","Epoch 49, Train Loss: 0.6944, Val Loss: 0.6960, F1 Micro: 0.6966, F1 Macro: 0.5092, Accuracy: 0.6966\n","Epoch 50, Train Loss: 0.6938, Val Loss: 0.6955, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 51, Train Loss: 0.6941, Val Loss: 0.6951, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 52, Train Loss: 0.6939, Val Loss: 0.6945, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 53, Train Loss: 0.6938, Val Loss: 0.6942, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 54, Train Loss: 0.6937, Val Loss: 0.6942, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 55, Train Loss: 0.6936, Val Loss: 0.6938, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 56, Train Loss: 0.6937, Val Loss: 0.6934, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 57, Train Loss: 0.6936, Val Loss: 0.6929, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 58, Train Loss: 0.6938, Val Loss: 0.6930, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 59, Train Loss: 0.6933, Val Loss: 0.6926, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 60, Train Loss: 0.6926, Val Loss: 0.6922, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 61, Train Loss: 0.6934, Val Loss: 0.6923, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 62, Train Loss: 0.6928, Val Loss: 0.6917, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 63, Train Loss: 0.6931, Val Loss: 0.6912, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.6928, Val Loss: 0.6910, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 65, Train Loss: 0.6928, Val Loss: 0.6906, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 66, Train Loss: 0.6926, Val Loss: 0.6903, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 67, Train Loss: 0.6923, Val Loss: 0.6897, F1 Micro: 0.7022, F1 Macro: 0.5236, Accuracy: 0.7022\n","Epoch 68, Train Loss: 0.6920, Val Loss: 0.6892, F1 Micro: 0.7022, F1 Macro: 0.5338, Accuracy: 0.7022\n","Epoch 69, Train Loss: 0.6922, Val Loss: 0.6890, F1 Micro: 0.7022, F1 Macro: 0.5433, Accuracy: 0.7022\n","Epoch 70, Train Loss: 0.6916, Val Loss: 0.6884, F1 Micro: 0.7022, F1 Macro: 0.5433, Accuracy: 0.7022\n","Epoch 71, Train Loss: 0.6910, Val Loss: 0.6884, F1 Micro: 0.7022, F1 Macro: 0.5433, Accuracy: 0.7022\n","Epoch 72, Train Loss: 0.6900, Val Loss: 0.6884, F1 Micro: 0.7079, F1 Macro: 0.5565, Accuracy: 0.7079\n","Epoch 73, Train Loss: 0.6901, Val Loss: 0.6885, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 74, Train Loss: 0.6957, Val Loss: 0.6896, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 75, Train Loss: 0.6887, Val Loss: 0.6884, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 76, Train Loss: 0.6888, Val Loss: 0.6876, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 77, Train Loss: 0.6886, Val Loss: 0.6881, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 78, Train Loss: 0.6886, Val Loss: 0.6875, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 79, Train Loss: 0.6884, Val Loss: 0.6879, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 80, Train Loss: 0.6870, Val Loss: 0.6874, F1 Micro: 0.7079, F1 Macro: 0.5650, Accuracy: 0.7079\n","Epoch 81, Train Loss: 0.6874, Val Loss: 0.6892, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 82, Train Loss: 0.6876, Val Loss: 0.6897, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 83, Train Loss: 0.6857, Val Loss: 0.6901, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 84, Train Loss: 0.6851, Val Loss: 0.6904, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 85, Train Loss: 0.6850, Val Loss: 0.6906, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 86, Train Loss: 0.6841, Val Loss: 0.6900, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 87, Train Loss: 0.6846, Val Loss: 0.6898, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 88, Train Loss: 0.6838, Val Loss: 0.6898, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 89, Train Loss: 0.6841, Val Loss: 0.6879, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 90, Train Loss: 0.6841, Val Loss: 0.6878, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 91, Train Loss: 0.6834, Val Loss: 0.6891, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 92, Train Loss: 0.6830, Val Loss: 0.6884, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 93, Train Loss: 0.6825, Val Loss: 0.6889, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 94, Train Loss: 0.6820, Val Loss: 0.6881, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 95, Train Loss: 0.6824, Val Loss: 0.6879, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 96, Train Loss: 0.6823, Val Loss: 0.6864, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 97, Train Loss: 0.6819, Val Loss: 0.6861, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 98, Train Loss: 0.6802, Val Loss: 0.6856, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 99, Train Loss: 0.6810, Val Loss: 0.6859, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 100, Train Loss: 0.6794, Val Loss: 0.6847, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 101, Train Loss: 0.6814, Val Loss: 0.6854, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 102, Train Loss: 0.6799, Val Loss: 0.6841, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 103, Train Loss: 0.6808, Val Loss: 0.6836, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 104, Train Loss: 0.6782, Val Loss: 0.6830, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 105, Train Loss: 0.6780, Val Loss: 0.6834, F1 Micro: 0.7135, F1 Macro: 0.5925, Accuracy: 0.7135\n","Epoch 106, Train Loss: 0.6796, Val Loss: 0.6829, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 107, Train Loss: 0.6793, Val Loss: 0.6819, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 108, Train Loss: 0.6776, Val Loss: 0.6808, F1 Micro: 0.7135, F1 Macro: 0.5925, Accuracy: 0.7135\n","Epoch 109, Train Loss: 0.6770, Val Loss: 0.6800, F1 Micro: 0.7135, F1 Macro: 0.5925, Accuracy: 0.7135\n","Epoch 110, Train Loss: 0.6763, Val Loss: 0.6793, F1 Micro: 0.7135, F1 Macro: 0.5925, Accuracy: 0.7135\n","Epoch 111, Train Loss: 0.6758, Val Loss: 0.6785, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 112, Train Loss: 0.6753, Val Loss: 0.6783, F1 Micro: 0.7079, F1 Macro: 0.6014, Accuracy: 0.7079\n","Epoch 113, Train Loss: 0.6746, Val Loss: 0.6774, F1 Micro: 0.7135, F1 Macro: 0.6059, Accuracy: 0.7135\n","Epoch 114, Train Loss: 0.6728, Val Loss: 0.6775, F1 Micro: 0.7135, F1 Macro: 0.6121, Accuracy: 0.7135\n","Epoch 115, Train Loss: 0.6728, Val Loss: 0.6768, F1 Micro: 0.7135, F1 Macro: 0.6180, Accuracy: 0.7135\n","Epoch 116, Train Loss: 0.6712, Val Loss: 0.6788, F1 Micro: 0.7079, F1 Macro: 0.6242, Accuracy: 0.7079\n","Epoch 117, Train Loss: 0.6677, Val Loss: 0.6828, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 118, Train Loss: 0.6641, Val Loss: 0.6824, F1 Micro: 0.7303, F1 Macro: 0.6702, Accuracy: 0.7303\n","Epoch 119, Train Loss: 0.6651, Val Loss: 0.6790, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 120, Train Loss: 0.6629, Val Loss: 0.6800, F1 Micro: 0.7303, F1 Macro: 0.6740, Accuracy: 0.7303\n","Epoch 121, Train Loss: 0.6617, Val Loss: 0.6795, F1 Micro: 0.7303, F1 Macro: 0.6776, Accuracy: 0.7303\n","Epoch 122, Train Loss: 0.6601, Val Loss: 0.6808, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 123, Train Loss: 0.6591, Val Loss: 0.6807, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 124, Train Loss: 0.6551, Val Loss: 0.6793, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 125, Train Loss: 0.6538, Val Loss: 0.6795, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 126, Train Loss: 0.6538, Val Loss: 0.6821, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 127, Train Loss: 0.6517, Val Loss: 0.6777, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 128, Train Loss: 0.6521, Val Loss: 0.6782, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 129, Train Loss: 0.6496, Val Loss: 0.6812, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 130, Train Loss: 0.6479, Val Loss: 0.6805, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 131, Train Loss: 0.6486, Val Loss: 0.6849, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 132, Train Loss: 0.6503, Val Loss: 0.6816, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 133, Train Loss: 0.6467, Val Loss: 0.6795, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 134, Train Loss: 0.6484, Val Loss: 0.6811, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 135, Train Loss: 0.6484, Val Loss: 0.6781, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 136, Train Loss: 0.6470, Val Loss: 0.6786, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 137, Train Loss: 0.6458, Val Loss: 0.6820, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 138, Train Loss: 0.6481, Val Loss: 0.6806, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 139, Train Loss: 0.6480, Val Loss: 0.6817, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 140, Train Loss: 0.6465, Val Loss: 0.6816, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 141, Train Loss: 0.6466, Val Loss: 0.6785, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 142, Train Loss: 0.6464, Val Loss: 0.6795, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 143, Train Loss: 0.6448, Val Loss: 0.6796, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 144, Train Loss: 0.6448, Val Loss: 0.6810, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 145, Train Loss: 0.6468, Val Loss: 0.6773, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 146, Train Loss: 0.6465, Val Loss: 0.6790, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 147, Train Loss: 0.6454, Val Loss: 0.6789, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 148, Train Loss: 0.6437, Val Loss: 0.6797, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 149, Train Loss: 0.6447, Val Loss: 0.6763, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 150, Train Loss: 0.6440, Val Loss: 0.6787, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 151, Train Loss: 0.6459, Val Loss: 0.6802, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 152, Train Loss: 0.6451, Val Loss: 0.6769, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 153, Train Loss: 0.6425, Val Loss: 0.6753, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 154, Train Loss: 0.6443, Val Loss: 0.6769, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 155, Train Loss: 0.6437, Val Loss: 0.6788, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Epoch 156, Train Loss: 0.6461, Val Loss: 0.6763, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 157, Train Loss: 0.6443, Val Loss: 0.6769, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 158, Train Loss: 0.6454, Val Loss: 0.6781, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 159, Train Loss: 0.6427, Val Loss: 0.6766, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 160, Train Loss: 0.6439, Val Loss: 0.6738, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 161, Train Loss: 0.6428, Val Loss: 0.6753, F1 Micro: 0.6854, F1 Macro: 0.6607, Accuracy: 0.6854\n","Epoch 162, Train Loss: 0.6445, Val Loss: 0.6740, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 163, Train Loss: 0.6434, Val Loss: 0.6749, F1 Micro: 0.6910, F1 Macro: 0.6657, Accuracy: 0.6910\n","Epoch 164, Train Loss: 0.6427, Val Loss: 0.6740, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 165, Train Loss: 0.6416, Val Loss: 0.6758, F1 Micro: 0.6910, F1 Macro: 0.6679, Accuracy: 0.6910\n","Epoch 166, Train Loss: 0.6432, Val Loss: 0.6767, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 167, Train Loss: 0.6415, Val Loss: 0.6748, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 168, Train Loss: 0.6431, Val Loss: 0.6738, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.0151, Val Loss: 0.9585, F1 Micro: 0.5337, F1 Macro: 0.4455, Accuracy: 0.5337\n","Epoch 2, Train Loss: 0.7343, Val Loss: 0.7834, F1 Micro: 0.5787, F1 Macro: 0.4108, Accuracy: 0.5787\n","Epoch 3, Train Loss: 0.6818, Val Loss: 0.7510, F1 Micro: 0.5899, F1 Macro: 0.4167, Accuracy: 0.5899\n","Epoch 4, Train Loss: 0.6693, Val Loss: 0.7352, F1 Micro: 0.5899, F1 Macro: 0.4167, Accuracy: 0.5899\n","Epoch 5, Train Loss: 0.6504, Val Loss: 0.7170, F1 Micro: 0.5843, F1 Macro: 0.4034, Accuracy: 0.5843\n","Epoch 6, Train Loss: 0.6415, Val Loss: 0.7004, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 7, Train Loss: 0.6303, Val Loss: 0.6861, F1 Micro: 0.5899, F1 Macro: 0.4062, Accuracy: 0.5899\n","Epoch 8, Train Loss: 0.6195, Val Loss: 0.6744, F1 Micro: 0.5899, F1 Macro: 0.4062, Accuracy: 0.5899\n","Epoch 9, Train Loss: 0.6129, Val Loss: 0.6612, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6071, Val Loss: 0.6516, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6013, Val Loss: 0.6410, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.5959, Val Loss: 0.6341, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 13, Train Loss: 0.5927, Val Loss: 0.6268, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 14, Train Loss: 0.5873, Val Loss: 0.6222, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 15, Train Loss: 0.5844, Val Loss: 0.6199, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.5851, Val Loss: 0.6165, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 17, Train Loss: 0.5808, Val Loss: 0.6140, F1 Micro: 0.6011, F1 Macro: 0.4326, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.5787, Val Loss: 0.6115, F1 Micro: 0.6011, F1 Macro: 0.4326, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.5808, Val Loss: 0.6096, F1 Micro: 0.6011, F1 Macro: 0.4326, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.5756, Val Loss: 0.6072, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 21, Train Loss: 0.5796, Val Loss: 0.6058, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 22, Train Loss: 0.5754, Val Loss: 0.6042, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 23, Train Loss: 0.5737, Val Loss: 0.6018, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.5700, Val Loss: 0.5992, F1 Micro: 0.6180, F1 Macro: 0.4787, Accuracy: 0.6180\n","Epoch 25, Train Loss: 0.5703, Val Loss: 0.5973, F1 Micro: 0.6236, F1 Macro: 0.4823, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.5678, Val Loss: 0.5955, F1 Micro: 0.6236, F1 Macro: 0.4904, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.5701, Val Loss: 0.5940, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 28, Train Loss: 0.5690, Val Loss: 0.5923, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 29, Train Loss: 0.5671, Val Loss: 0.5903, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 30, Train Loss: 0.5645, Val Loss: 0.5888, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 31, Train Loss: 0.5655, Val Loss: 0.5870, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 32, Train Loss: 0.5634, Val Loss: 0.5855, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 33, Train Loss: 0.5642, Val Loss: 0.5843, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 34, Train Loss: 0.5622, Val Loss: 0.5827, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 35, Train Loss: 0.5643, Val Loss: 0.5815, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 36, Train Loss: 0.5625, Val Loss: 0.5807, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 37, Train Loss: 0.5603, Val Loss: 0.5790, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 38, Train Loss: 0.5600, Val Loss: 0.5777, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 39, Train Loss: 0.5589, Val Loss: 0.5768, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 40, Train Loss: 0.5617, Val Loss: 0.5758, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 41, Train Loss: 0.5588, Val Loss: 0.5751, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 42, Train Loss: 0.5558, Val Loss: 0.5738, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 43, Train Loss: 0.5550, Val Loss: 0.5688, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.5558, Val Loss: 0.5441, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.5431, Val Loss: 0.5391, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.5412, Val Loss: 0.5368, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.5433, Val Loss: 0.5366, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.5403, Val Loss: 0.5363, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.5427, Val Loss: 0.5345, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.5386, Val Loss: 0.5340, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 51, Train Loss: 0.5485, Val Loss: 0.5322, F1 Micro: 0.6517, F1 Macro: 0.5390, Accuracy: 0.6517\n","Epoch 52, Train Loss: 0.5384, Val Loss: 0.5320, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 53, Train Loss: 0.5382, Val Loss: 0.5321, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 54, Train Loss: 0.5398, Val Loss: 0.5309, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 55, Train Loss: 0.5377, Val Loss: 0.5302, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 56, Train Loss: 0.5371, Val Loss: 0.5313, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 57, Train Loss: 0.5364, Val Loss: 0.5291, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 58, Train Loss: 0.5450, Val Loss: 0.5294, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 59, Train Loss: 0.5390, Val Loss: 0.5309, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 60, Train Loss: 0.5395, Val Loss: 0.5282, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 61, Train Loss: 0.5394, Val Loss: 0.5286, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 62, Train Loss: 0.5376, Val Loss: 0.5274, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.5364, Val Loss: 0.5268, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 64, Train Loss: 0.5362, Val Loss: 0.5271, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 65, Train Loss: 0.5329, Val Loss: 0.5262, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 66, Train Loss: 0.5357, Val Loss: 0.5258, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 67, Train Loss: 0.5355, Val Loss: 0.5260, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 68, Train Loss: 0.5353, Val Loss: 0.5260, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 69, Train Loss: 0.5370, Val Loss: 0.5260, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.5389, Val Loss: 0.5247, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 71, Train Loss: 0.5341, Val Loss: 0.5250, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 72, Train Loss: 0.5367, Val Loss: 0.5249, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 73, Train Loss: 0.5380, Val Loss: 0.5237, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 74, Train Loss: 0.5345, Val Loss: 0.5241, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 75, Train Loss: 0.5356, Val Loss: 0.5251, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 76, Train Loss: 0.5409, Val Loss: 0.5235, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.5347, Val Loss: 0.5236, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 78, Train Loss: 0.5341, Val Loss: 0.5233, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 79, Train Loss: 0.5353, Val Loss: 0.5222, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 80, Train Loss: 0.5351, Val Loss: 0.5239, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 81, Train Loss: 0.5373, Val Loss: 0.5229, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 82, Train Loss: 0.5431, Val Loss: 0.5225, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 83, Train Loss: 0.5375, Val Loss: 0.5219, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 84, Train Loss: 0.5369, Val Loss: 0.5233, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 85, Train Loss: 0.5357, Val Loss: 0.5226, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 86, Train Loss: 0.5358, Val Loss: 0.5219, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 87, Train Loss: 0.5348, Val Loss: 0.5218, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 88, Train Loss: 0.5369, Val Loss: 0.5212, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 89, Train Loss: 0.5355, Val Loss: 0.5224, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 90, Train Loss: 0.5352, Val Loss: 0.5215, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.5327, Val Loss: 0.5210, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 92, Train Loss: 0.5345, Val Loss: 0.5208, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 93, Train Loss: 0.5346, Val Loss: 0.5218, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 94, Train Loss: 0.5368, Val Loss: 0.5206, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 95, Train Loss: 0.5333, Val Loss: 0.5207, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 96, Train Loss: 0.5381, Val Loss: 0.5208, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 97, Train Loss: 0.5366, Val Loss: 0.5208, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 98, Train Loss: 0.5346, Val Loss: 0.5221, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 99, Train Loss: 0.5358, Val Loss: 0.5206, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 100, Train Loss: 0.5334, Val Loss: 0.5198, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 101, Train Loss: 0.5337, Val Loss: 0.5210, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 102, Train Loss: 0.5346, Val Loss: 0.5206, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 103, Train Loss: 0.5359, Val Loss: 0.5193, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 104, Train Loss: 0.5337, Val Loss: 0.5195, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 105, Train Loss: 0.5342, Val Loss: 0.5196, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 106, Train Loss: 0.5343, Val Loss: 0.5198, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 107, Train Loss: 0.5388, Val Loss: 0.5194, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 108, Train Loss: 0.5339, Val Loss: 0.5192, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 109, Train Loss: 0.5340, Val Loss: 0.5198, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 110, Train Loss: 0.5333, Val Loss: 0.5201, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 111, Train Loss: 0.5351, Val Loss: 0.5191, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 112, Train Loss: 0.5334, Val Loss: 0.5189, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 113, Train Loss: 0.5312, Val Loss: 0.5188, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 114, Train Loss: 0.5312, Val Loss: 0.5180, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 115, Train Loss: 0.5333, Val Loss: 0.5202, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 116, Train Loss: 0.5327, Val Loss: 0.5178, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 117, Train Loss: 0.5340, Val Loss: 0.5185, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 118, Train Loss: 0.5314, Val Loss: 0.5181, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 119, Train Loss: 0.5317, Val Loss: 0.5181, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 120, Train Loss: 0.5345, Val Loss: 0.5191, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 121, Train Loss: 0.5308, Val Loss: 0.5181, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 122, Train Loss: 0.5331, Val Loss: 0.5183, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 123, Train Loss: 0.5357, Val Loss: 0.5181, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 124, Train Loss: 0.5369, Val Loss: 0.5185, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 125, Train Loss: 0.5325, Val Loss: 0.5178, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 126, Train Loss: 0.5353, Val Loss: 0.5187, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 127, Train Loss: 0.5338, Val Loss: 0.5173, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 128, Train Loss: 0.5321, Val Loss: 0.5180, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 129, Train Loss: 0.5350, Val Loss: 0.5191, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 130, Train Loss: 0.5351, Val Loss: 0.5182, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 131, Train Loss: 0.5356, Val Loss: 0.5196, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 132, Train Loss: 0.5338, Val Loss: 0.5173, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 133, Train Loss: 0.5352, Val Loss: 0.5175, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 134, Train Loss: 0.5375, Val Loss: 0.5190, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 135, Train Loss: 0.5352, Val Loss: 0.5170, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 136, Train Loss: 0.5361, Val Loss: 0.5164, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 137, Train Loss: 0.5314, Val Loss: 0.5179, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 138, Train Loss: 0.5325, Val Loss: 0.5168, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 139, Train Loss: 0.5348, Val Loss: 0.5176, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 140, Train Loss: 0.5350, Val Loss: 0.5174, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 141, Train Loss: 0.5323, Val Loss: 0.5174, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 142, Train Loss: 0.5334, Val Loss: 0.5173, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 143, Train Loss: 0.5333, Val Loss: 0.5171, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 144, Train Loss: 0.5304, Val Loss: 0.5179, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 145, Train Loss: 0.5368, Val Loss: 0.5164, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 146, Train Loss: 0.5317, Val Loss: 0.5180, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6925, Val Loss: 0.6952, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6920, Val Loss: 0.6948, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6907, Val Loss: 0.6947, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6915, Val Loss: 0.6945, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6914, Val Loss: 0.6943, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6913, Val Loss: 0.6942, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6912, Val Loss: 0.6939, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6910, Val Loss: 0.6938, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6909, Val Loss: 0.6936, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6908, Val Loss: 0.6936, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6906, Val Loss: 0.6933, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6905, Val Loss: 0.6930, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6902, Val Loss: 0.6929, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6901, Val Loss: 0.6928, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6899, Val Loss: 0.6926, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6898, Val Loss: 0.6925, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6896, Val Loss: 0.6924, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6894, Val Loss: 0.6922, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6894, Val Loss: 0.6921, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6892, Val Loss: 0.6920, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6881, Val Loss: 0.6920, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6886, Val Loss: 0.6918, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6890, Val Loss: 0.6918, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6887, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6888, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6887, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6887, Val Loss: 0.6915, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6887, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6886, Val Loss: 0.6915, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6885, Val Loss: 0.6924, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6887, Val Loss: 0.6924, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6885, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6885, Val Loss: 0.6917, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6885, Val Loss: 0.6919, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6886, Val Loss: 0.6926, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6885, Val Loss: 0.6923, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6885, Val Loss: 0.6920, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6879, Val Loss: 0.6913, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6886, Val Loss: 0.6922, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6877, Val Loss: 0.6912, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6884, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6884, Val Loss: 0.6913, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6884, Val Loss: 0.6928, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6884, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6884, Val Loss: 0.6923, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6882, Val Loss: 0.6912, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6883, Val Loss: 0.6914, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6883, Val Loss: 0.6915, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6883, Val Loss: 0.6921, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6883, Val Loss: 0.6920, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6883, Val Loss: 0.6916, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 4.1593, Val Loss: 3.7302, F1 Micro: 0.3427, F1 Macro: 0.3295, Accuracy: 0.3427\n","Epoch 2, Train Loss: 3.1506, Val Loss: 2.7238, F1 Micro: 0.3371, F1 Macro: 0.3317, Accuracy: 0.3371\n","Epoch 3, Train Loss: 2.3206, Val Loss: 1.9142, F1 Micro: 0.3989, F1 Macro: 0.3984, Accuracy: 0.3989\n","Epoch 4, Train Loss: 1.6827, Val Loss: 1.4102, F1 Micro: 0.4551, F1 Macro: 0.4422, Accuracy: 0.4551\n","Epoch 5, Train Loss: 1.2775, Val Loss: 1.1156, F1 Micro: 0.5112, F1 Macro: 0.4809, Accuracy: 0.5112\n","Epoch 6, Train Loss: 1.0539, Val Loss: 0.9692, F1 Micro: 0.5562, F1 Macro: 0.5014, Accuracy: 0.5562\n","Epoch 7, Train Loss: 0.9274, Val Loss: 0.8962, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 8, Train Loss: 0.8546, Val Loss: 0.8495, F1 Micro: 0.6236, F1 Macro: 0.5423, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.8109, Val Loss: 0.8190, F1 Micro: 0.6180, F1 Macro: 0.5328, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.7830, Val Loss: 0.7963, F1 Micro: 0.6348, F1 Macro: 0.5453, Accuracy: 0.6348\n","Epoch 11, Train Loss: 0.7663, Val Loss: 0.7801, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.7549, Val Loss: 0.7675, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 13, Train Loss: 0.7460, Val Loss: 0.7564, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 14, Train Loss: 0.7365, Val Loss: 0.7458, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 15, Train Loss: 0.7303, Val Loss: 0.7380, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.7256, Val Loss: 0.7333, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.7221, Val Loss: 0.7295, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.7194, Val Loss: 0.7268, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.7175, Val Loss: 0.7254, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.7160, Val Loss: 0.7230, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.7146, Val Loss: 0.7206, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.7129, Val Loss: 0.7183, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.7115, Val Loss: 0.7160, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.7099, Val Loss: 0.7136, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.7088, Val Loss: 0.7120, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.7075, Val Loss: 0.7101, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 27, Train Loss: 0.7070, Val Loss: 0.7086, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 28, Train Loss: 0.7056, Val Loss: 0.7074, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.7048, Val Loss: 0.7060, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.7041, Val Loss: 0.7042, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.7023, Val Loss: 0.7022, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 32, Train Loss: 0.6994, Val Loss: 0.7006, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.6986, Val Loss: 0.6995, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 34, Train Loss: 0.6968, Val Loss: 0.6984, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.6955, Val Loss: 0.6977, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 36, Train Loss: 0.6944, Val Loss: 0.6970, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 37, Train Loss: 0.6938, Val Loss: 0.6962, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 38, Train Loss: 0.6929, Val Loss: 0.6964, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 39, Train Loss: 0.6920, Val Loss: 0.6960, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 40, Train Loss: 0.6924, Val Loss: 0.6957, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.6920, Val Loss: 0.6952, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.6920, Val Loss: 0.6944, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.6916, Val Loss: 0.6939, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.6915, Val Loss: 0.6932, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 45, Train Loss: 0.6910, Val Loss: 0.6927, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.6909, Val Loss: 0.6923, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 47, Train Loss: 0.6908, Val Loss: 0.6920, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.6907, Val Loss: 0.6920, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 49, Train Loss: 0.6903, Val Loss: 0.6913, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 50, Train Loss: 0.6900, Val Loss: 0.6911, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6901, Val Loss: 0.6913, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.6893, Val Loss: 0.6911, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 53, Train Loss: 0.6899, Val Loss: 0.6908, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 54, Train Loss: 0.6895, Val Loss: 0.6908, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 55, Train Loss: 0.6897, Val Loss: 0.6908, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 56, Train Loss: 0.6896, Val Loss: 0.6907, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 57, Train Loss: 0.6894, Val Loss: 0.6903, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 58, Train Loss: 0.6890, Val Loss: 0.6901, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 59, Train Loss: 0.6892, Val Loss: 0.6898, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 60, Train Loss: 0.6890, Val Loss: 0.6896, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 61, Train Loss: 0.6891, Val Loss: 0.6897, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 62, Train Loss: 0.6889, Val Loss: 0.6894, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 63, Train Loss: 0.6887, Val Loss: 0.6892, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 64, Train Loss: 0.6885, Val Loss: 0.6889, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Epoch 65, Train Loss: 0.6886, Val Loss: 0.6887, F1 Micro: 0.6573, F1 Macro: 0.5497, Accuracy: 0.6573\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.6426966292134833\n","Best hyperparameters for Outer FOLD 2: (0.01, 16, 10) with score 0.7292134831460675\n","Epoch 1, Train Loss: 2.0922, Val Loss: 1.1894, F1 Micro: 0.6323, F1 Macro: 0.5663, Accuracy: 0.6323\n","Epoch 2, Train Loss: 0.7958, Val Loss: 0.6779, F1 Micro: 0.6457, F1 Macro: 0.6409, Accuracy: 0.6457\n","Epoch 3, Train Loss: 0.5776, Val Loss: 0.6217, F1 Micro: 0.6726, F1 Macro: 0.6658, Accuracy: 0.6726\n","Epoch 4, Train Loss: 0.5689, Val Loss: 0.6260, F1 Micro: 0.6368, F1 Macro: 0.6353, Accuracy: 0.6368\n","Epoch 5, Train Loss: 0.5721, Val Loss: 0.6282, F1 Micro: 0.6996, F1 Macro: 0.6793, Accuracy: 0.6996\n","Epoch 6, Train Loss: 0.5783, Val Loss: 0.6322, F1 Micro: 0.6951, F1 Macro: 0.6562, Accuracy: 0.6951\n","Epoch 7, Train Loss: 0.5683, Val Loss: 0.6337, F1 Micro: 0.6547, F1 Macro: 0.6500, Accuracy: 0.6547\n","Epoch 8, Train Loss: 0.5724, Val Loss: 0.6510, F1 Micro: 0.6996, F1 Macro: 0.6552, Accuracy: 0.6996\n","Epoch 9, Train Loss: 0.5845, Val Loss: 0.6512, F1 Micro: 0.6726, F1 Macro: 0.6412, Accuracy: 0.6726\n","Epoch 10, Train Loss: 0.5747, Val Loss: 0.6221, F1 Micro: 0.7040, F1 Macro: 0.6903, Accuracy: 0.7040\n","Epoch 11, Train Loss: 0.5708, Val Loss: 0.6314, F1 Micro: 0.6233, F1 Macro: 0.6231, Accuracy: 0.6233\n","Epoch 12, Train Loss: 0.5851, Val Loss: 0.6611, F1 Micro: 0.6637, F1 Macro: 0.6245, Accuracy: 0.6637\n","Epoch 13, Train Loss: 0.5789, Val Loss: 0.6308, F1 Micro: 0.7040, F1 Macro: 0.6833, Accuracy: 0.7040\n","Epoch 14, Train Loss: 0.5740, Val Loss: 0.6212, F1 Micro: 0.6906, F1 Macro: 0.6698, Accuracy: 0.6906\n","Epoch 15, Train Loss: 0.5752, Val Loss: 0.6252, F1 Micro: 0.6682, F1 Macro: 0.6639, Accuracy: 0.6682\n","Epoch 16, Train Loss: 0.5761, Val Loss: 0.6187, F1 Micro: 0.6816, F1 Macro: 0.6772, Accuracy: 0.6816\n","Epoch 17, Train Loss: 0.5685, Val Loss: 0.6334, F1 Micro: 0.6637, F1 Macro: 0.6604, Accuracy: 0.6637\n","Epoch 18, Train Loss: 0.5888, Val Loss: 0.6896, F1 Micro: 0.6009, F1 Macro: 0.5988, Accuracy: 0.6009\n","Epoch 19, Train Loss: 0.5846, Val Loss: 0.6421, F1 Micro: 0.6951, F1 Macro: 0.6721, Accuracy: 0.6951\n","Epoch 20, Train Loss: 0.5929, Val Loss: 0.6631, F1 Micro: 0.6054, F1 Macro: 0.6031, Accuracy: 0.6054\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.6054, F1 Macro: 0.6031, Accuracy: 0.6054\n","Outer FOLD 3\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.0955, Val Loss: 0.7004, F1 Micro: 0.5642, F1 Macro: 0.5642, Accuracy: 0.5642\n","Epoch 2, Train Loss: 0.5847, Val Loss: 0.4855, F1 Micro: 0.7374, F1 Macro: 0.6961, Accuracy: 0.7374\n","Epoch 3, Train Loss: 0.6185, Val Loss: 0.5312, F1 Micro: 0.7207, F1 Macro: 0.6915, Accuracy: 0.7207\n","Epoch 4, Train Loss: 0.6126, Val Loss: 0.4599, F1 Micro: 0.7542, F1 Macro: 0.7113, Accuracy: 0.7542\n","Epoch 5, Train Loss: 0.5878, Val Loss: 0.6142, F1 Micro: 0.6816, F1 Macro: 0.6696, Accuracy: 0.6816\n","Epoch 6, Train Loss: 0.5763, Val Loss: 0.5219, F1 Micro: 0.7263, F1 Macro: 0.6966, Accuracy: 0.7263\n","Epoch 7, Train Loss: 0.5953, Val Loss: 0.4732, F1 Micro: 0.7654, F1 Macro: 0.7244, Accuracy: 0.7654\n","Epoch 8, Train Loss: 0.5770, Val Loss: 0.4838, F1 Micro: 0.7709, F1 Macro: 0.7349, Accuracy: 0.7709\n","Epoch 9, Train Loss: 0.5714, Val Loss: 0.4731, F1 Micro: 0.7598, F1 Macro: 0.7193, Accuracy: 0.7598\n","Epoch 10, Train Loss: 0.5681, Val Loss: 0.4795, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 11, Train Loss: 0.5714, Val Loss: 0.4829, F1 Micro: 0.7542, F1 Macro: 0.7141, Accuracy: 0.7542\n","Epoch 12, Train Loss: 0.5725, Val Loss: 0.5203, F1 Micro: 0.7374, F1 Macro: 0.7016, Accuracy: 0.7374\n","Epoch 13, Train Loss: 0.5839, Val Loss: 0.4807, F1 Micro: 0.7542, F1 Macro: 0.7141, Accuracy: 0.7542\n","Epoch 14, Train Loss: 0.6109, Val Loss: 0.4805, F1 Micro: 0.7542, F1 Macro: 0.7169, Accuracy: 0.7542\n","Epoch 15, Train Loss: 0.5774, Val Loss: 0.4844, F1 Micro: 0.7598, F1 Macro: 0.7294, Accuracy: 0.7598\n","Epoch 16, Train Loss: 0.5732, Val Loss: 0.5632, F1 Micro: 0.6983, F1 Macro: 0.6833, Accuracy: 0.6983\n","Epoch 17, Train Loss: 0.6358, Val Loss: 0.5514, F1 Micro: 0.6927, F1 Macro: 0.6782, Accuracy: 0.6927\n","Epoch 18, Train Loss: 0.5752, Val Loss: 0.6054, F1 Micro: 0.6704, F1 Macro: 0.6565, Accuracy: 0.6704\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.3073, Val Loss: 0.5925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.6125, Val Loss: 0.6001, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.6343, Val Loss: 0.5893, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.6299, Val Loss: 0.5900, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6204, Val Loss: 0.5869, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6115, Val Loss: 0.5953, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6048, Val Loss: 0.5963, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6084, Val Loss: 0.6050, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6207, Val Loss: 0.5871, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6258, Val Loss: 0.5857, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6602, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.3410, Val Loss: 0.8981, F1 Micro: 0.5449, F1 Macro: 0.4333, Accuracy: 0.5449\n","Epoch 2, Train Loss: 0.6492, Val Loss: 0.7722, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 3, Train Loss: 0.5984, Val Loss: 0.7387, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 4, Train Loss: 0.6130, Val Loss: 0.7086, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 5, Train Loss: 0.5668, Val Loss: 0.6904, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.5854, Val Loss: 0.9305, F1 Micro: 0.5449, F1 Macro: 0.4105, Accuracy: 0.5449\n","Epoch 7, Train Loss: 0.5712, Val Loss: 0.7821, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 8, Train Loss: 0.5683, Val Loss: 0.6935, F1 Micro: 0.5449, F1 Macro: 0.4261, Accuracy: 0.5449\n","Epoch 9, Train Loss: 0.5809, Val Loss: 0.7192, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 10, Train Loss: 0.5956, Val Loss: 0.7784, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 11, Train Loss: 0.5822, Val Loss: 0.7254, F1 Micro: 0.5393, F1 Macro: 0.4152, Accuracy: 0.5393\n","Epoch 12, Train Loss: 0.5794, Val Loss: 0.6921, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 13, Train Loss: 0.5649, Val Loss: 0.7421, F1 Micro: 0.5506, F1 Macro: 0.4137, Accuracy: 0.5506\n","Epoch 14, Train Loss: 0.5694, Val Loss: 0.7413, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 15, Train Loss: 0.5741, Val Loss: 0.7235, F1 Micro: 0.5618, F1 Macro: 0.4641, Accuracy: 0.5618\n","Epoch 16, Train Loss: 0.5776, Val Loss: 0.7874, F1 Micro: 0.5618, F1 Macro: 0.4577, Accuracy: 0.5618\n","Epoch 17, Train Loss: 0.5678, Val Loss: 0.7496, F1 Micro: 0.5562, F1 Macro: 0.4540, Accuracy: 0.5562\n","Epoch 18, Train Loss: 0.5683, Val Loss: 0.7727, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 19, Train Loss: 0.5708, Val Loss: 0.6885, F1 Micro: 0.5618, F1 Macro: 0.4641, Accuracy: 0.5618\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.2408, Val Loss: 0.6976, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6965, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6933, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.6407067980666625\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7608, Val Loss: 0.6768, F1 Micro: 0.6592, F1 Macro: 0.4642, Accuracy: 0.6592\n","Epoch 2, Train Loss: 0.6871, Val Loss: 0.6767, F1 Micro: 0.6760, F1 Macro: 0.5246, Accuracy: 0.6760\n","Epoch 3, Train Loss: 0.6760, Val Loss: 0.6701, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 4, Train Loss: 0.6784, Val Loss: 0.6669, F1 Micro: 0.6816, F1 Macro: 0.5453, Accuracy: 0.6816\n","Epoch 5, Train Loss: 0.6703, Val Loss: 0.6583, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 6, Train Loss: 0.6686, Val Loss: 0.6506, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 7, Train Loss: 0.6653, Val Loss: 0.6403, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 8, Train Loss: 0.6775, Val Loss: 0.6585, F1 Micro: 0.6927, F1 Macro: 0.5533, Accuracy: 0.6927\n","Epoch 9, Train Loss: 0.6611, Val Loss: 0.6622, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 10, Train Loss: 0.6647, Val Loss: 0.6501, F1 Micro: 0.7318, F1 Macro: 0.6327, Accuracy: 0.7318\n","Epoch 11, Train Loss: 0.6607, Val Loss: 0.6553, F1 Micro: 0.7263, F1 Macro: 0.6390, Accuracy: 0.7263\n","Epoch 12, Train Loss: 0.6643, Val Loss: 0.6501, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 13, Train Loss: 0.6589, Val Loss: 0.6467, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 14, Train Loss: 0.6608, Val Loss: 0.6457, F1 Micro: 0.7430, F1 Macro: 0.6635, Accuracy: 0.7430\n","Epoch 15, Train Loss: 0.6598, Val Loss: 0.6459, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 16, Train Loss: 0.6589, Val Loss: 0.6367, F1 Micro: 0.7486, F1 Macro: 0.6732, Accuracy: 0.7486\n","Epoch 17, Train Loss: 0.6627, Val Loss: 0.6336, F1 Micro: 0.7374, F1 Macro: 0.6633, Accuracy: 0.7374\n","Epoch 18, Train Loss: 0.6630, Val Loss: 0.6424, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 19, Train Loss: 0.6544, Val Loss: 0.6403, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 20, Train Loss: 0.6571, Val Loss: 0.6298, F1 Micro: 0.7486, F1 Macro: 0.6732, Accuracy: 0.7486\n","Epoch 21, Train Loss: 0.6572, Val Loss: 0.6455, F1 Micro: 0.7318, F1 Macro: 0.6489, Accuracy: 0.7318\n","Epoch 22, Train Loss: 0.6550, Val Loss: 0.6430, F1 Micro: 0.7374, F1 Macro: 0.6677, Accuracy: 0.7374\n","Epoch 23, Train Loss: 0.6557, Val Loss: 0.6388, F1 Micro: 0.7374, F1 Macro: 0.6586, Accuracy: 0.7374\n","Epoch 24, Train Loss: 0.6575, Val Loss: 0.6397, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 25, Train Loss: 0.6552, Val Loss: 0.6325, F1 Micro: 0.7486, F1 Macro: 0.6732, Accuracy: 0.7486\n","Epoch 26, Train Loss: 0.6538, Val Loss: 0.6427, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 27, Train Loss: 0.6555, Val Loss: 0.6363, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 28, Train Loss: 0.6556, Val Loss: 0.6375, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 29, Train Loss: 0.6578, Val Loss: 0.6437, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 30, Train Loss: 0.6773, Val Loss: 0.6374, F1 Micro: 0.7486, F1 Macro: 0.6685, Accuracy: 0.7486\n","Epoch 31, Train Loss: 0.6556, Val Loss: 0.6372, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 32, Train Loss: 0.6537, Val Loss: 0.6274, F1 Micro: 0.7430, F1 Macro: 0.6635, Accuracy: 0.7430\n","Epoch 33, Train Loss: 0.6602, Val Loss: 0.6385, F1 Micro: 0.7374, F1 Macro: 0.6586, Accuracy: 0.7374\n","Epoch 34, Train Loss: 0.6550, Val Loss: 0.6370, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 35, Train Loss: 0.6597, Val Loss: 0.6360, F1 Micro: 0.7430, F1 Macro: 0.6682, Accuracy: 0.7430\n","Epoch 36, Train Loss: 0.6524, Val Loss: 0.6397, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 37, Train Loss: 0.6551, Val Loss: 0.6387, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 38, Train Loss: 0.6529, Val Loss: 0.6370, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 39, Train Loss: 0.6522, Val Loss: 0.6378, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 40, Train Loss: 0.6549, Val Loss: 0.6432, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 41, Train Loss: 0.6550, Val Loss: 0.6413, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 42, Train Loss: 0.6428, Val Loss: 0.5054, F1 Micro: 0.7374, F1 Macro: 0.6432, Accuracy: 0.7374\n","Epoch 43, Train Loss: 0.6706, Val Loss: 0.6445, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 44, Train Loss: 0.6696, Val Loss: 0.6433, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 45, Train Loss: 0.6551, Val Loss: 0.6423, F1 Micro: 0.7263, F1 Macro: 0.6280, Accuracy: 0.7263\n","Epoch 46, Train Loss: 0.6549, Val Loss: 0.6428, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 47, Train Loss: 0.6550, Val Loss: 0.6411, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 48, Train Loss: 0.6573, Val Loss: 0.6360, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 49, Train Loss: 0.6528, Val Loss: 0.6386, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 50, Train Loss: 0.6583, Val Loss: 0.6470, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 51, Train Loss: 0.6509, Val Loss: 0.6273, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 52, Train Loss: 0.6603, Val Loss: 0.6401, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 53, Train Loss: 0.6556, Val Loss: 0.6391, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 54, Train Loss: 0.6566, Val Loss: 0.6537, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 55, Train Loss: 0.6612, Val Loss: 0.6321, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 56, Train Loss: 0.6526, Val Loss: 0.6433, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 57, Train Loss: 0.6558, Val Loss: 0.6516, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 58, Train Loss: 0.6541, Val Loss: 0.6414, F1 Micro: 0.7430, F1 Macro: 0.6586, Accuracy: 0.7430\n","Epoch 59, Train Loss: 0.6547, Val Loss: 0.6431, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 60, Train Loss: 0.6512, Val Loss: 0.6396, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 61, Train Loss: 0.6515, Val Loss: 0.6391, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 62, Train Loss: 0.6511, Val Loss: 0.6353, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 63, Train Loss: 0.6541, Val Loss: 0.6377, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 64, Train Loss: 0.6533, Val Loss: 0.6469, F1 Micro: 0.7318, F1 Macro: 0.6438, Accuracy: 0.7318\n","Epoch 65, Train Loss: 0.6509, Val Loss: 0.6296, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 66, Train Loss: 0.6573, Val Loss: 0.6416, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.9265, Val Loss: 0.8239, F1 Micro: 0.6011, F1 Macro: 0.4117, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.5967, Val Loss: 0.5565, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 3, Train Loss: 0.5590, Val Loss: 0.5471, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 4, Train Loss: 0.5518, Val Loss: 0.5435, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 5, Train Loss: 0.5525, Val Loss: 0.5601, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.5773, Val Loss: 0.5900, F1 Micro: 0.6461, F1 Macro: 0.6335, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.5610, Val Loss: 0.5429, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 8, Train Loss: 0.5531, Val Loss: 0.5435, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 9, Train Loss: 0.5663, Val Loss: 0.5243, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.5675, Val Loss: 0.5567, F1 Micro: 0.6854, F1 Macro: 0.6387, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.5483, Val Loss: 0.5911, F1 Micro: 0.7135, F1 Macro: 0.6180, Accuracy: 0.7135\n","Epoch 12, Train Loss: 0.5655, Val Loss: 0.5241, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 13, Train Loss: 0.5454, Val Loss: 0.5265, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 14, Train Loss: 0.5693, Val Loss: 0.5871, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 15, Train Loss: 0.5700, Val Loss: 0.5455, F1 Micro: 0.6685, F1 Macro: 0.6389, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.5707, Val Loss: 0.5311, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 17, Train Loss: 0.5453, Val Loss: 0.5275, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 18, Train Loss: 0.5630, Val Loss: 0.5573, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 19, Train Loss: 0.5592, Val Loss: 0.5400, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 20, Train Loss: 0.5511, Val Loss: 0.5536, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.5753, Val Loss: 0.5499, F1 Micro: 0.7191, F1 Macro: 0.6523, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.5712, Val Loss: 0.5408, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 23, Train Loss: 0.5750, Val Loss: 0.5829, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 24, Train Loss: 0.5550, Val Loss: 0.5265, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 25, Train Loss: 0.5943, Val Loss: 0.7286, F1 Micro: 0.6180, F1 Macro: 0.6096, Accuracy: 0.6180\n","Epoch 26, Train Loss: 0.5585, Val Loss: 0.5212, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 27, Train Loss: 0.5387, Val Loss: 0.5574, F1 Micro: 0.7135, F1 Macro: 0.6475, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.5714, Val Loss: 0.5604, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.5494, Val Loss: 0.5771, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 30, Train Loss: 0.5678, Val Loss: 0.5613, F1 Micro: 0.6742, F1 Macro: 0.6508, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.5631, Val Loss: 0.5436, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.5737, Val Loss: 0.5289, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 33, Train Loss: 0.5800, Val Loss: 0.5915, F1 Micro: 0.6798, F1 Macro: 0.6460, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.5775, Val Loss: 0.5830, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 35, Train Loss: 0.5761, Val Loss: 0.6318, F1 Micro: 0.6180, F1 Macro: 0.6096, Accuracy: 0.6180\n","Epoch 36, Train Loss: 0.5594, Val Loss: 0.5687, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.5616, Val Loss: 0.5437, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Epoch 38, Train Loss: 0.5968, Val Loss: 0.5446, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.5630, Val Loss: 0.5603, F1 Micro: 0.6685, F1 Macro: 0.6459, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.5512, Val Loss: 0.5479, F1 Micro: 0.6854, F1 Macro: 0.6420, Accuracy: 0.6854\n","Epoch 41, Train Loss: 0.5463, Val Loss: 0.5699, F1 Micro: 0.6629, F1 Macro: 0.6388, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.5938, Val Loss: 0.5891, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 43, Train Loss: 0.5585, Val Loss: 0.5567, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 44, Train Loss: 0.6072, Val Loss: 0.5499, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 45, Train Loss: 0.6000, Val Loss: 0.5598, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 46, Train Loss: 0.5600, Val Loss: 0.5600, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 47, Train Loss: 0.5490, Val Loss: 0.5432, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 48, Train Loss: 0.5517, Val Loss: 0.5642, F1 Micro: 0.7079, F1 Macro: 0.6468, Accuracy: 0.7079\n","Epoch 49, Train Loss: 0.5638, Val Loss: 0.5325, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 50, Train Loss: 0.5454, Val Loss: 0.5680, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 51, Train Loss: 0.5827, Val Loss: 0.5889, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 52, Train Loss: 0.5487, Val Loss: 0.5491, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 53, Train Loss: 0.5564, Val Loss: 0.7320, F1 Micro: 0.5730, F1 Macro: 0.5725, Accuracy: 0.5730\n","Epoch 54, Train Loss: 0.5653, Val Loss: 0.5614, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 55, Train Loss: 0.5699, Val Loss: 0.6294, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 56, Train Loss: 0.5737, Val Loss: 0.5339, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.5419, Val Loss: 0.6329, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 58, Train Loss: 0.6011, Val Loss: 0.6236, F1 Micro: 0.7135, F1 Macro: 0.6236, Accuracy: 0.7135\n","Epoch 59, Train Loss: 0.5698, Val Loss: 0.5853, F1 Micro: 0.7135, F1 Macro: 0.6432, Accuracy: 0.7135\n","Epoch 60, Train Loss: 0.5688, Val Loss: 0.5346, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 61, Train Loss: 0.5463, Val Loss: 0.5327, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 62, Train Loss: 0.5653, Val Loss: 0.5472, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 63, Train Loss: 0.5643, Val Loss: 0.5566, F1 Micro: 0.6798, F1 Macro: 0.6558, Accuracy: 0.6798\n","Epoch 64, Train Loss: 0.5649, Val Loss: 0.5552, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 65, Train Loss: 0.5717, Val Loss: 0.5533, F1 Micro: 0.6854, F1 Macro: 0.6352, Accuracy: 0.6854\n","Epoch 66, Train Loss: 0.5598, Val Loss: 0.5467, F1 Micro: 0.6742, F1 Macro: 0.6462, Accuracy: 0.6742\n","Epoch 67, Train Loss: 0.5661, Val Loss: 0.5484, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 68, Train Loss: 0.5719, Val Loss: 0.5514, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 69, Train Loss: 0.5803, Val Loss: 0.5493, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 70, Train Loss: 0.5650, Val Loss: 0.5436, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.5526, Val Loss: 0.5692, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7094, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6948, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6930, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6927, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6923, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6932, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6929, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6942, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7276, Val Loss: 0.6925, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 2, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6919, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6918, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6919, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6920, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6919, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6919, Val Loss: 0.6931, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 9, Train Loss: 0.6916, Val Loss: 0.6927, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 10, Train Loss: 0.6914, Val Loss: 0.6925, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 11, Train Loss: 0.6925, Val Loss: 0.6926, F1 Micro: 0.6067, F1 Macro: 0.3906, Accuracy: 0.6067\n","Epoch 12, Train Loss: 0.6894, Val Loss: 0.6782, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6892, Val Loss: 0.6744, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6736, Val Loss: 0.6553, F1 Micro: 0.6910, F1 Macro: 0.5880, Accuracy: 0.6910\n","Epoch 15, Train Loss: 0.6676, Val Loss: 0.6628, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.6599, Val Loss: 0.6437, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.6632, Val Loss: 0.6485, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 18, Train Loss: 0.6610, Val Loss: 0.6480, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 19, Train Loss: 0.6653, Val Loss: 0.6502, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 20, Train Loss: 0.6547, Val Loss: 0.6430, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 21, Train Loss: 0.6571, Val Loss: 0.6476, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 22, Train Loss: 0.6599, Val Loss: 0.6516, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 23, Train Loss: 0.6594, Val Loss: 0.6512, F1 Micro: 0.7135, F1 Macro: 0.6807, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.6528, Val Loss: 0.6492, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 25, Train Loss: 0.6567, Val Loss: 0.6499, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 26, Train Loss: 0.6662, Val Loss: 0.6441, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 27, Train Loss: 0.6640, Val Loss: 0.6437, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 28, Train Loss: 0.6646, Val Loss: 0.6520, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 29, Train Loss: 0.6588, Val Loss: 0.6429, F1 Micro: 0.6910, F1 Macro: 0.6400, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.6591, Val Loss: 0.6428, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 31, Train Loss: 0.6607, Val Loss: 0.6419, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6557, Val Loss: 0.6426, F1 Micro: 0.7079, F1 Macro: 0.6384, Accuracy: 0.7079\n","Epoch 33, Train Loss: 0.6645, Val Loss: 0.6429, F1 Micro: 0.6854, F1 Macro: 0.6197, Accuracy: 0.6854\n","Epoch 34, Train Loss: 0.6597, Val Loss: 0.6458, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.6662, Val Loss: 0.6555, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.6592, Val Loss: 0.6493, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 37, Train Loss: 0.6609, Val Loss: 0.6467, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 38, Train Loss: 0.6625, Val Loss: 0.6476, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 39, Train Loss: 0.6583, Val Loss: 0.6534, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 40, Train Loss: 0.6518, Val Loss: 0.6556, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 41, Train Loss: 0.6582, Val Loss: 0.6502, F1 Micro: 0.7135, F1 Macro: 0.6754, Accuracy: 0.7135\n","Epoch 42, Train Loss: 0.6631, Val Loss: 0.6477, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 43, Train Loss: 0.6622, Val Loss: 0.6454, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 44, Train Loss: 0.6588, Val Loss: 0.6478, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.6597, Val Loss: 0.6491, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 46, Train Loss: 0.6570, Val Loss: 0.6589, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 47, Train Loss: 0.6603, Val Loss: 0.6463, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 48, Train Loss: 0.6574, Val Loss: 0.6472, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 49, Train Loss: 0.6597, Val Loss: 0.6463, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 50, Train Loss: 0.6558, Val Loss: 0.6466, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 51, Train Loss: 0.6589, Val Loss: 0.6491, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 52, Train Loss: 0.6569, Val Loss: 0.6638, F1 Micro: 0.7022, F1 Macro: 0.6799, Accuracy: 0.7022\n","Epoch 53, Train Loss: 0.6593, Val Loss: 0.6585, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 54, Train Loss: 0.6602, Val Loss: 0.6476, F1 Micro: 0.7022, F1 Macro: 0.6496, Accuracy: 0.7022\n","Epoch 55, Train Loss: 0.6709, Val Loss: 0.6475, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 56, Train Loss: 0.6574, Val Loss: 0.6466, F1 Micro: 0.6742, F1 Macro: 0.6258, Accuracy: 0.6742\n","Epoch 57, Train Loss: 0.6725, Val Loss: 0.6462, F1 Micro: 0.6742, F1 Macro: 0.6222, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.6595, Val Loss: 0.6445, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 59, Train Loss: 0.6624, Val Loss: 0.6501, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 60, Train Loss: 0.6579, Val Loss: 0.6467, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 61, Train Loss: 0.6614, Val Loss: 0.6505, F1 Micro: 0.7022, F1 Macro: 0.6459, Accuracy: 0.7022\n","Epoch 62, Train Loss: 0.6589, Val Loss: 0.6549, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 63, Train Loss: 0.6583, Val Loss: 0.6493, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 64, Train Loss: 0.6593, Val Loss: 0.6511, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 65, Train Loss: 0.6589, Val Loss: 0.6520, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 66, Train Loss: 0.6581, Val Loss: 0.6546, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 67, Train Loss: 0.6545, Val Loss: 0.6483, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 68, Train Loss: 0.6543, Val Loss: 0.6474, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 69, Train Loss: 0.6537, Val Loss: 0.6525, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 70, Train Loss: 0.6613, Val Loss: 0.6479, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.6601, Val Loss: 0.6487, F1 Micro: 0.7022, F1 Macro: 0.6655, Accuracy: 0.7022\n","Epoch 72, Train Loss: 0.6585, Val Loss: 0.6465, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 73, Train Loss: 0.6606, Val Loss: 0.6462, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.6654510074697131\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6643, Val Loss: 0.5183, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 2, Train Loss: 0.5643, Val Loss: 0.5130, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 3, Train Loss: 0.5594, Val Loss: 0.4926, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 4, Train Loss: 0.5598, Val Loss: 0.5038, F1 Micro: 0.7039, F1 Macro: 0.6095, Accuracy: 0.7039\n","Epoch 5, Train Loss: 0.5629, Val Loss: 0.5189, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 6, Train Loss: 0.5565, Val Loss: 0.4881, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 7, Train Loss: 0.5425, Val Loss: 0.4952, F1 Micro: 0.7039, F1 Macro: 0.5844, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.5541, Val Loss: 0.5154, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 9, Train Loss: 0.5445, Val Loss: 0.5031, F1 Micro: 0.7039, F1 Macro: 0.5844, Accuracy: 0.7039\n","Epoch 10, Train Loss: 0.5573, Val Loss: 0.4901, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 11, Train Loss: 0.5463, Val Loss: 0.5192, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 12, Train Loss: 0.5500, Val Loss: 0.5018, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.5632, Val Loss: 0.5029, F1 Micro: 0.7039, F1 Macro: 0.5844, Accuracy: 0.7039\n","Epoch 14, Train Loss: 0.5448, Val Loss: 0.5470, F1 Micro: 0.6816, F1 Macro: 0.6021, Accuracy: 0.6816\n","Epoch 15, Train Loss: 0.5513, Val Loss: 0.4952, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 16, Train Loss: 0.5531, Val Loss: 0.4871, F1 Micro: 0.7207, F1 Macro: 0.6233, Accuracy: 0.7207\n","Epoch 17, Train Loss: 0.5514, Val Loss: 0.6344, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 18, Train Loss: 0.5616, Val Loss: 0.5147, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 19, Train Loss: 0.5583, Val Loss: 0.5187, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 20, Train Loss: 0.5533, Val Loss: 0.4904, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 21, Train Loss: 0.5466, Val Loss: 0.5065, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 22, Train Loss: 0.5534, Val Loss: 0.5011, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 23, Train Loss: 0.5540, Val Loss: 0.5143, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 24, Train Loss: 0.5473, Val Loss: 0.5014, F1 Micro: 0.7207, F1 Macro: 0.6233, Accuracy: 0.7207\n","Epoch 25, Train Loss: 0.5444, Val Loss: 0.5726, F1 Micro: 0.7039, F1 Macro: 0.6095, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.5738, Val Loss: 0.9909, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 2, Train Loss: 0.7411, Val Loss: 0.7055, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 3, Train Loss: 0.6799, Val Loss: 0.7030, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 4, Train Loss: 0.6724, Val Loss: 0.6974, F1 Micro: 0.6685, F1 Macro: 0.5706, Accuracy: 0.6685\n","Epoch 5, Train Loss: 0.6684, Val Loss: 0.6910, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6617, Val Loss: 0.6908, F1 Micro: 0.6348, F1 Macro: 0.5610, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6606, Val Loss: 0.6869, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.6591, Val Loss: 0.6847, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6557, Val Loss: 0.6910, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 10, Train Loss: 0.6564, Val Loss: 0.6808, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 11, Train Loss: 0.6562, Val Loss: 0.6929, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6542, Val Loss: 0.6869, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.6551, Val Loss: 0.6920, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6552, Val Loss: 0.6884, F1 Micro: 0.6854, F1 Macro: 0.6316, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6536, Val Loss: 0.6836, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6543, Val Loss: 0.6871, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 17, Train Loss: 0.6523, Val Loss: 0.6837, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 18, Train Loss: 0.6526, Val Loss: 0.6882, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 19, Train Loss: 0.6523, Val Loss: 0.6867, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.6525, Val Loss: 0.6871, F1 Micro: 0.6573, F1 Macro: 0.5784, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6945, Val Loss: 0.6681, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.6932, Val Loss: 0.6788, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 3, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6833, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7497, Val Loss: 0.7829, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6952, Val Loss: 0.7577, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6954, Val Loss: 0.7665, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6934, Val Loss: 0.7496, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6936, Val Loss: 0.7321, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6946, Val Loss: 0.7117, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6926, Val Loss: 0.7091, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6922, Val Loss: 0.7046, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6918, Val Loss: 0.7102, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6911, Val Loss: 0.6996, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6912, Val Loss: 0.7080, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6925, Val Loss: 0.5392, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 2, Train Loss: 0.5763, Val Loss: 0.5936, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.5801, Val Loss: 0.5941, F1 Micro: 0.6629, F1 Macro: 0.5539, Accuracy: 0.6629\n","Epoch 4, Train Loss: 0.5885, Val Loss: 0.5336, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 5, Train Loss: 0.5773, Val Loss: 0.5863, F1 Micro: 0.7022, F1 Macro: 0.6856, Accuracy: 0.7022\n","Epoch 6, Train Loss: 0.5712, Val Loss: 0.5467, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 7, Train Loss: 0.5545, Val Loss: 0.5257, F1 Micro: 0.7191, F1 Macro: 0.6743, Accuracy: 0.7191\n","Epoch 8, Train Loss: 0.5691, Val Loss: 0.5348, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.5577, Val Loss: 0.5421, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 10, Train Loss: 0.5655, Val Loss: 0.5497, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 11, Train Loss: 0.5794, Val Loss: 0.5593, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.6621116063021782\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8494, Val Loss: 0.5603, F1 Micro: 0.6872, F1 Macro: 0.5493, Accuracy: 0.6872\n","Epoch 2, Train Loss: 0.5795, Val Loss: 0.5518, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 3, Train Loss: 0.5770, Val Loss: 0.5083, F1 Micro: 0.6927, F1 Macro: 0.5533, Accuracy: 0.6927\n","Epoch 4, Train Loss: 0.5779, Val Loss: 0.5013, F1 Micro: 0.7039, F1 Macro: 0.5772, Accuracy: 0.7039\n","Epoch 5, Train Loss: 0.5691, Val Loss: 0.5310, F1 Micro: 0.6983, F1 Macro: 0.6157, Accuracy: 0.6983\n","Epoch 6, Train Loss: 0.5845, Val Loss: 0.5173, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 7, Train Loss: 0.5765, Val Loss: 0.4897, F1 Micro: 0.7095, F1 Macro: 0.6082, Accuracy: 0.7095\n","Epoch 8, Train Loss: 0.5841, Val Loss: 0.4997, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 9, Train Loss: 0.5889, Val Loss: 0.5518, F1 Micro: 0.6760, F1 Macro: 0.6024, Accuracy: 0.6760\n","Epoch 10, Train Loss: 0.5830, Val Loss: 0.4913, F1 Micro: 0.7095, F1 Macro: 0.6141, Accuracy: 0.7095\n","Epoch 11, Train Loss: 0.5860, Val Loss: 0.5034, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 12, Train Loss: 0.5785, Val Loss: 0.5046, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 13, Train Loss: 0.5834, Val Loss: 0.5226, F1 Micro: 0.7151, F1 Macro: 0.6000, Accuracy: 0.7151\n","Epoch 14, Train Loss: 0.5757, Val Loss: 0.4934, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 15, Train Loss: 0.5823, Val Loss: 0.4955, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 16, Train Loss: 0.5693, Val Loss: 0.4994, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 17, Train Loss: 0.5911, Val Loss: 0.5307, F1 Micro: 0.6872, F1 Macro: 0.6247, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.5691, Val Loss: 0.5010, F1 Micro: 0.7039, F1 Macro: 0.6253, Accuracy: 0.7039\n","Epoch 19, Train Loss: 0.5657, Val Loss: 0.5048, F1 Micro: 0.7263, F1 Macro: 0.6280, Accuracy: 0.7263\n","Epoch 20, Train Loss: 0.5807, Val Loss: 0.5050, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 21, Train Loss: 0.5742, Val Loss: 0.5090, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 22, Train Loss: 0.6020, Val Loss: 0.4815, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 23, Train Loss: 0.5873, Val Loss: 0.5226, F1 Micro: 0.6983, F1 Macro: 0.6206, Accuracy: 0.6983\n","Epoch 24, Train Loss: 0.5713, Val Loss: 0.4842, F1 Micro: 0.7263, F1 Macro: 0.6390, Accuracy: 0.7263\n","Epoch 25, Train Loss: 0.5719, Val Loss: 0.4891, F1 Micro: 0.7318, F1 Macro: 0.6438, Accuracy: 0.7318\n","Epoch 26, Train Loss: 0.5821, Val Loss: 0.4856, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 27, Train Loss: 0.5644, Val Loss: 0.4979, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 28, Train Loss: 0.5706, Val Loss: 0.4999, F1 Micro: 0.7318, F1 Macro: 0.6438, Accuracy: 0.7318\n","Epoch 29, Train Loss: 0.5745, Val Loss: 0.4924, F1 Micro: 0.7263, F1 Macro: 0.6390, Accuracy: 0.7263\n","Epoch 30, Train Loss: 0.5903, Val Loss: 0.5251, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 31, Train Loss: 0.5684, Val Loss: 0.4886, F1 Micro: 0.7486, F1 Macro: 0.6732, Accuracy: 0.7486\n","Epoch 32, Train Loss: 0.5728, Val Loss: 0.4921, F1 Micro: 0.7151, F1 Macro: 0.6440, Accuracy: 0.7151\n","Epoch 33, Train Loss: 0.5687, Val Loss: 0.4844, F1 Micro: 0.7263, F1 Macro: 0.6390, Accuracy: 0.7263\n","Epoch 34, Train Loss: 0.5815, Val Loss: 0.4801, F1 Micro: 0.7374, F1 Macro: 0.6633, Accuracy: 0.7374\n","Epoch 35, Train Loss: 0.5677, Val Loss: 0.5010, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 36, Train Loss: 0.5801, Val Loss: 0.5175, F1 Micro: 0.7263, F1 Macro: 0.6621, Accuracy: 0.7263\n","Epoch 37, Train Loss: 0.5894, Val Loss: 0.4902, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 38, Train Loss: 0.5742, Val Loss: 0.5166, F1 Micro: 0.7263, F1 Macro: 0.6220, Accuracy: 0.7263\n","Epoch 39, Train Loss: 0.5812, Val Loss: 0.5105, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 40, Train Loss: 0.5826, Val Loss: 0.5083, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 41, Train Loss: 0.5783, Val Loss: 0.5156, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 42, Train Loss: 0.5727, Val Loss: 0.4866, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 43, Train Loss: 0.5691, Val Loss: 0.4845, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 44, Train Loss: 0.5701, Val Loss: 0.4884, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 45, Train Loss: 0.5779, Val Loss: 0.4892, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 46, Train Loss: 0.5674, Val Loss: 0.5073, F1 Micro: 0.7151, F1 Macro: 0.6564, Accuracy: 0.7151\n","Epoch 47, Train Loss: 0.5700, Val Loss: 0.4838, F1 Micro: 0.7374, F1 Macro: 0.6633, Accuracy: 0.7374\n","Epoch 48, Train Loss: 0.5714, Val Loss: 0.4805, F1 Micro: 0.7263, F1 Macro: 0.6579, Accuracy: 0.7263\n","Epoch 49, Train Loss: 0.5689, Val Loss: 0.4845, F1 Micro: 0.7374, F1 Macro: 0.6486, Accuracy: 0.7374\n","Epoch 50, Train Loss: 0.5613, Val Loss: 0.5056, F1 Micro: 0.7318, F1 Macro: 0.6438, Accuracy: 0.7318\n","Epoch 51, Train Loss: 0.5646, Val Loss: 0.4892, F1 Micro: 0.7151, F1 Macro: 0.6440, Accuracy: 0.7151\n","Epoch 52, Train Loss: 0.5812, Val Loss: 0.4831, F1 Micro: 0.7430, F1 Macro: 0.6726, Accuracy: 0.7430\n","Epoch 53, Train Loss: 0.5720, Val Loss: 0.4868, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 54, Train Loss: 0.5683, Val Loss: 0.4933, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 55, Train Loss: 0.5688, Val Loss: 0.4866, F1 Micro: 0.7374, F1 Macro: 0.6586, Accuracy: 0.7374\n","Epoch 56, Train Loss: 0.5859, Val Loss: 0.5173, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 57, Train Loss: 0.5749, Val Loss: 0.4878, F1 Micro: 0.7263, F1 Macro: 0.6579, Accuracy: 0.7263\n","Epoch 58, Train Loss: 0.5708, Val Loss: 0.5184, F1 Micro: 0.7095, F1 Macro: 0.6588, Accuracy: 0.7095\n","Epoch 59, Train Loss: 0.5794, Val Loss: 0.4800, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 60, Train Loss: 0.5704, Val Loss: 0.5221, F1 Micro: 0.7374, F1 Macro: 0.6537, Accuracy: 0.7374\n","Epoch 61, Train Loss: 0.5768, Val Loss: 0.4847, F1 Micro: 0.7430, F1 Macro: 0.6635, Accuracy: 0.7430\n","Epoch 62, Train Loss: 0.5847, Val Loss: 0.5604, F1 Micro: 0.6816, F1 Macro: 0.6382, Accuracy: 0.6816\n","Epoch 63, Train Loss: 0.6030, Val Loss: 0.4733, F1 Micro: 0.7374, F1 Macro: 0.6633, Accuracy: 0.7374\n","Epoch 64, Train Loss: 0.5632, Val Loss: 0.4903, F1 Micro: 0.7374, F1 Macro: 0.6586, Accuracy: 0.7374\n","Epoch 65, Train Loss: 0.5801, Val Loss: 0.5020, F1 Micro: 0.7207, F1 Macro: 0.6752, Accuracy: 0.7207\n","Epoch 66, Train Loss: 0.5794, Val Loss: 0.5011, F1 Micro: 0.7039, F1 Macro: 0.6388, Accuracy: 0.7039\n","Epoch 67, Train Loss: 0.5651, Val Loss: 0.4821, F1 Micro: 0.7374, F1 Macro: 0.6633, Accuracy: 0.7374\n","Epoch 68, Train Loss: 0.5684, Val Loss: 0.4858, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 69, Train Loss: 0.5678, Val Loss: 0.4899, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 70, Train Loss: 0.5776, Val Loss: 0.4903, F1 Micro: 0.7374, F1 Macro: 0.6586, Accuracy: 0.7374\n","Epoch 71, Train Loss: 0.5980, Val Loss: 0.4988, F1 Micro: 0.7430, F1 Macro: 0.6726, Accuracy: 0.7430\n","Epoch 72, Train Loss: 0.5592, Val Loss: 0.4779, F1 Micro: 0.7430, F1 Macro: 0.6682, Accuracy: 0.7430\n","Epoch 73, Train Loss: 0.5664, Val Loss: 0.4832, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 74, Train Loss: 0.5726, Val Loss: 0.4940, F1 Micro: 0.7095, F1 Macro: 0.6515, Accuracy: 0.7095\n","Epoch 75, Train Loss: 0.5768, Val Loss: 0.4827, F1 Micro: 0.7374, F1 Macro: 0.6633, Accuracy: 0.7374\n","Epoch 76, Train Loss: 0.5785, Val Loss: 0.4840, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 77, Train Loss: 0.5812, Val Loss: 0.4719, F1 Micro: 0.7151, F1 Macro: 0.6483, Accuracy: 0.7151\n","Epoch 78, Train Loss: 0.5690, Val Loss: 0.4780, F1 Micro: 0.7207, F1 Macro: 0.6612, Accuracy: 0.7207\n","Epoch 79, Train Loss: 0.5710, Val Loss: 0.4917, F1 Micro: 0.7430, F1 Macro: 0.6682, Accuracy: 0.7430\n","Epoch 80, Train Loss: 0.5849, Val Loss: 0.5098, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 81, Train Loss: 0.5707, Val Loss: 0.4883, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.7469, Val Loss: 0.7383, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.6927, Val Loss: 0.7285, F1 Micro: 0.6517, F1 Macro: 0.4712, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6892, Val Loss: 0.7247, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.6878, Val Loss: 0.7240, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.6894, Val Loss: 0.7156, F1 Micro: 0.6517, F1 Macro: 0.4712, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6906, Val Loss: 0.6960, F1 Micro: 0.6461, F1 Macro: 0.4337, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6888, Val Loss: 0.7018, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6867, Val Loss: 0.7027, F1 Micro: 0.6629, F1 Macro: 0.4981, Accuracy: 0.6629\n","Epoch 9, Train Loss: 0.6856, Val Loss: 0.6943, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6860, Val Loss: 0.6903, F1 Micro: 0.6573, F1 Macro: 0.4946, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.6842, Val Loss: 0.6880, F1 Micro: 0.6742, F1 Macro: 0.5405, Accuracy: 0.6742\n","Epoch 12, Train Loss: 0.6855, Val Loss: 0.6894, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6835, Val Loss: 0.6913, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.6852, Val Loss: 0.6872, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6835, Val Loss: 0.6849, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6834, Val Loss: 0.6851, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6885, Val Loss: 0.6842, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Epoch 18, Train Loss: 0.6825, Val Loss: 0.6811, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6824, Val Loss: 0.6843, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.6823, Val Loss: 0.6859, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.6837, Val Loss: 0.6780, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 22, Train Loss: 0.6835, Val Loss: 0.6783, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.6826, Val Loss: 0.6779, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.6821, Val Loss: 0.6785, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.6848, Val Loss: 0.6809, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.6812, Val Loss: 0.6805, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 27, Train Loss: 0.6810, Val Loss: 0.6831, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.6831, Val Loss: 0.6821, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.6823, Val Loss: 0.6835, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 30, Train Loss: 0.6811, Val Loss: 0.6884, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.6825, Val Loss: 0.6827, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 32, Train Loss: 0.6871, Val Loss: 0.6879, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 33, Train Loss: 0.6827, Val Loss: 0.6839, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.6816, Val Loss: 0.6764, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 35, Train Loss: 0.6826, Val Loss: 0.6749, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 36, Train Loss: 0.6820, Val Loss: 0.6759, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 37, Train Loss: 0.6813, Val Loss: 0.6757, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 38, Train Loss: 0.6806, Val Loss: 0.6769, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.6811, Val Loss: 0.6787, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 40, Train Loss: 0.6846, Val Loss: 0.6793, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.6811, Val Loss: 0.6772, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.6821, Val Loss: 0.6857, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.6809, Val Loss: 0.6884, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.6830, Val Loss: 0.6812, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 45, Train Loss: 0.6818, Val Loss: 0.6823, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 46, Train Loss: 0.6853, Val Loss: 0.6749, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 47, Train Loss: 0.6819, Val Loss: 0.6746, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 48, Train Loss: 0.6840, Val Loss: 0.6817, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.6822, Val Loss: 0.6772, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 50, Train Loss: 0.6823, Val Loss: 0.6802, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.6835, Val Loss: 0.6816, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 52, Train Loss: 0.6833, Val Loss: 0.6844, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 53, Train Loss: 0.6814, Val Loss: 0.6882, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 54, Train Loss: 0.6824, Val Loss: 0.6918, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 55, Train Loss: 0.6830, Val Loss: 0.6925, F1 Micro: 0.6517, F1 Macro: 0.4712, Accuracy: 0.6517\n","Epoch 56, Train Loss: 0.6821, Val Loss: 0.6841, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 57, Train Loss: 0.6804, Val Loss: 0.6749, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.6823, Val Loss: 0.6730, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 59, Train Loss: 0.6829, Val Loss: 0.6725, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 60, Train Loss: 0.6830, Val Loss: 0.6826, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 61, Train Loss: 0.6845, Val Loss: 0.6729, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 62, Train Loss: 0.6820, Val Loss: 0.6781, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 63, Train Loss: 0.6816, Val Loss: 0.6783, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 64, Train Loss: 0.6821, Val Loss: 0.6770, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.6816, Val Loss: 0.6753, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 66, Train Loss: 0.6820, Val Loss: 0.6751, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 67, Train Loss: 0.6815, Val Loss: 0.6734, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 68, Train Loss: 0.6814, Val Loss: 0.6749, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 69, Train Loss: 0.6825, Val Loss: 0.6831, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.6820, Val Loss: 0.6796, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 71, Train Loss: 0.6822, Val Loss: 0.6766, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 72, Train Loss: 0.6829, Val Loss: 0.6767, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 73, Train Loss: 0.6830, Val Loss: 0.6823, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 74, Train Loss: 0.6810, Val Loss: 0.6875, F1 Micro: 0.6629, F1 Macro: 0.5163, Accuracy: 0.6629\n","Epoch 75, Train Loss: 0.6817, Val Loss: 0.6834, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 76, Train Loss: 0.6833, Val Loss: 0.6848, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 77, Train Loss: 0.6820, Val Loss: 0.6855, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 78, Train Loss: 0.6826, Val Loss: 0.6883, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 79, Train Loss: 0.6835, Val Loss: 0.6865, F1 Micro: 0.6629, F1 Macro: 0.4777, Accuracy: 0.6629\n","Epoch 80, Train Loss: 0.6854, Val Loss: 0.6786, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 81, Train Loss: 0.6816, Val Loss: 0.6787, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 82, Train Loss: 0.6817, Val Loss: 0.6767, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 83, Train Loss: 0.6811, Val Loss: 0.6771, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 84, Train Loss: 0.6811, Val Loss: 0.6771, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 85, Train Loss: 0.6817, Val Loss: 0.6833, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 86, Train Loss: 0.6815, Val Loss: 0.6892, F1 Micro: 0.6517, F1 Macro: 0.4712, Accuracy: 0.6517\n","Epoch 87, Train Loss: 0.6818, Val Loss: 0.6785, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 88, Train Loss: 0.6805, Val Loss: 0.6738, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 89, Train Loss: 0.6837, Val Loss: 0.6805, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 90, Train Loss: 0.6816, Val Loss: 0.6761, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.6814, Val Loss: 0.6869, F1 Micro: 0.6629, F1 Macro: 0.4777, Accuracy: 0.6629\n","Epoch 92, Train Loss: 0.6822, Val Loss: 0.6786, F1 Micro: 0.6629, F1 Macro: 0.5075, Accuracy: 0.6629\n","Epoch 93, Train Loss: 0.6807, Val Loss: 0.6805, F1 Micro: 0.6685, F1 Macro: 0.5201, Accuracy: 0.6685\n","Epoch 94, Train Loss: 0.6820, Val Loss: 0.6779, F1 Micro: 0.6742, F1 Macro: 0.5148, Accuracy: 0.6742\n","Epoch 95, Train Loss: 0.6809, Val Loss: 0.6860, F1 Micro: 0.6798, F1 Macro: 0.5186, Accuracy: 0.6798\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8485, Val Loss: 1.2837, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.7011, Val Loss: 1.0374, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6930, Val Loss: 1.0430, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6906, Val Loss: 1.0431, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6898, Val Loss: 1.0115, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6899, Val Loss: 1.0105, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6892, Val Loss: 0.9836, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6881, Val Loss: 0.9640, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6885, Val Loss: 1.0103, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.7024, Val Loss: 0.9373, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6883, Val Loss: 0.9406, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6872, Val Loss: 0.9833, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6881, Val Loss: 0.9866, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6944, Val Loss: 0.8714, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6904, Val Loss: 0.9435, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6878, Val Loss: 0.9377, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6877, Val Loss: 0.9477, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6876, Val Loss: 0.9426, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6870, Val Loss: 1.0045, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6926, Val Loss: 0.9519, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6881, Val Loss: 0.9170, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6877, Val Loss: 0.9437, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6877, Val Loss: 0.9156, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6876, Val Loss: 0.9432, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6901, Val Loss: 0.9356, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6876, Val Loss: 0.9265, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6875, Val Loss: 0.9486, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6915, Val Loss: 0.9495, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6877, Val Loss: 0.9318, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6901, Val Loss: 0.9935, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6871, Val Loss: 0.9715, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6867, Val Loss: 0.9544, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6882, Val Loss: 0.9062, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6876, Val Loss: 0.9435, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6864, Val Loss: 0.9716, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6886, Val Loss: 0.9198, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6876, Val Loss: 0.9369, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6872, Val Loss: 0.9689, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6893, Val Loss: 0.9737, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6875, Val Loss: 0.9428, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6873, Val Loss: 0.9188, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6875, Val Loss: 0.9784, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6870, Val Loss: 1.0237, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6881, Val Loss: 0.9552, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6885, Val Loss: 1.0695, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6942, Val Loss: 1.0035, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6881, Val Loss: 0.9622, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6875, Val Loss: 0.9442, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6874, Val Loss: 0.9695, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6873, Val Loss: 0.9720, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6862, Val Loss: 1.0089, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.6722, Val Loss: 1.0972, F1 Micro: 0.5618, F1 Macro: 0.4967, Accuracy: 0.5618\n","Epoch 2, Train Loss: 0.8044, Val Loss: 0.7765, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 3, Train Loss: 0.7110, Val Loss: 0.7396, F1 Micro: 0.5674, F1 Macro: 0.4740, Accuracy: 0.5674\n","Epoch 4, Train Loss: 0.6975, Val Loss: 0.7113, F1 Micro: 0.5674, F1 Macro: 0.4740, Accuracy: 0.5674\n","Epoch 5, Train Loss: 0.6918, Val Loss: 0.7059, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 6, Train Loss: 0.6895, Val Loss: 0.7009, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 7, Train Loss: 0.6889, Val Loss: 0.7012, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 8, Train Loss: 0.6882, Val Loss: 0.7007, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 9, Train Loss: 0.6876, Val Loss: 0.6986, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 10, Train Loss: 0.6867, Val Loss: 0.6978, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 11, Train Loss: 0.6859, Val Loss: 0.6962, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 12, Train Loss: 0.6858, Val Loss: 0.6926, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 13, Train Loss: 0.6849, Val Loss: 0.6964, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 14, Train Loss: 0.6839, Val Loss: 0.6894, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 15, Train Loss: 0.6842, Val Loss: 0.6887, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 16, Train Loss: 0.6832, Val Loss: 0.6873, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 17, Train Loss: 0.6821, Val Loss: 0.6882, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 18, Train Loss: 0.6821, Val Loss: 0.6858, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 19, Train Loss: 0.6812, Val Loss: 0.6832, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 20, Train Loss: 0.6808, Val Loss: 0.6819, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 21, Train Loss: 0.6807, Val Loss: 0.6815, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 22, Train Loss: 0.6803, Val Loss: 0.6793, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 23, Train Loss: 0.6789, Val Loss: 0.6791, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 24, Train Loss: 0.6801, Val Loss: 0.6808, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 25, Train Loss: 0.6794, Val Loss: 0.6790, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 26, Train Loss: 0.6781, Val Loss: 0.6777, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 27, Train Loss: 0.6778, Val Loss: 0.6770, F1 Micro: 0.5730, F1 Macro: 0.4716, Accuracy: 0.5730\n","Epoch 28, Train Loss: 0.6787, Val Loss: 0.6759, F1 Micro: 0.5730, F1 Macro: 0.4650, Accuracy: 0.5730\n","Epoch 29, Train Loss: 0.6768, Val Loss: 0.6753, F1 Micro: 0.5787, F1 Macro: 0.4817, Accuracy: 0.5787\n","Epoch 30, Train Loss: 0.6768, Val Loss: 0.6735, F1 Micro: 0.5787, F1 Macro: 0.4817, Accuracy: 0.5787\n","Epoch 31, Train Loss: 0.6761, Val Loss: 0.6687, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 32, Train Loss: 0.6746, Val Loss: 0.6633, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.6721, Val Loss: 0.6624, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6734, Val Loss: 0.6570, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 35, Train Loss: 0.6717, Val Loss: 0.6609, F1 Micro: 0.6067, F1 Macro: 0.5191, Accuracy: 0.6067\n","Epoch 36, Train Loss: 0.6700, Val Loss: 0.6545, F1 Micro: 0.6180, F1 Macro: 0.5382, Accuracy: 0.6180\n","Epoch 37, Train Loss: 0.6697, Val Loss: 0.6510, F1 Micro: 0.6180, F1 Macro: 0.5382, Accuracy: 0.6180\n","Epoch 38, Train Loss: 0.6675, Val Loss: 0.6468, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 39, Train Loss: 0.6670, Val Loss: 0.6456, F1 Micro: 0.6180, F1 Macro: 0.5382, Accuracy: 0.6180\n","Epoch 40, Train Loss: 0.6638, Val Loss: 0.6424, F1 Micro: 0.6180, F1 Macro: 0.5432, Accuracy: 0.6180\n","Epoch 41, Train Loss: 0.6629, Val Loss: 0.6400, F1 Micro: 0.6180, F1 Macro: 0.5481, Accuracy: 0.6180\n","Epoch 42, Train Loss: 0.6615, Val Loss: 0.6364, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 43, Train Loss: 0.6593, Val Loss: 0.6354, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 44, Train Loss: 0.6583, Val Loss: 0.6339, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 45, Train Loss: 0.6605, Val Loss: 0.6318, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 46, Train Loss: 0.6584, Val Loss: 0.6324, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 47, Train Loss: 0.6572, Val Loss: 0.6293, F1 Micro: 0.6292, F1 Macro: 0.5742, Accuracy: 0.6292\n","Epoch 48, Train Loss: 0.6588, Val Loss: 0.6303, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6585, Val Loss: 0.6305, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6584, Val Loss: 0.6283, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6585, Val Loss: 0.6283, F1 Micro: 0.6236, F1 Macro: 0.5657, Accuracy: 0.6236\n","Epoch 52, Train Loss: 0.6585, Val Loss: 0.6235, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 53, Train Loss: 0.6572, Val Loss: 0.6247, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 54, Train Loss: 0.6599, Val Loss: 0.6221, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 55, Train Loss: 0.6603, Val Loss: 0.6215, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 56, Train Loss: 0.6577, Val Loss: 0.6210, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 57, Train Loss: 0.6578, Val Loss: 0.6231, F1 Micro: 0.6292, F1 Macro: 0.5817, Accuracy: 0.6292\n","Epoch 58, Train Loss: 0.6583, Val Loss: 0.6225, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 59, Train Loss: 0.6599, Val Loss: 0.6200, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 60, Train Loss: 0.6581, Val Loss: 0.6216, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 61, Train Loss: 0.6586, Val Loss: 0.6201, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 62, Train Loss: 0.6578, Val Loss: 0.6210, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 63, Train Loss: 0.6576, Val Loss: 0.6209, F1 Micro: 0.6348, F1 Macro: 0.5898, Accuracy: 0.6348\n","Epoch 64, Train Loss: 0.6576, Val Loss: 0.6197, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 65, Train Loss: 0.6575, Val Loss: 0.6192, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 66, Train Loss: 0.6601, Val Loss: 0.6203, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 67, Train Loss: 0.6577, Val Loss: 0.6200, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 68, Train Loss: 0.6584, Val Loss: 0.6223, F1 Micro: 0.6292, F1 Macro: 0.5817, Accuracy: 0.6292\n","Epoch 69, Train Loss: 0.6600, Val Loss: 0.6193, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 70, Train Loss: 0.6559, Val Loss: 0.6180, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 71, Train Loss: 0.6591, Val Loss: 0.6173, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 72, Train Loss: 0.6568, Val Loss: 0.6214, F1 Micro: 0.6292, F1 Macro: 0.5817, Accuracy: 0.6292\n","Epoch 73, Train Loss: 0.6575, Val Loss: 0.6174, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 74, Train Loss: 0.6597, Val Loss: 0.6187, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 75, Train Loss: 0.6570, Val Loss: 0.6185, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 76, Train Loss: 0.6581, Val Loss: 0.6176, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 77, Train Loss: 0.6576, Val Loss: 0.6174, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 78, Train Loss: 0.6582, Val Loss: 0.6187, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 79, Train Loss: 0.6579, Val Loss: 0.6178, F1 Micro: 0.6180, F1 Macro: 0.5760, Accuracy: 0.6180\n","Epoch 80, Train Loss: 0.6604, Val Loss: 0.6166, F1 Micro: 0.6292, F1 Macro: 0.5916, Accuracy: 0.6292\n","Epoch 81, Train Loss: 0.6567, Val Loss: 0.6209, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 82, Train Loss: 0.6585, Val Loss: 0.6198, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 83, Train Loss: 0.6583, Val Loss: 0.6186, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 84, Train Loss: 0.6569, Val Loss: 0.6184, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 85, Train Loss: 0.6579, Val Loss: 0.6178, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 86, Train Loss: 0.6580, Val Loss: 0.6193, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 87, Train Loss: 0.6587, Val Loss: 0.6211, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 88, Train Loss: 0.6578, Val Loss: 0.6183, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 89, Train Loss: 0.6579, Val Loss: 0.6197, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 90, Train Loss: 0.6578, Val Loss: 0.6191, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 91, Train Loss: 0.6568, Val Loss: 0.6176, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 92, Train Loss: 0.6587, Val Loss: 0.6215, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 93, Train Loss: 0.6585, Val Loss: 0.6178, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 94, Train Loss: 0.6610, Val Loss: 0.6191, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 95, Train Loss: 0.6582, Val Loss: 0.6171, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 96, Train Loss: 0.6583, Val Loss: 0.6185, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 97, Train Loss: 0.6586, Val Loss: 0.6182, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 98, Train Loss: 0.6576, Val Loss: 0.6167, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 99, Train Loss: 0.6584, Val Loss: 0.6171, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 100, Train Loss: 0.6586, Val Loss: 0.6186, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 101, Train Loss: 0.6585, Val Loss: 0.6164, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 102, Train Loss: 0.6566, Val Loss: 0.6165, F1 Micro: 0.6348, F1 Macro: 0.5931, Accuracy: 0.6348\n","Epoch 103, Train Loss: 0.6587, Val Loss: 0.6135, F1 Micro: 0.6404, F1 Macro: 0.6096, Accuracy: 0.6404\n","Epoch 104, Train Loss: 0.6614, Val Loss: 0.6190, F1 Micro: 0.6180, F1 Macro: 0.5652, Accuracy: 0.6180\n","Epoch 105, Train Loss: 0.6578, Val Loss: 0.6147, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 106, Train Loss: 0.6582, Val Loss: 0.6177, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 107, Train Loss: 0.6596, Val Loss: 0.6181, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 108, Train Loss: 0.6578, Val Loss: 0.6160, F1 Micro: 0.6404, F1 Macro: 0.6010, Accuracy: 0.6404\n","Epoch 109, Train Loss: 0.6583, Val Loss: 0.6130, F1 Micro: 0.6404, F1 Macro: 0.6069, Accuracy: 0.6404\n","Epoch 110, Train Loss: 0.6571, Val Loss: 0.6221, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 111, Train Loss: 0.6591, Val Loss: 0.6175, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 112, Train Loss: 0.6578, Val Loss: 0.6162, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 113, Train Loss: 0.6581, Val Loss: 0.6172, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 114, Train Loss: 0.6565, Val Loss: 0.6162, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 115, Train Loss: 0.6566, Val Loss: 0.6195, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 116, Train Loss: 0.6577, Val Loss: 0.6180, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 117, Train Loss: 0.6571, Val Loss: 0.6157, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 118, Train Loss: 0.6594, Val Loss: 0.6177, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 119, Train Loss: 0.6579, Val Loss: 0.6173, F1 Micro: 0.6292, F1 Macro: 0.5852, Accuracy: 0.6292\n","Epoch 120, Train Loss: 0.6581, Val Loss: 0.6180, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 121, Train Loss: 0.6599, Val Loss: 0.6160, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 122, Train Loss: 0.6591, Val Loss: 0.6180, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 123, Train Loss: 0.6566, Val Loss: 0.6166, F1 Micro: 0.6236, F1 Macro: 0.5806, Accuracy: 0.6236\n","Epoch 124, Train Loss: 0.6579, Val Loss: 0.6160, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 125, Train Loss: 0.6572, Val Loss: 0.6176, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 126, Train Loss: 0.6611, Val Loss: 0.6168, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 127, Train Loss: 0.6592, Val Loss: 0.6167, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 128, Train Loss: 0.6584, Val Loss: 0.6154, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 129, Train Loss: 0.6582, Val Loss: 0.6170, F1 Micro: 0.6236, F1 Macro: 0.5735, Accuracy: 0.6236\n","Epoch 130, Train Loss: 0.6576, Val Loss: 0.6158, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 131, Train Loss: 0.6586, Val Loss: 0.6159, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 132, Train Loss: 0.6578, Val Loss: 0.6154, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 133, Train Loss: 0.6591, Val Loss: 0.6156, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 134, Train Loss: 0.6567, Val Loss: 0.6159, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 135, Train Loss: 0.6571, Val Loss: 0.6165, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 136, Train Loss: 0.6578, Val Loss: 0.6153, F1 Micro: 0.6348, F1 Macro: 0.5963, Accuracy: 0.6348\n","Epoch 137, Train Loss: 0.6568, Val Loss: 0.6166, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 138, Train Loss: 0.6574, Val Loss: 0.6159, F1 Micro: 0.6292, F1 Macro: 0.5885, Accuracy: 0.6292\n","Epoch 139, Train Loss: 0.6586, Val Loss: 0.6171, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 140, Train Loss: 0.6587, Val Loss: 0.6185, F1 Micro: 0.6292, F1 Macro: 0.5817, Accuracy: 0.6292\n","Epoch 141, Train Loss: 0.6578, Val Loss: 0.6158, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 142, Train Loss: 0.6585, Val Loss: 0.6160, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 143, Train Loss: 0.6564, Val Loss: 0.6154, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 144, Train Loss: 0.6586, Val Loss: 0.6156, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 145, Train Loss: 0.6578, Val Loss: 0.6181, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 146, Train Loss: 0.6574, Val Loss: 0.6131, F1 Micro: 0.6461, F1 Macro: 0.6144, Accuracy: 0.6461\n","Epoch 147, Train Loss: 0.6574, Val Loss: 0.6206, F1 Micro: 0.6180, F1 Macro: 0.5613, Accuracy: 0.6180\n","Epoch 148, Train Loss: 0.6590, Val Loss: 0.6191, F1 Micro: 0.6124, F1 Macro: 0.5568, Accuracy: 0.6124\n","Epoch 149, Train Loss: 0.6585, Val Loss: 0.6162, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 150, Train Loss: 0.6563, Val Loss: 0.6163, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 151, Train Loss: 0.6574, Val Loss: 0.6161, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 152, Train Loss: 0.6575, Val Loss: 0.6154, F1 Micro: 0.6180, F1 Macro: 0.5690, Accuracy: 0.6180\n","Epoch 153, Train Loss: 0.6582, Val Loss: 0.6151, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Epoch 154, Train Loss: 0.6579, Val Loss: 0.6163, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 155, Train Loss: 0.6573, Val Loss: 0.6147, F1 Micro: 0.6236, F1 Macro: 0.5771, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.8777, Val Loss: 0.8743, F1 Micro: 0.6292, F1 Macro: 0.5019, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.7567, Val Loss: 0.6815, F1 Micro: 0.6517, F1 Macro: 0.5088, Accuracy: 0.6517\n","Epoch 3, Train Loss: 0.6977, Val Loss: 0.6865, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.6920, Val Loss: 0.6874, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6907, Val Loss: 0.6863, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 6, Train Loss: 0.6897, Val Loss: 0.6850, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 7, Train Loss: 0.6893, Val Loss: 0.6822, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6867, Val Loss: 0.6819, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.6857, Val Loss: 0.6798, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.6854, Val Loss: 0.6785, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 11, Train Loss: 0.6831, Val Loss: 0.6777, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.6824, Val Loss: 0.6773, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.6830, Val Loss: 0.6778, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.6812, Val Loss: 0.6760, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.6797, Val Loss: 0.6719, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 16, Train Loss: 0.6824, Val Loss: 0.6745, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.6804, Val Loss: 0.6698, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.6779, Val Loss: 0.6710, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.6780, Val Loss: 0.6703, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.6757, Val Loss: 0.6700, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.6753, Val Loss: 0.6697, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.6755, Val Loss: 0.6655, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 23, Train Loss: 0.6732, Val Loss: 0.6616, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 24, Train Loss: 0.6736, Val Loss: 0.6577, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 25, Train Loss: 0.6696, Val Loss: 0.6569, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6694, Val Loss: 0.6538, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6671, Val Loss: 0.6434, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 28, Train Loss: 0.6674, Val Loss: 0.6416, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.6652, Val Loss: 0.6423, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 30, Train Loss: 0.6622, Val Loss: 0.6397, F1 Micro: 0.7022, F1 Macro: 0.6088, Accuracy: 0.7022\n","Epoch 31, Train Loss: 0.6596, Val Loss: 0.6364, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 32, Train Loss: 0.6603, Val Loss: 0.6370, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 33, Train Loss: 0.6599, Val Loss: 0.6351, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.6592, Val Loss: 0.6365, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 35, Train Loss: 0.6586, Val Loss: 0.6359, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 36, Train Loss: 0.6587, Val Loss: 0.6350, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.6585, Val Loss: 0.6355, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 38, Train Loss: 0.6582, Val Loss: 0.6347, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 39, Train Loss: 0.6581, Val Loss: 0.6346, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 40, Train Loss: 0.6581, Val Loss: 0.6349, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 41, Train Loss: 0.6611, Val Loss: 0.6346, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 42, Train Loss: 0.6588, Val Loss: 0.6357, F1 Micro: 0.7135, F1 Macro: 0.6475, Accuracy: 0.7135\n","Epoch 43, Train Loss: 0.6566, Val Loss: 0.6340, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 44, Train Loss: 0.6566, Val Loss: 0.6334, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 45, Train Loss: 0.6587, Val Loss: 0.6343, F1 Micro: 0.6854, F1 Macro: 0.6278, Accuracy: 0.6854\n","Epoch 46, Train Loss: 0.6585, Val Loss: 0.6340, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 47, Train Loss: 0.6573, Val Loss: 0.6343, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.6592, Val Loss: 0.6329, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 49, Train Loss: 0.6578, Val Loss: 0.6332, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 50, Train Loss: 0.6595, Val Loss: 0.6341, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 51, Train Loss: 0.6579, Val Loss: 0.6334, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 52, Train Loss: 0.6572, Val Loss: 0.6326, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 53, Train Loss: 0.6588, Val Loss: 0.6326, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 54, Train Loss: 0.6589, Val Loss: 0.6323, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 55, Train Loss: 0.6597, Val Loss: 0.6331, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 56, Train Loss: 0.6600, Val Loss: 0.6332, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.6590, Val Loss: 0.6336, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 58, Train Loss: 0.6588, Val Loss: 0.6349, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 59, Train Loss: 0.6604, Val Loss: 0.6350, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 60, Train Loss: 0.6599, Val Loss: 0.6318, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 61, Train Loss: 0.6585, Val Loss: 0.6326, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 62, Train Loss: 0.6604, Val Loss: 0.6325, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 63, Train Loss: 0.6578, Val Loss: 0.6329, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 64, Train Loss: 0.6584, Val Loss: 0.6337, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 65, Train Loss: 0.6583, Val Loss: 0.6319, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 66, Train Loss: 0.6578, Val Loss: 0.6330, F1 Micro: 0.7135, F1 Macro: 0.6475, Accuracy: 0.7135\n","Epoch 67, Train Loss: 0.6571, Val Loss: 0.6325, F1 Micro: 0.6910, F1 Macro: 0.6325, Accuracy: 0.6910\n","Epoch 68, Train Loss: 0.6588, Val Loss: 0.6318, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 69, Train Loss: 0.6578, Val Loss: 0.6321, F1 Micro: 0.6854, F1 Macro: 0.6238, Accuracy: 0.6854\n","Epoch 70, Train Loss: 0.6582, Val Loss: 0.6328, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 71, Train Loss: 0.6574, Val Loss: 0.6312, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 72, Train Loss: 0.6589, Val Loss: 0.6332, F1 Micro: 0.7079, F1 Macro: 0.6384, Accuracy: 0.7079\n","Epoch 73, Train Loss: 0.6570, Val Loss: 0.6347, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 74, Train Loss: 0.6595, Val Loss: 0.6336, F1 Micro: 0.6966, F1 Macro: 0.6483, Accuracy: 0.6966\n","Epoch 75, Train Loss: 0.6590, Val Loss: 0.6325, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 76, Train Loss: 0.6575, Val Loss: 0.6325, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 77, Train Loss: 0.6590, Val Loss: 0.6324, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 78, Train Loss: 0.6585, Val Loss: 0.6335, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 79, Train Loss: 0.6573, Val Loss: 0.6313, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 80, Train Loss: 0.6609, Val Loss: 0.6345, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 81, Train Loss: 0.6606, Val Loss: 0.6331, F1 Micro: 0.7022, F1 Macro: 0.6292, Accuracy: 0.7022\n","Epoch 82, Train Loss: 0.6592, Val Loss: 0.6314, F1 Micro: 0.7022, F1 Macro: 0.6380, Accuracy: 0.7022\n","Epoch 83, Train Loss: 0.6595, Val Loss: 0.6314, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 84, Train Loss: 0.6551, Val Loss: 0.6343, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 85, Train Loss: 0.6606, Val Loss: 0.6311, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 86, Train Loss: 0.6597, Val Loss: 0.6326, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 87, Train Loss: 0.6571, Val Loss: 0.6322, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 88, Train Loss: 0.6592, Val Loss: 0.6309, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 89, Train Loss: 0.6580, Val Loss: 0.6308, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 90, Train Loss: 0.6598, Val Loss: 0.6309, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 91, Train Loss: 0.6571, Val Loss: 0.6332, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 92, Train Loss: 0.6579, Val Loss: 0.6327, F1 Micro: 0.7079, F1 Macro: 0.6339, Accuracy: 0.7079\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.6834285355596007\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 3.0027, Val Loss: 2.5271, F1 Micro: 0.4916, F1 Macro: 0.4914, Accuracy: 0.4916\n","Epoch 2, Train Loss: 2.0218, Val Loss: 1.7496, F1 Micro: 0.6034, F1 Macro: 0.5934, Accuracy: 0.6034\n","Epoch 3, Train Loss: 1.4840, Val Loss: 1.3454, F1 Micro: 0.6480, F1 Macro: 0.6275, Accuracy: 0.6480\n","Epoch 4, Train Loss: 1.2069, Val Loss: 1.1471, F1 Micro: 0.7039, F1 Macro: 0.6743, Accuracy: 0.7039\n","Epoch 5, Train Loss: 1.0381, Val Loss: 1.0152, F1 Micro: 0.6816, F1 Macro: 0.6382, Accuracy: 0.6816\n","Epoch 6, Train Loss: 0.9193, Val Loss: 0.9224, F1 Micro: 0.6704, F1 Macro: 0.6068, Accuracy: 0.6704\n","Epoch 7, Train Loss: 0.8436, Val Loss: 0.8523, F1 Micro: 0.6816, F1 Macro: 0.6159, Accuracy: 0.6816\n","Epoch 8, Train Loss: 0.7885, Val Loss: 0.7998, F1 Micro: 0.6872, F1 Macro: 0.6115, Accuracy: 0.6872\n","Epoch 9, Train Loss: 0.7446, Val Loss: 0.7686, F1 Micro: 0.6872, F1 Macro: 0.6066, Accuracy: 0.6872\n","Epoch 10, Train Loss: 0.7205, Val Loss: 0.7528, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 11, Train Loss: 0.7125, Val Loss: 0.7429, F1 Micro: 0.6927, F1 Macro: 0.6060, Accuracy: 0.6927\n","Epoch 12, Train Loss: 0.7045, Val Loss: 0.7325, F1 Micro: 0.6927, F1 Macro: 0.6005, Accuracy: 0.6927\n","Epoch 13, Train Loss: 0.6968, Val Loss: 0.7229, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Epoch 14, Train Loss: 0.6918, Val Loss: 0.7188, F1 Micro: 0.6816, F1 Macro: 0.5801, Accuracy: 0.6816\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.4257, Val Loss: 1.0731, F1 Micro: 0.6685, F1 Macro: 0.6480, Accuracy: 0.6685\n","Epoch 2, Train Loss: 1.0665, Val Loss: 0.9025, F1 Micro: 0.6685, F1 Macro: 0.6244, Accuracy: 0.6685\n","Epoch 3, Train Loss: 0.9169, Val Loss: 0.8080, F1 Micro: 0.6798, F1 Macro: 0.6231, Accuracy: 0.6798\n","Epoch 4, Train Loss: 0.8232, Val Loss: 0.7560, F1 Micro: 0.6910, F1 Macro: 0.6243, Accuracy: 0.6910\n","Epoch 5, Train Loss: 0.7613, Val Loss: 0.7161, F1 Micro: 0.6966, F1 Macro: 0.6290, Accuracy: 0.6966\n","Epoch 6, Train Loss: 0.7336, Val Loss: 0.6982, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 7, Train Loss: 0.7219, Val Loss: 0.6863, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 8, Train Loss: 0.7117, Val Loss: 0.6784, F1 Micro: 0.7079, F1 Macro: 0.6292, Accuracy: 0.7079\n","Epoch 9, Train Loss: 0.7038, Val Loss: 0.6745, F1 Micro: 0.7135, F1 Macro: 0.6288, Accuracy: 0.7135\n","Epoch 10, Train Loss: 0.6999, Val Loss: 0.6731, F1 Micro: 0.7079, F1 Macro: 0.6189, Accuracy: 0.7079\n","Epoch 11, Train Loss: 0.6974, Val Loss: 0.6718, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 12, Train Loss: 0.6956, Val Loss: 0.6707, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.6940, Val Loss: 0.6698, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 14, Train Loss: 0.6930, Val Loss: 0.6696, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.6922, Val Loss: 0.6690, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 16, Train Loss: 0.6874, Val Loss: 0.6687, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 17, Train Loss: 0.6913, Val Loss: 0.6689, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 18, Train Loss: 0.6907, Val Loss: 0.6684, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 19, Train Loss: 0.6898, Val Loss: 0.6681, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 4.1594, Val Loss: 2.8405, F1 Micro: 0.2865, F1 Macro: 0.2227, Accuracy: 0.2865\n","Epoch 2, Train Loss: 2.3340, Val Loss: 1.3542, F1 Micro: 0.4607, F1 Macro: 0.4590, Accuracy: 0.4607\n","Epoch 3, Train Loss: 1.2264, Val Loss: 0.8987, F1 Micro: 0.6236, F1 Macro: 0.6085, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.8756, Val Loss: 0.8030, F1 Micro: 0.6629, F1 Macro: 0.6259, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.7772, Val Loss: 0.7870, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 6, Train Loss: 0.7382, Val Loss: 0.7870, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.7185, Val Loss: 0.7949, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 8, Train Loss: 0.7105, Val Loss: 0.7890, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.7010, Val Loss: 0.7853, F1 Micro: 0.6629, F1 Macro: 0.5472, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6965, Val Loss: 0.7716, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6944, Val Loss: 0.7572, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 12, Train Loss: 0.6916, Val Loss: 0.7657, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 13, Train Loss: 0.6898, Val Loss: 0.7483, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.6874, Val Loss: 0.7430, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 15, Train Loss: 0.6859, Val Loss: 0.7349, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 16, Train Loss: 0.6842, Val Loss: 0.7347, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 17, Train Loss: 0.6819, Val Loss: 0.7291, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.6785, Val Loss: 0.7291, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 19, Train Loss: 0.6787, Val Loss: 0.7201, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.6774, Val Loss: 0.7181, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.6757, Val Loss: 0.7098, F1 Micro: 0.7022, F1 Macro: 0.6420, Accuracy: 0.7022\n","Epoch 22, Train Loss: 0.6762, Val Loss: 0.7108, F1 Micro: 0.7022, F1 Macro: 0.6337, Accuracy: 0.7022\n","Epoch 23, Train Loss: 0.6741, Val Loss: 0.7198, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.6749, Val Loss: 0.7040, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 25, Train Loss: 0.6734, Val Loss: 0.7167, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.6733, Val Loss: 0.7138, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 27, Train Loss: 0.6724, Val Loss: 0.7057, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.6768, Val Loss: 0.7078, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 29, Train Loss: 0.6732, Val Loss: 0.6966, F1 Micro: 0.7079, F1 Macro: 0.6544, Accuracy: 0.7079\n","Epoch 30, Train Loss: 0.6694, Val Loss: 0.6986, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 31, Train Loss: 0.6690, Val Loss: 0.7042, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 32, Train Loss: 0.6709, Val Loss: 0.7006, F1 Micro: 0.6966, F1 Macro: 0.6373, Accuracy: 0.6966\n","Epoch 33, Train Loss: 0.6712, Val Loss: 0.6953, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 34, Train Loss: 0.6712, Val Loss: 0.7072, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.9624, Val Loss: 0.8824, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 2, Train Loss: 0.8768, Val Loss: 0.8276, F1 Micro: 0.5618, F1 Macro: 0.4919, Accuracy: 0.5618\n","Epoch 3, Train Loss: 0.8064, Val Loss: 0.7860, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 4, Train Loss: 0.7566, Val Loss: 0.7494, F1 Micro: 0.5449, F1 Macro: 0.4529, Accuracy: 0.5449\n","Epoch 5, Train Loss: 0.7387, Val Loss: 0.7326, F1 Micro: 0.5506, F1 Macro: 0.4567, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.7361, Val Loss: 0.7216, F1 Micro: 0.5506, F1 Macro: 0.4504, Accuracy: 0.5506\n","Epoch 7, Train Loss: 0.7287, Val Loss: 0.7085, F1 Micro: 0.5562, F1 Macro: 0.4473, Accuracy: 0.5562\n","Epoch 8, Train Loss: 0.7251, Val Loss: 0.7022, F1 Micro: 0.5618, F1 Macro: 0.4509, Accuracy: 0.5618\n","Epoch 9, Train Loss: 0.7222, Val Loss: 0.6982, F1 Micro: 0.5618, F1 Macro: 0.4509, Accuracy: 0.5618\n","Epoch 10, Train Loss: 0.7132, Val Loss: 0.6916, F1 Micro: 0.5618, F1 Macro: 0.4509, Accuracy: 0.5618\n","Epoch 11, Train Loss: 0.7164, Val Loss: 0.6885, F1 Micro: 0.5618, F1 Macro: 0.4509, Accuracy: 0.5618\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 2.1456, Val Loss: 1.7854, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 2, Train Loss: 1.6719, Val Loss: 1.4252, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 3, Train Loss: 1.3166, Val Loss: 1.1080, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 4, Train Loss: 0.9692, Val Loss: 0.8340, F1 Micro: 0.6404, F1 Macro: 0.5653, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.7470, Val Loss: 0.6667, F1 Micro: 0.6517, F1 Macro: 0.5880, Accuracy: 0.6517\n","Epoch 6, Train Loss: 0.6383, Val Loss: 0.5994, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 7, Train Loss: 0.6016, Val Loss: 0.5739, F1 Micro: 0.6966, F1 Macro: 0.6332, Accuracy: 0.6966\n","Epoch 8, Train Loss: 0.5937, Val Loss: 0.5666, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 9, Train Loss: 0.5885, Val Loss: 0.5618, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 10, Train Loss: 0.5897, Val Loss: 0.5584, F1 Micro: 0.7247, F1 Macro: 0.6957, Accuracy: 0.7247\n","Epoch 11, Train Loss: 0.5907, Val Loss: 0.5551, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 12, Train Loss: 0.5932, Val Loss: 0.5556, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 13, Train Loss: 0.5845, Val Loss: 0.5548, F1 Micro: 0.7303, F1 Macro: 0.6903, Accuracy: 0.7303\n","Epoch 14, Train Loss: 0.5928, Val Loss: 0.5521, F1 Micro: 0.7360, F1 Macro: 0.7008, Accuracy: 0.7360\n","Epoch 15, Train Loss: 0.5837, Val Loss: 0.5502, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.5831, Val Loss: 0.5491, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 17, Train Loss: 0.5872, Val Loss: 0.5490, F1 Micro: 0.7303, F1 Macro: 0.7030, Accuracy: 0.7303\n","Epoch 18, Train Loss: 0.5910, Val Loss: 0.5496, F1 Micro: 0.7528, F1 Macro: 0.7297, Accuracy: 0.7528\n","Epoch 19, Train Loss: 0.5910, Val Loss: 0.5526, F1 Micro: 0.7584, F1 Macro: 0.7475, Accuracy: 0.7584\n","Epoch 20, Train Loss: 0.5867, Val Loss: 0.5510, F1 Micro: 0.7584, F1 Macro: 0.7435, Accuracy: 0.7584\n","Epoch 21, Train Loss: 0.5919, Val Loss: 0.5490, F1 Micro: 0.7584, F1 Macro: 0.7368, Accuracy: 0.7584\n","Epoch 22, Train Loss: 0.5901, Val Loss: 0.5492, F1 Micro: 0.7584, F1 Macro: 0.7368, Accuracy: 0.7584\n","Epoch 23, Train Loss: 0.5879, Val Loss: 0.5506, F1 Micro: 0.7528, F1 Macro: 0.7423, Accuracy: 0.7528\n","Epoch 24, Train Loss: 0.5851, Val Loss: 0.5449, F1 Micro: 0.7528, F1 Macro: 0.7297, Accuracy: 0.7528\n","Epoch 25, Train Loss: 0.5892, Val Loss: 0.5452, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 26, Train Loss: 0.5831, Val Loss: 0.5490, F1 Micro: 0.7360, F1 Macro: 0.7081, Accuracy: 0.7360\n","Epoch 27, Train Loss: 0.5859, Val Loss: 0.5467, F1 Micro: 0.7584, F1 Macro: 0.7435, Accuracy: 0.7584\n","Epoch 28, Train Loss: 0.5868, Val Loss: 0.5500, F1 Micro: 0.7528, F1 Macro: 0.7423, Accuracy: 0.7528\n","Epoch 29, Train Loss: 0.5871, Val Loss: 0.5448, F1 Micro: 0.7528, F1 Macro: 0.7397, Accuracy: 0.7528\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.6947147071746909\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.3112, Val Loss: 0.7631, F1 Micro: 0.3966, F1 Macro: 0.3804, Accuracy: 0.3966\n","Epoch 2, Train Loss: 0.7684, Val Loss: 0.7219, F1 Micro: 0.5363, F1 Macro: 0.5363, Accuracy: 0.5363\n","Epoch 3, Train Loss: 0.7257, Val Loss: 0.7045, F1 Micro: 0.6648, F1 Macro: 0.6530, Accuracy: 0.6648\n","Epoch 4, Train Loss: 0.7104, Val Loss: 0.7015, F1 Micro: 0.6592, F1 Macro: 0.6530, Accuracy: 0.6592\n","Epoch 5, Train Loss: 0.7034, Val Loss: 0.6932, F1 Micro: 0.7318, F1 Macro: 0.7170, Accuracy: 0.7318\n","Epoch 6, Train Loss: 0.6973, Val Loss: 0.6911, F1 Micro: 0.6648, F1 Macro: 0.6570, Accuracy: 0.6648\n","Epoch 7, Train Loss: 0.6922, Val Loss: 0.6854, F1 Micro: 0.7430, F1 Macro: 0.7288, Accuracy: 0.7430\n","Epoch 8, Train Loss: 0.6890, Val Loss: 0.6847, F1 Micro: 0.7095, F1 Macro: 0.6979, Accuracy: 0.7095\n","Epoch 9, Train Loss: 0.6871, Val Loss: 0.6828, F1 Micro: 0.7430, F1 Macro: 0.7302, Accuracy: 0.7430\n","Epoch 10, Train Loss: 0.6851, Val Loss: 0.6850, F1 Micro: 0.6872, F1 Macro: 0.6799, Accuracy: 0.6872\n","Epoch 11, Train Loss: 0.6840, Val Loss: 0.6814, F1 Micro: 0.7430, F1 Macro: 0.7302, Accuracy: 0.7430\n","Epoch 12, Train Loss: 0.6838, Val Loss: 0.6827, F1 Micro: 0.7095, F1 Macro: 0.7005, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.6828, Val Loss: 0.6810, F1 Micro: 0.7151, F1 Macro: 0.7057, Accuracy: 0.7151\n","Epoch 14, Train Loss: 0.6812, Val Loss: 0.6774, F1 Micro: 0.7654, F1 Macro: 0.7480, Accuracy: 0.7654\n","Epoch 15, Train Loss: 0.6801, Val Loss: 0.6785, F1 Micro: 0.7263, F1 Macro: 0.7160, Accuracy: 0.7263\n","Epoch 16, Train Loss: 0.6803, Val Loss: 0.6763, F1 Micro: 0.7542, F1 Macro: 0.7391, Accuracy: 0.7542\n","Epoch 17, Train Loss: 0.6791, Val Loss: 0.6766, F1 Micro: 0.7374, F1 Macro: 0.7264, Accuracy: 0.7374\n","Epoch 18, Train Loss: 0.6791, Val Loss: 0.6758, F1 Micro: 0.7486, F1 Macro: 0.7367, Accuracy: 0.7486\n","Epoch 19, Train Loss: 0.6783, Val Loss: 0.6751, F1 Micro: 0.7542, F1 Macro: 0.7406, Accuracy: 0.7542\n","Epoch 20, Train Loss: 0.6774, Val Loss: 0.6757, F1 Micro: 0.7263, F1 Macro: 0.7160, Accuracy: 0.7263\n","Epoch 21, Train Loss: 0.6780, Val Loss: 0.6754, F1 Micro: 0.7263, F1 Macro: 0.7160, Accuracy: 0.7263\n","Epoch 22, Train Loss: 0.6773, Val Loss: 0.6736, F1 Micro: 0.7374, F1 Macro: 0.7264, Accuracy: 0.7374\n","Epoch 23, Train Loss: 0.6772, Val Loss: 0.6740, F1 Micro: 0.7374, F1 Macro: 0.7264, Accuracy: 0.7374\n","Epoch 24, Train Loss: 0.6764, Val Loss: 0.6739, F1 Micro: 0.7263, F1 Macro: 0.7160, Accuracy: 0.7263\n","Epoch 25, Train Loss: 0.6760, Val Loss: 0.6711, F1 Micro: 0.7709, F1 Macro: 0.7532, Accuracy: 0.7709\n","Epoch 26, Train Loss: 0.6770, Val Loss: 0.6733, F1 Micro: 0.7263, F1 Macro: 0.7160, Accuracy: 0.7263\n","Epoch 27, Train Loss: 0.6756, Val Loss: 0.6734, F1 Micro: 0.7207, F1 Macro: 0.7108, Accuracy: 0.7207\n","Epoch 28, Train Loss: 0.6757, Val Loss: 0.6711, F1 Micro: 0.7374, F1 Macro: 0.7264, Accuracy: 0.7374\n","Epoch 29, Train Loss: 0.6753, Val Loss: 0.6761, F1 Micro: 0.6983, F1 Macro: 0.6902, Accuracy: 0.6983\n","Epoch 30, Train Loss: 0.6749, Val Loss: 0.6712, F1 Micro: 0.7374, F1 Macro: 0.7264, Accuracy: 0.7374\n","Epoch 31, Train Loss: 0.6753, Val Loss: 0.6719, F1 Micro: 0.7318, F1 Macro: 0.7212, Accuracy: 0.7318\n","Epoch 32, Train Loss: 0.6750, Val Loss: 0.6720, F1 Micro: 0.7263, F1 Macro: 0.7160, Accuracy: 0.7263\n","Epoch 33, Train Loss: 0.6741, Val Loss: 0.6690, F1 Micro: 0.7374, F1 Macro: 0.7250, Accuracy: 0.7374\n","Epoch 34, Train Loss: 0.6744, Val Loss: 0.6679, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 35, Train Loss: 0.6746, Val Loss: 0.6679, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 36, Train Loss: 0.6741, Val Loss: 0.6705, F1 Micro: 0.7151, F1 Macro: 0.7044, Accuracy: 0.7151\n","Epoch 37, Train Loss: 0.6746, Val Loss: 0.6714, F1 Micro: 0.7095, F1 Macro: 0.6993, Accuracy: 0.7095\n","Epoch 38, Train Loss: 0.6741, Val Loss: 0.6655, F1 Micro: 0.7598, F1 Macro: 0.7443, Accuracy: 0.7598\n","Epoch 39, Train Loss: 0.6733, Val Loss: 0.6650, F1 Micro: 0.7654, F1 Macro: 0.7495, Accuracy: 0.7654\n","Epoch 40, Train Loss: 0.6741, Val Loss: 0.6674, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 41, Train Loss: 0.6727, Val Loss: 0.6656, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 42, Train Loss: 0.6730, Val Loss: 0.6682, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 43, Train Loss: 0.6727, Val Loss: 0.6656, F1 Micro: 0.7263, F1 Macro: 0.7119, Accuracy: 0.7263\n","Epoch 44, Train Loss: 0.6730, Val Loss: 0.6676, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 45, Train Loss: 0.6725, Val Loss: 0.6699, F1 Micro: 0.7095, F1 Macro: 0.6993, Accuracy: 0.7095\n","Epoch 46, Train Loss: 0.6740, Val Loss: 0.6720, F1 Micro: 0.7095, F1 Macro: 0.6993, Accuracy: 0.7095\n","Epoch 47, Train Loss: 0.6738, Val Loss: 0.6671, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 48, Train Loss: 0.6720, Val Loss: 0.6648, F1 Micro: 0.7263, F1 Macro: 0.7119, Accuracy: 0.7263\n","Epoch 49, Train Loss: 0.6719, Val Loss: 0.6672, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 50, Train Loss: 0.6730, Val Loss: 0.6629, F1 Micro: 0.7598, F1 Macro: 0.7443, Accuracy: 0.7598\n","Epoch 51, Train Loss: 0.6722, Val Loss: 0.6657, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 52, Train Loss: 0.6717, Val Loss: 0.6644, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 53, Train Loss: 0.6725, Val Loss: 0.6637, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 54, Train Loss: 0.6717, Val Loss: 0.6633, F1 Micro: 0.7263, F1 Macro: 0.7119, Accuracy: 0.7263\n","Epoch 55, Train Loss: 0.6714, Val Loss: 0.6618, F1 Micro: 0.7542, F1 Macro: 0.7376, Accuracy: 0.7542\n","Epoch 56, Train Loss: 0.6723, Val Loss: 0.6641, F1 Micro: 0.7374, F1 Macro: 0.7250, Accuracy: 0.7374\n","Epoch 57, Train Loss: 0.6720, Val Loss: 0.6639, F1 Micro: 0.7374, F1 Macro: 0.7250, Accuracy: 0.7374\n","Epoch 58, Train Loss: 0.6728, Val Loss: 0.6663, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 59, Train Loss: 0.6713, Val Loss: 0.6626, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 60, Train Loss: 0.6715, Val Loss: 0.6639, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 61, Train Loss: 0.6715, Val Loss: 0.6624, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 62, Train Loss: 0.6715, Val Loss: 0.6619, F1 Micro: 0.7765, F1 Macro: 0.7532, Accuracy: 0.7765\n","Epoch 63, Train Loss: 0.6722, Val Loss: 0.6628, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 64, Train Loss: 0.6713, Val Loss: 0.6637, F1 Micro: 0.7374, F1 Macro: 0.7250, Accuracy: 0.7374\n","Epoch 65, Train Loss: 0.6714, Val Loss: 0.6632, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 66, Train Loss: 0.6720, Val Loss: 0.6663, F1 Micro: 0.7207, F1 Macro: 0.7096, Accuracy: 0.7207\n","Epoch 67, Train Loss: 0.6712, Val Loss: 0.6633, F1 Micro: 0.7374, F1 Macro: 0.7250, Accuracy: 0.7374\n","Epoch 68, Train Loss: 0.6715, Val Loss: 0.6649, F1 Micro: 0.7318, F1 Macro: 0.7199, Accuracy: 0.7318\n","Epoch 69, Train Loss: 0.6710, Val Loss: 0.6610, F1 Micro: 0.7374, F1 Macro: 0.7236, Accuracy: 0.7374\n","Epoch 70, Train Loss: 0.6719, Val Loss: 0.6616, F1 Micro: 0.7318, F1 Macro: 0.7185, Accuracy: 0.7318\n","Epoch 71, Train Loss: 0.6712, Val Loss: 0.6601, F1 Micro: 0.7654, F1 Macro: 0.7480, Accuracy: 0.7654\n","Epoch 72, Train Loss: 0.6722, Val Loss: 0.6604, F1 Micro: 0.7877, F1 Macro: 0.7673, Accuracy: 0.7877\n","Epoch 73, Train Loss: 0.6713, Val Loss: 0.6653, F1 Micro: 0.7263, F1 Macro: 0.7147, Accuracy: 0.7263\n","Epoch 74, Train Loss: 0.6726, Val Loss: 0.6605, F1 Micro: 0.7374, F1 Macro: 0.7236, Accuracy: 0.7374\n","Epoch 75, Train Loss: 0.6718, Val Loss: 0.6588, F1 Micro: 0.7486, F1 Macro: 0.7340, Accuracy: 0.7486\n","Epoch 76, Train Loss: 0.6713, Val Loss: 0.6590, F1 Micro: 0.7430, F1 Macro: 0.7288, Accuracy: 0.7430\n","Epoch 77, Train Loss: 0.6708, Val Loss: 0.6586, F1 Micro: 0.7598, F1 Macro: 0.7443, Accuracy: 0.7598\n","Epoch 78, Train Loss: 0.6711, Val Loss: 0.6596, F1 Micro: 0.7430, F1 Macro: 0.7302, Accuracy: 0.7430\n","Epoch 79, Train Loss: 0.6709, Val Loss: 0.6579, F1 Micro: 0.7654, F1 Macro: 0.7495, Accuracy: 0.7654\n","Epoch 80, Train Loss: 0.6717, Val Loss: 0.6576, F1 Micro: 0.7877, F1 Macro: 0.7705, Accuracy: 0.7877\n","Epoch 81, Train Loss: 0.6709, Val Loss: 0.6578, F1 Micro: 0.7542, F1 Macro: 0.7391, Accuracy: 0.7542\n","Epoch 82, Train Loss: 0.6711, Val Loss: 0.6588, F1 Micro: 0.7374, F1 Macro: 0.7236, Accuracy: 0.7374\n","Epoch 83, Train Loss: 0.6707, Val Loss: 0.6571, F1 Micro: 0.7654, F1 Macro: 0.7495, Accuracy: 0.7654\n","Epoch 84, Train Loss: 0.6709, Val Loss: 0.6571, F1 Micro: 0.7542, F1 Macro: 0.7391, Accuracy: 0.7542\n","Epoch 85, Train Loss: 0.6706, Val Loss: 0.6567, F1 Micro: 0.7598, F1 Macro: 0.7443, Accuracy: 0.7598\n","Epoch 86, Train Loss: 0.6713, Val Loss: 0.6565, F1 Micro: 0.7765, F1 Macro: 0.7600, Accuracy: 0.7765\n","Epoch 87, Train Loss: 0.6705, Val Loss: 0.6561, F1 Micro: 0.7654, F1 Macro: 0.7495, Accuracy: 0.7654\n","Epoch 88, Train Loss: 0.6706, Val Loss: 0.6559, F1 Micro: 0.7821, F1 Macro: 0.7652, Accuracy: 0.7821\n","Epoch 89, Train Loss: 0.6709, Val Loss: 0.6554, F1 Micro: 0.7821, F1 Macro: 0.7694, Accuracy: 0.7821\n","Epoch 90, Train Loss: 0.6699, Val Loss: 0.6550, F1 Micro: 0.7821, F1 Macro: 0.7694, Accuracy: 0.7821\n","Epoch 91, Train Loss: 0.6708, Val Loss: 0.6555, F1 Micro: 0.7821, F1 Macro: 0.7681, Accuracy: 0.7821\n","Epoch 92, Train Loss: 0.6702, Val Loss: 0.6554, F1 Micro: 0.7765, F1 Macro: 0.7600, Accuracy: 0.7765\n","Epoch 93, Train Loss: 0.6703, Val Loss: 0.6543, F1 Micro: 0.7765, F1 Macro: 0.7654, Accuracy: 0.7765\n","Epoch 94, Train Loss: 0.6700, Val Loss: 0.6537, F1 Micro: 0.7877, F1 Macro: 0.7760, Accuracy: 0.7877\n","Epoch 95, Train Loss: 0.6698, Val Loss: 0.6534, F1 Micro: 0.7877, F1 Macro: 0.7760, Accuracy: 0.7877\n","Epoch 96, Train Loss: 0.6697, Val Loss: 0.6543, F1 Micro: 0.7709, F1 Macro: 0.7532, Accuracy: 0.7709\n","Epoch 97, Train Loss: 0.6702, Val Loss: 0.6530, F1 Micro: 0.7933, F1 Macro: 0.7813, Accuracy: 0.7933\n","Epoch 98, Train Loss: 0.6705, Val Loss: 0.6530, F1 Micro: 0.7877, F1 Macro: 0.7760, Accuracy: 0.7877\n","Epoch 99, Train Loss: 0.6694, Val Loss: 0.6530, F1 Micro: 0.7821, F1 Macro: 0.7694, Accuracy: 0.7821\n","Epoch 100, Train Loss: 0.6691, Val Loss: 0.6538, F1 Micro: 0.7821, F1 Macro: 0.7652, Accuracy: 0.7821\n","Epoch 101, Train Loss: 0.6693, Val Loss: 0.6524, F1 Micro: 0.7933, F1 Macro: 0.7813, Accuracy: 0.7933\n","Epoch 102, Train Loss: 0.6692, Val Loss: 0.6528, F1 Micro: 0.7877, F1 Macro: 0.7747, Accuracy: 0.7877\n","Epoch 103, Train Loss: 0.6688, Val Loss: 0.6526, F1 Micro: 0.7877, F1 Macro: 0.7747, Accuracy: 0.7877\n","Epoch 104, Train Loss: 0.6687, Val Loss: 0.6529, F1 Micro: 0.7821, F1 Macro: 0.7652, Accuracy: 0.7821\n","Epoch 105, Train Loss: 0.6689, Val Loss: 0.6523, F1 Micro: 0.7933, F1 Macro: 0.7800, Accuracy: 0.7933\n","Epoch 106, Train Loss: 0.6692, Val Loss: 0.6539, F1 Micro: 0.7933, F1 Macro: 0.7742, Accuracy: 0.7933\n","Epoch 107, Train Loss: 0.6687, Val Loss: 0.6532, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 108, Train Loss: 0.6687, Val Loss: 0.6520, F1 Micro: 0.7933, F1 Macro: 0.7800, Accuracy: 0.7933\n","Epoch 109, Train Loss: 0.6686, Val Loss: 0.6533, F1 Micro: 0.7877, F1 Macro: 0.7673, Accuracy: 0.7877\n","Epoch 110, Train Loss: 0.6696, Val Loss: 0.6530, F1 Micro: 0.7933, F1 Macro: 0.7742, Accuracy: 0.7933\n","Epoch 111, Train Loss: 0.6683, Val Loss: 0.6525, F1 Micro: 0.7877, F1 Macro: 0.7705, Accuracy: 0.7877\n","Epoch 112, Train Loss: 0.6685, Val Loss: 0.6511, F1 Micro: 0.7877, F1 Macro: 0.7734, Accuracy: 0.7877\n","Epoch 113, Train Loss: 0.6682, Val Loss: 0.6532, F1 Micro: 0.7877, F1 Macro: 0.7673, Accuracy: 0.7877\n","Epoch 114, Train Loss: 0.6688, Val Loss: 0.6523, F1 Micro: 0.7933, F1 Macro: 0.7742, Accuracy: 0.7933\n","Epoch 115, Train Loss: 0.6680, Val Loss: 0.6505, F1 Micro: 0.7821, F1 Macro: 0.7694, Accuracy: 0.7821\n","Epoch 116, Train Loss: 0.6685, Val Loss: 0.6518, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 117, Train Loss: 0.6680, Val Loss: 0.6519, F1 Micro: 0.7765, F1 Macro: 0.7584, Accuracy: 0.7765\n","Epoch 118, Train Loss: 0.6681, Val Loss: 0.6514, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 119, Train Loss: 0.6680, Val Loss: 0.6520, F1 Micro: 0.7933, F1 Macro: 0.7742, Accuracy: 0.7933\n","Epoch 120, Train Loss: 0.6679, Val Loss: 0.6509, F1 Micro: 0.7765, F1 Macro: 0.7584, Accuracy: 0.7765\n","Epoch 121, Train Loss: 0.6679, Val Loss: 0.6505, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 122, Train Loss: 0.6683, Val Loss: 0.6513, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 123, Train Loss: 0.6681, Val Loss: 0.6525, F1 Micro: 0.7821, F1 Macro: 0.7585, Accuracy: 0.7821\n","Epoch 124, Train Loss: 0.6679, Val Loss: 0.6508, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 125, Train Loss: 0.6678, Val Loss: 0.6504, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 126, Train Loss: 0.6677, Val Loss: 0.6507, F1 Micro: 0.7765, F1 Macro: 0.7584, Accuracy: 0.7765\n","Epoch 127, Train Loss: 0.6675, Val Loss: 0.6507, F1 Micro: 0.7765, F1 Macro: 0.7584, Accuracy: 0.7765\n","Epoch 128, Train Loss: 0.6674, Val Loss: 0.6502, F1 Micro: 0.7709, F1 Macro: 0.7532, Accuracy: 0.7709\n","Epoch 129, Train Loss: 0.6676, Val Loss: 0.6506, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 130, Train Loss: 0.6677, Val Loss: 0.6509, F1 Micro: 0.7821, F1 Macro: 0.7637, Accuracy: 0.7821\n","Epoch 131, Train Loss: 0.6677, Val Loss: 0.6511, F1 Micro: 0.7709, F1 Macro: 0.7498, Accuracy: 0.7709\n","Epoch 132, Train Loss: 0.6672, Val Loss: 0.6512, F1 Micro: 0.7933, F1 Macro: 0.7726, Accuracy: 0.7933\n","Epoch 133, Train Loss: 0.6674, Val Loss: 0.6506, F1 Micro: 0.7765, F1 Macro: 0.7568, Accuracy: 0.7765\n","Epoch 134, Train Loss: 0.6676, Val Loss: 0.6508, F1 Micro: 0.7709, F1 Macro: 0.7498, Accuracy: 0.7709\n","Epoch 135, Train Loss: 0.6674, Val Loss: 0.6512, F1 Micro: 0.7765, F1 Macro: 0.7513, Accuracy: 0.7765\n","Epoch 136, Train Loss: 0.6670, Val Loss: 0.6502, F1 Micro: 0.7709, F1 Macro: 0.7480, Accuracy: 0.7709\n","Epoch 137, Train Loss: 0.6668, Val Loss: 0.6495, F1 Micro: 0.7765, F1 Macro: 0.7532, Accuracy: 0.7765\n","Epoch 138, Train Loss: 0.6671, Val Loss: 0.6488, F1 Micro: 0.7598, F1 Macro: 0.7376, Accuracy: 0.7598\n","Epoch 139, Train Loss: 0.6662, Val Loss: 0.6500, F1 Micro: 0.7765, F1 Macro: 0.7513, Accuracy: 0.7765\n","Epoch 140, Train Loss: 0.6664, Val Loss: 0.6504, F1 Micro: 0.7933, F1 Macro: 0.7671, Accuracy: 0.7933\n","Epoch 141, Train Loss: 0.6660, Val Loss: 0.6492, F1 Micro: 0.7821, F1 Macro: 0.7585, Accuracy: 0.7821\n","Epoch 142, Train Loss: 0.6662, Val Loss: 0.6496, F1 Micro: 0.7765, F1 Macro: 0.7513, Accuracy: 0.7765\n","Epoch 143, Train Loss: 0.6662, Val Loss: 0.6500, F1 Micro: 0.7877, F1 Macro: 0.7618, Accuracy: 0.7877\n","Epoch 144, Train Loss: 0.6660, Val Loss: 0.6490, F1 Micro: 0.7765, F1 Macro: 0.7513, Accuracy: 0.7765\n","Epoch 145, Train Loss: 0.6657, Val Loss: 0.6503, F1 Micro: 0.7877, F1 Macro: 0.7598, Accuracy: 0.7877\n","Epoch 146, Train Loss: 0.6656, Val Loss: 0.6496, F1 Micro: 0.7821, F1 Macro: 0.7545, Accuracy: 0.7821\n","Epoch 147, Train Loss: 0.6657, Val Loss: 0.6492, F1 Micro: 0.7765, F1 Macro: 0.7513, Accuracy: 0.7765\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7059, Val Loss: 0.7131, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.6991, Val Loss: 0.7082, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.6958, Val Loss: 0.7039, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6944, Val Loss: 0.7008, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 5, Train Loss: 0.6938, Val Loss: 0.6985, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.6934, Val Loss: 0.6964, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6955, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.6928, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6926, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6924, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 28, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 52, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 54, Train Loss: 0.6922, Val Loss: 0.6933, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 55, Train Loss: 0.6922, Val Loss: 0.6936, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 56, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 57, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 58, Train Loss: 0.6922, Val Loss: 0.6931, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.0347, Val Loss: 1.9788, F1 Micro: 0.4944, F1 Macro: 0.4615, Accuracy: 0.4944\n","Epoch 2, Train Loss: 1.5928, Val Loss: 1.5530, F1 Micro: 0.5730, F1 Macro: 0.5223, Accuracy: 0.5730\n","Epoch 3, Train Loss: 1.2799, Val Loss: 1.1953, F1 Micro: 0.6292, F1 Macro: 0.5614, Accuracy: 0.6292\n","Epoch 4, Train Loss: 1.0295, Val Loss: 0.8896, F1 Micro: 0.6629, F1 Macro: 0.6053, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.7637, Val Loss: 0.6854, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 6, Train Loss: 0.6410, Val Loss: 0.6043, F1 Micro: 0.7416, F1 Macro: 0.6840, Accuracy: 0.7416\n","Epoch 7, Train Loss: 0.6053, Val Loss: 0.5787, F1 Micro: 0.7416, F1 Macro: 0.6943, Accuracy: 0.7416\n","Epoch 8, Train Loss: 0.5830, Val Loss: 0.5739, F1 Micro: 0.7472, F1 Macro: 0.7083, Accuracy: 0.7472\n","Epoch 9, Train Loss: 0.5826, Val Loss: 0.5696, F1 Micro: 0.7640, F1 Macro: 0.7338, Accuracy: 0.7640\n","Epoch 10, Train Loss: 0.5765, Val Loss: 0.5690, F1 Micro: 0.7640, F1 Macro: 0.7360, Accuracy: 0.7640\n","Epoch 11, Train Loss: 0.5838, Val Loss: 0.5689, F1 Micro: 0.7584, F1 Macro: 0.7308, Accuracy: 0.7584\n","Epoch 12, Train Loss: 0.5810, Val Loss: 0.5712, F1 Micro: 0.7472, F1 Macro: 0.7265, Accuracy: 0.7472\n","Epoch 13, Train Loss: 0.5842, Val Loss: 0.5687, F1 Micro: 0.7640, F1 Macro: 0.7338, Accuracy: 0.7640\n","Epoch 14, Train Loss: 0.5813, Val Loss: 0.5694, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 15, Train Loss: 0.5809, Val Loss: 0.5753, F1 Micro: 0.7303, F1 Macro: 0.6843, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.5818, Val Loss: 0.5696, F1 Micro: 0.7416, F1 Macro: 0.7194, Accuracy: 0.7416\n","Epoch 17, Train Loss: 0.5783, Val Loss: 0.5689, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 18, Train Loss: 0.5837, Val Loss: 0.5725, F1 Micro: 0.7472, F1 Macro: 0.7299, Accuracy: 0.7472\n","Epoch 19, Train Loss: 0.5796, Val Loss: 0.5684, F1 Micro: 0.7697, F1 Macro: 0.7412, Accuracy: 0.7697\n","Epoch 20, Train Loss: 0.5811, Val Loss: 0.5690, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 21, Train Loss: 0.5788, Val Loss: 0.5684, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 22, Train Loss: 0.5768, Val Loss: 0.5691, F1 Micro: 0.7472, F1 Macro: 0.7265, Accuracy: 0.7472\n","Epoch 23, Train Loss: 0.5797, Val Loss: 0.5695, F1 Micro: 0.7416, F1 Macro: 0.7213, Accuracy: 0.7416\n","Epoch 24, Train Loss: 0.5758, Val Loss: 0.5697, F1 Micro: 0.7640, F1 Macro: 0.7338, Accuracy: 0.7640\n","Epoch 25, Train Loss: 0.5808, Val Loss: 0.5700, F1 Micro: 0.7360, F1 Macro: 0.7162, Accuracy: 0.7360\n","Epoch 26, Train Loss: 0.5756, Val Loss: 0.5698, F1 Micro: 0.7360, F1 Macro: 0.7162, Accuracy: 0.7360\n","Epoch 27, Train Loss: 0.5805, Val Loss: 0.5681, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 28, Train Loss: 0.5789, Val Loss: 0.5706, F1 Micro: 0.7528, F1 Macro: 0.7187, Accuracy: 0.7528\n","Epoch 29, Train Loss: 0.5823, Val Loss: 0.5681, F1 Micro: 0.7640, F1 Macro: 0.7381, Accuracy: 0.7640\n","Epoch 30, Train Loss: 0.5829, Val Loss: 0.5730, F1 Micro: 0.7584, F1 Macro: 0.7435, Accuracy: 0.7584\n","Epoch 31, Train Loss: 0.5838, Val Loss: 0.5681, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 32, Train Loss: 0.5792, Val Loss: 0.5676, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 33, Train Loss: 0.5802, Val Loss: 0.5675, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 34, Train Loss: 0.5847, Val Loss: 0.5676, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 35, Train Loss: 0.5832, Val Loss: 0.5672, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 36, Train Loss: 0.5797, Val Loss: 0.5674, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 37, Train Loss: 0.5824, Val Loss: 0.5678, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 38, Train Loss: 0.5811, Val Loss: 0.5672, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 39, Train Loss: 0.5783, Val Loss: 0.5679, F1 Micro: 0.7416, F1 Macro: 0.7194, Accuracy: 0.7416\n","Epoch 40, Train Loss: 0.5805, Val Loss: 0.5683, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 41, Train Loss: 0.5736, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 42, Train Loss: 0.5793, Val Loss: 0.5672, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 43, Train Loss: 0.5790, Val Loss: 0.5679, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 44, Train Loss: 0.5788, Val Loss: 0.5676, F1 Micro: 0.7416, F1 Macro: 0.7194, Accuracy: 0.7416\n","Epoch 45, Train Loss: 0.5787, Val Loss: 0.5681, F1 Micro: 0.7416, F1 Macro: 0.7213, Accuracy: 0.7416\n","Epoch 46, Train Loss: 0.5804, Val Loss: 0.5698, F1 Micro: 0.7528, F1 Macro: 0.7367, Accuracy: 0.7528\n","Epoch 47, Train Loss: 0.5797, Val Loss: 0.5671, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 48, Train Loss: 0.5826, Val Loss: 0.5669, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 49, Train Loss: 0.5876, Val Loss: 0.5692, F1 Micro: 0.7584, F1 Macro: 0.7435, Accuracy: 0.7584\n","Epoch 50, Train Loss: 0.5826, Val Loss: 0.5670, F1 Micro: 0.7528, F1 Macro: 0.7257, Accuracy: 0.7528\n","Epoch 51, Train Loss: 0.5777, Val Loss: 0.5673, F1 Micro: 0.7472, F1 Macro: 0.7183, Accuracy: 0.7472\n","Epoch 52, Train Loss: 0.5821, Val Loss: 0.5671, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 53, Train Loss: 0.5815, Val Loss: 0.5683, F1 Micro: 0.7416, F1 Macro: 0.7231, Accuracy: 0.7416\n","Epoch 54, Train Loss: 0.5782, Val Loss: 0.5675, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 55, Train Loss: 0.5799, Val Loss: 0.5706, F1 Micro: 0.7640, F1 Macro: 0.7338, Accuracy: 0.7640\n","Epoch 56, Train Loss: 0.5794, Val Loss: 0.5671, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 57, Train Loss: 0.5862, Val Loss: 0.5672, F1 Micro: 0.7360, F1 Macro: 0.7123, Accuracy: 0.7360\n","Epoch 58, Train Loss: 0.5854, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.7265, Accuracy: 0.7472\n","Epoch 59, Train Loss: 0.5748, Val Loss: 0.5670, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 60, Train Loss: 0.5738, Val Loss: 0.5671, F1 Micro: 0.7472, F1 Macro: 0.7226, Accuracy: 0.7472\n","Epoch 61, Train Loss: 0.5836, Val Loss: 0.5679, F1 Micro: 0.7416, F1 Macro: 0.7213, Accuracy: 0.7416\n","Epoch 62, Train Loss: 0.5809, Val Loss: 0.5675, F1 Micro: 0.7360, F1 Macro: 0.7143, Accuracy: 0.7360\n","Epoch 63, Train Loss: 0.5797, Val Loss: 0.5681, F1 Micro: 0.7584, F1 Macro: 0.7329, Accuracy: 0.7584\n","Epoch 64, Train Loss: 0.5768, Val Loss: 0.5685, F1 Micro: 0.7528, F1 Macro: 0.7367, Accuracy: 0.7528\n","Epoch 65, Train Loss: 0.5809, Val Loss: 0.5710, F1 Micro: 0.7697, F1 Macro: 0.7568, Accuracy: 0.7697\n","Epoch 66, Train Loss: 0.5803, Val Loss: 0.5675, F1 Micro: 0.7472, F1 Macro: 0.7265, Accuracy: 0.7472\n","Epoch 67, Train Loss: 0.5807, Val Loss: 0.5689, F1 Micro: 0.7584, F1 Macro: 0.7435, Accuracy: 0.7584\n","Epoch 68, Train Loss: 0.5757, Val Loss: 0.5672, F1 Micro: 0.7416, F1 Macro: 0.7175, Accuracy: 0.7416\n","Epoch 69, Train Loss: 0.5803, Val Loss: 0.5684, F1 Micro: 0.7472, F1 Macro: 0.7299, Accuracy: 0.7472\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6968, Val Loss: 0.6932, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6950, Val Loss: 0.6932, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.6938, Val Loss: 0.6933, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.6928, Val Loss: 0.6939, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.6925, Val Loss: 0.6942, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.6922, Val Loss: 0.6948, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.6918, Val Loss: 0.6952, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6915, Val Loss: 0.6979, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6911, Val Loss: 0.7012, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6915, Val Loss: 0.7092, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6907, Val Loss: 0.7032, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6908, Val Loss: 0.7061, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6910, Val Loss: 0.7041, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6906, Val Loss: 0.7096, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6910, Val Loss: 0.7062, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6909, Val Loss: 0.7040, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6906, Val Loss: 0.7068, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6908, Val Loss: 0.7078, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6909, Val Loss: 0.7050, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6908, Val Loss: 0.7044, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6907, Val Loss: 0.7077, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6907, Val Loss: 0.7027, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6907, Val Loss: 0.7053, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6907, Val Loss: 0.7047, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6906, Val Loss: 0.7057, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6906, Val Loss: 0.7102, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6908, Val Loss: 0.7060, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6907, Val Loss: 0.7046, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6906, Val Loss: 0.7096, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6907, Val Loss: 0.7113, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6908, Val Loss: 0.7038, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6906, Val Loss: 0.7064, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6907, Val Loss: 0.7069, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6905, Val Loss: 0.7080, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6906, Val Loss: 0.7046, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6906, Val Loss: 0.7057, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6906, Val Loss: 0.7054, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6905, Val Loss: 0.7102, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6907, Val Loss: 0.7061, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6906, Val Loss: 0.7068, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6906, Val Loss: 0.7091, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6904, Val Loss: 0.7104, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6908, Val Loss: 0.7052, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6906, Val Loss: 0.7060, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6905, Val Loss: 0.7052, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.6906, Val Loss: 0.7065, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.6905, Val Loss: 0.7057, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.6905, Val Loss: 0.7085, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.6905, Val Loss: 0.7091, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.6905, Val Loss: 0.7081, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.6905, Val Loss: 0.7062, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.3535, Val Loss: 2.0252, F1 Micro: 0.4944, F1 Macro: 0.4702, Accuracy: 0.4944\n","Epoch 2, Train Loss: 1.8390, Val Loss: 1.7251, F1 Micro: 0.6236, F1 Macro: 0.5524, Accuracy: 0.6236\n","Epoch 3, Train Loss: 1.5820, Val Loss: 1.4913, F1 Micro: 0.6292, F1 Macro: 0.5465, Accuracy: 0.6292\n","Epoch 4, Train Loss: 1.3645, Val Loss: 1.2905, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 5, Train Loss: 1.1998, Val Loss: 1.1258, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 6, Train Loss: 1.0602, Val Loss: 1.0013, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 7, Train Loss: 0.9477, Val Loss: 0.8993, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 8, Train Loss: 0.8661, Val Loss: 0.8209, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.8184, Val Loss: 0.7693, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.7801, Val Loss: 0.7481, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.7677, Val Loss: 0.7342, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 12, Train Loss: 0.7564, Val Loss: 0.7247, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 13, Train Loss: 0.7484, Val Loss: 0.7205, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.7401, Val Loss: 0.7143, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 15, Train Loss: 0.7329, Val Loss: 0.7099, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.7231, Val Loss: 0.7095, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 17, Train Loss: 0.7225, Val Loss: 0.7058, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 18, Train Loss: 0.7186, Val Loss: 0.7037, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.7148, Val Loss: 0.7007, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.7116, Val Loss: 0.6997, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.7095, Val Loss: 0.6973, F1 Micro: 0.6629, F1 Macro: 0.5925, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.7085, Val Loss: 0.6954, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 23, Train Loss: 0.7064, Val Loss: 0.6936, F1 Micro: 0.6685, F1 Macro: 0.6058, Accuracy: 0.6685\n","Epoch 24, Train Loss: 0.7039, Val Loss: 0.6907, F1 Micro: 0.6629, F1 Macro: 0.6092, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.7028, Val Loss: 0.6886, F1 Micro: 0.6798, F1 Macro: 0.6339, Accuracy: 0.6798\n","Epoch 26, Train Loss: 0.7004, Val Loss: 0.6879, F1 Micro: 0.6798, F1 Macro: 0.6372, Accuracy: 0.6798\n","Epoch 27, Train Loss: 0.6990, Val Loss: 0.6843, F1 Micro: 0.6742, F1 Macro: 0.6324, Accuracy: 0.6742\n","Epoch 28, Train Loss: 0.6965, Val Loss: 0.6845, F1 Micro: 0.6685, F1 Macro: 0.6276, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.6959, Val Loss: 0.6825, F1 Micro: 0.6854, F1 Macro: 0.6508, Accuracy: 0.6854\n","Epoch 30, Train Loss: 0.6938, Val Loss: 0.6797, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 31, Train Loss: 0.6917, Val Loss: 0.6791, F1 Micro: 0.7022, F1 Macro: 0.6708, Accuracy: 0.7022\n","Epoch 32, Train Loss: 0.6898, Val Loss: 0.6795, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 33, Train Loss: 0.6864, Val Loss: 0.6734, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 34, Train Loss: 0.6838, Val Loss: 0.6715, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 35, Train Loss: 0.6820, Val Loss: 0.6702, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 36, Train Loss: 0.6809, Val Loss: 0.6680, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 37, Train Loss: 0.6833, Val Loss: 0.6647, F1 Micro: 0.7303, F1 Macro: 0.7072, Accuracy: 0.7303\n","Epoch 38, Train Loss: 0.6785, Val Loss: 0.6651, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 39, Train Loss: 0.6759, Val Loss: 0.6615, F1 Micro: 0.7360, F1 Macro: 0.7162, Accuracy: 0.7360\n","Epoch 40, Train Loss: 0.6741, Val Loss: 0.6642, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 41, Train Loss: 0.6726, Val Loss: 0.6622, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 42, Train Loss: 0.6677, Val Loss: 0.6636, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 43, Train Loss: 0.6708, Val Loss: 0.6633, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 44, Train Loss: 0.6685, Val Loss: 0.6594, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 45, Train Loss: 0.6689, Val Loss: 0.6625, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 46, Train Loss: 0.6691, Val Loss: 0.6589, F1 Micro: 0.7191, F1 Macro: 0.6950, Accuracy: 0.7191\n","Epoch 47, Train Loss: 0.6665, Val Loss: 0.6598, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 48, Train Loss: 0.6661, Val Loss: 0.6582, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 49, Train Loss: 0.6649, Val Loss: 0.6578, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 50, Train Loss: 0.6635, Val Loss: 0.6586, F1 Micro: 0.7416, F1 Macro: 0.7263, Accuracy: 0.7416\n","Epoch 51, Train Loss: 0.6600, Val Loss: 0.6585, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 52, Train Loss: 0.6632, Val Loss: 0.6581, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 53, Train Loss: 0.6629, Val Loss: 0.6579, F1 Micro: 0.7360, F1 Macro: 0.7196, Accuracy: 0.7360\n","Epoch 54, Train Loss: 0.6623, Val Loss: 0.6579, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 55, Train Loss: 0.6556, Val Loss: 0.6583, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 56, Train Loss: 0.6622, Val Loss: 0.6575, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 57, Train Loss: 0.6613, Val Loss: 0.6595, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 58, Train Loss: 0.6605, Val Loss: 0.6566, F1 Micro: 0.7360, F1 Macro: 0.7196, Accuracy: 0.7360\n","Epoch 59, Train Loss: 0.6614, Val Loss: 0.6564, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 60, Train Loss: 0.6721, Val Loss: 0.6559, F1 Micro: 0.7416, F1 Macro: 0.7263, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.6560, Val Loss: 0.6604, F1 Micro: 0.7416, F1 Macro: 0.7263, Accuracy: 0.7416\n","Epoch 62, Train Loss: 0.6576, Val Loss: 0.6572, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 63, Train Loss: 0.6562, Val Loss: 0.6557, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 64, Train Loss: 0.6562, Val Loss: 0.6563, F1 Micro: 0.7247, F1 Macro: 0.7059, Accuracy: 0.7247\n","Epoch 65, Train Loss: 0.6585, Val Loss: 0.6552, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 66, Train Loss: 0.6542, Val Loss: 0.6555, F1 Micro: 0.7191, F1 Macro: 0.6990, Accuracy: 0.7191\n","Epoch 67, Train Loss: 0.6547, Val Loss: 0.6539, F1 Micro: 0.7360, F1 Macro: 0.7196, Accuracy: 0.7360\n","Epoch 68, Train Loss: 0.6552, Val Loss: 0.6547, F1 Micro: 0.7360, F1 Macro: 0.7179, Accuracy: 0.7360\n","Epoch 69, Train Loss: 0.6549, Val Loss: 0.6545, F1 Micro: 0.7303, F1 Macro: 0.7128, Accuracy: 0.7303\n","Epoch 70, Train Loss: 0.6545, Val Loss: 0.6492, F1 Micro: 0.7303, F1 Macro: 0.7110, Accuracy: 0.7303\n","Epoch 71, Train Loss: 0.5994, Val Loss: 0.5414, F1 Micro: 0.7472, F1 Macro: 0.7299, Accuracy: 0.7472\n","Epoch 72, Train Loss: 0.5687, Val Loss: 0.5446, F1 Micro: 0.7247, F1 Macro: 0.6979, Accuracy: 0.7247\n","Epoch 73, Train Loss: 0.5756, Val Loss: 0.5365, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 74, Train Loss: 0.5708, Val Loss: 0.5345, F1 Micro: 0.7416, F1 Macro: 0.7231, Accuracy: 0.7416\n","Epoch 75, Train Loss: 0.5635, Val Loss: 0.5340, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 76, Train Loss: 0.5644, Val Loss: 0.5343, F1 Micro: 0.7303, F1 Macro: 0.7092, Accuracy: 0.7303\n","Epoch 77, Train Loss: 0.5594, Val Loss: 0.5402, F1 Micro: 0.7247, F1 Macro: 0.7093, Accuracy: 0.7247\n","Epoch 78, Train Loss: 0.5662, Val Loss: 0.5347, F1 Micro: 0.7247, F1 Macro: 0.7041, Accuracy: 0.7247\n","Epoch 79, Train Loss: 0.5674, Val Loss: 0.5341, F1 Micro: 0.7247, F1 Macro: 0.7041, Accuracy: 0.7247\n","Epoch 80, Train Loss: 0.5608, Val Loss: 0.5358, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 81, Train Loss: 0.5600, Val Loss: 0.5341, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 82, Train Loss: 0.5649, Val Loss: 0.5382, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 83, Train Loss: 0.5572, Val Loss: 0.5362, F1 Micro: 0.7247, F1 Macro: 0.7021, Accuracy: 0.7247\n","Epoch 84, Train Loss: 0.5631, Val Loss: 0.5347, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 85, Train Loss: 0.5644, Val Loss: 0.5319, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 86, Train Loss: 0.5623, Val Loss: 0.5325, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 87, Train Loss: 0.5596, Val Loss: 0.5332, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 88, Train Loss: 0.5636, Val Loss: 0.5340, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 89, Train Loss: 0.5582, Val Loss: 0.5371, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 90, Train Loss: 0.5578, Val Loss: 0.5354, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 91, Train Loss: 0.5590, Val Loss: 0.5356, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 92, Train Loss: 0.5588, Val Loss: 0.5352, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 93, Train Loss: 0.5542, Val Loss: 0.5371, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 94, Train Loss: 0.5676, Val Loss: 0.5382, F1 Micro: 0.7079, F1 Macro: 0.6870, Accuracy: 0.7079\n","Epoch 95, Train Loss: 0.5564, Val Loss: 0.5386, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 96, Train Loss: 0.5603, Val Loss: 0.5369, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 97, Train Loss: 0.5586, Val Loss: 0.5353, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 98, Train Loss: 0.5573, Val Loss: 0.5360, F1 Micro: 0.7135, F1 Macro: 0.6920, Accuracy: 0.7135\n","Epoch 99, Train Loss: 0.5527, Val Loss: 0.5348, F1 Micro: 0.7247, F1 Macro: 0.7001, Accuracy: 0.7247\n","Epoch 100, Train Loss: 0.5554, Val Loss: 0.5346, F1 Micro: 0.7191, F1 Macro: 0.6906, Accuracy: 0.7191\n","Epoch 101, Train Loss: 0.5575, Val Loss: 0.5340, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 102, Train Loss: 0.5571, Val Loss: 0.5362, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 103, Train Loss: 0.5613, Val Loss: 0.5352, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 104, Train Loss: 0.5568, Val Loss: 0.5339, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 105, Train Loss: 0.5575, Val Loss: 0.5345, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 106, Train Loss: 0.5572, Val Loss: 0.5343, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 107, Train Loss: 0.5610, Val Loss: 0.5328, F1 Micro: 0.7079, F1 Macro: 0.6850, Accuracy: 0.7079\n","Epoch 108, Train Loss: 0.5594, Val Loss: 0.5324, F1 Micro: 0.7191, F1 Macro: 0.6929, Accuracy: 0.7191\n","Epoch 109, Train Loss: 0.5626, Val Loss: 0.5313, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 110, Train Loss: 0.5540, Val Loss: 0.5327, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 111, Train Loss: 0.5536, Val Loss: 0.5321, F1 Micro: 0.7135, F1 Macro: 0.6900, Accuracy: 0.7135\n","Epoch 112, Train Loss: 0.5522, Val Loss: 0.5330, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 113, Train Loss: 0.5577, Val Loss: 0.5319, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 114, Train Loss: 0.5525, Val Loss: 0.5290, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 115, Train Loss: 0.5558, Val Loss: 0.5288, F1 Micro: 0.7135, F1 Macro: 0.6879, Accuracy: 0.7135\n","Epoch 116, Train Loss: 0.5543, Val Loss: 0.5291, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 117, Train Loss: 0.5555, Val Loss: 0.5317, F1 Micro: 0.6966, F1 Macro: 0.6728, Accuracy: 0.6966\n","Epoch 118, Train Loss: 0.5588, Val Loss: 0.5310, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 119, Train Loss: 0.5592, Val Loss: 0.5297, F1 Micro: 0.7079, F1 Macro: 0.6828, Accuracy: 0.7079\n","Epoch 120, Train Loss: 0.5606, Val Loss: 0.5301, F1 Micro: 0.7079, F1 Macro: 0.6806, Accuracy: 0.7079\n","Epoch 121, Train Loss: 0.5608, Val Loss: 0.5352, F1 Micro: 0.6910, F1 Macro: 0.6699, Accuracy: 0.6910\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.6946142740568703\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.2295, Val Loss: 1.1195, F1 Micro: 0.6425, F1 Macro: 0.5955, Accuracy: 0.6425\n","Epoch 2, Train Loss: 1.0587, Val Loss: 1.0024, F1 Micro: 0.6425, F1 Macro: 0.5711, Accuracy: 0.6425\n","Epoch 3, Train Loss: 0.9456, Val Loss: 0.9316, F1 Micro: 0.6536, F1 Macro: 0.5799, Accuracy: 0.6536\n","Epoch 4, Train Loss: 0.8771, Val Loss: 0.8582, F1 Micro: 0.6592, F1 Macro: 0.5793, Accuracy: 0.6592\n","Epoch 5, Train Loss: 0.8276, Val Loss: 0.8133, F1 Micro: 0.6704, F1 Macro: 0.5881, Accuracy: 0.6704\n","Epoch 6, Train Loss: 0.7906, Val Loss: 0.7780, F1 Micro: 0.6704, F1 Macro: 0.5828, Accuracy: 0.6704\n","Epoch 7, Train Loss: 0.7510, Val Loss: 0.7525, F1 Micro: 0.6760, F1 Macro: 0.5816, Accuracy: 0.6760\n","Epoch 8, Train Loss: 0.7275, Val Loss: 0.7366, F1 Micro: 0.6592, F1 Macro: 0.5439, Accuracy: 0.6592\n","Epoch 9, Train Loss: 0.7132, Val Loss: 0.7286, F1 Micro: 0.6536, F1 Macro: 0.5256, Accuracy: 0.6536\n","Epoch 10, Train Loss: 0.7085, Val Loss: 0.7218, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 11, Train Loss: 0.7056, Val Loss: 0.7167, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 12, Train Loss: 0.6986, Val Loss: 0.7091, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 13, Train Loss: 0.6954, Val Loss: 0.7056, F1 Micro: 0.6592, F1 Macro: 0.5216, Accuracy: 0.6592\n","Epoch 14, Train Loss: 0.6932, Val Loss: 0.7009, F1 Micro: 0.6536, F1 Macro: 0.5096, Accuracy: 0.6536\n","Epoch 15, Train Loss: 0.6919, Val Loss: 0.6985, F1 Micro: 0.6592, F1 Macro: 0.5133, Accuracy: 0.6592\n","Epoch 16, Train Loss: 0.6913, Val Loss: 0.6972, F1 Micro: 0.6592, F1 Macro: 0.5133, Accuracy: 0.6592\n","Epoch 17, Train Loss: 0.6905, Val Loss: 0.6949, F1 Micro: 0.6592, F1 Macro: 0.5133, Accuracy: 0.6592\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.4212, Val Loss: 1.4171, F1 Micro: 0.5112, F1 Macro: 0.4412, Accuracy: 0.5112\n","Epoch 2, Train Loss: 1.1565, Val Loss: 1.1487, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 3, Train Loss: 0.9614, Val Loss: 0.9333, F1 Micro: 0.6011, F1 Macro: 0.5093, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.7950, Val Loss: 0.7609, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 5, Train Loss: 0.6976, Val Loss: 0.6682, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.6427, Val Loss: 0.6207, F1 Micro: 0.7416, F1 Macro: 0.6762, Accuracy: 0.7416\n","Epoch 7, Train Loss: 0.6176, Val Loss: 0.5966, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 8, Train Loss: 0.6050, Val Loss: 0.5862, F1 Micro: 0.7247, F1 Macro: 0.6613, Accuracy: 0.7247\n","Epoch 9, Train Loss: 0.5987, Val Loss: 0.5767, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 10, Train Loss: 0.5962, Val Loss: 0.5724, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 11, Train Loss: 0.5906, Val Loss: 0.5699, F1 Micro: 0.7079, F1 Macro: 0.6645, Accuracy: 0.7079\n","Epoch 12, Train Loss: 0.5851, Val Loss: 0.5663, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.5825, Val Loss: 0.5685, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 14, Train Loss: 0.5825, Val Loss: 0.5646, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 15, Train Loss: 0.5773, Val Loss: 0.5668, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.5795, Val Loss: 0.5642, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.2834, Val Loss: 3.7339, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 2.8467, Val Loss: 3.1711, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 2.3811, Val Loss: 2.5574, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 4, Train Loss: 1.9517, Val Loss: 2.0105, F1 Micro: 0.6517, F1 Macro: 0.5002, Accuracy: 0.6517\n","Epoch 5, Train Loss: 1.5415, Val Loss: 1.6219, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 6, Train Loss: 1.2686, Val Loss: 1.3975, F1 Micro: 0.6910, F1 Macro: 0.6199, Accuracy: 0.6910\n","Epoch 7, Train Loss: 1.1491, Val Loss: 1.2533, F1 Micro: 0.7079, F1 Macro: 0.6579, Accuracy: 0.7079\n","Epoch 8, Train Loss: 1.0641, Val Loss: 1.1648, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 9, Train Loss: 0.9699, Val Loss: 1.1061, F1 Micro: 0.7247, F1 Macro: 0.6853, Accuracy: 0.7247\n","Epoch 10, Train Loss: 0.9108, Val Loss: 1.0251, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 11, Train Loss: 0.8459, Val Loss: 0.9661, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.7894, Val Loss: 0.9098, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.7352, Val Loss: 0.8465, F1 Micro: 0.7191, F1 Macro: 0.6803, Accuracy: 0.7191\n","Epoch 14, Train Loss: 0.6954, Val Loss: 0.7958, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 15, Train Loss: 0.6520, Val Loss: 0.7380, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 16, Train Loss: 0.6197, Val Loss: 0.7073, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 17, Train Loss: 0.5999, Val Loss: 0.6689, F1 Micro: 0.7247, F1 Macro: 0.6907, Accuracy: 0.7247\n","Epoch 18, Train Loss: 0.5859, Val Loss: 0.6355, F1 Micro: 0.7416, F1 Macro: 0.7084, Accuracy: 0.7416\n","Epoch 19, Train Loss: 0.5683, Val Loss: 0.6147, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 20, Train Loss: 0.5667, Val Loss: 0.6063, F1 Micro: 0.7079, F1 Macro: 0.6783, Accuracy: 0.7079\n","Epoch 21, Train Loss: 0.5577, Val Loss: 0.5870, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 22, Train Loss: 0.5597, Val Loss: 0.5735, F1 Micro: 0.7360, F1 Macro: 0.7034, Accuracy: 0.7360\n","Epoch 23, Train Loss: 0.5564, Val Loss: 0.5681, F1 Micro: 0.7135, F1 Macro: 0.6832, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.5559, Val Loss: 0.5660, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Epoch 25, Train Loss: 0.5554, Val Loss: 0.5653, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.5578, Val Loss: 0.5603, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 27, Train Loss: 0.5571, Val Loss: 0.5606, F1 Micro: 0.7191, F1 Macro: 0.6882, Accuracy: 0.7191\n","Epoch 28, Train Loss: 0.5526, Val Loss: 0.5741, F1 Micro: 0.7247, F1 Macro: 0.6933, Accuracy: 0.7247\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 7.5274, Val Loss: 5.2786, F1 Micro: 0.4045, F1 Macro: 0.3819, Accuracy: 0.4045\n","Epoch 2, Train Loss: 6.2094, Val Loss: 4.5600, F1 Micro: 0.4270, F1 Macro: 0.4181, Accuracy: 0.4270\n","Epoch 3, Train Loss: 5.0418, Val Loss: 4.0073, F1 Micro: 0.4719, F1 Macro: 0.4708, Accuracy: 0.4719\n","Epoch 4, Train Loss: 3.9818, Val Loss: 3.6627, F1 Micro: 0.4888, F1 Macro: 0.4868, Accuracy: 0.4888\n","Epoch 5, Train Loss: 3.4041, Val Loss: 3.5388, F1 Micro: 0.4944, F1 Macro: 0.4865, Accuracy: 0.4944\n","Epoch 6, Train Loss: 3.0080, Val Loss: 3.4294, F1 Micro: 0.5112, F1 Macro: 0.4959, Accuracy: 0.5112\n","Epoch 7, Train Loss: 2.7655, Val Loss: 3.3001, F1 Micro: 0.5112, F1 Macro: 0.4938, Accuracy: 0.5112\n","Epoch 8, Train Loss: 2.5619, Val Loss: 3.1450, F1 Micro: 0.5000, F1 Macro: 0.4799, Accuracy: 0.5000\n","Epoch 9, Train Loss: 2.3885, Val Loss: 2.9684, F1 Micro: 0.5000, F1 Macro: 0.4774, Accuracy: 0.5000\n","Epoch 10, Train Loss: 2.2320, Val Loss: 2.7828, F1 Micro: 0.5112, F1 Macro: 0.4866, Accuracy: 0.5112\n","Epoch 11, Train Loss: 2.1150, Val Loss: 2.5865, F1 Micro: 0.5169, F1 Macro: 0.4912, Accuracy: 0.5169\n","Epoch 12, Train Loss: 1.8960, Val Loss: 2.3529, F1 Micro: 0.5225, F1 Macro: 0.4957, Accuracy: 0.5225\n","Epoch 13, Train Loss: 1.7088, Val Loss: 2.1314, F1 Micro: 0.5225, F1 Macro: 0.4957, Accuracy: 0.5225\n","Epoch 14, Train Loss: 1.5512, Val Loss: 1.9232, F1 Micro: 0.5337, F1 Macro: 0.5019, Accuracy: 0.5337\n","Epoch 15, Train Loss: 1.3879, Val Loss: 1.6905, F1 Micro: 0.5337, F1 Macro: 0.5019, Accuracy: 0.5337\n","Epoch 16, Train Loss: 1.2249, Val Loss: 1.4860, F1 Micro: 0.5449, F1 Macro: 0.5108, Accuracy: 0.5449\n","Epoch 17, Train Loss: 1.0652, Val Loss: 1.2737, F1 Micro: 0.5449, F1 Macro: 0.5139, Accuracy: 0.5449\n","Epoch 18, Train Loss: 0.9239, Val Loss: 1.0824, F1 Micro: 0.5393, F1 Macro: 0.5122, Accuracy: 0.5393\n","Epoch 19, Train Loss: 0.8037, Val Loss: 0.9420, F1 Micro: 0.5787, F1 Macro: 0.5574, Accuracy: 0.5787\n","Epoch 20, Train Loss: 0.7148, Val Loss: 0.8278, F1 Micro: 0.6067, F1 Macro: 0.5900, Accuracy: 0.6067\n","Epoch 21, Train Loss: 0.6411, Val Loss: 0.7612, F1 Micro: 0.6404, F1 Macro: 0.6251, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6006, Val Loss: 0.7182, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 23, Train Loss: 0.5755, Val Loss: 0.6975, F1 Micro: 0.6461, F1 Macro: 0.6241, Accuracy: 0.6461\n","Epoch 24, Train Loss: 0.5629, Val Loss: 0.6916, F1 Micro: 0.6517, F1 Macro: 0.6290, Accuracy: 0.6517\n","Epoch 25, Train Loss: 0.5518, Val Loss: 0.6885, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.5466, Val Loss: 0.6952, F1 Micro: 0.6292, F1 Macro: 0.6074, Accuracy: 0.6292\n","Epoch 27, Train Loss: 0.5448, Val Loss: 0.6959, F1 Micro: 0.6124, F1 Macro: 0.5928, Accuracy: 0.6124\n","Epoch 28, Train Loss: 0.5449, Val Loss: 0.7134, F1 Micro: 0.6124, F1 Macro: 0.5883, Accuracy: 0.6124\n","Epoch 29, Train Loss: 0.5433, Val Loss: 0.7028, F1 Micro: 0.6067, F1 Macro: 0.5880, Accuracy: 0.6067\n","Epoch 30, Train Loss: 0.5421, Val Loss: 0.7090, F1 Micro: 0.6067, F1 Macro: 0.5880, Accuracy: 0.6067\n","Epoch 31, Train Loss: 0.5400, Val Loss: 0.6995, F1 Micro: 0.6124, F1 Macro: 0.5949, Accuracy: 0.6124\n","Epoch 32, Train Loss: 0.5414, Val Loss: 0.7027, F1 Micro: 0.6067, F1 Macro: 0.5880, Accuracy: 0.6067\n","Epoch 33, Train Loss: 0.5409, Val Loss: 0.7058, F1 Micro: 0.6067, F1 Macro: 0.5880, Accuracy: 0.6067\n","Epoch 34, Train Loss: 0.5415, Val Loss: 0.7116, F1 Micro: 0.6067, F1 Macro: 0.5880, Accuracy: 0.6067\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 4.4608, Val Loss: 2.9660, F1 Micro: 0.4270, F1 Macro: 0.3589, Accuracy: 0.4270\n","Epoch 2, Train Loss: 2.3856, Val Loss: 1.2676, F1 Micro: 0.3876, F1 Macro: 0.3685, Accuracy: 0.3876\n","Epoch 3, Train Loss: 1.1435, Val Loss: 0.8518, F1 Micro: 0.4944, F1 Macro: 0.4834, Accuracy: 0.4944\n","Epoch 4, Train Loss: 0.8745, Val Loss: 0.7812, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 5, Train Loss: 0.7992, Val Loss: 0.7301, F1 Micro: 0.6236, F1 Macro: 0.5839, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.7372, Val Loss: 0.6783, F1 Micro: 0.6461, F1 Macro: 0.6116, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6881, Val Loss: 0.6421, F1 Micro: 0.6798, F1 Macro: 0.6403, Accuracy: 0.6798\n","Epoch 8, Train Loss: 0.6576, Val Loss: 0.6140, F1 Micro: 0.7135, F1 Macro: 0.6781, Accuracy: 0.7135\n","Epoch 9, Train Loss: 0.6316, Val Loss: 0.5908, F1 Micro: 0.7191, F1 Macro: 0.6831, Accuracy: 0.7191\n","Epoch 10, Train Loss: 0.6123, Val Loss: 0.5802, F1 Micro: 0.7303, F1 Macro: 0.6983, Accuracy: 0.7303\n","Epoch 11, Train Loss: 0.6032, Val Loss: 0.5700, F1 Micro: 0.7360, F1 Macro: 0.7058, Accuracy: 0.7360\n","Epoch 12, Train Loss: 0.5944, Val Loss: 0.5654, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 13, Train Loss: 0.5955, Val Loss: 0.5609, F1 Micro: 0.7753, F1 Macro: 0.7543, Accuracy: 0.7753\n","Epoch 14, Train Loss: 0.5888, Val Loss: 0.5605, F1 Micro: 0.7640, F1 Macro: 0.7420, Accuracy: 0.7640\n","Epoch 15, Train Loss: 0.5865, Val Loss: 0.5587, F1 Micro: 0.7584, F1 Macro: 0.7386, Accuracy: 0.7584\n","Epoch 16, Train Loss: 0.5852, Val Loss: 0.5573, F1 Micro: 0.7584, F1 Macro: 0.7368, Accuracy: 0.7584\n","Epoch 17, Train Loss: 0.5844, Val Loss: 0.5569, F1 Micro: 0.7584, F1 Macro: 0.7368, Accuracy: 0.7584\n","Epoch 18, Train Loss: 0.5848, Val Loss: 0.5571, F1 Micro: 0.7584, F1 Macro: 0.7368, Accuracy: 0.7584\n","Epoch 19, Train Loss: 0.5842, Val Loss: 0.5542, F1 Micro: 0.7640, F1 Macro: 0.7438, Accuracy: 0.7640\n","Epoch 20, Train Loss: 0.5855, Val Loss: 0.5545, F1 Micro: 0.7584, F1 Macro: 0.7368, Accuracy: 0.7584\n","Epoch 21, Train Loss: 0.5856, Val Loss: 0.5544, F1 Micro: 0.7640, F1 Macro: 0.7438, Accuracy: 0.7640\n","Epoch 22, Train Loss: 0.5833, Val Loss: 0.5536, F1 Micro: 0.7640, F1 Macro: 0.7438, Accuracy: 0.7640\n","Epoch 23, Train Loss: 0.5868, Val Loss: 0.5529, F1 Micro: 0.7584, F1 Macro: 0.7435, Accuracy: 0.7584\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.7172180026363694\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 6.3357, Val Loss: 6.4236, F1 Micro: 0.3799, F1 Macro: 0.3227, Accuracy: 0.3799\n","Epoch 2, Train Loss: 5.2749, Val Loss: 5.3204, F1 Micro: 0.3464, F1 Macro: 0.3002, Accuracy: 0.3464\n","Epoch 3, Train Loss: 4.2566, Val Loss: 4.1968, F1 Micro: 0.3128, F1 Macro: 0.2839, Accuracy: 0.3128\n","Epoch 4, Train Loss: 3.3128, Val Loss: 3.2207, F1 Micro: 0.2626, F1 Macro: 0.2574, Accuracy: 0.2626\n","Epoch 5, Train Loss: 2.4736, Val Loss: 2.3470, F1 Micro: 0.2961, F1 Macro: 0.2959, Accuracy: 0.2961\n","Epoch 6, Train Loss: 1.8025, Val Loss: 1.6867, F1 Micro: 0.3240, F1 Macro: 0.3210, Accuracy: 0.3240\n","Epoch 7, Train Loss: 1.3107, Val Loss: 1.1950, F1 Micro: 0.4302, F1 Macro: 0.4047, Accuracy: 0.4302\n","Epoch 8, Train Loss: 1.0071, Val Loss: 0.9750, F1 Micro: 0.5307, F1 Macro: 0.4735, Accuracy: 0.5307\n","Epoch 9, Train Loss: 0.8618, Val Loss: 0.8632, F1 Micro: 0.5754, F1 Macro: 0.4961, Accuracy: 0.5754\n","Epoch 10, Train Loss: 0.7899, Val Loss: 0.8112, F1 Micro: 0.6089, F1 Macro: 0.5082, Accuracy: 0.6089\n","Epoch 11, Train Loss: 0.7571, Val Loss: 0.7836, F1 Micro: 0.6089, F1 Macro: 0.4880, Accuracy: 0.6089\n","Epoch 12, Train Loss: 0.7391, Val Loss: 0.7683, F1 Micro: 0.6257, F1 Macro: 0.4991, Accuracy: 0.6257\n","Epoch 13, Train Loss: 0.7287, Val Loss: 0.7576, F1 Micro: 0.6201, F1 Macro: 0.4797, Accuracy: 0.6201\n","Epoch 14, Train Loss: 0.7273, Val Loss: 0.7515, F1 Micro: 0.6257, F1 Macro: 0.4832, Accuracy: 0.6257\n","Epoch 15, Train Loss: 0.7161, Val Loss: 0.7428, F1 Micro: 0.6257, F1 Macro: 0.4746, Accuracy: 0.6257\n","Epoch 16, Train Loss: 0.7121, Val Loss: 0.7370, F1 Micro: 0.6313, F1 Macro: 0.4780, Accuracy: 0.6313\n","Epoch 17, Train Loss: 0.7082, Val Loss: 0.7318, F1 Micro: 0.6369, F1 Macro: 0.4814, Accuracy: 0.6369\n","Epoch 18, Train Loss: 0.7062, Val Loss: 0.7287, F1 Micro: 0.6369, F1 Macro: 0.4814, Accuracy: 0.6369\n","Epoch 19, Train Loss: 0.7041, Val Loss: 0.7259, F1 Micro: 0.6425, F1 Macro: 0.4849, Accuracy: 0.6425\n","Epoch 20, Train Loss: 0.7029, Val Loss: 0.7235, F1 Micro: 0.6425, F1 Macro: 0.4849, Accuracy: 0.6425\n","Epoch 21, Train Loss: 0.7013, Val Loss: 0.7214, F1 Micro: 0.6425, F1 Macro: 0.4849, Accuracy: 0.6425\n","Epoch 22, Train Loss: 0.7009, Val Loss: 0.7194, F1 Micro: 0.6369, F1 Macro: 0.4721, Accuracy: 0.6369\n","Epoch 23, Train Loss: 0.6991, Val Loss: 0.7165, F1 Micro: 0.6313, F1 Macro: 0.4591, Accuracy: 0.6313\n","Epoch 24, Train Loss: 0.6981, Val Loss: 0.7147, F1 Micro: 0.6369, F1 Macro: 0.4623, Accuracy: 0.6369\n","Epoch 25, Train Loss: 0.6973, Val Loss: 0.7130, F1 Micro: 0.6425, F1 Macro: 0.4655, Accuracy: 0.6425\n","Epoch 26, Train Loss: 0.6967, Val Loss: 0.7116, F1 Micro: 0.6425, F1 Macro: 0.4655, Accuracy: 0.6425\n","Epoch 27, Train Loss: 0.6962, Val Loss: 0.7103, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 28, Train Loss: 0.6960, Val Loss: 0.7093, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 29, Train Loss: 0.6952, Val Loss: 0.7079, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 30, Train Loss: 0.6949, Val Loss: 0.7066, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 31, Train Loss: 0.6925, Val Loss: 0.7056, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 32, Train Loss: 0.6940, Val Loss: 0.7050, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 33, Train Loss: 0.6936, Val Loss: 0.7038, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 34, Train Loss: 0.6935, Val Loss: 0.7032, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 35, Train Loss: 0.6932, Val Loss: 0.7026, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 36, Train Loss: 0.6933, Val Loss: 0.7026, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 37, Train Loss: 0.6932, Val Loss: 0.7016, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 38, Train Loss: 0.6931, Val Loss: 0.7012, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 39, Train Loss: 0.6929, Val Loss: 0.7008, F1 Micro: 0.6313, F1 Macro: 0.4263, Accuracy: 0.6313\n","Epoch 40, Train Loss: 0.6932, Val Loss: 0.7002, F1 Micro: 0.6369, F1 Macro: 0.4290, Accuracy: 0.6369\n","Epoch 41, Train Loss: 0.6927, Val Loss: 0.6995, F1 Micro: 0.6369, F1 Macro: 0.4290, Accuracy: 0.6369\n","Epoch 42, Train Loss: 0.6926, Val Loss: 0.6994, F1 Micro: 0.6369, F1 Macro: 0.4290, Accuracy: 0.6369\n","Epoch 43, Train Loss: 0.6925, Val Loss: 0.6989, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 44, Train Loss: 0.6926, Val Loss: 0.6989, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 45, Train Loss: 0.6926, Val Loss: 0.6983, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 46, Train Loss: 0.6926, Val Loss: 0.6981, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 47, Train Loss: 0.6924, Val Loss: 0.6982, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 48, Train Loss: 0.6919, Val Loss: 0.6982, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 49, Train Loss: 0.6925, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 50, Train Loss: 0.6922, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 51, Train Loss: 0.6924, Val Loss: 0.6978, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 52, Train Loss: 0.6925, Val Loss: 0.6978, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 53, Train Loss: 0.6925, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 54, Train Loss: 0.6925, Val Loss: 0.6978, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 55, Train Loss: 0.6925, Val Loss: 0.6983, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 56, Train Loss: 0.6926, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 57, Train Loss: 0.6929, Val Loss: 0.6981, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 58, Train Loss: 0.6925, Val Loss: 0.6982, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 59, Train Loss: 0.6917, Val Loss: 0.6979, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 60, Train Loss: 0.6924, Val Loss: 0.6981, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 61, Train Loss: 0.6924, Val Loss: 0.6979, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 62, Train Loss: 0.6925, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 63, Train Loss: 0.6925, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 64, Train Loss: 0.6925, Val Loss: 0.6979, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 65, Train Loss: 0.6925, Val Loss: 0.6981, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 66, Train Loss: 0.6924, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 67, Train Loss: 0.6924, Val Loss: 0.6980, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 68, Train Loss: 0.6926, Val Loss: 0.6978, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Epoch 69, Train Loss: 0.6927, Val Loss: 0.6983, F1 Micro: 0.6313, F1 Macro: 0.4140, Accuracy: 0.6313\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.5640, Val Loss: 1.1756, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 1.4121, Val Loss: 1.0495, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 1.2576, Val Loss: 0.9443, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 4, Train Loss: 1.1530, Val Loss: 0.8701, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 1.0650, Val Loss: 0.8126, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.9970, Val Loss: 0.7728, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.9469, Val Loss: 0.7527, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.9061, Val Loss: 0.7368, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.8836, Val Loss: 0.7251, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.8648, Val Loss: 0.7180, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.8404, Val Loss: 0.7112, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.8234, Val Loss: 0.7037, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.8132, Val Loss: 0.6974, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.7936, Val Loss: 0.6889, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.7779, Val Loss: 0.6816, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.7652, Val Loss: 0.6714, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.7504, Val Loss: 0.6607, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.7535, Val Loss: 0.6505, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.7219, Val Loss: 0.6424, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.7047, Val Loss: 0.6316, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6920, Val Loss: 0.6240, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6764, Val Loss: 0.6179, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6596, Val Loss: 0.6113, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6495, Val Loss: 0.6034, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6332, Val Loss: 0.5969, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6207, Val Loss: 0.5942, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6084, Val Loss: 0.5933, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 28, Train Loss: 0.6067, Val Loss: 0.5929, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6042, Val Loss: 0.5935, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6034, Val Loss: 0.5947, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6012, Val Loss: 0.5946, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.5999, Val Loss: 0.5957, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.5991, Val Loss: 0.5948, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.5998, Val Loss: 0.5953, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.5982, Val Loss: 0.5959, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.5988, Val Loss: 0.5965, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.5986, Val Loss: 0.5951, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.5981, Val Loss: 0.5975, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.5983, Val Loss: 0.5955, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6007, Val Loss: 0.5948, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.5965, Val Loss: 0.5958, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6010, Val Loss: 0.5952, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.5954, Val Loss: 0.5957, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.5963, Val Loss: 0.5961, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.5961, Val Loss: 0.5946, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.5991, Val Loss: 0.5938, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.5981, Val Loss: 0.5946, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.5978, Val Loss: 0.5930, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.5944, Val Loss: 0.5937, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.5964, Val Loss: 0.5936, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.5977, Val Loss: 0.5936, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.7399, Val Loss: 2.0022, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 2, Train Loss: 1.5176, Val Loss: 1.7145, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 3, Train Loss: 1.3042, Val Loss: 1.4540, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 4, Train Loss: 1.1181, Val Loss: 1.2154, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 5, Train Loss: 0.9407, Val Loss: 1.0292, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 6, Train Loss: 0.7956, Val Loss: 0.8728, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 7, Train Loss: 0.6957, Val Loss: 0.7859, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 8, Train Loss: 0.6373, Val Loss: 0.7427, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 9, Train Loss: 0.6101, Val Loss: 0.7225, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 10, Train Loss: 0.5971, Val Loss: 0.7061, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 11, Train Loss: 0.5917, Val Loss: 0.6884, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 12, Train Loss: 0.5853, Val Loss: 0.6729, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.5827, Val Loss: 0.6601, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.5780, Val Loss: 0.6462, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 15, Train Loss: 0.5774, Val Loss: 0.6345, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 16, Train Loss: 0.5755, Val Loss: 0.6234, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 17, Train Loss: 0.5735, Val Loss: 0.6101, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 18, Train Loss: 0.5696, Val Loss: 0.5982, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 19, Train Loss: 0.5741, Val Loss: 0.5886, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.5698, Val Loss: 0.5762, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 21, Train Loss: 0.5693, Val Loss: 0.5705, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 22, Train Loss: 0.5665, Val Loss: 0.5625, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 23, Train Loss: 0.5678, Val Loss: 0.5518, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 24, Train Loss: 0.5662, Val Loss: 0.5461, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 25, Train Loss: 0.5650, Val Loss: 0.5409, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 26, Train Loss: 0.5625, Val Loss: 0.5349, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 27, Train Loss: 0.5702, Val Loss: 0.5309, F1 Micro: 0.6910, F1 Macro: 0.5526, Accuracy: 0.6910\n","Epoch 28, Train Loss: 0.5628, Val Loss: 0.5232, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 29, Train Loss: 0.5655, Val Loss: 0.5222, F1 Micro: 0.6966, F1 Macro: 0.5647, Accuracy: 0.6966\n","Epoch 30, Train Loss: 0.5601, Val Loss: 0.5198, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 31, Train Loss: 0.5601, Val Loss: 0.5193, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 32, Train Loss: 0.5615, Val Loss: 0.5197, F1 Micro: 0.7022, F1 Macro: 0.5765, Accuracy: 0.7022\n","Epoch 33, Train Loss: 0.5604, Val Loss: 0.5182, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 34, Train Loss: 0.5610, Val Loss: 0.5166, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 35, Train Loss: 0.5563, Val Loss: 0.5176, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 36, Train Loss: 0.5567, Val Loss: 0.5162, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 37, Train Loss: 0.5592, Val Loss: 0.5130, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 38, Train Loss: 0.5572, Val Loss: 0.5174, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 39, Train Loss: 0.5588, Val Loss: 0.5164, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 40, Train Loss: 0.5616, Val Loss: 0.5164, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 41, Train Loss: 0.5568, Val Loss: 0.5171, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 42, Train Loss: 0.5544, Val Loss: 0.5159, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 43, Train Loss: 0.5573, Val Loss: 0.5141, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 44, Train Loss: 0.5571, Val Loss: 0.5166, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 45, Train Loss: 0.5560, Val Loss: 0.5138, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 46, Train Loss: 0.5596, Val Loss: 0.5158, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 47, Train Loss: 0.5561, Val Loss: 0.5148, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 48, Train Loss: 0.5572, Val Loss: 0.5170, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 49, Train Loss: 0.5560, Val Loss: 0.5174, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 50, Train Loss: 0.5557, Val Loss: 0.5227, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 51, Train Loss: 0.5558, Val Loss: 0.5144, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 52, Train Loss: 0.5562, Val Loss: 0.5149, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 53, Train Loss: 0.5590, Val Loss: 0.5133, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 54, Train Loss: 0.5557, Val Loss: 0.5146, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 55, Train Loss: 0.5583, Val Loss: 0.5181, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 56, Train Loss: 0.5543, Val Loss: 0.5187, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 4.0026, Val Loss: 1.9559, F1 Micro: 0.3933, F1 Macro: 0.3155, Accuracy: 0.3933\n","Epoch 2, Train Loss: 1.8601, Val Loss: 0.9195, F1 Micro: 0.4607, F1 Macro: 0.4582, Accuracy: 0.4607\n","Epoch 3, Train Loss: 0.7700, Val Loss: 0.7659, F1 Micro: 0.5393, F1 Macro: 0.4659, Accuracy: 0.5393\n","Epoch 4, Train Loss: 0.6082, Val Loss: 0.7943, F1 Micro: 0.5449, F1 Macro: 0.4402, Accuracy: 0.5449\n","Epoch 5, Train Loss: 0.5852, Val Loss: 0.8039, F1 Micro: 0.5506, F1 Macro: 0.4437, Accuracy: 0.5506\n","Epoch 6, Train Loss: 0.5735, Val Loss: 0.8033, F1 Micro: 0.5449, F1 Macro: 0.4261, Accuracy: 0.5449\n","Epoch 7, Train Loss: 0.5669, Val Loss: 0.7977, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 8, Train Loss: 0.5625, Val Loss: 0.7874, F1 Micro: 0.5337, F1 Macro: 0.3960, Accuracy: 0.5337\n","Epoch 9, Train Loss: 0.5601, Val Loss: 0.7728, F1 Micro: 0.5506, F1 Macro: 0.4295, Accuracy: 0.5506\n","Epoch 10, Train Loss: 0.5527, Val Loss: 0.7678, F1 Micro: 0.5337, F1 Macro: 0.3960, Accuracy: 0.5337\n","Epoch 11, Train Loss: 0.5488, Val Loss: 0.7618, F1 Micro: 0.5281, F1 Macro: 0.3844, Accuracy: 0.5281\n","Epoch 12, Train Loss: 0.5445, Val Loss: 0.7416, F1 Micro: 0.5506, F1 Macro: 0.4295, Accuracy: 0.5506\n","Epoch 13, Train Loss: 0.5433, Val Loss: 0.7388, F1 Micro: 0.5449, F1 Macro: 0.4185, Accuracy: 0.5449\n","Epoch 14, Train Loss: 0.5364, Val Loss: 0.7294, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 15, Train Loss: 0.5367, Val Loss: 0.7271, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 16, Train Loss: 0.5343, Val Loss: 0.7326, F1 Micro: 0.5562, F1 Macro: 0.4403, Accuracy: 0.5562\n","Epoch 17, Train Loss: 0.5301, Val Loss: 0.7268, F1 Micro: 0.5506, F1 Macro: 0.4368, Accuracy: 0.5506\n","Epoch 18, Train Loss: 0.5325, Val Loss: 0.7286, F1 Micro: 0.5562, F1 Macro: 0.4473, Accuracy: 0.5562\n","Epoch 19, Train Loss: 0.5279, Val Loss: 0.7282, F1 Micro: 0.5562, F1 Macro: 0.4473, Accuracy: 0.5562\n","Epoch 20, Train Loss: 0.5284, Val Loss: 0.7242, F1 Micro: 0.5618, F1 Macro: 0.4577, Accuracy: 0.5618\n","Epoch 21, Train Loss: 0.5240, Val Loss: 0.7238, F1 Micro: 0.5618, F1 Macro: 0.4577, Accuracy: 0.5618\n","Epoch 22, Train Loss: 0.5266, Val Loss: 0.7170, F1 Micro: 0.5618, F1 Macro: 0.4702, Accuracy: 0.5618\n","Epoch 23, Train Loss: 0.5242, Val Loss: 0.7157, F1 Micro: 0.5618, F1 Macro: 0.4702, Accuracy: 0.5618\n","Epoch 24, Train Loss: 0.5216, Val Loss: 0.7101, F1 Micro: 0.5618, F1 Macro: 0.4816, Accuracy: 0.5618\n","Epoch 25, Train Loss: 0.5211, Val Loss: 0.7144, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 26, Train Loss: 0.5188, Val Loss: 0.7158, F1 Micro: 0.5618, F1 Macro: 0.4761, Accuracy: 0.5618\n","Epoch 27, Train Loss: 0.5186, Val Loss: 0.7151, F1 Micro: 0.5674, F1 Macro: 0.4856, Accuracy: 0.5674\n","Epoch 28, Train Loss: 0.5181, Val Loss: 0.7078, F1 Micro: 0.5787, F1 Macro: 0.5091, Accuracy: 0.5787\n","Epoch 29, Train Loss: 0.5167, Val Loss: 0.7143, F1 Micro: 0.5787, F1 Macro: 0.5041, Accuracy: 0.5787\n","Epoch 30, Train Loss: 0.5137, Val Loss: 0.7047, F1 Micro: 0.5843, F1 Macro: 0.5225, Accuracy: 0.5843\n","Epoch 31, Train Loss: 0.5096, Val Loss: 0.7068, F1 Micro: 0.5843, F1 Macro: 0.5180, Accuracy: 0.5843\n","Epoch 32, Train Loss: 0.5152, Val Loss: 0.7068, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 33, Train Loss: 0.5100, Val Loss: 0.7070, F1 Micro: 0.5899, F1 Macro: 0.5268, Accuracy: 0.5899\n","Epoch 34, Train Loss: 0.5093, Val Loss: 0.7031, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 35, Train Loss: 0.5079, Val Loss: 0.7075, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 36, Train Loss: 0.5080, Val Loss: 0.7083, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 37, Train Loss: 0.5062, Val Loss: 0.7019, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 38, Train Loss: 0.5038, Val Loss: 0.7055, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 39, Train Loss: 0.5023, Val Loss: 0.7117, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 40, Train Loss: 0.5042, Val Loss: 0.7083, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 41, Train Loss: 0.5055, Val Loss: 0.7086, F1 Micro: 0.5899, F1 Macro: 0.5393, Accuracy: 0.5899\n","Epoch 42, Train Loss: 0.5032, Val Loss: 0.7102, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 43, Train Loss: 0.5022, Val Loss: 0.7069, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.5043, Val Loss: 0.7149, F1 Micro: 0.5843, F1 Macro: 0.5310, Accuracy: 0.5843\n","Epoch 45, Train Loss: 0.5007, Val Loss: 0.7086, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.5021, Val Loss: 0.7090, F1 Micro: 0.6011, F1 Macro: 0.5590, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.5005, Val Loss: 0.7154, F1 Micro: 0.6067, F1 Macro: 0.5635, Accuracy: 0.6067\n","Epoch 48, Train Loss: 0.4975, Val Loss: 0.7051, F1 Micro: 0.6011, F1 Macro: 0.5623, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.5000, Val Loss: 0.7136, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 50, Train Loss: 0.4997, Val Loss: 0.7199, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 51, Train Loss: 0.4987, Val Loss: 0.7117, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 52, Train Loss: 0.4991, Val Loss: 0.7188, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 53, Train Loss: 0.4974, Val Loss: 0.7084, F1 Micro: 0.5843, F1 Macro: 0.5487, Accuracy: 0.5843\n","Epoch 54, Train Loss: 0.4954, Val Loss: 0.7163, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 55, Train Loss: 0.4981, Val Loss: 0.7168, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 56, Train Loss: 0.4969, Val Loss: 0.7168, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 57, Train Loss: 0.4924, Val Loss: 0.7179, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 58, Train Loss: 0.4925, Val Loss: 0.7107, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 59, Train Loss: 0.4942, Val Loss: 0.7247, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 60, Train Loss: 0.4926, Val Loss: 0.7187, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 61, Train Loss: 0.4914, Val Loss: 0.7109, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 62, Train Loss: 0.4929, Val Loss: 0.7206, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 63, Train Loss: 0.4911, Val Loss: 0.7156, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 64, Train Loss: 0.4893, Val Loss: 0.7186, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 65, Train Loss: 0.4890, Val Loss: 0.7337, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 66, Train Loss: 0.4896, Val Loss: 0.7190, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 67, Train Loss: 0.4883, Val Loss: 0.7217, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 68, Train Loss: 0.4902, Val Loss: 0.7199, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 69, Train Loss: 0.4899, Val Loss: 0.7373, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 70, Train Loss: 0.4891, Val Loss: 0.7386, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 71, Train Loss: 0.4920, Val Loss: 0.7355, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 72, Train Loss: 0.4860, Val Loss: 0.7265, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 73, Train Loss: 0.4899, Val Loss: 0.7353, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 74, Train Loss: 0.4859, Val Loss: 0.7335, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 75, Train Loss: 0.4886, Val Loss: 0.7380, F1 Micro: 0.6011, F1 Macro: 0.5684, Accuracy: 0.6011\n","Epoch 76, Train Loss: 0.4888, Val Loss: 0.7291, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 77, Train Loss: 0.4858, Val Loss: 0.7269, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 78, Train Loss: 0.4850, Val Loss: 0.7282, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 79, Train Loss: 0.4881, Val Loss: 0.7316, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 80, Train Loss: 0.4861, Val Loss: 0.7492, F1 Micro: 0.5955, F1 Macro: 0.5609, Accuracy: 0.5955\n","Epoch 81, Train Loss: 0.4883, Val Loss: 0.7385, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 82, Train Loss: 0.4891, Val Loss: 0.7308, F1 Micro: 0.5955, F1 Macro: 0.5638, Accuracy: 0.5955\n","Epoch 83, Train Loss: 0.4878, Val Loss: 0.7444, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 84, Train Loss: 0.4900, Val Loss: 0.7439, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 85, Train Loss: 0.4889, Val Loss: 0.7276, F1 Micro: 0.5899, F1 Macro: 0.5619, Accuracy: 0.5899\n","Epoch 86, Train Loss: 0.4933, Val Loss: 0.7192, F1 Micro: 0.5955, F1 Macro: 0.5717, Accuracy: 0.5955\n","Epoch 87, Train Loss: 0.4873, Val Loss: 0.7273, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 88, Train Loss: 0.4868, Val Loss: 0.7390, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 89, Train Loss: 0.4874, Val Loss: 0.7130, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Epoch 90, Train Loss: 0.4858, Val Loss: 0.7445, F1 Micro: 0.5899, F1 Macro: 0.5563, Accuracy: 0.5899\n","Epoch 91, Train Loss: 0.4880, Val Loss: 0.7249, F1 Micro: 0.5955, F1 Macro: 0.5692, Accuracy: 0.5955\n","Epoch 92, Train Loss: 0.4893, Val Loss: 0.7391, F1 Micro: 0.5843, F1 Macro: 0.5517, Accuracy: 0.5843\n","Epoch 93, Train Loss: 0.4870, Val Loss: 0.7199, F1 Micro: 0.5899, F1 Macro: 0.5645, Accuracy: 0.5899\n","Epoch 94, Train Loss: 0.4856, Val Loss: 0.7298, F1 Micro: 0.5899, F1 Macro: 0.5619, Accuracy: 0.5899\n","Epoch 95, Train Loss: 0.4917, Val Loss: 0.7138, F1 Micro: 0.6067, F1 Macro: 0.5858, Accuracy: 0.6067\n","Epoch 96, Train Loss: 0.4875, Val Loss: 0.7329, F1 Micro: 0.5955, F1 Macro: 0.5666, Accuracy: 0.5955\n","Epoch 97, Train Loss: 0.4918, Val Loss: 0.7403, F1 Micro: 0.5843, F1 Macro: 0.5517, Accuracy: 0.5843\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 3.0410, Val Loss: 2.7302, F1 Micro: 0.5787, F1 Macro: 0.5266, Accuracy: 0.5787\n","Epoch 2, Train Loss: 2.7452, Val Loss: 2.4861, F1 Micro: 0.5899, F1 Macro: 0.5353, Accuracy: 0.5899\n","Epoch 3, Train Loss: 2.4496, Val Loss: 2.2446, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 4, Train Loss: 2.1808, Val Loss: 2.0058, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 5, Train Loss: 1.9302, Val Loss: 1.7651, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 6, Train Loss: 1.7172, Val Loss: 1.5524, F1 Micro: 0.6292, F1 Macro: 0.5614, Accuracy: 0.6292\n","Epoch 7, Train Loss: 1.4941, Val Loss: 1.3459, F1 Micro: 0.6180, F1 Macro: 0.5432, Accuracy: 0.6180\n","Epoch 8, Train Loss: 1.2959, Val Loss: 1.1633, F1 Micro: 0.6180, F1 Macro: 0.5432, Accuracy: 0.6180\n","Epoch 9, Train Loss: 1.1203, Val Loss: 1.0032, F1 Micro: 0.6236, F1 Macro: 0.5423, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.9885, Val Loss: 0.8924, F1 Micro: 0.6292, F1 Macro: 0.5411, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.8814, Val Loss: 0.8012, F1 Micro: 0.6180, F1 Macro: 0.5213, Accuracy: 0.6180\n","Epoch 12, Train Loss: 0.7934, Val Loss: 0.7265, F1 Micro: 0.6236, F1 Macro: 0.5253, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.7359, Val Loss: 0.6749, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6919, Val Loss: 0.6296, F1 Micro: 0.6348, F1 Macro: 0.5202, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6573, Val Loss: 0.5963, F1 Micro: 0.6461, F1 Macro: 0.5281, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.6313, Val Loss: 0.5740, F1 Micro: 0.6517, F1 Macro: 0.5321, Accuracy: 0.6517\n","Epoch 17, Train Loss: 0.6113, Val Loss: 0.5602, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 18, Train Loss: 0.6005, Val Loss: 0.5513, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.5963, Val Loss: 0.5453, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.5937, Val Loss: 0.5421, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.5859, Val Loss: 0.5397, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 22, Train Loss: 0.5834, Val Loss: 0.5382, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 23, Train Loss: 0.5817, Val Loss: 0.5367, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 24, Train Loss: 0.5803, Val Loss: 0.5359, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.5812, Val Loss: 0.5356, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 26, Train Loss: 0.5805, Val Loss: 0.5352, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 27, Train Loss: 0.5776, Val Loss: 0.5348, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 28, Train Loss: 0.5801, Val Loss: 0.5353, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 29, Train Loss: 0.5785, Val Loss: 0.5347, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.5779, Val Loss: 0.5347, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 31, Train Loss: 0.5768, Val Loss: 0.5347, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 32, Train Loss: 0.5790, Val Loss: 0.5346, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 33, Train Loss: 0.5786, Val Loss: 0.5346, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 34, Train Loss: 0.5759, Val Loss: 0.5348, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 35, Train Loss: 0.5817, Val Loss: 0.5350, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 36, Train Loss: 0.5757, Val Loss: 0.5357, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 37, Train Loss: 0.5741, Val Loss: 0.5346, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 38, Train Loss: 0.5766, Val Loss: 0.5345, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 39, Train Loss: 0.5724, Val Loss: 0.5348, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 40, Train Loss: 0.5755, Val Loss: 0.5344, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 41, Train Loss: 0.5720, Val Loss: 0.5353, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 42, Train Loss: 0.5727, Val Loss: 0.5345, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.5700, Val Loss: 0.5344, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 44, Train Loss: 0.5691, Val Loss: 0.5349, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 45, Train Loss: 0.5741, Val Loss: 0.5343, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 46, Train Loss: 0.5727, Val Loss: 0.5344, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 47, Train Loss: 0.5704, Val Loss: 0.5345, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.5682, Val Loss: 0.5349, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 49, Train Loss: 0.5693, Val Loss: 0.5347, F1 Micro: 0.6629, F1 Macro: 0.5247, Accuracy: 0.6629\n","Epoch 50, Train Loss: 0.5701, Val Loss: 0.5354, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.5672, Val Loss: 0.5348, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 52, Train Loss: 0.5716, Val Loss: 0.5354, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 53, Train Loss: 0.5646, Val Loss: 0.5352, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 54, Train Loss: 0.5664, Val Loss: 0.5362, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 55, Train Loss: 0.5643, Val Loss: 0.5354, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 56, Train Loss: 0.5620, Val Loss: 0.5359, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 57, Train Loss: 0.5625, Val Loss: 0.5366, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 58, Train Loss: 0.5651, Val Loss: 0.5364, F1 Micro: 0.6629, F1 Macro: 0.5326, Accuracy: 0.6629\n","Epoch 59, Train Loss: 0.5644, Val Loss: 0.5365, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.5631, Val Loss: 0.5375, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 61, Train Loss: 0.5603, Val Loss: 0.5366, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 62, Train Loss: 0.5614, Val Loss: 0.5359, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.5608, Val Loss: 0.5356, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 64, Train Loss: 0.5596, Val Loss: 0.5353, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.5597, Val Loss: 0.5352, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 66, Train Loss: 0.5573, Val Loss: 0.5350, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 67, Train Loss: 0.5582, Val Loss: 0.5349, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 68, Train Loss: 0.5580, Val Loss: 0.5347, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 69, Train Loss: 0.5564, Val Loss: 0.5349, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 70, Train Loss: 0.5565, Val Loss: 0.5345, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 71, Train Loss: 0.5536, Val Loss: 0.5338, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 72, Train Loss: 0.5556, Val Loss: 0.5341, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 73, Train Loss: 0.5523, Val Loss: 0.5331, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 74, Train Loss: 0.5566, Val Loss: 0.5325, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 75, Train Loss: 0.5533, Val Loss: 0.5326, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 76, Train Loss: 0.5528, Val Loss: 0.5317, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 77, Train Loss: 0.5522, Val Loss: 0.5318, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 78, Train Loss: 0.5512, Val Loss: 0.5318, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 79, Train Loss: 0.5512, Val Loss: 0.5314, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.5526, Val Loss: 0.5310, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 81, Train Loss: 0.5526, Val Loss: 0.5306, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 82, Train Loss: 0.5522, Val Loss: 0.5304, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 83, Train Loss: 0.5517, Val Loss: 0.5306, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 84, Train Loss: 0.5491, Val Loss: 0.5294, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 85, Train Loss: 0.5501, Val Loss: 0.5288, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 86, Train Loss: 0.5469, Val Loss: 0.5285, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 87, Train Loss: 0.5477, Val Loss: 0.5277, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 88, Train Loss: 0.5520, Val Loss: 0.5275, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 89, Train Loss: 0.5489, Val Loss: 0.5278, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 90, Train Loss: 0.5500, Val Loss: 0.5281, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 91, Train Loss: 0.5501, Val Loss: 0.5272, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 92, Train Loss: 0.5481, Val Loss: 0.5266, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.5518, Val Loss: 0.5266, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 94, Train Loss: 0.5502, Val Loss: 0.5266, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 95, Train Loss: 0.5474, Val Loss: 0.5275, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 96, Train Loss: 0.5470, Val Loss: 0.5263, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 97, Train Loss: 0.5469, Val Loss: 0.5280, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 98, Train Loss: 0.5464, Val Loss: 0.5264, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 99, Train Loss: 0.5499, Val Loss: 0.5279, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 100, Train Loss: 0.5501, Val Loss: 0.5277, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 101, Train Loss: 0.5525, Val Loss: 0.5267, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 102, Train Loss: 0.5467, Val Loss: 0.5276, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 103, Train Loss: 0.5476, Val Loss: 0.5265, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 104, Train Loss: 0.5522, Val Loss: 0.5264, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 105, Train Loss: 0.5466, Val Loss: 0.5282, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 106, Train Loss: 0.5488, Val Loss: 0.5270, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 107, Train Loss: 0.5495, Val Loss: 0.5266, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 108, Train Loss: 0.5474, Val Loss: 0.5267, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 109, Train Loss: 0.5500, Val Loss: 0.5266, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 110, Train Loss: 0.5476, Val Loss: 0.5265, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 111, Train Loss: 0.5462, Val Loss: 0.5283, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 112, Train Loss: 0.5509, Val Loss: 0.5272, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 113, Train Loss: 0.5458, Val Loss: 0.5284, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 114, Train Loss: 0.5455, Val Loss: 0.5272, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 115, Train Loss: 0.5440, Val Loss: 0.5275, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 116, Train Loss: 0.5470, Val Loss: 0.5268, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 117, Train Loss: 0.5464, Val Loss: 0.5266, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 118, Train Loss: 0.5441, Val Loss: 0.5264, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 119, Train Loss: 0.5482, Val Loss: 0.5237, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 120, Train Loss: 0.5424, Val Loss: 0.5203, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 121, Train Loss: 0.5389, Val Loss: 0.5197, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 122, Train Loss: 0.5396, Val Loss: 0.5214, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 123, Train Loss: 0.5386, Val Loss: 0.5195, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 124, Train Loss: 0.5403, Val Loss: 0.5208, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 125, Train Loss: 0.5421, Val Loss: 0.5186, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.6577051032577993\n","Best hyperparameters for Outer FOLD 3: (0.001, 16, 10) with score 0.7172180026363694\n","Epoch 1, Train Loss: 8.7195, Val Loss: 8.0647, F1 Micro: 0.4414, F1 Macro: 0.3532, Accuracy: 0.4414\n","Epoch 2, Train Loss: 6.4388, Val Loss: 5.8705, F1 Micro: 0.4099, F1 Macro: 0.3651, Accuracy: 0.4099\n","Epoch 3, Train Loss: 4.4633, Val Loss: 4.0341, F1 Micro: 0.3829, F1 Macro: 0.3672, Accuracy: 0.3829\n","Epoch 4, Train Loss: 3.0155, Val Loss: 2.6986, F1 Micro: 0.4099, F1 Macro: 0.4099, Accuracy: 0.4099\n","Epoch 5, Train Loss: 2.2091, Val Loss: 2.0144, F1 Micro: 0.4505, F1 Macro: 0.4450, Accuracy: 0.4505\n","Epoch 6, Train Loss: 1.8626, Val Loss: 1.6733, F1 Micro: 0.5090, F1 Macro: 0.4934, Accuracy: 0.5090\n","Epoch 7, Train Loss: 1.6593, Val Loss: 1.4680, F1 Micro: 0.5405, F1 Macro: 0.5180, Accuracy: 0.5405\n","Epoch 8, Train Loss: 1.5050, Val Loss: 1.3061, F1 Micro: 0.5766, F1 Macro: 0.5478, Accuracy: 0.5766\n","Epoch 9, Train Loss: 1.3624, Val Loss: 1.1584, F1 Micro: 0.5766, F1 Macro: 0.5478, Accuracy: 0.5766\n","Epoch 10, Train Loss: 1.2042, Val Loss: 1.0176, F1 Micro: 0.6036, F1 Macro: 0.5767, Accuracy: 0.6036\n","Epoch 11, Train Loss: 1.0643, Val Loss: 0.8835, F1 Micro: 0.6126, F1 Macro: 0.5863, Accuracy: 0.6126\n","Epoch 12, Train Loss: 0.9329, Val Loss: 0.7737, F1 Micro: 0.6171, F1 Macro: 0.5921, Accuracy: 0.6171\n","Epoch 13, Train Loss: 0.8218, Val Loss: 0.6858, F1 Micro: 0.6261, F1 Macro: 0.5997, Accuracy: 0.6261\n","Epoch 14, Train Loss: 0.7321, Val Loss: 0.6263, F1 Micro: 0.6982, F1 Macro: 0.6769, Accuracy: 0.6982\n","Epoch 15, Train Loss: 0.6683, Val Loss: 0.5949, F1 Micro: 0.7117, F1 Macro: 0.6890, Accuracy: 0.7117\n","Epoch 16, Train Loss: 0.6226, Val Loss: 0.5788, F1 Micro: 0.7387, F1 Macro: 0.7223, Accuracy: 0.7387\n","Epoch 17, Train Loss: 0.5953, Val Loss: 0.5727, F1 Micro: 0.7432, F1 Macro: 0.7312, Accuracy: 0.7432\n","Epoch 18, Train Loss: 0.5795, Val Loss: 0.5717, F1 Micro: 0.7432, F1 Macro: 0.7312, Accuracy: 0.7432\n","Epoch 19, Train Loss: 0.5701, Val Loss: 0.5722, F1 Micro: 0.7387, F1 Macro: 0.7281, Accuracy: 0.7387\n","Epoch 20, Train Loss: 0.5645, Val Loss: 0.5738, F1 Micro: 0.7387, F1 Macro: 0.7290, Accuracy: 0.7387\n","Epoch 21, Train Loss: 0.5619, Val Loss: 0.5754, F1 Micro: 0.7387, F1 Macro: 0.7290, Accuracy: 0.7387\n","Epoch 22, Train Loss: 0.5591, Val Loss: 0.5758, F1 Micro: 0.7387, F1 Macro: 0.7290, Accuracy: 0.7387\n","Epoch 23, Train Loss: 0.5597, Val Loss: 0.5808, F1 Micro: 0.7252, F1 Macro: 0.7112, Accuracy: 0.7252\n","Epoch 24, Train Loss: 0.5582, Val Loss: 0.5802, F1 Micro: 0.7432, F1 Macro: 0.7322, Accuracy: 0.7432\n","Epoch 25, Train Loss: 0.5571, Val Loss: 0.5806, F1 Micro: 0.7342, F1 Macro: 0.7218, Accuracy: 0.7342\n","Epoch 26, Train Loss: 0.5563, Val Loss: 0.5839, F1 Micro: 0.7162, F1 Macro: 0.7004, Accuracy: 0.7162\n","Epoch 27, Train Loss: 0.5557, Val Loss: 0.5799, F1 Micro: 0.7432, F1 Macro: 0.7332, Accuracy: 0.7432\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.7432, F1 Macro: 0.7332, Accuracy: 0.7432\n","Outer FOLD 4\n","--------------------------------\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.1926, Val Loss: 0.6339, F1 Micro: 0.6425, F1 Macro: 0.4437, Accuracy: 0.6425\n","Epoch 2, Train Loss: 0.6276, Val Loss: 0.6280, F1 Micro: 0.6592, F1 Macro: 0.5133, Accuracy: 0.6592\n","Epoch 3, Train Loss: 0.5961, Val Loss: 0.5713, F1 Micro: 0.6592, F1 Macro: 0.5046, Accuracy: 0.6592\n","Epoch 4, Train Loss: 0.5877, Val Loss: 0.5632, F1 Micro: 0.6648, F1 Macro: 0.5171, Accuracy: 0.6648\n","Epoch 5, Train Loss: 0.5933, Val Loss: 0.5410, F1 Micro: 0.6760, F1 Macro: 0.5246, Accuracy: 0.6760\n","Epoch 6, Train Loss: 0.5832, Val Loss: 0.5305, F1 Micro: 0.6816, F1 Macro: 0.5672, Accuracy: 0.6816\n","Epoch 7, Train Loss: 0.5692, Val Loss: 0.5453, F1 Micro: 0.6872, F1 Macro: 0.5781, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.5728, Val Loss: 0.5646, F1 Micro: 0.6927, F1 Macro: 0.5687, Accuracy: 0.6927\n","Epoch 9, Train Loss: 0.5844, Val Loss: 0.5550, F1 Micro: 0.6927, F1 Macro: 0.5687, Accuracy: 0.6927\n","Epoch 10, Train Loss: 0.5628, Val Loss: 0.5808, F1 Micro: 0.6983, F1 Macro: 0.5729, Accuracy: 0.6983\n","Epoch 11, Train Loss: 0.5715, Val Loss: 0.5385, F1 Micro: 0.6927, F1 Macro: 0.5687, Accuracy: 0.6927\n","Epoch 12, Train Loss: 0.5610, Val Loss: 0.5683, F1 Micro: 0.6816, F1 Macro: 0.5860, Accuracy: 0.6816\n","Epoch 13, Train Loss: 0.5485, Val Loss: 0.5471, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 14, Train Loss: 0.5519, Val Loss: 0.5343, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 15, Train Loss: 0.5771, Val Loss: 0.5166, F1 Micro: 0.6927, F1 Macro: 0.6252, Accuracy: 0.6927\n","Epoch 16, Train Loss: 0.5680, Val Loss: 0.5292, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 17, Train Loss: 0.5644, Val Loss: 0.5495, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 18, Train Loss: 0.5645, Val Loss: 0.5606, F1 Micro: 0.6872, F1 Macro: 0.5844, Accuracy: 0.6872\n","Epoch 19, Train Loss: 0.5640, Val Loss: 0.5484, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 20, Train Loss: 0.5569, Val Loss: 0.5438, F1 Micro: 0.6872, F1 Macro: 0.6161, Accuracy: 0.6872\n","Epoch 21, Train Loss: 0.5465, Val Loss: 0.5349, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 22, Train Loss: 0.5610, Val Loss: 0.5392, F1 Micro: 0.6927, F1 Macro: 0.5948, Accuracy: 0.6927\n","Epoch 23, Train Loss: 0.5713, Val Loss: 0.5534, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7802, Val Loss: 0.6770, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 2, Train Loss: 0.7178, Val Loss: 0.6804, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.6902, Val Loss: 0.6867, F1 Micro: 0.6348, F1 Macro: 0.4025, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6886, Val Loss: 0.6848, F1 Micro: 0.6404, F1 Macro: 0.4048, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6813, Val Loss: 0.6814, F1 Micro: 0.6461, F1 Macro: 0.4071, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.6884, Val Loss: 0.6877, F1 Micro: 0.6404, F1 Macro: 0.4048, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.6869, Val Loss: 0.6857, F1 Micro: 0.6404, F1 Macro: 0.4048, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6867, Val Loss: 0.7076, F1 Micro: 0.6292, F1 Macro: 0.4132, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6885, Val Loss: 0.6969, F1 Micro: 0.6404, F1 Macro: 0.4183, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6849, Val Loss: 0.6881, F1 Micro: 0.6404, F1 Macro: 0.4048, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6848, Val Loss: 0.6968, F1 Micro: 0.6348, F1 Macro: 0.4025, Accuracy: 0.6348\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7713, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.9819, Val Loss: 0.8397, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 2, Train Loss: 0.7055, Val Loss: 0.7690, F1 Micro: 0.5674, F1 Macro: 0.4678, Accuracy: 0.5674\n","Epoch 3, Train Loss: 0.6937, Val Loss: 0.7052, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 4, Train Loss: 0.6838, Val Loss: 0.6982, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 5, Train Loss: 0.6808, Val Loss: 0.6875, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 6, Train Loss: 0.6796, Val Loss: 0.6954, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 7, Train Loss: 0.6842, Val Loss: 0.6799, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 8, Train Loss: 0.6857, Val Loss: 0.6764, F1 Micro: 0.5787, F1 Macro: 0.4686, Accuracy: 0.5787\n","Epoch 9, Train Loss: 0.6790, Val Loss: 0.6753, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 10, Train Loss: 0.6782, Val Loss: 0.6824, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 11, Train Loss: 0.6753, Val Loss: 0.6726, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 12, Train Loss: 0.6779, Val Loss: 0.6698, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 13, Train Loss: 0.6773, Val Loss: 0.6673, F1 Micro: 0.5787, F1 Macro: 0.4753, Accuracy: 0.5787\n","Epoch 14, Train Loss: 0.6750, Val Loss: 0.6705, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 15, Train Loss: 0.6745, Val Loss: 0.6658, F1 Micro: 0.5843, F1 Macro: 0.4855, Accuracy: 0.5843\n","Epoch 16, Train Loss: 0.6760, Val Loss: 0.6643, F1 Micro: 0.5899, F1 Macro: 0.5070, Accuracy: 0.5899\n","Epoch 17, Train Loss: 0.6699, Val Loss: 0.6579, F1 Micro: 0.6067, F1 Macro: 0.5246, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.6675, Val Loss: 0.6532, F1 Micro: 0.6011, F1 Macro: 0.5205, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6610, Val Loss: 0.6475, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 20, Train Loss: 0.6609, Val Loss: 0.6452, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.6582, Val Loss: 0.6447, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 22, Train Loss: 0.6575, Val Loss: 0.6435, F1 Micro: 0.6124, F1 Macro: 0.5608, Accuracy: 0.6124\n","Epoch 23, Train Loss: 0.6536, Val Loss: 0.6435, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 24, Train Loss: 0.6595, Val Loss: 0.6431, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 25, Train Loss: 0.6583, Val Loss: 0.6433, F1 Micro: 0.6180, F1 Macro: 0.5726, Accuracy: 0.6180\n","Epoch 26, Train Loss: 0.6563, Val Loss: 0.6435, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 27, Train Loss: 0.6572, Val Loss: 0.6438, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 28, Train Loss: 0.6573, Val Loss: 0.6415, F1 Micro: 0.6011, F1 Macro: 0.5353, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6569, Val Loss: 0.6433, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 30, Train Loss: 0.6570, Val Loss: 0.6459, F1 Micro: 0.6180, F1 Macro: 0.5481, Accuracy: 0.6180\n","Epoch 31, Train Loss: 0.6568, Val Loss: 0.6407, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 32, Train Loss: 0.6576, Val Loss: 0.6428, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.6576, Val Loss: 0.6407, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 34, Train Loss: 0.6564, Val Loss: 0.6406, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 35, Train Loss: 0.6577, Val Loss: 0.6490, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7925, Val Loss: 0.6916, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 2, Train Loss: 0.6945, Val Loss: 0.6926, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.6918, Val Loss: 0.6929, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6884, Val Loss: 0.6922, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6888, Val Loss: 0.6918, F1 Micro: 0.6067, F1 Macro: 0.4454, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.6894, Val Loss: 0.6904, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 7, Train Loss: 0.6971, Val Loss: 0.6898, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 8, Train Loss: 0.6917, Val Loss: 0.6902, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 9, Train Loss: 0.6863, Val Loss: 0.6833, F1 Micro: 0.6461, F1 Macro: 0.5350, Accuracy: 0.6461\n","Epoch 10, Train Loss: 0.6799, Val Loss: 0.6802, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.6830, Val Loss: 0.6777, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 12, Train Loss: 0.6817, Val Loss: 0.6834, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.6810, Val Loss: 0.6599, F1 Micro: 0.7303, F1 Macro: 0.7007, Accuracy: 0.7303\n","Epoch 14, Train Loss: 0.6907, Val Loss: 0.6920, F1 Micro: 0.6236, F1 Macro: 0.4449, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6890, Val Loss: 0.6782, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.6748, Val Loss: 0.6537, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 17, Train Loss: 0.6649, Val Loss: 0.6605, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 18, Train Loss: 0.6621, Val Loss: 0.6543, F1 Micro: 0.7191, F1 Macro: 0.6857, Accuracy: 0.7191\n","Epoch 19, Train Loss: 0.6590, Val Loss: 0.6538, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 20, Train Loss: 0.6609, Val Loss: 0.6501, F1 Micro: 0.7135, F1 Macro: 0.6694, Accuracy: 0.7135\n","Epoch 21, Train Loss: 0.6727, Val Loss: 0.6453, F1 Micro: 0.7135, F1 Macro: 0.6725, Accuracy: 0.7135\n","Epoch 22, Train Loss: 0.6579, Val Loss: 0.6448, F1 Micro: 0.7191, F1 Macro: 0.6971, Accuracy: 0.7191\n","Epoch 23, Train Loss: 0.6626, Val Loss: 0.6511, F1 Micro: 0.7135, F1 Macro: 0.6628, Accuracy: 0.7135\n","Epoch 24, Train Loss: 0.6607, Val Loss: 0.6523, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 25, Train Loss: 0.6540, Val Loss: 0.6480, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 26, Train Loss: 0.6569, Val Loss: 0.6504, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 10): 0.669976774841504\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.8133, Val Loss: 0.6868, F1 Micro: 0.6536, F1 Macro: 0.4372, Accuracy: 0.6536\n","Epoch 2, Train Loss: 0.6647, Val Loss: 0.6749, F1 Micro: 0.7039, F1 Macro: 0.6095, Accuracy: 0.7039\n","Epoch 3, Train Loss: 0.6345, Val Loss: 0.6512, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 4, Train Loss: 0.6570, Val Loss: 0.5904, F1 Micro: 0.7039, F1 Macro: 0.5844, Accuracy: 0.7039\n","Epoch 5, Train Loss: 0.6031, Val Loss: 0.6143, F1 Micro: 0.6927, F1 Macro: 0.5533, Accuracy: 0.6927\n","Epoch 6, Train Loss: 0.5976, Val Loss: 0.5741, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 7, Train Loss: 0.6008, Val Loss: 0.6591, F1 Micro: 0.6872, F1 Macro: 0.6775, Accuracy: 0.6872\n","Epoch 8, Train Loss: 0.6254, Val Loss: 0.5704, F1 Micro: 0.7374, F1 Macro: 0.6989, Accuracy: 0.7374\n","Epoch 9, Train Loss: 0.5794, Val Loss: 0.5659, F1 Micro: 0.7374, F1 Macro: 0.7152, Accuracy: 0.7374\n","Epoch 10, Train Loss: 0.5814, Val Loss: 0.5742, F1 Micro: 0.7095, F1 Macro: 0.6917, Accuracy: 0.7095\n","Epoch 11, Train Loss: 0.5739, Val Loss: 0.5545, F1 Micro: 0.7318, F1 Macro: 0.7039, Accuracy: 0.7318\n","Epoch 12, Train Loss: 0.5671, Val Loss: 0.5727, F1 Micro: 0.7095, F1 Macro: 0.6934, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.5806, Val Loss: 0.5781, F1 Micro: 0.7430, F1 Macro: 0.6917, Accuracy: 0.7430\n","Epoch 14, Train Loss: 0.5682, Val Loss: 0.5602, F1 Micro: 0.7039, F1 Macro: 0.6810, Accuracy: 0.7039\n","Epoch 15, Train Loss: 0.5693, Val Loss: 0.5450, F1 Micro: 0.7430, F1 Macro: 0.6917, Accuracy: 0.7430\n","Epoch 16, Train Loss: 0.5664, Val Loss: 0.5601, F1 Micro: 0.6983, F1 Macro: 0.6693, Accuracy: 0.6983\n","Epoch 17, Train Loss: 0.5541, Val Loss: 0.5508, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 18, Train Loss: 0.5655, Val Loss: 0.5427, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 19, Train Loss: 0.5578, Val Loss: 0.5471, F1 Micro: 0.7263, F1 Macro: 0.6768, Accuracy: 0.7263\n","Epoch 20, Train Loss: 0.5579, Val Loss: 0.5532, F1 Micro: 0.7151, F1 Macro: 0.6762, Accuracy: 0.7151\n","Epoch 21, Train Loss: 0.5657, Val Loss: 0.5652, F1 Micro: 0.6983, F1 Macro: 0.6669, Accuracy: 0.6983\n","Epoch 22, Train Loss: 0.5554, Val Loss: 0.5485, F1 Micro: 0.7318, F1 Macro: 0.6783, Accuracy: 0.7318\n","Epoch 23, Train Loss: 0.5587, Val Loss: 0.5631, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 24, Train Loss: 0.5558, Val Loss: 0.5548, F1 Micro: 0.7207, F1 Macro: 0.6572, Accuracy: 0.7207\n","Epoch 25, Train Loss: 0.5431, Val Loss: 0.5461, F1 Micro: 0.6983, F1 Macro: 0.6557, Accuracy: 0.6983\n","Epoch 26, Train Loss: 0.5485, Val Loss: 0.5478, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 27, Train Loss: 0.5445, Val Loss: 0.5395, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 28, Train Loss: 0.5471, Val Loss: 0.6071, F1 Micro: 0.7263, F1 Macro: 0.6489, Accuracy: 0.7263\n","Epoch 29, Train Loss: 0.5496, Val Loss: 0.5204, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 30, Train Loss: 0.5724, Val Loss: 0.5439, F1 Micro: 0.7039, F1 Macro: 0.6300, Accuracy: 0.7039\n","Epoch 31, Train Loss: 0.5424, Val Loss: 0.5651, F1 Micro: 0.7263, F1 Macro: 0.6390, Accuracy: 0.7263\n","Epoch 32, Train Loss: 0.5382, Val Loss: 0.5469, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 33, Train Loss: 0.5405, Val Loss: 0.5631, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 34, Train Loss: 0.5377, Val Loss: 0.5707, F1 Micro: 0.7207, F1 Macro: 0.6343, Accuracy: 0.7207\n","Epoch 35, Train Loss: 0.5413, Val Loss: 0.5360, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 36, Train Loss: 0.5439, Val Loss: 0.5439, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 37, Train Loss: 0.5316, Val Loss: 0.5469, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 38, Train Loss: 0.5380, Val Loss: 0.5397, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 39, Train Loss: 0.5491, Val Loss: 0.5530, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 40, Train Loss: 0.5525, Val Loss: 0.5478, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 41, Train Loss: 0.5550, Val Loss: 0.5605, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 42, Train Loss: 0.5414, Val Loss: 0.5329, F1 Micro: 0.6816, F1 Macro: 0.6115, Accuracy: 0.6816\n","Epoch 43, Train Loss: 0.5586, Val Loss: 0.5639, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 44, Train Loss: 0.5424, Val Loss: 0.5623, F1 Micro: 0.6983, F1 Macro: 0.6105, Accuracy: 0.6983\n","Epoch 45, Train Loss: 0.5448, Val Loss: 0.5535, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 46, Train Loss: 0.5395, Val Loss: 0.5452, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 47, Train Loss: 0.5490, Val Loss: 0.5618, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 48, Train Loss: 0.5405, Val Loss: 0.5302, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 49, Train Loss: 0.5461, Val Loss: 0.5515, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 50, Train Loss: 0.5513, Val Loss: 0.6434, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 51, Train Loss: 0.5539, Val Loss: 0.5935, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 52, Train Loss: 0.5704, Val Loss: 0.5926, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 53, Train Loss: 0.5431, Val Loss: 0.5340, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 54, Train Loss: 0.5340, Val Loss: 0.5775, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 55, Train Loss: 0.5489, Val Loss: 0.5445, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 56, Train Loss: 0.5418, Val Loss: 0.5713, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 57, Train Loss: 0.5429, Val Loss: 0.5589, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 58, Train Loss: 0.5484, Val Loss: 0.5510, F1 Micro: 0.7095, F1 Macro: 0.6249, Accuracy: 0.7095\n","Epoch 59, Train Loss: 0.5372, Val Loss: 0.5710, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 60, Train Loss: 0.5410, Val Loss: 0.6107, F1 Micro: 0.6983, F1 Macro: 0.6420, Accuracy: 0.6983\n","Epoch 61, Train Loss: 0.5667, Val Loss: 0.5512, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 62, Train Loss: 0.5440, Val Loss: 0.5943, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 63, Train Loss: 0.5472, Val Loss: 0.5676, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.9038, Val Loss: 0.7377, F1 Micro: 0.6573, F1 Macro: 0.4392, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.7775, Val Loss: 0.6841, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.7190, Val Loss: 0.6903, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 4, Train Loss: 0.6975, Val Loss: 0.6903, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.6927, Val Loss: 0.6908, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.6924, Val Loss: 0.6909, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 7, Train Loss: 0.7011, Val Loss: 0.6905, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.6930, Val Loss: 0.6907, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 9, Train Loss: 0.6930, Val Loss: 0.6903, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 10, Train Loss: 0.6936, Val Loss: 0.6906, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 11, Train Loss: 0.6930, Val Loss: 0.6907, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6930, Val Loss: 0.6912, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 13, Train Loss: 0.6931, Val Loss: 0.6913, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 14, Train Loss: 0.6931, Val Loss: 0.6916, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.6934, Val Loss: 0.6917, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 16, Train Loss: 0.6932, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 18, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 19, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 20, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 21, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 22, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 23, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 24, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 25, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 26, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 27, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 28, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 29, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 30, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 31, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 32, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 34, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 35, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 36, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 37, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 38, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 39, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 40, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 41, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 42, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 43, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 44, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 45, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 46, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 47, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 48, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 49, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 50, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 51, Train Loss: 0.6931, Val Loss: 0.6925, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.9108, Val Loss: 0.7052, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.7028, Val Loss: 0.6957, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6970, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6471, Val Loss: 0.6659, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 2, Train Loss: 0.5573, Val Loss: 0.6550, F1 Micro: 0.6011, F1 Macro: 0.5205, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.5529, Val Loss: 0.6547, F1 Micro: 0.5787, F1 Macro: 0.5305, Accuracy: 0.5787\n","Epoch 4, Train Loss: 0.5552, Val Loss: 0.6544, F1 Micro: 0.6011, F1 Macro: 0.5257, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.5577, Val Loss: 0.6515, F1 Micro: 0.6067, F1 Macro: 0.5246, Accuracy: 0.6067\n","Epoch 6, Train Loss: 0.5431, Val Loss: 0.6805, F1 Micro: 0.6011, F1 Macro: 0.5205, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.5613, Val Loss: 0.6598, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.5860, Val Loss: 0.6412, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.5655, Val Loss: 0.6426, F1 Micro: 0.5955, F1 Macro: 0.5215, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.5609, Val Loss: 0.6417, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.5502, Val Loss: 0.6566, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.5655, Val Loss: 0.6333, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 13, Train Loss: 0.5581, Val Loss: 0.6160, F1 Micro: 0.6011, F1 Macro: 0.5257, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.5553, Val Loss: 0.6373, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 15, Train Loss: 0.5580, Val Loss: 0.6172, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 16, Train Loss: 0.5513, Val Loss: 0.6708, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 17, Train Loss: 0.5567, Val Loss: 0.6557, F1 Micro: 0.5843, F1 Macro: 0.5386, Accuracy: 0.5843\n","Epoch 18, Train Loss: 0.5430, Val Loss: 0.6406, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 19, Train Loss: 0.5327, Val Loss: 0.6240, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 20, Train Loss: 0.5764, Val Loss: 0.6115, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.5398, Val Loss: 0.6444, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.5251, Val Loss: 0.6070, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.5425, Val Loss: 0.6492, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 24, Train Loss: 0.5468, Val Loss: 0.7009, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 25, Train Loss: 0.5463, Val Loss: 0.6172, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 26, Train Loss: 0.5487, Val Loss: 0.6224, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 27, Train Loss: 0.5453, Val Loss: 0.6496, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 28, Train Loss: 0.5441, Val Loss: 0.7841, F1 Micro: 0.5955, F1 Macro: 0.4931, Accuracy: 0.5955\n","Epoch 29, Train Loss: 0.5766, Val Loss: 0.7486, F1 Micro: 0.6011, F1 Macro: 0.5257, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.5387, Val Loss: 0.6339, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.5399, Val Loss: 0.6645, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.5330, Val Loss: 0.6174, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 33, Train Loss: 0.5415, Val Loss: 0.6294, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 34, Train Loss: 0.5298, Val Loss: 0.6851, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 35, Train Loss: 0.5392, Val Loss: 0.6046, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.5316, Val Loss: 0.5935, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 37, Train Loss: 0.5216, Val Loss: 0.5996, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 38, Train Loss: 0.5342, Val Loss: 0.6089, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 39, Train Loss: 0.5233, Val Loss: 0.6217, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 40, Train Loss: 0.5463, Val Loss: 0.6111, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.5342, Val Loss: 0.6178, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 42, Train Loss: 0.5570, Val Loss: 0.6002, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 43, Train Loss: 0.5438, Val Loss: 0.5938, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 44, Train Loss: 0.5550, Val Loss: 0.6268, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 45, Train Loss: 0.5332, Val Loss: 0.6173, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 46, Train Loss: 0.5393, Val Loss: 0.6135, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 47, Train Loss: 0.5527, Val Loss: 0.6102, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 48, Train Loss: 0.5514, Val Loss: 0.6313, F1 Micro: 0.5955, F1 Macro: 0.5215, Accuracy: 0.5955\n","Epoch 49, Train Loss: 0.5290, Val Loss: 0.6066, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 50, Train Loss: 0.5312, Val Loss: 0.6378, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 51, Train Loss: 0.5687, Val Loss: 0.6298, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 52, Train Loss: 0.5438, Val Loss: 0.6080, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 53, Train Loss: 0.5501, Val Loss: 0.6294, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 54, Train Loss: 0.5427, Val Loss: 0.6286, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 55, Train Loss: 0.5244, Val Loss: 0.6474, F1 Micro: 0.5955, F1 Macro: 0.5578, Accuracy: 0.5955\n","Epoch 56, Train Loss: 0.5501, Val Loss: 0.6445, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 57, Train Loss: 0.5317, Val Loss: 0.6075, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 58, Train Loss: 0.5437, Val Loss: 0.6078, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 59, Train Loss: 0.5326, Val Loss: 0.6048, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 60, Train Loss: 0.5202, Val Loss: 0.6194, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 61, Train Loss: 0.5309, Val Loss: 0.6198, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 62, Train Loss: 0.5266, Val Loss: 0.5937, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 63, Train Loss: 0.5484, Val Loss: 0.6092, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 64, Train Loss: 0.5409, Val Loss: 0.6033, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 65, Train Loss: 0.5585, Val Loss: 0.5896, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 66, Train Loss: 0.5536, Val Loss: 0.5972, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 67, Train Loss: 0.5235, Val Loss: 0.6323, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 68, Train Loss: 0.5405, Val Loss: 0.7880, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 69, Train Loss: 0.5274, Val Loss: 0.6684, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 70, Train Loss: 0.5259, Val Loss: 0.6052, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 71, Train Loss: 0.5358, Val Loss: 0.5893, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 72, Train Loss: 0.5449, Val Loss: 0.6136, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 73, Train Loss: 0.5292, Val Loss: 0.6048, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 74, Train Loss: 0.5555, Val Loss: 0.6264, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 75, Train Loss: 0.5528, Val Loss: 0.5985, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 76, Train Loss: 0.5269, Val Loss: 0.5972, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 77, Train Loss: 0.5367, Val Loss: 0.6343, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 78, Train Loss: 0.5295, Val Loss: 0.5948, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 79, Train Loss: 0.5368, Val Loss: 0.6108, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 80, Train Loss: 0.5461, Val Loss: 0.6051, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 81, Train Loss: 0.5448, Val Loss: 0.6045, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 82, Train Loss: 0.5381, Val Loss: 0.6226, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 83, Train Loss: 0.5591, Val Loss: 0.5911, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 84, Train Loss: 0.5291, Val Loss: 0.6884, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 85, Train Loss: 0.5453, Val Loss: 0.6004, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 86, Train Loss: 0.5418, Val Loss: 0.5859, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 87, Train Loss: 0.5404, Val Loss: 0.6055, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 88, Train Loss: 0.5305, Val Loss: 0.6134, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 89, Train Loss: 0.5266, Val Loss: 0.6248, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 90, Train Loss: 0.5441, Val Loss: 0.5997, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 91, Train Loss: 0.5277, Val Loss: 0.5939, F1 Micro: 0.6067, F1 Macro: 0.5524, Accuracy: 0.6067\n","Epoch 92, Train Loss: 0.5429, Val Loss: 0.6131, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 93, Train Loss: 0.5275, Val Loss: 0.5944, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 94, Train Loss: 0.5197, Val Loss: 0.6163, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 95, Train Loss: 0.5408, Val Loss: 0.6526, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 96, Train Loss: 0.5144, Val Loss: 0.6346, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 97, Train Loss: 0.5241, Val Loss: 0.6452, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 98, Train Loss: 0.5323, Val Loss: 0.6506, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 99, Train Loss: 0.5291, Val Loss: 0.6638, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 100, Train Loss: 0.5408, Val Loss: 0.5953, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 101, Train Loss: 0.5311, Val Loss: 0.6314, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 102, Train Loss: 0.5470, Val Loss: 0.6530, F1 Micro: 0.6067, F1 Macro: 0.5246, Accuracy: 0.6067\n","Epoch 103, Train Loss: 0.5324, Val Loss: 0.6280, F1 Micro: 0.6067, F1 Macro: 0.5600, Accuracy: 0.6067\n","Epoch 104, Train Loss: 0.5253, Val Loss: 0.6696, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 105, Train Loss: 0.5323, Val Loss: 0.6989, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 106, Train Loss: 0.5325, Val Loss: 0.5977, F1 Micro: 0.6124, F1 Macro: 0.5484, Accuracy: 0.6124\n","Epoch 107, Train Loss: 0.5321, Val Loss: 0.6213, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 108, Train Loss: 0.5263, Val Loss: 0.6238, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 109, Train Loss: 0.5483, Val Loss: 0.5881, F1 Micro: 0.6236, F1 Macro: 0.5570, Accuracy: 0.6236\n","Epoch 110, Train Loss: 0.5469, Val Loss: 0.5937, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 111, Train Loss: 0.5449, Val Loss: 0.5971, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 112, Train Loss: 0.5388, Val Loss: 0.6033, F1 Micro: 0.6180, F1 Macro: 0.5571, Accuracy: 0.6180\n","Epoch 113, Train Loss: 0.5370, Val Loss: 0.5975, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 114, Train Loss: 0.5317, Val Loss: 0.6754, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 115, Train Loss: 0.5380, Val Loss: 0.6232, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 116, Train Loss: 0.5354, Val Loss: 0.5991, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 117, Train Loss: 0.5314, Val Loss: 0.6310, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 118, Train Loss: 0.5425, Val Loss: 0.6242, F1 Micro: 0.5955, F1 Macro: 0.5511, Accuracy: 0.5955\n","Epoch 119, Train Loss: 0.5322, Val Loss: 0.5901, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 120, Train Loss: 0.5258, Val Loss: 0.6432, F1 Micro: 0.5899, F1 Macro: 0.5532, Accuracy: 0.5899\n","Epoch 121, Train Loss: 0.5589, Val Loss: 0.6180, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 122, Train Loss: 0.5520, Val Loss: 0.6011, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 123, Train Loss: 0.5547, Val Loss: 0.6039, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 124, Train Loss: 0.5246, Val Loss: 0.6153, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 125, Train Loss: 0.5347, Val Loss: 0.6067, F1 Micro: 0.6124, F1 Macro: 0.5390, Accuracy: 0.6124\n","Epoch 126, Train Loss: 0.5349, Val Loss: 0.6218, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 127, Train Loss: 0.5283, Val Loss: 0.6408, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 128, Train Loss: 0.5254, Val Loss: 0.6925, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 129, Train Loss: 0.5163, Val Loss: 0.5906, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Epoch 130, Train Loss: 0.5317, Val Loss: 0.6044, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 131, Train Loss: 0.5314, Val Loss: 0.6821, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 132, Train Loss: 0.5405, Val Loss: 0.6175, F1 Micro: 0.6180, F1 Macro: 0.5432, Accuracy: 0.6180\n","Epoch 133, Train Loss: 0.5353, Val Loss: 0.5988, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 134, Train Loss: 0.5326, Val Loss: 0.5856, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 135, Train Loss: 0.5286, Val Loss: 0.6099, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 136, Train Loss: 0.5391, Val Loss: 0.6042, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.6878, Val Loss: 0.6061, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 2, Train Loss: 0.6386, Val Loss: 0.6290, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.6240, Val Loss: 0.5836, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 4, Train Loss: 0.6242, Val Loss: 0.5896, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 5, Train Loss: 0.6105, Val Loss: 0.6019, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6224, Val Loss: 0.6145, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 7, Train Loss: 0.6322, Val Loss: 0.6012, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6198, Val Loss: 0.5856, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 9, Train Loss: 0.6174, Val Loss: 0.5934, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 10, Train Loss: 0.6156, Val Loss: 0.5870, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 11, Train Loss: 0.6188, Val Loss: 0.5780, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.6306, Val Loss: 0.5776, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.6215, Val Loss: 0.5794, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 14, Train Loss: 0.6109, Val Loss: 0.6063, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.6265, Val Loss: 0.6053, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 16, Train Loss: 0.6384, Val Loss: 0.5809, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.6290, Val Loss: 0.5824, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 18, Train Loss: 0.6213, Val Loss: 0.5793, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.6187, Val Loss: 0.5736, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 20, Train Loss: 0.6137, Val Loss: 0.5745, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 21, Train Loss: 0.6183, Val Loss: 0.5986, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.6099, Val Loss: 0.5925, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 23, Train Loss: 0.6194, Val Loss: 0.5891, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 24, Train Loss: 0.6193, Val Loss: 0.5756, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.6119, Val Loss: 0.5872, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 26, Train Loss: 0.6303, Val Loss: 0.5727, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.6212, Val Loss: 0.5940, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 28, Train Loss: 0.6426, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 29, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 31, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 32, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 33, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 34, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 35, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 36, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 38, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 40, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 41, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 44, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 47, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 48, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 49, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Epoch 51, Train Loss: 0.6931, Val Loss: 0.6931, F1 Micro: 0.6011, F1 Macro: 0.3754, Accuracy: 0.6011\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 8, 50): 0.6497269474609253\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.6359, Val Loss: 0.5450, F1 Micro: 0.6983, F1 Macro: 0.5800, Accuracy: 0.6983\n","Epoch 2, Train Loss: 0.5434, Val Loss: 0.5679, F1 Micro: 0.6927, F1 Macro: 0.6207, Accuracy: 0.6927\n","Epoch 3, Train Loss: 0.5515, Val Loss: 0.5332, F1 Micro: 0.7095, F1 Macro: 0.6082, Accuracy: 0.7095\n","Epoch 4, Train Loss: 0.5492, Val Loss: 0.5320, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 5, Train Loss: 0.5393, Val Loss: 0.5526, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 6, Train Loss: 0.5608, Val Loss: 0.5398, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 7, Train Loss: 0.5432, Val Loss: 0.5236, F1 Micro: 0.7039, F1 Macro: 0.6095, Accuracy: 0.7039\n","Epoch 8, Train Loss: 0.5410, Val Loss: 0.5421, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 9, Train Loss: 0.5365, Val Loss: 0.5373, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 10, Train Loss: 0.5363, Val Loss: 0.5148, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 11, Train Loss: 0.5413, Val Loss: 0.5351, F1 Micro: 0.7151, F1 Macro: 0.6187, Accuracy: 0.7151\n","Epoch 12, Train Loss: 0.5412, Val Loss: 0.5215, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 13, Train Loss: 0.5425, Val Loss: 0.5250, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 14, Train Loss: 0.5457, Val Loss: 0.5302, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 15, Train Loss: 0.5440, Val Loss: 0.5210, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 16, Train Loss: 0.5432, Val Loss: 0.5274, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 17, Train Loss: 0.5655, Val Loss: 0.5476, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 18, Train Loss: 0.5436, Val Loss: 0.5529, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 19, Train Loss: 0.5727, Val Loss: 0.5846, F1 Micro: 0.7263, F1 Macro: 0.6280, Accuracy: 0.7263\n","Epoch 20, Train Loss: 0.5691, Val Loss: 0.5423, F1 Micro: 0.7151, F1 Macro: 0.6187, Accuracy: 0.7151\n","Epoch 21, Train Loss: 0.5396, Val Loss: 0.5230, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 22, Train Loss: 0.5376, Val Loss: 0.5290, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 23, Train Loss: 0.5337, Val Loss: 0.5373, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 24, Train Loss: 0.5351, Val Loss: 0.5491, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.0537, Val Loss: 0.6306, F1 Micro: 0.7247, F1 Macro: 0.6726, Accuracy: 0.7247\n","Epoch 2, Train Loss: 0.5746, Val Loss: 0.5982, F1 Micro: 0.7809, F1 Macro: 0.7162, Accuracy: 0.7809\n","Epoch 3, Train Loss: 0.5879, Val Loss: 0.5947, F1 Micro: 0.7472, F1 Macro: 0.7025, Accuracy: 0.7472\n","Epoch 4, Train Loss: 0.5758, Val Loss: 0.6440, F1 Micro: 0.5730, F1 Macro: 0.5728, Accuracy: 0.5730\n","Epoch 5, Train Loss: 0.5864, Val Loss: 0.5943, F1 Micro: 0.7753, F1 Macro: 0.7525, Accuracy: 0.7753\n","Epoch 6, Train Loss: 0.5889, Val Loss: 0.5875, F1 Micro: 0.7472, F1 Macro: 0.7299, Accuracy: 0.7472\n","Epoch 7, Train Loss: 0.5858, Val Loss: 0.6276, F1 Micro: 0.7753, F1 Macro: 0.7283, Accuracy: 0.7753\n","Epoch 8, Train Loss: 0.5989, Val Loss: 0.6412, F1 Micro: 0.7584, F1 Macro: 0.7213, Accuracy: 0.7584\n","Epoch 9, Train Loss: 0.6015, Val Loss: 0.6011, F1 Micro: 0.7640, F1 Macro: 0.7420, Accuracy: 0.7640\n","Epoch 10, Train Loss: 0.5980, Val Loss: 0.5955, F1 Micro: 0.7640, F1 Macro: 0.7455, Accuracy: 0.7640\n","Epoch 11, Train Loss: 0.5811, Val Loss: 0.6091, F1 Micro: 0.7753, F1 Macro: 0.7560, Accuracy: 0.7753\n","Epoch 12, Train Loss: 0.5746, Val Loss: 0.6427, F1 Micro: 0.5674, F1 Macro: 0.5673, Accuracy: 0.5674\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.2465, Val Loss: 0.7064, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 2, Train Loss: 0.7336, Val Loss: 0.6729, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 3, Train Loss: 0.7020, Val Loss: 0.6645, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.6960, Val Loss: 0.6645, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.6933, Val Loss: 0.6647, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.6931, Val Loss: 0.6648, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.6931, Val Loss: 0.6648, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 8, Train Loss: 0.6931, Val Loss: 0.6648, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.6931, Val Loss: 0.6648, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.6931, Val Loss: 0.6648, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.6931, Val Loss: 0.6648, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.7389, Val Loss: 0.7017, F1 Micro: 0.5730, F1 Macro: 0.4895, Accuracy: 0.5730\n","Epoch 2, Train Loss: 0.5862, Val Loss: 0.6866, F1 Micro: 0.5674, F1 Macro: 0.4799, Accuracy: 0.5674\n","Epoch 3, Train Loss: 0.5660, Val Loss: 0.7138, F1 Micro: 0.5787, F1 Macro: 0.4935, Accuracy: 0.5787\n","Epoch 4, Train Loss: 0.5586, Val Loss: 0.7199, F1 Micro: 0.5730, F1 Macro: 0.4838, Accuracy: 0.5730\n","Epoch 5, Train Loss: 0.5531, Val Loss: 0.7069, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 6, Train Loss: 0.5561, Val Loss: 0.6617, F1 Micro: 0.5843, F1 Macro: 0.5029, Accuracy: 0.5843\n","Epoch 7, Train Loss: 0.5626, Val Loss: 0.6587, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 8, Train Loss: 0.5467, Val Loss: 0.6986, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 9, Train Loss: 0.5561, Val Loss: 0.6644, F1 Micro: 0.5787, F1 Macro: 0.4877, Accuracy: 0.5787\n","Epoch 10, Train Loss: 0.5521, Val Loss: 0.6873, F1 Micro: 0.5955, F1 Macro: 0.5215, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.5397, Val Loss: 0.6445, F1 Micro: 0.6011, F1 Macro: 0.5353, Accuracy: 0.6011\n","Epoch 12, Train Loss: 0.5403, Val Loss: 0.6410, F1 Micro: 0.6011, F1 Macro: 0.5353, Accuracy: 0.6011\n","Epoch 13, Train Loss: 0.5304, Val Loss: 0.6419, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 14, Train Loss: 0.5327, Val Loss: 0.6118, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.5338, Val Loss: 0.6099, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.5330, Val Loss: 0.6220, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 17, Train Loss: 0.5297, Val Loss: 0.6380, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.5340, Val Loss: 0.6224, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.5322, Val Loss: 0.6059, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 20, Train Loss: 0.5308, Val Loss: 0.6284, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 21, Train Loss: 0.5373, Val Loss: 0.6146, F1 Micro: 0.6011, F1 Macro: 0.5257, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.5305, Val Loss: 0.6374, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 23, Train Loss: 0.5420, Val Loss: 0.6179, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.2030, Val Loss: 0.8533, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.7723, Val Loss: 0.7726, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.7274, Val Loss: 0.7455, F1 Micro: 0.6404, F1 Macro: 0.5094, Accuracy: 0.6404\n","Epoch 4, Train Loss: 0.7038, Val Loss: 0.7220, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6956, Val Loss: 0.7214, F1 Micro: 0.6011, F1 Macro: 0.4225, Accuracy: 0.6011\n","Epoch 6, Train Loss: 0.6936, Val Loss: 0.7145, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Epoch 7, Train Loss: 0.6918, Val Loss: 0.7206, F1 Micro: 0.6011, F1 Macro: 0.4003, Accuracy: 0.6011\n","Epoch 8, Train Loss: 0.6906, Val Loss: 0.7270, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 9, Train Loss: 0.6909, Val Loss: 0.7343, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 10, Train Loss: 0.6904, Val Loss: 0.7303, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 11, Train Loss: 0.6904, Val Loss: 0.7265, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 12, Train Loss: 0.6902, Val Loss: 0.7337, F1 Micro: 0.5955, F1 Macro: 0.3859, Accuracy: 0.5955\n","Epoch 13, Train Loss: 0.6902, Val Loss: 0.7324, F1 Micro: 0.6067, F1 Macro: 0.4145, Accuracy: 0.6067\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 10): 0.6767120708053481\n","Inner FOLD 0\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.1178, Val Loss: 0.6191, F1 Micro: 0.6480, F1 Macro: 0.6314, Accuracy: 0.6480\n","Epoch 2, Train Loss: 0.5917, Val Loss: 0.5539, F1 Micro: 0.7151, F1 Macro: 0.6066, Accuracy: 0.7151\n","Epoch 3, Train Loss: 0.5738, Val Loss: 0.5544, F1 Micro: 0.6872, F1 Macro: 0.5961, Accuracy: 0.6872\n","Epoch 4, Train Loss: 0.5612, Val Loss: 0.5398, F1 Micro: 0.6927, F1 Macro: 0.5824, Accuracy: 0.6927\n","Epoch 5, Train Loss: 0.5533, Val Loss: 0.5633, F1 Micro: 0.7095, F1 Macro: 0.5956, Accuracy: 0.7095\n","Epoch 6, Train Loss: 0.5657, Val Loss: 0.5399, F1 Micro: 0.6983, F1 Macro: 0.5932, Accuracy: 0.6983\n","Epoch 7, Train Loss: 0.5560, Val Loss: 0.5332, F1 Micro: 0.6704, F1 Macro: 0.5828, Accuracy: 0.6704\n","Epoch 8, Train Loss: 0.5471, Val Loss: 0.5319, F1 Micro: 0.7039, F1 Macro: 0.5912, Accuracy: 0.7039\n","Epoch 9, Train Loss: 0.5449, Val Loss: 0.5396, F1 Micro: 0.7095, F1 Macro: 0.6021, Accuracy: 0.7095\n","Epoch 10, Train Loss: 0.5577, Val Loss: 0.5177, F1 Micro: 0.6983, F1 Macro: 0.5932, Accuracy: 0.6983\n","Epoch 11, Train Loss: 0.5569, Val Loss: 0.5225, F1 Micro: 0.6983, F1 Macro: 0.5993, Accuracy: 0.6983\n","Epoch 12, Train Loss: 0.5534, Val Loss: 0.5178, F1 Micro: 0.7039, F1 Macro: 0.6151, Accuracy: 0.7039\n","Epoch 13, Train Loss: 0.5576, Val Loss: 0.5133, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 14, Train Loss: 0.5474, Val Loss: 0.5464, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 15, Train Loss: 0.5403, Val Loss: 0.5240, F1 Micro: 0.6983, F1 Macro: 0.6050, Accuracy: 0.6983\n","Epoch 16, Train Loss: 0.5421, Val Loss: 0.5288, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 17, Train Loss: 0.5393, Val Loss: 0.5344, F1 Micro: 0.7039, F1 Macro: 0.6037, Accuracy: 0.7039\n","Epoch 18, Train Loss: 0.5445, Val Loss: 0.5242, F1 Micro: 0.7039, F1 Macro: 0.6203, Accuracy: 0.7039\n","Epoch 19, Train Loss: 0.5408, Val Loss: 0.5289, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 20, Train Loss: 0.5369, Val Loss: 0.5466, F1 Micro: 0.7263, F1 Macro: 0.6280, Accuracy: 0.7263\n","Epoch 21, Train Loss: 0.5559, Val Loss: 0.5291, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 22, Train Loss: 0.5409, Val Loss: 0.5285, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 23, Train Loss: 0.5369, Val Loss: 0.5384, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 24, Train Loss: 0.5330, Val Loss: 0.5416, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 25, Train Loss: 0.5419, Val Loss: 0.5396, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 26, Train Loss: 0.5372, Val Loss: 0.5337, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 27, Train Loss: 0.5352, Val Loss: 0.5422, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 28, Train Loss: 0.5334, Val Loss: 0.5246, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 29, Train Loss: 0.5354, Val Loss: 0.5395, F1 Micro: 0.7151, F1 Macro: 0.6128, Accuracy: 0.7151\n","Epoch 30, Train Loss: 0.5418, Val Loss: 0.5363, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 31, Train Loss: 0.5371, Val Loss: 0.5470, F1 Micro: 0.7207, F1 Macro: 0.6343, Accuracy: 0.7207\n","Epoch 32, Train Loss: 0.5357, Val Loss: 0.5258, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 33, Train Loss: 0.5343, Val Loss: 0.5190, F1 Micro: 0.7095, F1 Macro: 0.6249, Accuracy: 0.7095\n","Epoch 34, Train Loss: 0.5379, Val Loss: 0.5531, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 35, Train Loss: 0.5506, Val Loss: 0.5303, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 36, Train Loss: 0.5359, Val Loss: 0.5502, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 37, Train Loss: 0.5393, Val Loss: 0.5373, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 38, Train Loss: 0.5422, Val Loss: 0.5343, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 39, Train Loss: 0.5375, Val Loss: 0.5497, F1 Micro: 0.6927, F1 Macro: 0.6111, Accuracy: 0.6927\n","Epoch 40, Train Loss: 0.5413, Val Loss: 0.5378, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 41, Train Loss: 0.5367, Val Loss: 0.5263, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 42, Train Loss: 0.5312, Val Loss: 0.5593, F1 Micro: 0.7095, F1 Macro: 0.6196, Accuracy: 0.7095\n","Epoch 43, Train Loss: 0.5462, Val Loss: 0.5338, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 44, Train Loss: 0.5346, Val Loss: 0.5443, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 45, Train Loss: 0.5398, Val Loss: 0.5394, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 46, Train Loss: 0.5402, Val Loss: 0.5594, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 47, Train Loss: 0.5381, Val Loss: 0.5451, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 48, Train Loss: 0.5333, Val Loss: 0.5293, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 49, Train Loss: 0.5323, Val Loss: 0.5327, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 50, Train Loss: 0.5307, Val Loss: 0.5361, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 51, Train Loss: 0.5342, Val Loss: 0.5393, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 52, Train Loss: 0.5381, Val Loss: 0.5391, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 53, Train Loss: 0.5412, Val Loss: 0.5406, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 54, Train Loss: 0.5429, Val Loss: 0.5260, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 55, Train Loss: 0.5382, Val Loss: 0.5268, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 56, Train Loss: 0.5333, Val Loss: 0.5718, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 57, Train Loss: 0.5517, Val Loss: 0.5385, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 58, Train Loss: 0.5435, Val Loss: 0.5477, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 59, Train Loss: 0.5284, Val Loss: 0.5408, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 60, Train Loss: 0.5551, Val Loss: 0.5300, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 61, Train Loss: 0.5331, Val Loss: 0.5450, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 62, Train Loss: 0.5444, Val Loss: 0.5356, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 63, Train Loss: 0.5273, Val Loss: 0.5319, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 64, Train Loss: 0.5357, Val Loss: 0.5355, F1 Micro: 0.7207, F1 Macro: 0.6289, Accuracy: 0.7207\n","Epoch 65, Train Loss: 0.5411, Val Loss: 0.5360, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 66, Train Loss: 0.5379, Val Loss: 0.5501, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 67, Train Loss: 0.5344, Val Loss: 0.5562, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 68, Train Loss: 0.5501, Val Loss: 0.5289, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 69, Train Loss: 0.5366, Val Loss: 0.5314, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 70, Train Loss: 0.5326, Val Loss: 0.5488, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 71, Train Loss: 0.5411, Val Loss: 0.5532, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 72, Train Loss: 0.5376, Val Loss: 0.5200, F1 Micro: 0.7095, F1 Macro: 0.6347, Accuracy: 0.7095\n","Epoch 73, Train Loss: 0.5339, Val Loss: 0.5444, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 74, Train Loss: 0.5428, Val Loss: 0.5643, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 75, Train Loss: 0.5358, Val Loss: 0.5233, F1 Micro: 0.6872, F1 Macro: 0.6287, Accuracy: 0.6872\n","Epoch 76, Train Loss: 0.5357, Val Loss: 0.5299, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 77, Train Loss: 0.5371, Val Loss: 0.5252, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 78, Train Loss: 0.5356, Val Loss: 0.5581, F1 Micro: 0.7318, F1 Macro: 0.6384, Accuracy: 0.7318\n","Epoch 79, Train Loss: 0.5420, Val Loss: 0.5256, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 80, Train Loss: 0.5364, Val Loss: 0.5340, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 81, Train Loss: 0.5384, Val Loss: 0.5466, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 82, Train Loss: 0.5340, Val Loss: 0.5565, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 83, Train Loss: 0.5357, Val Loss: 0.5324, F1 Micro: 0.7151, F1 Macro: 0.6243, Accuracy: 0.7151\n","Epoch 84, Train Loss: 0.5314, Val Loss: 0.5363, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6709, Val Loss: 0.6263, F1 Micro: 0.6404, F1 Macro: 0.3904, Accuracy: 0.6404\n","Epoch 2, Train Loss: 0.5862, Val Loss: 0.5282, F1 Micro: 0.7079, F1 Macro: 0.5949, Accuracy: 0.7079\n","Epoch 3, Train Loss: 0.5687, Val Loss: 0.5550, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 4, Train Loss: 0.5650, Val Loss: 0.5941, F1 Micro: 0.6966, F1 Macro: 0.5394, Accuracy: 0.6966\n","Epoch 5, Train Loss: 0.5624, Val Loss: 0.5252, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 6, Train Loss: 0.5555, Val Loss: 0.5815, F1 Micro: 0.7022, F1 Macro: 0.5609, Accuracy: 0.7022\n","Epoch 7, Train Loss: 0.5688, Val Loss: 0.5615, F1 Micro: 0.7247, F1 Macro: 0.6572, Accuracy: 0.7247\n","Epoch 8, Train Loss: 0.5554, Val Loss: 0.5461, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 9, Train Loss: 0.5535, Val Loss: 0.5558, F1 Micro: 0.7472, F1 Macro: 0.6629, Accuracy: 0.7472\n","Epoch 10, Train Loss: 0.5735, Val Loss: 0.5298, F1 Micro: 0.7640, F1 Macro: 0.6922, Accuracy: 0.7640\n","Epoch 11, Train Loss: 0.5547, Val Loss: 0.5708, F1 Micro: 0.7584, F1 Macro: 0.6729, Accuracy: 0.7584\n","Epoch 12, Train Loss: 0.5644, Val Loss: 0.5599, F1 Micro: 0.7528, F1 Macro: 0.6728, Accuracy: 0.7528\n","Epoch 13, Train Loss: 0.5491, Val Loss: 0.5461, F1 Micro: 0.7640, F1 Macro: 0.6922, Accuracy: 0.7640\n","Epoch 14, Train Loss: 0.5568, Val Loss: 0.5611, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 15, Train Loss: 0.5534, Val Loss: 0.5393, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 16, Train Loss: 0.5537, Val Loss: 0.5327, F1 Micro: 0.7640, F1 Macro: 0.6964, Accuracy: 0.7640\n","Epoch 17, Train Loss: 0.5554, Val Loss: 0.5704, F1 Micro: 0.7640, F1 Macro: 0.6964, Accuracy: 0.7640\n","Epoch 18, Train Loss: 0.5559, Val Loss: 0.5590, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 19, Train Loss: 0.5422, Val Loss: 0.5262, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 20, Train Loss: 0.5511, Val Loss: 0.5618, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 21, Train Loss: 0.5466, Val Loss: 0.5390, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 22, Train Loss: 0.5477, Val Loss: 0.5338, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 23, Train Loss: 0.5479, Val Loss: 0.5640, F1 Micro: 0.7584, F1 Macro: 0.6779, Accuracy: 0.7584\n","Epoch 24, Train Loss: 0.5373, Val Loss: 0.5242, F1 Micro: 0.7640, F1 Macro: 0.6964, Accuracy: 0.7640\n","Epoch 25, Train Loss: 0.5513, Val Loss: 0.5783, F1 Micro: 0.7584, F1 Macro: 0.6729, Accuracy: 0.7584\n","Epoch 26, Train Loss: 0.5611, Val Loss: 0.5485, F1 Micro: 0.7472, F1 Macro: 0.6852, Accuracy: 0.7472\n","Epoch 27, Train Loss: 0.5476, Val Loss: 0.5252, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 28, Train Loss: 0.5469, Val Loss: 0.5694, F1 Micro: 0.7584, F1 Macro: 0.6729, Accuracy: 0.7584\n","Epoch 29, Train Loss: 0.5551, Val Loss: 0.5210, F1 Micro: 0.7640, F1 Macro: 0.6964, Accuracy: 0.7640\n","Epoch 30, Train Loss: 0.5495, Val Loss: 0.5511, F1 Micro: 0.7528, F1 Macro: 0.6728, Accuracy: 0.7528\n","Epoch 31, Train Loss: 0.5616, Val Loss: 0.5497, F1 Micro: 0.7528, F1 Macro: 0.6728, Accuracy: 0.7528\n","Epoch 32, Train Loss: 0.5479, Val Loss: 0.5124, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 33, Train Loss: 0.5444, Val Loss: 0.5605, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 34, Train Loss: 0.5474, Val Loss: 0.5276, F1 Micro: 0.7753, F1 Macro: 0.7184, Accuracy: 0.7753\n","Epoch 35, Train Loss: 0.5474, Val Loss: 0.5442, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 36, Train Loss: 0.5505, Val Loss: 0.5315, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 37, Train Loss: 0.5405, Val Loss: 0.5258, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 38, Train Loss: 0.5496, Val Loss: 0.5093, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 39, Train Loss: 0.5505, Val Loss: 0.5142, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 40, Train Loss: 0.5632, Val Loss: 0.5177, F1 Micro: 0.7753, F1 Macro: 0.7184, Accuracy: 0.7753\n","Epoch 41, Train Loss: 0.5436, Val Loss: 0.5195, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 42, Train Loss: 0.5385, Val Loss: 0.5243, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 43, Train Loss: 0.5461, Val Loss: 0.5344, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 44, Train Loss: 0.5411, Val Loss: 0.5624, F1 Micro: 0.7247, F1 Macro: 0.6793, Accuracy: 0.7247\n","Epoch 45, Train Loss: 0.5534, Val Loss: 0.5276, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 46, Train Loss: 0.5500, Val Loss: 0.5135, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 47, Train Loss: 0.5427, Val Loss: 0.5093, F1 Micro: 0.7809, F1 Macro: 0.7237, Accuracy: 0.7809\n","Epoch 48, Train Loss: 0.5547, Val Loss: 0.5438, F1 Micro: 0.7528, F1 Macro: 0.6977, Accuracy: 0.7528\n","Epoch 49, Train Loss: 0.5619, Val Loss: 0.5158, F1 Micro: 0.7753, F1 Macro: 0.7219, Accuracy: 0.7753\n","Epoch 50, Train Loss: 0.5396, Val Loss: 0.5726, F1 Micro: 0.7584, F1 Macro: 0.6729, Accuracy: 0.7584\n","Epoch 51, Train Loss: 0.5484, Val Loss: 0.5401, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 52, Train Loss: 0.5464, Val Loss: 0.5254, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 53, Train Loss: 0.5467, Val Loss: 0.5080, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 54, Train Loss: 0.5486, Val Loss: 0.5232, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 55, Train Loss: 0.5435, Val Loss: 0.5191, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 56, Train Loss: 0.5415, Val Loss: 0.5189, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 57, Train Loss: 0.5472, Val Loss: 0.5006, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 58, Train Loss: 0.5414, Val Loss: 0.5478, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 59, Train Loss: 0.5490, Val Loss: 0.5101, F1 Micro: 0.7809, F1 Macro: 0.7237, Accuracy: 0.7809\n","Epoch 60, Train Loss: 0.5507, Val Loss: 0.5445, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 61, Train Loss: 0.5525, Val Loss: 0.5491, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 62, Train Loss: 0.5554, Val Loss: 0.4989, F1 Micro: 0.7640, F1 Macro: 0.6964, Accuracy: 0.7640\n","Epoch 63, Train Loss: 0.5623, Val Loss: 0.5190, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 64, Train Loss: 0.5504, Val Loss: 0.5330, F1 Micro: 0.7528, F1 Macro: 0.6728, Accuracy: 0.7528\n","Epoch 65, Train Loss: 0.5479, Val Loss: 0.5169, F1 Micro: 0.7753, F1 Macro: 0.7147, Accuracy: 0.7753\n","Epoch 66, Train Loss: 0.5543, Val Loss: 0.5304, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 67, Train Loss: 0.5677, Val Loss: 0.5217, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Epoch 68, Train Loss: 0.5372, Val Loss: 0.5239, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 69, Train Loss: 0.5441, Val Loss: 0.5193, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 70, Train Loss: 0.5545, Val Loss: 0.5257, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 71, Train Loss: 0.5479, Val Loss: 0.5253, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 72, Train Loss: 0.5380, Val Loss: 0.5307, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 73, Train Loss: 0.5641, Val Loss: 0.5532, F1 Micro: 0.7584, F1 Macro: 0.6992, Accuracy: 0.7584\n","Epoch 74, Train Loss: 0.5547, Val Loss: 0.5635, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 75, Train Loss: 0.5521, Val Loss: 0.5144, F1 Micro: 0.7640, F1 Macro: 0.7080, Accuracy: 0.7640\n","Epoch 76, Train Loss: 0.5469, Val Loss: 0.5602, F1 Micro: 0.7584, F1 Macro: 0.6779, Accuracy: 0.7584\n","Epoch 77, Train Loss: 0.5608, Val Loss: 0.5383, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 78, Train Loss: 0.5463, Val Loss: 0.5205, F1 Micro: 0.7697, F1 Macro: 0.7057, Accuracy: 0.7697\n","Epoch 79, Train Loss: 0.5392, Val Loss: 0.5309, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 80, Train Loss: 0.5637, Val Loss: 0.5069, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 81, Train Loss: 0.5623, Val Loss: 0.5258, F1 Micro: 0.7753, F1 Macro: 0.7147, Accuracy: 0.7753\n","Epoch 82, Train Loss: 0.5503, Val Loss: 0.5341, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 83, Train Loss: 0.5427, Val Loss: 0.5401, F1 Micro: 0.7584, F1 Macro: 0.7063, Accuracy: 0.7584\n","Epoch 84, Train Loss: 0.5458, Val Loss: 0.5827, F1 Micro: 0.7528, F1 Macro: 0.6627, Accuracy: 0.7528\n","Epoch 85, Train Loss: 0.5508, Val Loss: 0.5107, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 86, Train Loss: 0.5531, Val Loss: 0.5151, F1 Micro: 0.7640, F1 Macro: 0.6964, Accuracy: 0.7640\n","Epoch 87, Train Loss: 0.5366, Val Loss: 0.5354, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 88, Train Loss: 0.5391, Val Loss: 0.5380, F1 Micro: 0.7584, F1 Macro: 0.7028, Accuracy: 0.7584\n","Epoch 89, Train Loss: 0.5452, Val Loss: 0.5463, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 90, Train Loss: 0.5581, Val Loss: 0.5225, F1 Micro: 0.7697, F1 Macro: 0.7057, Accuracy: 0.7697\n","Epoch 91, Train Loss: 0.5439, Val Loss: 0.5188, F1 Micro: 0.7640, F1 Macro: 0.7147, Accuracy: 0.7640\n","Epoch 92, Train Loss: 0.5511, Val Loss: 0.5753, F1 Micro: 0.7528, F1 Macro: 0.6627, Accuracy: 0.7528\n","Epoch 93, Train Loss: 0.5412, Val Loss: 0.5044, F1 Micro: 0.7697, F1 Macro: 0.7166, Accuracy: 0.7697\n","Epoch 94, Train Loss: 0.5429, Val Loss: 0.5436, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 95, Train Loss: 0.5503, Val Loss: 0.5253, F1 Micro: 0.7640, F1 Macro: 0.7043, Accuracy: 0.7640\n","Epoch 96, Train Loss: 0.5542, Val Loss: 0.5568, F1 Micro: 0.7584, F1 Macro: 0.6953, Accuracy: 0.7584\n","Epoch 97, Train Loss: 0.5517, Val Loss: 0.5346, F1 Micro: 0.7640, F1 Macro: 0.7114, Accuracy: 0.7640\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.8673, Val Loss: 0.7677, F1 Micro: 0.6798, F1 Macro: 0.5445, Accuracy: 0.6798\n","Epoch 2, Train Loss: 0.5607, Val Loss: 0.6651, F1 Micro: 0.5955, F1 Macro: 0.5164, Accuracy: 0.5955\n","Epoch 3, Train Loss: 0.5660, Val Loss: 0.6431, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 4, Train Loss: 0.5721, Val Loss: 0.6124, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 5, Train Loss: 0.5551, Val Loss: 0.6022, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.5568, Val Loss: 0.6743, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.5630, Val Loss: 0.5871, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 8, Train Loss: 0.5644, Val Loss: 0.6556, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.5562, Val Loss: 0.6828, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.5693, Val Loss: 0.6932, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.5655, Val Loss: 0.5978, F1 Micro: 0.6573, F1 Macro: 0.5125, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.5561, Val Loss: 0.6138, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.5642, Val Loss: 0.5935, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.5528, Val Loss: 0.6083, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.5554, Val Loss: 0.5961, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 16, Train Loss: 0.5618, Val Loss: 0.6096, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 17, Train Loss: 0.5529, Val Loss: 0.5802, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 18, Train Loss: 0.5630, Val Loss: 0.6026, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 19, Train Loss: 0.5539, Val Loss: 0.6017, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 20, Train Loss: 0.5658, Val Loss: 0.6076, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 21, Train Loss: 0.5536, Val Loss: 0.5602, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 22, Train Loss: 0.5554, Val Loss: 0.5867, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 23, Train Loss: 0.5511, Val Loss: 0.5544, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 24, Train Loss: 0.5561, Val Loss: 0.6482, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 25, Train Loss: 0.5505, Val Loss: 0.6085, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 26, Train Loss: 0.5543, Val Loss: 0.5604, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 27, Train Loss: 0.5474, Val Loss: 0.6413, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 28, Train Loss: 0.5518, Val Loss: 0.5922, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.5580, Val Loss: 0.6022, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.5476, Val Loss: 0.5801, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 31, Train Loss: 0.5451, Val Loss: 0.5443, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 32, Train Loss: 0.5540, Val Loss: 0.6670, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 33, Train Loss: 0.5446, Val Loss: 0.6103, F1 Micro: 0.6461, F1 Macro: 0.5593, Accuracy: 0.6461\n","Epoch 34, Train Loss: 0.5553, Val Loss: 0.6153, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.5514, Val Loss: 0.6109, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 36, Train Loss: 0.5472, Val Loss: 0.5970, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 37, Train Loss: 0.5437, Val Loss: 0.5842, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 38, Train Loss: 0.5451, Val Loss: 0.5727, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 39, Train Loss: 0.5409, Val Loss: 0.5467, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 40, Train Loss: 0.5533, Val Loss: 0.6125, F1 Micro: 0.6910, F1 Macro: 0.5880, Accuracy: 0.6910\n","Epoch 41, Train Loss: 0.5430, Val Loss: 0.6051, F1 Micro: 0.6910, F1 Macro: 0.5880, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.5370, Val Loss: 0.5397, F1 Micro: 0.6629, F1 Macro: 0.5776, Accuracy: 0.6629\n","Epoch 43, Train Loss: 0.5509, Val Loss: 0.6482, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 44, Train Loss: 0.5499, Val Loss: 0.6056, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 45, Train Loss: 0.5403, Val Loss: 0.5625, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.5434, Val Loss: 0.6168, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 47, Train Loss: 0.5461, Val Loss: 0.5529, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 48, Train Loss: 0.5361, Val Loss: 0.5504, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 49, Train Loss: 0.5369, Val Loss: 0.5313, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 50, Train Loss: 0.5393, Val Loss: 0.7258, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 51, Train Loss: 0.5383, Val Loss: 0.5655, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 52, Train Loss: 0.5327, Val Loss: 0.5598, F1 Micro: 0.6404, F1 Macro: 0.5603, Accuracy: 0.6404\n","Epoch 53, Train Loss: 0.5403, Val Loss: 0.5648, F1 Micro: 0.6685, F1 Macro: 0.5441, Accuracy: 0.6685\n","Epoch 54, Train Loss: 0.5465, Val Loss: 0.5912, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 55, Train Loss: 0.5465, Val Loss: 0.5562, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 56, Train Loss: 0.5375, Val Loss: 0.6138, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 57, Train Loss: 0.5382, Val Loss: 0.5455, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 58, Train Loss: 0.5422, Val Loss: 0.6206, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 59, Train Loss: 0.5368, Val Loss: 0.5583, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 60, Train Loss: 0.5390, Val Loss: 0.5385, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 61, Train Loss: 0.5359, Val Loss: 0.5537, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 62, Train Loss: 0.5385, Val Loss: 0.5723, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 63, Train Loss: 0.5494, Val Loss: 0.5371, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 64, Train Loss: 0.5338, Val Loss: 0.5590, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.5401, Val Loss: 0.5769, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 66, Train Loss: 0.5457, Val Loss: 0.6124, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 67, Train Loss: 0.5428, Val Loss: 0.5670, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 68, Train Loss: 0.5413, Val Loss: 0.5653, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 69, Train Loss: 0.5477, Val Loss: 0.5682, F1 Micro: 0.6742, F1 Macro: 0.5554, Accuracy: 0.6742\n","Epoch 70, Train Loss: 0.5344, Val Loss: 0.5527, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 71, Train Loss: 0.5462, Val Loss: 0.5547, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 72, Train Loss: 0.5525, Val Loss: 0.5193, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 73, Train Loss: 0.5554, Val Loss: 0.5448, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 74, Train Loss: 0.5403, Val Loss: 0.6694, F1 Micro: 0.6742, F1 Macro: 0.5405, Accuracy: 0.6742\n","Epoch 75, Train Loss: 0.5442, Val Loss: 0.5857, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 76, Train Loss: 0.5425, Val Loss: 0.6305, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.5373, Val Loss: 0.5565, F1 Micro: 0.6629, F1 Macro: 0.5721, Accuracy: 0.6629\n","Epoch 78, Train Loss: 0.5508, Val Loss: 0.5650, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 79, Train Loss: 0.5515, Val Loss: 0.5797, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.5326, Val Loss: 0.5362, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 81, Train Loss: 0.5421, Val Loss: 0.5515, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 82, Train Loss: 0.5389, Val Loss: 0.5273, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 83, Train Loss: 0.5551, Val Loss: 0.5887, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 84, Train Loss: 0.5442, Val Loss: 0.5339, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 85, Train Loss: 0.5445, Val Loss: 0.5609, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 86, Train Loss: 0.5396, Val Loss: 0.5378, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 87, Train Loss: 0.5464, Val Loss: 0.5216, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 88, Train Loss: 0.5484, Val Loss: 0.5165, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 89, Train Loss: 0.5379, Val Loss: 0.5237, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Epoch 90, Train Loss: 0.5294, Val Loss: 0.5237, F1 Micro: 0.6854, F1 Macro: 0.5773, Accuracy: 0.6854\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.4495, Val Loss: 0.7493, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.6323, Val Loss: 0.6346, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.5887, Val Loss: 0.6313, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 4, Train Loss: 0.5875, Val Loss: 0.6878, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 5, Train Loss: 0.5805, Val Loss: 0.6418, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 6, Train Loss: 0.5863, Val Loss: 0.6370, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 7, Train Loss: 0.5897, Val Loss: 0.6362, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 8, Train Loss: 0.5930, Val Loss: 0.6489, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.5832, Val Loss: 0.6387, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 10, Train Loss: 0.5805, Val Loss: 0.6422, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 11, Train Loss: 0.5869, Val Loss: 0.6392, F1 Micro: 0.5281, F1 Macro: 0.3561, Accuracy: 0.5281\n","Epoch 12, Train Loss: 0.5909, Val Loss: 0.7199, F1 Micro: 0.5506, F1 Macro: 0.4052, Accuracy: 0.5506\n","Epoch 13, Train Loss: 0.5767, Val Loss: 0.6338, F1 Micro: 0.5843, F1 Macro: 0.5082, Accuracy: 0.5843\n","Epoch 14, Train Loss: 0.5431, Val Loss: 0.6250, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 15, Train Loss: 0.5200, Val Loss: 0.6670, F1 Micro: 0.5730, F1 Macro: 0.5479, Accuracy: 0.5730\n","Epoch 16, Train Loss: 0.5407, Val Loss: 0.6748, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Epoch 17, Train Loss: 0.5235, Val Loss: 0.6162, F1 Micro: 0.6067, F1 Macro: 0.5348, Accuracy: 0.6067\n","Epoch 18, Train Loss: 0.5285, Val Loss: 0.6398, F1 Micro: 0.6011, F1 Macro: 0.5257, Accuracy: 0.6011\n","Epoch 19, Train Loss: 0.5297, Val Loss: 0.6606, F1 Micro: 0.5899, F1 Macro: 0.5466, Accuracy: 0.5899\n","Epoch 20, Train Loss: 0.5264, Val Loss: 0.6325, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 21, Train Loss: 0.5204, Val Loss: 0.6350, F1 Micro: 0.6011, F1 Macro: 0.5306, Accuracy: 0.6011\n","Epoch 22, Train Loss: 0.5371, Val Loss: 0.6084, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 23, Train Loss: 0.5269, Val Loss: 0.6185, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 24, Train Loss: 0.5226, Val Loss: 0.6104, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 25, Train Loss: 0.5407, Val Loss: 0.6288, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 26, Train Loss: 0.5280, Val Loss: 0.6569, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 27, Train Loss: 0.5291, Val Loss: 0.6874, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 28, Train Loss: 0.5339, Val Loss: 0.6271, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 29, Train Loss: 0.5358, Val Loss: 0.6421, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 30, Train Loss: 0.5225, Val Loss: 0.6109, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 31, Train Loss: 0.5266, Val Loss: 0.6166, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 32, Train Loss: 0.5304, Val Loss: 0.6134, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 33, Train Loss: 0.5266, Val Loss: 0.5917, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 34, Train Loss: 0.5412, Val Loss: 0.6185, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 35, Train Loss: 0.5160, Val Loss: 0.6334, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 36, Train Loss: 0.5380, Val Loss: 0.6081, F1 Micro: 0.6011, F1 Macro: 0.5440, Accuracy: 0.6011\n","Epoch 37, Train Loss: 0.5349, Val Loss: 0.6059, F1 Micro: 0.6067, F1 Macro: 0.5563, Accuracy: 0.6067\n","Epoch 38, Train Loss: 0.5266, Val Loss: 0.6235, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 39, Train Loss: 0.5200, Val Loss: 0.6275, F1 Micro: 0.6124, F1 Macro: 0.5645, Accuracy: 0.6124\n","Epoch 40, Train Loss: 0.5330, Val Loss: 0.6143, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 41, Train Loss: 0.5198, Val Loss: 0.6023, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 42, Train Loss: 0.5227, Val Loss: 0.6152, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 43, Train Loss: 0.5181, Val Loss: 0.5944, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 44, Train Loss: 0.5254, Val Loss: 0.6245, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 45, Train Loss: 0.5254, Val Loss: 0.5897, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 46, Train Loss: 0.5248, Val Loss: 0.6032, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 47, Train Loss: 0.5195, Val Loss: 0.5904, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 48, Train Loss: 0.5334, Val Loss: 0.5893, F1 Micro: 0.6180, F1 Macro: 0.5527, Accuracy: 0.6180\n","Epoch 49, Train Loss: 0.5250, Val Loss: 0.6694, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 50, Train Loss: 0.5298, Val Loss: 0.6468, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 51, Train Loss: 0.5405, Val Loss: 0.5949, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 52, Train Loss: 0.5311, Val Loss: 0.6072, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 53, Train Loss: 0.5227, Val Loss: 0.5960, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 54, Train Loss: 0.5292, Val Loss: 0.6162, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 55, Train Loss: 0.5351, Val Loss: 0.5957, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 56, Train Loss: 0.5347, Val Loss: 0.6188, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 57, Train Loss: 0.5205, Val Loss: 0.5951, F1 Micro: 0.5955, F1 Macro: 0.5475, Accuracy: 0.5955\n","Epoch 58, Train Loss: 0.5332, Val Loss: 0.5921, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 59, Train Loss: 0.5532, Val Loss: 0.6437, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 60, Train Loss: 0.5258, Val Loss: 0.6089, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 61, Train Loss: 0.5202, Val Loss: 0.5969, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 62, Train Loss: 0.5155, Val Loss: 0.6543, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 63, Train Loss: 0.5225, Val Loss: 0.6104, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 64, Train Loss: 0.5227, Val Loss: 0.5965, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 65, Train Loss: 0.5247, Val Loss: 0.5947, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 66, Train Loss: 0.5179, Val Loss: 0.6083, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 67, Train Loss: 0.5242, Val Loss: 0.6117, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 68, Train Loss: 0.5310, Val Loss: 0.5896, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 69, Train Loss: 0.5178, Val Loss: 0.6552, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 70, Train Loss: 0.5235, Val Loss: 0.5989, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 71, Train Loss: 0.5173, Val Loss: 0.6167, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 72, Train Loss: 0.5167, Val Loss: 0.6120, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 73, Train Loss: 0.5292, Val Loss: 0.6193, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 74, Train Loss: 0.5290, Val Loss: 0.6273, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 75, Train Loss: 0.5252, Val Loss: 0.5994, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 76, Train Loss: 0.5274, Val Loss: 0.6433, F1 Micro: 0.5899, F1 Macro: 0.5312, Accuracy: 0.5899\n","Epoch 77, Train Loss: 0.5374, Val Loss: 0.5959, F1 Micro: 0.6011, F1 Macro: 0.5398, Accuracy: 0.6011\n","Epoch 78, Train Loss: 0.5238, Val Loss: 0.6033, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 79, Train Loss: 0.5329, Val Loss: 0.6150, F1 Micro: 0.6011, F1 Macro: 0.5480, Accuracy: 0.6011\n","Epoch 80, Train Loss: 0.5322, Val Loss: 0.6061, F1 Micro: 0.6124, F1 Macro: 0.5527, Accuracy: 0.6124\n","Epoch 81, Train Loss: 0.5328, Val Loss: 0.6071, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 82, Train Loss: 0.5243, Val Loss: 0.5982, F1 Micro: 0.6067, F1 Macro: 0.5484, Accuracy: 0.6067\n","Epoch 83, Train Loss: 0.5209, Val Loss: 0.6306, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 84, Train Loss: 0.5212, Val Loss: 0.6213, F1 Micro: 0.6067, F1 Macro: 0.5669, Accuracy: 0.6067\n","Epoch 85, Train Loss: 0.5275, Val Loss: 0.5966, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 86, Train Loss: 0.5169, Val Loss: 0.6562, F1 Micro: 0.6067, F1 Macro: 0.5298, Accuracy: 0.6067\n","Epoch 87, Train Loss: 0.5267, Val Loss: 0.6434, F1 Micro: 0.6124, F1 Macro: 0.5438, Accuracy: 0.6124\n","Epoch 88, Train Loss: 0.5344, Val Loss: 0.5892, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 89, Train Loss: 0.5364, Val Loss: 0.6070, F1 Micro: 0.5955, F1 Macro: 0.5355, Accuracy: 0.5955\n","Epoch 90, Train Loss: 0.5250, Val Loss: 0.6598, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 91, Train Loss: 0.5283, Val Loss: 0.6066, F1 Micro: 0.6067, F1 Macro: 0.5395, Accuracy: 0.6067\n","Epoch 92, Train Loss: 0.5264, Val Loss: 0.6380, F1 Micro: 0.6124, F1 Macro: 0.5340, Accuracy: 0.6124\n","Epoch 93, Train Loss: 0.5382, Val Loss: 0.6030, F1 Micro: 0.6011, F1 Macro: 0.5555, Accuracy: 0.6011\n","Epoch 94, Train Loss: 0.5307, Val Loss: 0.6116, F1 Micro: 0.5955, F1 Macro: 0.5437, Accuracy: 0.5955\n","Epoch 95, Train Loss: 0.5236, Val Loss: 0.6356, F1 Micro: 0.6067, F1 Macro: 0.5441, Accuracy: 0.6067\n","Epoch 96, Train Loss: 0.5205, Val Loss: 0.5926, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Epoch 97, Train Loss: 0.5271, Val Loss: 0.6201, F1 Micro: 0.6011, F1 Macro: 0.5519, Accuracy: 0.6011\n","Epoch 98, Train Loss: 0.5205, Val Loss: 0.6131, F1 Micro: 0.5955, F1 Macro: 0.5397, Accuracy: 0.5955\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.01, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 2.2534, Val Loss: 1.6432, F1 Micro: 0.5899, F1 Macro: 0.4893, Accuracy: 0.5899\n","Epoch 2, Train Loss: 0.8428, Val Loss: 0.5990, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.5965, Val Loss: 0.5873, F1 Micro: 0.6461, F1 Macro: 0.5208, Accuracy: 0.6461\n","Epoch 4, Train Loss: 0.5942, Val Loss: 0.6002, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.5861, Val Loss: 0.5713, F1 Micro: 0.6404, F1 Macro: 0.5170, Accuracy: 0.6404\n","Epoch 6, Train Loss: 0.5867, Val Loss: 0.5711, F1 Micro: 0.6461, F1 Macro: 0.5477, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.5769, Val Loss: 0.5663, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 8, Train Loss: 0.5703, Val Loss: 0.5638, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.5727, Val Loss: 0.5438, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.5739, Val Loss: 0.5545, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.5755, Val Loss: 0.5586, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.5979, Val Loss: 0.5519, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 13, Train Loss: 0.5613, Val Loss: 0.5372, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.5820, Val Loss: 0.5399, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 15, Train Loss: 0.5812, Val Loss: 0.5296, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 16, Train Loss: 0.5790, Val Loss: 0.5704, F1 Micro: 0.6404, F1 Macro: 0.5494, Accuracy: 0.6404\n","Epoch 17, Train Loss: 0.5679, Val Loss: 0.5291, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 18, Train Loss: 0.5631, Val Loss: 0.5421, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.5769, Val Loss: 0.5402, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 20, Train Loss: 0.5753, Val Loss: 0.5341, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 21, Train Loss: 0.5684, Val Loss: 0.5269, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 22, Train Loss: 0.5709, Val Loss: 0.5259, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 23, Train Loss: 0.5716, Val Loss: 0.5564, F1 Micro: 0.6461, F1 Macro: 0.5536, Accuracy: 0.6461\n","Epoch 24, Train Loss: 0.5748, Val Loss: 0.5308, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 25, Train Loss: 0.5662, Val Loss: 0.5629, F1 Micro: 0.6573, F1 Macro: 0.5621, Accuracy: 0.6573\n","Epoch 26, Train Loss: 0.5766, Val Loss: 0.5297, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 27, Train Loss: 0.5640, Val Loss: 0.5353, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 28, Train Loss: 0.5717, Val Loss: 0.5324, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 29, Train Loss: 0.5587, Val Loss: 0.5541, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 30, Train Loss: 0.5662, Val Loss: 0.5455, F1 Micro: 0.6517, F1 Macro: 0.5519, Accuracy: 0.6517\n","Epoch 31, Train Loss: 0.5730, Val Loss: 0.5288, F1 Micro: 0.6573, F1 Macro: 0.5561, Accuracy: 0.6573\n","Epoch 32, Train Loss: 0.5665, Val Loss: 0.5720, F1 Micro: 0.6404, F1 Macro: 0.5790, Accuracy: 0.6404\n","Epoch 33, Train Loss: 0.5743, Val Loss: 0.5310, F1 Micro: 0.6685, F1 Macro: 0.5645, Accuracy: 0.6685\n","Epoch 34, Train Loss: 0.5612, Val Loss: 0.5293, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.5647, Val Loss: 0.5388, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 36, Train Loss: 0.5680, Val Loss: 0.5697, F1 Micro: 0.6461, F1 Macro: 0.5835, Accuracy: 0.6461\n","Epoch 37, Train Loss: 0.5886, Val Loss: 0.5207, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 38, Train Loss: 0.5761, Val Loss: 0.5494, F1 Micro: 0.6573, F1 Macro: 0.5732, Accuracy: 0.6573\n","Epoch 39, Train Loss: 0.5610, Val Loss: 0.5308, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 40, Train Loss: 0.5712, Val Loss: 0.5752, F1 Micro: 0.6292, F1 Macro: 0.5780, Accuracy: 0.6292\n","Epoch 41, Train Loss: 0.5676, Val Loss: 0.5280, F1 Micro: 0.6685, F1 Macro: 0.5764, Accuracy: 0.6685\n","Epoch 42, Train Loss: 0.5683, Val Loss: 0.5207, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 43, Train Loss: 0.5615, Val Loss: 0.5537, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 44, Train Loss: 0.5705, Val Loss: 0.5189, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 45, Train Loss: 0.5602, Val Loss: 0.5146, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 46, Train Loss: 0.5674, Val Loss: 0.5240, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 47, Train Loss: 0.5706, Val Loss: 0.5941, F1 Micro: 0.6348, F1 Macro: 0.5825, Accuracy: 0.6348\n","Epoch 48, Train Loss: 0.5722, Val Loss: 0.5996, F1 Micro: 0.6236, F1 Macro: 0.5697, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.5826, Val Loss: 0.5166, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 50, Train Loss: 0.5644, Val Loss: 0.5390, F1 Micro: 0.6629, F1 Macro: 0.6013, Accuracy: 0.6629\n","Epoch 51, Train Loss: 0.5868, Val Loss: 0.5402, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 52, Train Loss: 0.5615, Val Loss: 0.5225, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 53, Train Loss: 0.5777, Val Loss: 0.5341, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 54, Train Loss: 0.5622, Val Loss: 0.5280, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 55, Train Loss: 0.5540, Val Loss: 0.5225, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 56, Train Loss: 0.5777, Val Loss: 0.5196, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.5683, Val Loss: 0.5206, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 58, Train Loss: 0.5597, Val Loss: 0.5324, F1 Micro: 0.6742, F1 Macro: 0.5688, Accuracy: 0.6742\n","Epoch 59, Train Loss: 0.5600, Val Loss: 0.5374, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 60, Train Loss: 0.5671, Val Loss: 0.5252, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 61, Train Loss: 0.5756, Val Loss: 0.5423, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 62, Train Loss: 0.5633, Val Loss: 0.5563, F1 Micro: 0.6685, F1 Macro: 0.6138, Accuracy: 0.6685\n","Epoch 63, Train Loss: 0.5569, Val Loss: 0.5228, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 64, Train Loss: 0.5598, Val Loss: 0.5408, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.5672, Val Loss: 0.5231, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 66, Train Loss: 0.5667, Val Loss: 0.5503, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 67, Train Loss: 0.5604, Val Loss: 0.5162, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 68, Train Loss: 0.5577, Val Loss: 0.5468, F1 Micro: 0.6685, F1 Macro: 0.6015, Accuracy: 0.6685\n","Epoch 69, Train Loss: 0.5698, Val Loss: 0.5486, F1 Micro: 0.6629, F1 Macro: 0.5970, Accuracy: 0.6629\n","Epoch 70, Train Loss: 0.5675, Val Loss: 0.5169, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 71, Train Loss: 0.5758, Val Loss: 0.5350, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 72, Train Loss: 0.5644, Val Loss: 0.5264, F1 Micro: 0.6910, F1 Macro: 0.6152, Accuracy: 0.6910\n","Epoch 73, Train Loss: 0.5617, Val Loss: 0.5375, F1 Micro: 0.6685, F1 Macro: 0.5820, Accuracy: 0.6685\n","Epoch 74, Train Loss: 0.5748, Val Loss: 0.5709, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 75, Train Loss: 0.5628, Val Loss: 0.5203, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 76, Train Loss: 0.5678, Val Loss: 0.5339, F1 Micro: 0.6742, F1 Macro: 0.5749, Accuracy: 0.6742\n","Epoch 77, Train Loss: 0.5625, Val Loss: 0.5571, F1 Micro: 0.6573, F1 Macro: 0.5833, Accuracy: 0.6573\n","Epoch 78, Train Loss: 0.5549, Val Loss: 0.5587, F1 Micro: 0.6517, F1 Macro: 0.5740, Accuracy: 0.6517\n","Epoch 79, Train Loss: 0.5695, Val Loss: 0.5216, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.5658, Val Loss: 0.5364, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 81, Train Loss: 0.5618, Val Loss: 0.5252, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 82, Train Loss: 0.5533, Val Loss: 0.5223, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 83, Train Loss: 0.5499, Val Loss: 0.5480, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 84, Train Loss: 0.5515, Val Loss: 0.5080, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Epoch 85, Train Loss: 0.5471, Val Loss: 0.5251, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 86, Train Loss: 0.5471, Val Loss: 0.5228, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 87, Train Loss: 0.5435, Val Loss: 0.5373, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 88, Train Loss: 0.5421, Val Loss: 0.5429, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 89, Train Loss: 0.5573, Val Loss: 0.5369, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 90, Train Loss: 0.5762, Val Loss: 0.5373, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.5482, Val Loss: 0.5332, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 92, Train Loss: 0.5554, Val Loss: 0.5172, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 93, Train Loss: 0.5456, Val Loss: 0.5068, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Epoch 94, Train Loss: 0.5538, Val Loss: 0.5431, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 95, Train Loss: 0.5468, Val Loss: 0.5075, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 96, Train Loss: 0.5507, Val Loss: 0.5232, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 97, Train Loss: 0.5594, Val Loss: 0.5223, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 98, Train Loss: 0.5623, Val Loss: 0.5193, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 99, Train Loss: 0.5446, Val Loss: 0.5116, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 100, Train Loss: 0.5530, Val Loss: 0.5255, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Epoch 101, Train Loss: 0.5433, Val Loss: 0.5050, F1 Micro: 0.6966, F1 Macro: 0.6042, Accuracy: 0.6966\n","Epoch 102, Train Loss: 0.5442, Val Loss: 0.5357, F1 Micro: 0.6742, F1 Macro: 0.5864, Accuracy: 0.6742\n","Epoch 103, Train Loss: 0.5470, Val Loss: 0.5249, F1 Micro: 0.6685, F1 Macro: 0.5872, Accuracy: 0.6685\n","Epoch 104, Train Loss: 0.5494, Val Loss: 0.5291, F1 Micro: 0.6742, F1 Macro: 0.5917, Accuracy: 0.6742\n","Epoch 105, Train Loss: 0.5496, Val Loss: 0.5452, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 106, Train Loss: 0.5499, Val Loss: 0.5840, F1 Micro: 0.6517, F1 Macro: 0.5835, Accuracy: 0.6517\n","Epoch 107, Train Loss: 0.5533, Val Loss: 0.5209, F1 Micro: 0.6798, F1 Macro: 0.5908, Accuracy: 0.6798\n","Early stopping triggered\n","Average Score for hyperparameters (0.01, 16, 50): 0.7036720858703157\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.8113, Val Loss: 1.5953, F1 Micro: 0.6760, F1 Macro: 0.6113, Accuracy: 0.6760\n","Epoch 2, Train Loss: 1.6471, Val Loss: 1.4641, F1 Micro: 0.6760, F1 Macro: 0.6113, Accuracy: 0.6760\n","Epoch 3, Train Loss: 1.5046, Val Loss: 1.3361, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Epoch 4, Train Loss: 1.3593, Val Loss: 1.2087, F1 Micro: 0.6816, F1 Macro: 0.6279, Accuracy: 0.6816\n","Epoch 5, Train Loss: 1.2232, Val Loss: 1.0903, F1 Micro: 0.6927, F1 Macro: 0.6409, Accuracy: 0.6927\n","Epoch 6, Train Loss: 1.0888, Val Loss: 0.9770, F1 Micro: 0.6872, F1 Macro: 0.6362, Accuracy: 0.6872\n","Epoch 7, Train Loss: 0.9702, Val Loss: 0.8760, F1 Micro: 0.6983, F1 Macro: 0.6492, Accuracy: 0.6983\n","Epoch 8, Train Loss: 0.8623, Val Loss: 0.7913, F1 Micro: 0.6983, F1 Macro: 0.6587, Accuracy: 0.6983\n","Epoch 9, Train Loss: 0.7736, Val Loss: 0.7135, F1 Micro: 0.7039, F1 Macro: 0.6692, Accuracy: 0.7039\n","Epoch 10, Train Loss: 0.6914, Val Loss: 0.6441, F1 Micro: 0.7207, F1 Macro: 0.6938, Accuracy: 0.7207\n","Epoch 11, Train Loss: 0.6319, Val Loss: 0.6054, F1 Micro: 0.7318, F1 Macro: 0.7138, Accuracy: 0.7318\n","Epoch 12, Train Loss: 0.5993, Val Loss: 0.5910, F1 Micro: 0.7207, F1 Macro: 0.7036, Accuracy: 0.7207\n","Epoch 13, Train Loss: 0.5861, Val Loss: 0.5813, F1 Micro: 0.7095, F1 Macro: 0.6917, Accuracy: 0.7095\n","Epoch 14, Train Loss: 0.5810, Val Loss: 0.5814, F1 Micro: 0.6927, F1 Macro: 0.6782, Accuracy: 0.6927\n","Epoch 15, Train Loss: 0.5805, Val Loss: 0.5775, F1 Micro: 0.6927, F1 Macro: 0.6748, Accuracy: 0.6927\n","Epoch 16, Train Loss: 0.5780, Val Loss: 0.5821, F1 Micro: 0.6760, F1 Macro: 0.6598, Accuracy: 0.6760\n","Epoch 17, Train Loss: 0.5774, Val Loss: 0.5800, F1 Micro: 0.6872, F1 Macro: 0.6716, Accuracy: 0.6872\n","Epoch 18, Train Loss: 0.5776, Val Loss: 0.5814, F1 Micro: 0.6816, F1 Macro: 0.6665, Accuracy: 0.6816\n","Epoch 19, Train Loss: 0.5789, Val Loss: 0.5786, F1 Micro: 0.6872, F1 Macro: 0.6716, Accuracy: 0.6872\n","Epoch 20, Train Loss: 0.5763, Val Loss: 0.5770, F1 Micro: 0.7151, F1 Macro: 0.6949, Accuracy: 0.7151\n","Epoch 21, Train Loss: 0.5782, Val Loss: 0.5785, F1 Micro: 0.6872, F1 Macro: 0.6716, Accuracy: 0.6872\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.6915, Val Loss: 0.6880, F1 Micro: 0.6966, F1 Macro: 0.5394, Accuracy: 0.6966\n","Epoch 2, Train Loss: 0.6873, Val Loss: 0.6808, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 3, Train Loss: 0.6862, Val Loss: 0.6809, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 4, Train Loss: 0.6857, Val Loss: 0.6773, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 5, Train Loss: 0.6858, Val Loss: 0.6768, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 6, Train Loss: 0.6852, Val Loss: 0.6767, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 7, Train Loss: 0.6853, Val Loss: 0.6764, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 8, Train Loss: 0.6847, Val Loss: 0.6781, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 9, Train Loss: 0.6844, Val Loss: 0.6784, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.6844, Val Loss: 0.6770, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 11, Train Loss: 0.6839, Val Loss: 0.6769, F1 Micro: 0.7191, F1 Macro: 0.5969, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.6837, Val Loss: 0.6776, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 0.7074, Val Loss: 1.0496, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 2, Train Loss: 0.7034, Val Loss: 1.0236, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 3, Train Loss: 0.6998, Val Loss: 0.9987, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6962, Val Loss: 0.9774, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 5, Train Loss: 0.6943, Val Loss: 0.9668, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.6934, Val Loss: 0.9592, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 7, Train Loss: 0.6926, Val Loss: 0.9505, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 8, Train Loss: 0.6923, Val Loss: 0.9430, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 9, Train Loss: 0.6921, Val Loss: 0.9437, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6919, Val Loss: 0.9398, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6917, Val Loss: 0.9379, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 1.2315, Val Loss: 1.1905, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 2, Train Loss: 1.0632, Val Loss: 1.0763, F1 Micro: 0.6404, F1 Macro: 0.6213, Accuracy: 0.6404\n","Epoch 3, Train Loss: 0.8856, Val Loss: 0.9384, F1 Micro: 0.6517, F1 Macro: 0.6332, Accuracy: 0.6517\n","Epoch 4, Train Loss: 0.7631, Val Loss: 0.8176, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 5, Train Loss: 0.6698, Val Loss: 0.7175, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.5995, Val Loss: 0.6566, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 7, Train Loss: 0.5565, Val Loss: 0.6128, F1 Micro: 0.6573, F1 Macro: 0.6435, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.5407, Val Loss: 0.6175, F1 Micro: 0.6573, F1 Macro: 0.6381, Accuracy: 0.6573\n","Epoch 9, Train Loss: 0.5351, Val Loss: 0.6059, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 10, Train Loss: 0.5268, Val Loss: 0.6001, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 11, Train Loss: 0.5276, Val Loss: 0.5953, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.5255, Val Loss: 0.5920, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.5268, Val Loss: 0.6051, F1 Micro: 0.6573, F1 Macro: 0.6400, Accuracy: 0.6573\n","Epoch 14, Train Loss: 0.5314, Val Loss: 0.6154, F1 Micro: 0.6404, F1 Macro: 0.6147, Accuracy: 0.6404\n","Epoch 15, Train Loss: 0.5240, Val Loss: 0.6188, F1 Micro: 0.6461, F1 Macro: 0.6195, Accuracy: 0.6461\n","Epoch 16, Train Loss: 0.5290, Val Loss: 0.6067, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 17, Train Loss: 0.5229, Val Loss: 0.5964, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Epoch 18, Train Loss: 0.5234, Val Loss: 0.5952, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.5314, Val Loss: 0.6120, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 20, Train Loss: 0.5242, Val Loss: 0.5946, F1 Micro: 0.6629, F1 Macro: 0.6485, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.5283, Val Loss: 0.5944, F1 Micro: 0.6573, F1 Macro: 0.6418, Accuracy: 0.6573\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=10\n","Epoch 1, Train Loss: 5.9362, Val Loss: 4.6839, F1 Micro: 0.3989, F1 Macro: 0.2851, Accuracy: 0.3989\n","Epoch 2, Train Loss: 1.9690, Val Loss: 1.0403, F1 Micro: 0.6011, F1 Macro: 0.5150, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.8199, Val Loss: 0.9115, F1 Micro: 0.5787, F1 Macro: 0.4204, Accuracy: 0.5787\n","Epoch 4, Train Loss: 0.7609, Val Loss: 0.8246, F1 Micro: 0.5787, F1 Macro: 0.4204, Accuracy: 0.5787\n","Epoch 5, Train Loss: 0.7209, Val Loss: 0.7356, F1 Micro: 0.5787, F1 Macro: 0.4204, Accuracy: 0.5787\n","Epoch 6, Train Loss: 0.6736, Val Loss: 0.6548, F1 Micro: 0.5618, F1 Macro: 0.3821, Accuracy: 0.5618\n","Epoch 7, Train Loss: 0.6277, Val Loss: 0.6011, F1 Micro: 0.5955, F1 Macro: 0.4090, Accuracy: 0.5955\n","Epoch 8, Train Loss: 0.6018, Val Loss: 0.5805, F1 Micro: 0.6124, F1 Macro: 0.4172, Accuracy: 0.6124\n","Epoch 9, Train Loss: 0.6014, Val Loss: 0.5729, F1 Micro: 0.6573, F1 Macro: 0.5208, Accuracy: 0.6573\n","Epoch 10, Train Loss: 0.5989, Val Loss: 0.5681, F1 Micro: 0.6292, F1 Macro: 0.4582, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.5963, Val Loss: 0.5649, F1 Micro: 0.6461, F1 Macro: 0.4966, Accuracy: 0.6461\n","Epoch 12, Train Loss: 0.5987, Val Loss: 0.5615, F1 Micro: 0.6742, F1 Macro: 0.5808, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.5915, Val Loss: 0.5598, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 14, Train Loss: 0.5968, Val Loss: 0.5599, F1 Micro: 0.6966, F1 Macro: 0.6097, Accuracy: 0.6966\n","Epoch 15, Train Loss: 0.5968, Val Loss: 0.5561, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 16, Train Loss: 0.5945, Val Loss: 0.5552, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 17, Train Loss: 0.5874, Val Loss: 0.5544, F1 Micro: 0.7191, F1 Macro: 0.6677, Accuracy: 0.7191\n","Epoch 18, Train Loss: 0.5930, Val Loss: 0.5531, F1 Micro: 0.7416, F1 Macro: 0.7109, Accuracy: 0.7416\n","Epoch 19, Train Loss: 0.5913, Val Loss: 0.5541, F1 Micro: 0.7135, F1 Macro: 0.6516, Accuracy: 0.7135\n","Epoch 20, Train Loss: 0.5882, Val Loss: 0.5519, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 21, Train Loss: 0.5922, Val Loss: 0.5517, F1 Micro: 0.7135, F1 Macro: 0.6593, Accuracy: 0.7135\n","Epoch 22, Train Loss: 0.6050, Val Loss: 0.5449, F1 Micro: 0.7697, F1 Macro: 0.7524, Accuracy: 0.7697\n","Epoch 23, Train Loss: 0.5901, Val Loss: 0.5495, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 24, Train Loss: 0.5883, Val Loss: 0.5502, F1 Micro: 0.7528, F1 Macro: 0.7351, Accuracy: 0.7528\n","Epoch 25, Train Loss: 0.5896, Val Loss: 0.5477, F1 Micro: 0.7472, F1 Macro: 0.7110, Accuracy: 0.7472\n","Epoch 26, Train Loss: 0.5927, Val Loss: 0.5486, F1 Micro: 0.7416, F1 Macro: 0.7004, Accuracy: 0.7416\n","Epoch 27, Train Loss: 0.5902, Val Loss: 0.5488, F1 Micro: 0.7360, F1 Macro: 0.6953, Accuracy: 0.7360\n","Epoch 28, Train Loss: 0.5993, Val Loss: 0.5459, F1 Micro: 0.7528, F1 Macro: 0.7234, Accuracy: 0.7528\n","Epoch 29, Train Loss: 0.5858, Val Loss: 0.5437, F1 Micro: 0.7528, F1 Macro: 0.7316, Accuracy: 0.7528\n","Epoch 30, Train Loss: 0.5867, Val Loss: 0.5457, F1 Micro: 0.7416, F1 Macro: 0.7059, Accuracy: 0.7416\n","Epoch 31, Train Loss: 0.5944, Val Loss: 0.5417, F1 Micro: 0.7584, F1 Macro: 0.7419, Accuracy: 0.7584\n","Epoch 32, Train Loss: 0.5838, Val Loss: 0.5418, F1 Micro: 0.7584, F1 Macro: 0.7419, Accuracy: 0.7584\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 10): 0.7014248948590798\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 2.1293, Val Loss: 1.5525, F1 Micro: 0.6313, F1 Macro: 0.5528, Accuracy: 0.6313\n","Epoch 2, Train Loss: 1.7336, Val Loss: 1.2485, F1 Micro: 0.6201, F1 Macro: 0.5538, Accuracy: 0.6201\n","Epoch 3, Train Loss: 1.3221, Val Loss: 0.9848, F1 Micro: 0.6201, F1 Macro: 0.5624, Accuracy: 0.6201\n","Epoch 4, Train Loss: 0.9789, Val Loss: 0.7618, F1 Micro: 0.6425, F1 Macro: 0.5842, Accuracy: 0.6425\n","Epoch 5, Train Loss: 0.7416, Val Loss: 0.6279, F1 Micro: 0.6927, F1 Macro: 0.6294, Accuracy: 0.6927\n","Epoch 6, Train Loss: 0.6253, Val Loss: 0.5873, F1 Micro: 0.7263, F1 Macro: 0.6661, Accuracy: 0.7263\n","Epoch 7, Train Loss: 0.5871, Val Loss: 0.5717, F1 Micro: 0.7374, F1 Macro: 0.6867, Accuracy: 0.7374\n","Epoch 8, Train Loss: 0.5737, Val Loss: 0.5772, F1 Micro: 0.7430, F1 Macro: 0.7183, Accuracy: 0.7430\n","Epoch 9, Train Loss: 0.5705, Val Loss: 0.5632, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 10, Train Loss: 0.5679, Val Loss: 0.5588, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 11, Train Loss: 0.5627, Val Loss: 0.5530, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 12, Train Loss: 0.5643, Val Loss: 0.5517, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 13, Train Loss: 0.5607, Val Loss: 0.5489, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 14, Train Loss: 0.5592, Val Loss: 0.5553, F1 Micro: 0.7430, F1 Macro: 0.7117, Accuracy: 0.7430\n","Epoch 15, Train Loss: 0.5580, Val Loss: 0.5468, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 16, Train Loss: 0.5536, Val Loss: 0.5420, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 17, Train Loss: 0.5520, Val Loss: 0.5411, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 18, Train Loss: 0.5503, Val Loss: 0.5388, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 19, Train Loss: 0.5513, Val Loss: 0.5421, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 20, Train Loss: 0.5481, Val Loss: 0.5318, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 21, Train Loss: 0.5500, Val Loss: 0.5303, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 22, Train Loss: 0.5471, Val Loss: 0.5302, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 23, Train Loss: 0.5469, Val Loss: 0.5373, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 24, Train Loss: 0.5466, Val Loss: 0.5364, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 25, Train Loss: 0.5492, Val Loss: 0.5426, F1 Micro: 0.7430, F1 Macro: 0.7140, Accuracy: 0.7430\n","Epoch 26, Train Loss: 0.5452, Val Loss: 0.5414, F1 Micro: 0.7374, F1 Macro: 0.7066, Accuracy: 0.7374\n","Epoch 27, Train Loss: 0.5486, Val Loss: 0.5326, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 28, Train Loss: 0.5452, Val Loss: 0.5279, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 29, Train Loss: 0.5463, Val Loss: 0.5398, F1 Micro: 0.7318, F1 Macro: 0.6992, Accuracy: 0.7318\n","Epoch 30, Train Loss: 0.5432, Val Loss: 0.5304, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 31, Train Loss: 0.5431, Val Loss: 0.5419, F1 Micro: 0.7430, F1 Macro: 0.7162, Accuracy: 0.7430\n","Epoch 32, Train Loss: 0.5464, Val Loss: 0.5312, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 33, Train Loss: 0.5466, Val Loss: 0.5258, F1 Micro: 0.7039, F1 Macro: 0.6573, Accuracy: 0.7039\n","Epoch 34, Train Loss: 0.5444, Val Loss: 0.5298, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 35, Train Loss: 0.5441, Val Loss: 0.5284, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 36, Train Loss: 0.5439, Val Loss: 0.5308, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 37, Train Loss: 0.5443, Val Loss: 0.5256, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 38, Train Loss: 0.5449, Val Loss: 0.5280, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 39, Train Loss: 0.5441, Val Loss: 0.5295, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 40, Train Loss: 0.5466, Val Loss: 0.5360, F1 Micro: 0.7318, F1 Macro: 0.6992, Accuracy: 0.7318\n","Epoch 41, Train Loss: 0.5436, Val Loss: 0.5271, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 42, Train Loss: 0.5443, Val Loss: 0.5292, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 43, Train Loss: 0.5436, Val Loss: 0.5334, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 44, Train Loss: 0.5445, Val Loss: 0.5303, F1 Micro: 0.7318, F1 Macro: 0.6966, Accuracy: 0.7318\n","Epoch 45, Train Loss: 0.5441, Val Loss: 0.5277, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 46, Train Loss: 0.5437, Val Loss: 0.5242, F1 Micro: 0.7095, F1 Macro: 0.6654, Accuracy: 0.7095\n","Epoch 47, Train Loss: 0.5436, Val Loss: 0.5267, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 48, Train Loss: 0.5441, Val Loss: 0.5290, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 49, Train Loss: 0.5448, Val Loss: 0.5356, F1 Micro: 0.7318, F1 Macro: 0.6992, Accuracy: 0.7318\n","Epoch 50, Train Loss: 0.5455, Val Loss: 0.5283, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 51, Train Loss: 0.5434, Val Loss: 0.5266, F1 Micro: 0.7151, F1 Macro: 0.6733, Accuracy: 0.7151\n","Epoch 52, Train Loss: 0.5448, Val Loss: 0.5290, F1 Micro: 0.7263, F1 Macro: 0.6889, Accuracy: 0.7263\n","Epoch 53, Train Loss: 0.5445, Val Loss: 0.5371, F1 Micro: 0.7318, F1 Macro: 0.7016, Accuracy: 0.7318\n","Epoch 54, Train Loss: 0.5437, Val Loss: 0.5406, F1 Micro: 0.7318, F1 Macro: 0.7082, Accuracy: 0.7318\n","Epoch 55, Train Loss: 0.5438, Val Loss: 0.5279, F1 Micro: 0.7207, F1 Macro: 0.6812, Accuracy: 0.7207\n","Epoch 56, Train Loss: 0.5455, Val Loss: 0.5394, F1 Micro: 0.7318, F1 Macro: 0.7039, Accuracy: 0.7318\n","Epoch 57, Train Loss: 0.5430, Val Loss: 0.5319, F1 Micro: 0.7374, F1 Macro: 0.7042, Accuracy: 0.7374\n","Epoch 58, Train Loss: 0.5469, Val Loss: 0.5355, F1 Micro: 0.7374, F1 Macro: 0.7042, Accuracy: 0.7374\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 4.7057, Val Loss: 3.1916, F1 Micro: 0.3371, F1 Macro: 0.3268, Accuracy: 0.3371\n","Epoch 2, Train Loss: 3.0910, Val Loss: 1.9803, F1 Micro: 0.3876, F1 Macro: 0.3875, Accuracy: 0.3876\n","Epoch 3, Train Loss: 1.9374, Val Loss: 1.3038, F1 Micro: 0.5337, F1 Macro: 0.5150, Accuracy: 0.5337\n","Epoch 4, Train Loss: 1.3532, Val Loss: 1.0103, F1 Micro: 0.6404, F1 Macro: 0.5908, Accuracy: 0.6404\n","Epoch 5, Train Loss: 1.0719, Val Loss: 0.8775, F1 Micro: 0.6685, F1 Macro: 0.6099, Accuracy: 0.6685\n","Epoch 6, Train Loss: 0.9366, Val Loss: 0.8087, F1 Micro: 0.6966, F1 Macro: 0.6198, Accuracy: 0.6966\n","Epoch 7, Train Loss: 0.8616, Val Loss: 0.7639, F1 Micro: 0.7022, F1 Macro: 0.6245, Accuracy: 0.7022\n","Epoch 8, Train Loss: 0.8170, Val Loss: 0.7335, F1 Micro: 0.6966, F1 Macro: 0.6149, Accuracy: 0.6966\n","Epoch 9, Train Loss: 0.7777, Val Loss: 0.6964, F1 Micro: 0.7079, F1 Macro: 0.6134, Accuracy: 0.7079\n","Epoch 10, Train Loss: 0.7046, Val Loss: 0.6663, F1 Micro: 0.6854, F1 Macro: 0.5316, Accuracy: 0.6854\n","Epoch 11, Train Loss: 0.6247, Val Loss: 0.6187, F1 Micro: 0.6573, F1 Macro: 0.4392, Accuracy: 0.6573\n","Epoch 12, Train Loss: 0.6048, Val Loss: 0.5896, F1 Micro: 0.6629, F1 Macro: 0.4665, Accuracy: 0.6629\n","Epoch 13, Train Loss: 0.5910, Val Loss: 0.5758, F1 Micro: 0.6910, F1 Macro: 0.5355, Accuracy: 0.6910\n","Epoch 14, Train Loss: 0.5840, Val Loss: 0.5654, F1 Micro: 0.7022, F1 Macro: 0.5609, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.5771, Val Loss: 0.5597, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 16, Train Loss: 0.5821, Val Loss: 0.5588, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 17, Train Loss: 0.5763, Val Loss: 0.5615, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 18, Train Loss: 0.5771, Val Loss: 0.5597, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 19, Train Loss: 0.5717, Val Loss: 0.5594, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 20, Train Loss: 0.5699, Val Loss: 0.5592, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 21, Train Loss: 0.5747, Val Loss: 0.5571, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 22, Train Loss: 0.5672, Val Loss: 0.5601, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 23, Train Loss: 0.5653, Val Loss: 0.5599, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 24, Train Loss: 0.5621, Val Loss: 0.5572, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 25, Train Loss: 0.5659, Val Loss: 0.5649, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 26, Train Loss: 0.5708, Val Loss: 0.5590, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 27, Train Loss: 0.5604, Val Loss: 0.5596, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 28, Train Loss: 0.5737, Val Loss: 0.5583, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 29, Train Loss: 0.5602, Val Loss: 0.5577, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 30, Train Loss: 0.5555, Val Loss: 0.5584, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 31, Train Loss: 0.5676, Val Loss: 0.5545, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 32, Train Loss: 0.5545, Val Loss: 0.5611, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 33, Train Loss: 0.5601, Val Loss: 0.5611, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 34, Train Loss: 0.5591, Val Loss: 0.5561, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 35, Train Loss: 0.5523, Val Loss: 0.5589, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 36, Train Loss: 0.5515, Val Loss: 0.5592, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 37, Train Loss: 0.5538, Val Loss: 0.5600, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 38, Train Loss: 0.5574, Val Loss: 0.5604, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 39, Train Loss: 0.5505, Val Loss: 0.5601, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 40, Train Loss: 0.5568, Val Loss: 0.5575, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 41, Train Loss: 0.5562, Val Loss: 0.5559, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 42, Train Loss: 0.5549, Val Loss: 0.5578, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 43, Train Loss: 0.5731, Val Loss: 0.5564, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 44, Train Loss: 0.5570, Val Loss: 0.5560, F1 Micro: 0.7191, F1 Macro: 0.6105, Accuracy: 0.7191\n","Epoch 45, Train Loss: 0.5544, Val Loss: 0.5583, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 46, Train Loss: 0.5540, Val Loss: 0.5553, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 47, Train Loss: 0.5488, Val Loss: 0.5548, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 48, Train Loss: 0.5533, Val Loss: 0.5523, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 49, Train Loss: 0.5539, Val Loss: 0.5544, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 50, Train Loss: 0.5455, Val Loss: 0.5561, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 51, Train Loss: 0.5506, Val Loss: 0.5581, F1 Micro: 0.7247, F1 Macro: 0.6214, Accuracy: 0.7247\n","Epoch 52, Train Loss: 0.5625, Val Loss: 0.5541, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 53, Train Loss: 0.5581, Val Loss: 0.5557, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 54, Train Loss: 0.5477, Val Loss: 0.5480, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 55, Train Loss: 0.5450, Val Loss: 0.5509, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 56, Train Loss: 0.5517, Val Loss: 0.5482, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 57, Train Loss: 0.5486, Val Loss: 0.5483, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 58, Train Loss: 0.5510, Val Loss: 0.5410, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 59, Train Loss: 0.5458, Val Loss: 0.5457, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 60, Train Loss: 0.5475, Val Loss: 0.5416, F1 Micro: 0.7416, F1 Macro: 0.6528, Accuracy: 0.7416\n","Epoch 61, Train Loss: 0.5481, Val Loss: 0.5373, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 62, Train Loss: 0.5470, Val Loss: 0.5375, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 63, Train Loss: 0.5408, Val Loss: 0.5368, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 64, Train Loss: 0.5574, Val Loss: 0.5350, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 65, Train Loss: 0.5432, Val Loss: 0.5411, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 66, Train Loss: 0.5682, Val Loss: 0.5382, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 67, Train Loss: 0.5516, Val Loss: 0.5355, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 68, Train Loss: 0.5396, Val Loss: 0.5297, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 69, Train Loss: 0.5450, Val Loss: 0.5266, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 70, Train Loss: 0.5467, Val Loss: 0.5308, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 71, Train Loss: 0.5487, Val Loss: 0.5322, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 72, Train Loss: 0.5448, Val Loss: 0.5257, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 73, Train Loss: 0.5412, Val Loss: 0.5275, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 74, Train Loss: 0.5426, Val Loss: 0.5266, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 75, Train Loss: 0.5432, Val Loss: 0.5258, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 76, Train Loss: 0.5381, Val Loss: 0.5302, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 77, Train Loss: 0.5382, Val Loss: 0.5280, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 78, Train Loss: 0.5389, Val Loss: 0.5282, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 79, Train Loss: 0.5431, Val Loss: 0.5297, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 80, Train Loss: 0.5425, Val Loss: 0.5286, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 81, Train Loss: 0.5432, Val Loss: 0.5296, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 82, Train Loss: 0.5442, Val Loss: 0.5331, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 83, Train Loss: 0.5437, Val Loss: 0.5326, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 84, Train Loss: 0.5425, Val Loss: 0.5283, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 85, Train Loss: 0.5480, Val Loss: 0.5299, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 86, Train Loss: 0.5492, Val Loss: 0.5296, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 87, Train Loss: 0.5404, Val Loss: 0.5305, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 88, Train Loss: 0.5458, Val Loss: 0.5303, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 89, Train Loss: 0.5388, Val Loss: 0.5307, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 90, Train Loss: 0.5435, Val Loss: 0.5319, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 91, Train Loss: 0.5468, Val Loss: 0.5337, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 92, Train Loss: 0.5508, Val Loss: 0.5310, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 93, Train Loss: 0.5467, Val Loss: 0.5203, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 94, Train Loss: 0.5434, Val Loss: 0.5277, F1 Micro: 0.7528, F1 Macro: 0.6775, Accuracy: 0.7528\n","Epoch 95, Train Loss: 0.5353, Val Loss: 0.5300, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 96, Train Loss: 0.5443, Val Loss: 0.5345, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 97, Train Loss: 0.5352, Val Loss: 0.5334, F1 Micro: 0.7584, F1 Macro: 0.6826, Accuracy: 0.7584\n","Epoch 98, Train Loss: 0.5430, Val Loss: 0.5274, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 99, Train Loss: 0.5422, Val Loss: 0.5298, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 100, Train Loss: 0.5359, Val Loss: 0.5332, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 101, Train Loss: 0.5424, Val Loss: 0.5330, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 102, Train Loss: 0.5358, Val Loss: 0.5273, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 103, Train Loss: 0.5434, Val Loss: 0.5326, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 104, Train Loss: 0.5438, Val Loss: 0.5288, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 105, Train Loss: 0.5439, Val Loss: 0.5351, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 106, Train Loss: 0.5408, Val Loss: 0.5365, F1 Micro: 0.7472, F1 Macro: 0.6678, Accuracy: 0.7472\n","Epoch 107, Train Loss: 0.5345, Val Loss: 0.5301, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 108, Train Loss: 0.5377, Val Loss: 0.5295, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 109, Train Loss: 0.5423, Val Loss: 0.5302, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 110, Train Loss: 0.5418, Val Loss: 0.5306, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Epoch 111, Train Loss: 0.5403, Val Loss: 0.5267, F1 Micro: 0.7584, F1 Macro: 0.6871, Accuracy: 0.7584\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7421, Val Loss: 1.0874, F1 Micro: 0.6573, F1 Macro: 0.5678, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.7149, Val Loss: 1.0286, F1 Micro: 0.6461, F1 Macro: 0.5415, Accuracy: 0.6461\n","Epoch 3, Train Loss: 0.7063, Val Loss: 0.9896, F1 Micro: 0.6236, F1 Macro: 0.4904, Accuracy: 0.6236\n","Epoch 4, Train Loss: 0.6996, Val Loss: 0.9642, F1 Micro: 0.6124, F1 Macro: 0.4668, Accuracy: 0.6124\n","Epoch 5, Train Loss: 0.6959, Val Loss: 0.9555, F1 Micro: 0.6124, F1 Macro: 0.4580, Accuracy: 0.6124\n","Epoch 6, Train Loss: 0.6924, Val Loss: 0.9438, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 7, Train Loss: 0.6905, Val Loss: 0.9379, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 8, Train Loss: 0.6897, Val Loss: 0.9298, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 9, Train Loss: 0.6889, Val Loss: 0.9290, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.6884, Val Loss: 0.9239, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 11, Train Loss: 0.6882, Val Loss: 0.9181, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 12, Train Loss: 0.6871, Val Loss: 0.9127, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 13, Train Loss: 0.6864, Val Loss: 0.9071, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 14, Train Loss: 0.6858, Val Loss: 0.9023, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 15, Train Loss: 0.6859, Val Loss: 0.8986, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6850, Val Loss: 0.8955, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 17, Train Loss: 0.6846, Val Loss: 0.8937, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 18, Train Loss: 0.6846, Val Loss: 0.8905, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 19, Train Loss: 0.6842, Val Loss: 0.8858, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 20, Train Loss: 0.6840, Val Loss: 0.8906, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6841, Val Loss: 0.8828, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 22, Train Loss: 0.6837, Val Loss: 0.8826, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 23, Train Loss: 0.6835, Val Loss: 0.8788, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 24, Train Loss: 0.6838, Val Loss: 0.8802, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 25, Train Loss: 0.6841, Val Loss: 0.8786, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6833, Val Loss: 0.8777, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6834, Val Loss: 0.8768, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6833, Val Loss: 0.8791, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6837, Val Loss: 0.8762, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6832, Val Loss: 0.8775, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6830, Val Loss: 0.8773, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6830, Val Loss: 0.8767, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6836, Val Loss: 0.8727, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6829, Val Loss: 0.8817, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6779, Val Loss: 0.8779, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6831, Val Loss: 0.8760, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6826, Val Loss: 0.8807, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 38, Train Loss: 0.6832, Val Loss: 0.8781, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 39, Train Loss: 0.6830, Val Loss: 0.8786, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 40, Train Loss: 0.6827, Val Loss: 0.8745, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 41, Train Loss: 0.6825, Val Loss: 0.8677, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 42, Train Loss: 0.6830, Val Loss: 0.8757, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 43, Train Loss: 0.6829, Val Loss: 0.8647, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6827, Val Loss: 0.8717, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6822, Val Loss: 0.8713, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6822, Val Loss: 0.8754, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6823, Val Loss: 0.8754, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6816, Val Loss: 0.8733, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6825, Val Loss: 0.8796, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6822, Val Loss: 0.8703, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6824, Val Loss: 0.8754, F1 Micro: 0.6236, F1 Macro: 0.4646, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 0.7750, Val Loss: 0.8836, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 2, Train Loss: 0.7289, Val Loss: 0.8239, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 3, Train Loss: 0.7133, Val Loss: 0.7886, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 4, Train Loss: 0.7064, Val Loss: 0.7665, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 5, Train Loss: 0.7030, Val Loss: 0.7559, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 6, Train Loss: 0.7012, Val Loss: 0.7463, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 7, Train Loss: 0.7005, Val Loss: 0.7418, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 8, Train Loss: 0.6999, Val Loss: 0.7383, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 9, Train Loss: 0.6994, Val Loss: 0.7352, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 10, Train Loss: 0.6994, Val Loss: 0.7312, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 11, Train Loss: 0.6981, Val Loss: 0.7313, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 12, Train Loss: 0.6980, Val Loss: 0.7273, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 13, Train Loss: 0.6974, Val Loss: 0.7254, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.6973, Val Loss: 0.7254, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 15, Train Loss: 0.6969, Val Loss: 0.7237, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 16, Train Loss: 0.6965, Val Loss: 0.7223, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 17, Train Loss: 0.6962, Val Loss: 0.7204, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 18, Train Loss: 0.6955, Val Loss: 0.7188, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 19, Train Loss: 0.6955, Val Loss: 0.7187, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 20, Train Loss: 0.6949, Val Loss: 0.7163, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 21, Train Loss: 0.6946, Val Loss: 0.7150, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 22, Train Loss: 0.6943, Val Loss: 0.7144, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 23, Train Loss: 0.6941, Val Loss: 0.7113, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 24, Train Loss: 0.6937, Val Loss: 0.7110, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 25, Train Loss: 0.6933, Val Loss: 0.7095, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 26, Train Loss: 0.6930, Val Loss: 0.7090, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 27, Train Loss: 0.6932, Val Loss: 0.7076, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 28, Train Loss: 0.6931, Val Loss: 0.7076, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 29, Train Loss: 0.6923, Val Loss: 0.7066, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 30, Train Loss: 0.6923, Val Loss: 0.7042, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 31, Train Loss: 0.6920, Val Loss: 0.7048, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 32, Train Loss: 0.6916, Val Loss: 0.7033, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 33, Train Loss: 0.6915, Val Loss: 0.7023, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 34, Train Loss: 0.6914, Val Loss: 0.7029, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 35, Train Loss: 0.6913, Val Loss: 0.7017, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 36, Train Loss: 0.6905, Val Loss: 0.7031, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 37, Train Loss: 0.6892, Val Loss: 0.7093, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 38, Train Loss: 0.6876, Val Loss: 0.7097, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 39, Train Loss: 0.6867, Val Loss: 0.7113, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 40, Train Loss: 0.6862, Val Loss: 0.7065, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 41, Train Loss: 0.6857, Val Loss: 0.7063, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 42, Train Loss: 0.6854, Val Loss: 0.7056, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 43, Train Loss: 0.6850, Val Loss: 0.7027, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 44, Train Loss: 0.6850, Val Loss: 0.7012, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 45, Train Loss: 0.6460, Val Loss: 0.6713, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 46, Train Loss: 0.5859, Val Loss: 0.6427, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 47, Train Loss: 0.5842, Val Loss: 0.6391, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 48, Train Loss: 0.5800, Val Loss: 0.6415, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 49, Train Loss: 0.5837, Val Loss: 0.6517, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 50, Train Loss: 0.5844, Val Loss: 0.6496, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Epoch 51, Train Loss: 0.5787, Val Loss: 0.6457, F1 Micro: 0.5225, F1 Macro: 0.3432, Accuracy: 0.5225\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=8, Patience=50\n","Epoch 1, Train Loss: 1.8976, Val Loss: 2.0138, F1 Micro: 0.5843, F1 Macro: 0.5800, Accuracy: 0.5843\n","Epoch 2, Train Loss: 1.2559, Val Loss: 1.3685, F1 Micro: 0.6236, F1 Macro: 0.6066, Accuracy: 0.6236\n","Epoch 3, Train Loss: 1.0021, Val Loss: 1.1166, F1 Micro: 0.6573, F1 Macro: 0.6292, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.8738, Val Loss: 0.9547, F1 Micro: 0.6629, F1 Macro: 0.6197, Accuracy: 0.6629\n","Epoch 5, Train Loss: 0.8083, Val Loss: 0.8301, F1 Micro: 0.6798, F1 Macro: 0.6269, Accuracy: 0.6798\n","Epoch 6, Train Loss: 0.7662, Val Loss: 0.7546, F1 Micro: 0.6685, F1 Macro: 0.5970, Accuracy: 0.6685\n","Epoch 7, Train Loss: 0.7316, Val Loss: 0.7104, F1 Micro: 0.6629, F1 Macro: 0.5828, Accuracy: 0.6629\n","Epoch 8, Train Loss: 0.7197, Val Loss: 0.7011, F1 Micro: 0.6517, F1 Macro: 0.5579, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.7069, Val Loss: 0.6991, F1 Micro: 0.6629, F1 Macro: 0.5663, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.6993, Val Loss: 0.6984, F1 Micro: 0.6517, F1 Macro: 0.5456, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.6957, Val Loss: 0.6981, F1 Micro: 0.6404, F1 Macro: 0.5241, Accuracy: 0.6404\n","Epoch 12, Train Loss: 0.6944, Val Loss: 0.6977, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.6937, Val Loss: 0.6976, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.6908, Val Loss: 0.6976, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.6933, Val Loss: 0.6976, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 16, Train Loss: 0.6929, Val Loss: 0.6977, F1 Micro: 0.6292, F1 Macro: 0.5019, Accuracy: 0.6292\n","Epoch 17, Train Loss: 0.6923, Val Loss: 0.6984, F1 Micro: 0.6348, F1 Macro: 0.5056, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.6920, Val Loss: 0.6983, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 19, Train Loss: 0.6919, Val Loss: 0.6983, F1 Micro: 0.6292, F1 Macro: 0.4941, Accuracy: 0.6292\n","Epoch 20, Train Loss: 0.6916, Val Loss: 0.6979, F1 Micro: 0.6236, F1 Macro: 0.4823, Accuracy: 0.6236\n","Epoch 21, Train Loss: 0.6913, Val Loss: 0.6977, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 22, Train Loss: 0.6912, Val Loss: 0.6976, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 23, Train Loss: 0.6910, Val Loss: 0.6975, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 24, Train Loss: 0.6909, Val Loss: 0.6973, F1 Micro: 0.6180, F1 Macro: 0.4702, Accuracy: 0.6180\n","Epoch 25, Train Loss: 0.6910, Val Loss: 0.6972, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 26, Train Loss: 0.6909, Val Loss: 0.6971, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 27, Train Loss: 0.6907, Val Loss: 0.6970, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 28, Train Loss: 0.6908, Val Loss: 0.6969, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 29, Train Loss: 0.6907, Val Loss: 0.6969, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 30, Train Loss: 0.6907, Val Loss: 0.6968, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 31, Train Loss: 0.6904, Val Loss: 0.6967, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 32, Train Loss: 0.6903, Val Loss: 0.6966, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 33, Train Loss: 0.6904, Val Loss: 0.6965, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 34, Train Loss: 0.6903, Val Loss: 0.6965, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 35, Train Loss: 0.6901, Val Loss: 0.6964, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 36, Train Loss: 0.6901, Val Loss: 0.6963, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 37, Train Loss: 0.6900, Val Loss: 0.6963, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 38, Train Loss: 0.6899, Val Loss: 0.6958, F1 Micro: 0.6124, F1 Macro: 0.4486, Accuracy: 0.6124\n","Epoch 39, Train Loss: 0.6898, Val Loss: 0.6959, F1 Micro: 0.6124, F1 Macro: 0.4486, Accuracy: 0.6124\n","Epoch 40, Train Loss: 0.6898, Val Loss: 0.6959, F1 Micro: 0.6124, F1 Macro: 0.4486, Accuracy: 0.6124\n","Epoch 41, Train Loss: 0.6897, Val Loss: 0.6956, F1 Micro: 0.6124, F1 Macro: 0.4486, Accuracy: 0.6124\n","Epoch 42, Train Loss: 0.6895, Val Loss: 0.6959, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 43, Train Loss: 0.6900, Val Loss: 0.6958, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 44, Train Loss: 0.6900, Val Loss: 0.6956, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 45, Train Loss: 0.6894, Val Loss: 0.6956, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 46, Train Loss: 0.6899, Val Loss: 0.6954, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 47, Train Loss: 0.6897, Val Loss: 0.6952, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 48, Train Loss: 0.6874, Val Loss: 0.6951, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 49, Train Loss: 0.6894, Val Loss: 0.6950, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 50, Train Loss: 0.6894, Val Loss: 0.6949, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 51, Train Loss: 0.6894, Val Loss: 0.6948, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 52, Train Loss: 0.6891, Val Loss: 0.6948, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 53, Train Loss: 0.6890, Val Loss: 0.6947, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Epoch 54, Train Loss: 0.6884, Val Loss: 0.6947, F1 Micro: 0.6180, F1 Macro: 0.4613, Accuracy: 0.6180\n","Epoch 55, Train Loss: 0.6888, Val Loss: 0.6945, F1 Micro: 0.6236, F1 Macro: 0.4737, Accuracy: 0.6236\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 8, 50): 0.6721988575732848\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 4.2232, Val Loss: 3.3648, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 2, Train Loss: 3.8782, Val Loss: 3.0797, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 3, Train Loss: 3.5365, Val Loss: 2.7840, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 4, Train Loss: 3.1555, Val Loss: 2.4993, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 5, Train Loss: 2.8264, Val Loss: 2.2162, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 6, Train Loss: 2.4994, Val Loss: 1.9344, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 7, Train Loss: 2.1350, Val Loss: 1.6611, F1 Micro: 0.6425, F1 Macro: 0.4056, Accuracy: 0.6425\n","Epoch 8, Train Loss: 1.8405, Val Loss: 1.4105, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 9, Train Loss: 1.5122, Val Loss: 1.1562, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 10, Train Loss: 1.2045, Val Loss: 0.9350, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Epoch 11, Train Loss: 0.9432, Val Loss: 0.7513, F1 Micro: 0.6369, F1 Macro: 0.3891, Accuracy: 0.6369\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 2.2422, Val Loss: 1.6623, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 2, Train Loss: 2.0194, Val Loss: 1.4842, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 3, Train Loss: 1.7295, Val Loss: 1.2951, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 4, Train Loss: 1.5068, Val Loss: 1.1508, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 5, Train Loss: 1.3089, Val Loss: 1.0512, F1 Micro: 0.6910, F1 Macro: 0.5940, Accuracy: 0.6910\n","Epoch 6, Train Loss: 1.1825, Val Loss: 0.9823, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 7, Train Loss: 1.0615, Val Loss: 0.9224, F1 Micro: 0.6966, F1 Macro: 0.5985, Accuracy: 0.6966\n","Epoch 8, Train Loss: 0.9759, Val Loss: 0.8681, F1 Micro: 0.6966, F1 Macro: 0.5924, Accuracy: 0.6966\n","Epoch 9, Train Loss: 0.9013, Val Loss: 0.8261, F1 Micro: 0.6966, F1 Macro: 0.5860, Accuracy: 0.6966\n","Epoch 10, Train Loss: 0.8405, Val Loss: 0.7817, F1 Micro: 0.7135, F1 Macro: 0.5994, Accuracy: 0.7135\n","Epoch 11, Train Loss: 0.7874, Val Loss: 0.7477, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 12, Train Loss: 0.7535, Val Loss: 0.7292, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 13, Train Loss: 0.7367, Val Loss: 0.7176, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 14, Train Loss: 0.7275, Val Loss: 0.7072, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 15, Train Loss: 0.7187, Val Loss: 0.7003, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 16, Train Loss: 0.7138, Val Loss: 0.6939, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 17, Train Loss: 0.7104, Val Loss: 0.6902, F1 Micro: 0.7191, F1 Macro: 0.6039, Accuracy: 0.7191\n","Epoch 18, Train Loss: 0.7079, Val Loss: 0.6867, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 19, Train Loss: 0.7062, Val Loss: 0.6847, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 20, Train Loss: 0.7034, Val Loss: 0.6852, F1 Micro: 0.7247, F1 Macro: 0.6084, Accuracy: 0.7247\n","Epoch 21, Train Loss: 0.7016, Val Loss: 0.6855, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 22, Train Loss: 0.7006, Val Loss: 0.6856, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 23, Train Loss: 0.6992, Val Loss: 0.6857, F1 Micro: 0.7079, F1 Macro: 0.5731, Accuracy: 0.7079\n","Epoch 24, Train Loss: 0.6982, Val Loss: 0.6849, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 25, Train Loss: 0.6971, Val Loss: 0.6846, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 26, Train Loss: 0.6965, Val Loss: 0.6844, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 27, Train Loss: 0.6951, Val Loss: 0.6843, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Epoch 28, Train Loss: 0.6944, Val Loss: 0.6835, F1 Micro: 0.7135, F1 Macro: 0.5852, Accuracy: 0.7135\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 3.5398, Val Loss: 2.6534, F1 Micro: 0.3483, F1 Macro: 0.3416, Accuracy: 0.3483\n","Epoch 2, Train Loss: 2.0258, Val Loss: 1.4299, F1 Micro: 0.4045, F1 Macro: 0.3871, Accuracy: 0.4045\n","Epoch 3, Train Loss: 1.3196, Val Loss: 1.0742, F1 Micro: 0.5056, F1 Macro: 0.4374, Accuracy: 0.5056\n","Epoch 4, Train Loss: 1.1037, Val Loss: 0.9693, F1 Micro: 0.5955, F1 Macro: 0.4647, Accuracy: 0.5955\n","Epoch 5, Train Loss: 0.9886, Val Loss: 0.8929, F1 Micro: 0.6348, F1 Macro: 0.4806, Accuracy: 0.6348\n","Epoch 6, Train Loss: 0.8970, Val Loss: 0.8166, F1 Micro: 0.6461, F1 Macro: 0.4780, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.8098, Val Loss: 0.7555, F1 Micro: 0.6404, F1 Macro: 0.4647, Accuracy: 0.6404\n","Epoch 8, Train Loss: 0.7417, Val Loss: 0.7020, F1 Micro: 0.6348, F1 Macro: 0.4400, Accuracy: 0.6348\n","Epoch 9, Train Loss: 0.6898, Val Loss: 0.6682, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 10, Train Loss: 0.6508, Val Loss: 0.6461, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 11, Train Loss: 0.6360, Val Loss: 0.6396, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 12, Train Loss: 0.6203, Val Loss: 0.6371, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 13, Train Loss: 0.6164, Val Loss: 0.6335, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 14, Train Loss: 0.6115, Val Loss: 0.6350, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 15, Train Loss: 0.6057, Val Loss: 0.6346, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Epoch 16, Train Loss: 0.6034, Val Loss: 0.6354, F1 Micro: 0.6236, F1 Macro: 0.3841, Accuracy: 0.6236\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 1.4028, Val Loss: 1.1558, F1 Micro: 0.6348, F1 Macro: 0.6275, Accuracy: 0.6348\n","Epoch 2, Train Loss: 1.1575, Val Loss: 1.0831, F1 Micro: 0.6348, F1 Macro: 0.6201, Accuracy: 0.6348\n","Epoch 3, Train Loss: 1.0100, Val Loss: 1.0080, F1 Micro: 0.6292, F1 Macro: 0.6095, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.8965, Val Loss: 0.9257, F1 Micro: 0.6404, F1 Macro: 0.6170, Accuracy: 0.6404\n","Epoch 5, Train Loss: 0.8056, Val Loss: 0.8269, F1 Micro: 0.6461, F1 Macro: 0.6262, Accuracy: 0.6461\n","Epoch 6, Train Loss: 0.7245, Val Loss: 0.7502, F1 Micro: 0.6461, F1 Macro: 0.6282, Accuracy: 0.6461\n","Epoch 7, Train Loss: 0.6576, Val Loss: 0.6959, F1 Micro: 0.6573, F1 Macro: 0.6361, Accuracy: 0.6573\n","Epoch 8, Train Loss: 0.6171, Val Loss: 0.6480, F1 Micro: 0.6517, F1 Macro: 0.6351, Accuracy: 0.6517\n","Epoch 9, Train Loss: 0.5954, Val Loss: 0.6362, F1 Micro: 0.6629, F1 Macro: 0.6450, Accuracy: 0.6629\n","Epoch 10, Train Loss: 0.5779, Val Loss: 0.6229, F1 Micro: 0.6517, F1 Macro: 0.6311, Accuracy: 0.6517\n","Epoch 11, Train Loss: 0.5745, Val Loss: 0.6199, F1 Micro: 0.6629, F1 Macro: 0.6410, Accuracy: 0.6629\n","Epoch 12, Train Loss: 0.5720, Val Loss: 0.6249, F1 Micro: 0.6966, F1 Macro: 0.6749, Accuracy: 0.6966\n","Epoch 13, Train Loss: 0.5720, Val Loss: 0.6217, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 14, Train Loss: 0.5703, Val Loss: 0.6176, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 15, Train Loss: 0.5678, Val Loss: 0.6208, F1 Micro: 0.6854, F1 Macro: 0.6629, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.5702, Val Loss: 0.6154, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 17, Train Loss: 0.5679, Val Loss: 0.6197, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 18, Train Loss: 0.5676, Val Loss: 0.6200, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 19, Train Loss: 0.5671, Val Loss: 0.6184, F1 Micro: 0.6910, F1 Macro: 0.6719, Accuracy: 0.6910\n","Epoch 20, Train Loss: 0.5683, Val Loss: 0.6222, F1 Micro: 0.6854, F1 Macro: 0.6649, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.5686, Val Loss: 0.6138, F1 Micro: 0.7079, F1 Macro: 0.6939, Accuracy: 0.7079\n","Epoch 22, Train Loss: 0.5694, Val Loss: 0.6173, F1 Micro: 0.6966, F1 Macro: 0.6787, Accuracy: 0.6966\n","Epoch 23, Train Loss: 0.5703, Val Loss: 0.6101, F1 Micro: 0.7022, F1 Macro: 0.6888, Accuracy: 0.7022\n","Epoch 24, Train Loss: 0.5708, Val Loss: 0.6101, F1 Micro: 0.7022, F1 Macro: 0.6903, Accuracy: 0.7022\n","Epoch 25, Train Loss: 0.5727, Val Loss: 0.6161, F1 Micro: 0.6910, F1 Macro: 0.6754, Accuracy: 0.6910\n","Epoch 26, Train Loss: 0.5726, Val Loss: 0.6208, F1 Micro: 0.7022, F1 Macro: 0.6838, Accuracy: 0.7022\n","Epoch 27, Train Loss: 0.5656, Val Loss: 0.6116, F1 Micro: 0.7022, F1 Macro: 0.6903, Accuracy: 0.7022\n","Epoch 28, Train Loss: 0.5679, Val Loss: 0.6091, F1 Micro: 0.6966, F1 Macro: 0.6837, Accuracy: 0.6966\n","Epoch 29, Train Loss: 0.5684, Val Loss: 0.6221, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Epoch 30, Train Loss: 0.5696, Val Loss: 0.6231, F1 Micro: 0.7079, F1 Macro: 0.6923, Accuracy: 0.7079\n","Epoch 31, Train Loss: 0.5704, Val Loss: 0.6233, F1 Micro: 0.6910, F1 Macro: 0.6737, Accuracy: 0.6910\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=10\n","Epoch 1, Train Loss: 0.9585, Val Loss: 1.1174, F1 Micro: 0.5730, F1 Macro: 0.4778, Accuracy: 0.5730\n","Epoch 2, Train Loss: 0.8562, Val Loss: 0.9917, F1 Micro: 0.6011, F1 Macro: 0.4970, Accuracy: 0.6011\n","Epoch 3, Train Loss: 0.8064, Val Loss: 0.9152, F1 Micro: 0.6067, F1 Macro: 0.5008, Accuracy: 0.6067\n","Epoch 4, Train Loss: 0.7814, Val Loss: 0.8665, F1 Micro: 0.6180, F1 Macro: 0.5085, Accuracy: 0.6180\n","Epoch 5, Train Loss: 0.7622, Val Loss: 0.8439, F1 Micro: 0.6236, F1 Macro: 0.5124, Accuracy: 0.6236\n","Epoch 6, Train Loss: 0.7470, Val Loss: 0.8219, F1 Micro: 0.6292, F1 Macro: 0.5163, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.7335, Val Loss: 0.8045, F1 Micro: 0.6348, F1 Macro: 0.5131, Accuracy: 0.6348\n","Epoch 8, Train Loss: 0.7219, Val Loss: 0.7898, F1 Micro: 0.6292, F1 Macro: 0.5019, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.7127, Val Loss: 0.7763, F1 Micro: 0.6180, F1 Macro: 0.4787, Accuracy: 0.6180\n","Epoch 10, Train Loss: 0.7041, Val Loss: 0.7660, F1 Micro: 0.6124, F1 Macro: 0.4668, Accuracy: 0.6124\n","Epoch 11, Train Loss: 0.6996, Val Loss: 0.7573, F1 Micro: 0.5899, F1 Macro: 0.4167, Accuracy: 0.5899\n","Epoch 12, Train Loss: 0.6968, Val Loss: 0.7526, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 13, Train Loss: 0.6941, Val Loss: 0.7486, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 14, Train Loss: 0.6939, Val Loss: 0.7467, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 15, Train Loss: 0.6935, Val Loss: 0.7451, F1 Micro: 0.5955, F1 Macro: 0.4196, Accuracy: 0.5955\n","Epoch 16, Train Loss: 0.6926, Val Loss: 0.7426, F1 Micro: 0.5955, F1 Macro: 0.4090, Accuracy: 0.5955\n","Epoch 17, Train Loss: 0.6927, Val Loss: 0.7410, F1 Micro: 0.5955, F1 Macro: 0.4090, Accuracy: 0.5955\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 10): 0.671188249325215\n","Inner FOLD 0\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 7.6279, Val Loss: 5.1916, F1 Micro: 0.3296, F1 Macro: 0.2753, Accuracy: 0.3296\n","Epoch 2, Train Loss: 5.7734, Val Loss: 3.6860, F1 Micro: 0.3240, F1 Macro: 0.3017, Accuracy: 0.3240\n","Epoch 3, Train Loss: 3.9101, Val Loss: 2.4212, F1 Micro: 0.3799, F1 Macro: 0.3786, Accuracy: 0.3799\n","Epoch 4, Train Loss: 2.7004, Val Loss: 1.6782, F1 Micro: 0.4916, F1 Macro: 0.4823, Accuracy: 0.4916\n","Epoch 5, Train Loss: 1.8662, Val Loss: 1.3852, F1 Micro: 0.5698, F1 Macro: 0.5422, Accuracy: 0.5698\n","Epoch 6, Train Loss: 1.5741, Val Loss: 1.2587, F1 Micro: 0.6034, F1 Macro: 0.5493, Accuracy: 0.6034\n","Epoch 7, Train Loss: 1.4339, Val Loss: 1.1973, F1 Micro: 0.6145, F1 Macro: 0.5495, Accuracy: 0.6145\n","Epoch 8, Train Loss: 1.3532, Val Loss: 1.1453, F1 Micro: 0.6369, F1 Macro: 0.5620, Accuracy: 0.6369\n","Epoch 9, Train Loss: 1.2621, Val Loss: 1.0978, F1 Micro: 0.6480, F1 Macro: 0.5602, Accuracy: 0.6480\n","Epoch 10, Train Loss: 1.1913, Val Loss: 1.0580, F1 Micro: 0.6592, F1 Macro: 0.5630, Accuracy: 0.6592\n","Epoch 11, Train Loss: 1.1498, Val Loss: 1.0185, F1 Micro: 0.6592, F1 Macro: 0.5569, Accuracy: 0.6592\n","Epoch 12, Train Loss: 1.0740, Val Loss: 0.9712, F1 Micro: 0.6704, F1 Macro: 0.5715, Accuracy: 0.6704\n","Epoch 13, Train Loss: 1.0140, Val Loss: 0.9327, F1 Micro: 0.6536, F1 Macro: 0.5329, Accuracy: 0.6536\n","Epoch 14, Train Loss: 0.9619, Val Loss: 0.8904, F1 Micro: 0.6592, F1 Macro: 0.5369, Accuracy: 0.6592\n","Epoch 15, Train Loss: 0.9182, Val Loss: 0.8475, F1 Micro: 0.6592, F1 Macro: 0.5369, Accuracy: 0.6592\n","Epoch 16, Train Loss: 0.8657, Val Loss: 0.8148, F1 Micro: 0.6592, F1 Macro: 0.5295, Accuracy: 0.6592\n","Epoch 17, Train Loss: 0.8197, Val Loss: 0.7713, F1 Micro: 0.6480, F1 Macro: 0.4974, Accuracy: 0.6480\n","Epoch 18, Train Loss: 0.7772, Val Loss: 0.7357, F1 Micro: 0.6480, F1 Macro: 0.4974, Accuracy: 0.6480\n","Epoch 19, Train Loss: 0.7394, Val Loss: 0.7068, F1 Micro: 0.6313, F1 Macro: 0.4488, Accuracy: 0.6313\n","Epoch 20, Train Loss: 0.7087, Val Loss: 0.6783, F1 Micro: 0.6257, F1 Macro: 0.4350, Accuracy: 0.6257\n","Epoch 21, Train Loss: 0.6736, Val Loss: 0.6541, F1 Micro: 0.6369, F1 Macro: 0.4408, Accuracy: 0.6369\n","Epoch 22, Train Loss: 0.6493, Val Loss: 0.6361, F1 Micro: 0.6425, F1 Macro: 0.4317, Accuracy: 0.6425\n","Epoch 23, Train Loss: 0.6298, Val Loss: 0.6228, F1 Micro: 0.6480, F1 Macro: 0.4079, Accuracy: 0.6480\n","Epoch 24, Train Loss: 0.6198, Val Loss: 0.6147, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 25, Train Loss: 0.6110, Val Loss: 0.6081, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 26, Train Loss: 0.6030, Val Loss: 0.6040, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 27, Train Loss: 0.6005, Val Loss: 0.5999, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 28, Train Loss: 0.5988, Val Loss: 0.5983, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 29, Train Loss: 0.5955, Val Loss: 0.5950, F1 Micro: 0.6425, F1 Macro: 0.3912, Accuracy: 0.6425\n","Epoch 30, Train Loss: 0.5962, Val Loss: 0.5943, F1 Micro: 0.6480, F1 Macro: 0.4079, Accuracy: 0.6480\n","Epoch 31, Train Loss: 0.5907, Val Loss: 0.5934, F1 Micro: 0.6480, F1 Macro: 0.4079, Accuracy: 0.6480\n","Epoch 32, Train Loss: 0.5906, Val Loss: 0.5896, F1 Micro: 0.6536, F1 Macro: 0.4241, Accuracy: 0.6536\n","Epoch 33, Train Loss: 0.5915, Val Loss: 0.5880, F1 Micro: 0.6648, F1 Macro: 0.4554, Accuracy: 0.6648\n","Epoch 34, Train Loss: 0.5933, Val Loss: 0.5873, F1 Micro: 0.6704, F1 Macro: 0.4924, Accuracy: 0.6704\n","Epoch 35, Train Loss: 0.5876, Val Loss: 0.5873, F1 Micro: 0.6872, F1 Macro: 0.5323, Accuracy: 0.6872\n","Epoch 36, Train Loss: 0.5869, Val Loss: 0.5863, F1 Micro: 0.6872, F1 Macro: 0.5410, Accuracy: 0.6872\n","Epoch 37, Train Loss: 0.5883, Val Loss: 0.5846, F1 Micro: 0.7039, F1 Macro: 0.5772, Accuracy: 0.7039\n","Epoch 38, Train Loss: 0.5865, Val Loss: 0.5827, F1 Micro: 0.7039, F1 Macro: 0.5772, Accuracy: 0.7039\n","Epoch 39, Train Loss: 0.5854, Val Loss: 0.5836, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 40, Train Loss: 0.5828, Val Loss: 0.5823, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 41, Train Loss: 0.5821, Val Loss: 0.5806, F1 Micro: 0.7207, F1 Macro: 0.6174, Accuracy: 0.7207\n","Epoch 42, Train Loss: 0.5824, Val Loss: 0.5794, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 43, Train Loss: 0.5797, Val Loss: 0.5776, F1 Micro: 0.7263, F1 Macro: 0.6336, Accuracy: 0.7263\n","Epoch 44, Train Loss: 0.5834, Val Loss: 0.5826, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 45, Train Loss: 0.5794, Val Loss: 0.5748, F1 Micro: 0.7151, F1 Macro: 0.6296, Accuracy: 0.7151\n","Epoch 46, Train Loss: 0.5801, Val Loss: 0.5779, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 47, Train Loss: 0.5802, Val Loss: 0.5748, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 48, Train Loss: 0.5791, Val Loss: 0.5727, F1 Micro: 0.7151, F1 Macro: 0.6394, Accuracy: 0.7151\n","Epoch 49, Train Loss: 0.5767, Val Loss: 0.5703, F1 Micro: 0.7151, F1 Macro: 0.6346, Accuracy: 0.7151\n","Epoch 50, Train Loss: 0.5776, Val Loss: 0.5693, F1 Micro: 0.7095, F1 Macro: 0.6299, Accuracy: 0.7095\n","Epoch 51, Train Loss: 0.5769, Val Loss: 0.5694, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 52, Train Loss: 0.5804, Val Loss: 0.5738, F1 Micro: 0.7263, F1 Macro: 0.6698, Accuracy: 0.7263\n","Epoch 53, Train Loss: 0.5778, Val Loss: 0.5678, F1 Micro: 0.7263, F1 Macro: 0.6579, Accuracy: 0.7263\n","Epoch 54, Train Loss: 0.5758, Val Loss: 0.5665, F1 Micro: 0.7207, F1 Macro: 0.6487, Accuracy: 0.7207\n","Epoch 55, Train Loss: 0.5748, Val Loss: 0.5657, F1 Micro: 0.7318, F1 Macro: 0.6670, Accuracy: 0.7318\n","Epoch 56, Train Loss: 0.5759, Val Loss: 0.5646, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 57, Train Loss: 0.5744, Val Loss: 0.5636, F1 Micro: 0.7263, F1 Macro: 0.6621, Accuracy: 0.7263\n","Epoch 58, Train Loss: 0.5746, Val Loss: 0.5671, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 59, Train Loss: 0.5727, Val Loss: 0.5625, F1 Micro: 0.7318, F1 Macro: 0.6710, Accuracy: 0.7318\n","Epoch 60, Train Loss: 0.5747, Val Loss: 0.5590, F1 Micro: 0.7207, F1 Macro: 0.6531, Accuracy: 0.7207\n","Epoch 61, Train Loss: 0.5740, Val Loss: 0.5598, F1 Micro: 0.7207, F1 Macro: 0.6649, Accuracy: 0.7207\n","Epoch 62, Train Loss: 0.5688, Val Loss: 0.5572, F1 Micro: 0.7151, F1 Macro: 0.6564, Accuracy: 0.7151\n","Epoch 63, Train Loss: 0.5706, Val Loss: 0.5581, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 64, Train Loss: 0.5692, Val Loss: 0.5574, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 65, Train Loss: 0.5713, Val Loss: 0.5547, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 66, Train Loss: 0.5661, Val Loss: 0.5529, F1 Micro: 0.6983, F1 Macro: 0.6381, Accuracy: 0.6983\n","Epoch 67, Train Loss: 0.5649, Val Loss: 0.5516, F1 Micro: 0.7039, F1 Macro: 0.6429, Accuracy: 0.7039\n","Epoch 68, Train Loss: 0.5690, Val Loss: 0.5528, F1 Micro: 0.7039, F1 Macro: 0.6468, Accuracy: 0.7039\n","Epoch 69, Train Loss: 0.5660, Val Loss: 0.5520, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 70, Train Loss: 0.5660, Val Loss: 0.5533, F1 Micro: 0.7039, F1 Macro: 0.6468, Accuracy: 0.7039\n","Epoch 71, Train Loss: 0.5669, Val Loss: 0.5495, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 72, Train Loss: 0.5640, Val Loss: 0.5494, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 73, Train Loss: 0.5642, Val Loss: 0.5493, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 74, Train Loss: 0.5660, Val Loss: 0.5471, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 75, Train Loss: 0.5645, Val Loss: 0.5468, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 76, Train Loss: 0.5636, Val Loss: 0.5465, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 77, Train Loss: 0.5667, Val Loss: 0.5457, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 78, Train Loss: 0.5631, Val Loss: 0.5469, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 79, Train Loss: 0.5645, Val Loss: 0.5425, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 80, Train Loss: 0.5638, Val Loss: 0.5417, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 81, Train Loss: 0.5645, Val Loss: 0.5405, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 82, Train Loss: 0.5665, Val Loss: 0.5441, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 83, Train Loss: 0.5639, Val Loss: 0.5423, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 84, Train Loss: 0.5631, Val Loss: 0.5381, F1 Micro: 0.7095, F1 Macro: 0.6515, Accuracy: 0.7095\n","Epoch 85, Train Loss: 0.5640, Val Loss: 0.5386, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 86, Train Loss: 0.5631, Val Loss: 0.5397, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 87, Train Loss: 0.5618, Val Loss: 0.5393, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 88, Train Loss: 0.5615, Val Loss: 0.5382, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 89, Train Loss: 0.5635, Val Loss: 0.5393, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 90, Train Loss: 0.5626, Val Loss: 0.5397, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 91, Train Loss: 0.5672, Val Loss: 0.5396, F1 Micro: 0.7207, F1 Macro: 0.6719, Accuracy: 0.7207\n","Epoch 92, Train Loss: 0.5640, Val Loss: 0.5378, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 93, Train Loss: 0.5640, Val Loss: 0.5381, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 94, Train Loss: 0.5625, Val Loss: 0.5383, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 95, Train Loss: 0.5624, Val Loss: 0.5359, F1 Micro: 0.7151, F1 Macro: 0.6601, Accuracy: 0.7151\n","Epoch 96, Train Loss: 0.5645, Val Loss: 0.5330, F1 Micro: 0.7095, F1 Macro: 0.6476, Accuracy: 0.7095\n","Epoch 97, Train Loss: 0.5638, Val Loss: 0.5330, F1 Micro: 0.7151, F1 Macro: 0.6564, Accuracy: 0.7151\n","Epoch 98, Train Loss: 0.5614, Val Loss: 0.5360, F1 Micro: 0.7151, F1 Macro: 0.6636, Accuracy: 0.7151\n","Epoch 99, Train Loss: 0.5618, Val Loss: 0.5312, F1 Micro: 0.6983, F1 Macro: 0.6298, Accuracy: 0.6983\n","Epoch 100, Train Loss: 0.5591, Val Loss: 0.5339, F1 Micro: 0.7095, F1 Macro: 0.6553, Accuracy: 0.7095\n","Epoch 101, Train Loss: 0.5615, Val Loss: 0.5299, F1 Micro: 0.7039, F1 Macro: 0.6345, Accuracy: 0.7039\n","Epoch 102, Train Loss: 0.5588, Val Loss: 0.5321, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 103, Train Loss: 0.5607, Val Loss: 0.5371, F1 Micro: 0.7151, F1 Macro: 0.6703, Accuracy: 0.7151\n","Epoch 104, Train Loss: 0.5646, Val Loss: 0.5300, F1 Micro: 0.6983, F1 Macro: 0.6341, Accuracy: 0.6983\n","Epoch 105, Train Loss: 0.5580, Val Loss: 0.5323, F1 Micro: 0.7039, F1 Macro: 0.6468, Accuracy: 0.7039\n","Early stopping triggered\n","Inner FOLD 1\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.0576, Val Loss: 1.2854, F1 Micro: 0.6461, F1 Macro: 0.4458, Accuracy: 0.6461\n","Epoch 2, Train Loss: 1.0148, Val Loss: 1.2338, F1 Micro: 0.6348, F1 Macro: 0.4157, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.9673, Val Loss: 1.1894, F1 Micro: 0.6292, F1 Macro: 0.4001, Accuracy: 0.6292\n","Epoch 4, Train Loss: 0.9502, Val Loss: 1.1555, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 5, Train Loss: 0.9186, Val Loss: 1.1143, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 6, Train Loss: 0.8988, Val Loss: 1.0784, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 7, Train Loss: 0.8817, Val Loss: 1.0520, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 8, Train Loss: 0.8687, Val Loss: 1.0231, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 9, Train Loss: 0.8494, Val Loss: 0.9999, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 10, Train Loss: 0.8357, Val Loss: 0.9728, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 11, Train Loss: 0.8218, Val Loss: 0.9590, F1 Micro: 0.6292, F1 Macro: 0.3862, Accuracy: 0.6292\n","Epoch 12, Train Loss: 0.8091, Val Loss: 0.9439, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 13, Train Loss: 0.7947, Val Loss: 0.9236, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 14, Train Loss: 0.7804, Val Loss: 0.9097, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 15, Train Loss: 0.7786, Val Loss: 0.8877, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 16, Train Loss: 0.7519, Val Loss: 0.8673, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 17, Train Loss: 0.7376, Val Loss: 0.8480, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 18, Train Loss: 0.7236, Val Loss: 0.8299, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 19, Train Loss: 0.7029, Val Loss: 0.7954, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 20, Train Loss: 0.6745, Val Loss: 0.7625, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 21, Train Loss: 0.6519, Val Loss: 0.7265, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 22, Train Loss: 0.6311, Val Loss: 0.6991, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 23, Train Loss: 0.6110, Val Loss: 0.6754, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 24, Train Loss: 0.5992, Val Loss: 0.6586, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 25, Train Loss: 0.5917, Val Loss: 0.6467, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 26, Train Loss: 0.5955, Val Loss: 0.6447, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 27, Train Loss: 0.5888, Val Loss: 0.6456, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 28, Train Loss: 0.5865, Val Loss: 0.6357, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 29, Train Loss: 0.5863, Val Loss: 0.6358, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 30, Train Loss: 0.5901, Val Loss: 0.6346, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 31, Train Loss: 0.5861, Val Loss: 0.6300, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 32, Train Loss: 0.5861, Val Loss: 0.6293, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 33, Train Loss: 0.5858, Val Loss: 0.6307, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 34, Train Loss: 0.5863, Val Loss: 0.6320, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 35, Train Loss: 0.5858, Val Loss: 0.6304, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 36, Train Loss: 0.5886, Val Loss: 0.6272, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 37, Train Loss: 0.5852, Val Loss: 0.6315, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 38, Train Loss: 0.5874, Val Loss: 0.6319, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 39, Train Loss: 0.5840, Val Loss: 0.6315, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 40, Train Loss: 0.5832, Val Loss: 0.6282, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 41, Train Loss: 0.5812, Val Loss: 0.6308, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 42, Train Loss: 0.5830, Val Loss: 0.6297, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 43, Train Loss: 0.5819, Val Loss: 0.6280, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 44, Train Loss: 0.5809, Val Loss: 0.6291, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 45, Train Loss: 0.5848, Val Loss: 0.6289, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 46, Train Loss: 0.5832, Val Loss: 0.6300, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 47, Train Loss: 0.5824, Val Loss: 0.6265, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 48, Train Loss: 0.5823, Val Loss: 0.6274, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 49, Train Loss: 0.5824, Val Loss: 0.6273, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 50, Train Loss: 0.5843, Val Loss: 0.6265, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Epoch 51, Train Loss: 0.5819, Val Loss: 0.6272, F1 Micro: 0.6348, F1 Macro: 0.3883, Accuracy: 0.6348\n","Early stopping triggered\n","Inner FOLD 2\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 1.2438, Val Loss: 0.8801, F1 Micro: 0.5169, F1 Macro: 0.4679, Accuracy: 0.5169\n","Epoch 2, Train Loss: 0.8648, Val Loss: 0.7919, F1 Micro: 0.6348, F1 Macro: 0.5334, Accuracy: 0.6348\n","Epoch 3, Train Loss: 0.7772, Val Loss: 0.7299, F1 Micro: 0.6573, F1 Macro: 0.5431, Accuracy: 0.6573\n","Epoch 4, Train Loss: 0.7195, Val Loss: 0.6743, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 5, Train Loss: 0.6617, Val Loss: 0.6312, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 6, Train Loss: 0.6295, Val Loss: 0.6077, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 7, Train Loss: 0.6139, Val Loss: 0.5962, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 8, Train Loss: 0.6067, Val Loss: 0.5906, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 9, Train Loss: 0.6009, Val Loss: 0.5870, F1 Micro: 0.6742, F1 Macro: 0.5481, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.6037, Val Loss: 0.5858, F1 Micro: 0.6685, F1 Macro: 0.5365, Accuracy: 0.6685\n","Epoch 11, Train Loss: 0.5996, Val Loss: 0.5846, F1 Micro: 0.6798, F1 Macro: 0.5595, Accuracy: 0.6798\n","Epoch 12, Train Loss: 0.5992, Val Loss: 0.5838, F1 Micro: 0.6854, F1 Macro: 0.5707, Accuracy: 0.6854\n","Epoch 13, Train Loss: 0.6002, Val Loss: 0.5829, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 14, Train Loss: 0.5979, Val Loss: 0.5836, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 15, Train Loss: 0.5996, Val Loss: 0.5821, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 16, Train Loss: 0.5982, Val Loss: 0.5815, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 17, Train Loss: 0.5981, Val Loss: 0.5824, F1 Micro: 0.6517, F1 Macro: 0.5689, Accuracy: 0.6517\n","Epoch 18, Train Loss: 0.5991, Val Loss: 0.5816, F1 Micro: 0.6798, F1 Macro: 0.5665, Accuracy: 0.6798\n","Epoch 19, Train Loss: 0.5975, Val Loss: 0.5818, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.5956, Val Loss: 0.5804, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 21, Train Loss: 0.5984, Val Loss: 0.5801, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 22, Train Loss: 0.5981, Val Loss: 0.5797, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 23, Train Loss: 0.5956, Val Loss: 0.5795, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 24, Train Loss: 0.5973, Val Loss: 0.5798, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 25, Train Loss: 0.5974, Val Loss: 0.5791, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 26, Train Loss: 0.5966, Val Loss: 0.5789, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 27, Train Loss: 0.5940, Val Loss: 0.5786, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 28, Train Loss: 0.5950, Val Loss: 0.5780, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.6007, Val Loss: 0.5780, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 30, Train Loss: 0.5931, Val Loss: 0.5776, F1 Micro: 0.6798, F1 Macro: 0.6150, Accuracy: 0.6798\n","Epoch 31, Train Loss: 0.5920, Val Loss: 0.5778, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 32, Train Loss: 0.5943, Val Loss: 0.5774, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 33, Train Loss: 0.5917, Val Loss: 0.5772, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.5938, Val Loss: 0.5765, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 35, Train Loss: 0.5956, Val Loss: 0.5769, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 36, Train Loss: 0.5944, Val Loss: 0.5762, F1 Micro: 0.6798, F1 Macro: 0.6107, Accuracy: 0.6798\n","Epoch 37, Train Loss: 0.5912, Val Loss: 0.5764, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 38, Train Loss: 0.5925, Val Loss: 0.5761, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 39, Train Loss: 0.5951, Val Loss: 0.5760, F1 Micro: 0.6798, F1 Macro: 0.6192, Accuracy: 0.6798\n","Epoch 40, Train Loss: 0.5900, Val Loss: 0.5766, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 41, Train Loss: 0.5929, Val Loss: 0.5765, F1 Micro: 0.7022, F1 Macro: 0.6596, Accuracy: 0.7022\n","Epoch 42, Train Loss: 0.5925, Val Loss: 0.5766, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 43, Train Loss: 0.6047, Val Loss: 0.5765, F1 Micro: 0.6798, F1 Macro: 0.6012, Accuracy: 0.6798\n","Epoch 44, Train Loss: 0.5888, Val Loss: 0.5774, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 45, Train Loss: 0.5903, Val Loss: 0.5786, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 46, Train Loss: 0.5883, Val Loss: 0.5740, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 47, Train Loss: 0.5879, Val Loss: 0.5737, F1 Micro: 0.7079, F1 Macro: 0.6613, Accuracy: 0.7079\n","Epoch 48, Train Loss: 0.5939, Val Loss: 0.5730, F1 Micro: 0.6910, F1 Macro: 0.6285, Accuracy: 0.6910\n","Epoch 49, Train Loss: 0.5902, Val Loss: 0.5778, F1 Micro: 0.6742, F1 Macro: 0.6411, Accuracy: 0.6742\n","Epoch 50, Train Loss: 0.5917, Val Loss: 0.5724, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 51, Train Loss: 0.5897, Val Loss: 0.5731, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 52, Train Loss: 0.5915, Val Loss: 0.5720, F1 Micro: 0.6910, F1 Macro: 0.6435, Accuracy: 0.6910\n","Epoch 53, Train Loss: 0.5868, Val Loss: 0.5723, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 54, Train Loss: 0.5885, Val Loss: 0.5718, F1 Micro: 0.7079, F1 Macro: 0.6675, Accuracy: 0.7079\n","Epoch 55, Train Loss: 0.5866, Val Loss: 0.5710, F1 Micro: 0.6910, F1 Macro: 0.6364, Accuracy: 0.6910\n","Epoch 56, Train Loss: 0.5893, Val Loss: 0.5713, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 57, Train Loss: 0.5856, Val Loss: 0.5691, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 58, Train Loss: 0.5874, Val Loss: 0.5631, F1 Micro: 0.6966, F1 Macro: 0.6448, Accuracy: 0.6966\n","Epoch 59, Train Loss: 0.5854, Val Loss: 0.5627, F1 Micro: 0.6966, F1 Macro: 0.6411, Accuracy: 0.6966\n","Epoch 60, Train Loss: 0.5852, Val Loss: 0.5601, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 61, Train Loss: 0.5833, Val Loss: 0.5590, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 62, Train Loss: 0.5831, Val Loss: 0.5559, F1 Micro: 0.7022, F1 Macro: 0.6531, Accuracy: 0.7022\n","Epoch 63, Train Loss: 0.5828, Val Loss: 0.5566, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 64, Train Loss: 0.5826, Val Loss: 0.5556, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 65, Train Loss: 0.5818, Val Loss: 0.5553, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 66, Train Loss: 0.5805, Val Loss: 0.5548, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 67, Train Loss: 0.5806, Val Loss: 0.5553, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 68, Train Loss: 0.5821, Val Loss: 0.5574, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 69, Train Loss: 0.5817, Val Loss: 0.5546, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 70, Train Loss: 0.5857, Val Loss: 0.5563, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 71, Train Loss: 0.5829, Val Loss: 0.5571, F1 Micro: 0.6854, F1 Macro: 0.6153, Accuracy: 0.6854\n","Epoch 72, Train Loss: 0.5815, Val Loss: 0.5544, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 73, Train Loss: 0.5815, Val Loss: 0.5547, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 74, Train Loss: 0.5788, Val Loss: 0.5546, F1 Micro: 0.6910, F1 Macro: 0.6529, Accuracy: 0.6910\n","Epoch 75, Train Loss: 0.5802, Val Loss: 0.5554, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 76, Train Loss: 0.5814, Val Loss: 0.5540, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 77, Train Loss: 0.5795, Val Loss: 0.5547, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 78, Train Loss: 0.5814, Val Loss: 0.5534, F1 Micro: 0.7022, F1 Macro: 0.6564, Accuracy: 0.7022\n","Epoch 79, Train Loss: 0.5832, Val Loss: 0.5541, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 80, Train Loss: 0.5801, Val Loss: 0.5538, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 81, Train Loss: 0.5809, Val Loss: 0.5567, F1 Micro: 0.6798, F1 Macro: 0.6511, Accuracy: 0.6798\n","Epoch 82, Train Loss: 0.5794, Val Loss: 0.5536, F1 Micro: 0.7135, F1 Macro: 0.6662, Accuracy: 0.7135\n","Epoch 83, Train Loss: 0.5811, Val Loss: 0.5552, F1 Micro: 0.6854, F1 Macro: 0.6535, Accuracy: 0.6854\n","Epoch 84, Train Loss: 0.5841, Val Loss: 0.5537, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 85, Train Loss: 0.5823, Val Loss: 0.5531, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 86, Train Loss: 0.5815, Val Loss: 0.5536, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 87, Train Loss: 0.5811, Val Loss: 0.5558, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 88, Train Loss: 0.5822, Val Loss: 0.5548, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 89, Train Loss: 0.5816, Val Loss: 0.5543, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 90, Train Loss: 0.5817, Val Loss: 0.5571, F1 Micro: 0.6742, F1 Macro: 0.6486, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.5841, Val Loss: 0.5533, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 92, Train Loss: 0.5814, Val Loss: 0.5535, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 93, Train Loss: 0.5820, Val Loss: 0.5533, F1 Micro: 0.7079, F1 Macro: 0.6732, Accuracy: 0.7079\n","Epoch 94, Train Loss: 0.5819, Val Loss: 0.5528, F1 Micro: 0.6910, F1 Macro: 0.6468, Accuracy: 0.6910\n","Epoch 95, Train Loss: 0.5811, Val Loss: 0.5568, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 96, Train Loss: 0.5812, Val Loss: 0.5536, F1 Micro: 0.7022, F1 Macro: 0.6682, Accuracy: 0.7022\n","Epoch 97, Train Loss: 0.5851, Val Loss: 0.5586, F1 Micro: 0.6742, F1 Macro: 0.6530, Accuracy: 0.6742\n","Epoch 98, Train Loss: 0.5838, Val Loss: 0.5543, F1 Micro: 0.7079, F1 Macro: 0.6507, Accuracy: 0.7079\n","Epoch 99, Train Loss: 0.5815, Val Loss: 0.5560, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 100, Train Loss: 0.5807, Val Loss: 0.5534, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 101, Train Loss: 0.5845, Val Loss: 0.5556, F1 Micro: 0.6854, F1 Macro: 0.6584, Accuracy: 0.6854\n","Epoch 102, Train Loss: 0.5800, Val Loss: 0.5525, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 103, Train Loss: 0.5801, Val Loss: 0.5543, F1 Micro: 0.6966, F1 Macro: 0.6659, Accuracy: 0.6966\n","Epoch 104, Train Loss: 0.5770, Val Loss: 0.5529, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 105, Train Loss: 0.5777, Val Loss: 0.5538, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 106, Train Loss: 0.5792, Val Loss: 0.5530, F1 Micro: 0.6910, F1 Macro: 0.6499, Accuracy: 0.6910\n","Epoch 107, Train Loss: 0.5800, Val Loss: 0.5527, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 108, Train Loss: 0.5847, Val Loss: 0.5567, F1 Micro: 0.6798, F1 Macro: 0.6535, Accuracy: 0.6798\n","Epoch 109, Train Loss: 0.5819, Val Loss: 0.5524, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 110, Train Loss: 0.5795, Val Loss: 0.5536, F1 Micro: 0.6910, F1 Macro: 0.6557, Accuracy: 0.6910\n","Epoch 111, Train Loss: 0.5810, Val Loss: 0.5530, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 112, Train Loss: 0.5817, Val Loss: 0.5547, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 113, Train Loss: 0.5798, Val Loss: 0.5538, F1 Micro: 0.6910, F1 Macro: 0.6584, Accuracy: 0.6910\n","Epoch 114, Train Loss: 0.5829, Val Loss: 0.5524, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 115, Train Loss: 0.5829, Val Loss: 0.5531, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 116, Train Loss: 0.5820, Val Loss: 0.5526, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 117, Train Loss: 0.5798, Val Loss: 0.5546, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 118, Train Loss: 0.5792, Val Loss: 0.5526, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 119, Train Loss: 0.5818, Val Loss: 0.5545, F1 Micro: 0.7022, F1 Macro: 0.6733, Accuracy: 0.7022\n","Epoch 120, Train Loss: 0.5800, Val Loss: 0.5546, F1 Micro: 0.6910, F1 Macro: 0.6610, Accuracy: 0.6910\n","Epoch 121, Train Loss: 0.5791, Val Loss: 0.5526, F1 Micro: 0.6966, F1 Macro: 0.6516, Accuracy: 0.6966\n","Epoch 122, Train Loss: 0.5792, Val Loss: 0.5528, F1 Micro: 0.6966, F1 Macro: 0.6606, Accuracy: 0.6966\n","Epoch 123, Train Loss: 0.5802, Val Loss: 0.5547, F1 Micro: 0.6966, F1 Macro: 0.6683, Accuracy: 0.6966\n","Epoch 124, Train Loss: 0.5804, Val Loss: 0.5527, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 125, Train Loss: 0.5811, Val Loss: 0.5553, F1 Micro: 0.6854, F1 Macro: 0.6560, Accuracy: 0.6854\n","Epoch 126, Train Loss: 0.5822, Val Loss: 0.5522, F1 Micro: 0.6966, F1 Macro: 0.6547, Accuracy: 0.6966\n","Epoch 127, Train Loss: 0.5799, Val Loss: 0.5538, F1 Micro: 0.6966, F1 Macro: 0.6633, Accuracy: 0.6966\n","Epoch 128, Train Loss: 0.5783, Val Loss: 0.5524, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 129, Train Loss: 0.5813, Val Loss: 0.5529, F1 Micro: 0.6854, F1 Macro: 0.6451, Accuracy: 0.6854\n","Epoch 130, Train Loss: 0.5793, Val Loss: 0.5553, F1 Micro: 0.6910, F1 Macro: 0.6634, Accuracy: 0.6910\n","Epoch 131, Train Loss: 0.5896, Val Loss: 0.5524, F1 Micro: 0.7022, F1 Macro: 0.6626, Accuracy: 0.7022\n","Epoch 132, Train Loss: 0.5808, Val Loss: 0.5532, F1 Micro: 0.6854, F1 Macro: 0.6480, Accuracy: 0.6854\n","Early stopping triggered\n","Inner FOLD 3\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 7.0665, Val Loss: 5.4188, F1 Micro: 0.3708, F1 Macro: 0.3337, Accuracy: 0.3708\n","Epoch 2, Train Loss: 5.9694, Val Loss: 4.6511, F1 Micro: 0.3539, F1 Macro: 0.3337, Accuracy: 0.3539\n","Epoch 3, Train Loss: 5.0270, Val Loss: 3.9774, F1 Micro: 0.3820, F1 Macro: 0.3724, Accuracy: 0.3820\n","Epoch 4, Train Loss: 4.1597, Val Loss: 3.3931, F1 Micro: 0.3764, F1 Macro: 0.3759, Accuracy: 0.3764\n","Epoch 5, Train Loss: 3.3255, Val Loss: 2.9348, F1 Micro: 0.4045, F1 Macro: 0.4026, Accuracy: 0.4045\n","Epoch 6, Train Loss: 2.6936, Val Loss: 2.6055, F1 Micro: 0.4213, F1 Macro: 0.4132, Accuracy: 0.4213\n","Epoch 7, Train Loss: 2.2322, Val Loss: 2.3335, F1 Micro: 0.4607, F1 Macro: 0.4470, Accuracy: 0.4607\n","Epoch 8, Train Loss: 1.9408, Val Loss: 2.0953, F1 Micro: 0.4944, F1 Macro: 0.4646, Accuracy: 0.4944\n","Epoch 9, Train Loss: 1.6356, Val Loss: 1.8472, F1 Micro: 0.4944, F1 Macro: 0.4615, Accuracy: 0.4944\n","Epoch 10, Train Loss: 1.4302, Val Loss: 1.6285, F1 Micro: 0.5056, F1 Macro: 0.4595, Accuracy: 0.5056\n","Epoch 11, Train Loss: 1.2626, Val Loss: 1.4458, F1 Micro: 0.5169, F1 Macro: 0.4549, Accuracy: 0.5169\n","Epoch 12, Train Loss: 1.1491, Val Loss: 1.3087, F1 Micro: 0.5281, F1 Macro: 0.4529, Accuracy: 0.5281\n","Epoch 13, Train Loss: 1.0603, Val Loss: 1.1842, F1 Micro: 0.5225, F1 Macro: 0.4380, Accuracy: 0.5225\n","Epoch 14, Train Loss: 0.9915, Val Loss: 1.0869, F1 Micro: 0.5281, F1 Macro: 0.4358, Accuracy: 0.5281\n","Epoch 15, Train Loss: 0.9246, Val Loss: 1.0079, F1 Micro: 0.5169, F1 Macro: 0.4091, Accuracy: 0.5169\n","Epoch 16, Train Loss: 0.8664, Val Loss: 0.9445, F1 Micro: 0.5112, F1 Macro: 0.3987, Accuracy: 0.5112\n","Epoch 17, Train Loss: 0.8191, Val Loss: 0.8825, F1 Micro: 0.5169, F1 Macro: 0.3946, Accuracy: 0.5169\n","Epoch 18, Train Loss: 0.7779, Val Loss: 0.8383, F1 Micro: 0.5169, F1 Macro: 0.3946, Accuracy: 0.5169\n","Epoch 19, Train Loss: 0.7482, Val Loss: 0.8074, F1 Micro: 0.5056, F1 Macro: 0.3724, Accuracy: 0.5056\n","Epoch 20, Train Loss: 0.7302, Val Loss: 0.7839, F1 Micro: 0.5000, F1 Macro: 0.3611, Accuracy: 0.5000\n","Epoch 21, Train Loss: 0.7189, Val Loss: 0.7637, F1 Micro: 0.5000, F1 Macro: 0.3611, Accuracy: 0.5000\n","Epoch 22, Train Loss: 0.7119, Val Loss: 0.7516, F1 Micro: 0.5056, F1 Macro: 0.3640, Accuracy: 0.5056\n","Epoch 23, Train Loss: 0.7069, Val Loss: 0.7435, F1 Micro: 0.5056, F1 Macro: 0.3640, Accuracy: 0.5056\n","Epoch 24, Train Loss: 0.7040, Val Loss: 0.7370, F1 Micro: 0.5112, F1 Macro: 0.3669, Accuracy: 0.5112\n","Epoch 25, Train Loss: 0.7014, Val Loss: 0.7325, F1 Micro: 0.5112, F1 Macro: 0.3669, Accuracy: 0.5112\n","Epoch 26, Train Loss: 0.6997, Val Loss: 0.7280, F1 Micro: 0.5169, F1 Macro: 0.3697, Accuracy: 0.5169\n","Epoch 27, Train Loss: 0.6984, Val Loss: 0.7256, F1 Micro: 0.5169, F1 Macro: 0.3697, Accuracy: 0.5169\n","Epoch 28, Train Loss: 0.6975, Val Loss: 0.7233, F1 Micro: 0.5169, F1 Macro: 0.3697, Accuracy: 0.5169\n","Epoch 29, Train Loss: 0.6969, Val Loss: 0.7218, F1 Micro: 0.5169, F1 Macro: 0.3697, Accuracy: 0.5169\n","Epoch 30, Train Loss: 0.6963, Val Loss: 0.7198, F1 Micro: 0.5169, F1 Macro: 0.3697, Accuracy: 0.5169\n","Epoch 31, Train Loss: 0.6961, Val Loss: 0.7175, F1 Micro: 0.5169, F1 Macro: 0.3697, Accuracy: 0.5169\n","Epoch 32, Train Loss: 0.6944, Val Loss: 0.7158, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 33, Train Loss: 0.6949, Val Loss: 0.7143, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 34, Train Loss: 0.6945, Val Loss: 0.7135, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 35, Train Loss: 0.6942, Val Loss: 0.7120, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 36, Train Loss: 0.6942, Val Loss: 0.7108, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 37, Train Loss: 0.6940, Val Loss: 0.7102, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 38, Train Loss: 0.6939, Val Loss: 0.7095, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 39, Train Loss: 0.6936, Val Loss: 0.7084, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 40, Train Loss: 0.6929, Val Loss: 0.7078, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 41, Train Loss: 0.6934, Val Loss: 0.7070, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 42, Train Loss: 0.6932, Val Loss: 0.7058, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 43, Train Loss: 0.6931, Val Loss: 0.7051, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 44, Train Loss: 0.6929, Val Loss: 0.7046, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 45, Train Loss: 0.6929, Val Loss: 0.7042, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 46, Train Loss: 0.6928, Val Loss: 0.7033, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 47, Train Loss: 0.6927, Val Loss: 0.7026, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 48, Train Loss: 0.6926, Val Loss: 0.7024, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 49, Train Loss: 0.6926, Val Loss: 0.7019, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 50, Train Loss: 0.6925, Val Loss: 0.7015, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 51, Train Loss: 0.6925, Val Loss: 0.7013, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 52, Train Loss: 0.6924, Val Loss: 0.7009, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 53, Train Loss: 0.6924, Val Loss: 0.7009, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 54, Train Loss: 0.6924, Val Loss: 0.7007, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 55, Train Loss: 0.6924, Val Loss: 0.7005, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 56, Train Loss: 0.6924, Val Loss: 0.7002, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 57, Train Loss: 0.6924, Val Loss: 0.7000, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 58, Train Loss: 0.6924, Val Loss: 0.6996, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 59, Train Loss: 0.6924, Val Loss: 0.6994, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 60, Train Loss: 0.6923, Val Loss: 0.6989, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 61, Train Loss: 0.6922, Val Loss: 0.6982, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Epoch 62, Train Loss: 0.6921, Val Loss: 0.6978, F1 Micro: 0.5112, F1 Macro: 0.3578, Accuracy: 0.5112\n","Early stopping triggered\n","Inner FOLD 4\n","Hyperparameters: LR=0.001, Batch Size=16, Patience=50\n","Epoch 1, Train Loss: 0.6891, Val Loss: 0.5783, F1 Micro: 0.6573, F1 Macro: 0.5286, Accuracy: 0.6573\n","Epoch 2, Train Loss: 0.5857, Val Loss: 0.5730, F1 Micro: 0.6629, F1 Macro: 0.5603, Accuracy: 0.6629\n","Epoch 3, Train Loss: 0.5819, Val Loss: 0.5678, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 4, Train Loss: 0.5840, Val Loss: 0.5631, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 5, Train Loss: 0.5850, Val Loss: 0.5634, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 6, Train Loss: 0.5792, Val Loss: 0.5608, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 7, Train Loss: 0.5828, Val Loss: 0.5643, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 8, Train Loss: 0.5856, Val Loss: 0.5564, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 9, Train Loss: 0.5802, Val Loss: 0.5582, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 10, Train Loss: 0.5815, Val Loss: 0.5580, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 11, Train Loss: 0.5867, Val Loss: 0.5594, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 12, Train Loss: 0.5829, Val Loss: 0.5581, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 13, Train Loss: 0.5816, Val Loss: 0.5568, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 14, Train Loss: 0.5806, Val Loss: 0.5577, F1 Micro: 0.6685, F1 Macro: 0.5513, Accuracy: 0.6685\n","Epoch 15, Train Loss: 0.5818, Val Loss: 0.5586, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 16, Train Loss: 0.5793, Val Loss: 0.5589, F1 Micro: 0.6854, F1 Macro: 0.5836, Accuracy: 0.6854\n","Epoch 17, Train Loss: 0.5830, Val Loss: 0.5588, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 18, Train Loss: 0.5801, Val Loss: 0.5546, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 19, Train Loss: 0.5784, Val Loss: 0.5557, F1 Micro: 0.6798, F1 Macro: 0.5730, Accuracy: 0.6798\n","Epoch 20, Train Loss: 0.5782, Val Loss: 0.5541, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 21, Train Loss: 0.5788, Val Loss: 0.5543, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 22, Train Loss: 0.5768, Val Loss: 0.5552, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 23, Train Loss: 0.5815, Val Loss: 0.5538, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 24, Train Loss: 0.5809, Val Loss: 0.5527, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 25, Train Loss: 0.5822, Val Loss: 0.5566, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 26, Train Loss: 0.5779, Val Loss: 0.5547, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 27, Train Loss: 0.5762, Val Loss: 0.5540, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 28, Train Loss: 0.5778, Val Loss: 0.5557, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 29, Train Loss: 0.5800, Val Loss: 0.5506, F1 Micro: 0.6629, F1 Macro: 0.5401, Accuracy: 0.6629\n","Epoch 30, Train Loss: 0.5780, Val Loss: 0.5534, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 31, Train Loss: 0.5828, Val Loss: 0.5566, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 32, Train Loss: 0.5793, Val Loss: 0.5528, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 33, Train Loss: 0.5763, Val Loss: 0.5559, F1 Micro: 0.6798, F1 Macro: 0.5961, Accuracy: 0.6798\n","Epoch 34, Train Loss: 0.5792, Val Loss: 0.5506, F1 Micro: 0.6742, F1 Macro: 0.5622, Accuracy: 0.6742\n","Epoch 35, Train Loss: 0.5801, Val Loss: 0.5540, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 36, Train Loss: 0.5811, Val Loss: 0.5512, F1 Micro: 0.6854, F1 Macro: 0.5896, Accuracy: 0.6854\n","Epoch 37, Train Loss: 0.5779, Val Loss: 0.5541, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 38, Train Loss: 0.5798, Val Loss: 0.5520, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 39, Train Loss: 0.5776, Val Loss: 0.5551, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 40, Train Loss: 0.5777, Val Loss: 0.5508, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 41, Train Loss: 0.5811, Val Loss: 0.5504, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 42, Train Loss: 0.5784, Val Loss: 0.5519, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 43, Train Loss: 0.5793, Val Loss: 0.5536, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 44, Train Loss: 0.5778, Val Loss: 0.5512, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 45, Train Loss: 0.5795, Val Loss: 0.5555, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 46, Train Loss: 0.5784, Val Loss: 0.5513, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 47, Train Loss: 0.5789, Val Loss: 0.5492, F1 Micro: 0.6798, F1 Macro: 0.5852, Accuracy: 0.6798\n","Epoch 48, Train Loss: 0.5825, Val Loss: 0.5491, F1 Micro: 0.6798, F1 Macro: 0.5793, Accuracy: 0.6798\n","Epoch 49, Train Loss: 0.5888, Val Loss: 0.5521, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 50, Train Loss: 0.5785, Val Loss: 0.5530, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 51, Train Loss: 0.5768, Val Loss: 0.5506, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 52, Train Loss: 0.5791, Val Loss: 0.5506, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 53, Train Loss: 0.5824, Val Loss: 0.5523, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 54, Train Loss: 0.5784, Val Loss: 0.5472, F1 Micro: 0.6854, F1 Macro: 0.5953, Accuracy: 0.6854\n","Epoch 55, Train Loss: 0.5784, Val Loss: 0.5501, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 56, Train Loss: 0.5800, Val Loss: 0.5464, F1 Micro: 0.6910, F1 Macro: 0.5997, Accuracy: 0.6910\n","Epoch 57, Train Loss: 0.5813, Val Loss: 0.5481, F1 Micro: 0.6910, F1 Macro: 0.6052, Accuracy: 0.6910\n","Epoch 58, Train Loss: 0.5781, Val Loss: 0.5474, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 59, Train Loss: 0.5778, Val Loss: 0.5473, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 60, Train Loss: 0.5790, Val Loss: 0.5474, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 61, Train Loss: 0.5787, Val Loss: 0.5530, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 62, Train Loss: 0.5760, Val Loss: 0.5499, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 63, Train Loss: 0.5779, Val Loss: 0.5512, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Epoch 64, Train Loss: 0.5778, Val Loss: 0.5526, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 65, Train Loss: 0.5797, Val Loss: 0.5468, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 66, Train Loss: 0.5791, Val Loss: 0.5554, F1 Micro: 0.6742, F1 Macro: 0.6061, Accuracy: 0.6742\n","Epoch 67, Train Loss: 0.5786, Val Loss: 0.5474, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 68, Train Loss: 0.5783, Val Loss: 0.5514, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 69, Train Loss: 0.5782, Val Loss: 0.5497, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 70, Train Loss: 0.5795, Val Loss: 0.5472, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 71, Train Loss: 0.5790, Val Loss: 0.5488, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 72, Train Loss: 0.5801, Val Loss: 0.5471, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 73, Train Loss: 0.5781, Val Loss: 0.5477, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 74, Train Loss: 0.5777, Val Loss: 0.5484, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 75, Train Loss: 0.5795, Val Loss: 0.5490, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 76, Train Loss: 0.5797, Val Loss: 0.5470, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 77, Train Loss: 0.5790, Val Loss: 0.5486, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 78, Train Loss: 0.5783, Val Loss: 0.5478, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 79, Train Loss: 0.5793, Val Loss: 0.5472, F1 Micro: 0.6854, F1 Macro: 0.6106, Accuracy: 0.6854\n","Epoch 80, Train Loss: 0.5761, Val Loss: 0.5484, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 81, Train Loss: 0.5805, Val Loss: 0.5451, F1 Micro: 0.6685, F1 Macro: 0.5581, Accuracy: 0.6685\n","Epoch 82, Train Loss: 0.5783, Val Loss: 0.5518, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 83, Train Loss: 0.5816, Val Loss: 0.5515, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 84, Train Loss: 0.5761, Val Loss: 0.5456, F1 Micro: 0.6910, F1 Macro: 0.6103, Accuracy: 0.6910\n","Epoch 85, Train Loss: 0.5802, Val Loss: 0.5467, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 86, Train Loss: 0.5775, Val Loss: 0.5522, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 87, Train Loss: 0.5789, Val Loss: 0.5467, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 88, Train Loss: 0.5827, Val Loss: 0.5450, F1 Micro: 0.6854, F1 Macro: 0.6006, Accuracy: 0.6854\n","Epoch 89, Train Loss: 0.5807, Val Loss: 0.5470, F1 Micro: 0.6854, F1 Macro: 0.6058, Accuracy: 0.6854\n","Epoch 90, Train Loss: 0.5806, Val Loss: 0.5494, F1 Micro: 0.6742, F1 Macro: 0.6015, Accuracy: 0.6742\n","Epoch 91, Train Loss: 0.5793, Val Loss: 0.5477, F1 Micro: 0.6798, F1 Macro: 0.6061, Accuracy: 0.6798\n","Early stopping triggered\n","Average Score for hyperparameters (0.001, 16, 50): 0.6620990521624505\n","Best hyperparameters for Outer FOLD 4: (0.01, 16, 50) with score 0.7036720858703157\n","Epoch 1, Train Loss: 0.9729, Val Loss: 0.6568, F1 Micro: 0.6486, F1 Macro: 0.5678, Accuracy: 0.6486\n","Epoch 2, Train Loss: 0.7026, Val Loss: 0.6660, F1 Micro: 0.6216, F1 Macro: 0.5152, Accuracy: 0.6216\n","Epoch 3, Train Loss: 0.6948, Val Loss: 0.6697, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 4, Train Loss: 0.6915, Val Loss: 0.6725, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 5, Train Loss: 0.6900, Val Loss: 0.6751, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 6, Train Loss: 0.6897, Val Loss: 0.6707, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 7, Train Loss: 0.6897, Val Loss: 0.6706, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 8, Train Loss: 0.6895, Val Loss: 0.6716, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 9, Train Loss: 0.6893, Val Loss: 0.6703, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 10, Train Loss: 0.6891, Val Loss: 0.6725, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 11, Train Loss: 0.6898, Val Loss: 0.6736, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 12, Train Loss: 0.6897, Val Loss: 0.6766, F1 Micro: 0.6036, F1 Macro: 0.4683, Accuracy: 0.6036\n","Epoch 13, Train Loss: 0.6895, Val Loss: 0.6720, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 14, Train Loss: 0.6891, Val Loss: 0.6695, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 15, Train Loss: 0.6890, Val Loss: 0.6731, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 16, Train Loss: 0.6887, Val Loss: 0.6698, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 17, Train Loss: 0.6884, Val Loss: 0.6675, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 18, Train Loss: 0.6888, Val Loss: 0.6747, F1 Micro: 0.6036, F1 Macro: 0.4683, Accuracy: 0.6036\n","Epoch 19, Train Loss: 0.6887, Val Loss: 0.6711, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 20, Train Loss: 0.6887, Val Loss: 0.6696, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 21, Train Loss: 0.6885, Val Loss: 0.6699, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 22, Train Loss: 0.6883, Val Loss: 0.6732, F1 Micro: 0.6036, F1 Macro: 0.4683, Accuracy: 0.6036\n","Epoch 23, Train Loss: 0.6887, Val Loss: 0.6687, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 24, Train Loss: 0.6889, Val Loss: 0.6724, F1 Micro: 0.6036, F1 Macro: 0.4683, Accuracy: 0.6036\n","Epoch 25, Train Loss: 0.6883, Val Loss: 0.6661, F1 Micro: 0.6216, F1 Macro: 0.5043, Accuracy: 0.6216\n","Epoch 26, Train Loss: 0.6886, Val Loss: 0.6680, F1 Micro: 0.6171, F1 Macro: 0.4955, Accuracy: 0.6171\n","Epoch 27, Train Loss: 0.6894, Val Loss: 0.6749, F1 Micro: 0.6036, F1 Macro: 0.4683, Accuracy: 0.6036\n","Epoch 28, Train Loss: 0.6887, Val Loss: 0.6722, F1 Micro: 0.6081, F1 Macro: 0.4775, Accuracy: 0.6081\n","Epoch 29, Train Loss: 0.6882, Val Loss: 0.6658, F1 Micro: 0.6216, F1 Macro: 0.5043, Accuracy: 0.6216\n","Epoch 30, Train Loss: 0.6886, Val Loss: 0.6611, F1 Micro: 0.6171, F1 Macro: 0.5013, Accuracy: 0.6171\n","Epoch 31, Train Loss: 0.6891, Val Loss: 0.6674, F1 Micro: 0.6171, F1 Macro: 0.4955, Accuracy: 0.6171\n","Epoch 32, Train Loss: 0.6872, Val Loss: 0.6698, F1 Micro: 0.6081, F1 Macro: 0.4775, Accuracy: 0.6081\n","Epoch 33, Train Loss: 0.6900, Val Loss: 0.6683, F1 Micro: 0.6171, F1 Macro: 0.4955, Accuracy: 0.6171\n","Epoch 34, Train Loss: 0.6931, Val Loss: 0.6637, F1 Micro: 0.6306, F1 Macro: 0.5216, Accuracy: 0.6306\n","Epoch 35, Train Loss: 0.6926, Val Loss: 0.6850, F1 Micro: 0.5901, F1 Macro: 0.4398, Accuracy: 0.5901\n","Epoch 36, Train Loss: 0.6924, Val Loss: 0.6843, F1 Micro: 0.5901, F1 Macro: 0.4398, Accuracy: 0.5901\n","Epoch 37, Train Loss: 0.6923, Val Loss: 0.6830, F1 Micro: 0.5901, F1 Macro: 0.4398, Accuracy: 0.5901\n","Epoch 38, Train Loss: 0.6911, Val Loss: 0.6746, F1 Micro: 0.5991, F1 Macro: 0.4589, Accuracy: 0.5991\n","Epoch 39, Train Loss: 0.6872, Val Loss: 0.6648, F1 Micro: 0.6261, F1 Macro: 0.5130, Accuracy: 0.6261\n","Epoch 40, Train Loss: 0.6865, Val Loss: 0.6670, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 41, Train Loss: 0.6876, Val Loss: 0.6692, F1 Micro: 0.6081, F1 Macro: 0.4775, Accuracy: 0.6081\n","Epoch 42, Train Loss: 0.6862, Val Loss: 0.6582, F1 Micro: 0.6351, F1 Macro: 0.5399, Accuracy: 0.6351\n","Epoch 43, Train Loss: 0.6870, Val Loss: 0.6653, F1 Micro: 0.6216, F1 Macro: 0.5043, Accuracy: 0.6216\n","Epoch 44, Train Loss: 0.6905, Val Loss: 0.6688, F1 Micro: 0.6126, F1 Macro: 0.4866, Accuracy: 0.6126\n","Epoch 45, Train Loss: 0.6909, Val Loss: 0.6762, F1 Micro: 0.5991, F1 Macro: 0.4589, Accuracy: 0.5991\n","Epoch 46, Train Loss: 0.6882, Val Loss: 0.6651, F1 Micro: 0.6306, F1 Macro: 0.5268, Accuracy: 0.6306\n","Epoch 47, Train Loss: 0.6838, Val Loss: 0.6546, F1 Micro: 0.6306, F1 Macro: 0.5499, Accuracy: 0.6306\n","Epoch 48, Train Loss: 0.6819, Val Loss: 0.6521, F1 Micro: 0.6441, F1 Macro: 0.5760, Accuracy: 0.6441\n","Epoch 49, Train Loss: 0.6814, Val Loss: 0.6615, F1 Micro: 0.6396, F1 Macro: 0.5479, Accuracy: 0.6396\n","Epoch 50, Train Loss: 0.6770, Val Loss: 0.6473, F1 Micro: 0.6712, F1 Macro: 0.6207, Accuracy: 0.6712\n","Epoch 51, Train Loss: 0.6746, Val Loss: 0.6500, F1 Micro: 0.6712, F1 Macro: 0.6235, Accuracy: 0.6712\n","Epoch 52, Train Loss: 0.6655, Val Loss: 0.6442, F1 Micro: 0.7207, F1 Macro: 0.6899, Accuracy: 0.7207\n","Epoch 53, Train Loss: 0.6603, Val Loss: 0.6428, F1 Micro: 0.7072, F1 Macro: 0.6717, Accuracy: 0.7072\n","Epoch 54, Train Loss: 0.6565, Val Loss: 0.6267, F1 Micro: 0.7252, F1 Macro: 0.7112, Accuracy: 0.7252\n","Epoch 55, Train Loss: 0.6563, Val Loss: 0.6409, F1 Micro: 0.7117, F1 Macro: 0.6819, Accuracy: 0.7117\n","Epoch 56, Train Loss: 0.6566, Val Loss: 0.6342, F1 Micro: 0.7162, F1 Macro: 0.6914, Accuracy: 0.7162\n","Epoch 57, Train Loss: 0.6566, Val Loss: 0.6424, F1 Micro: 0.7117, F1 Macro: 0.6819, Accuracy: 0.7117\n","Epoch 58, Train Loss: 0.6566, Val Loss: 0.6328, F1 Micro: 0.7252, F1 Macro: 0.7028, Accuracy: 0.7252\n","Epoch 59, Train Loss: 0.6547, Val Loss: 0.6281, F1 Micro: 0.7387, F1 Macro: 0.7210, Accuracy: 0.7387\n","Epoch 60, Train Loss: 0.6586, Val Loss: 0.6315, F1 Micro: 0.7252, F1 Macro: 0.7028, Accuracy: 0.7252\n","Epoch 61, Train Loss: 0.6553, Val Loss: 0.6286, F1 Micro: 0.7207, F1 Macro: 0.7058, Accuracy: 0.7207\n","Epoch 62, Train Loss: 0.6563, Val Loss: 0.6275, F1 Micro: 0.7297, F1 Macro: 0.7127, Accuracy: 0.7297\n","Epoch 63, Train Loss: 0.6573, Val Loss: 0.6332, F1 Micro: 0.7252, F1 Macro: 0.7012, Accuracy: 0.7252\n","Epoch 64, Train Loss: 0.6589, Val Loss: 0.6495, F1 Micro: 0.6802, F1 Macro: 0.6252, Accuracy: 0.6802\n","Epoch 65, Train Loss: 0.6592, Val Loss: 0.6322, F1 Micro: 0.7162, F1 Macro: 0.6878, Accuracy: 0.7162\n","Epoch 66, Train Loss: 0.6533, Val Loss: 0.6284, F1 Micro: 0.7252, F1 Macro: 0.7073, Accuracy: 0.7252\n","Epoch 67, Train Loss: 0.6558, Val Loss: 0.6301, F1 Micro: 0.7162, F1 Macro: 0.6962, Accuracy: 0.7162\n","Epoch 68, Train Loss: 0.6554, Val Loss: 0.6275, F1 Micro: 0.7162, F1 Macro: 0.6946, Accuracy: 0.7162\n","Epoch 69, Train Loss: 0.6551, Val Loss: 0.6339, F1 Micro: 0.7297, F1 Macro: 0.7035, Accuracy: 0.7297\n","Epoch 70, Train Loss: 0.6542, Val Loss: 0.6322, F1 Micro: 0.7252, F1 Macro: 0.6995, Accuracy: 0.7252\n","Epoch 71, Train Loss: 0.6546, Val Loss: 0.6287, F1 Micro: 0.7252, F1 Macro: 0.7028, Accuracy: 0.7252\n","Epoch 72, Train Loss: 0.6577, Val Loss: 0.6310, F1 Micro: 0.7297, F1 Macro: 0.7035, Accuracy: 0.7297\n","Epoch 73, Train Loss: 0.6540, Val Loss: 0.6273, F1 Micro: 0.7252, F1 Macro: 0.7073, Accuracy: 0.7252\n","Epoch 74, Train Loss: 0.6561, Val Loss: 0.6313, F1 Micro: 0.7162, F1 Macro: 0.6896, Accuracy: 0.7162\n","Epoch 75, Train Loss: 0.6547, Val Loss: 0.6272, F1 Micro: 0.7207, F1 Macro: 0.7003, Accuracy: 0.7207\n","Epoch 76, Train Loss: 0.6541, Val Loss: 0.6284, F1 Micro: 0.7207, F1 Macro: 0.7003, Accuracy: 0.7207\n","Epoch 77, Train Loss: 0.6558, Val Loss: 0.6263, F1 Micro: 0.7207, F1 Macro: 0.7017, Accuracy: 0.7207\n","Epoch 78, Train Loss: 0.6560, Val Loss: 0.6260, F1 Micro: 0.7342, F1 Macro: 0.7155, Accuracy: 0.7342\n","Epoch 79, Train Loss: 0.6575, Val Loss: 0.6309, F1 Micro: 0.7162, F1 Macro: 0.6914, Accuracy: 0.7162\n","Epoch 80, Train Loss: 0.6537, Val Loss: 0.6367, F1 Micro: 0.7117, F1 Macro: 0.6778, Accuracy: 0.7117\n","Epoch 81, Train Loss: 0.6549, Val Loss: 0.6332, F1 Micro: 0.7072, F1 Macro: 0.6738, Accuracy: 0.7072\n","Epoch 82, Train Loss: 0.6538, Val Loss: 0.6307, F1 Micro: 0.7117, F1 Macro: 0.6838, Accuracy: 0.7117\n","Epoch 83, Train Loss: 0.6538, Val Loss: 0.6274, F1 Micro: 0.7207, F1 Macro: 0.7017, Accuracy: 0.7207\n","Epoch 84, Train Loss: 0.6541, Val Loss: 0.6323, F1 Micro: 0.7117, F1 Macro: 0.6838, Accuracy: 0.7117\n","Epoch 85, Train Loss: 0.6540, Val Loss: 0.6326, F1 Micro: 0.7027, F1 Macro: 0.6739, Accuracy: 0.7027\n","Epoch 86, Train Loss: 0.6544, Val Loss: 0.6308, F1 Micro: 0.7072, F1 Macro: 0.6798, Accuracy: 0.7072\n","Epoch 87, Train Loss: 0.6542, Val Loss: 0.6335, F1 Micro: 0.7162, F1 Macro: 0.6818, Accuracy: 0.7162\n","Epoch 88, Train Loss: 0.6570, Val Loss: 0.6368, F1 Micro: 0.7027, F1 Macro: 0.6632, Accuracy: 0.7027\n","Epoch 89, Train Loss: 0.6568, Val Loss: 0.6362, F1 Micro: 0.7027, F1 Macro: 0.6678, Accuracy: 0.7027\n","Epoch 90, Train Loss: 0.6540, Val Loss: 0.6275, F1 Micro: 0.7297, F1 Macro: 0.7084, Accuracy: 0.7297\n","Epoch 91, Train Loss: 0.6553, Val Loss: 0.6305, F1 Micro: 0.7162, F1 Macro: 0.6896, Accuracy: 0.7162\n","Epoch 92, Train Loss: 0.6554, Val Loss: 0.6318, F1 Micro: 0.7072, F1 Macro: 0.6759, Accuracy: 0.7072\n","Epoch 93, Train Loss: 0.6552, Val Loss: 0.6348, F1 Micro: 0.7072, F1 Macro: 0.6738, Accuracy: 0.7072\n","Epoch 94, Train Loss: 0.6537, Val Loss: 0.6320, F1 Micro: 0.7027, F1 Macro: 0.6719, Accuracy: 0.7027\n","Epoch 95, Train Loss: 0.6538, Val Loss: 0.6276, F1 Micro: 0.7162, F1 Macro: 0.6977, Accuracy: 0.7162\n","Epoch 96, Train Loss: 0.6554, Val Loss: 0.6309, F1 Micro: 0.7162, F1 Macro: 0.6896, Accuracy: 0.7162\n","Epoch 97, Train Loss: 0.6544, Val Loss: 0.6307, F1 Micro: 0.7117, F1 Macro: 0.6838, Accuracy: 0.7117\n","Epoch 98, Train Loss: 0.6561, Val Loss: 0.6295, F1 Micro: 0.7117, F1 Macro: 0.6856, Accuracy: 0.7117\n","Epoch 99, Train Loss: 0.6551, Val Loss: 0.6272, F1 Micro: 0.7252, F1 Macro: 0.7058, Accuracy: 0.7252\n","Epoch 100, Train Loss: 0.6561, Val Loss: 0.6365, F1 Micro: 0.6982, F1 Macro: 0.6569, Accuracy: 0.6982\n","Epoch 101, Train Loss: 0.6565, Val Loss: 0.6374, F1 Micro: 0.6937, F1 Macro: 0.6530, Accuracy: 0.6937\n","Epoch 102, Train Loss: 0.6560, Val Loss: 0.6381, F1 Micro: 0.6757, F1 Macro: 0.6244, Accuracy: 0.6757\n","Epoch 103, Train Loss: 0.6556, Val Loss: 0.6323, F1 Micro: 0.6982, F1 Macro: 0.6699, Accuracy: 0.6982\n","Epoch 104, Train Loss: 0.6550, Val Loss: 0.6293, F1 Micro: 0.7162, F1 Macro: 0.6896, Accuracy: 0.7162\n","Epoch 105, Train Loss: 0.6544, Val Loss: 0.6283, F1 Micro: 0.7162, F1 Macro: 0.6946, Accuracy: 0.7162\n","Epoch 106, Train Loss: 0.6545, Val Loss: 0.6284, F1 Micro: 0.7252, F1 Macro: 0.7012, Accuracy: 0.7252\n","Epoch 107, Train Loss: 0.6541, Val Loss: 0.6278, F1 Micro: 0.7162, F1 Macro: 0.6946, Accuracy: 0.7162\n","Epoch 108, Train Loss: 0.6535, Val Loss: 0.6363, F1 Micro: 0.7027, F1 Macro: 0.6678, Accuracy: 0.7027\n","Epoch 109, Train Loss: 0.6561, Val Loss: 0.6351, F1 Micro: 0.7072, F1 Macro: 0.6717, Accuracy: 0.7072\n","Early stopping triggered\n","Test set evaluation - F1 Micro: 0.7072, F1 Macro: 0.6717, Accuracy: 0.7072\n"]}]},{"cell_type":"code","source":["print(np.mean(f1_micro_test_list))\n","print(np.mean(f1_macro_test_list))\n","print(np.mean(accuracy_test_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QOqxvjHT6gn","executionInfo":{"status":"ok","timestamp":1711499366619,"user_tz":-60,"elapsed":262,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"8a9f9db3-d9fd-4f3e-9f55-7598b8857ba5"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6936775340362784\n","0.6447894038088363\n","0.6936775340362784\n"]}]},{"cell_type":"code","source":["# Initialize a dictionary to store metrics for different models\n","models_evaluation_metrics = {}\n","\n","# Example model identifiers\n","model_names = ['BasicGraphModel', 'GraphSAGEModel', 'GINModel']\n","\n","# Initialize metric dictionaries for each model\n","for model_name in model_names:\n","    models_evaluation_metrics[model_name] = {'f1_micro': [], 'f1_macro': [], 'accuracy': []}\n","\n","def update_model_metrics(model_name, f1_micro, f1_macro, accuracy):\n","    models_evaluation_metrics[model_name]['f1_micro'].append(f1_micro)\n","    models_evaluation_metrics[model_name]['f1_macro'].append(f1_macro)\n","    models_evaluation_metrics[model_name]['accuracy'].append(accuracy)\n","\n","update_model_metrics('BasicGraphModel', f1_micro_test_list, f1_macro_test_list, accuracy_test_list)\n","\n","print(models_evaluation_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8haKn8GT9af","executionInfo":{"status":"ok","timestamp":1711499380184,"user_tz":-60,"elapsed":2,"user":{"displayName":"Haoran XIONG","userId":"03070642770817180472"}},"outputId":"21a18aea-1d38-4696-a2fa-70722d131408"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["{'BasicGraphModel': {'f1_micro': [[0.6905829596412556, 0.7219730941704036, 0.6053811659192825, 0.7432432432432431, 0.7072072072072072]], 'f1_macro': [[0.6474510253179058, 0.5684769038701623, 0.6030744336569579, 0.7332349530937072, 0.6717097031054488]], 'accuracy': [[0.6905829596412556, 0.7219730941704036, 0.6053811659192825, 0.7432432432432432, 0.7072072072072072]]}, 'GraphSAGEModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}, 'GINModel': {'f1_micro': [], 'f1_macro': [], 'accuracy': []}}\n"]}]}]}